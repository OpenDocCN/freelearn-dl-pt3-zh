["```\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import initializers\nimport matplotlib.pyplot as plt\nimport numpy as np \n```", "```\nrandomDim = 10\n(X_train, _), (_,  _) = mnist.load_data()\nX_train = (X_train.astype(np.float32) - 127.5)/127.5 \n```", "```\nX_train = X_train.reshape(60000, 784) \n```", "```\ngenerator = Sequential()\ngenerator.add(Dense(256, input_dim=randomDim))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(Dense(512))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(Dense(1024))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(Dense(784, activation='tanh')) \n```", "```\ndiscriminator = Sequential()\ndiscriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02))\n)\ndiscriminator.add(LeakyReLU(0.2))\ndiscriminator.add(Dropout(0.3))\ndiscriminator.add(Dense(512))\ndiscriminator.add(LeakyReLU(0.2))\ndiscriminator.add(Dropout(0.3))\ndiscriminator.add(Dense(256))\ndiscriminator.add(LeakyReLU(0.2))\ndiscriminator.add(Dropout(0.3))\ndiscriminator.add(Dense(1, activation='sigmoid')) \n```", "```\ndiscriminator.trainable = False\nganInput = Input(shape=(randomDim,))\nx = generator(ganInput)\nganOutput = discriminator(x)\ngan = Model(inputs=ganInput, outputs=ganOutput) \n```", "```\ndiscriminator.compile(loss='binary_crossentropy', optimizer='adam')\ngan.compile(loss='binary_crossentropy', optimizer='adam') \n```", "```\ndef train(epochs=1, batchSize=128):\n    batchCount = int(X_train.shape[0] / batchSize)\n    print ('Epochs:', epochs)\n    print ('Batch size:', batchSize)\n    print ('Batches per epoch:', batchCount)\n    for e in range(1, epochs+1):\n        print ('-'*15, 'Epoch %d' % e, '-'*15)\n        for _ in range(batchCount):\n            # Get a random set of input noise and images\n            noise = np.random.normal(0, 1, size=[batchSize,\n            randomDim])\n            imageBatch = X_train[np.random.randint(0,\n            X_train.shape[0], size=batchSize)]\n            # Generate fake MNIST images\n            generatedImages = generator.predict(noise)\n            # print np.shape(imageBatch), np.shape(generatedImages)\n            X = np.concatenate([imageBatch, generatedImages])\n            # Labels for generated and real data\n            yDis = np.zeros(2*batchSize)\n            # One-sided label smoothing\n            yDis[:batchSize] = 0.9\n            # Train discriminator\n            discriminator.trainable = True\n            dloss = discriminator.train_on_batch(X, yDis) \n```", "```\n # Train generator\n            noise = np.random.normal(0, 1, size=[batchSize,\n            randomDim])\n            yGen = np.ones(batchSize)\n            discriminator.trainable = False\n            gloss = gan.train_on_batch(noise, yGen) \n```", "```\n # Store loss of most recent batch from this epoch\n        dLosses.append(dloss)\n        gLosses.append(gloss)\n        if e == 1 or e % 20 == 0:\n               saveGeneratedImages(e) \n```", "```\n# Plot the loss from each batch\ndef plotLoss(epoch):\n    plt.figure(figsize=(10, 8))\n    plt.plot(dLosses, label='Discriminitive loss')\n    plt.plot(gLosses, label='Generative loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('images/gan_loss_epoch_%d.png' % epoch)\n# Create a wall of generated MNIST images\ndef saveGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n    noise = np.random.normal(0, 1, size=[examples, randomDim])\n    generatedImages = generator.predict(noise)\n    generatedImages = generatedImages.reshape(examples, 28, 28)\n    plt.figure(figsize=figsize)\n    for i in range(generatedImages.shape[0]):\n        plt.subplot(dim[0], dim[1], i+1)\n        plt.imshow(generatedImages[i], interpolation='nearest',\n        cmap='gray_r')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.savefig('images/gan_generated_image_epoch_%d.png' % epoch) \n```", "```\ndef build_generator(self):\n    model = Sequential()\n    model.add(Dense(128 * 7 * 7, activation=\"relu\",\n    input_dim=self.latent_dim))\n    model.add(Reshape((7, 7, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n    model.summary()\n    noise = Input(shape=(self.latent_dim,))\n    img = model(noise)\n    return Model(noise, img) \n```", "```\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_3 (Conv2D)           (None, 14, 14, 32)        320       \n\n leaky_re_lu (LeakyReLU)     (None, 14, 14, 32)        0         \n\n dropout (Dropout)           (None, 14, 14, 32)        0         \n\n conv2d_4 (Conv2D)           (None, 7, 7, 64)          18496     \n\n zero_padding2d (ZeroPadding  (None, 8, 8, 64)         0         \n 2D)                                                             \n\n batch_normalization_2 (Batc  (None, 8, 8, 64)         256       \n hNormalization)                                                 \n\n leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 64)          0         \n\n dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n\n conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n\n batch_normalization_3 (Batc  (None, 4, 4, 128)        512       \n hNormalization)                                                 \n\n leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n\n dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n\n conv2d_6 (Conv2D)           (None, 4, 4, 256)         295168    \n\n batch_normalization_4 (Batc  (None, 4, 4, 256)        1024      \n hNormalization)                                                 \n\n leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n\n dropout_3 (Dropout)         (None, 4, 4, 256)         0         \n\n flatten (Flatten)           (None, 4096)              0         \n\n dense_1 (Dense)             (None, 1)                 4097      \n\n=================================================================\nTotal params: 393,729\nTrainable params: 392,833\nNon-trainable params: 896 \n```", "```\ndef build_discriminator(self):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=3, strides=2,\n    input_shape=self.img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n    img = Input(shape=self.img_shape)\n    validity = model(img)\n    return Model(img, validity) \n```", "```\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 6272)              633472    \n\n reshape (Reshape)           (None, 7, 7, 128)         0         \n\n up_sampling2d (UpSampling2D  (None, 14, 14, 128)      0         \n )                                                               \n\n conv2d (Conv2D)             (None, 14, 14, 128)       147584    \n\n batch_normalization (BatchN  (None, 14, 14, 128)      512       \n ormalization)                                                   \n\n activation (Activation)     (None, 14, 14, 128)       0         \n\n up_sampling2d_1 (UpSampling  (None, 28, 28, 128)      0         \n 2D)                                                             \n\n conv2d_1 (Conv2D)           (None, 28, 28, 64)        73792     \n\n batch_normalization_1 (Batc  (None, 28, 28, 64)       256       \n hNormalization)                                                 \n\n activation_1 (Activation)   (None, 28, 28, 64)        0         \n\n conv2d_2 (Conv2D)           (None, 28, 28, 1)         577       \n\n activation_2 (Activation)   (None, 28, 28, 1)         0         \n\n=================================================================\nTotal params: 856,193\nTrainable params: 855,809\nNon-trainable params: 384\n_________________________________________________________________ \n```", "```\nclass DCGAN():\n    def __init__(self, rows, cols, channels, z = 10):\n        # Input shape\n        self.img_rows = rows\n        self.img_cols = cols\n        self.channels = channels\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.latent_dim = z\n        optimizer = Adam(0.0002, 0.5)\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss=’binary_crossentropy’,\n            optimizer=optimizer,\n            metrics=[‘accuracy’])\n        # Build the generator\n        self.generator = self.build_generator()\n        # The generator takes noise as input and generates imgs\n        z = Input(shape=(self.latent_dim,))\n        img = self.generator(z)\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n        # The discriminator takes generated images as input and determines validity\n        valid = self.discriminator(img)\n        # The combined model  (stacked generator and discriminator)\n        # Trains the generator to fool the discriminator\n        self.combined = Model(z, valid)\n        self.combined.compile(loss=’binary_crossentropy’, optimizer=optimizer) \n```", "```\n def train(self, epochs, batch_size=256, save_interval=50):\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n        # Rescale -1 to 1\n        X_train = X_train / 127.5 - 1.\n        X_train = np.expand_dims(X_train, axis=3)\n        # Adversarial ground truths\n        valid = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n        for epoch in range(epochs):\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n            # Select a random half of images\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs = X_train[idx]\n            # Sample noise and generate a batch of new images\n            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n            gen_imgs = self.generator.predict(noise)\n            # Train the discriminator (real classified as ones and generated as zeros)\n            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n            # Train the generator (wants discriminator to mistake images as real)\n            g_loss = self.combined.train_on_batch(noise, valid)\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n            # If at save interval => save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch) \n```", "```\n def save_imgs(self, epoch):\n        r, c = 5, 5\n        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n        gen_imgs = self.generator.predict(noise)\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"images/dcgan_mnist_%d.png\" % epoch)\n        plt.close() \n```", "```\ndcgan = DCGAN(28,28,1)\ndcgan.train(epochs=5000, batch_size=256, save_interval=50) \n```", "```\nimport tensorflow_datasets as tfds\nfrom tensorflow_examples.models.pix2pix import pix2pix\nimport os\nimport time\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport tensorflow as tf \n```", "```\ndataset, metadata = tfds.load('cycle_gan/summer2winter_yosemite',\n                              with_info=True, as_supervised=True)\ntrain_summer, train_winter = dataset['trainA'], dataset['trainB']\ntest_summer, test_winter = dataset['testA'], dataset['testB'] \n```", "```\nBUFFER_SIZE = 1000\nBATCH_SIZE = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nEPOCHS = 100\nLAMBDA = 10\nAUTOTUNE = tf.data.AUTOTUNE \n```", "```\ndef normalize(input_image, label):\n    input_image = tf.cast(input_image, tf.float32)\n    input_image = (input_image / 127.5) - 1\n    return input_image\ndef random_crop(image):\n    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT,\n    IMG_WIDTH, 3])\n    return cropped_image\ndef random_jitter(image):\n    # resizing to 286 x 286 x 3\n    image = tf.image.resize(image, [286, 286],\n    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    # randomly cropping to 256 x 256 x 3\n    image = random_crop(image)\n    # random mirroring\n    image = tf.image.random_flip_left_right(image)\n    return image \n```", "```\ndef preprocess_image_train(image, label):\n    image = random_jitter(image)\n    image = normalize(image)\n    return image\ndef preprocess_image_test(image, label):\n    image = normalize(image)\n    return image \n```", "```\ntrain_summer = train_summer.cache().map(\n    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\ntrain_winter = train_winter.cache().map(\n    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\ntest_summer = test_summer.map(\n    preprocess_image_test,\n    num_parallel_calls=AUTOTUNE).cache().shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE)\ntest_winter = test_winter.map(\n    preprocess_image_test,\n    num_parallel_calls=AUTOTUNE).cache().shuffle(\n    BUFFER_SIZE).batch(BATCH_SIZE) \n```", "```\nOUTPUT_CHANNELS = 3\ngenerator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\ngenerator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\ndiscriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\ndiscriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False) \n```", "```\nto_winter = generator_g(sample_summer)\nto_summer = generator_f(sample_winter)\nplt.figure(figsize=(8, 8))\ncontrast = 8\nimgs = [sample_summer, to_winter, sample_winter, to_summer]\ntitle = ['Summer', 'To Winter', 'Winter', 'To Summer']\nfor i in range(len(imgs)):\n  plt.subplot(2, 2, i+1)\n  plt.title(title[i])\n  if i % 2 == 0:\n    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n  else:\n    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\nplt.show() \n```", "```\nloss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real, generated):\n    real_loss = loss_obj(tf.ones_like(real), real)\n    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n    total_disc_loss = real_loss + generated_loss\n    return total_disc_loss * 0.5\ndef generator_loss(generated):\n    return loss_obj(tf.ones_like(generated), generated) \n```", "```\ngenerator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ngenerator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\ndiscriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5) \n```", "```\ndef calc_cycle_loss(real_image, cycled_image):\n    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n    return LAMBDA * loss1 \n```", "```\ndef identity_loss(real_image, same_image):\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return LAMBDA * 0.5 * loss \n```", "```\n    @tf.function\n    def train_step(real_x, real_y):\n        # persistent is set to True because the tape is used\n        # more than once to calculate the gradients.\n      with tf.GradientTape(persistent=True) as tape:\n        # Generator G translates X -> Y\n        # Generator F translates Y -> X.\n\n        fake_y = generator_g(real_x, training=True)\n        cycled_x = generator_f(fake_y, training=True)\n        fake_x = generator_f(real_y, training=True)\n        cycled_y = generator_g(fake_x, training=True)\n        # same_x and same_y are used for identity loss.\n        same_x = generator_f(real_x, training=True)\n        same_y = generator_g(real_y, training=True)\n        disc_real_x = discriminator_x(real_x, training=True)\n        disc_real_y = discriminator_y(real_y, training=True)\n        disc_fake_x = discriminator_x(fake_x, training=True)\n        disc_fake_y = discriminator_y(fake_y, training=True)\n        # calculate the loss\n        gen_g_loss = generator_loss(disc_fake_y)\n        gen_f_loss = generator_loss(disc_fake_x)\n\n        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + \\\n        calc_cycle_loss(real_y, cycled_y)\n\n        # Total generator loss = adversarial loss + cycle loss\n        total_gen_g_loss = gen_g_loss + total_cycle_loss + \\\n        identity_loss(real_y, same_y)\n        total_gen_f_loss = gen_f_loss + total_cycle_loss + \\\n        identity_loss(real_x, same_x)\n        disc_x_loss = discriminator_loss(disc_real_x,\n        disc_fake_x)\n        disc_y_loss = discriminator_loss(disc_real_y,\n        disc_fake_y)\n        # Calculate the gradients for generator and discriminator\n        generator_g_gradients = tape.gradient(total_gen_g_loss,\n        generator_g.trainable_variables)\n        generator_f_gradients = tape.gradient(total_gen_f_loss,\n        generator_f.trainable_variables)\n        discriminator_x_gradients = tape.gradient(disc_x_loss,\n        discriminator_x.trainable_variables)\n        discriminator_y_gradients = tape.gradient(disc_y_loss,\n        discriminator_y.trainable_variables)\n        # Apply the gradients to the optimizer\n        generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n        generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n        discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n        discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables)) \n    ```", "```\ncheckpoint_path = \"./checkpoints/train\"\nckpt = tf.train.Checkpoint(generator_g=generator_g,\n                           generator_f=generator_f,\n                           discriminator_x=discriminator_x,\n                           discriminator_y=discriminator_y,\n                           generator_g_optimizer=generator_g_optimizer,\ngenerator_f_optimizer=generator_f_optimizer,\ndiscriminator_x_optimizer=discriminator_x_optimizer,\ndiscriminator_y_optimizer=discriminator_y_optimizer)\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n# if a checkpoint exists, restore the latest checkpoint.\nif ckpt_manager.latest_checkpoint:\n    ckpt.restore(ckpt_manager.latest_checkpoint)\n    print ('Latest checkpoint restored!!') \n```", "```\nfor epoch in range(EPOCHS):\n    start = time.time()\n    n = 0\n    for image_x, image_y in tf.data.Dataset.zip((train_summer, train_winter)):\n        train_step(image_x, image_y)\n        if n % 10 == 0:\n            print ('.', end='')\n        n += 1\n    clear_output(wait=True)\n    # Using a consistent image (sample_summer) so that the progress of\n    # the model is clearly visible.\n    generate_images(generator_g, sample_summer)\n    if (epoch + 1) % 5 == 0:\n        ckpt_save_path = ckpt_manager.save()\n        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n                                                             ckpt_save_path))\n    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n                                                        time.time()-start)) \n```"]