<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer574">
<h1 class="chapterNumber">13</h1>
<h1 class="chapterTitle" id="_idParaDest-353">An Introduction to AutoML</h1>
<p class="normal">The goal of AutoML is to enable domain experts who are unfamiliar with machine learning technologies to use ML techniques easily.</p>
<p class="normal">In this chapter, we will go through a practical exercise using Google Cloud Platform and do quite a bit of hands-on work after briefly discussing the fundamentals.</p>
<p class="normal">We will cover:</p>
<ul>
<li class="bulletList">Automatic data preparation</li>
<li class="bulletList">Automatic feature engineering</li>
<li class="bulletList">Automatic model generation</li>
<li class="bulletList">AutoKeras</li>
<li class="bulletList">Google Cloud AutoML with its multiple solutions for table, vision, text, translation, and video processing</li>
</ul>
<p class="normal">Let’s begin with an introduction to AutoML.</p>
<h1 class="heading-1" id="_idParaDest-354">What is AutoML?</h1>
<p class="normal">During the previous chapters, we introduced several models used in modern machine learning and deep learning. For<a id="_idIndexMarker1325"/> instance, we have seen architectures such as dense networks, CNNs, RNNs, autoencoders, and GANs.</p>
<p class="normal">Two observations are in order. First, these architectures are manually designed by deep learning experts and are not necessarily easy to explain to non-experts. Second, the composition of these architectures themselves was a manual process, which involved a lot of human intuition and trial and error.</p>
<p class="normal">Today, one primary goal of artificial intelligence research is to achieve <strong class="keyWord">Artificial General Intelligence</strong> (<strong class="keyWord">AGI</strong>) – the intelligence of a <a id="_idIndexMarker1326"/>machine that can understand and automatically learn any type of work or activity that a human being can do. It should be noted that many researchers do not believe that AGI is achievable because there is not only one form of intelligence but many forms. </p>
<p class="normal">Personally, I tend to agree with this view. See <a href="https://twitter.com/ylecun/status/1526672565233758213"><span class="url">https://twitter.com/ylecun/status/1526672565233758213</span></a> for Yann LeCun’s position on this subject. However, the reality was very different before AutoML research and industrial applications<a id="_idIndexMarker1327"/> started. Indeed, before AutoML, designing deep learning architectures was very similar to crafting – the activity or hobby of making decorative articles by hand.</p>
<p class="normal">Take, for instance, the task of recognizing breast cancer from X-rays. After reading the previous chapters, you will probably think that a deep learning pipeline created by composing several CNNs may be an appropriate tool for this purpose. That is probably a good intuition to start with. The problem is that it is not easy to explain to the users of your model why a <em class="italic">particular</em> composition of CNN works well within the breast cancer detection domain. Ideally, you want to provide easily accessible deep learning tools to the domain experts (in this case, medical professionals) without such a tool requiring a strong machine learning background.</p>
<p class="normal">The other problem is that it is not easy to understand whether or not there are variants (for example, different compositions) of the original manually crafted model that can achieve better results. Ideally, you want to provide deep learning tools for exploring the space of variants (for example, different compositions) in a more principled and automatic way.</p>
<p class="normal">So, the central idea of AutoML is to reduce the steep learning curve and the huge costs of handcrafting machine learning solutions by making the whole end-to-end machine learning pipeline more automated. To this end, we assume that the AutoML pipeline consists of three macro-steps: data preparation, feature engineering, and automatic model generation, as shown in <em class="italic">Figure 13.1</em>:</p>
<figure class="mediaobject"><img alt="Text, letter  Description automatically generated with medium confidence" height="205" src="../Images/B18331_13_01.png" width="696"/></figure>
<p class="packt_figref">Figure 13.1: Three steps of an AutoML pipeline</p>
<p class="normal">Throughout the<a id="_idIndexMarker1328"/> initial part of this chapter, we are going to discuss these three steps in detail. Then, we will focus on Google Cloud AutoML.</p>
<h1 class="heading-1" id="_idParaDest-355">Achieving AutoML</h1>
<p class="normal">How can AutoML <a id="_idIndexMarker1329"/>achieve the goal of end-to-end automatization? Well, you have probably already guessed that a natural choice is to use machine learning – that’s very cool. AutoML uses ML for automating ML pipelines.</p>
<p class="normal">What are the benefits? Automating the creation and tuning of machine learning end to end offers simpler solutions, reduces the time to produce them, and ultimately might produce architectures that could potentially outperform models that were crafted by hand.</p>
<p class="normal">Is this a closed research area? Quite the opposite. At the beginning of 2022, AutoML is a very open research field, which is not surprising, as the initial paper drawing attention to AutoML was published at the end of 2016.</p>
<h1 class="heading-1" id="_idParaDest-356">Automatic data preparation</h1>
<p class="normal">The first stage of a typical machine<a id="_idIndexMarker1330"/> learning pipeline deals with data preparation (recall the pipeline in <em class="italic">Figure 13.1</em>). There are two main aspects that should be taken into account: data cleansing and data synthesis:</p>
<p class="normal"><strong class="keyWord">Data cleansing</strong> is about improving<a id="_idIndexMarker1331"/> the quality of data by checking for wrong data types, missing values, and errors, and by applying data normalization, bucketization, scaling, and encoding. A robust AutoML pipeline should automate all of these mundane but extremely important steps as much as possible.</p>
<p class="normal"><strong class="keyWord">Data synthesis</strong> is about generating <a id="_idIndexMarker1332"/>synthetic data via augmentation for training, evaluation, and validation. Normally, this step is domain-specific. For instance, we have seen how to generate synthetic CIFAR10-like images (<em class="chapterRef">Chapter 4</em>) by using cropping, rotation, resizing, and flipping operations. One can also think about generating additional images or video<a id="_idIndexMarker1333"/> via GANs (see <em class="chapterRef">Chapter 9</em>) and using the augmented synthetic dataset for training. A different approach should be taken for text, where it is possible to train RNNs (<em class="chapterRef">Chapter 5</em>) to generate synthetic text or to adopt more NLP techniques such as BERT, Seq2Seq, or Transformers (see <em class="chapterRef">Chapter 6</em>) to annotate or translate text across languages and then translate it back to the original one – another domain-specific form of augmentation.</p>
<p class="normal">A different approach is to generate synthetic environments where machine learning can occur. This became very popular in reinforcement learning and gaming, especially with toolkits such as OpenAI Gym, which aims to provide an easy-to-set-up simulation environment with a variety of different (gaming) scenarios.</p>
<p class="normal">Put simply, we can say that synthetic data generation is another option that should be provided by AutoML engines. Frequently, the tools used are very domain-specific and what works for image or video would not necessarily work in other domains such as text. Therefore, we need a (quite) large set of tools for performing synthetic data generation across domains.</p>
<h1 class="heading-1" id="_idParaDest-357">Automatic feature engineering</h1>
<p class="normal">Feature engineering is the <a id="_idIndexMarker1334"/>second step of a typical machine learning pipeline (see <em class="italic">Figure 13.1</em>). It consists of three major steps: feature selection, feature construction, and feature mapping. Let’s look at each of them in turn:</p>
<p class="normal"><strong class="keyWord">Feature selection</strong> aims at <a id="_idIndexMarker1335"/>selecting a subset of <em class="italic">meaningful</em> features by discarding those that are making little contribution to the learning task. In this context, “meaningful” truly depends on the application and the domain of your specific problem.</p>
<p class="normal"><strong class="keyWord">Feature construction</strong> has the goal of building new derived features, starting from the basic ones. Frequently, this technique is <a id="_idIndexMarker1336"/>used to allow better generalization and to have a richer representation of the data.</p>
<p class="normal"><strong class="keyWord">Feature mapping</strong> aims at altering the <a id="_idIndexMarker1337"/>original feature space by means of a mapping function. This can be implemented in multiple ways; for instance, it can use autoencoders (see <em class="chapterRef">Chapter 8</em>), PCA (see <em class="chapterRef">Chapter 7</em>), or clustering (see <em class="chapterRef">Chapter 7</em>).</p>
<p class="normal">In short, feature<a id="_idIndexMarker1338"/> engineering is an art based on intuition, trial and error, and a lot of human experience. Modern AutoML engines aim to make the entire process more automated, requiring less human intervention.</p>
<h1 class="heading-1" id="_idParaDest-358">Automatic model generation</h1>
<p class="normal">Model generation and <a id="_idIndexMarker1339"/>hyperparameter tuning is the typical third macro-step of a machine learning pipeline (see <em class="italic">Figure 13.1</em>).</p>
<p class="normal"><strong class="keyWord">Model generation</strong> consists of creating <a id="_idIndexMarker1340"/>a suitable model for solving specific tasks. For instance, you will probably use CNNs for visual recognition, and you will use RNNs for either time series analysis or for sequences. Of course, many variants are possible, each of which is manually crafted through a process of trial and error and works for very specific domains.</p>
<p class="normal"><strong class="keyWord">Hyperparameter tuning</strong> happens once the<a id="_idIndexMarker1341"/> model is manually crafted. This process is generally very computationally expensive and can significantly change the quality of the results in a positive way. That’s because tuning the hyperparameters can help to optimize our model further.</p>
<p class="normal">Automatic model generation is the ultimate goal of any AutoML pipeline. How can this be achieved? One approach consists of generating the model by combining a set of primitive operations including convolution, pooling, concatenation, skip connections, recurrent neural networks, autoencoders, and pretty much all the deep learning models we have encountered throughout this book. These operations constitute a (typically very large) search space to be explored, and the goal is to make this exploration as efficient as possible. In AutoML jargon, the exploration is called <strong class="keyWord">NAS</strong>, or <strong class="keyWord">Neural Architecture Search</strong>. The seminal paper on AutoML [1] was produced in November 2016. The key idea (see <em class="italic">Figure 13.2</em>) is to use reinforcement learning (RL, see <em class="chapterRef">Chapter 11</em>). An RNN acts as the controller, and it generates the model descriptions of candidate neural networks. RL is used to maximize the expected accuracy of the generated architectures on a validation set.</p>
<p class="normal">On the CIFAR-10 dataset, this method, starting from scratch, designed a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. The CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, the model can compose a novel recurrent cell that outperforms the widely used LSTM cell (see <em class="chapterRef">Chapter 9</em>) and other state-of-the-art baselines. The cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 better than the previous state-of-the-art model.</p>
<p class="normal">The key outcome <a id="_idIndexMarker1342"/>of the paper is shown in <em class="italic">Figure 13.2</em>. A controller network based on RNNs produces a sample architecture A with probability p. This candidate architecture A is trained by a child network to get a candidate accuracy R. Then a gradient of p is computed and scaled by R to update the controller. This reinforcement learning operation is computed in a cycle a number of times. The process of generating an architecture stops if the number of layers exceeds a certain value. </p>
<p class="normal">The details of how an RL-based policy gradient method is used by the controller RNN to generate better architectures are in [1]. Here we emphasize the fact that NAS uses a meta-modeling algorithm based on Q-learning with an ϵ-greedy exploration strategy and with experience replay (see <em class="chapterRef">Chapter 11</em>) to explore the model search space:</p>
<figure class="mediaobject"><img alt="Diagram  Description automatically generated" height="342" src="../Images/B18331_13_02.png" width="742"/></figure>
<p class="packt_figref">Figure 13.2: NAS with recurrent neural networks</p>
<p class="normal">Since the original paper in late 2016, a Cambrian explosion of model generation techniques has been observed. Initially, the goal was to generate the entire model in one single step. Later, a<em class="italic"> cell-based </em>approach was proposed where the generation is divided into two macro-steps: first, a cell structure is automatically built, and then a predefined number of discovered cells are stacked<a id="_idIndexMarker1343"/> together to generate an entire end-to-end architecture [2]. This <strong class="keyWord">Efficient Neural Architecture Search</strong> (<strong class="keyWord">ENAS</strong>) delivers strong empirical performance using significantly fewer GPU hours compared with all existing automatic model design approaches, and notably, is 1,000x less computationally expensive than standard neural architecture search (in 2018). Here, the primary ENAS goal is to reduce the search space via hierarchical composition. Variants of the cell-based approach have been proposed including pure hierarchical methods where higher-level cells are generated by incorporating lower-level cells iteratively.</p>
<p class="normal">A completely different <a id="_idIndexMarker1344"/>approach to NAS is to use transfer learning (see <em class="chapterRef">Chapter 5</em>) to transfer the learning of an existing neural network into a new neural network in order to speed up the design [3]. In other words, we want to use transfer learning in AutoML.</p>
<p class="normal">Another approach is<a id="_idIndexMarker1345"/> based on <strong class="keyWord">Genetic Programming</strong> (<strong class="keyWord">GP</strong>) and <strong class="keyWord">Evolutionary Algorithms</strong> (<strong class="keyWord">EAs</strong>), where the<a id="_idIndexMarker1346"/> basic operations constituting the model search space are encoded into a suitable representation, and then this encoding is gradually mutated to progressively better models in a way that resembles the genetic evolution of living beings [4].</p>
<p class="normal"><strong class="keyWord">Hyperparameter tuning </strong>consists of <a id="_idIndexMarker1347"/>finding the optimal combination of hyperparameters both related to learning optimization (batch size, learning rate, and so on) and model-specific ones (kernel size; number of feature maps and so on for CNNs; or number of neurons for dense or autoencoder networks, and so on). Again, the search space can be extremely large. There are three approaches generally used: Bayesian optimization, grid search, and random search.</p>
<p class="normal"><strong class="keyWord">Bayesian optimization</strong> builds a probability <a id="_idIndexMarker1348"/>model of the objective function and uses it to select the most promising hyperparameters to evaluate in the true objective function.</p>
<p class="normal"><strong class="keyWord">Grid search</strong> divides the search space into a<a id="_idIndexMarker1349"/> discrete grid of values and tests all the possible combinations in the grid. For instance, if there are three hyperparameters and a grid with only two candidate values for each of them, then a total of 2 x 3 = 6 combinations must be checked. There are also hierarchical variants of grid search, which progressively refine the grid for regions of the search space and provide better results. The key idea is to use a coarse grid first, and after finding a better grid region, implement a finer grid search on that region.</p>
<p class="normal"><strong class="keyWord">Random search</strong> performs a random <a id="_idIndexMarker1350"/>sampling of the parameter search space, and this simple approach has been proven to work very well in many situations [5].</p>
<p class="normal">Now that we have briefly discussed the fundamentals, we will do quite a bit of hands-on work on Google Cloud. Let’s start.</p>
<h1 class="heading-1" id="_idParaDest-359">AutoKeras</h1>
<p class="normal">AutoKeras [6] provides functions to <a id="_idIndexMarker1351"/>automatically search for architecture and hyperparameters of deep learning models. The framework uses Bayesian optimization for efficient neural architecture search. You can install the alpha version by using <code class="inlineCode">pip</code>:</p>
<pre class="programlisting con"><code class="hljs-con">pip3 install autokeras # for 1.19 version
</code></pre>
<p class="normal">The architecture is explained in <em class="italic">Figure 13.3</em> [6]: </p>
<figure class="mediaobject"><img alt="Chart  Description automatically generated with medium confidence" height="356" src="../Images/B18331_13_03.png" width="480"/></figure>
<p class="packt_figref">Figure 13.3: AutoKeras system overview</p>
<p class="normal">The architecture follows these steps:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">The user calls the API.</li>
<li class="numberedList">The searcher generates neural architectures on the CPU.</li>
<li class="numberedList">Real neural networks with parameters are built on RAM from the neural architectures.</li>
<li class="numberedList">The neural network is copied to the GPU for training.</li>
<li class="numberedList">The trained<a id="_idIndexMarker1352"/> neural networks are saved on storage devices.</li>
<li class="numberedList">The searcher is updated based on the training results.</li>
</ol>
<p class="normal">Steps 2 to 6 will repeat until a time limit is reached.</p>
<h1 class="heading-1" id="_idParaDest-360">Google Cloud AutoML and Vertex AI</h1>
<p class="normal">Google Cloud AutoML (<a href="https://cloud.google.com/automl/"><span class="url">https://cloud.google.com/automl/</span></a>) is a full suite of products for image, video, and text processing. AutoML <a id="_idIndexMarker1353"/>can be used to train high-quality custom machine learning models with minimal effort and machine learning expertise.</p>
<p class="normal">Vertex AI brings together the Google Cloud services for building ML under one, unified UI and API. In Vertex AI, you can now easily train, compare, test, and deploy models. Then you can serve a model with sophisticated ways to monitor and run experiments (see <a href="https://cloud.google.com/vertex-ai"><span class="url">https://cloud.google.com/vertex-ai</span></a>).</p>
<p class="normal">As of 2022, the suite consists of the following components, which do not require you to know how the deep learning networks are shaped internally:</p>
<p class="normal"><strong class="keyWord">Vertex AI</strong></p>
<ul>
<li class="bulletList">Unified <a id="_idIndexMarker1354"/>platform to help you build, deploy, and scale more AI models</li>
</ul>
<p class="normal"><strong class="keyWord">Structured data</strong></p>
<ul>
<li class="bulletList">AutoML Tables: Automatically build and deploy state-of-the-art machine learning models on structured data</li>
</ul>
<p class="normal"><strong class="keyWord">Sight</strong></p>
<ul>
<li class="bulletList">AutoML Image: Derive insights from object detection and image classification, in the cloud or at the edge</li>
<li class="bulletList">AutoML Video: Enable powerful content discovery and engaging video experiences</li>
</ul>
<p class="normal"><strong class="keyWord">Language</strong></p>
<ul>
<li class="bulletList">AutoML Text: Reveal the structure and meaning of text through machine learning</li>
<li class="bulletList">AutoML Translation: Dynamically detect and translate between languages</li>
</ul>
<p class="normal">In the remainder of this <a id="_idIndexMarker1355"/>chapter, we will review three AutoML solutions: AutoML Tables, AutoML Text, and AutoML Video.</p>
<h2 class="heading-2" id="_idParaDest-361">Using the Google Cloud AutoML Tables solution</h2>
<p class="normal">Let’s see an example of<a id="_idIndexMarker1356"/> using Google Cloud AutoML Tables. We’ll aim to import some tabular data and train a classifier on that data; we’ll use some marketing data from a bank. Note that this and the following examples might be charged by Google according to different usage criteria (please check online for the latest cost estimation – see <a href="https://cloud.google.com/products/calculator/"><span class="url">https://cloud.google.com/products/calculator/</span></a>). </p>
<p class="normal">The first step required is to enable the Vertex AI API:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, website  Description automatically generated" height="545" src="../Images/B18331_13_04.png" width="771"/></figure>
<p class="packt_figref">Figure 13.4: Enable the Vertex AI API</p>
<p class="normal">We can then select the <strong class="screenText">TABULAR</strong> dataset from the console (see <em class="italic">Figure 13.5</em>). The name of the dataset is <code class="inlineCode">bank-marketing.csv</code>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="350" src="../Images/B18331_13_05.png" width="665"/></figure>
<p class="packt_figref">Figure 13.5: Selecting TABULAR datasets</p>
<p class="normal">On the next screen, we indicate<a id="_idIndexMarker1357"/> that we want to load the data from CSV:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" height="492" src="../Images/B18331_13_06.png" width="458"/></figure>
<p class="packt_figref">Figure 13.6: AutoML Tables – loading data from a CSV file</p>
<p class="normal">Next, we can train <a id="_idIndexMarker1358"/>a new model, as shown in <em class="italic">Figure 13.7</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, chat or text message  Description automatically generated" height="262" src="../Images/B18331_13_07.png" width="422"/></figure>
<p class="packt_figref">Figure 13.7: Training a new model</p>
<p class="normal">Several options for training are offered for <strong class="screenText">Classification</strong> and <strong class="screenText">Regression</strong>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" height="620" src="../Images/B18331_13_08.png" width="527"/></figure>
<p class="packt_figref">Figure 13.8: Options offered for Classification and Regression</p>
<p class="normal">Let’s select the target as the <strong class="screenText">Deposit</strong> column. The dataset is described at <a href="https://archive.ics.uci.edu/ml/datasets/bank+marketing"><span class="url">https://archive.ics.uci.edu/ml/datasets/bank+marketing</span></a>. The data is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is<a id="_idIndexMarker1359"/> to predict if the client will subscribe to a term deposit.</p>
<p class="normal">Since the selected column is categorical data, AutoML Tables will build a classification model. This will predict the target from the classes in the selected column. The classification is binary: <em class="italic">1</em> represents a negative outcome, meaning that a deposit is not made at the bank; <em class="italic">2</em> represents a positive outcome, meaning that a deposit is made at the bank, as shown in <em class="italic">Figure 13.9</em>:</p>
<figure class="mediaobject"><img alt="Text, application  Description automatically generated" height="340" src="../Images/B18331_13_09.png" width="594"/></figure>
<p class="packt_figref">Figure 13.9: Training a new model with Target column set to Deposit</p>
<p class="normal">We can then inspect<a id="_idIndexMarker1360"/> the dataset (see <em class="italic">Figure 13.10</em>), which gives us the opportunity to inspect the dataset with several features, such as <em class="italic">names</em>, <em class="italic">type</em>, <em class="italic">missing values</em>, <em class="italic">distinct values</em>, <em class="italic">invalid values, correlation with the target</em>, <em class="italic">mean</em>, and<em class="italic"> standard deviation</em>:</p>
<figure class="mediaobject"><img alt="Table  Description automatically generated" height="620" src="../Images/B18331_13_10.png" width="519"/></figure>
<p class="packt_figref">Figure 13.10: AutoML Tables – inspecting the dataset</p>
<p class="normal">It is now time to<a id="_idIndexMarker1361"/> train the model by using the <strong class="screenText">Train</strong> tab. First let’s give a budget for training, as shown in <em class="italic">Figure 13.11</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" height="418" src="../Images/B18331_13_11.png" width="803"/></figure>
<p class="packt_figref">Figure 13.11: Setting up the budget for training</p>
<p class="normal">In this example, we accept <strong class="screenText">3</strong> hours as our training budget. During this time, you can go and take a coffee <a id="_idIndexMarker1362"/>whilst AutoML works on your behalf (see <em class="italic">Figure 13.12</em>). The training budget is a number between 1 and 72 for the maximum number of node hours to spend training your model. If your model stops improving before then, AutoML Tables will stop training and you’ll only be charged the money corresponding to the actual node budget used:</p>
<figure class="mediaobject"><img alt="Text  Description automatically generated" height="163" src="../Images/B18331_13_12.png" width="456"/></figure>
<p class="packt_figref">Figure 13.12: AutoML Tables training process</p>
<p class="normal">While training, we can check the progress, as shown in <em class="italic">Figure 13.13</em>:</p>
<figure class="mediaobject"><img alt="Table  Description automatically generated" height="484" src="../Images/B18331_13_13.png" width="459"/></figure>
<p class="packt_figref">Figure 13.13: Checking the training progress</p>
<p class="normal">After less than one<a id="_idIndexMarker1363"/> hour, Google AutoML should send an email to our inbox:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" height="283" src="../Images/B18331_13_14.png" width="577"/></figure>
<p class="packt_figref">Figure 13.14: AutoML Tables: training is concluded, and an email is sent to my account</p>
<p class="normal">Clicking on the suggested URL, it is possible to see the results of our training. The AutoML-generated model reached an accuracy of 94% (see <em class="italic">Figure 13.15</em>). Remember that accuracy is the fraction of classification predictions produced by the model that were correct on a test, set which is held automatically. The log-loss (for example, the cross-entropy between<a id="_idIndexMarker1364"/> the model predictions and the label values) is also provided. In the case of log-loss, a lower value indicates a higher-quality model:</p>
<figure class="mediaobject"><img alt="Chart, line chart  Description automatically generated" height="309" src="../Images/B18331_13_15.png" width="810"/></figure>
<p class="packt_figref">Figure 13.15: AutoML Tables – analyzing the results of our training</p>
<p class="normal">In addition, the <strong class="keyWord">Area Under the Receiver Operating Characteristic Curve</strong> (<strong class="keyWord">AUC ROC</strong>) is represented. This ranges from zero to one, and <a id="_idIndexMarker1365"/>a higher value indicates a higher-quality model. This statistic summarizes an AUC ROC curve, which is a graph showing the performance of a classification model at all classification<a id="_idIndexMarker1366"/> thresholds. The <strong class="keyWord">True Positive Rate</strong> (<strong class="keyWord">TPR</strong>) (also known as “recall”) is:</p>
<p class="center"><img alt="" height="92" src="../Images/B18331_13_001.png" style="height: 2.30em !important; vertical-align: 0.05em !important;" width="288"/></p>
<p class="normal">where <em class="italic">TP</em> is the number of true positives <a id="_idIndexMarker1367"/>and <em class="italic">FN</em> is the number of false negatives. The <strong class="keyWord">False Positive Rate</strong> (<strong class="keyWord">FPR</strong>) is:</p>
<p class="center"><img alt="" height="92" src="../Images/B18331_13_002.png" style="height: 2.30em !important; vertical-align: 0.05em !important;" width="292"/></p>
<p class="normal">where <em class="italic">FP</em> is the number of false positives and <em class="italic">TN</em> is the number of true negatives.</p>
<p class="normal">A ROC curve plots TPR vs. FPR at different classification<a id="_idIndexMarker1368"/> thresholds. In <em class="italic">Figure 13.16</em> you will see the <strong class="keyWord">Area Under the Curve</strong> (<strong class="keyWord">AUC</strong>) for one threshold of a ROC curve:</p>
<figure class="mediaobject"><img alt="Chart, line chart  Description automatically generated" height="401" src="../Images/B18331_13_16.png" width="755"/></figure>
<p class="packt_figref">Figure 13.16: AutoML Tables – deep dive on the results of our training</p>
<p class="normal">It is possible to deep dive into <a id="_idIndexMarker1369"/>the evaluation and access the confusion matrix (see <em class="italic">Figure 13.17</em>):</p>
<figure class="mediaobject"><img alt="A picture containing chart  Description automatically generated" height="492" src="../Images/B18331_13_17.png" width="759"/></figure>
<p class="packt_figref">Figure 13.17: AutoML Tables – additional deep dive on the results of our training</p>
<p class="normal">Note that manually crafted models available in <a href="https://www.kaggle.com/uciml/adult-census-income/kernels"><span class="url">https://www.kaggle.com/uciml/adult-census-income/kernels</span></a> get to an accuracy of ˜86-90%. Therefore, our model generated with AutoML is definitively a very<a id="_idIndexMarker1370"/> good result!</p>
<p class="normal">We can also have a look at the importance of each feature in isolation, as shown in <em class="italic">Figure 13.18</em>:</p>
<figure class="mediaobject"><img alt="Chart, bar chart  Description automatically generated" height="399" src="../Images/B18331_13_18.png" width="571"/></figure>
<p class="packt_figref">Figure 13.18: Specific importance of each feature considered in isolation</p>
<p class="normal">If we are happy with our results, we can then deploy the model in production via <strong class="screenText">DEPLOY &amp; TEST</strong> (see <em class="italic">Figure 13.19</em>). We can decide to create a Docker container deployable at the edge or we can simply use an endpoint. Let’s go for this option and just use the default setting for each available choice:</p>
<figure class="mediaobject"><img alt="Graphical user interface, application, Teams  Description automatically generated" height="546" src="../Images/B18331_13_19.png" width="581"/></figure>
<p class="packt_figref">Figure 13.19: AutoML Tables – deploying in production</p>
<p class="normal">Then it is possible to<a id="_idIndexMarker1371"/> make online predictions of income<a id="_idIndexMarker1372"/> by using a REST API (see <a href="https://en.wikipedia.org/wiki/Representational_state_transfer"><span class="url">https://en.wikipedia.org/wiki/Representational_state_transfer</span></a>), using this command for the example we’re looking at in this chapter, as shown in <em class="italic">Figure 13.20</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="686" src="../Images/B18331_13_20.png" width="495"/></figure>
<p class="packt_figref">Figure 13.20: AutoML Tables – querying the deployed model in production</p>
<p class="normal">Put simply, we can say <a id="_idIndexMarker1373"/>that Google Cloud ML is very focused on simplicity of use and efficiency for AutoML. Let’s summarize the main steps required (see <em class="italic">Figure 13.21</em>):</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">The dataset is imported.</li>
<li class="numberedList">Your dataset schema and labels are defined.</li>
<li class="numberedList">The input features are automatically recognized.</li>
<li class="numberedList">AutoML performs magic by automatically doing feature engineering, creating a model, and tuning the hyperparameters.</li>
<li class="numberedList">The automatically built model can then be evaluated.</li>
<li class="numberedList">The model is then deployed in production.</li>
</ol>
<p class="normal">Of course, it is possible to repeat the steps 2-6 by changing the schema and the definition of the labels.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="432" src="../Images/B18331_13_21.png" width="879"/></figure>
<p class="packt_figref">Figure 13.21: AutoML Tables – the main steps required</p>
<p class="normal">In this section, we have<a id="_idIndexMarker1374"/> seen an example of AutoML focused on ease of use and efficiency. The progress made is shown in Faes et al. [7], quoting the paper:</p>
<blockquote class="packt_quote">
<p class="quote">”We show, to our knowledge, a first of its kind automated design and implementation of deep learning models for health-care application by non-AI experts, namely physicians. Although comparable performance to expert-tuned medical image classification algorithms was obtained in internal validations of binary and multiple classification tasks, more complex challenges, such as multilabel classification, and external validation of these models was insufficient. We believe that AI might advance medical care by improving efficiency of triage to subspecialists and the personalisation of medicine through tailored prediction models. The automated approach to prediction model design improves access to this technology, thus facilitating engagement by the medical community and providing a medium through which clinicians can enhance their understanding of the advantages and potential pitfalls of AI integration.”</p>
</blockquote>
<p class="normal">In this case, Cloud AutoML Tables has been used. So, let’s look at another example.</p>
<h2 class="heading-2" id="_idParaDest-362">Using the Google Cloud AutoML Text solution</h2>
<p class="normal">In this section, we are going to build a<a id="_idIndexMarker1375"/> classifier using AutoML. Let’s create a dataset for text from the Vertex AI console. We want to focus on the task of single-label classification:</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="613" src="../Images/B18331_13_22.png" width="745"/></figure>
<p class="packt_figref">Figure 13.22: AutoML Text classification – creating a dataset</p>
<p class="normal">We are going to use a dataset already available online (the happy moments dataset is stored in <code class="inlineCode">cloud-ml-data/NL-classification/happiness.csv</code>), load it into a dataset named <strong class="screenText">happiness</strong>, and perform single-label classification (as shown in <em class="italic">Figure 13.23</em>). This can take several minutes or more. </p>
<p class="normal">We will be emailed once processing completes:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" height="447" src="../Images/B18331_13_23.png" width="674"/></figure>
<p class="packt_figref">Figure 13.23: AutoML Text classification – creating the dataset</p>
<p class="normal">Once the dataset is<a id="_idIndexMarker1376"/> loaded, you should be able to see that each text fragment is annotated with one category out of seven, as shown in <em class="italic">Figure 13.24</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="445" src="../Images/B18331_13_24.png" width="642"/></figure>
<p class="packt_figref">Figure 13.24: AutoML Text classification – a sample of categories</p>
<p class="normal">It is now time to start training the model:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, chat or text message  Description automatically generated" height="218" src="../Images/B18331_13_25.png" width="297"/></figure>
<p class="packt_figref">Figure 13.25: AutoML Text classification – start training</p>
<p class="normal">By the end, the <a id="_idIndexMarker1377"/>model is built, and it achieves a good precision of 90.2% and recall of 86.7%:</p>
<figure class="mediaobject"><img alt="Table  Description automatically generated" height="293" src="../Images/B18331_13_26.png" width="447"/></figure>
<p class="packt_figref">Figure 13.26: AutoML Text classification – precision and recall</p>
<p class="normal">We can also have a look at the precision-recall curve and precision-recall by threshold (see <em class="italic">Figure 13.27</em>). These curves can be used to calibrate the classifier, calibrating on the threshold (based on the prediction probabilities that are greater than the threshold):</p>
<figure class="mediaobject"><img alt="Chart, line chart  Description automatically generated" height="355" src="../Images/B18331_13_27.png" width="659"/></figure>
<p class="packt_figref">Figure 13.27: Precision-recall and Precision-recall by threshold</p>
<p class="normal">The confusion<a id="_idIndexMarker1378"/> matrix is shown in <em class="italic">Figure 13.28</em>:</p>
<figure class="mediaobject"><img alt="Application, table  Description automatically generated" height="423" src="../Images/B18331_13_28.png" width="691"/></figure>
<p class="packt_figref">Figure 13.28: Confusion matrix for the text classification problem</p>
<h2 class="heading-2" id="_idParaDest-363">Using the Google Cloud AutoML Video solution</h2>
<p class="normal">In this solution, we are going to automatically<a id="_idIndexMarker1379"/> build a new model for video classification. The intent is to be able to sort different video segments into various categories (or classes) based on their content. The first step is to create the dataset, as shown in <em class="italic">Figure 13.29</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="480" src="../Images/B18331_13_29.png" width="567"/></figure>
<p class="packt_figref">Figure 13.29: AutoML Video intelligence – a classification problem</p>
<p class="normal">We are going to use a collection of about 5,000 videos available in a demo already stored in a GCP bucket on <code class="inlineCode">automl-video-demo-data/hmdb_split1_5classes_all.csv</code>, as shown in <em class="italic">Figure 13.30</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="414" src="../Images/B18331_13_30.png" width="510"/></figure>
<p class="packt_figref">Figure 13.30. Importing the demo dataset</p>
<p class="normal">As usual, importing <a id="_idIndexMarker1380"/>will take a while and we will be notified when it is done with an email. Once the videos are imported, we can preview them with their associated categories:</p>
<figure class="mediaobject"><img alt="Table  Description automatically generated" height="533" src="../Images/B18331_13_31.png" width="419"/></figure>
<p class="packt_figref">Figure 13.31: AutoML Video intelligence – imported video preview</p>
<p class="normal">We can now start to build a <a id="_idIndexMarker1381"/>model. There are a number of options including training with AutoML, using AutoML at the edge for models to be exported at the edge, and custom models built on TensorFlow. Let’s use the default, as shown in <em class="italic">Figure 13.32</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" height="656" src="../Images/B18331_13_32.png" width="558"/></figure>
<p class="packt_figref">Figure 13.32: AutoML Video intelligence – warning to get more videos</p>
<p class="normal">In this case, we decide to run <a id="_idIndexMarker1382"/>an experiment training with a few labels and divide the dataset into 20% training and 80% testing:</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="529" src="../Images/B18331_13_33.png" width="741"/></figure>
<p class="packt_figref">Figure 13.33: Test and Training dataset split</p>
<p class="normal">Once the model is trained, you can access the results from the console (<em class="italic">Figure 13.34</em>). In this case, we achieved a precision of 99.5% and a recall of 99.5% even though we were using only 20% of the labels<a id="_idIndexMarker1383"/> for training in our experiment. We wanted to keep the training short and still achieve awesome results. You can play with the model, for instance, increasing the number of labeled videos available, to see how the performance will change:</p>
<figure class="mediaobject"><img alt="Graphical user interface, table  Description automatically generated" height="273" src="../Images/B18331_13_34.png" width="426"/></figure>
<p class="packt_figref">Figure 13.34: AutoML Video intelligence – evaluating the results</p>
<p class="normal">Let’s have a detailed look at the results. For instance, we can analyze the precision/recall graph for different <a id="_idIndexMarker1384"/>levels of threshold:</p>
<figure class="mediaobject"><img alt="Chart, line chart  Description automatically generated" height="396" src="../Images/B18331_13_35.png" width="727"/></figure>
<p class="packt_figref">Figure 13.35: AutoML Video intelligence – precision and recall</p>
<p class="normal">The confusion matrix shows examples of the wrong classification of shots:</p>
<figure class="mediaobject"><img alt="Application  Description automatically generated with low confidence" height="382" src="../Images/B18331_13_36.png" width="624"/></figure>
<p class="packt_figref">Figure 13.36: AutoML Video intelligence – confusion matrix</p>
<h2 class="heading-2" id="_idParaDest-364">Cost</h2>
<p class="normal">Training on GCP has different costs depending <a id="_idIndexMarker1385"/>on the type of AutoML adopted; for example, training all the solutions presented in this chapter and serving models for testing had a cost of less than $10 in 2022. This is, however, not including the initial six hours of free discount that were available for the account (around $150 were available at the time of writing). Depending on your organizational needs, this is likely to work out significantly less than the cost of buying expensive on-premises hardware.</p>
<h1 class="heading-1" id="_idParaDest-365">Summary</h1>
<p class="normal">The goal of AutoML is to enable domain experts who are not familiar with machine learning technologies to use ML techniques easily. The primary goal is to reduce the steep learning curve and the huge costs of handcrafting machine learning solutions by making the whole end-to-end machine learning pipeline (data preparation, feature engineering, and automatic model generation) more automated.</p>
<p class="normal">After reviewing the state-of-the-art solution available at the end of 2022, we discussed how to use Google Cloud AutoML both for text, videos, and images, achieving results comparable to the ones achieved with handcrafted models. AutoML is probably the fastest-growing research topic and interested readers can find the latest results at <a href="https://www.automl.org/"><span class="url">https://www.automl.org/</span></a>.</p>
<p class="normal">The next chapter discusses the math behind deep learning, a rather advanced topic that is recommended if you are interested in understanding what is going on “under the hood” when you play with neural networks.</p>
<h1 class="heading-1" id="_idParaDest-366">References</h1>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Zoph, B., Le, Q. V. (2016). <em class="italic">Neural Architecture Search with Reinforcement Learning.</em> <a href="http://arxiv.org/abs/1611.01578"><span class="url">http://arxiv.org/abs/1611.01578</span></a></li>
<li class="numberedList">Pham, H., Guan, M. Y., Zoph, B., Le, Q. V., Dean, J. (2018). <em class="italic">Efficient Neural Architecture Search via Parameter Sharing</em>. <a href="https://arxiv.org/abs/1802.03268"><span class="url">https://arxiv.org/abs/1802.03268</span></a> </li>
<li class="numberedList">Borsos, Z., Khorlin, A., Gesmundo, A. (2019). <em class="italic">Transfer NAS: Knowledge Transfer between Search Spaces with Transformer Agents</em>. <a href="https://arxiv.org/abs/1906.08102"><span class="url">https://arxiv.org/abs/1906.08102</span></a> </li>
<li class="numberedList">Lu, Z., Whalen, I., Boddeti V., Dhebar, Y., Deb, K., Goodman, E., and Banzhaf, W. (2018). <em class="italic">NSGA-Net: Neural Architecture Search using Multi-Objective Genetic Algorithm</em>. <a href="https://arxiv.org/abs/1810.03522"><span class="url">https://arxiv.org/abs/1810.03522</span></a></li>
<li class="numberedList">Bergstra, J., Bengio, Y. (2012). <em class="italic">Random search for hyper-parameter optimization</em>. <a href="http://www.jmlr.org/papers/v13/bergstra12a.xhtml"><span class="url">http://www.jmlr.org/papers/v13/bergstra12a.xhtml</span></a> </li>
<li class="numberedList">Jin, H., Song, Q., and Hu, X. (2019). <em class="italic">Auto-Keras: An Efficient Neural Architecture Search System</em>. <a href="https://arxiv.org/abs/1806.10282"><span class="url">https://arxiv.org/abs/1806.10282</span></a></li>
<li class="numberedList">Faes, L., et al. (2019). <em class="italic">Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study</em>. The Lancet Digital Health Volume 1, Issue 5, September 2019. Pages e232-e242. <a href="https://www.sciencedirect.com/science/article/pii/S2589750019301086%20"><span class="url">https://www.sciencedirect.com/science/article/pii/S2589750019301086</span></a></li>
</ol>
<h1 class="heading-1">Join our book’s Discord space</h1>
<p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 2000 members at: <a href="https://packt.link/keras"><span class="url">https://packt.link/keras</span></a></p>
<p class="normal"><img alt="" height="177" src="../Images/QR_Code1831217224278819687.png" width="177"/></p>
</div>
</div>
</body></html>