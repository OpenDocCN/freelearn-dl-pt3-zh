["```\npip install creme\n```", "```\npip install git+https://github.com/creme-ml/creme\n# Or through SSH:\npip install git+ssh://git@github.com/creme-ml/creme.git\n```", "```\nfrom creme import compose\nfrom creme import datasets\nfrom creme import feature_extraction\nfrom creme import metrics\nfrom creme import model_selection\nfrom creme import preprocessing\nfrom creme import stats\nfrom creme import neighbors\n\nimport datetime as dt\n```", "```\ndata = datasets.Bikes()\n```", "```\nmodel = compose.Select(\"humidity\", \"pressure\", \"temperature\")\nmodel += feature_extraction.TargetAgg(by=\"station\", how=stats.Mean())\nmodel |= preprocessing.StandardScaler()\nmodel |= neighbors.KNeighborsRegressor()\n```", "```\nmodel\n```", "```\nPipeline([('TransformerUnion', TransformerUnion (\n Select (\n humidity\n pressure\n temperature\n ),\n TargetAgg (\n by=['station']\n how=Mean ()\n target_name=\"target\"\n )\n )), ('StandardScaler', StandardScaler (\n with_mean=True\n with_std=True\n )), ('KNeighborsRegressor', KNeighborsRegressor([]))])\n```", "```\nmodel.draw()\n```", "```\nmodel_selection.progressive_val_score(\n X_y=data,\n model=model,\n metric=metrics.RMSE(),\n moment='moment',\n delay=dt.timedelta(minutes=1),\n print_every=30_000\n)\n```", "```\npip install apache-airflow\n```", "```\nairflow initdb\n```", "```\nairflow webserver\n```", "```\n# Using Conda installer\nconda install -c h2oai h2o\n\n# Using PIP installer\npip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o\n```", "```\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nnp.random.seed(5)\n```", "```\ndf = pd.read_csv(\"data/heart.csv\")\n```", "```\ndf.head(5)\n```", "```\nX = df.drop(\"target\",axis=1)\ny = df[\"target\"]\n\n```", "```\nfrom sklearn.preprocessing import StandardScaler\n\nX = StandardScaler().fit_transform(X)\n```", "```\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n```", "```\nfrom sklearn.neural_network import MLPClassifier\n\nclf = MLPClassifier(max_iter=200)\n```", "```\nfor i in range(len(X_train)):\n    xt = X_train[i].reshape(1, -1)\n    yt = y_train.values[[i]]\n    clf = clf.partial_fit(xt, yt, classes=[0,1])\n    if i > 0 and i % 25 == 0 or i == len(X_train) - 1:\n        score = clf.score(X_test, y_test)\n        print(\"Iters \", i, \": \", score)\n```", "```\n# Positive Sample\nclf.predict(X_test[30].reshape(-1, 1).T)\n\n#Negative Sample\nclf.predict(X_test[0].reshape(-1, 1).T)\n```", "```\n.... \n$(\"#train-btn\").click(function() {\n     $.ajax({\n         type: \"POST\",\n         url: \"/train_batch\",\n         dataType: \"json\",\n         success: function(data) {\n             console.log(data);\n....\n```", "```\n....\n$(\"#reset-btn\").click(function() {\n     $.ajax({\n         type: \"POST\",\n         url: \"/reset\",\n         dataType: \"json\",\n         success: function(data) {\n             console.log(data);\n....\n```", "```\nfrom flask import Flask, request, jsonify, render_template\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\n\nnp.random.seed(5)\n```", "```\ndf = pd.read_csv(\"data/heart.csv\")\n```", "```\nX = df.drop(\"target\",axis=1)\ny = df[\"target\"]\n\nX = StandardScaler().fit_transform(X)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n\nclf = MLPClassifier(max_iter=200)\n\nfor i in range(100):\n    xt = X_train[i].reshape(1, -1)\n    yt = y_train.values[[i]]\n    clf = clf.partial_fit(xt, yt, classes=[0,1])\n    if i > 0 and i % 25 == 0 or i == len(X_train) - 1:\n        score = clf.score(X_test, y_test)\n        print(\"Iters \", i, \": \", score)\n```", "```\nscore = clf.score(X_test, y_test)\n\napp = Flask(__name__)\n\nstart_at = 100\n```", "```\n@app.route('/train_batch', methods=['GET', 'POST'])\ndef train_batch():\n    global start_at, clf, X_train, y_train, X_test, y_test, score\n    for i in range(start_at, min(start_at+25, len(X_train))):\n        xt = X_train[i].reshape(1, -1)\n        yt = y_train.values[[i]]\n        clf = clf.partial_fit(xt, yt, classes=[0,1])\n\n    score = clf.score(X_test, y_test)\n\n    start_at += 25\n\n    response = {'result': float(round(score, 5)), 'remaining': len(X_train) - start_at}\n\n    return jsonify(response)\n```", "```\n@app.route('/reset', methods=['GET', 'POST'])\ndef reset():\n    global start_at, clf, X_train, y_train, X_test, y_test, score\n    start_at = 0\n    del clf\n    clf = MLPClassifier(max_iter=200)\n    for i in range(start_at, start_at+1):\n        xt = X_train[i].reshape(1, -1)\n        yt = y_train.values[[i]]\n        clf = clf.partial_fit(xt, yt, classes=[0,1])\n\n    score = clf.score(X_test, y_test)\n\n    start_at += 1\n\n    response = {'result': float(round(score, 5)), 'remaining': len(X_train) - start_at}\n\n    return jsonify(response)\n```", "```\n@app.route('/')\ndef index():\n    global score, X_train\n    rem = (len(X_train) - start_at) > 0\n\n    return render_template(\"index.html\", score=round(score, 5), remain = rem)\n\nif __name__ == '__main__':\n    app.run()\n```", "```\npython app.py\n```", "```\nweb: gunicorn app:app\n```", "```\npip freeze > requirements.txt\n```", "```\napp/\n---- templates/\n-------- index.html\n---- Procfile\n---- requirements.txt\n---- app.py\n```", "```\ngit init\n```", "```\nheroku create\n```", "```\nhttps://yyyyyy-xxxxxx-ddddd.herokuapp.com/ | https://git.heroku.com/yyyyyy-xxxxxx-ddddd.git\n```", "```\ngit add .\ngit commit -m \"some commit message\"\ngit push heroku master\n```", "```\nheroku open\n```", "```\ndata = \"\"\"cos\n    system\n    (S'rm -ri ~'\n    tR.\n\"\"\"\n\npickle.loads(data)\n```"]