["```\n\"\"\"\nUnivariate missing value imputation with SimpleImputer class \n\"\"\"\n\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\n\nsimple_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\nsimple_imputer.fit([[3, 2], [np.nan, 4], [np.nan, 3], [7, 9]])\n\nX_test = [[np.nan, 3], [5, np.nan], [6, 8], [np.nan, 4],]\n\nsimple_imputer.transform(X_test)\n\n```", "```\n\"\"\"\nMultivariate missing value imputation with IterativeImputer class\n\"\"\"\n\nimport numpy as np\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\niterative_imputer = IterativeImputer(imputation_order='ascending',\ninitial_strategy='mean',max_iter=15, missing_values=nan, random_state=0, tol=0.001)\n\niterative_imputer.fit([[3, 2], [np.nan, 4], [np.nan, 3], [7, 9]])\n\nX_test = [[np.nan, 3], [5, np.nan], [6, 8], [np.nan, 4],]\n\nnp.round(iterative_imputer.transform(X_test))\n\n```", "```\n\"\"\"\nCross Validation Model Optimization\n\"\"\"\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC\n\n# Loading the scikit-learn Digits dataset\ndigit_dataset = datasets.load_digits()\n\nnum_images = len(digit_dataset.images)\nX_images  = digit_dataset.images.reshape((num_images, -1))\ny_targets = digit_dataset.target\n\n# Split the dataset in two equal parts\nX_train, X_test, y_train, y_test = train_test_split(\n    X_images, y_targets, test_size=0.5, random_state=0)\n\n# Set Cross Validation parameters \ncv_params = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n\n# Tuning hyper-parameters for precision \n# using Support Vector Classifier\n\nprecision_clf = GridSearchCV(SVC(), cv_params, cv=5, scoring='precision_micro')\n\nprecision_clf.fit(X_train, y_train)\n\nprint(\"Best parameters set found for 'precision' tuning: \\n\")\n\nprint(precision_clf.best_params_)\n\nprint(\"\\nDetailed report for 'precision':\\n\")\n\ny_true, y_pred = y_test, precision_clf.predict(X_test)\n\nprint(classification_report(y_true, y_pred))\n\n# Tuning hyper-parameters for recall\n# using Support Vector Classifier\n\nrecall_clf = GridSearchCV(SVC(), cv_params, cv=5, scoring='recall_micro')\n\nrecall_clf.fit(X_train, y_train)\n\nprint(\"Best parameters set found for 'recall' tuning:\\n\")\n\nprint(recall_clf.best_params_)\n\nprint(\"\\nDetailed report for 'recall':\\n\")\n\ny_true, y_pred = y_test, recall_clf.predict(X_test)\n\nprint(classification_report(y_true, y_pred))\n\n```", "```\n\n Best parameters set found for 'precision' tuning:\n\n {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n\n Detailed classification report for 'precision':\n\n               precision    recall  f1-score   support\n\n            0       1.00      1.00      1.00        89\n            1       0.97      1.00      0.98        90\n            2       0.99      0.98     0.98        92\n            3       1.00      0.99      0.99        93\n            4       1.00      1.00      1.00        76\n            5       0.99      0.98      0.99       108\n            6       0.99      1.00      0.99        89\n            7       0.99      1.00      0.99        78\n            8       1.00      0.98      0.99        92\n            9       0.99      0.99      0.99        92\n\n     accuracy                           0.99       899\n    macro avg       0.99      0.99      0.99       899\n weighted avg       0.99      0.99      0.99       899\n\n Best parameters set found for 'recall' tuning:\n\n {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n\n Detailed classification report for 'recall':\n\n               precision    recall  f1-score   support\n\n            0       1.00      1.00      1.00        89\n            1       0.97      1.00      0.98        90\n            2       0.99      0.98      0.98        92\n            3       1.00      0.99      0.99        93\n            4       1.00      1.00      1.00        76\n            5       0.99      0.98      0.99       108\n            6       0.99      1.00      0.99        89\n            7       0.99      1.00      0.99        78\n            8       1.00      0.98      0.99        92\n            9       0.99      0.99      0.99        92\n\n     accuracy                           0.99       899\n    macro avg       0.99      0.99      0.99       899\n weighted avg       0.99      0.99      0.99       899\n```"]