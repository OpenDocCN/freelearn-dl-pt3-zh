- en: Object Detection – Transfer Learning with CNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"How individuals transfer in one context to another context that share similar
    characteristics"'
  prefs: []
  type: TYPE_NORMAL
- en: – *E. L. Thorndike*, *R. S. Woodworth (1991)*
  prefs: []
  type: TYPE_NORMAL
- en: '**Transfer learning** (**TL**) is a research problem in data science that is
    mainly concerned with persisting knowledge acquired during solving a specific
    task and using this acquired knowledge to solve another different but similar
    task. In this chapter, we will demonstrate one of the modern practices and common
    themes used in the field of data science with TL. The idea here is how to get
    the help from domains with very large datasets to domains that have less dataset
    size. Finally, we will revisit our object detection example of CIFAR-10 and try
    to reduce both the training time and performance error via TL.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CIFAR-10 object detection revisited
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning architectures are data greedy and having a few samples in a training
    set will not get us the best out of them. TL solves this problem by transferring
    learned or gained knowledge/representations from solving a task with a large dataset
    to another different but similar one with a smaller dataset.
  prefs: []
  type: TYPE_NORMAL
- en: TL is not only useful for the case of small training sets, but also we can use
    it to make the training process faster. Training large deep learning architectures
    from scratch can sometimes be very slow because we have millions of weights in
    these architectures that need to be learned. Instead, someone can make use of
    TL by just fine-tuning a learned weight on a similar problem to the one that he/she's
    trying to solve.
  prefs: []
  type: TYPE_NORMAL
- en: The intuition behind TL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's build up the intuition behind TL by using the following teacher-student
    analogy. A teacher has many years of experience in the modules that he'she's teaching.
    On the other side, the students get a compact overview of the topic from the lectures
    that this teacher gives. So you can say that the teacher is transferring their
    knowledge in a concise and compact way to the students.
  prefs: []
  type: TYPE_NORMAL
- en: The same analogy of the teacher and students can be applied to our case of transferring
    knowledge in deep learning, or in neural networks in general. So our model learns
    some representations from the data, which is represented by the *weights* of the
    network. These learned representations/features (weights) can be transferred to
    another different but similar task. This process of transferring the learned weights
    to another task will reduce the need for huge datasets for deep learning architectures
    to converge, and it will also reduce the time needed to adapt the model to the
    new dataset compared to training the model from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep learning is widely used nowadays, but usually most people are using TL
    while training deep learning architectures; few of them train deep learning architectures
    from scratch, because most of the time it''s rare to have a dataset of sufficient
    size for deep learning to converge. So it''s very common to use a pre-trained
    model on a large dataset such as `ImageNet`, which has about 1.2 million images,
    and apply it to your new task. We can use the weights of that pre-trained model
    as a feature extractor, or we can just initialize our architecture with it and
    then fine-tune them to your new task. There are three major scenarios for using
    TL:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use a convolution network as a fixed feature extractor**:In this scenario,
    you use a pre-trained convolution model on a large dataset such as ImageNet and
    adapt it to work on your problem. For instance, a pre-trained convolution model
    on ImageNet will have a fully connected layer with output scores for the 1,000
    categories that ImageNet has. So you need to remove this layer because you are
    not interested anymore in the classes of ImageNet. Then, you treat all other layers
    as a feature extractor. Once you have extracted the features using the pre-trained
    model, you can feed these features to any linear classifier, such as the softmax
    classifier, or even linear SVM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fine-tune the convolution neural network**: The second scenario involves
    the first one but with an extra effort to fine-tune the pre-trained weights on
    your new task using backpropagation. Usually, people keep most of the layers fixed
    and only fine-tune the top end of the network. Trying to fine-tune the whole network
    or even most of the layers may result in overfitting. So, you might be interested
    in fine-tuning only those layers that are concerned with the semantic-level features
    of the images. The intuition behind leaving the earlier layers fixed is that they
    contain generic or low-level features that are common across most imaging tasks,
    such as corners, edges, and so on. Fine-tuning the higher level or the top end
    layers of the network will be useful if you''re introducing new classes that are
    not present in the original dataset that the model was pre-trained on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/7b634245-e286-449f-8f6a-5b7fee31ffef.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 10.1: Fine-tuning the pre-trained CNN for a new task'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-trained models**: The third widely used scenario is to download checkpoints
    that people have made available on the internet. You may go for this scenario
    if you don''t have big computational power to train the model from scratch, so
    you just initialize the model with the released checkpoints and then do a little
    fine-tuning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differences between traditional machine learning and TL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you've noticed from the previous section, there's a clear difference between
    the traditional way we apply machine learning and machine learning that involves
    TL (as shown in the following diagram*)*. In traditional machine learning, you
    don't transfer any knowledge or representations to any other task, which is not
    the case in TL. Sometimes, people use TL in a wrong way, so we are going to mention
    a few conditions under which you can only use TL to maximize the gains.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the conditions for applying TL:'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional machine learning, the source and target task or domains don't
    have to come from the same distribution, but they have to be similar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also use TL in case of less training samples or if you don't have the
    necessary computational power
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/ba7e27f6-a962-4f30-8c43-f6798ad21fe0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: Traditional machine learning versus machine learning with TL'
  prefs: []
  type: TYPE_NORMAL
- en: CIFAR-10 object detection – revisited
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we trained a simple **convolution neural network**
    (**CNN**) model on the CIFAR-10 dataset. Here, we are going to demonstrate the
    case of using a pre-trained model as a feature extractor while removing the fully
    connected layer of the pre-trained model, and then we'll feed these extracted
    features or transferred values to a softmax layer.
  prefs: []
  type: TYPE_NORMAL
- en: The pre-trained model in this implementation will be the inception model, which
    will be pre-trained on ImageNet. But bear in mind that this implementation builds
    on the previous two chapters that introduced CNN.
  prefs: []
  type: TYPE_NORMAL
- en: Solution outline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Again, we are going to replace the final fully connected layer of the pre-trained
    inception model and then use the rest of the inception model as a feature extractor.
    So, we first feed our raw images in the inception model, which will extract the
    features from them and then output our so-called transfer values.
  prefs: []
  type: TYPE_NORMAL
- en: After getting the transfer values of the extracted features from the inception
    model, you might need to save them to your desk because it will take some time
    if you did it on the fly, so it's useful to persist them to your desk to save
    you time. In TensorFlow tutorials, they use the term bottleneck values instead
    of transfer values, but it's just a different name for the exact same thing.
  prefs: []
  type: TYPE_NORMAL
- en: After getting the transfer values or loading them from the desk, we can feed
    them to any linear classifier that's customized to our new task. Here, we will
    feed the extracted transfer values to another neural network and then train for
    the new classes of CIFAR-10.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram, shows the general solution outline that we will be following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/389af43d-d01c-4193-b267-df995b4124a1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: The solution outline for an object detection task using the CIFAR-10
    dataset with TL'
  prefs: []
  type: TYPE_NORMAL
- en: Loading and exploring CIFAR-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s start off by importing the required packages for this implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to load another helper script that we can use to download
    the processing CIFAR-10 dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you haven''t done this already, you need to set the path for CIFAR-10\.
    This path will be used by the `cifar-10.py` script to persist the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the categories that we have in the CIFAR-10 dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns `images`, the class-numbers as `integers`, and the class-numbers
    as one-hot encoded arrays called `labels`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s do the same for the testing set by loading the images and their
    corresponding integer representation of the target classes with their one-hot
    encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s have a look at the distribution of the training and testing sets in
    CIFAR-10:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define some helper functions that will enable us to explore the dataset.
    The following helper function plots a set of nine images in a grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go ahead and visualize some images from the test set along with their
    corresponding actual class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/94ffc181-5c5d-4376-b599-6ecef7f9cf86.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: The first nine images of the test set'
  prefs: []
  type: TYPE_NORMAL
- en: Inception model transfer values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned earlier, we will be using the pre-trained inception model on
    the ImageNet dataset. So, we need to download this pre-trained model from the
    internet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start off by defining `data_dir` for the inception model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The weights of the pre-trained inception model are about 85 MB. The following
    line of code will download it if it doesn''t exist in the `data_dir` defined previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We will load the inception model so that we can use it as a feature extractor
    for our CIFAR-10 images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'As we mentioned previously, calculating the transfer values for the CIFAR-10
    dataset will take some time, so we need to cache them for future use. Thankfully,
    there''s a helper function in the `inception` module that can help us do that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to set the file paths for the cached training and testing
    files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned before, we have 50,000 images in the training set of the CIFAR-10
    dataset. So let''s check the shapes of the transfer values of these images. It
    should be 2,048 for each image in this training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to do the same for the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To intuitively understand how the transfer values look, we are going to define
    a helper function to enable us to use the plot the transfer values of a specific
    image from the training or the testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/b7e00c35-26ef-40ae-95aa-8aed2b82d9ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: Input image'
  prefs: []
  type: TYPE_NORMAL
- en: 'Transfer values for the image using the inception model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77a148f8-97e1-4f21-9498-5968fdbdbfce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.6: Transfer values for the input image in Figure 10.3'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/a7e0afb5-7e8e-4566-bfd8-1e8259915cff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.7: Input image'
  prefs: []
  type: TYPE_NORMAL
- en: 'Transfer values for the image using the inception model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/190cc356-b9bd-40b0-b453-b2edde09a99c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.8: Transfer values for the input image in Figure 10.5'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis of transfer values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will do some analysis of the transferred values that we
    just got for the training images. The purpose of this analysis is to see whether
    these transfer values will be enough for classifying the images that we have in
    CIFAR-10 or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have 2,048 transfer values for each input image. In order to plot these
    transfer values and do further analysis on them, we can use dimensionality reduction
    techniques such as **Principal Component Analysis** (**PCA**) from scikit-learn.
    We''ll reduce the transfer values from 2,048 to 2  to be able to visualize it
    and see if they will be good features for discriminating between different categories
    of CIFAR-10:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to create a PCA object wherein the number of components is
    only `2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'It takes a lot of time to reduce the transfer values from 2,048 to 2, so we
    are going to subset only 3,000 out of the 5,000 images that we have transfer values
    for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to get the class numbers of these images as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We can double-check our subsetting by printing the shape of the transfer values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we use our PCA object to reduce the transfer values from 2,048 to
    just 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s see the output of the PCA reduction process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'After reducing the dimensionality of the transfer values to only 2, let''s
    plot these values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are plotting the reduced transfer values of the subset from the training
    set. We have 10 classes in CIFAR-10, so we are going to plot their corresponding
    transfer values with different colors. As you can see from the following graph,
    the transfer values are grouped according to the corresponding class. The overlap
    between groups is because the reduction process of PCA can''t properly separate
    the transfer values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/665d1102-3dcb-4584-9292-f80f1af46526.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.9: Transfer values reduced using PCA'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do a further analysis on our transfer values using a different dimensionality
    reduction method called **t-SNE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we''ll be reduce our dimensionality of the transfer values, which is
    2,048, but this time to 50 values and not 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we stack the second dimensionality reduction technique and feed the
    output of the PCA process to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we use the reduced values from the PCA method and apply the t-SNE
    method to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'And double-check if it has the correct shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Let's plot the reduced transfer values by the t-SNE method. As you can see in
    the next image, the t-SNE has been able to do better separation of grouped transfer
    values than the PCA one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The takeaway from this analysis is that the extracted transfer values we got
    by feeding our input images to the pre-trained inception model can be used to
    separate training images into the 10 classes. This separation won''t be 100% accurate
    because of the small overlap in the following graph, but we can get rid of this
    overlap by doing some fine-tuning on our pre-trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/35bdf697-4c8f-4a3d-a228-586343632d6c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.10: Transfer values reduced using t-SNE'
  prefs: []
  type: TYPE_NORMAL
- en: Now we have transfer values extracted from our training images and we know that
    these values will be able to, to some extent, distinguish between the different
    classes that CIFAR-10 has. Next, we need to build a linear classifier and feed
    these transfer values to it to do the actual classification.
  prefs: []
  type: TYPE_NORMAL
- en: Model building and training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, let''s start off by specifying the input placeholder variables that will
    be fed to our neural network model. The shape of the first input variable (which
    will contain the extracted transfer values) will be `[None, transfer_len]`. The
    second placeholder variable will hold the actual class labels of the training
    set in a one-hot vector format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also get the corresponding integer value of each class from 1 to 10
    by defining another placeholder variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to build the actual classification neural network that will
    take these input placeholders and produce the predicted classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to define an optimization criteria that will be used during the
    training of the classifier. In this implementation, we will use `AdamOptimizer`.
    The output of this classifier will be an array of 10 probability scores, corresponding
    to the number of classes that we have in the CIFAR-10 dataset. Then, we are going
    to apply the `argmax` operation over this array to assign the class of the largest
    score to this input sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to define a TensorFlow session that will actually execute
    the graph and then initialize the variables that we defined earlier in this implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: In this implementation, we will be using **Stochastic Gradient Descent** (**SGD**),
    so we need to define a function to randomly generate batches of a particular size
    from our training set of 50,000 images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we are going to define a helper function for generating a random batch
    from the input training set of the transfer values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to define a helper function to do the actual optimization
    process, which will refine the weights of the network. It will generate a batch
    at each iteration and optimize the network based on that batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We are going to define some helper functions to show the results of the previous
    neural network and show the confusion matrix of the predicted results as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to define the helper function for plotting the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, we are going to define another helper function to run the trained classifier
    over the test set and measure the accuracy of the trained model over the test
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the performance of the previous neural network model before doing
    any optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the performance of the network is very low, but it will get
    better after doing some optimization based on the optimization criteria that we
    already defined. So we are going to run the optimizer for 10,000 iterations and
    test the model accuracy after that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/125c29c9-437c-4a01-be7d-f3769cc2940e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.11: Some misclassified images from the test set'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'To wrap this up, we are going to close the opened sessions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced one of the most widely used best practices of
    deep learning. TL is a very exciting tool that you can use to get deep learning
    architectures to learn from your small dataset, but make sure you use it in the
    right way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next up, we are going to introduce a widely used deep learning architecture
    for natural language processing. These recurrent-type architectures have achieved
    a breakthrough in most NLP domains: machine translation, speech recognition, language
    modeling, and sentiment analysis.'
  prefs: []
  type: TYPE_NORMAL
