["```\n    wget https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh \n    ```", "```\n    bash Anaconda3-5.0.1-Linux-x86_64.sh \n    ```", "```\nconda create --name universe python=3.6 anaconda \n```", "```\nsource activate universe \n```", "```\nsource activate universe \n```", "```\nsudo apt-get update\nsudo apt-get install golang libcupti-dev libjpeg-turbo8-dev make tmux htop chromium-browser git cmake zlib1g-dev libjpeg-dev xvfb libav-tools xorg-dev python-opengl libboost-all-dev libsdl2-dev swig\nconda install pip six libgcc swig\nconda install opencv \n```", "```\npip install gym==0.15.4 \n```", "```\ncd ~\ngit clone https://github.com/openai/gym.git\ncd gym\npip install -e '.[all]' \n```", "```\n    sudo apt-get update\n    sudo apt-get install xvfb libav-tools xorg-dev libsdl2-dev swig cmake \n    ```", "```\n    git clone https://github.com/openai/mujoco-py.git\n    cd mujoco-py\n    sudo apt-get update\n    sudo apt-get install libgl1-mesa-dev libgl1-mesa-glx libosmesa6-dev python3-pip python3-numpy python3-scipy\n    pip3 install -r requirements.txt\n    sudo python3 setup.py install \n    ```", "```\n    sudo apt-get update\n    sudo apt-get install python-dev \n    sudo apt-get install libevent-dev \n    ```", "```\nimport gym \n```", "```\nenv = gym.make(\"FrozenLake-v0\") \n```", "```\nenv.render() \n```", "```\nprint(env.observation_space) \n```", "```\nDiscrete(16) \n```", "```\nprint(env.action_space) \n```", "```\nDiscrete(4) \n```", "```\nprint(env.P[0][2]) \n```", "```\n[(0.33333, 4, 0.0, False),\n (0.33333, 1, 0.0, False),\n (0.33333, 0, 0.0, False)] \n```", "```\nprint(env.P[3][1]) \n```", "```\n[(0.33333, 2, 0.0, False),\n (0.33333, 7, 0.0, True),\n (0.33333, 3, 0.0, False)] \n```", "```\nstate = env.reset() \n```", "```\nenv.step(1) \n```", "```\nenv.render() \n```", "```\n(7, 0.0, True, {'prob': 0.33333}) \n```", "```\n(next_state, reward, done, info) = env.step(1) \n```", "```\nrandom_action = env.action_space.sample() \n```", "```\nnext_state, reward, done, info = env.step(random_action) \n```", "```\nnum_timesteps = 20 \n```", "```\nfor t in range(num_timesteps): \n```", "```\n random_action = env.action_space.sample() \n```", "```\n next_state, reward, done, info = env.step(random_action) \n```", "```\n if done:\n        break \nfrom the action space, and our episode will end if the agent reaches the terminal state:\n```", "```\nimport gym\nenv = gym.make(\"FrozenLake-v0\")\nstate = env.reset()\nprint('Time Step 0 :')\nenv.render()\nnum_timesteps = 20\nfor t in range(num_timesteps):\n  random_action = env.action_space.sample()\n  new_state, reward, done, info = env.step(random_action)\n  print ('Time Step {} :'.format(t+1))\n  env.render()\n  if done:\n    break \n```", "```\nimport gym\nenv = gym.make(\"FrozenLake-v0\")\n**num_episodes =** **10**\nnum_timesteps = 20 \n**for** **i** **in** **range(num_episodes):**\n\n    state = env.reset()\n    print('Time Step 0 :')\n    env.render()\n    for t in range(num_timesteps):\n        random_action = env.action_space.sample()\n\n        new_state, reward, done, info = env.step(random_action)\n        print ('Time Step {} :'.format(t+1))\n        env.render()\n        if done:\n            break \n```", "```\nenv = gym.make(\"CartPole-v0\") \n```", "```\nenv.render() \n```", "```\nenv.close() \n```", "```\narray([cart position, cart velocity, pole angle, pole velocity at the tip]) \n```", "```\nprint(env.observation_space) \n```", "```\nBox(4,) \n```", "```\nprint(env.reset()) \n```", "```\narray([ 0.02002635, -0.0228838 ,  0.01248453,  0.04931007]) \n```", "```\nprint(env.observation_space.high) \n```", "```\n[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38] \n```", "```\nprint(env.observation_space.low) \n```", "```\n[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38] \n```", "```\nprint(env.action_space) \n```", "```\nDiscrete(2) \n```", "```\nimport gym\nenv = gym.make('CartPole-v0') \n```", "```\nnum_episodes = 100\nnum_timesteps = 50 \n```", "```\nfor i in range(num_episodes): \n```", "```\n Return = 0 \n```", "```\n state = env.reset() \n```", "```\n for t in range(num_timesteps): \n```", "```\n env.render() \n```", "```\n random_action = env.action_space.sample() \n```", "```\n next_state, reward, done, info = env.step(random_action) \n```", "```\n Return = Return + reward \n```", "```\n if done:\n            break \n```", "```\n if i%10==0:\n        print('Episode: {}, Return: {}'.format(i, Return)) \n```", "```\nenv.close() \n```", "```\nEpisode: 0, Return: 14.0\nEpisode: 10, Return: 31.0\nEpisode: 20, Return: 16.0\nEpisode: 30, Return: 9.0\nEpisode: 40, Return: 18.0\nEpisode: 50, Return: 13.0\nEpisode: 60, Return: 25.0\nEpisode: 70, Return: 21.0\nEpisode: 80, Return: 17.0\nEpisode: 90, Return: 14.0 \n```", "```\nenv = gym.make(\"Pong-v0\") \n```", "```\n [Image height, image width, number of the channel] \n```", "```\nprint(env.observation_space) \n```", "```\nBox(210, 160, 3) \n```", "```\nprint(env.reset()) \n```", "```\nenv = gym.make(\"Pong-ram-v0\") \n```", "```\nprint(env.observation_space) \n```", "```\nBox(128,) \n```", "```\nprint(env.reset()) \n```", "```\nenv = gym.make(\"Pong-v0\")\nprint(env.action_space) \n```", "```\nDiscrete(6) \n```", "```\nenv = gym.make(\"RoadRunner-v0\")\nprint(env.action_space) \n```", "```\nDiscrete(18) \n```", "```\nimport gym\nenv = gym.make('Tennis-v0') \n```", "```\nenv.render() \n```", "```\nnum_episodes = 100\nnum_timesteps = 50 \n```", "```\nfor i in range(num_episodes): \n```", "```\n Return = 0 \n```", "```\n state = env.reset() \n```", "```\n for t in range(num_timesteps): \n```", "```\n env.render() \n```", "```\n random_action = env.action_space.sample() \n```", "```\n next_state, reward, done, info = env.step(random_action) \n```", "```\n Return = Return + reward \n```", "```\n if done:\n            break \n```", "```\n if i%10==0:\n        print('Episode: {}, Return: {}'.format(i, Return)) \n```", "```\nenv.close() \n```", "```\nEpisode: 0, Return: -1.0\nEpisode: 10, Return: -1.0\nEpisode: 20, Return: 0.0\nEpisode: 30, Return: -1.0\nEpisode: 40, Return: -1.0\nEpisode: 50, Return: -1.0\nEpisode: 60, Return: 0.0\nEpisode: 70, Return: 0.0\nEpisode: 80, Return: -1.0\nEpisode: 90, Return: 0.0 \n```", "```\nenv = gym.wrappers.Monitor(env, 'recording', force=True) \n```", "```\nimport gym\nenv = gym.make('Tennis-v0')\n#Record the game\nenv = gym.wrappers.Monitor(env, 'recording', force=True)\nenv.reset()\nfor _ in range(5000):\n    env.render()\n    action = env.action_space.sample() \n    next_state, reward, done, info = env.step(action)\n    if done:\n        break\nenv.close() \n```", "```\nfrom gym import envs\nprint(envs.registry.all()) \n```"]