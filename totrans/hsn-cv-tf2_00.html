<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root">As a result of leveraging deep learning methods such as <strong>convolutional neural networks</strong> (<strong>CNNs</strong>), computer vision is attaining new heights in fields including health, the automotive sector, social media, and robotics. Whether to automate complex tasks, to guide experts in their work, or to help artists in their creative process, more and more companies are integrating computer vision solutions.</p>
<p class="mce-root">In this book, we will explore TensorFlow 2, the brand new version of Google's open source framework for machine learning. Covering its key features, as well as state-of-the-art solutions, we will demonstrate how to efficiently build, train, and deploy CNNs for a variety of real-life tasks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p>This book is intended for anyone with some background in Python programming and image processing (such as knowing how to read and write image files, and how to edit their pixel values). With its gradual learning curve, this book targets not only deep learning novices but also experts who are curious about the new features of TensorFlow 2.</p>
<p>While some theoretical explanations require knowledge of algebra and calculus, concrete examples are provided for learners focused on practical applications. Step by step, you will tackle real-life tasks, such as visual recognition for self-driving cars and smartphone applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml">Chapter 1</a>, <em>Computer Vision and Neural Networks</em><span>, introduces you to computer vision and deep learning, providing some theoretical background and teaching you how to implement and train a neural network for visual recognition from scratch.</span></p>
<p><a href="c7c49010-458f-47ef-a538-96118f9cd892.xhtml">Chapter 2</a>, <em>TensorFlow Basics and Training a Model</em><span>, goes through TensorFlow 2 concepts related to computer vision, as well as some more advanced notions. It introduces Keras—now a submodule of TensorFlow—and describes the training of a simple recognition method implemented with these frameworks.</span></p>
<p><a href="dd1d3406-d506-4690-bf13-e5e0584ea9d1.xhtml">Chapter 3</a><span>,</span> <span><em>Modern Neural Networks</em>, presents CNNs and explains how they have revolutionized computer vision. This chapter also introduces regularization tools and modern optimization algorithms that can be used to train more robust recognition systems.</span></p>
<p><a href="061eb54a-4e3f-44e8-afb1-bacf796511f4.xhtml">Chapter 4</a>, <em>Influential Classification Tools</em><span>, provides theoretical details and practical code to expertly apply state-of-the-art solutions—such as Inception and ResNet—to the classification of images. This chapter also explains what makes transfer learning a key concept in machine learning, and how it can be performed with TensorFlow 2.<br/></span></p>
<p><a href="593ada62-2ff4-4085-a15e-44f8f5e3d071.xhtml">Chapter 5</a>, <em>Object Detection Models</em><span>, covers the architecture of two methods to detect specific objects in images—You Only Look Once, known for its speed, and</span> Faster R-CNN, <span>known for its accuracy.<br/></span></p>
<p><a href="c4bb2429-f9f5-424d-8462-e376fd81f5a4.xhtml">Chapter 6</a>, <em>Enhancing and Segmenting Images</em><span>, introduces autoencoders and how networks such as U-Net and FCN can be applied to image denoising, semantic segmentation, and more.<br/></span></p>
<p><a href="337ec077-c215-4782-b56c-beae4d94d718.xhtml">Chapter 7</a>, <em>Training on Complex and Scarce Datasets</em><span>, focuses on solutions to efficiently collect and preprocess datasets for your deep learning applications. TensorFlow tools that build optimized data pipelines are presented, as well as various solutions to compensate for data scarcity (image rendering, domain adaptation, and generative networks such as VAEs and GANs).<br/></span></p>
<p><a href="97884989-bb57-4611-8c66-ebe8ab387965.xhtml">Chapter 8</a>, <em>Video and Recurrent Neural Networks</em><span>, covers</span> recurrent neural networks, pres<span>enting the more advanced version known</span> as the long short-term memory a<span>rchitecture. It provides practical code to apply LSTMs to action recognition in video.<br/></span></p>
<p><a href="e8935e55-c3b5-419e-a86a-43eba3ff4dad.xhtml">Chapter 9</a>, <span><em>Optimizing Models and Deploying on Mobile Devices</em>, details model optimization in terms of speed, disk space, and computational performance. It goes through the deployment of TensorFlow solutions on mobile devices and in the browser, using a practical example.<br/></span></p>
<p><a href="59767fa2-b254-47a4-a39a-3f8c826490fa.xhtml">Appendix</a>, <em>Migrating from TensorFlow 1 to TensorFlow 2</em>, <span>provides some information about TensorFlow 1, highlighting key changes introduced in TensorFlow 2. A guide to migrate older projects to the latest version is also included. Finally, per-chapter references are listed for those who want to dive deeper.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<p class="mce-root">The following section contains some information and advice to facilitate the reading of this book and to help readers benefit from its supplementary materials.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download and run the example code files</h1>
                </header>
            
            <article>
                
<p>Practice makes perfect. Therefore, this book not only provides in-depth explanations of TensorFlow 2 and state-of-the-art computer-vision methods, but it also comes with a number of practical examples and complete implementations for each chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the code files</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packt.com" target="_blank">www.packt.com</a>. If you purchased this book elsewhere, you can visit <a href="https://www.packtpub.com/support">www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packt.com" target="_blank">www.packt.com</a>.</li>
<li>Select the <span class="packt_screen">Support</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for Mac</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2" target="_blank">https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2</a></span></strong><span>. </span><span>In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/" target="_blank">https://github.com/PacktPublishing</a></span></strong><span>. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Study and run the experiments</h1>
                </header>
            
            <article>
                
<p><strong>Jupyter Notebook</strong> (<a href="https://jupyter.org">https://jupyter.org</a>) is an open source web application for creating and sharing Python scripts, along with textual information, visual results, equations, and more. We will call <em>Jupyter notebooks</em> the documents provided with the book, containing detailed code, expected results, and supplementary explanations. Each Jupyter notebook is dedicated to a concrete computer vision task. For example, one notebook explains how to train a CNN to detect animals in images, while another details all the steps to build a recognition system for self-driving cars, and so on.</p>
<p>As we will see in this section, these documents can either be studied directly, or they can be used as code recipes to run and reproduce the experiments presented in the book.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Study the Jupyter notebooks online</h1>
                </header>
            
            <article>
                
<p>If you simply want to go through the code and results <span>provided</span>, you can directly access them online in the book's <em>GitHub</em> repository. Indeed, GitHub is able to render Jupyter notebooks and to display them as static web pages.</p>
<p>However, the GitHub viewer ignores some style formatting and interactive content. For the best online viewing experience, we recommend using instead <em>Jupyter nbviewer</em> (<a href="https://nbviewer.jupyter.org">https://nbviewer.jupyter.org</a>), an official web platform you can use to read Jupyter notebooks uploaded online. This website can be queried to render notebooks stored in GitHub repositories. Therefore, the Jupyter notebooks provided can also be read at the following address: <a href="https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2">https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Run the Jupyter notebooks on your machine</h1>
                </header>
            
            <article>
                
<p>To read or run these documents on your machine, you should first install <span>Jupyter Notebook</span>. For those who already use <em>Anaconda</em> (<span><a href="https://www.anaconda.com">https://www.anaconda.com</a>) to manage and deploy their Python environments (as we will recommend in this book), Jupyter Notebook should be directly available (as it is installed with Anaconda). For those using other Python distributions and those not familiar with Jupyter Notebook, we recommend having a look at the documentation, which provides installation instructions and tutorials (<a href="https://jupyter.org/documentation">https://jupyter.org/documentation</a>).<br/></span></p>
<p>Once Jupyter Notebook is installed on your machine, navigate to the directory containing the book's code files, open a terminal, and execute the following command:</p>
<pre><strong>$ jupyter notebook</strong></pre>
<p>The web interface should open in your default browser. From there, you should be able to navigate the directory and open the Jupyter notebooks provided, either to read, execute, or edit them.</p>
<div class="packt_infobox">Some documents contain advanced experiments that can be extremely compute-intensive (such as the training of recognition algorithms over large datasets). Without the proper acceleration hardware (that is, without compatible NVIDIA GPUs, as explained in <a href="c7c49010-458f-47ef-a538-96118f9cd892.xhtml">Chapter 2</a>, <em>TensorFlow Basics and Training a Model</em>), these scripts can take hours or even days (even with compatible GPUs, the most advanced examples can take quite some time).</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Run the Jupyter notebooks in Google Colab</h1>
                </header>
            
            <article>
                
<p>For those who wish to run the Jupyter notebooks themselves—or play with new experiments—but do not have access to a powerful enough machine, we recommend using <strong>Google Colab</strong>, also named <strong>Colaboratory</strong> (<a href="https://colab.research.google.com">https://colab.research.google.com</a>). It is a cloud-based Jupyter environment, provided by Google, for people to run compute-intensive scripts on powerful machines. You will find more details regarding this service in the <span>GitHub</span> repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="https://www.packtpub.com/sites/default/files/downloads/9781788830645_ColorImages.pdf">https://www.packtpub.com/sites/default/files/downloads/9781788830645_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>: <span>Indicates c</span>ode words in text, folder names, filenames, file extensions, pathnames, dummy URLs, and user input. <span>Here is an example:</span> "The <kbd>.fit()</kbd> method of the <kbd>Model</kbd> object starts the training procedure."</p>
<p>A block of code is set as follows:</p>
<pre>import tensorflow as tf<br/><br/>x1 = tf.constant([[0, 1], [2, 3]])<br/>x2 = tf.constant(10)<br/>x = x1 * x2</pre>
<p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre>neural_network = tf.keras.Sequential(<br/>    [tf.keras.layers.Dense(64),<br/>     tf.keras.layers.Dense(10, activation="<strong>softmax</strong>")])</pre>
<p>Any command-line input or output is written as follows:</p>
<pre><strong>$ tensorboard --logdir ./logs</strong></pre>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see on screen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "You can observe the performance of your solution on the <span class="packt_screen">Scalars</span> page of TensorBoard.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: If you have questions about any aspect of this book, <span>mention the book title in the subject of your message and</span> email us at <kbd><span>customercare@packtpub.com</span></kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="https://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd>copyright@packt.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in, and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="http://www.packt.com/" target="_blank">packt.com</a>.<a href="https://www.packtpub.com/" target="_blank"/></p>


            </article>

            
        </section>
    </body></html>