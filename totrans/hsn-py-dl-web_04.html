<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Getting Started with Deep Learning Using Python</h1>
                </header>
            
            <article>
                
<p>In the first chapter, we <span>had a very close look at deep learning and how it is related to machine learning and artificial intelligence. In this chapter, we are going to delve deeper into this topic. We will start off by learning about what sits at the heart of deep learning—namely, neural networks and their fundamental components, such as neurons, activation units, backpropagation, and so on.</span></p>
<p><span>Note that this chapter is not going to be too math heavy, but at the same time, we are not going to cut short the most important formulas that are fundamental to the world of neural networks. For a more math-heavy study of the subject, readers are encouraged to read the book</span> <em>Deep Learning</em> <span>(</span><a href="http://deeplearningbook.org">deeplearningbook.org</a><span>) by</span> Goodfellow <span>et al.</span></p>
<p>The following is an overview of what we are going to cover in this chapter:</p>
<ul>
<li>A whirlwind tour of neural networks and their related concepts</li>
<li>Deep learning versus shallow learning</li>
<li>Different types of neural networks</li>
<li>Setting up a deep-learning-based cloud environment</li>
<li>Exploring Jupyter Notebooks</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Demystifying neural networks</h1>
                </header>
            
            <article>
                
<p>Let's start this section by finding the answers to the question, “Why are neural networks called 'neural'?”. What is the significance behind this term?</p>
<p>Our intuition says that it has something to do with our brains, which is correct, but only partially. Before we get to the reason why it is only partially correct, we need to have some familiarity with the structure of a brain. For this purpose, let's look at the anatomy of our own brains.</p>
<p>A human brain is composed of approximately 10 billion <em>neurons</em>, each connected to about 10,000 other neurons, which gives it a network-like structure. The inputs to the neurons are called <em>dendrites</em> and the outputs are called <em>axons</em>. The body of a neuron is called a <em>soma</em>. So, on a high level, a particular soma is connected to another soma. The word "neural" comes from the word "neuron," and in fact, neural is the adjective form of the word "neuron." In our brains, neurons are the most granular units that form this dense network we just discussed. We are slowly understanding the resemblance of an artificial neural network to the brain, and in order to continue our understanding of this similarity, we will briefly learn about the functionalities of a neuron.</p>
<div class="packt_infobox">A network is nothing but a graph-like structure that contains a set of nodes and edges that are connected to each other. In the case of our brains, or any brain in general, neurons are referred to as nodes and the dendrites are referred to as the vertices.</div>
<p>A neuron receives inputs from other neurons via their dendrites. These inputs are electrochemical in nature. Not all the inputs are equally powerful. If the inputs are powerful enough, then the connected neurons are activated and continue the process of passing the input to the other neurons. Their power is determined by a predefined threshold that allows the activation process to be selective so that it does not activate all the neurons that are present in the network at the same time.</p>
<p>To summarize, neurons receive a collective sum of inputs from other neurons, this sum is compared to a threshold, and the neurons are activated accordingly. An <strong>artificial neural network</strong> (<strong>ANN</strong>), or simply a <strong>neural network</strong> (<strong>NN</strong>), is based on this important fact, hence the resemblance.</p>
<p>So, what makes a network a <em>neural</em> one? What does it take to form an NN?</p>
<p>The following quote from the book <em>Deep Learning For Computer Vision With Python</em> by Adrian Rosebrock answers this question in a very commendable way:</p>
<p>Each node performs a simple computation. Each connection then carries a signal (i.e., the output of the computation) from one node to another, labeled by a weight indicating the extent to which the signal is amplified or diminished. Some connections have large, positive weights that amplify the signal, indicating that the signal is very important when making a classification. Others have negative weights, diminishing the strength of the signal, thus specifying that the output of the node is less important in the final classification. We call such a system an Artificial Neural Network if it consists of a graph structure with connection weights that are modifiable using a learning algorithm.</p>
<p>We have learned about the resemblance of neural networks to brains. We will now take this information and learn more about the granular units of ANNs. Let's start by learning what a simple neuron has to do in an ANN.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Artificial neurons</h1>
                </header>
            
            <article>
                
<p>Let's call the neurons that are used in ANNs artificial neurons. Broadly speaking, artificial neurons can be of two types:</p>
<ul>
<li>Linear neuron</li>
<li>Nonlinear neuron</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Anatomy of a linear neuron</h1>
                </header>
            
            <article>
                
<p>A neuron is the most granular unit in a neural network. Let's look at the second word of "neural network." A network is nothing but a set of vertices (also called nodes) whose edges are connected to each other. In the case of a neural network, neurons serve as the nodes. Let's consider the following neural network architecture and try to dissect it piece by piece:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1384 image-border" src="assets/c5502868-fd41-47b9-859a-f36bcfd8020e.png" style="width:43.50em;height:24.33em;"/></p>
<p>What we can see in the preceding diagram is a neural network with two hidden layers (in a neural network, a layer is a set of neurons) with a single output. In fact, this is called a two-layer neural network. The neural network consists of the following:</p>
<ul>
<li>One single input</li>
<li>Two hidden layers, where the first hidden layer has three neurons and the second hidden layer contains two neurons</li>
<li>One single output</li>
</ul>
<p>There is no deeper psychological significance in calling the layers hidden they are called hidden simply because the neurons involved in these layers are neither parts of the input nor output. One thing that is very evident here is that there is a layer before the first hidden layer. Why are we <span>not</span> <span>counting</span> <span>that layer? In the world of neural networks, that initial layer and output are not</span> counted <span>in the stack of layers. In simple words, if there are</span> <em>n</em> <span>hidden layers, it is an</span> <em>n</em><span>-layer neural network.</span></p>
<p>The initial layer (also called an input layer) is used for receiving primary input to the neural network. After receiving the primary input, the neurons present in the input layer pass them to the next set of neurons that are present in the subsequent hidden layers. Before this propagation happens, the neurons add weights to the inputs and a bias term to the inputs. These inputs can be from various domains—for example, the inputs can be the raw pixels of an image, the frequencies of an audio signal, a collection of words, and so on. Generally, these inputs are given as feature vectors to the neural network. In this case, the input data has only one feature.</p>
<p>Now, what are the neurons from the next two layers doing here? This is an important question. We can consider the addition of weights and biases to the inputs as the first level/layer of learning (also called the decision making layer). The neurons in the initial hidden layer repeat this process, but before sending the calculated output to the neurons that are present in the next hidden layer, they compare this value to a threshold. If the threshold criteria are satisfied, then only the outputs are propagated to the next level. This part of the whole neural network learning process bears a solid resemblance to the biological process that we discussed earlier. This also supports the philosophy of learning complex things in a layered fashion.</p>
<p>A question that is raised here is, "What happens if no hidden layers are used?". It turns out that adding more levels of complexity (by adding more layers) in a neural network allows it to learn the underlying representations of the input data in a more concise manner than a network with just the input layer and the output. But how many layers would we need? We will get to that later.</p>
<p>Let's introduce some mathematical formulas here to formalize what we just studied.</p>
<p>We express the input features as <em>x</em>, the weights as <em>w</em>, and the bias term as <em>b</em>. The neural network model that we are currently trying to dissect builds upon the following rule:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/73d8417a-6a5d-48b3-9d3c-2df95ad05b55.png" style="width:15.67em;height:3.00em;"/></p>
<p>The rule says that after calculating the sum of weighted input and the bias, if the result is greater than 0, then the neuron is going to yield 1, and if the result is less than or equal to 0, then the neuron is simply going to produce 0 in other words, the neuron is not going to fire. In the case of multiple input features, the rule remains exactly the same and the multivariate version of the rule looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/fd99fc73-d225-45bc-9dcb-8ae25e9d5647.png" style="width:17.17em;height:3.08em;"/></p>
<p>Here, <em>i</em> means that we have a total of <em>i</em> input features. The preceding rule can be broken down as follows:</p>
<ul>
<li>We take the features individually, and then we multiply them by the weights</li>
<li>After finishing this process for all the individual input features, we take all of the weighted inputs and sum them and finally add the bias term.</li>
</ul>
<div class="packt_infobox">The preceding process is continued for the number of layers we have in our network. In this case, we have two hidden layers, so the output of one layer would be fed to the next.</div>
<p>The elements we just studied were proposed by Frank Rosenblatt in the 1960s. The idea of assigning 0 or 1 to the weighted sum of the inputs based on a certain threshold is also known as the <strong>step-function</strong>. There are many rules like this in the literature, these are called update rules.</p>
<p>The neurons we studied are <strong>linear neurons</strong> that are capable of learning linear functions. They are not suited for learning representations that are nonlinear in nature. Practically, almost all the inputs that neural networks are fed with are nonlinear in nature. In the next section, we are going to introduce another type of neuron that is capable of capturing the nonlinearities that may be present in the data.</p>
<div class="packt_infobox">Some of you might be wondering whether this NN model is called an <strong>MLP</strong> (<strong>multilayer</strong> <strong>perceptron</strong>). Well, it is. In fact, Rosenblatt proposed this way back in the 1960s. Then what are neural networks? We are going to learn the answer to this shortly.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Anatomy of a nonlinear neuron</h1>
                </header>
            
            <article>
                
<p>A nonlinear neuron means that it is capable of responding to the nonlinearities that may be present in the data. Nonlinearity in this context essentially means that for a given input, the output does not change in a linear way. Look at the following diagrams:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1385 image-border" src="assets/43498898-28e2-44bf-a26c-a071493c6de0.png" style="width:32.50em;height:13.58em;"/></p>
<p>Both of the preceding figures depict the relationship between the inputs that are given to a neural network and the outputs that the network produces. From the first figure, it is clear that the input data is linearly separable, whereas the second figure tells us that the inputs cannot be linearly separated. In cases like this, a linear neuron will miserably fail, hence the need for nonlinear neurons.</p>
<div class="packt_infobox"><span>In the training process of a neural network,</span> <span>conditions</span> <span>can arise</span> <span>where a small change in the bias and weight values may affect the output of the neural network in a drastic way. Ideally, this should not happen. A small change to either the bias or weight values should cause only a small change in the output. When a step function is used, the changes in weight and bias terms can affect the output to a great extent, hence the need for something other than a step function.</span></div>
<p>Behind the operation of a neuron sits a function. In the case of the linear neuron, we saw that its operations were based on a step function. We have a bunch of functions that are capable of capturing the nonlinearities. The sigmoid function is such a function, and the neurons that use this function are often called sigmoid neurons. Unlike the step function, the output in the case of a sigmoid neuron is produced using the following rule:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c07baaa1-6d33-4e1b-b759-e81faa535390.png" style="width:17.50em;height:3.25em;"/></p>
<p>So, our final, updated rule becomes the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f641c5d4-03a7-4cf6-8f46-eacadf6206f4.png" style="width:15.25em;height:3.75em;"/></p>
<p>But why is the sigmoid function better than a step function in terms of capturing nonlinearities? Let's compare their performance in graphical to understand this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1386 image-border" src="assets/c67899b6-21c7-48ed-adf3-4fd1efd01d29.png" style="width:41.17em;height:14.50em;"/></p>
<p>The preceding two figures give us a clear picture about the two functions regarding their intrinsic nature. It is absolutely clear that the sigmoid function is more sensitive to the nonlinearities than the step function.</p>
<p>Apart from the sigmoid function, the following are some widely known and used functions that are used to give a neuron a nonlinear character:</p>
<ul>
<li>Tanh</li>
<li>ReLU</li>
<li>Leaky ReLU</li>
</ul>
<p>In the literature, these functions, along with the two that we have just studied, are called activation functions. Currently, ReLU and its variants are by far the most successful activation functions.</p>
<p>We are still left with a few other basic things related to artificial neural networks. Let's summarize what we have learned so far:</p>
<ul>
<li>Neurons and their two main types</li>
<li>Layers</li>
<li>Activation functions</li>
</ul>
<p>We are now in a position to draw a line between MLPs and neural networks. Michael Nielson in his online book <em>Neural Networks and Deep Learning</em> describes this quite well:</p>
<div class="mce-root packt_quote"><span>Somewhat confusingly, and for historical reasons, such multiple layer networks are sometimes called</span> <em>multilayer perceptrons</em> <span>or <em>MLPs</em></span><span>, despite being made up of sigmoid neurons, not perceptrons.</span></div>
<p>We are going to use <span>the</span> neural network and deep neural network terminologies throughout this book. We will now move forward and learn more about the input and output layers of a neural network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A note on the input and output layers of a neural network</h1>
                </header>
            
            <article>
                
<p>It is important to understand what can be given as inputs to a neural network. Do we feed raw images or raw text data to a neural network? Or are <span>there</span> <span>other ways to provide input to a neural network? In this section, we will learn how a computer really interprets an image to show what exactly can be given as input to a neural network when it is dealing with images (yes, neural networks are pretty great at image processing). We will also learn the ways to show what it takes to feed a neural network with raw text data. But before that, we need to have a clear understanding of how a regular tabular dataset is given as an input to a neural network. Because tabular datasets are everywhere, in the form of SQL tables, server logs, and so on.</span></p>
<p>We will take the following toy dataset for this purpose:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1387 image-border" src="assets/92ffcb3f-b5eb-4b0c-8ec6-a364fa7a3775.png" style="width:11.17em;height:16.08em;"/></p>
<p>Take note of the following points regarding this toy dataset:</p>
<ul>
<li>It has two predictor variables, <em>x1</em> and <em>x2</em>, and these predictors are generally called input feature vectors.</li>
<li>It is common to assign <em>x1</em> and <em>x2</em> to a vector, <em>X</em> (more on this later).</li>
<li>The response variable is <em>y</em>.</li>
</ul>
<ul>
<li>We have 10 instances (containing <em>x1</em>, <em>x2</em>, and <em>y</em> attributes) that are categorized into two classes, 0 and 1.</li>
<li>Given <em>x1</em> and <em>x2</em>, our (neural network's) task is to predict <em>y</em>, which essentially makes this a classification task.</li>
</ul>
<p>When we say that the neural network predicts something, we mean that it is supposed to learn the underlying representations of the input data that best approximate a certain function (we saw what function plotting look like a while ago).</p>
<p>Let's now see how this data is given as inputs to a neural network. As our data has two predictor variables (or two input vectors), the input layer of the neural network has to contain two neurons. We will use the following neural network architecture for this classification task:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1388 image-border" src="assets/bdab7ceb-ab2d-45c2-8c77-c896a0bfb2c5.png" style="width:33.17em;height:12.75em;"/></p>
<p>The architecture is quite identical to the one that we saw a while ago, but in this case, we have an added input feature vector. The rest is exactly the same.</p>
<p>To keep it simple, we are not considering the data preprocessing that might be needed before we feed the data to the network. Now, let's see how the data is combined with the weights and the bias term, and how the activation function is applied to them.</p>
<p><span>In this case, t</span>he feature vectors and the response variable (which is <em>y</em>) are interpreted separately by the neural network the response variable is used in the later stage in the network's training process. Most importantly, it is used for evaluating how the neural network is performing. The input data is organized as a matrix form, like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/75262c2f-fdbc-41c3-b461-9a04b2d24de7.png" style="width:12.67em;height:7.00em;"/></p>
<p>The kind of NN architecture that we are using now is a fully connected architecture, which means that all of the neurons in a particular layer are connected to all the other neurons in the next layer.</p>
<p>The weight matrix is defined as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6c7cc6d2-b697-492b-b277-1a3217a04fe2.png" style="width:10.75em;height:2.92em;"/></p>
<p>For now, let's not bother about the weight values. The dimensions of the weight matrix is interpreted as the following:</p>
<ul>
<li>The number of rows equals the number of feature vectors (<em>x1</em> and <em>x2</em>, in our case).</li>
<li>The number of columns equals the number of neurons in the first hidden layer.</li>
</ul>
<p>There are some suffixes and superscripts associated with each of the weight values in the matrix. If we take the general form of the weight as <img class="fm-editor-equation" src="assets/c16cd84f-3e3a-42e5-b619-a628b3160c0c.png" style="width:2.00em;height:1.75em;"/>, then it should be interpreted as follows:</p>
<ul>
<li><em>l</em> denotes the layer from which the weight is coming. In this case, the weight matrix that we just saw is going to be associated with the input layer.</li>
<li><em>j</em> denotes the position of the neuron in <img class="fm-editor-equation" src="assets/ef96922d-fbab-4bf0-bac4-07dc23ece429.png" style="width:0.42em;height:1.17em;"/>, whereas <em>k</em> denotes the position of the neuron in the next layer that the value is propagated to.</li>
</ul>
<p>The weights are generally randomly initialized, which adds a <em>stochastic</em> character to the neural network. Let's randomly initialize a weight matrix for the input layer:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/28fe1ff8-96fa-4c85-ac98-fa1c4d0ec5db.png" style="width:11.75em;height:2.50em;"/></p>
<p>Now we calculate the values that are to be given to the first hidden layer of the NN. This is computed as follows:</p>
<p style="padding-left: 210px;"><img class="alignnone size-full wp-image-1469 image-border" src="assets/4716dd77-2dfc-490d-b796-aa1215cab251.png" style="width:16.83em;height:12.50em;"/></p>
<p>The first matrix contains all the instances from the training set (without the response variable <em>y</em>) and the second matrix is the weight matrix that we just defined. The result of this multiplication is stored in a variable, <img class="fm-editor-equation" src="assets/a85b6a85-7af3-46bc-aa93-70b13630a83d.png" style="width:1.92em;height:1.25em;"/> (this variable can be named anything, and the superscript denotes that it is related to the first hidden layer of the network).</p>
<p>We are still left with one more step before we send these results to the neurons in the next layer, where the activation functions will be applied. The sigmoid activation function and the final output from the input layer would look like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/20a23d3e-6c8c-44ac-874b-3e088653fec9.png" style="width:9.58em;height:1.50em;"/></p>
<p>Here, <em>a<sup>(1)</sup></em> is our final output for the next layer of neurons. Note that the sigmoid function is applied to each and every element of the <img class="fm-editor-equation" src="assets/ad7faaaf-0c2c-4576-92b4-6b1cf41f2489.png" style="width:1.75em;height:1.17em;"/> matrix. The final matrix will have a <span>dimension</span> <span>of 10 X 3, where each row is for each instance from the training set and each column is for each neuron of the first hidden layer.</span></p>
<p>The whole calculation that we saw is without the bias term, <em>b</em>, that we initially talked about. Well, that is just a matter the of addition of another dimension to the picture. In that case, before we apply the sigmoid function to each of the elements of the <img class="fm-editor-equation" src="assets/2f62dd1e-ca80-4973-a7da-b0b7622410bc.png" style="width:1.67em;height:1.08em;"/> matrix, the matrix itself would be changed to something like this:</p>
<p style="padding-left: 210px;"><img class="alignnone size-full wp-image-1470 image-border" src="assets/541cba3d-b30e-416a-8eac-8a9b0ec6f6f1.png" style="width:17.42em;height:11.75em;"/></p>
<p>After this matrix multiplication process, the sigmoid function is applied and the output is sent to the neurons in the next layers, and this whole process repeats for each hidden layer and output layer that we have in the NN. As we proceed, we are supposed to get <img class="fm-editor-equation" src="assets/7ca8c778-786e-4432-b25f-0409a6d2ef8c.png" style="width:1.58em;height:1.17em;"/> from the output layer.</p>
<p>The sigmoid activation function outputs values ranging from 0–1, but we are dealing with a binary classification problem, and we only want 0 or 1 as the final output from the NN. We can do this with a little tweak. We can define a threshold at the output layer of the NN—for the values that are less than 0.5 they should be identified as class 0 and the values that are greater than or equal to 0.5 should be identified as class 1. Note that this <span>is called forward pass or forward propagation.</span></p>
<div class="mce-root packt_infobox">The NN we just saw is referred to as a feed-forward network with no further optimization in its learning process. But wait! What does the network even learn? Well, an NN typically learns the weights and bias terms so that the final output is as accurate as possible. And this happens with gradient descent and backpropagation.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gradient descent and backpropagation</h1>
                </header>
            
            <article>
                
<p>Before we start learning about what gradient descent and backpropagation have to do in the context of neural networks, let's learn what is meant by an optimization problem.</p>
<p>An optimization problem, briefly, corresponds to the following:</p>
<ul>
<li>Minimizing a certain cost</li>
<li>Maximizing a certain profit</li>
</ul>
<p>Let's now try to map this to a neural network. What happens if, after getting the output from a feed-forward neural network, we find that its performance is not up to the mark (which is the case almost all the time)? How are we going to enhance the performance of the NN? The answer is gradient descent and backpropagation.</p>
<p>We are going to optimize the learning process of the neural network with these two techniques. But what are we going to optimize? What are we going to minimize or maximize? We require a specific type of cost that we will attempt to minimize.</p>
<p>We will define the cost in terms of a function. Before we define a cost function for the NN model, we will have to decide the parameters of the cost function. In our case, the weights and the biases are the parameters of the function that the NN is trying to learn to give us accurate results (see the information box just before this section). In addition, we will have to calculate the amount of loss that the network is inculcating at each step of its training process.</p>
<p>For a binary classification problem, a loss function called a <strong>cross-entropy</strong> loss function (for a binary classification problem it is called a binary cross cross-entropy loss function) is widely used, and we are going to use it. So, what does this function look like?</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6d3375fb-d8cf-49aa-ba7e-26efe4d6b342.png" style="width:17.67em;height:1.17em;"/></p>
<p>Here, <em>y</em> denotes the ground truth or true label (remember the response variable, <em>y</em>, in the training set) of a given instance and <img class="fm-editor-equation" src="assets/e50fa991-8408-4440-88e2-cd37d88e29a1.png" style="width:0.67em;height:1.25em;"/> denotes the output as yielded by the NN model. This function is convex in nature, which is just perfect for convex optimizers such as gradient descent.</p>
<p>This is one of the reasons that we didn't pick up a simpler and nonconvex loss function. (Don't worry if you are not familiar with terms like convex and nonconvex.)</p>
<p>We have our loss function now. Keep in mind that this is just for one instance of the entire set of data this is not the function on which we are going to apply gradient descent. The preceding function is going to help us define the cost function that we will eventually optimize using gradient descent. Let's see what that cost function looks like.</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2fe2f681-2cd6-4422-b942-fba491e140e1.png" style="width:13.00em;height:3.33em;"/></p>
<p>Here, <em>w</em> and <em>b</em> are the weights and biases that the network is trying to learn. The letter <em>m</em> represents the number of training instances, which is 10 in this case. The rest seems familiar. Let's put the original form of the function, <em>L()</em>, and see what <em>J()</em> looks like:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bc0b7b74-497f-4bae-8f14-a5661a0c48af.png" style="width:34.08em;height:3.08em;"/></p>
<p>The function may look a bit confusing, so just slow it down and make sure you understand it well.</p>
<p>We can finally move toward the optimization process. Broadly, gradient descent is trying to do the following:</p>
<ul>
<li>Give us a point where the cost function is as minimal as possible (this point is called the minima).</li>
<li>Give us the right values of the weights and biases so that the cost function reaches that point.</li>
</ul>
<p>To visualize this, let's take a simple convex function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1389 image-border" src="assets/b648cee7-9c85-4912-a310-764c72904530.png" style="width:23.08em;height:14.67em;"/></p>
<p>Now, say we start the journey at a random point, such as the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1390 image-border" src="assets/b7d2ca94-6643-41d4-ac7d-aa8bdb593cff.png" style="width:24.08em;height:15.25em;"/></p>
<p>So, the point at the top right corner is the point at which we started. And the point (directed by the dotted arrow) is the point we wish to arrive at. So, how do we do this in terms of simple computations?</p>
<p>In order to arrive at this point the following update rule is used:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/932dc7a9-29ef-438c-ae22-d0397b9fab67.png" style="width:10.75em;height:2.83em;"/></p>
<p>Here, we are taking the partial derivative of <em>J(w,b)</em> with respect to the weights. We are taking a partial derivative because <em>J(w,b)</em> contains <em>b</em> as one of the parameters. 𝝰 is the learning rate that speeds up this process. This update rule is applied multiple times to find the right values of the weights. But what about the bias values? The rule remains exactly the same only the equation is changed:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0505bb51-e6be-440d-86e5-3774b8532cbe.png" style="width:10.08em;height:2.83em;"/></p>
<p>These new assignments of weights and biases are essentially referred to as <em>backpropagation</em>, and it is done in conjunction with <em>gradient descent</em>. After computing the new values of the weights and the biases, the whole forward propagation process is repeated until the NN model generalizes well. Note that these rules are just for one single instance, provided that the instance has only one feature. Doing this for several instances that contain several features can be difficult, so we are going to skip that part however, those who are interested in seeing the fully fledged version of this may refer to a lecture online by Andrew Ng.</p>
<p>We have covered the necessary fundamental units of a standard neural network, and it was not easy at all. We started by defining neurons and we ended with backprop (the nerdy term of backpropagation). We have already laid the foundations of a deep neural network. Readers might be wondering whether that was a deep neural net that we just studied. As <strong>Andriy Burkov</strong> says (from his book titled <em>The Hundred Page Machine-Learning Book</em>):</p>
<div class="packt_quote">Deep learning refers to training neural networks with more than two non-output layers. … the term “deep learning” refers to training neural networks using the modern algorithmic and mathematical toolkit independently of how deep the neural network is. In practice, many business problems can be solved with neural networks having 2-3 layers between the input and output layers.</div>
<p>In the next sections, we will learn about the difference between deep learning and shallow learning. We will also take a look at two different types of neural networks—namely, convolutional neural networks and recurrent neural networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Different types of neural network</h1>
                </header>
            
            <article>
                
<p>So far, we have learned what feed-forward neural networks look like and how techniques such as backpropagation and gradient descent are applied to it in order to optimize their training process. The binary classification problem we studied earlier appears to be too naive and too impractical, doesn't it?</p>
<p>Well, there are many problems that a simple NN model can solve well. But as the complexity of the problem increases, improvements to the basic NN model become necessary. These complex problems include object detection, object classification, image-caption generation, sentiment analysis, fake-news classification, sequence generation, speech translation, and so on. For problems like these, a basic NN model is not sufficient. It needs some architectural improvements so that it can solve these problems. In this section, we are going to study two of the most powerful and widely used NN models—convolutional neural networks and recurrent neural networks. At the heart of the stunning applications of deep learning that we see nowadays sit these NN models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional neural networks</h1>
                </header>
            
            <article>
                
<p>Have you ever uploaded a photo of your friends' group to Facebook? If yes, have you ever wondered how Facebook detects all the faces in the photo automatically <span>just after the upload finishes</span><span>? In short, the answer is</span> <strong>convolutional neural networks</strong> <span>(</span><strong>CNNs</strong><span>).</span></p>
<p>A feed-forward network generally consists of several fully connected layers, whereas a CNN consists of several layers of convolution, along with other types of sophisticated layers, including fully-connected layers. These fully-connected layers are generally placed towards the very end and are typically used for making predictions. But what kinds of predictions? In an image-processing and computer-vision context, a prediction task can encompass many use cases, such as identifying the type of object present in the image that is given to the network. But are CNNs only good for image-related tasks? CNNs were designed and proposed for image-processing tasks (such as object detection, object classification, and so on) but it has found its use in many text-processing tasks as well. We are going to learn about CNNs in an image-processing context because CNNs are most popular for the wonders they can work in the domains of image processing and computer vision. But before we move on to this topic, it would be useful to understand how an image can be represented in terms of numbers.</p>
<p>An image consists of numerous pixels and dimensions—height x width x depth. For a color image, the depth dimension is generally 3, and for a grayscale image, the dimension is 1. Let's dig a bit deeper into this. Consider the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1391 image-border" src="assets/79d278c8-9d3b-409e-ae79-de957bb6251c.png" style="width:25.42em;height:27.42em;"/></p>
<p>The dimension of the preceding image is 626 x 675 x 3, and numerically, it is nothing but a matrix. Each pixel represents a particular intensity of red, green, and blue (according to the RGB color system). The image contains a total of 422,550 pixels (675 x 626).</p>
<p>The pixels are denoted by a list of three values of red, green, and blue colors. Let's now see what a pixel (corresponding to the twentieth row and the hundredth column in the matrix of 422,550 pixels) looks like in coding terms:</p>
<pre class="CDPAlignCenter CDPAlign"><strong>12, 24, 10</strong></pre>
<p>Each value corresponds to a particular intensity of the colors red, green, and blue. For the purpose of understanding CNNs, we will look at a much smaller dimensional image in grayscale. Keep in mind that each pixel in a grayscale image is between 0 and 255, where 0 corresponds to black and 255 corresponds to white.</p>
<p>The following is a dummy matrix of pixels representing a grayscale image (we will refer to this as an image matrix):</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1392 image-border" src="assets/a24eda9c-4190-41e1-bc67-d4d3a775f1d9.png" style="width:11.92em;height:3.67em;"/></p>
<p>Before we proceed, let's think intuitively about how can we train a CNN to learn the underlying representations of an image and make it perform some tasks. Images have a special property inherent to them: the pixels in an image that contain a similar type of information generally remain close to each other. Consider the image of a standard human face: the pixels denoting the hair are darker and are closely located on the image, whereas the pixels denoting the other parts of the face are generally lighter and also stay very close to each other. The intensities may vary from face to face, but you get the idea. We can use this spatial relationship of the pixels in an image and train a CNN to detect the similar pixels and the edges that they create in between them to distinguish between the several regions present in an image (in an image of a face, there are arbitrary edges in between the hair, eyebrows, and so on). Let's see how this <span>can</span> <span>be done.</span></p>
<p>A CNN typically has the following components:</p>
<ul>
<li>Convolutional layer</li>
<li>Activation layer</li>
<li>Pooling layer</li>
<li>Fully connected layer</li>
</ul>
<p>At the heart of a CNN sits an operation called convolution (which is also known as cross relation in the literature of computer vision and image processing). Adrian Rosebrock of PyImageSearch describes the operation as follows:</p>
<div class="packt_quote">In terms of deep learning, an (image) convolution is an element-wise multiplication of two matrices followed by a sum.</div>
<p>This quote tells us how an (image) convolution operator works. The matrices mentioned in the quote are the image matrix itself and another matrix known as the kernel. The original image matrix can be higher than the kernel matrix and the convolution operation is performed on the image matrix in a left–right top–bottom direction. Here is an example of a convolution operation involving the preceding dummy matrix and a kernel of size 2 x 2:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1393 image-border" src="assets/81b66b3b-aaa5-45a5-82d4-e14bfc38ecc0.png" style="width:52.92em;height:12.50em;"/></p>
<p>The kernel matrix actually serves as the weight matrix for the network, and to keep it simple, we ignore the bias term for now. It is also worth noting that our favorite image filters (sharpening, blurring, and so on) are nothing but outputs of certain kinds of convolution applied to the original images. A CNN actually learns these filter (kernel) values so that it can best capture the spatial representation of an image. These values can be further optimized using gradient descent and backpropagation. The following figure depicts four convolution operations applied to the image:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1394 image-border" src="assets/3f1deaa5-9ebe-413d-8869-8a3b87ddc294.png" style="width:53.08em;height:26.50em;"/></p>
<p>Note how the kernel is sliding and how the convoluted pixels are being calculated. But if we proceed like this, then the original dimensionality of the image gets lost. This can cause information loss. To prevent this, we apply a technique called padding and retain the dimensionality of the original image. There are many padding techniques, such as replicate padding, zero padding, wrap around, and so on. Zero padding is very popular in deep learning. We will now see how zero padding can be applied to the original image matrix so that the original dimensionality of the image is retained:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1395 image-border" src="assets/c102f556-b78a-45cb-b402-302b91561d97.png" style="width:20.67em;height:6.67em;"/></p>
<div class="p1 packt_infobox">Zero padding means that the pixel value matrix will be padded by zero on all sides, as shown in the preceding image.</div>
<p>It is important to instruct the network how it should slide the image matrix. This is controlled using a parameter called stride. The choice of stride depends on the dataset and the correct use of stride 2 is standard practice in deep learning. Let's see how stride 1 differs from stride 2:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1396 image-border" src="assets/fee0eddc-8450-4997-ab80-615b4b4155c1.png" style="width:41.92em;height:22.00em;"/></p>
<p>A convoluted image typically looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1397 image-border" src="assets/6e10b613-f9a8-49eb-b1d6-d6e2072fcff4.png" style="width:46.92em;height:26.83em;"/></p>
<p><span>The convoluted image largely depends on the kernel that is being used. The final output matrix is passed to an activation function and the function is applied to the matrix's elements. Another important operation in a CNN is pooling, but we will skip this for now. By now, you should have a good understanding of how a CNN works on a high level, which is sufficient for continuing to follow the book</span>. If you want to have a deeper understanding of how a CNN works, then refer to the blog post at <a href="https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/">https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recurrent neural networks</h1>
                </header>
            
            <article>
                
<p><strong>Recurrent neural networks (RNNs)</strong> are another type of neural network, and are tremendously good at NLP tasks—for example, sentiment analysis, sequence prediction, speech-to-text translation, language-to-language translation, and so on. Consider an example: you open up Google and you start searching for recurrent neural networks. The moment you start typing a word, Google starts giving you a list of suggestions which is most likely to be topped by the complete word, or the most commonly searched phrase that begins with the letters you have typed by then. This is an example of sequence prediction where the task is to predict the next sequence of the given phrase.</p>
<p>Let's take another example: you are given a bunch of English sentences containing one blank per sentence. Your task is to appropriately fill the gaps with the correct words. Now, in order to do this, you will need to use your previous knowledge of the English language in general and make use of the context as much as possible. To use previously encountered information like this, you use your memory. But what about neural networks? Traditional neural networks cannot do this because they do not have any memory. This is exactly where RNNs come into the picture.</p>
<p>The question that we need to answer is how can we empower neural networks with memory? An absolutely naive idea would be to do the following:</p>
<ul>
<li>Feed a certain sequence into a neuron.</li>
<li>Take the output of the neuron and feed it to the neuron again.</li>
</ul>
<p>It turns out that this idea is not that naive, and in fact constitutes the foundation of the RNN. A single layer of an RNN actually looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1399 image-border" src="assets/598b05d6-11ee-4c08-9c52-9bebfd97f229.png" style="width:7.08em;height:9.92em;"/></p>
<p>The loop seems to be a bit mysterious. You might already be thinking about what happens in each iteration of the loop:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1400 image-border" src="assets/4865606d-533c-4d58-a488-c425003e96e4.png" style="width:37.08em;height:13.33em;"/></p>
<p>In the preceding diagram, an RNN (the figure on the left) is unrolled to show three simple feedforward networks. But what do these unrolled networks do? Let's find this out now.</p>
<p>Let's consider the task of sequence prediction. To keep it simple, we will look at how an RNN can learn to predict the next letter to complete a word. For example, if we train the network with a set of letters, <em>{w, h, a, t}</em>, and after giving the letters <em>w,h</em>, and <em>a</em> sequentially<span>, the network should be able to predict that the letter should</span> be <em>t</em> so <span>that the meaningful word "what" is produced. Just like the feed-forward networks we saw earlier, <em>X</em> serves as the input vector to the network in RNN terminology, this vector is also referred to as the vocabulary of the network. The vocabulary of the network is, in this case</span>, <em>{w, h, a, t}</em>.</p>
<p>The network is fed with the letters <em>w,h</em>, and <em>a</em> sequentially. Let's try to give indices to the letters:</p>
<ul>
<li><img class="fm-editor-equation" src="assets/454ba3b9-649e-4cae-877b-6b2cde5bf155.png" style="width:1.08em;height:1.00em;"/>→ <img class="fm-editor-equation" src="assets/f653ecc8-9aae-468b-983e-256285270df6.png" style="width:4.42em;height:1.83em;"/></li>
<li><img class="fm-editor-equation" src="assets/173cfead-90f6-4776-83e6-208f4919ba20.png" style="width:0.92em;height:1.42em;"/>→ <img class="fm-editor-equation" src="assets/a2112f9b-9250-42c1-85c0-9be6fab58c48.png" style="width:1.75em;height:1.83em;"/></li>
<li><img class="fm-editor-equation" src="assets/3e03023b-b603-4d60-bb97-cb51c112e8c1.png" style="width:0.83em;height:0.92em;"/>→ <img class="fm-editor-equation" src="assets/2815c5c2-68c2-44ae-a545-8a9227b5685e.png" style="width:4.42em;height:1.83em;"/></li>
</ul>
<p>These indices are known as time-steps (the superscripts in the figure presenting the unrolling of an RNN). A recurrent layer makes use of the input that is given at previous time-steps, along with a function when operating on the current time-step. Let's see how the output is produced by this recurrent layer step by step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feeding the letters to the network</h1>
                </header>
            
            <article>
                
<p>Before we see how a recurrent layer produces the output, it is important to learn how we can feed the set of letters to the networks. One-hot encoding lets us do this in a very efficient way:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1401 image-border" src="assets/82595ac0-af4d-4777-8394-1939beb4c4b7.png" style="width:25.50em;height:10.17em;"/></p>
<p>So, in one-hot encoding, our input vectors/vocabulary of letters are nothing but four 4 x 1 matrices, each denoting a particular letter. One-hot encoding is standard practice for these tasks. This step is actually a data-preprocessing step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Initializing the weight matrix and more</h1>
                </header>
            
            <article>
                
<p>When there are neural networks, there are weights. This is true, right? But before we start to deal with the weights for our RNN, let's see exactly <span>where</span> <span>they are needed.</span></p>
<p>There are two different weight matrices in the case of an RNN—one for the input neuron (remember that we feed feature vectors <span>only</span> <span>through neurons</span><span>) and one for the recurrent neuron. A particular state in an RNN is produced using the following two equations:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0a36036b-7a4b-4307-b60b-5031283c9060.png" style="width:18.17em;height:2.83em;"/></p>
<p>To understand what each term means in the first equation, refer to the following image (don't worry, we will get to the second equation):</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1435 image-border" src="assets/8bbaa47e-7702-433d-aac9-870000b96aa9.png" style="width:30.42em;height:22.25em;"/></p>
<p>The first pass of <span>the</span> RNN <img class="fm-editor-equation" src="assets/4b9aaa2a-87d5-487b-9d8c-6a54cb705d09.png" style="width:1.58em;height:1.17em;"/>is the letter <em>w</em>. We will randomly initialize the two weight matrices as present in the equation (1). Assume that the matrix <img class="fm-editor-equation" src="assets/06871357-5a95-4e0b-aee0-90bfb11dcc7c.png" style="width:2.92em;height:1.50em;"/> after getting initialized looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1403 image-border" src="assets/94ec44a4-d673-4c34-854b-e1d35c371270.png" style="width:22.67em;height:6.42em;"/></p>
<p>The <img class="fm-editor-equation" src="assets/6ccce969-b83d-44cd-87d9-647322b6f44a.png" style="width:2.25em;height:1.17em;"/> matrix is 3 x 4:</p>
<ul>
<li><em>x</em> = 3, as we have three recurrent neurons in the recurrent layer</li>
<li><em>h</em> = 4, as our vocabulary is 4</li>
</ul>
<p>The matrix <img class="fm-editor-equation" src="assets/a1666498-816b-4b2b-87a6-4c777b0e2976.png" style="width:2.42em;height:1.25em;"/> is a 1 x 1 matrix. Let's take its value as 0.35028053. Let's also introduce the bias term <em>b</em> here, which is also a 1 x 1 matrix, 0.6161462. In the next step, we will put these values together and determine the value of <img class="fm-editor-equation" src="assets/8d4bf29d-dca0-4114-9f7b-79469774b4a9.png" style="width:1.17em;height:1.25em;"/>. (We will deal with the second equation later.)</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Putting the weight matrices together</h1>
                </header>
            
            <article>
                
<p>Let's determine <img class="fm-editor-equation" src="assets/c1ccae7d-7e2d-4c5c-9d8f-8f3d7d29a2bf.png" style="width:4.50em;height:1.50em;"/> first. <img class="fm-editor-equation" src="assets/d9784c61-5546-4ef2-8485-d134d1b8c132.png" style="width:1.58em;height:1.17em;"/>is a 4 x 1 matrix representing the letter <em>w</em>, which we defined earlier. The standard rules of matrix multiplication apply here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1404 image-border" src="assets/234a5eeb-d4fd-4fb8-ad16-468a49bb1010.png" style="width:38.42em;height:8.33em;"/></p>
<p>Now we will calculate the term <img class="fm-editor-equation" src="assets/a1b2ed80-6b11-4cdd-b69f-4dd54bf630b9.png" style="width:5.50em;height:1.25em;"/>. We will shortly see the significance of the bias term. Since <em>w</em> is the first letter that we are feeding to the network, it does not have any previous state therefore, we will take <img class="fm-editor-equation" src="assets/47774b6e-33a9-495f-9c90-7a98bc56ad42.png" style="width:1.42em;height:1.42em;"/> as a matrix of 3 x 1 consisting of zeros:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1405 image-border" src="assets/7dcad348-20fc-4827-96c5-f4e62ffd10bb.png" style="width:39.75em;height:14.08em;"/></p>
<p>Note that if we didn't take the bias term, we would have got a matrix consisting of only zeros. We will now add these two matrices as per the equation (1). The result of this addition is a 3 x 1 matrix and is stored in <img class="fm-editor-equation" src="assets/fe80e464-21d6-468f-bbc8-1a23d3a7a9a5.png" style="width:1.17em;height:1.33em;"/> (which in this case is <img class="fm-editor-equation" src="assets/def168f0-bef1-4905-8c0d-1ced2411df48.png" style="width:1.33em;height:1.33em;"/>):</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1406 image-border" src="assets/8d9339a0-4050-4c6f-8756-c05e881ccb3c.png" style="width:40.75em;height:8.75em;"/></p>
<p>Following the equation (1), all we need to do is apply the activation function to this matrix.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying activation functions and the final output</h1>
                </header>
            
            <article>
                
<p>When it comes to RNNs, <img class="fm-editor-equation" src="assets/ff3c61ce-bd96-4088-8fbe-4cf175154e52.png" style="width:3.17em;height:1.42em;"/> is a good choice <span>as an activation function</span><span>. So, after applying</span> <img style="font-size: 1em;;width:3.17em;height:1.42em;" class="fm-editor-equation" src="assets/00494d15-6793-4ec3-9fb8-3c3f40d6c9d9.png"/><span>, the matrix looks like the following:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1407 image-border" src="assets/fefb7cb2-a21e-4ac2-8aaa-84401ab2bf71.png" style="width:10.75em;height:9.83em;"/></p>
<p>We have got the result of <img class="fm-editor-equation" src="assets/5a3592f6-3ebd-4459-aa50-dfaa77b7eedd.png" style="width:1.42em;height:1.58em;"/>. <em>ht</em> acts as <img class="fm-editor-equation" src="assets/1f0a601e-c001-4c1a-86b6-84ffa79cc16e.png" style="width:2.83em;height:1.67em;"/> for the next time-step. We will now calculate the value of <img class="fm-editor-equation" src="assets/62216a8f-4753-45e0-853e-a73540ac5f36.png" style="width:1.33em;height:1.33em;"/> using equation (2). We will require another weight matrix <img class="fm-editor-equation" src="assets/7e9e4820-3c32-47c8-9529-a914a16cdd59.png" style="width:2.83em;height:1.67em;"/> (of shape 4 x 3) that is randomly initialized:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1408 image-border" src="assets/281bbcd0-d1ba-46a1-9998-7609b6319c5f.png" style="width:20.00em;height:8.42em;"/></p>
<p><span>After applying the second equation, t</span>he value of <img class="fm-editor-equation" src="assets/d7a94c7b-b682-4671-99b8-63180437e306.png" style="width:1.33em;height:1.33em;"/> becomes a 4 x 1 matrix:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1409 image-border" src="assets/0a969531-c833-44fd-8c6f-f034c65b267d.png" style="width:39.17em;height:9.25em;"/></p>
<p>Now, in order to predict what might be the next letter that comes after <em>w</em> (remember, we started all our calculations with the letter <em>w</em> and we still left with the first pass of the RNN) to make a suitable word from the given vocabulary, we will apply the softmax function to <img class="fm-editor-equation" src="assets/220321b9-76f4-476f-9fac-b77514106737.png" style="width:1.33em;height:1.33em;"/>. This will output a set of probabilities for each of the letters from the vocabulary:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1410 image-border" src="assets/20663bb4-96fe-4e90-bf5e-5ced2e6e9e10.png" style="width:7.00em;height:8.83em;"/></p>
<div class="packt_infobox">If anyone is curious about learning what a softmax function looks like, there is an extremely helpful article at <a href="http://bit.ly/softmaxfunc">http://bit.ly/softmaxfunc</a>.</div>
<p>So, the RNN tells us that the next letter after <em>w</em> is more likely to be an <img class="fm-editor-equation" src="assets/fdcd5b37-b1e7-4248-8ec0-1569c96a25a8.png" style="width:0.75em;height:0.83em;"/><span>. With this, we finish the initial pass of the RNN. As an exercise, you can play around with the <em>ht</em> value we got from this pass and apply it (along with the next letter</span> <em>h</em><span>) to the next pass of the RNN to see what happens.</span></p>
<p>Now, let's get to the most important question—what is the network learning? Again, weights and biases! You might have guessed the next sentence already. These weights are further optimized using backpropagation. Now, this backpropagation is a little bit different from what we have seen earlier. This version of backpropagation is referred to as <strong>backpropagation through time</strong>. We won't be learning about this. Before finishing off this section, let's summarize the steps (after one-hot encoding of the vocabulary) that were performed during the forward pass of the RNN:</p>
<ul>
<li>Initialize the weight matrices randomly.</li>
<li>Calculate <img class="fm-editor-equation" src="assets/06efe53c-1ce5-45a5-9526-995ad648f78c.png" style="width:1.25em;height:1.42em;"/> using equation (1).</li>
</ul>
<ul>
<li>Calculate <img class="fm-editor-equation" src="assets/71c99373-2b99-42eb-9199-be1382be273b.png" style="width:1.17em;height:1.17em;"/> using equation (2).</li>
<li>Apply the softmax function to <img class="fm-editor-equation" src="assets/fbe962da-d664-4cf8-9c26-31ddc850c175.png" style="width:1.00em;height:1.00em;"/>to get the probabilities of each of the letters in the vocabulary.</li>
</ul>
<p>It is good to know that apart from CNNs and RNNs, there are other types of neural networks, such as auto-encoders, generative adversarial networks, capsule networks, and so on. In the previous two sections, we learned about two of the most powerful types of neural network in detail. But when we talk about cutting-edge deep-learning applications, are these networks good enough to be used? Or do we need more enhancements on top of these? It turns out that although these architectures perform well, they fail to scale, hence the need for more sophisticated architectures. We will get to some of these specialized architectures in the next chapters.</p>
<p>We have covered a good amount of theory since <a href="f97d928f-3614-4d12-ad37-d5736008f542.xhtml">Chapter 1</a>, <em>Demystifying Artificial Intelligence and Fundamentals of Machine Learning</em>. In the next few sections, we will be diving into some hands-on examples.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring Jupyter Notebooks</h1>
                </header>
            
            <article>
                
<p>While working on a project relating to deep learning, you must deal with a huge amount of variables of various types and arrays of various dimensions. Also, since the data contained in them is massive and keeps changing after nearly every step, we need a tool that helps us to observe the output produced by each step so that we can proceed accordingly. A Jupyter Notebook is one such tool. Jupyter Notebooks are known for their simplicity, and their wide support of features and platforms are currently the standard tool for developing deep-learning solutions. The reasons for their popularity can be understood by considering the fact that several of the top tech giants offer their own version of the tool, such as Google Colaboratory and Microsoft Azure Notebooks. Moreover, the popular code-hosting website GitHub has been providing a native rendering of Jupyter Notebook <span>since 2016</span><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing Jupyter Notebook</h1>
                </header>
            
            <article>
                
<p>Let's begin with the installation of Jupyter Notebook.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installation using pip</h1>
                </header>
            
            <article>
                
<p>If you already have Python installed on your system, you can install the Jupyter package from the <kbd>pip</kbd> repository to start using Jupyter Notebooks quickly.</p>
<p>For Python 3, use the following:</p>
<pre><strong>python3 -m pip install --upgrade pip</strong><br/><strong>python3 -m pip install jupyter</strong></pre>
<p>For Python 2, use the following:</p>
<pre><strong>python -m pip install --upgrade pip</strong><br/><strong>python -m pip install jupyter</strong></pre>
<div class="packt_infobox">For Mac users, if the <kbd>pip</kbd> installation is not found, you can download the latest Python version, which carries <kbd>pip</kbd> bundled with it.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installation using Anaconda</h1>
                </header>
            
            <article>
                
<p>While it is possible to install Jupyter as a single package from <kbd>pip</kbd>, it is strongly recommended that you install the Anaconda distribution for Python, which automatically installs Python, Jupyter, and several other packages required for machine learning and data science. Anaconda makes it very easy to deal with the various package versions and update dependency packages or dependent packages.</p>
<p>Firstly, download the correct Anaconda distribution for your system and requirements from <a href="https://www.anaconda.com/downloads">https://www.anaconda.com/downloads</a> and then follow the corresponding installation steps given on the website.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Verifying the installation</h1>
                </header>
            
            <article>
                
<p>To check whether Jupyter has correctly installed, run the following command in Command Prompt (Windows) or Terminal (Linux/Mac):</p>
<pre><strong>jupyter notebook</strong></pre>
<p>You will be able to see some logging output at the terminal (henceforth, the default term for Command Prompt on Windows and Terminal on Linux or Mac). After that, your default browser, will open up and you will be taken to a link on the browser which will resemble the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1411 image-border" src="assets/580396c4-cea4-4e26-9fa3-b206c340510a.png" style="width:34.83em;height:23.67em;"/></p>
<p>Under the <span class="packt_screen">Files</span> tab, a basic file manager is provided that the user can use to create, upload, rename, delete, and move files.</p>
<p>The <span class="packt_screen">Running</span> tab lists all the currently running Jupyter Notebooks, which can be shut down from the listing displayed.</p>
<p>The <span class="packt_screen">Clusters</span> tab provides an overview of all the available IPython clusters. In order to use this feature, you are required to install the IPython Parallel extension for your Python environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Jupyter Notebooks</h1>
                </header>
            
            <article>
                
<p>A Jupyter Notebook by default is identified by the <kbd>.ipynb</kbd> extension. Upon clicking on the name of once such notebook in the file manager provided by Jupyter, you'll be presented with a screen resembling the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1412 image-border" src="assets/9585b379-18ef-43e1-9a0a-60b00b5e6efb.png" style="width:49.08em;height:38.83em;"/></p>
<p>The topmost section, where you can see a menu bar, a toolbar, and the title of the notebook, is called the <strong>header</strong>. On the right side of the header you can see the environment in which the notebook is executing, and when any task is running, the white circle beside the environment language's name turns gray.</p>
<p>Below the header is the body of the notebook, which is composed of cells stacked vertically. Each cell in the body of the notebook is either a block of code, a markdown cell, or a raw cell. A code cell can have <span>an output cell</span> <span>attached below it, which the user cannot edit manually. This holds the output produced by the code cell associated with it.</span></p>
<p>In a Jupyter Notebook, the keyboard behaves differently for different <strong>modes</strong> of a cell For this reason, these notebooks are called <strong>modal</strong>. There are two modes in which a notebook cell can operate: the <strong>command</strong> mode and the <strong>editx</strong> mode.</p>
<p>While a cell is in command mode, it has a gray border. In this mode, the cell contents cannot be changed. The keys of the keyboard in this mode are mapped to several shortcuts that can be used to modify the cell or the notebook as a whole.</p>
<p>While in command mode, if you press the <em>Enter</em> key on the keyboard, the cell mode changes to the edit mode. While in this mode, the contents of the cell can be changed and the basic keyboard shortcuts that are available in the usual textboxes in the browser can be invoked.</p>
<p>To exit the edit mode, the user can use the <em>Esc</em> key. To run the particular cell, the user has to input <em>Shift</em> + <em>Return</em>, which will do one of the following in each case:</p>
<ul>
<li>For a markdown cell, the rendered markdown shall be displayed.</li>
<li>For a raw cell, the raw text as entered shall be visible.</li>
<li>For a code cell, the code will be executed and if it produces some output, an output cell attached to the code cell will be created and the output will get displayed there. If the code in the cell asks for an input, an input field will appear and the cell's code execution stalls until the input is provided.</li>
</ul>
<p>Jupyter also allows the manipulation of text files and Python script files using its in-built text editor. It is also possible to invoke the system terminal from within the Jupyter environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up a deep-learning-based cloud environment</h1>
                </header>
            
            <article>
                
<p>Before we begin setting up a cloud-based deep learning environment, we might wonder why would we need it or how a cloud-based deep learning environment would benefit us. Deep learning requires a massive amount of mathematical calculation. At every layer of the neural network, there is a mathematical matrix undergoing multiplication with another or several other such matrices. Furthermore, every data point itself can be a vector instead of a singular entity. Now, to train over several repetitions, such a deep learning model would require a lot of time just because of the number of mathematical operations involved.</p>
<p>A GPU-enabled machine would be much more efficient at executing these operations because a GPU is made specifically for high-speed mathematical calculations however, GPU-enabled machines are costly and may not be affordable to everyone. Furthermore, considering that <span>multiple developers work on the same software</span> <span>in a work environment</span><span>, it might be a very costly option to buy GPU-enabled machines for all the developers on the team. For these reasons, the idea of a GPU-enabled cloud computing environment has a strong appeal.</span></p>
<p>Companies nowadays are increasingly leaning towards the usage of GPU-enabled cloud environments for their development teams, which can lead to the creation of a common environment for all of the developers as well as the facilitation of high-speed computation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up an AWS EC2 GPU deep learning environment</h1>
                </header>
            
            <article>
                
<p>In this section, we will learn how to set up a deep learning specific instance on AWS. Before you can begin working with AWS, you will need to create an account on the AWS console. To do so, go through the following steps:</p>
<ol>
<li>Visit <a href="https://console.aws.amazon.com">https://console.aws.amazon.com</a> and you'll be presented with a login/sign up screen.</li>
<li>If you do not already have an AWS account, click on <span class="packt_screen">Create a new AWS account</span> and follow the steps to create one, which might require you to enter your debit/credit card details to enable billing for your account.</li>
<li>Upon logging into your account, on the dashboard, click on <span class="packt_screen"><span class="packt_screen">EC2</span></span> in the <span class="packt_screen">All services</span> section, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1413 image-border" src="assets/a1e52502-90c0-477b-82fa-70b9ee8e3450.png" style="width:14.33em;height:12.75em;"/></p>
<p>Once you have reached the EC2 management page within the AWS console, you'll need to go through the steps in the following sections to create an instance for your deep learning needs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1: Creating an EC2 GPU-enabled instance</h1>
                </header>
            
            <article>
                
<p>First, select the Ubuntu 16.04 or 18.04 LTS AMI:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1414 image-border" src="assets/41e6aa63-bb63-4a50-bbc7-3ae7249e74f9.png" style="width:103.25em;height:62.25em;"/></p>
<p>Then, choose a GPU-enabled instance configuration. The <kbd>g2.2xlarge</kbd> is a good choice for a starter deep learning environment:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1415 image-border" src="assets/9b74f7f3-e953-46a0-a975-3d9b78497042.png" style="width:104.75em;height:40.00em;"/></p>
<p>Next, configure the required instance settings or leave them as their default and proceed to the storage step. Here, a recommended size of the volume is 30 GB. You can then proceed to launch the instance with the default options.</p>
<p>Assign an EC2 key pair to your instance so that you can access the instance's terminal over SSH from your system. If you name the key pair <kbd>abc</kbd>, then a file named <kbd>abc.pem</kbd> would download automatically to your browser's default download location.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2: SSHing into your EC2 instance</h1>
                </header>
            
            <article>
                
<p>Open up a terminal on your system and <span>using</span> <kbd>cd</kbd>, <span>navigate</span> <span>to the directory that your</span> <kbd>abc.pem</kbd> <span>file is stored in.</span></p>
<p>If you're unfamiliar with the <kbd>cd</kbd> command, consider a scenario in which you are inside a folder named <kbd>Folder1</kbd>, which has the following contents:</p>
<pre><strong>Folder1 /</strong><br/><strong>    - Folder2</strong><br/><strong>    - Folder3</strong><br/><strong>    - File1.jpg</strong><br/><strong>   - File2.jpg</strong></pre>
<p>To access any files inside the folder named <kbd>Folder2</kbd>, you'll have to change your working directory to that folder. To do so, you can use the following example of the <kbd>cd</kbd> command:</p>
<pre><strong>cd Folder2</strong></pre>
<div class="packt_infobox">Note that this command only works when you're already inside <kbd>Folder1</kbd>, which can be reached with a similar usage of the <kbd>cd</kbd> command from anywhere on the system.</div>
<p>You can read more about the usage of any command on a Linux system by using the following command:</p>
<pre><strong>man &lt;command&gt;</strong></pre>
<p>For example, you can use the following:</p>
<pre><strong>man cd</strong></pre>
<p>Now, set the permissions required for SSH using the key file by entering the following:</p>
<pre><strong>$ chmod 400 abc.pem</strong></pre>
<p>Now, to SSH into your instance, you will need its public IP or instance public DNS. For example, if the public IP is <kbd>1.2.3.4</kbd>, then use the following command:</p>
<pre><strong>$ ssh -i abc.pem ubuntu@1.2.3.4</strong></pre>
<p>The public IP of the AWS instance can be found on the details panel below the list of running instances on the AWS console in the EC2 management page.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3: Installing CUDA drivers on the GPU instance</h1>
                </header>
            
            <article>
                
<p>First, update/install the NVIDIA graphics drivers:</p>
<pre><strong>$ sudo add-apt-repository ppa:graphics-drivers/ppa -y</strong><br/><strong>$ sudo apt-get update</strong><br/><strong>$ sudo apt-get install -y nvidia-xxx nvidia-settings</strong></pre>
<p>Here, <kbd>xxx</kbd> can be replaced with the graphics hardware version installed on your instance, which can be found in the instance details.</p>
<p>Next, download the CUDA deb file (this code is for the latest version at the time of writing, from Jan, 2019):</p>
<pre><strong>$ wget https://developer.download.nvidia.com/compute/cuda/10.0/secure/Prod/local_installers/cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb</strong></pre>
<p>Then, proceed with the following commands:</p>
<pre><strong>$ sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb</strong><br/><strong>$ sudo apt-key add /var/cuda-repo-&lt;version&gt;/7fa2af80.pub</strong><br/><strong>$ sudo apt-get update</strong><br/><strong>$ sudo apt-get install -y cuda nvidia-cuda-toolkit</strong></pre>
<p>To verify whether everything was installed successfully, run the following commands:</p>
<pre><strong>$ nvidia-smi</strong><br/><strong>$ nvcc -version</strong></pre>
<p>If both the commands produce output without any warnings or errors, then the installation is successful.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4: Installing the Anaconda distribution of Python</h1>
                </header>
            
            <article>
                
<p>First, download the Anaconda installer script:</p>
<pre><strong>$ wget https://repo.continuum.io/archive/Anaconda3-2018.12-Linux-x86_64.sh</strong></pre>
<p>Next, set the script to executable:</p>
<pre><strong>$ chmod +x Anaconda*.sh</strong></pre>
<p>Then, run the installation script:</p>
<pre><strong>$ ./Anaconda3-2018.12-Linux-x86_64.sh</strong></pre>
<p>The installer will ask for several options. To verify successful installation, use the following command:</p>
<pre><strong>$ python3</strong></pre>
<p>The Python3 REPL loads into the terminal with a banner reflecting the Anaconda distribution version installed on your instance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 5: Run Jupyter</h1>
                </header>
            
            <article>
                
<p>Use the following command to get the Jupyter Notebook server started on the instance:</p>
<pre><strong>$ jupyter notebook</strong></pre>
<p>The output on the terminal will contain a URL on opening, with which you will be able to access the Jupyter Notebook running on your EC2 GPU instance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning on Crestle</h1>
                </header>
            
            <article>
                
<p>While a customized deep learning environment can be of use when you need greater control over the system—such as when you want to have third-party applications working along with your deep learning model—at other times, you may not have such needs, and you'll only be interested in performing deep learning on the cloud, quickly and in a collaborative manner. In such circumstances, paying the cost of an AWS <kbd>g2.2xlarge</kbd> instance would be much higher than that of paying only for computing time or GPU time used.</p>
<p>Crestle is a service that provides GPU-enabled Jupyter Notebooks online at very affordable pricing. To begin using Crestle, go through the following steps:</p>
<ol>
<li>Log on to <a href="http://www.crestle.com">www.crestle.com</a>.</li>
<li>Click on <span class="packt_screen">Sign Up</span> and fill up the sign-up form that appears.</li>
<li>Check your email for an account confirmation link. Activate your account and sign in.</li>
<li>You'll be taken to the dashboard where you'll find a button reading <span class="packt_screen">Start Jupyter</span>. You will have the option of using the GPU or keeping it disabled. Click on the <span class="packt_screen">Start Jupyter</span> button with the GPU option enabled.</li>
</ol>
<p>You will be presented with a Jupyter environment running on the cloud with GPU support. While the pricing is subject to change with the passage of time, it is one of the most affordable solutions available on the internet as of January 2020.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other deep learning environments</h1>
                </header>
            
            <article>
                
<p>As well as the aforementioned ways of performing GPU-enabled deep learning on the cloud, you can also, in certain circumstances, choose to use other platforms.</p>
<p>Google Colaboratory is a freely available Jupyter Notebook service that is accessible at <a href="https://colab.research.google.com">https://colab.research.google.com</a>. Colaboratory notebooks are stored on the user's Google Drive and so have a storage limit of 15 GB. It is possible to store large datasets on Google Drive and include them in the project with the help of the Google Drive Python API. By default, the GPU is disabled on Colaboratory and has to be manually turned on.</p>
<p>Kaggle is yet another platform that was specifically built to carry out contests on data science. It provides a Jupyter-Notebooks-like environment called a <strong>kernel</strong>. Each kernel is provided with a large amount of RAM and free GPU power however, there are more strict storage limits on Kaggle than on Google Colaboratory, and so it is an effective option when the computation is intensive but the data that is to be used and the output is not very large.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring NumPy and pandas</h1>
                </header>
            
            <article>
                
<p>NumPy and pandas are the backbone of nearly every data-science-related library available in the Python language. While pandas is built on top of NumPy, NumPy itself is a wrapping of Python around high-performance C code to facilitate superior mathematical computing in Python than Python itself in its pure form can provide.</p>
<p>Almost all deep learning software developed in Python in one way or another depends upon NumPy and pandas. It is therefore important to have a good understanding of both libraries and the features that they can provide.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NumPy</h1>
                </header>
            
            <article>
                
<p>NumPy is an acronym for <strong>Numerical Python</strong>. Vanilla Python lacks the implementation of arrays, which are close analogs of the mathematical matrices used to develop machine learning models. NumPy brings to Python support for multidimensional arrays and high-performance computing features. It can be included into any Python code by using the following import statement:</p>
<pre><strong>import numpy as np</strong></pre>
<p><kbd>np</kbd> is a commonly used convention for importing NumPy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NumPy arrays</h1>
                </header>
            
            <article>
                
<p>There are several methods to create arrays in NumPy. The following are some notable ones:</p>
<ul>
<li><kbd>np.array</kbd>: To convert Python lists to NumPy arrays:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1416 image-border" src="assets/bea02ad3-cb06-4762-8ddd-1ecd8acd8a7a.png" style="width:44.75em;height:10.92em;"/></p>
<ul>
<li><kbd>np.ones</kbd> or <kbd>np.zeros</kbd>: To create a NumPy array of all 1s or all 0s:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1471 image-border" src="assets/be91b2e2-dce0-40eb-ae79-746dd9ddb97c.png" style="width:31.67em;height:39.75em;"/></p>
<ul>
<li><kbd>np.random.rand</kbd>: To generate an array of random numbers:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1418 image-border" src="assets/e5956406-688a-4c1b-986c-d73d3ef30bff.png" style="width:32.67em;height:12.50em;"/></p>
<ul>
<li><kbd>np.eye</kbd>: To generate an identity matrix of given square matrix dimensions:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1419 image-border" src="assets/3468a284-89f9-41d5-ba9e-8cadbfd6ca35.png" style="width:25.08em;height:17.50em;"/></p>
<p>Let's now look at basic NumPy array operations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basic NumPy array operations</h1>
                </header>
            
            <article>
                
<p>NumPy arrays are Python analogues of mathematical matrices, and so they support the arithmetic manipulation of all basic types, such as addition, subtraction, division, and multiplication.</p>
<p>Let's declare two NumPy arrays and store them as <kbd>array1</kbd> and <kbd>array2</kbd>:</p>
<pre><strong>array1 = np.array([[10,20,30], [40, 50, 60], [70, 80, 90]])</strong><br/><strong><span>array2 = np.array([[90, 80, 70], [60, 50, 40], [30, 20, 10]])</span></strong></pre>
<p>Now let's look at some examples of each arithmetic operation on these arrays:</p>
<ul>
<li><strong>Addition</strong>:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1420 image-border" src="assets/170428ce-55de-4a81-bf59-4ea0b5e9af4a.png" style="width:18.42em;height:8.50em;"/></p>
<ul>
<li><strong>Subtraction</strong>:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1421 image-border" src="assets/ad215dbc-939b-4eff-a0be-e217c9cc2bf5.png" style="width:18.08em;height:8.42em;"/></p>
<ul>
<li><strong>Multiplication</strong>:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1422 image-border" src="assets/780c5000-1e48-466d-8e60-de7561b8d815.png" style="width:19.75em;height:8.25em;"/></p>
<ul>
<li><strong>Division</strong>:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1423 image-border" src="assets/d1097939-d2ab-4455-a459-056d54e7e468.png" style="width:31.42em;height:9.50em;"/></p>
<p>Let's now compare NumPy arrays with Python lists.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NumPy arrays versus Python lists</h1>
                </header>
            
            <article>
                
<p>Let's now see how NumPy arrays offer advantages over Python lists.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Array slicing over multiple rows and columns</h1>
                </header>
            
            <article>
                
<p>While it is not possible to slice lists of lists in Python in such a way as to select a specific number of rows and columns in the list of lists, NumPy array slicing works according to the following syntax:</p>
<p><kbd>Array [ rowStartIndex : rowEndIndex, columnStartIndex : columnEndIndex ]</kbd></p>
<p>Here's an example:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1424 image-border" src="assets/3f6ed47b-cf3a-42f9-9413-9e6a146e5577.png" style="width:21.67em;height:17.75em;"/></p>
<p>In the preceding example, we are able to select two rows and all elements of those rows in NumPy array <kbd>a</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Assignment over slicing</h1>
                </header>
            
            <article>
                
<p>While it is not possible to assign values to slices of Python lists, NumPy allows the assignment of values to NumPy arrays. For example, to assign 4 to the third to the fifth element of a NumPy one-dimensional array, we can use the following:</p>
<pre><strong>arr[2:5] = 4</strong></pre>
<p>Next, we will be looking at pandas.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pandas</h1>
                </header>
            
            <article>
                
<p>Built on top of NumPy, pandas is one of the most widely used libraries for data science using Python. It facilitates high-performance data structures and data-analysis methods. Pandas provides an in-memory two-dimensional table object called a DataFrame, which in turn is made of a one-dimensional, array-like structure called a series.</p>
<p>Each DataFrame in pandas is in the form of a spreadsheet-like table with row labels and column headers. It is possible to carry out row-based or column-based operations, or both together. Pandas strongly integrates with matplotlib to provide several intuitive visualizations of data that are often very useful when making presentations or during exploratory data analysis.</p>
<p>To import pandas into a Python project, use the following line of code:</p>
<pre><strong>import pandas as pd</strong></pre>
<p>Here, <kbd>pd</kbd> is a common name for importing pandas.</p>
<p>Pandas provides the following data structures:</p>
<ul>
<li><strong>Series</strong>: One-dimensional array or vector, similar to a column in a table</li>
<li><strong>DataFrames</strong>: Two-dimensional table, with table headers and labels for the rows</li>
<li><strong>Panels</strong>: A dictionary of DataFrames, much like a MySQL database that contains several tables inside</li>
</ul>
<p>A pandas series can be created using the <kbd>pd.Series( )</kbd> method, while a DataFrame can be created using the <kbd>pd.DataFrame( )</kbd> method—for example, in the following code, we create a pandas DataFrame object using multiple series objects:</p>
<pre><strong>import pandas as pd</strong><br/><br/><strong>employees = pd.DataFrame({ "weight": pd.Series([60, 80, 100],index=["Ram", "Sam", "Max"]),"dob": pd.Series([1990, 1970, 1991], index=["Ram", "Max", "Sam"], name="year"),"hobby": pd.Series(["Reading", "Singing"], index=["Ram", "Max"])})</strong><br/><br/><strong>employees</strong></pre>
<p>The output of the preceding code is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1425 image-border" src="assets/0eac47bd-7093-4c7e-a082-545d3e511900.png" style="width:23.58em;height:12.25em;"/></p>
<p>Some of the most important methods available for a pandas DataFrame are as follows:</p>
<ul>
<li><kbd>head(n)</kbd> or <kbd>tail(n)</kbd>: To display the top or bottom <em>n</em> rows of the DataFrame.</li>
<li><kbd>info( )</kbd>: To display information on all the columns, dimensions, and types of data in the columns of the DataFrame.</li>
<li><kbd>describe( )</kbd>: To display handy aggregate and statistical information about each of the columns in the DataFrame. Columns that are not numeric are omitted.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We covered a lot of different things in this chapter. We started by learning the basics of a neural network and <span>then</span> <span>we gradually proceeded. We learned the two most powerful types of neural networks used today—CNNs and RNNs—and we also learned about them on a high level, but without skipping their foundational units. We learned that as the complexity in a neural network increases, it requires a lot of computational power, which standard computers may fail to cater for we saw how this problem can be overcome by configuring a deep learning development environment using two different providers—AWS and Crestle. We explored Jupyter Notebooks, a powerful tool for performing deep learning tasks. We learned about the usage of two very popular Python libraries—NumPy and pandas. Both of these libraries are extensively used when performing deep learning tasks.</span></p>
<p>In the next chapter, we will be building applications and integrating deep learning to make them perform intelligently. But before we did this, it was important for us to know the basics that were covered in this chapter. We are now in a good position to move on to the next chapter.</p>


            </article>

            
        </section>
    </body></html>