["```\ndef load(image_file): \n    def load_data(image_file):\n        jpg_file = image_file.numpy().decode(\"utf-8\")\n        bmp_file = jpg_file.replace('.jpg','.bmp')\n        png_file = jpg_file.replace('.jpg','.png')        \n        image = np.array(Image.open(jpg_file))/127.5 - 1\n        map = np.array(Image.open(png_file))/127.5 - 1\n        labels = np.array(Image.open(bmp_file),  \t\t\t\t\t\t\tdtype=np.uint8)\n        h, w, _ = image.shape\n        n_class = 12\n        mask = np.zeros((h, w, n_class), dtype=np.float32)\n        for i in range(n_class):\n            one_hot[labels==i, i] = 1        \n        return map, image, mask \n    [mask, image, label] = tf.py_function( \t\t\t\t\t\tload_data, [image_file], \t\t\t\t\t\t [tf.float32, tf.float32, \t\t\t\t\t\t  tf.float32])\n```", "```\nclass SPADE(layers.Layer):\n    def __init__(self, filters, epsilon=1e-5):\n        super(SPADE, self).__init__()\n        self.epsilon = epsilon\n        self.conv = layers.Conv2D(128, 3, padding='same', \t\t\t\t\t\t\tactivation='relu')\n        self.conv_gamma = layers.Conv2D(filters, 3,  \t\t\t\t\t\t\t  padding='same')\n        self.conv_beta = layers.Conv2D(filters, 3, \t\t\t\t\t\t\t padding='same')\n```", "```\n    def build(self, input_shape):\n        self.resize_shape = input_shape[1:3]\n```", "```\n    def call(self, input_tensor, raw_mask):\n        mask = tf.image.resize(raw_mask, self.resize_shape, \t\t\t\t\t    method='nearest')\n        x = self.conv(mask)\n        gamma = self.conv_gamma(x)\n        beta = self.conv_beta(x)        \n        mean, var = tf.nn.moments(input_tensor, \t\t\t\t\t   axes=(0,1,2), keepdims=True)\n        std = tf.sqrt(var + self.epsilon)\n        normalized = (input_tensor - mean)/std        \n        output = gamma * normalized + beta\n        return output\n```", "```\nclass Resblock(layers.Layer):\n    def __init__(self, filters):\n        super(Resblock, self).__init__()\n        self.filters = filters        \n    def build(self, input_shape):\n        input_filter = input_shape[-1]\n        self.spade_1 = SPADE(input_filter)\n        self.spade_2 = SPADE(self.filters)\n        self.conv_1 = layers.Conv2D(self.filters, 3, \t\t\t\t\t\t\tpadding='same')\n        self.conv_2 = layers.Conv2D(self.filters, 3,  \t\t\t\t\t\t\tpadding='same')\n        self.learned_skip = False        \n        if self.filters != input_filter:\n            self.learned_skip = True\n            self.spade_3 = SPADE(input_filter)\n            self.conv_3 = layers.Conv2D(self.filters,  \t\t\t\t    \t\t\t3, padding='same')\n```", "```\n    def call(self, input_tensor, mask):\n        x = self.spade_1(input_tensor, mask)\n        x = self.conv_1(tf.nn.leaky_relu(x, 0.2))\n        x = self.spade_2(x, mask)\n        x = self.conv_2(tf.nn.leaky_relu(x, 0.2))        \n        if self.learned_skip:\n            skip = self.spade_3(input_tensor, mask)\n            skip = self.conv_3(tf.nn.leaky_relu(skip, 0.2))\n        else:\n            skip = input_tensor            \n        output = skip + x\n        return output\n```", "```\ndef build_generator(self):\n    DIM = 64\n    z = Input(shape=(self.z_dim))\n    mask = Input(shape=self.input_shape)\n    x = Dense(16384)(z)\n    x = Reshape((4, 4, 1024))(x)\n    x = UpSampling2D((2,2))(Resblock(filters=1024)(x, mask))\n    x = UpSampling2D((2,2))(Resblock(filters=1024)(x, mask))\n    x = UpSampling2D((2,2))(Resblock(filters=1024)(x, mask))\n    x = UpSampling2D((2,2))(Resblock(filters=512)(x, mask))\n    x = UpSampling2D((2,2))(Resblock(filters=256)(x, mask))\n    x = UpSampling2D((2,2))(Resblock(filters=128)(x, mask))\n    x = tf.nn.leaky_relu(x, 0.2)\n    output_image = tanh(Conv2D(3, 4, padding='same')(x)) \n    return Model([z, mask], output_image, name='generator')   \n```", "```\ndef build_discriminator(self):\n    DIM = 64\n    model = tf.keras.Sequential(name='discriminators') \n    input_image_A = layers.Input(shape=self.image_shape, \t\t\t\t\tname='discriminator_image_A')\n    input_image_B = layers.Input(shape=self.image_shape, \t\t\t\t\tname='discriminator_image_B') \n    x = layers.Concatenate()([input_image_A, input_image_B]) \n    x1 = self.downsample(DIM, 4, norm=False)(x) # 128\n    x2 = self.downsample(2*DIM, 4)(x1) # 64\n    x3 = self.downsample(4*DIM, 4)(x2) # 32\n    x4 = self.downsample(8*DIM, 4, strides=1)(x3) # 29\n    x5 = layers.Conv2D(1, 4)(x4) \n    outputs = [x1, x2, x3, x4, x5]\n    return Model([input_image_A, input_image_B], outputs)\n```", "```\ndef VGG_loss(self, real_image, fake_image):\n    # RGB to BGR\n    x = tf.reverse(real_image, axis=[-1])\n    y = tf.reverse(fake_image, axis=[-1])\n    # [-1, +1] to [0, 255]\n    x = tf.keras.applications.vgg19.preprocess_input( \t\t\t\t\t\t\t\t127.5*(x+1))\n    y = tf.keras.applications.vgg19.preprocess_input( \t\t\t\t\t\t\t\t127.5*(y+1))\n    # extract features\n    feat_real = self.vgg(x)\n    feat_fake = self.vgg(y) \n    weights = [1./32, 1./16, 1./8, 1./4, 1.]\n    loss = 0\n    mae = tf.keras.losses.MeanAbsoluteError()\n    for i in range(len(feat_real)):\n        loss += weights[i] * mae(feat_real[i], feat_fake[i])\n    return loss\n```", "```\ndef feature_matching_loss(self, feat_real, feat_fake):\n    loss = 0\n    mae = tf.keras.losses.MeanAbsoluteError()\n    for i in range(len(feat_real)-1):\n        loss +=  mae(feat_real[i], feat_fake[i])\n    return loss\n```", "```\ndef d_hinge_loss(y, is_real):\n    if is_real:\n        loss = tf.reduce_mean(tf.maximum(0., 1-y))\n    else:\n        loss = tf.reduce_mean (tf.maximum(0., 1+y))\n    return loss\n```", "```\ndef hinge_loss_d(self, y, is_real):\n    label = 1\\. if is_real else -1.\n    loss = tf.keras.losses.Hinge()(y, label)\n    return loss\n```", "```\ndef g_hinge_loss(y):\n    return –tf.reduce_mean(y)\n```"]