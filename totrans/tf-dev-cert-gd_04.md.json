["```\n    # import tensorflow\n    ```", "```\n    import tensorflow as tf\n    ```", "```\n    from tensorflow import keras\n    ```", "```\n    from tensorflow.keras import Sequential\n    ```", "```\n    from tensorflow.keras.layers import Dense\n    ```", "```\n    print(tf.__version__)\n    ```", "```\n2.8.0\n```", "```\n    #import additional libraries\n    ```", "```\n    import numpy as np\n    ```", "```\n    import pandas as pd\n    ```", "```\n    # For visualizations\n    ```", "```\n    import matplotlib.pyplot as plt\n    ```", "```\n    import seaborn as sns\n    ```", "```\n    #for splitting the data into training and test set\n    ```", "```\n    from sklearn.model_selection import train_test_split\n    ```", "```\n    # For Normalization\n    ```", "```\n    from sklearn.preprocessing import MinMaxScaler\n    ```", "```\n    # Confusion matrix\n    ```", "```\n    from sklearn.metrics import confusion_matrix, classification_report\n    ```", "```\n    #Loading data from the course GitHub repository\n    ```", "```\n    df=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/TensorFlow-Developer-Certificate/main/Chapter%204/Students-Dropout-Prediction.csv', index_col=0)\n    ```", "```\n    df.head()\n    ```", "```\n    df = df.drop(['Student ID', 'Student Name'], axis=1)\n    ```", "```\n    plt.hist(df['Graduated'])\n    ```", "```\n    plt.show()\n    ```", "```\n    sns.set(style=\"darkgrid\")\n    ```", "```\n    tdc =sns.scatterplot(x ='Library', y ='GPA',\n    ```", "```\n        data = df, hue ='Graduated')\n    ```", "```\n    tdc.legend(loc='center left',\n    ```", "```\n        bbox_to_anchor=(1.0, 0.5), ncol=1)\n    ```", "```\n#To get the number of students with gpa equal to or greater than 3.5 and did not graduate\nlen(df[(df['GPA']>=3.50)&(df['Graduated']==\"Drop out\")])\n```", "```\n    #Replace the classes in the graduate column\n    ```", "```\n    df['Graduated'] = df['Graduated'].replace(\n    ```", "```\n        ['Graduated', 'Drop out'],[1,0])\n    ```", "```\n    df.corr()\n    ```", "```\n    #Converting categorical variables to numeric values\n    ```", "```\n    df = pd.get_dummies(df, drop_first=True)\n    ```", "```\n    df.head()\n    ```", "```\n    tagret_corr= df.corr()\n    ```", "```\n    tagret_corr\n    ```", "```\n    tagret_corr['Graduated'].sort_values(ascending=False)\n    ```", "```\n    # We split the attributes and labels into X and y variables\n    ```", "```\n    X = df.drop(\"Graduated\", axis=1)\n    ```", "```\n    y = df[\"Graduated\"]\n    ```", "```\n    # create a scaler object\n    ```", "```\n    scaler = MinMaxScaler()\n    ```", "```\n    # fit and transform the data\n    ```", "```\n    X_norm = pd.DataFrame(scaler.fit_transform(X),\n    ```", "```\n        columns=X.columns)\n    ```", "```\n    X_norm.head()\n    ```", "```\n# Create training and test sets\n#We set the random state to ensure reproducibility\nX_train, X_test, y_train, y_test =   train_test_split(\n    X_norm, test_size=0.2, random_state=10)\n```", "```\n#compile the model\nmodel1.compile(loss='binary_crossentropy',\n    optimizer='adam', metrics='accuracy')\n```", "```\n#fit the model\nhistory1= model1.fit(X_train, y_train, epochs=40,\n    validation_split=0.2)\n```", "```\nmodel1.summary()\n```", "```\nModel: \"sequential\"\n___________________________________________________________\n Layer (type)             Output Shape              Param #\n===========================================================\n dense (Dense)            (None, 16)                256\n dense_1 (Dense)          (None, 1)                 17\n===========================================================\nTotal params: 273\nTrainable params: 273\nNon-trainable params: 0\n___________________________________________________________\n```", "```\n# Evaluate the Classication model\neval_model=model1.evaluate(X_test, y_test)\neval_model\n```", "```\n157/157 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9944\n[0.05915425345301628, 0.9944000244140625]\n```", "```\ny_pred=model1.predict(X_test).flatten()\ny_pred = np.round(y_pred).astype('int')\ndf_predictions = pd.DataFrame(\n    {'Ground_Truth': y_test, 'Model_prediction': y_pred},\n    columns=[ 'Ground_Truth', 'Model_prediction'])\nlen(df_predictions[(df_predictions[\n    'Ground_Truth']!=df_predictions['Model_prediction'])])\n```", "```\n#Generating the confusion matrix\neval = confusion_matrix(y_test, y_pred)\nprint(eval)\n```", "```\nclass_names = [ 'Drop Out', 'Graduated']\nprint(classification_report(y_test, y_pred,\n    target_names=class_names))\n```", "```\n#saving our model\nmodel1.save('classification_model.h5')\n```"]