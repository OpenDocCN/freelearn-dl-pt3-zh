<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer085">&#13;
			<p id="_idParaDest-57" class="chapter-number"><a id="_idTextAnchor101"/>Chapter 4: </p>&#13;
			<h1 id="_idParaDest-58"><a id="_idTextAnchor102"/>Reusable Models and Scalable Data Pipelines</h1>&#13;
			<p><a id="_idTextAnchor103"/>In this chapter, you will learn different ways of using scalable data ingestion pipelines with pre-made model elements in TensorFlow Enterprise's high-level API's. These options provide the flexibility to suit different requirements or styles for building, training, and deploying models. Armed with this knowledge, you will be able to make informed choices and understand trade-offs among different model development approaches. The three major approaches are TensorFlow Hub, the TensorFlow Estimators API, and the TensorFlow Keras API. </p>&#13;
			<p>TensorFlow Hub is a library of open source machine learning models. TensorFlow Estimators and <strong class="source-inline">tf.keras</strong> APIs are wrappers that can be regarded as high-level elements that can be configured and reused as building blocks in a model. In terms of the amount of coding required, TensorFlow Hub models require the least amount of extra coding, while Estimator and Keras APIs are building blocks at a lower level, and therefore more coding is involved when using either Estimator or Keras APIs. But in any case, all three approaches really made TensorFlow much easier to learn and use. We are going to spend the next few sections of this chapter learning how these approaches work with scalable data ingestion pipelines from cloud storage.</p>&#13;
			<p>With the help of an example, we will learn to use <em class="italic">TensorFlow datasets</em> and <em class="italic">TensorFlow I/O</em> as a means to ingest large amounts of data without reading it into the JupyterLab runtime memory. We will cover the following topics in this chapter:</p>&#13;
			<ul>&#13;
				<li>Using TensorFlow Hub</li>&#13;
				<li>Applying models from TensorFlow Hub</li>&#13;
				<li>Leveraging TensorFlow Keras API</li>&#13;
				<li>Working with TensorFlow Estimators</li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-59"><a id="_idTextAnchor104"/>Using TensorFlow Hub</h1>&#13;
			<p>Of these three approaches (<strong class="bold">TensorFlow Hub, the Estimators API, and the Keras API</strong>), TensorFlow Hub stands out from the other two. It is a library for open source machine learning <a id="_idIndexMarker159"/>models. The main purpose of TensorFlow Hub is to enable model reusability through transfer learning. Transfer learning is a very practical and convenient technique in deep learning modeling development. The hypothesis is that as a well-designed model (peer reviewed and made famous by publications) learned patterns in features during the training process, the model learned to generalize these patterns, and such generalization can be applied to new data. Therefore, we do not need to retrain the model again when we have new training data. </p>&#13;
			<p>Let's take human vision as an example. The content of what we see can be decomposed from simple to sophisticated patterns in the order of lines, edges, shapes, layers, and finally a pattern. As it turns out, this is how a computer vision model recognizes human faces. If we imagine a multilayer perceptron model, in the beginning, the layers learn patterns in lines, then shapes, and as we go into deep layers, we see that what's learned is the facial patterns.  <a id="_idTextAnchor105"/></p>&#13;
			<p>Since the hierarchy of the same pattern can be used to classify other images, we can reuse the architecture of the model (from a repository such as TensorFlow Hub) and append a final classification layer for our own purposes. We will utilize this approach of transfer learning in this chapter.<a id="_idTextAnchor106"/></p>&#13;
			<h1 id="_idParaDest-60"><a id="_idTextAnchor107"/>Applying models from TensorFlow Hub</h1>&#13;
			<p>TensorFlow Hub <a id="_idIndexMarker160"/>contains many reusable models. For example, in image classification tasks, there are pretrained models such as Inception V3, ResNet of different versions, as well as feature vectors available. In this chapter, we will take a look at how to load and use a ResNet feature vector model for image classification of our own images. The images are five types of flowers: daisy, dandelion, roses, sunflowers, and tulips. We will use the <strong class="source-inline">tf.keras</strong> API to get these images for our use: </p>&#13;
			<ol>&#13;
				<li>You may use Google Cloud AI Platform's JupyterLab environment for this work. Once you are in the AI Platform's JupyterLab environment, you may start by importing the necessary modules and download the images:<p class="source-code">import tensorflow as tf</p><p class="source-code">import tensorflow_hub as hub</p><p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">import numpy as np</p><p class="source-code">data_dir = tf.keras.utils.get_file(</p><p class="source-code">    'flower_photos',</p><p class="source-code">    'https://storage.googleapis.com/download.tensorflow.</p><p class="source-code">     org/example_images/flower_photos.tgz',</p><p class="source-code">    untar=True)</p><p class="source-code">print(data_dir)</p><p>You may find the flower images in the runtime instance of your JupyterLab at <strong class="source-inline">/home/jupyter/.keras/datasets/flower_photos</strong>.</p></li>&#13;
				<li>In a new cell, we may <a id="_idIndexMarker161"/>run the following command to take a look at the directory structure for our data:<p class="source-code">!ls -lrt {data_dir}</p><p>The preceding command will return the following structure:</p><p class="source-code">-rw-r----- 1 jupyter jupyter 418049 Feb  9  2016 LICENSE.txt</p><p class="source-code">drwx------ 2 jupyter jupyter  45056 Feb 10  2016 tulips</p><p class="source-code">drwx------ 2 jupyter jupyter  36864 Feb 10  2016 sunflowers</p><p class="source-code">drwx------ 2 jupyter jupyter  36864 Feb 10  2016 roses</p><p class="source-code">drwx------ 2 jupyter jupyter  45056 Feb 10  2016 dandelion</p><p class="source-code">drwx------ 2 jupyter jupyter  36864 Feb 10  2016 daisy</p><p>Inside each folder, you will find colored images in <strong class="source-inline">.jpg</strong> format with different widths and heights. Before using any pre-built model, it is important to find out about the required data shape at the entry point of the model. </p></li>&#13;
				<li>We are going to use the ResNet V2 feature vector that was pretrained with imagenet as our base model. The URL to this model is <a href="https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4">https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4</a>.<p>The documentation there indicates the expected height and width of the image at the entry point to be <strong class="source-inline">224</strong>. Let's go ahead and specify these parameters as well as the batch size for training:</p><p class="source-code">pixels =224</p><p class="source-code">BATCH_SIZE = 32 </p><p class="source-code">IMAGE_SIZE = (pixels, pixels)  </p></li>&#13;
			</ol>&#13;
			<p>Now <a id="_idIndexMarker162"/>that we have understood the dimension of the image expected as model input, we are ready to deal with the next step, which is about how to ingest our training image<a id="_idTextAnchor108"/>s. </p>&#13;
			<h2 id="_idParaDest-61"><a id="_idTextAnchor109"/>Creating a generator to feed image data at scale</h2>&#13;
			<p>A convenient method <a id="_idIndexMarker163"/>to ingest data into the model is by a generator. A Pythonic generator is an iterator that goes through the data directory and passes batches of data to the model. When a generator is used to cycle through our training data, we do not have to load the entire image collection at one time and worry about memory constraints in our compute node. Rather, we send a batch of images at one time. Therefore, the use of the Python generator is more efficient for the compute node's memory than passing all the data as a huge NumPy array. </p>&#13;
			<p>TensorFlow provides APIs and workflows to create such generators specific for the TensorFlow model's consumption. At a high level, it follows this process:</p>&#13;
			<ol>&#13;
				<li value="1">It creates an object with the <strong class="source-inline">ImageDataGenerator</strong> function.</li>&#13;
				<li>It uses this object to invoke the <strong class="source-inline">flow_from_directory</strong> function to create a TensorFlow generator.</li>&#13;
			</ol>&#13;
			<p>As a result, this generator knows the directory where the training data is stored. </p>&#13;
			<p>When working with images, there are a few parameters about the data that we need to specify for the generator. The input images' color values are preferred to be between <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>. Therefore, we have to normalize our image by dividing it by a rescale factor with a value of <strong class="source-inline">255</strong>, which is the maximum pixel value in an RGB image of <strong class="source-inline">.jpg</strong> format. We may also hold on to 20% of the data for validation. This is known as the validation split factor. We also need to specify the standard image size that conforms to ResNet, an interpolation method that converts images of any size into this size, and the amount of data in a batch (batch size). The necessary steps are as follows:</p>&#13;
			<ol>&#13;
				<li value="1">Organize these factors as tuples. These factors are specified as input keywords for either <strong class="source-inline">ImageDataGenerator</strong> or <strong class="source-inline">flow_from_directory</strong>. We may pass these parameters and their values as tuples to these functions. The tuple will <a id="_idIndexMarker164"/>be unpacked when the function is executed. These parameters are held in these dictionaries:<p class="source-code">datagen_kwargs = dict(rescale=1./255, </p><p class="source-code">                      validation_split=.20)</p><p class="source-code">dataflow_kwargs = dict(target_size=IMAGE_SIZE, </p><p class="source-code">                       batch_size=BATCH_SIZE,</p><p class="source-code">                       interpolation='bilinear')</p><p>As seen in the preceding lines of code, <strong class="source-inline">datagen_kwargs</strong> goes to <strong class="source-inline">ImageDataGenerator</strong>, while <strong class="source-inline">dataflow_kwargs</strong> goes to <strong class="source-inline">flow_from_directory</strong>.</p></li>&#13;
				<li>Pass the tuples to <strong class="source-inline">ImageGenerator</strong>. These tuples encapsulate all these factors. Now we will pass these tuples into the generator, as shown in the following code:<p class="source-code">valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(</p><p class="source-code">    **datagen_kwargs)</p><p class="source-code">valid_generator = valid_datagen.flow_from_directory(</p><p class="source-code">data_dir, subset='validation', shuffle=False, **dataflow_kwargs)</p><p>And you will see the output with number of images and classes in the cross validation data:</p><p class="source-code">Found 731 images belonging to 5 classes.</p></li>&#13;
				<li>For training data, if you wish, you may consider the option for data augmentation. If so, then we may set these parameters in <strong class="source-inline">ImageDataGenerator</strong>:<p class="source-code">rotation_range</p><p class="source-code">horizontal_flip</p><p class="source-code">Width_shift_range</p><p class="source-code">height_shift_range</p><p class="source-code">Shear_range</p><p class="source-code">Zoom_range</p><p>These <a id="_idIndexMarker165"/>parameters help transform original images into different orientations. This is a typical technique to add more training data to improve accuracy. </p></li>&#13;
				<li>For now, let's not bother with that, so we set <strong class="source-inline">do_data_augmentation = False</strong>, as shown in the following code. You may set it to <strong class="source-inline">True</strong> if you wish. Suggested augmentation parameters are provided:<p class="source-code">do_data_augmentation = False </p><p class="source-code">if do_data_augmentation:</p><p class="source-code">  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(</p><p class="source-code">      rotation_range=40,</p><p class="source-code">      horizontal_flip=True,</p><p class="source-code">      width_shift_range=0.2, height_shift_range=0.2,</p><p class="source-code">      shear_range=0.2, zoom_range=0.2,</p><p class="source-code">      **datagen_kwargs)</p><p class="source-code">else:</p><p class="source-code">  train_datagen = valid_datagen</p><p class="source-code">train_generator = </p><p class="source-code">	train_datagen.flow_from_directory(</p><p class="source-code">		data_dir, subset='training', shuffle=True, 			**dataflow_kwargs)</p><p>Upon executing the preceding code, you will receive the following output:</p><p class="source-code">Found 731 images belonging to 5 classes.</p><p class="source-code">Found 2939 images belonging to 5 classes.</p><p>Our generators for validation data and training data correctly identified the directory and were able to identify the number of classes.</p></li>&#13;
				<li>As with <a id="_idIndexMarker166"/>all classification tasks, labels are converted to integer indices. The generator maps labels with <strong class="source-inline">train_generator.class_indices</strong>:<p class="source-code">labels_idx = (train_generator.class_indices)</p></li>&#13;
				<li>We can easily map indices back to labels by creating a reverse lookup, also in the form of a dictionary. This can be done by reversing the key-value pairs as we iterated <strong class="source-inline">through labels_idx</strong>, where the key is the index and the values are flower types:<p class="source-code">idx_labels = dict((v,k) for k,v in labels_idx.items())</p><p class="source-code">print(idx_labels)</p><p class="source-code">{0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', 4: 'tulips'}</p></li>&#13;
			</ol>&#13;
			<p>In this section, we learned how to implement <strong class="source-inline">ImageGenerator</strong> for both training and validation data. We leveraged optional input parameters to rescale and normalize our images. We also learned to retrieve the ground truth label mapping so that we may decode the model prediction. </p>&#13;
			<p>Next, we <a id="_idIndexMarker167"/>will learn to implement transfer learning by reusing ResNet feature vectors for our own image classificati<a id="_idTextAnchor110"/>on task.</p>&#13;
			<h2 id="_idParaDest-62"><a id="_idTextAnchor111"/>Reusing pretrained ResNet feature vectors</h2>&#13;
			<p>Now we are ready to <a id="_idIndexMarker168"/>construct the model. We will use the <strong class="source-inline">tf.keras.sequential</strong> API. It consists of three layers—input, ResNet, and a dense layer—as the classification output. We also have the choice between fine-tuning and retraining the ResNet (this requires longer training time). The code for defining the model architecture is as follows:</p>&#13;
			<ol>&#13;
				<li value="1">We'll begin by defining the parameters, as shown in the following lines of code:<p class="source-code">FINE_TUNING_CHOICE = True</p><p class="source-code">NUM_CLASSES = len(idx_labels)</p></li>&#13;
				<li>Next, we will construct the model with the help of the following code:<p class="source-code">mdl = tf.keras.Sequential([</p><p class="source-code">    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + </p><p class="source-code">                               (3,)),</p><p class="source-code">    hub.KerasLayer('https://tfhub.dev/google/imagenet/    </p><p class="source-code">    resnet_v2_50/feature_vector/4', </p><p class="source-code">    trainable = FINE_TUNING_CHOICE),</p><p class="source-code">    tf.keras.layers.Dense(NUM_CLASSES, </p><p class="source-code">    activation='softmax', name = 'custom_class')</p><p class="source-code">])</p></li>&#13;
				<li>Now, let's build the model with the following line of code:<p class="source-code">mdl.build([None, 224, 224, 3])</p><p>ResNet requires RGB layers to be separated as a third dimension. Therefore, we need to add an input layer that takes on <strong class="source-inline">input_shape</strong> of <strong class="source-inline">[224, 224, 3]</strong>. Also, since we have five types of flowers, this is a multiclass classification. We need a dense layer with softmax activation for outputting probability for each label.</p></li>&#13;
				<li>We may confirm the model architecture with the following line of code:<p class="source-code">mdl.summary()</p><p>Upon executing the preceding line of code, you will see the sequence of the three layers and their <a id="_idIndexMarker169"/>expected output shape:</p><p class="source-code">Model: 'sequential_1'</p><p class="source-code">_________________________________________________________________</p><p class="source-code">Layer (type)                 Output Shape              Param #   </p><p class="source-code">=================================================================</p><p class="source-code">keras_layer_1 (KerasLayer)   (None, 2048)              23564800  </p><p class="source-code">_________________________________________________________________</p><p class="source-code">custom_class (Dense)         (None, 5)                 10245     </p><p class="source-code">=================================================================</p><p class="source-code">Total params: 23,575,045</p><p class="source-code">Trainable params: 23,529,605</p><p class="source-code">Non-trainable params: 45,440</p><p class="source-code">_________________________________________________________________</p><p>This shows the model is very simple in its structure. It consists of the ResNet feature vector layer that we downloaded from TensorFlow Hub, followed by a classification head with five nodes (there are five flower classes in our image col<a id="_idTextAnchor112"/>lection). </p></li>&#13;
			</ol>&#13;
			<h2 id="_idParaDest-63"><a id="_idTextAnchor113"/>Compiling the model</h2>&#13;
			<p>Now that we have <a id="_idIndexMarker170"/>wrapped the ResNet feature vector with proper input and output layers, we are ready to set up the training workflow. To begin, we need to compile the model, where we specify the <a id="_idIndexMarker171"/>optimizer (in this case, we select <strong class="bold">stochastic gradient descent</strong> (<strong class="bold">SGD</strong>) with hyperparameters such as learning rate and momentum). It also requires a <strong class="source-inline">loss</strong> function. The optimizer leverages the gradient decent algorithm to continuously seek weights and biases to minimize the <strong class="source-inline">loss</strong> function. Since this is a multiclass classification problem, it needs to be categorical cross-entropy. </p>&#13;
			<p>For a deeper discussion, see <em class="italic">TensorFlow 2.0 Quick Start Guide</em>, by <em class="italic">Tony Holroyd</em>, published by <em class="italic">Packt Publishing</em>. You can refer to <a href="B16070_04_Final_JM_ePub.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a><em class="italic"> Supervised Machine Learning Using TensorFlow 2</em>, and the section entitled <em class="italic">Logistic regression</em>, concerning loss functions and optimizers. This is how we define an optimizer:</p>&#13;
			<p class="source-code">my_optimizer = tf.keras.optimizers.SGD(lr=0.005, momentum=0.9)</p>&#13;
			<p>And since we want to output probability for each class, we set <strong class="source-inline">from_logits = True</strong>,  We also would like the model not to become overconfident, so we set <strong class="source-inline">label_smoothing = 0.1</strong> as a regularization to penalize extremely high probability. We may define a <strong class="source-inline">loss</strong> function as follows:</p>&#13;
			<p class="source-code">my_loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)</p>&#13;
			<p>We need to configure the model for training. This is accomplished by defining the <strong class="source-inline">loss</strong> function and optimizer as part of the model's training process, as the training process needs to know what the <strong class="source-inline">loss</strong> function is to optimize for, and what optimizer to use. To compile the model with the optimizer and <strong class="source-inline">loss</strong> function specified, execute the following code: </p>&#13;
			<p class="source-code">mdl.compile(</p>&#13;
			<p class="source-code">  optimizer=my_optimizer,</p>&#13;
			<p class="source-code">  loss=my_loss_function,</p>&#13;
			<p class="source-code">  metrics=['accuracy'])</p>&#13;
			<p>The outcome is a model architecture that is ready to be used fo<a id="_idTextAnchor114"/>r training. </p>&#13;
			<h2 id="_idParaDest-64"><a id="_idTextAnchor115"/>Training the model</h2>&#13;
			<p>For model training, we <a id="_idIndexMarker172"/>will use the <strong class="source-inline">tf.keras.fit</strong> function. We are only going to train for five epochs:</p>&#13;
			<p class="source-code">steps_per_epoch = train_generator.samples // train_generator.batch_size</p>&#13;
			<p class="source-code">validation_steps = valid_generator.samples // valid_generator.batch_size</p>&#13;
			<p class="source-code">hist = mdl.fit(</p>&#13;
			<p class="source-code">    train_generator,</p>&#13;
			<p class="source-code">    epochs=5, steps_per_epoch=steps_per_epoch,</p>&#13;
			<p class="source-code">    validation_data=valid_generator,</p>&#13;
			<p class="source-code">    validation_steps=validation_steps).history</p>&#13;
			<p>And the training result should be similar to this:</p>&#13;
			<p class="source-code">Epoch 1/5</p>&#13;
			<p class="source-code">91/91 [==============================] - 404s 4s/step - loss: 1.4899 - accuracy: 0.7348 - val_loss: 1.3749 - val_accuracy: 0.8565</p>&#13;
			<p class="source-code">Epoch 2/5</p>&#13;
			<p class="source-code">91/91 [==============================] - 404s 4s/step - loss: 1.3083 - accuracy: 0.9309 - val_loss: 1.3359 - val_accuracy: 0.8963</p>&#13;
			<p class="source-code">Epoch 3/5</p>&#13;
			<p class="source-code">91/91 [==============================] - 405s 4s/step - loss: 1.2723 - accuracy: 0.9704 - val_loss: 1.3282 - val_accuracy: 0.9077</p>&#13;
			<p class="source-code">Epoch 4/5</p>&#13;
			<p class="source-code">91/91 [==============================] - 1259s 14s/step - loss: 1.2554 - accuracy: 0.9869 - val_loss: 1.3302 - val_accuracy: 0.9020</p>&#13;
			<p class="source-code">Epoch 5/5</p>&#13;
			<p class="source-code">91/91 [==============================] - 403s 4s/step - loss: 1.2487 - accuracy: 0.9935 - val_loss: 1.3307 - val_accuracy: 0.8963</p>&#13;
			<p>At each epoch, the <strong class="source-inline">loss</strong> function value and accuracy on training data is provided. Since we have cross-validation data provided, the model is also tested with a validation dataset at the end of each training epoch. The <strong class="source-inline">loss</strong> function and accuracy measurement are provided at each epoch by the Fit API. This is the standard output for each training run.  </p>&#13;
			<p>It is also worth mentioning that when the preceding code is executed in AI Notebook using the Nvidia Tesla T4 Graphics Processing Unit (GPU) and a basic driver node of 4 CPUs at 15 GB RAM, the total training time is just a little over 2 minutes, whereas if this training process was executed in the same driver node without a GPU, it could take more than 30 minutes to complete the training process. </p>&#13;
			<p>GPUs are well <a id="_idIndexMarker173"/>suited for deep learning model training because it can process multiple computations in parallel. A GPU achieves parallel processing through a large number of cores. This translates to large memory bandwidth and faster gradient computation of all trainable parameters in the deep learning architecture than otherwise would be the c<a id="_idTextAnchor116"/>ase in a CPU. </p>&#13;
			<h2 id="_idParaDest-65"><a id="_idTextAnchor117"/>Scoring with test images</h2>&#13;
			<p>Now we <a id="_idIndexMarker174"/>may test the model using test (holdout) images. In this example, I uploaded five flower images, and we <a id="_idIndexMarker175"/>need to convert them all to the shape of <strong class="source-inline">[224, 224]</strong> and normalize pixel values to <strong class="source-inline">[0, 1]</strong>. As common practice, test images are stored separately from training and cross-validation images. Therefore, it is typical to have a different file path to test images:</p>&#13;
			<ol>&#13;
				<li value="1">We are going to download some test images for these types of flowers. The images are partitioned into training, validation, and test images at the following link: <a href="https://dataverse.harvard.edu/api/access/datafile/4159750">https://dataverse.harvard.edu/api/access/datafile/4159750</a></li>&#13;
				<li>So, in the next cell, you may use <strong class="source-inline">wget</strong> to download it to your notebook:<p class="source-code"><strong class="bold">!wget https://dataverse.harvard.edu/api/access/datafile/4159750</strong></p></li>&#13;
				<li>Then, unzip it:<p class="source-code"><strong class="bold">!unzip 4159750</strong></p><p>You will have the<strong class="source-inline">/flower_photos/small_test</strong> directory available in the left panel of your notebook instance. </p></li>&#13;
				<li>Create a data generator instance for test data. Since our <strong class="source-inline">train_datagen</strong> already knows how to do that, we may reuse this object. Make sure you specify the <strong class="source-inline">working_dir</strong> directory as a file path to where our test images reside:<p class="source-code">working_dir = ‘flower_photos/small_test’</p><p class="source-code">test_generator =     </p><p class="source-code">	train_datagen.flow_from_directory</p><p class="source-code">		(directory=working_dir,</p><p class="source-code">            batch_size = 5,</p><p class="source-code">            target_size = [224, 224],</p><p class="source-code">            shuffle=False,</p><p class="source-code">            classes = list(labels_idx))</p></li>&#13;
				<li>Let's take a <a id="_idIndexMarker176"/>note of the label index: <p class="source-code">print(test_generator.class_indices)</p><p>The output indicates the relative position of each label in the array of probability: </p><p class="source-code">{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}</p></li>&#13;
				<li>Let's also define a helper function that plots the images:<p class="source-code">def plotImages(images_arr):</p><p class="source-code">    fig, axes = plt.subplots(1, 5, figsize=(10,10))</p><p class="source-code">    axes = axes.flatten()</p><p class="source-code">    for img, ax in zip( images_arr, axes):</p><p class="source-code">        ax.imshow(img)</p><p class="source-code">        ax.axis('off')</p><p class="source-code">    plt.tight_layout()</p><p class="source-code">    plt.show()</p></li>&#13;
				<li>Now, let's take a look at the test images and their corresponding labels (ground truth):<p class="source-code">sample_test_images, ground_truth_labels = next(test_generator)</p><p class="source-code">print(ground_truth_labels)</p><p>The output for the test images is shown as follows. In the first three rows, one-hot <a id="_idIndexMarker177"/>encoding is <strong class="source-inline">1</strong> at the first position. This corresponds to <strong class="source-inline">daisy</strong> according to <strong class="source-inline">test_generator.class_indices</strong>, whereas for the last two rows, <strong class="source-inline">1</strong> is at the last position, indicating the last two images are of <strong class="source-inline">tulips</strong>:</p><p class="source-code">[[1. 0. 0. 0. 0.]</p><p class="source-code"> [1. 0. 0. 0. 0.]</p><p class="source-code"> [1. 0. 0. 0. 0.]</p><p class="source-code"> [0. 0. 0. 0. 1.]</p><p class="source-code"> [0. 0. 0. 0. 1.]]</p></li>&#13;
				<li>And we may plot these images:<p class="source-code">plotImages(sample_te<a id="_idTextAnchor118"/>st_images[:5])</p><div id="_idContainer081" class="IMG---Figure"><img src="Images/Figure_4.1.jpg" alt="Figure 4.1 – Test image examples; the first three are daisies, and the last two are tulips&#13;&#10;"/></div><p class="figure-caption">Figure 4.1 – Test image examples; the first three are daisies, and the last two are tulips</p></li>&#13;
				<li>For the model to make predictions on these images, execute the following code:<p class="source-code">prediction = mdl.predict(sample_test_images[:5])</p><p>The output of the <a id="_idIndexMarker178"/>prediction is as follows:</p><p class="source-code">array([[9.9985600e-01, 3.2907694e-05, 2.3326173e-05,            </p><p class="source-code">        6.8752386e-05, 1.8940274e-05],</p><p class="source-code">       [9.9998152e-01, 7.6931758e-07, 9.4449973e-07, </p><p class="source-code">        1.6520202e-05, 2.8859478e-07],</p><p class="source-code">       [9.9977893e-01, 2.0959340e-05, 6.2238797e-07,         </p><p class="source-code">        1.8358800e-04, 1.6017557e-05],</p><p class="source-code">       [6.7357789e-04, 5.8116650e-05, 3.0710772e-04, </p><p class="source-code">        6.2863214e-04, 9.9833256e-01],</p><p class="source-code">       [1.9417066e-04, 1.3316995e-04, 6.2624150e-04, </p><p class="source-code">        1.4169540e-04, 9.9890471e-01]], dtype=float32)</p></li>&#13;
			</ol>&#13;
			<p>This output is a NumPy array of probabilities for each class in each image. Each row corresponds to an image, and consists of five probabilities for each label. The first three rows have the highest probability in the first position, and the last two rows have the highest probability in the last position. This means the model predicted that the first three images would be daisies, and the last two images tulips, according to the mapping provided by <strong class="source-inline">test_generator.class_indices</strong>.</p>&#13;
			<p>It would also be helpful if we could output these results in a more readable format such as a CSV file, with filenames of the test images and their respective predictions.</p>&#13;
			<ol>&#13;
				<li value="1">Let's map the probability magnitude with respect to the position and define a label reference:<p class="source-code">labelings = tf.math.argmax(prediction, axis = -1)</p><p class="source-code">label_reference = np.asarray(list(labels_idx))</p></li>&#13;
				<li>Write a helper function to map position with respect to the actual label:<p class="source-code">def find_label(idx):</p><p class="source-code">    return label_reference[idx]</p></li>&#13;
				<li>Now we can map the position of each observation's highest probability:<p class="source-code">predicted_idx = tf.math.argmax(prediction, axis = -1)</p></li>&#13;
				<li>And we <a id="_idIndexMarker179"/>can take a look at <strong class="source-inline">predicted_idx</strong>: <p class="source-code">&lt;tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 4, 4])&gt;</p><p>This means that in the first three images, the maximum probability occurs at position <strong class="source-inline">0</strong>, which corresponds to <strong class="source-inline">daisy</strong> according to <strong class="source-inline">test_generator.class_indices</strong>. By the same token, the last two images have the maximum probability occurring at position <strong class="source-inline">4</strong>, which corresponds to <strong class="source-inline">tulips</strong>. </p></li>&#13;
				<li>Then, apply the helper function to each row of the prediction output, and insert test image filenames (<strong class="source-inline">test_generator.filenames</strong>) alongside the prediction in a nicely formatted pandas DataFrame:<p class="source-code">import pandas as pd</p><p class="source-code">predicted_label = list(map(find_label, predicted_idx))</p><p class="source-code">file_name = test_generator.filenames</p><p class="source-code">results=pd.DataFrame({'File':file_name,</p><p class="source-code">                      'Prediction':predicted_label})</p><p class="source-code">results</p><p>The results should look similar to the following diagram. Now you may save the pandas DataFrame to any format of your choice, such as a CSV f<a id="_idTextAnchor119"/>ile or a pickle:</p></li>&#13;
			</ol>&#13;
			<div>&#13;
				<div id="_idContainer082" class="IMG---Figure">&#13;
					<img src="Images/Figure_4.2.jpg" alt="Figure 4.2 – Prediction output in a DataFrame format&#13;&#10;"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 4.2 – Prediction output in a DataFrame format</p>&#13;
			<p>This completes the <a id="_idIndexMarker180"/>demonstration of using a pretrained model from TensorFlow Hub, applying it to our own data, retraining the model, and making the prediction. We also saw how to leverage generators to ingest training data in batches to the model. </p>&#13;
			<p>TensorFlow Hub sits at the highest level of model reusability. There, you will find many open source models already built for consumption via a <a id="_idIndexMarker181"/>technique known as transfer learning. In this chapter, we built a regression model using the <strong class="source-inline">tf.keras</strong> API. Building a model this way (custom) is actually not a straightforward task. Often, you will spend a lot of time experimenting with different model parameters and architectures. If your need falls into classification or regression problems that are compatible with pre-built open source models, then TensorFlow Hub is the one-stop shop for finding the classification or regression model for your data. However, for these pre-built models, you still need to investigate the data structure required for the input layer and provide a final output layer for your purpose. However, reusing these pre-built models in TensorFlow Hub will save time in building and debugging your own model architecture. </p>&#13;
			<p>In the next section, we <a id="_idIndexMarker182"/>are going to see the TensorFlow Keras API, which is the newest high-level API that provides m<a id="_idTextAnchor120"/><a id="_idTextAnchor121"/>any reusable models. </p>&#13;
			<h1 id="_idParaDest-66"><a id="_idTextAnchor122"/>Leveraging the TensorFlow Keras API</h1>&#13;
			<p>Keras is a deep <a id="_idIndexMarker183"/>learning API that wraps around machine learning libraries such as TensorFlow, Theano, and Microsoft Cognitive Toolkit (also known <a id="_idIndexMarker184"/>as CNTK). Its popularity as a standalone API stems from the succinct style of the model construction process. As of 2018, TensorFlow added Keras as a high-level API moving forward, and it is now known as <strong class="source-inline">tf.keras</strong>. Starting with the TensorFlow 2.0 distribution released in 2019, <strong class="source-inline">tf.keras</strong> has become the official high-level API. </p>&#13;
			<p><strong class="source-inline">tf.keras</strong> excels <a id="_idIndexMarker185"/>at modeling sophisticated deep learning architecture that contains <strong class="bold">long short-term memory</strong> (<strong class="bold">LSTM</strong>), <strong class="bold">gated recurring units</strong> (<strong class="bold">GRUs</strong>), and <strong class="bold">convolutional neural network</strong> (<strong class="bold">CNN</strong>) layers. These are <a id="_idIndexMarker186"/>considered to be workhorses in current <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) and computer vision models. It <a id="_idIndexMarker187"/>also provides simple and straightforward architecture <a id="_idIndexMarker188"/>for simpler deep learning models, such as multilayer perceptrons. In the following example, we are going to use the <strong class="source-inline">tf.keras</strong> dense layer to build a regression model with t<a id="_idTextAnchor123"/>abular data from BigQuery. </p>&#13;
			<h2 id="_idParaDest-67"><a id="_idTextAnchor124"/>Data acquisition</h2>&#13;
			<p>We are going to use a <a id="_idIndexMarker189"/>publicly available dataset from Google Cloud as the working data for this example:</p>&#13;
			<ol>&#13;
				<li value="1">This is our table of interest:<p class="source-code">DATASET_GCP_PROJECT_ID = 'bigquery-public-data'</p><p class="source-code">DATASET_ID = 'covid19_geotab_mobility_impact'</p><p class="source-code">TABLE_ID = 'us_border_volumes'</p><p>You<a id="_idTextAnchor125"/> may find it in BigQuery:</p><div id="_idContainer083" class="IMG---Figure"><img src="Images/Figure_4.3.jpg" alt="Figure 4.3 – BigQuery portal and table selection&#13;&#10;"/></div><p class="figure-caption">Figure 4.3 – BigQuery portal and table selection</p></li>&#13;
				<li>Let's take a <a id="_idIndexMarker190"/>look at the data by running the following query:<p class="source-code">SELECT * FROM `bigquery-public-data.covid19_geotab_mobility_impact.us_border_volumes` ORDER BY RAND() LIMIT 1000</p><p>The preceding query helps us to retrieve 1,000 random rows of the table: <strong class="source-inline">data.covid19_geotab_mobility_impact.us_border_volumes</strong>. <a id="_idTextAnchor126"/></p></li>&#13;
			</ol>&#13;
			<p>And this is the output:</p>&#13;
			<div>&#13;
				<div id="_idContainer084" class="IMG---Figure">&#13;
					<img src="Images/Figure_4.4.jpg" alt="Figure 4.4 – Table columns in us_border_volumes&#13;&#10;"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="figure-caption">Figure 4.4 – Table c<a id="_idTextAnchor127"/>olumns in us_border_volumes</p>&#13;
			<h2 id="_idParaDest-68"><a id="_idTextAnchor128"/>Solving a data science problem with the us_border_volumes table</h2>&#13;
			<p>The output consists of rows that are randomly selected from the table being queried. Your output will consist of different values.</p>&#13;
			<p>In the <strong class="source-inline">us_border_volumes</strong> table, each record represents a truck's entry or exit at a USA border point. The <a id="_idIndexMarker191"/>attributes in each record are <strong class="source-inline">trip_direction</strong>, <strong class="source-inline">day_type</strong>, <strong class="source-inline">day_of_week</strong>, <strong class="source-inline">date</strong>, <strong class="source-inline">avg_crossing_duration</strong>, <strong class="source-inline">percent_of_normal_volume</strong>, <strong class="source-inline">avg_crossing_duration_truck</strong>, and <strong class="source-inline">percent_of_nortal_volume_truck</strong>. We would like to build a model that predicts how long it would take for a truck to cross a border, given these features.</p>&#13;
			<h2 id="_idParaDest-69"><a id="_idTextAnchor129"/>Selecting features and a target for model training</h2>&#13;
			<p>Here is an <a id="_idIndexMarker192"/>example problem that we will use to demonstrate how to leverage a TensorFlow I/O pipeline to provide training data to a model. </p>&#13;
			<p>Let's set this problem up as a regression problem with this data. We are going to build a regression model to predict the average time it takes for a truck to cross the border (<strong class="source-inline">avg_crossing_duration_truck</strong>). Other columns (ex<a id="_idTextAnchor130"/><a id="_idTextAnchor131"/>cept <strong class="source-inline">date</strong>) are the features. </p>&#13;
			<h2 id="_idParaDest-70"><a id="_idTextAnchor132"/>Streaming training data</h2>&#13;
			<p>For the rest of this <a id="_idIndexMarker193"/>example, we are going to use the Google AI Platform JupyterLab notebook with TensorFlow Enterprise 2.1 distribution. You may reuse the project ID from <a href="B16070_02_Final_JM_ePub.xhtml#_idTextAnchor061"><em class="italic">Chapter 2</em></a>, <em class="italic">Running TensorFlow Enterprise in Google AI Platform</em>.</p>&#13;
			<p>Having identified the data source, we are going to build a streaming workflow to feed training data to the model. This is different from reading the table as a pandas DataFrame in the Python runtime. We want to stream the training data by batches rather than using up all the memory allocated for the Python runtime. Therefore, we are going to use TensorFlow I/O for streaming the training data from BigQuery:</p>&#13;
			<ol>&#13;
				<li value="1">We will start with the following code to import the necessary libraries and set up environmental variables:<p class="source-code">import tensorflow as tf</p><p class="source-code">from tensorflow import feature_column</p><p class="source-code">from tensorflow_io.bigquery import BigQueryClient</p><p class="source-code">import numpy as np</p><p class="source-code">from google.cloud import bigquery</p><p class="source-code">client = BigQueryClient()</p><p class="source-code">PROJECT_ID = 'project1-XXXXX' </p><p class="source-code"># A project ID in your GCP subscription.</p><p class="source-code">DATASET_GCP_PROJECT_ID = 'bigquery-public-data'</p><p class="source-code">DATASET_ID = 'covid19_geotab_mobility_impact'</p><p class="source-code">TABLE_ID = 'us_border_volumes'</p></li>&#13;
				<li>Create a session <a id="_idIndexMarker194"/>to read from BigQuery:<p class="source-code">read_session3 = client.read_session(</p><p class="source-code">   'projects/' + PROJECT_ID,</p><p class="source-code">   DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,</p><p class="source-code">   ['trip_direction',</p><p class="source-code">    'day_type',</p><p class="source-code">    'day_of_week',</p><p class="source-code">    'avg_crossing_duration',</p><p class="source-code">    'percent_of_normal_volume',</p><p class="source-code">    'avg_crossing_duration_truck',</p><p class="source-code">    'percent_of_normal_volume_truck'</p><p class="source-code">   </p><p class="source-code">    ],</p><p class="source-code">   [tf.string,</p><p class="source-code">    tf.string,</p><p class="source-code">    tf.int64,</p><p class="source-code">    tf.double,</p><p class="source-code">    tf.int64,</p><p class="source-code">    tf.double,</p><p class="source-code">    tf.int64</p><p class="source-code">    ],</p><p class="source-code">     requested_streams=10</p><p class="source-code">)</p><p class="source-code">dataset3 = read_session3.parallel_read_rows()</p></li>&#13;
				<li>We have just <a id="_idIndexMarker195"/>selected fields of interest from the table in BigQuery. Now that the table is read as a dataset, we need to designate each column as either features or target. Let's use this helper function:<p class="source-code">def transfrom_row(row_dict):</p><p class="source-code">	# Identify column names for features.</p><p class="source-code">	feature_dict = { column:</p><p class="source-code">        (tf.strings.strip(tensor) if tensor.dtype ==   </p><p class="source-code">            'string' else tensor)</p><p class="source-code">                	for (column,tensor) in row_dict.items()</p><p class="source-code">                	}</p><p class="source-code">	# Remove target column from data</p><p class="source-code">	target = feature_dict.pop</p><p class="source-code">                          ('avg_crossing_duration_truck')</p><p class="source-code">	# Return a tuple of features and target</p><p class="source-code">	return (feature_dict, target)</p></li>&#13;
				<li>Now we apply this function to each row of the training dataset. This is essentially a transformation of <a id="_idIndexMarker196"/>the dataset, because we are applying a function that splits a dataset into a tuple of two dictionaries—features and target:<p class="source-code">transformed_ds = dataset3.map(transfrom_row)</p></li>&#13;
				<li>And now we will shuffle the dataset and batch it:<p class="source-code">BATCH_SIZE = 32</p><p class="source-code">SHUFFLE_BUFFER = 1024</p><p class="source-code">training_dataset3 = transformed_ds.shuffle</p><p class="source-code">                       (SHUFFLE_BUFFER).batch(BATCH_SIZE)</p></li>&#13;
			</ol>&#13;
			<p>In this section, we identified a table from BigQuery, identified the feature and target columns, convert the table to a TensorFlow dataset, shuffled it, and batched it. This is a common technique that is preferred when you are not sure if data size presents a problem in terms of memory usage. </p>&#13;
			<p>For the next section, we are going to look at the <strong class="source-inline">tf.keras</strong> API and how to u<a id="_idTextAnchor133"/>se it to build and train a model.</p>&#13;
			<h2 id="_idParaDest-71"><a id="_idTextAnchor134"/>Input to a model</h2>&#13;
			<p>So far, we have taken <a id="_idIndexMarker197"/>care of specifying features and the target in the training dataset. Now, we need to specify each feature as either categorical or numeric. This requires us to set up TensorFlow's <strong class="source-inline">feature_columns</strong> object. The <strong class="source-inline">feature_columns</strong> object is the input to the model:</p>&#13;
			<ol>&#13;
				<li value="1">For each categorical column, we need to keep track of the possible categories. This is done through a helper function:<p class="source-code">def get_categorical_feature_values(column):</p><p class="source-code">    query = 'SELECT DISTINCT TRIM({}) FROM `{}`.{}.{}'. 	        format(column, DATASET_GCP_PROJECT_ID, </p><p class="source-code">                DATASET_ID, TABLE_ID)</p><p class="source-code">    client = bigquery.Client(project=PROJECT_ID)</p><p class="source-code">    dataset_ref = client.dataset(DATASET_ID)</p><p class="source-code">    job_config = bigquery.QueryJobConfig()</p><p class="source-code">    query_job = client.query(query, </p><p class="source-code">                             job_config=job_config)</p><p class="source-code">    result = query_job.to_dataframe()</p><p class="source-code">    return result.values[:,0]</p></li>&#13;
				<li>Then, we can create the <strong class="source-inline">feature_columns</strong> object (which is really a Python list) with the following code snippet:<p class="source-code">feature_columns = []</p><p class="source-code"># Numeric columns</p><p class="source-code">for header in ['day_of_week',     </p><p class="source-code">             'avg_crossing_duration',</p><p class="source-code">             'percent_of_normal_volume',</p><p class="source-code">             'percent_of_normal_volume_truck']:</p><p class="source-code"> feature_columns.append</p><p class="source-code">                  (feature_column.numeric_column(header))</p><p class="source-code"># Categorical columns</p><p class="source-code">for header in ['trip_direction', 'day_type']:</p><p class="source-code"> categorical_feature = feature_column.categorical_column_with_vocabulary_list(</p><p class="source-code">       header, get_categorical_feature_values(header))</p><p class="source-code"> categorical_feature_one_hot = feature_column.indicator_column(categorical_feature)</p><p class="source-code"> feature_columns.append(categorical_feature_one_hot)</p><p>Notice that the target column is not in the <strong class="source-inline">feature_columns</strong>. </p></li>&#13;
				<li>Now all we have to do is create a layer that creates the input to the model. The first layer is <a id="_idIndexMarker198"/>the feature columns' input to the model, which is a multilayer perceptron as defined by a series of reusable <strong class="source-inline">Dense</strong> layers:<p class="source-code">feature_layer = tf.keras.layers.DenseFeatures(feature_columns)</p><p class="source-code">Dense = tf.keras.layers.Dense</p><p class="source-code">model = tf.keras.Sequential(</p><p class="source-code"> [</p><p class="source-code">   feature_layer,</p><p class="source-code">   Dense(100, activation=tf.nn.relu, </p><p class="source-code">   kernel_initializer='uniform'),</p><p class="source-code">   Dense(75, activation=tf.nn.relu),</p><p class="source-code">   Dense(50, activation=tf.nn.relu),</p><p class="source-code">   Dense(25, activation=tf.nn.relu),</p><p class="source-code">   Dense(1)</p><p class="source-code"> ])  </p></li>&#13;
			</ol>&#13;
			<p>In this section, we created a flow to ingest our dataset into the model's feature layer. During this process, for <a id="_idIndexMarker199"/>categorical columns, we have to one-hot encode it as these columns are not numeric. We then build a model architecture with the <strong class="source-inline">tf.keras</strong> API. </p>&#13;
			<p>Next, we are going to compile this mo<a id="_idTextAnchor135"/><a id="_idTextAnchor136"/>del and launch the training process.</p>&#13;
			<h2 id="_idParaDest-72"><a id="_idTextAnchor137"/>Model training</h2>&#13;
			<p>Before the <a id="_idIndexMarker200"/>model can be used, we need to compile it. Since this is a <a id="_idIndexMarker201"/>regression model, we may specify <strong class="bold">mean-square-error</strong> (<strong class="bold">MSE</strong>) as our <strong class="source-inline">loss</strong> function, and for training metrics, we <a id="_idIndexMarker202"/>will track MSE as well as <strong class="bold">mean-absolute-error</strong> (<strong class="bold">MAE</strong>):</p>&#13;
			<ol>&#13;
				<li value="1">Compile the model with the proper <strong class="source-inline">loss</strong> function and metrics used in the regression task:<p class="source-code">model.compile(</p><p class="source-code">   loss='mse',</p><p class="source-code">   metrics=['mae', 'mse'])</p></li>&#13;
				<li>Train the model:<p class="source-code">model.fit(training_dataset3, epochs=5)</p></li>&#13;
				<li>Once the model is trained, we may create a sample test dataset with two observations. The test data has to be in a dictionary format:<p class="source-code">test_samples = {</p><p class="source-code">   'trip_direction' : np.array(['Mexico to US', </p><p class="source-code">                                'US to Canada']),</p><p class="source-code">   'day_type' : np.array(['Weekdays', 'Weekends']),</p><p class="source-code">   'day_of_week' : np.array([4, 7]),</p><p class="source-code">   'avg_crossing_duration' : np.array([32.8, 10.4]),</p><p class="source-code">   'percent_of_normal_volume' : np.array([102, 89]),</p><p class="source-code">   'percent_of_normal_volume_truck' : np.array([106, 84])</p><p class="source-code">}</p></li>&#13;
				<li>To score this test sample, execute the following code: <p class="source-code">model.predict(test_samples)</p><p>The output of the preceding code is as follows: </p><p class="source-code">array([[29.453201],</p><p class="source-code">       [10.395596]], dtype=float32)</p><p>This indicates the predicted average number of waiting minutes for a truck to cross the border (<strong class="source-inline">avg_crossing_duration_truck</strong>).</p></li>&#13;
			</ol>&#13;
			<p>We just learned how to reuse the <strong class="source-inline">tf.keras</strong> dense layer and the sequential API, and integrate it with a data input pipeline driven by the use of datasets for streaming, and <strong class="source-inline">feature_column</strong> objects for feature encoding.</p>&#13;
			<p><strong class="source-inline">tf.keras</strong> is a <a id="_idIndexMarker203"/>high-level API that provides another set of reusable elements specifically for deep learning problems. If your solution requires deep learning techniques, then <strong class="source-inline">tf.keras</strong> is the recommended starting point.</p>&#13;
			<p>In the next section, we are going to take a look at another <a id="_idIndexMarker204"/>high-level API known as TensorFlow Estimators. Before the <strong class="source-inline">tf.keras</strong> API became a first-class citizen in TensorFlow and in the 1.x TensorFlow distribution, TensorFlow Estimators was the only high-level API available.</p>&#13;
			<p>So, in the next sect<a id="_idTextAnchor138"/>ion, we will take a look at how it works.</p>&#13;
			<h1 id="_idParaDest-73"><a id="_idTextAnchor139"/>Working with TensorFlow Estimators</h1>&#13;
			<p>TensorFlow estimators are also reusable components. The Estimators are higher-level APIs that enable <a id="_idIndexMarker205"/>users to build, train, and deploy machine learning models. It has several pre-made models that can save users from the hassle of creating computational graphs or sessions. This makes it easier for users to try different model architectures quickly with limited code changes. The Estimators are not specifically dedicated to deep learning models in the same way as <strong class="source-inline">tf.keras</strong>. Therefore, you will not find a lot of pre-made deep learning models available. If you need to work with deep learning frameworks, then the <strong class="source-inline">tf.keras</strong> API is the right choice to get started.</p>&#13;
			<p>For this example, we are going to set up the same regression problem and build a regression model. The source of data is the same one we used in streaming training data, which is available through Google Cloud's BigQuery:</p>&#13;
			<p class="source-code">DATASET_GCP_PROJECT_ID = 'bigquery-public-data'</p>&#13;
			<p class="source-code">DATASET_ID = 'covid19_geotab_mobility_impact'</p>&#13;
			<p class="source-code">TABLE_ID = 'us_border_volumes'</p>&#13;
			<p>This is the same BigQuery table (<em class="italic">Figure 4.4</em>) that we used for the <strong class="source-inline">tf.keras</strong> section. See <em class="italic">Figure 4.4</em> for some randomly extracted rows of this table.</p>&#13;
			<p>Just as we did in the previous section using the <strong class="source-inline">tf.keras</strong> API, here we want to build a linear regression model using TensorFlow Estimators to predict the average time it takes for a truck to cross the border (<strong class="source-inline">avg_crossing_duration_truck</strong>). Other columns (except <strong class="source-inline">date</strong>) are the features.</p>&#13;
			<p>The pattern of using the TensorFlow Estimators API to build and train a model is as follows.</p>&#13;
			<p>Create an <strong class="source-inline">estimator</strong> object by invoking an estimator (that is, for a pre-made estimator such as a linear <a id="_idIndexMarker206"/>regressor) and specify the <strong class="source-inline">feature_columns</strong> object, so the model knows what data types to expect in the feature data.</p>&#13;
			<p>Use the <strong class="source-inline">estimator</strong> object to <strong class="source-inline">call .train()</strong> and pass an input function to it. This input function is responsible for parsing training data and the label. Since we are setting up a regression problem, let's use the pre-made linear regression estimator as an example. This is the common pattern for training:</p>&#13;
			<p class="source-code">linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir=MODEL_DIR)</p>&#13;
			<p class="source-code">linear_est.train(input_fn)</p>&#13;
			<p> From the preceding code, the following is observed:</p>&#13;
			<ul>&#13;
				<li>First, an instance of a linear regressor, <strong class="source-inline">linear_est</strong>, is created with a <strong class="source-inline">feature_columns</strong> object. This object provides an annotation regarding each feature (numeric or categorical data types). <strong class="source-inline">model_dir</strong> is the specified directory to save the model by checkpoints.   </li>&#13;
				<li>Next in the code is <strong class="source-inline">linear_est.train(input_fn)</strong>. This instance invokes the <strong class="source-inline">train()</strong> method to start the training process. The <strong class="source-inline">train()</strong> method takes on a function, <strong class="source-inline">input_fn</strong>. This is responsible for streaming, formatting, and <a id="_idIndexMarker207"/>sending the training data by batches into the model. We will take a look at how to construct <strong class="source-inline">input_fn</strong>. In other words, TensorFlow Estimators separates data annotation from the data ingestion process for training workflows.</li>&#13;
			</ul>&#13;
			<h2 id="_idParaDest-74"><a id="_idTextAnchor140"/>Data pipeline for TensorFlow Estimators</h2>&#13;
			<p>Like <strong class="source-inline">tf.keras</strong>, TensorFlow Estimators can leverage the streaming data pipeline when running in the <a id="_idIndexMarker208"/>TensorFlow Enterprise <a id="_idIndexMarker209"/>environment, such as the Google Cloud AI Platform. In this section, as an example, we are going to see how to stream training data (from a table in BigQuery) into a TensorFlow Estimator model. </p>&#13;
			<p>Below are the steps to building a BigQuery data pipeline for TensorFlow Estimator's consumption.</p>&#13;
			<ol>&#13;
				<li value="1">As usual, we start with the <strong class="source-inline">import</strong> operations for the requisite libraries:<p class="source-code">import tensorflow as tf</p><p class="source-code">from tensorflow_io.bigquery import BigQueryClient</p><p class="source-code">from tensorflow import feature_column</p><p class="source-code">from google.cloud import bigquery</p><p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import datetime, os</p><p class="source-code">import itertools</p></li>&#13;
				<li>Now we specify a few parameters for our table of interest in BigQuery. Make sure you specify your own <strong class="source-inline">PROJECT_ID</strong>:<p class="source-code">PROJECT_ID = '&lt;YOUR_PROJECT_ID&gt;'</p><p class="source-code">DATASET_GCP_PROJECT_ID = 'bigquery-public-data'</p><p class="source-code">DATASET_ID = 'covid19_geotab_mobility_impact'</p><p class="source-code">TABLE_ID = 'us_border_volumes'</p></li>&#13;
				<li>Next, we will specify the input function for the training process. This input function will handle the read operation, data annotation, transformation, and separation of the target from features by means of the <strong class="source-inline">transform_row</strong> function. These are exactly the identical operations seen in the previously <a id="_idIndexMarker210"/>described <strong class="source-inline">tf.keras</strong> example in the <em class="italic">Leveraging TensorFlow Keras API</em> section. The only difference is that we now wrap all of the code as follows:<p class="source-code">def input_fn():</p><p class="source-code"> PROJECT_ID = 'project1-190517' # This is from what you created in your Google Cloud Account.</p><p class="source-code"> DATASET_GCP_PROJECT_ID = 'bigquery-public-data'</p><p class="source-code"> TABLE_ID = 'us_border_volumes'</p><p class="source-code"> DATASET_ID = 'covid19_geotab_mobility_impact'  </p><p class="source-code"> client = BigQueryClient()</p><p class="source-code"> read_session = client.read_session(</p><p class="source-code">   'projects/' + PROJECT_ID,</p><p class="source-code">   DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,</p><p class="source-code">   ['trip_direction',</p><p class="source-code">    'day_type',</p><p class="source-code">    'day_of_week',</p><p class="source-code">    'avg_crossing_duration',</p><p class="source-code">    'percent_of_normal_volume',</p><p class="source-code">    'avg_crossing_duration_truck',</p><p class="source-code">    'percent_of_normal_volume_truck'</p><p class="source-code">   </p><p class="source-code">    ],</p><p class="source-code">   [tf.string,</p><p class="source-code">    tf.string,</p><p class="source-code">    tf.int64,</p><p class="source-code">    tf.double,</p><p class="source-code">    tf.int64,</p><p class="source-code">    tf.double,</p><p class="source-code">    tf.int64</p><p class="source-code">    ],</p><p class="source-code">     requested_streams=10</p><p class="source-code">   )</p><p class="source-code"> dataset = read_session.parallel_read_rows()</p><p>We are still inside <strong class="source-inline">input_fn</strong>. Continue on with <strong class="source-inline">input_fn</strong>:</p></li>&#13;
				<li>We also reorganized how we specify features and the target in our data with the <strong class="source-inline">transform_row</strong> function inside <strong class="source-inline">input_fn</strong>.<p class="source-code">def transform_row(row_dict):</p><p class="source-code">   # Trim all string tensors</p><p class="source-code">   feature_dict = { column:</p><p class="source-code">       (tf.strings.strip(tensor) if tensor.dtype == 	 	           'string' else tensor)</p><p class="source-code">       for (column,tensor) in row_dict.items()</p><p class="source-code">   }</p><p class="source-code">   # Extract target from features</p><p class="source-code">   target = feature_dict.pop(</p><p class="source-code">                           'avg_crossing_duration_truck')</p><p class="source-code">   # return a tuple of features and target</p><p class="source-code">   return (feature_dict, target)</p><p class="source-code"> transformed_ds = dataset.map(transfrom_row)</p><p class="source-code"> transformed_ds = transformed_ds.batch(32)</p><p class="source-code"> return transformed_ds  </p><p>This <a id="_idIndexMarker211"/>concludes the entire <strong class="source-inline">input_fn</strong>. At this point, <strong class="source-inline">input_fn</strong> returns a <a id="_idIndexMarker212"/>dataset read from <strong class="source-inline">us_border_volumes</strong>.</p></li>&#13;
				<li>Just as we discussed in the <strong class="source-inline">tf.keras</strong> example in the <em class="italic">Leveraging TensorFlow Keras API</em> section, we also need to build a <strong class="source-inline">feature_columns</strong> object for feature annotation. We can reuse the same code:<p class="source-code">feature_columns = []</p><p class="source-code"># Numeric columns</p><p class="source-code">for header in ['day_of_week',     </p><p class="source-code">             'avg_crossing_duration',</p><p class="source-code">             'percent_of_normal_volume',</p><p class="source-code">             'percent_of_normal_volume_truck']:</p><p class="source-code"> feature_columns.append(</p><p class="source-code">                   feature_column.numeric_column(header))</p><p class="source-code"># Categorical columns</p><p class="source-code">for header in ['trip_direction', 'day_type']:</p><p class="source-code"> categorical_feature = feature_column.categorical_column_with_vocabulary_list(</p><p class="source-code">       header, get_categorical_feature_values(header))</p><p class="source-code"> categorical_feature_one_hot = feature_column.indicator_column(categorical_feature)</p><p class="source-code"> feature_columns.append(categorical_feature_one_hot)</p></li>&#13;
				<li>Now, let's <a id="_idIndexMarker213"/>set up a directory to save the <a id="_idIndexMarker214"/>model checkpoints:<p class="source-code">MODEL_DIR = os.path.join('models', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))</p></li>&#13;
				<li>Use the following command to make the directory:<p class="source-code">%mkdir models</p><p class="source-code">%mkdir {MODEL_DIR}</p></li>&#13;
				<li>Launch the training process:<p class="source-code">linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir=MODEL_DIR)</p><p class="source-code">linear_est.train(input_fn)</p></li>&#13;
			</ol>&#13;
			<p>This completes the model training process.</p>&#13;
			<p>Since the <strong class="source-inline">estimator</strong> model expects input to be a function, in order to use the <strong class="source-inline">estimator</strong> for scoring, I have to pass into it a function that takes the test data, formats it, and feeds it to the model just like the training data.</p>&#13;
			<p>The input function for training basically did two things:</p>&#13;
			<ul>&#13;
				<li>It queried the table and got the dataset representation of the table.</li>&#13;
				<li>It transformed the data by separating the target from the features.</li>&#13;
			</ul>&#13;
			<p>In terms of the <a id="_idIndexMarker215"/>scoring situation here, we do <a id="_idIndexMarker216"/>not need to worry about this. We just need to get a dataset representation of the test data:</p>&#13;
			<ol>&#13;
				<li value="1">We can reuse the same test data as shown in the <em class="italic">Model training</em> section:<p class="source-code">test_samples = {</p><p class="source-code">   'trip_direction' : np.array(['Mexico to US', </p><p class="source-code">                                'US to Canada']),</p><p class="source-code">   'day_type' : np.array(['Weekdays', 'Weekends']),</p><p class="source-code">   'day_of_week' : np.array([4, 7]),</p><p class="source-code">   'avg_crossing_duration' : np.array([32.8, 10.4]),</p><p class="source-code">   'percent_of_normal_volume' : np.array([102, 89]),</p><p class="source-code">   'percent_of_normal_volume_truck' : np.array([106, 84])</p><p class="source-code">}</p></li>&#13;
				<li>Create a helper function to convert <strong class="source-inline">test_samples</strong> to a dataset with the following code:<p class="source-code">def scoring_input_fn():</p><p class="source-code"> return tf.data.Dataset.from_tensor_slices(test_samples).batch(2)</p></li>&#13;
				<li>The next step involves scoring the test data with the following lines of code:<p class="source-code">y = linear_est.predict(   </p><p class="source-code">        input_fn=scoring_input_fn)</p></li>&#13;
				<li>Finally, let's print the prediction as shown in the following code:<p class="source-code">predictions = list(p['predictions'] for p in itertools.islice(y, 2))</p><p class="source-code">print('Predictions: {}'.format(str(predictions)))</p><p class="source-code">Above code prints the output:</p><p class="source-code">Predictions: [array([23.875168], dtype=float32), array([13.621282], dtype=float32)]   </p><p>In the preceding code, we iterate through the model output, which is a dictionary. To refer to the values associated with the model output, we need to access it by the key named <strong class="source-inline">prediction</strong>. For readability, we convert it to a list and print it out as a string. It shows the first truck is predicted to cross the border in <strong class="source-inline">23.87</strong> minutes, while the second truck is predicted to cross the border in <strong class="source-inline">13.62</strong> minutes.</p></li>&#13;
			</ol>&#13;
			<p>TensorFlow Estimators was the only <a id="_idTextAnchor141"/>high-level API before <strong class="source-inline">tf.keras</strong> became an official part of TensorFlow distribution. While it contains many pre-made modules, such as linear <a id="_idIndexMarker217"/>regressors and different flavors of <a id="_idIndexMarker218"/>classifiers, it lacks the support for some of the commonplace deep learning modules, including CNN, LSTM, and GRU. But if your need can be addressed with non-deep learning regressors or classifiers, then TensorFlow Estimators is a good starting poi<a id="_idTextAnchor142"/>nt. It also integrates with the data ingestion pipeline.</p>&#13;
			<h1 id="_idParaDest-75"><a id="_idTextAnchor143"/>Summary</h1>&#13;
			<p>In this chapter, you have seen how the three major sources of reusable model elements can integrate with the scalable data pipeline. Through TensorFlow datasets and TensorFlow I/O APIs, training data is streamed into the model training process. This enables models to be trained without having to deal with the compute node's memory. </p>&#13;
			<p>TensorFlow Hub sits at the highest level of model reusability. There, you will find many open source models already built for consumption via a technique known as transfer learning. In this chapter, we built a regression model using the <strong class="source-inline">tf.keras</strong> API. Building a model this way (custom) is actually not a straightforward task. Often, you will spend a lot of time experimenting with different model parameters and architectures. If your need can be addressed by means of pre-built open source models, then TensorFlow Hub is the place. However, for these pre-built models, you still need to investigate the data structure required for the input layer, and provide a final output layer for your purpose. However, reusing these pre-built models in TensorFlow Hub will save time in building and debugging your own model architecture. </p>&#13;
			<p><strong class="source-inline">tf.keras</strong> is a high-level API that provides another set of reusable elements specifically for deep learning problems. If your solution requires deep learning techniques, then <strong class="source-inline">tf.keras</strong> is the recommended starting point. With the help of an example, we have seen how a multilayer perceptron can be built quickly with the <strong class="source-inline">tf.keras</strong> API and integrated with the TensorFlow I/O module that streams training data. </p>&#13;
			<p>In the next chapter, we are going to take up what we learned about <strong class="source-inline">tf.keras</strong> and TensorFlow Hub here, and leverage Google Cloud AI Platform to run our model training routine as a cloud training job. </p>&#13;
		</div>&#13;
	</div></body></html>