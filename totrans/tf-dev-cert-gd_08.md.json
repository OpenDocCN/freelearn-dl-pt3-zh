["```\n#Build\nmodel_1 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=16,\n        kernel_size=3, # can also be (3, 3)\n        activation=\"relu\",\n        input_shape=(224, 224, 3)),\n        #(height, width, colour channels)\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1050, activation=\"relu\"),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n])\n# Compile the model\nmodel_1.compile(loss=\"CategoricalCrossentropy\",\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=[\"accuracy\"])\n#fit\nhistory_1 = model_1.fit(train_data,\n    epochs=20,\n    validation_data=valid_data\n)\n```", "```\n#Fit the model\n# Add an early stopping callback\ncallbacks = [tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\", patience=3,\n    restore_best_weights=True)]\nhistory_2 = model_2.fit(train_data,\n    epochs=20,\n    validation_data=valid_data,\n    callbacks=[callbacks])\n```", "```\nEpoch 8/20\n25/25 [==============================] - 8s 318ms/step - loss: 0.0685 - accuracy: 0.9810 - val_loss: 0.3937 - val_accuracy: 0.8827\nEpoch 9/20\n25/25 [==============================] - 8s 325ms/step - loss: 0.0368 - accuracy: 0.9912 - val_loss: 0.3338 - val_accuracy: 0.9218\nEpoch 10/20\n25/25 [==============================] - 8s 316ms/step - loss: 0.0169 - accuracy: 0.9987 - val_loss: 0.4322 - val_accuracy: 0.8994\nEpoch 11/20\n25/25 [==============================] - 8s 297ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.2994 - val_accuracy: 0.8994\nEpoch 12/20\n25/25 [==============================] - 8s 318ms/step - loss: 0.1352 - accuracy: 0.9570 - val_loss: 0.4503 - val_accuracy: 0.8939\n```", "```\nmodel_2.evaluate(test_data)\n```", "```\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(500, activation=\"relu\"),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n])\n```", "```\nEpoch 5/50\n25/25 [==============================] - 8s 300ms/step - loss: 0.1284 - accuracy: 0.9482 - val_loss: 0.4489 - val_accuracy: 0.8771\nEpoch 6/50\n25/25 [==============================] - 8s 315ms/step - loss: 0.1122 - accuracy: 0.9659 - val_loss: 0.2414 - val_accuracy: 0.9162\nEpoch 7/50\n25/25 [==============================] - 8s 327ms/step - loss: 0.0814 - accuracy: 0.9735 - val_loss: 0.2976 - val_accuracy: 0.9050\nEpoch 8/50\n25/25 [==============================] - 11s 441ms/step - loss: 0.0541 - accuracy: 0.9785 - val_loss: 0.2215 - val_accuracy: 0.9050\nEpoch 9/50\n25/25 [==============================] - 8s 313ms/step - loss: 0.1279 - accuracy: 0.9621 - val_loss: 0.2848 - val_accuracy: 0.8994\n```", "```\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1050, activation=\"relu\",\n        kernel_regularizer=regularizers.l2(0.01)),\n    tf.keras.layers.Dense(4, activation=\"softmax\")\n    # binary activation output\n])\n```", "```\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1050, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.6), # added dropout layer\n    tf.keras.layers.Dense(4, activation=\"softmax\")])\n```", "```\n25/25 [==============================] - 8s 333ms/step - loss: 0.3069 - accuracy: 0.8913 - val_loss: 0.2227 - val_accuracy: 0.9330\nEpoch 6/10\n25/25 [==============================] - 8s 317ms/step - loss: 0.3206 - accuracy: 0.8824 - val_loss: 0.1797 - val_accuracy: 0.9441\nEpoch 7/10\n25/25 [==============================] - 8s 322ms/step - loss: 0.2557 - accuracy: 0.9166 - val_loss: 0.2503 - val_accuracy: 0.8994\nEpoch 8/10\n25/25 [==============================] - 9s 339ms/step - loss: 0.1474 - accuracy: 0.9469 - val_loss: 0.2282 - val_accuracy: 0.9274\nEpoch 9/10\n25/25 [==============================] - 8s 326ms/step - loss: 0.2321 - accuracy: 0.9241 - val_loss: 0.3958 - val_accuracy: 0.8659\n```", "```\n# Compile the model\nmodel_7.compile(loss=\"CategoricalCrossentropy\",\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    metrics=[\"accuracy\"])\n```", "```\nEpoch 3/10\n25/25 [==============================] - 8s 321ms/step - loss: 0.4608 - accuracy: 0.8508 - val_loss: 0.2776 - val_accuracy: 0.8994\nEpoch 4/10\n25/25 [==============================] - 8s 305ms/step - loss: 0.3677 - accuracy: 0.8824 - val_loss: 0.2512 - val_accuracy: 0.9274\nEpoch 5/10\n25/25 [==============================] - 8s 316ms/step - loss: 0.3143 - accuracy: 0.8925 - val_loss: 0.4450 - val_accuracy: 0.8324\nEpoch 6/10\n25/25 [==============================] - 8s 317ms/step - loss: 0.2749 - accuracy: 0.9052 - val_loss: 0.3427 - val_accuracy: 0.8603\nEpoch 7/10\n25/25 [==============================] - 8s 322ms/step - loss: 0.2241 - accuracy: 0.9279 - val_loss: 0.2996 - val_accuracy: 0.8659\n```", "```\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n    rotation_range=25, zoom_range=0.3)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n# Set up the train, validation, and test directories\ntrain_dir = \"/content/drive/MyDrive/weather dataset/train/\"\nval_dir = \"/content/drive/MyDrive/weather dataset/validation/\"\ntest_dir = \"/content/drive/MyDrive/weather dataset/test/\"\n# Import data from directories and turn it into batches\ntrain_data = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224,224), # convert all images to be 224 x 224\n    class_mode=\"categorical\")\nvalid_data = valid_datagen.flow_from_directory(\n    val_dir,\n    target_size=(224,224),\n    class_mode=\"categorical\")\ntest_data = valid_datagen.flow_from_directory(\n    test_dir,\n    target_size=(224,224),\n    class_mode=\"categorical\",)\n```", "```\nEpoch 4/20\n25/25 [==============================] - 8s 308ms/step - loss: 0.2888 - accuracy: 0.9014 - val_loss: 0.3256 - val_accuracy: 0.8715\nEpoch 5/20\n25/25 [==============================] - 8s 312ms/step - loss: 0.2339 - accuracy: 0.9115 - val_loss: 0.2172 - val_accuracy: 0.9330\nEpoch 6/20\n25/25 [==============================] - 8s 320ms/step - loss: 0.1444 - accuracy: 0.9507 - val_loss: 0.2379 - val_accuracy: 0.9106\nEpoch 7/20\n25/25 [==============================] - 8s 315ms/step - loss: 0.1190 - accuracy: 0.9545 - val_loss: 0.2828 - val_accuracy: 0.9162\nEpoch 8/20\n25/25 [==============================] - 8s 317ms/step - loss: 0.0760 - accuracy: 0.9785 - val_loss: 0.3220 - val_accuracy: 0.8883\n```"]