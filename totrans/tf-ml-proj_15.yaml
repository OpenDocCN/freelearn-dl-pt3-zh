- en: What is Next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations on making it this far. So far, have learned to implement a variety
    of cutting-edge AI algorithms in TensorFlow and built cool projects on the side.
    Specifically, we have built projects on reinforcement learning, Bayesian neural
    networks, capsule networks, and **Generative Adversarial Networks** (**GANs**),
    among others. We have also learned about several modules of TensorFlow, including
    TensorFlow.js, TensorFlow Lite, and TensorFlow Probability, among others. This
    surely deserves a pat on the back and a well-earned rest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go out to play, there are a few more things that we should consider
    reading about before we are prime-time ready to deploy these cutting edge techniques
    in production. As we will realize in this chapter, there is more to deploying
    a machine learning model in production than just implementing the latest research
    paper in AI. To understand what I mean by this, let''s read through the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow utilities to deploy models in production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General rules for building AI applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations of deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications of AI across different industries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ethical Considerations in AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing TensorFlow in production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to software engineering, we see several best practices, like version
    control through GitHub, reusable libraries, continuous integration, and others,
    which have made developers more productive. Machine learning is a new field where
    there is a definite need for some tooling to make model deployment simple and
    improve a data scientist's productivity. In that respect, TensorFlow has released
    a host of tools recently.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding TensorFlow Hub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software repositories have a real benefit in the field of software engineering
    as they enhance the reusability of code. This not only helps to improve developer
    productivity, but also helps in sharing expertise among different developers.
    Also, because developers now want to share their code, they develop their code
    in a manner that is more clean and modular so that it can benefit the entire community.
  prefs: []
  type: TYPE_NORMAL
- en: Google introduced TensorFlow Hub to achieve the similar purpose of reusability
    in machine learning. It is designed so that you can create, share, and reuse the
    components of machine learning models. Reusability in machine learning is even
    more important than software engineering because we are not only using the algorithm/architecture
    and the expertise—we are also using an enormous amount of compute power that went
    into training the model and all of the data as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'TF hub comprises of several machine learning models which are trained using
    state-of-the-art algorithms and huge amounts of data by experts at Google. Each
    of this trained model is termed as **Module **in TF hub. A module and can be shared
    on the **TensorFlow Hub**, where they can then be imported by anyone into their
    code. The following diagram depicts the flow of what how a trained TensorFlow
    model can be used by other applications/models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c851d7e2-fe42-404d-aae8-2a87f7f0424c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Modules** in **TensorFlow Hub** contain both the model''s architecture or
    the TensorFlow graph and the weights of the trained **Model**. **Modules** have
    the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Composable:** Composable means that we can use modules as building blocks
    and add stuff on top of them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reusable:** Reusable means that modules have a common signature so that we
    can swap one with another. This is mainly useful when we are iterating over models
    to get the best accuracy on our dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retrainable:** Modules come with pre-trained weights, but they are flexible
    enough to be retrained on the new dataset. This means that we can back propagate
    through the model to generate new set of weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's understand this with the help of an example. Say we have a dataset of
    different Toyota cars such as the Camry, the Corolla, and other models. If we
    don't have a lot of images of each category, it won't be prudent to train the
    entire model from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, what we can do is take a general purpose model that has been trained
    on a giant set of images from TensorFlow Hub and take the reusable part of the
    model, such as its architecture and pre-trained weights. On top of the pre-trained
    model, we can add a classifier that classifies the images that are present in
    our dataset appropriately. This procedure is sometimes also referred to as transfer
    learning. This is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbb61268-5dd9-446e-8095-20c8abb8be51.png)'
  prefs: []
  type: TYPE_IMG
- en: If you want to learn more about Transfer Learning, please refer to the Stanford's
    course notes [(](http://cs231n.github.io/transfer-learning/)[http://cs231n.github.io/transfer-learning/](http://cs231n.github.io/transfer-learning/)[)](http://cs231n.github.io/transfer-learning/)
  prefs: []
  type: TYPE_NORMAL
- en: 'You can visit TensorFlow Hub ([https://www.tensorflow.org/hub/](https://www.tensorflow.org/hub/))
    to get state-of-the-art, research-oriented image models that you can directly
    import into your custom models. Let''s say we are using NasNet ([https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/1](https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/1)),
    which is an image module that''s trained through architecture search. Here we
    are going to use the URL for the NasNet module in our code to import the module,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: module = hub.Module(“https://tfhub.dev/google/imagenet/nasnet_large/feature_vect
  prefs: []
  type: TYPE_NORMAL
- en: or/1”)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: features = module(toyota_images)
  prefs: []
  type: TYPE_NORMAL
- en: logits = tf.layers.dense(features, NUM_CLASSES)
  prefs: []
  type: TYPE_NORMAL
- en: probabilities = tf.nn.softmax(logits)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We added a dense layer with softmax non-linearity on top of the module. We train
    the weights of the dense layer through backpropagation to classify the Toyota
    car images.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we don't need to download the module, nor do we need to instantiate
    it.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow takes care of all of those low-level details, which makes the module
    reusable in a true sense. Another great thing about using this module is that
    you get thousands of hours of compute required to train NasNet for free.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we do have a large dataset. In that case, we can train the reusable
    part of the module as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: module = hub.Module(“https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/1”,trainable
    = True, tags {“train”})features = module(toyota_images)
  prefs: []
  type: TYPE_NORMAL
- en: logits = tf.layers.dense(features, NUM_CLASSES)
  prefs: []
  type: TYPE_NORMAL
- en: probabilities = tf.nn.softmax(logits)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: TensorFlow Hub has pre-trained models for image classification, word embeddings,
    sentence embeddings, and other applications. Let's consider our movie sentiment
    detection project from [Chapter 3](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml),
    *Sentiment Analysis in your browser using Tensorflow.js* in this book. We could
    have used a pre-trained embedding for each piece of work in the dataset from TensorFlow Hub.
    This availability of pre-trained modules across domains will potentially help
    many developers build new applications without having to worry about the math
    behind the models.
  prefs: []
  type: TYPE_NORMAL
- en: You can find more details about this on the official web page of TensorFlow
    Hub ([https://www.tensorflow.org/hub/](https://www.tensorflow.org/hub/)).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Serving
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TensorFlow Serving** is a highly flexible serving system for deploying machine
    learning models in production. Before we go into the details, first let''s try
    to understand what serving is by taking a look at its architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d0b5b79d-79ad-4299-b98e-3a3f6f66e7b9.png)'
  prefs: []
  type: TYPE_IMG
- en: We have some **Data** and we use that to train a machine learning **Model**.
    Once the **Model** is trained, it needs to be deployed onto a web or mobile **App**
    to serve the end users. One way to do that is through a **remote procedure call**
    (**RPC**) server ([https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/com.ibm.aix.progcomc/ch8_rpc.htm](https://www.ibm.com/support/knowledgecenter/en/ssw_aix_72/com.ibm.aix.progcomc/ch8_rpc.htm)).
    TensorFlow Serving can be used both as an **RPC Server** and as a set of libraries,
    both inside an app or embedded device.
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow Serving has three pillars:'
  prefs: []
  type: TYPE_NORMAL
- en: '**C++ libraries:** Low-level C++ libraries primarily contain the functions
    and methods required for TensorFlow serving. These are the libraries that Google
    uses to generate the binaries used by applications. They are also open sourced.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Binaries:** If we want standard settings for our serving architecture, we
    can use pre-defined binaries, that incorporate all the best practices from Google.
    Google also provides Docker containers ([https://www.docker.com/](https://www.docker.com/))
    to scale the binaries on Kubernetes ([https://kubernetes.io/](https://kubernetes.io/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hosted services:** TensorFlow Serving also has hosted services across Google
    Cloud ML, which makes it pretty easy to use and deploy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some of the advantages of TensorFlow Serving:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Online and low latency:** Users don''t want to wait to see predictions on
    their application. With TF serving, predictions are not only fast—they are consistently
    fast.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple models in a single process:** TF serving lets you load multiple
    models in the same process. Let''s say we have a model that is serving great predictions
    to the customers. However, if we want to run an experiment, then we might want
    to load another model, along with the production model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Auto-loading and training of versions of the same model:** TF serving has
    support for auto-loading a newly trained model without downtime and switching
    from an old version of the same model in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalable:** TF Serving is auto-scalable with Cloud ML, Docker, and Kubernetes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more details on how to deploy your models using TF Serving, refer to the
    official documentation [here](https://www.tensorflow.org/serving/) ([https://www.tensorflow.org/serving/](https://www.tensorflow.org/serving/)).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Extended
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TensorFlow Extended** (**TFX**) is a general-purpose machine learning platform
    that was built at Google. Some components of it are open sourced, and there was
    a recent paper ([https://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform](https://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform))
    in a KDD conference illustrating the capabilities and vision of TFX.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this book, we primarily understood the semantics of building a TensorFlow model.
    However, when we look at the actual machine learning applications in production,
    there are many more components. The following diagram illustrates these components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e01138c-711e-49eb-8e39-c41fb9d698c8.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, ML code is a very small component of the overall system. Other
    blocks take the maximum amount of time to build and occupy the maximum lines of
    code. TFX provides the libraries and tools to construct the other components of
    machine learning pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at an example of the machine learning process to understand the
    different open source components of TensorFlow Extended:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/949f43e6-ceb7-495a-9177-1fac8f01f203.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Analyze Data**: Exploratory data analysis is a requirement for building any
    machine learning model. TFX has a tool named Facets ([https://github.com/PAIR-code/facets](https://github.com/PAIR-code/facets)),
    which lets us visualize the distribution of each variable and identify missing
    data or outliers, or inform others about what data transformations might be required
    on the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transform**: TensorFlow transforms ([https://www.tensorflow.org/tfx/transform/get_started](https://www.tensorflow.org/tfx/transform/get_started))
    provide out-of-the-box functions to perform a full transform on the base data
    to make it suitable for training a model. It is also very much attached to the
    TF graph itself, which ensures that you are applying the same transforms in training,
    as well as serving.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Train TF estimator**: After transforming the data, we can use the TF Estimator
    ([https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator)),
    which provides a high-level API to quickly define, train, and export a model.
    TF Estimators also let you export models in different formats for inference and
    serving.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analyze Model**: Once the model is built, we can directly push it to production,
    but that would be a very bad idea. Instead, we should analyze the model predictions
    and make sure that the model is predicting things that we want it to predict.
    TF Model Analysis ([https://www.tensorflow.org/tfx/model_analysis/get_started](https://www.tensorflow.org/tfx/model_analysis/get_started))
    lets us evaluate the model over a large dataset and provides a UI to slice the
    predictions by different values of attributes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Serve Model**: After analyzing our model and getting comfortable with its
    model predictions, we want to serve the model to production. One way this can
    be achieved is by using TensorFlow Serving, which was described in the previous
    section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow Extended is heavily used inside Google for building products. It
    definitely has more features than the ones that are open sourced. For people working
    at startups or companies that don't have their own internal ML platform, TFX is
    highly recommended for building end-to-end ML applications.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendations for building AI applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand some of the tools from TensorFlow that can help us in
    developing and deploying models at scale, let's try to understand the general
    rules of thumb when building AI applications.
  prefs: []
  type: TYPE_NORMAL
- en: '**Engineering over machine learning**: Almost all the solutions to problems
    start with engineering. It is very important to get the data pipeline right before
    building any machine learning model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Keep it simple**: Generally, data scientists have a natural tendency to build
    the most complex model for the problem. However, it is great to start with a simple,
    interpretable model—say, a logistic regression model for classification. It helps
    in discovering and debugging data or engineering pipeline issues better. Only
    when you are not satisfied with the results of the basic model should you use
    advanced techniques like deep learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed processing**: In the era of big data, you will almost always
    run into issues where you can''t fit the data into RAM. Learning about distributed
    frameworks like Spark can help a lot in processing and building scalable machine
    learning applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated model retraining**: Once the model is deployed, its performance
    can degrade over time. It is important to keep checking the model''s accuracy
    so that automated training of the model can be kicked off with new data. This
    will help in maintaining prediction accuracy for the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training and testing pipelines**: With separate pipelines for training and
    testing, there is always a possibility of divergence between training and testing
    features. Try to have as much overlap as possible between training and testing
    pipelines. This can help make debugging model predictions easier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Launch new models with A/B testing**: A/B testing is a method of comparing
    two versions of model/webpage and others. It is a statistical experiment conducted
    where two different versions are shown to the users at random. You can read more
    about them in lecture notes from Purdue ([https://www.cs.purdue.edu/homes/ribeirob/courses/Fall2016/lectures/hyp_tests.pdf](https://www.cs.purdue.edu/homes/ribeirob/courses/Fall2016/lectures/hyp_tests.pdf))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you build a better model than the one already existing in production, you
    will see some uplift in accuracy for testing datasets. However, there is a real
    chance that you might not see the same uplift in production compared to the existing
    model because of a variety of issues like correlations versus causation, change
    in user behavior, and so on. It is very important to perform A/B tests with a
    new model in production before rolling them out to all users.
  prefs: []
  type: TYPE_NORMAL
- en: '**One model over ensemble**: Ensemble models (a combination of many single
    models) might give better accuracy over a single model. However, if the gain is
    not significant, always prefer using a single model. This is because ensemble
    models are difficult to maintain, debug, and scale in production systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations of deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this project, almost all of the projects involved some sort of deep learning.
    Deep learning has been pivotal in powering most of the advances in the last few
    years. However, there are obvious limitations to deep learning that we should
    understand before applying them to real-world situations. Here are some of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data-hungry**: Usually, we don''t have big datasets for every problem we
    want to solve using machine learning. On the contrary, deep learning algorithms
    only work when we have huge datasets for the problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compute intensive**: Deep learning training usually requires GPU support
    and a huge amount of RAM. However, this makes it impossible to train deep neural
    networks on edge devices like mobiles and tablets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No prediction uncertainty**: Deep learning algorithms are, by default, poor
    at representing uncertainty. Deep neural networks can confidently misclassify
    a cat image as that of a dog.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no notion of confidence intervals or uncertainty in predictions. For
    applications like self-driving cars, it is very important to take uncertainty
    into account before making any decision. In this book, we touched on concepts
    like Bayesian neural networks, which are an attempt to incorporate uncertainty
    in deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Uninterpretable black boxes**: Deep learning models are hard to interpret
    and trust. For example, the loan department at a bank decides whether to give
    a loan to an individual based on their past purchases or credit history using
    a deep neural network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the model denies the loan, the bank has to give an explanation to the individual
    regarding why their loan was denied. However, with deep neural networks, it is
    almost impossible to provide an explicit reason about why the loan was denied.
    Uninterpretability is a major reason why these models are not ubiquitous across
    different industries.
  prefs: []
  type: TYPE_NORMAL
- en: AI applications in industries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AI is the new paradigm that every company is trying to move to. As per the Mckinsey
    report ([https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy](https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy)),
    by 2030, 70% of companies are expected to adopt at least one AI technology. Let''s
    look at different applications of AI by industries:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Retail**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supply chain optimization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Customization of shopping experiences by micro targeting
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Pricing of products and holiday discount calculations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom product placement in retail stores to increase sales
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Social Networks (Facebook, LinkedIn, Twitter)**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Friend/follower recommendations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Home feed customization to increase engagement based on past history
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fake news/fraud detection
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Healthcare**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: New drug discovery
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated medical imaging
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommending workouts/food through data stored in Apple Watch or other devices
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finance**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stock market prediction
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Credit card fraud detection
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Loan qualification
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbots for customer support
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manufacturing**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictive maintenance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Demand forecasting
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Inventory management
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logistics**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ETA optimization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Surge pricing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Shared rides/pool
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Pricing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-driving cars
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ethical considerations in AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are seeing an extraordinary rise in Artificial Intelligence and its applications.
    However, the growing sophistication of AI applications has raised a number of
    concerns around bias, fairness, safety, transparency, and accountability. This
    is mainly because AI models don't have a conscience and can't distinguish good
    from bad all by themselves. They are as good as the data they are trained on.
    So, if the data is biased in some sense, so will the predictions be. There are
    other concerns around rising unemployment due to automation, the use of AI for
    terrorism, and racist predictions from AI models, among others.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that many universities are spending time and resources to come
    up with solutions on how to make AI more fair and free from bias. At the same
    time, regulators are trying to frame new rules so that AI applications are safe
    and secure for humans.
  prefs: []
  type: TYPE_NORMAL
- en: As an AI practitioner, it is imperative that we understand these issues before
    using AI in our own products. I urge you to make yourself aware of the ethical
    issues in your products and correct them accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at various extensions of TensorFlow for improving
    the productivity of data scientists and enabling the easier deployment of cutting-edge
    models in production at a large scale.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at TensorFlow Hub, which is similar to the GitHub repository of trained deep
    learning models from various areas like Computer Vision, Natural Language Processing,
    and so on. Thereafter, we understood how TensorFlow Serving provide tools and
    libraries to deploy deep learning models at scale. Lastly, we learned about the
    open source components of **TensorFlow Extended** (**TFX**), which is a machine
    learning platform from Google. TFX helps in the entire model building pipeline,
    from data analysis to model deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we learned about several best practices when building scalable AI products.
    Building a robust engineering pipeline and trying out simple models before deep
    learning and always launching new models with A/B tests are few of them.
  prefs: []
  type: TYPE_NORMAL
- en: Thereafter, we dispensed the hype around deep learning by understanding the
    limitations of deep neural networks. Specifically, we learned that they require
    huge amounts of data and compute power for building good, accurate models. Also,
    the fact that they are not interpretable makes them unusable in many AI applications.
    We also looked at various applications of AI across different industries and learned
    about the importance of ethics in AI.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, if you have made it this far and completed the projects, I thank you
    and congratulate you for your awesome achievement. You have acquired the necessary
    skills to build practical AI applications using state-of-the-art techniques in
    reinforcement learning, computer vision, and natural language processing, among
    others. I would request that you now use your knowledge for good and make this
    world a better place.
  prefs: []
  type: TYPE_NORMAL
- en: 'I would like to end this book with my favorite quote:'
  prefs: []
  type: TYPE_NORMAL
- en: The future is not some place we are going, but one we are creating.
  prefs: []
  type: TYPE_NORMAL
- en: '- John H. Schaar'
  prefs: []
  type: TYPE_NORMAL
