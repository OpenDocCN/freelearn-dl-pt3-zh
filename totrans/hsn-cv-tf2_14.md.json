["```\n$ tensorboard --logdir ./model_logs\n```", "```\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Inputs, Conv2D, MaxPooling2D, Flatten, Dense\n\n# \"Layer\" representing the network's inputs:\ninputs = Input(shape=input_shape)\n# First block (conv + max-pool):\nconv1 = Conv2D(6, kernel_size=5, padding='same', activation='relu')(inputs)\nmax_pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n# 2nd block:\nconv2 = Conv2D(16, kernel_size=5, activation='relu')(max_pool1)\nmax_pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n# Dense layers:\nflatten = Flatten()(max_pool2)\ndense1 = Dense(120, activation='relu')(flatten)\ndense2 = Dense(84, activation='relu')(dense1)\ndense3 = Dense(num_classes, activation='softmax')(dense2)\n\nlenet5_model = Model(inputs=inputs, outputs=dense3)\n```", "```\nfreeze_num = 3\n# Looking at `resnet50.summary()`, we could observe that the 1st layer of the 4th macro-block is named \"res5[...]\":\nbreak_layer_name = 'res{}'.format(freeze_num + 2)\nfor layer in resnet50_finetune.layers:\n   if break_layer_name in layer.name:\n        break\n    if isinstance(layer, tf.keras.layers.Conv2D):\n        # If the layer is a convolution, and isn't after \n        # the 1st layer not to train:\n        layer.trainable = False\n```", "```\ndataset_a = tf.data.Dataset.from_tensor_slices(a)\ndataset_b = tf.data.Dataset.from_tensor_slices(b)\ndataset_ab = dataset_a.concatenate(dataset_b)\nfor element in dataset_ab:\n    print(element) # will print 1, then 2, ... until 6\n```"]