- en: Creating an E2E Web App Using DL APIs and Customer Support Chatbot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will draw together several tools and methods that we have
    learned how to use in previous chapters of this book, as well as introducing some
    great new tools and techniques, as well. This chapter covers a very important
    facet of an enterprise—customer support. For a budding business, customer support
    can be exhausting and frustrating to keep up with. More often than not, the questions
    raised by customers are easily answerable by referring to documentation or a set
    of FAQ answers provided by the company on their website, but customers don't often
    read through them. So, it would be great to have a layer of automation in place,
    where the most common queries will be answered by a chatbot that is always available
    and responsive throughout the day.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter discusses how to create a chatbot using Dialogflow to resolve general
    customer support queries and how to integrate it into a Django-based website.
    Furthermore, the chatbot will draw its answers from a Django API, which will be
    hosted separately. We'll explore ways of implementing bot personalities and introduce
    a method of implementing **Text-to-Speech** (**TTS**)- and **Speech-to-Text**
    (**STT**)-based user interfaces via the Web Speech API, which deploys neural networks
    right to the user's browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to chatbots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Dialogflow bot with the personality of a customer support representative
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using ngrok to facilitate HTTPS APIs on localhost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a testing UI using Django for managing orders within a company
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech recognition and speech synthesis on a web page using the Web Speech API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will be drawing insights from what we have learned in previous chapters and
    building on them, while at the same time revising a few concepts and introducing
    new ones along the way. Let's begin by understanding **Natural Language Processing**
    (**NLP**).
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can access the code for this chapter at [https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter12](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter12).
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll need the following software to run the code used in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.6+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Django 2.x
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All other installations will be covered during the course of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A popular—and one of the most exciting—fields of machine learning and deep learning
    applications is NLP, which refers to a collection of techniques and methods developed
    to understand and generate human language. The goals of NLP begin with comprehending
    the meaning of human language text and extend to generating human language, such
    that the generated sentences are meaningful and make sense to humans who read
    that text. NLP has found major usage in building systems that are able to take
    instructions and requests directly from humans in the form of natural language,
    such as chatbots. However, chatbots also need to respond in natural language,
    which is another aspect of NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Let's study some common terms related to NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Corpus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will often come across the term **corpus** while you are studying NLP. In
    layman's terms, a corpus is a collection of writings from any one author or from
    a genre of literature. In the study of NLP, the dictionary definition of corpus
    gets a bit modified and can be stated as a collection of written text documents,
    such that they can all be categorized together by any metric of choice. These
    metrics might be authors, publishers, genres, types of writing, ranges of time,
    and other features associated with written texts.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a collection of Shakespeare's works or the threads on any forum
    for any given topic can both be considered a corpus.
  prefs: []
  type: TYPE_NORMAL
- en: Parts of speech
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we decompose a sentence into its constituent words and perform a qualitative
    analysis of what each of the words of the sentence contributes to the overall
    meaning of that sentence, we perform the act of determining parts of speech. So,
    parts of speech are notations provided to words in a sentence based on how those
    words contribute to the meaning of the sentence.
  prefs: []
  type: TYPE_NORMAL
- en: In the English language, we commonly have eight types of parts of speech—the
    verb, the noun, the pronoun, the adjective, the adverb, the preposition, the conjunction,
    and the interjection.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the sentence "Ram is reading a book", "Ram" is a noun and the
    subject, "reading" is a word and the action, and "book" is a noun and the object.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about parts of speech at [http://partofspeech.org/](http://partofspeech.org/).
    You can try finding out the parts of speech of your own sentences at [https://linguakit.com/en/part-of-speech-tagging](https://linguakit.com/en/part-of-speech-tagging).
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tokenization is the process of breaking down documents into sentences and sentences
    into words. This is important because it would be a computational nightmare if
    any computer program attempted to process entire documents as single strings,
    due to the resource-intensiveness associated with processing strings.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, it is very rare that all sentences need to be read at once to be
    able to understand the meaning of an entire document. Often, each sentence has
    its own discrete meaning that can be assimilated with other sentences in the document
    by statistical methods to determine the overall meaning and content of any document.
  prefs: []
  type: TYPE_NORMAL
- en: Again, we often need to break down sentences into words in order to better process
    the sentence, such that the meaning of the sentence can be generalized and derived
    from a dictionary, where each word is listed individually.
  prefs: []
  type: TYPE_NORMAL
- en: Stemming and lemmatization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stemming and lemmatization are closely related terms in NLP, but with a slight
    but significant difference. The objective of both methods is to determine the
    root word that any given word originates from, such that any derivates of the
    root word can be matched to the root word in the dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: Stemming is a rule-based process where the words are trimmed and sometimes appended
    with modifiers that indicate its root word. However, stemming might, at times,
    produce root words that don't exist in the human dictionary and so mean nothing
    to the human reader.
  prefs: []
  type: TYPE_NORMAL
- en: Lemmatization is the process of converting words to their lemma, or their root
    word, as given in the dictionary. So, the originally intended meaning of the word
    can be derived from a human dictionary, making lemmatized text easier to work
    with than stemmed text. Furthermore, lemmatization takes into consideration the
    part of speech that any word is in any given sentence before determining its correct
    lemma, which a stemming algorithm overlooks. This makes lemmatization more context-aware
    than stemming.
  prefs: []
  type: TYPE_NORMAL
- en: Bag of words
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is not possible for computers to directly process and work with text. Hence,
    all text must be converted into numbers before being fed into a machine learning
    model. The process of changing text to an array of numbers, such that it is possible
    to retrieve the most important pieces of the original text from the converted
    text at any point in time, is known as feature extraction or encoding. **Bag of
    Words** (**BoW**) is one popular and simple technique used to perform feature
    extraction on text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps associated with a BoW implementation are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract all the unique words from the document.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a single vector with all the unique words in the document.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert each document into a Boolean array based on whether any word in the
    word vector is present in that document or not.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For example, consider the following three documents:'
  prefs: []
  type: TYPE_NORMAL
- en: Ram is a boy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ram is a good boy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ram is not a girl.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The unique words present in these documents can be listed in a vector as ["Ram",
    "is", "a", "boy", "good", "not", "girl"].
  prefs: []
  type: TYPE_NORMAL
- en: 'So, each sentence can be converted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[1, 1, 1, 1, 0, 0, 0]'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[1, 1, 1, 1, 1, 0, 0]'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[1, 1, 1, 0, 0, 1, 1]'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will observe that BoW tends to lose the information of where each word appears
    in the sentence or what meaning it contributes to the sentence. So, BoW is a very
    basic method of feature extraction and may not be suitable for several applications
    that require context-awareness.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The similarity is the measure of how similar any two given sentences are. It
    is a very popular operation in the domain of computer science, and anywhere where
    records are maintained, for searching the right documents, searching words in
    any document, authentication, and other applications.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways of calculating the similarity between any two given documents.
    The Jaccard index is one of the most basic forms, which computes the similarity
    of two documents based on the percentage ratio of the number of tokens that are
    the same in both documents over the total unique tokens in the documents.
  prefs: []
  type: TYPE_NORMAL
- en: Cosine similarity is another very popular similarity index, which is computed
    by calculating the cosine formed between the vectors of two documents when converted
    into vectors using BoW or any other feature-extraction technique.
  prefs: []
  type: TYPE_NORMAL
- en: With these concepts in mind, let's move on to studying chatbots, which are one
    of the most popular forms of application of NLP.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to chatbots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chatbots are a segment of application of NLP that deals specifically with conversational
    interfaces. These interfaces can also expand their work to handle rudimentary
    commands and actions and are, in these cases, termed voice-based virtual assistants.
    Voice-based virtual assistants have been on the rise recently with the introduction
    of dedicated devices such as Google Home and Alexa by Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots can exist in multiple forms. They don't need to only be present as
    virtual assistants. You could talk to a chatbot in a game, where it tries to draw
    a storyline in a certain direction, or you could interact with the social chatbots
    that some companies use to reply to their customers on social media platforms,
    such as Twitter or Facebook. Chatbots can be considered a move over **Interactive
    Voice Response** (**IVR**) systems, with their added intelligence and ability
    to respond to unknown input, sometimes merely with a fallback reply or sometimes
    with a calculated response that draws on the input provided.
  prefs: []
  type: TYPE_NORMAL
- en: A virtual assistant can also exist on a website, giving instructions and offering
    help to visitors. Assistants such as these are regularly found on websites, mostly
    offering instant support to consumer queries. You must have noticed the "Ask a
    question" or "May I help you" chatboxes, usually at the bottom-right side of the
    screen, on several websites that sell products or services. More often than not,
    they employ the use of automated chatbots instead of real people to answer queries.
    Only in cases where the query is too complex to be answered by the automated customer
    support chatbot is the query transferred to a real person.
  prefs: []
  type: TYPE_NORMAL
- en: Creating conversational UIs is an art in itself. You need to be able to use
    words that are clear yet natural to a spoken tongue. You can learn more about
    creating conversational UIs at [https://designguidelines.withgoogle.com/conversation](https://designguidelines.withgoogle.com/conversation/).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will work on creating a chatbot that acts as a customer
    support agent.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Dialogflow bot with the personality of a customer support representative
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dialogflow is a very popular tool used to create chatbots. Similar to Wit.ai,
    Botpress, Microsoft Bot Framework, and several other ready-to-deploy services
    available for creating chatbots, Dialogflow comes with the added advantage of
    its tight integration with **Google Cloud Platform** (**GCP**) and the possibility
    of using Dialogflow agents as actions for the Google Assistant, which runs natively
    on billions of Android devices.
  prefs: []
  type: TYPE_NORMAL
- en: Dialogflow was formerly known as Api.ai. After its acquisition by Google, it
    was renamed and has since grown in its popularity and extensibility. The platform
    allows very easy integration with several platforms, such as Facebook Messenger,
    Telegram, Slack, Line, Viber, and several other major communication platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'The project we will develop in this chapter will follow the following architecture
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a41d094b-e97b-407c-917d-75e3604a9f83.png)'
  prefs: []
  type: TYPE_IMG
- en: We will use several libraries and services that are not mentioned in the preceding
    diagram. We'll introduce them during the course of the project and discuss why
    it is interesting for us to know about them.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Dialogflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started with Dialogflow, you should head to the official website, at
    [https://dialogflow.com](https://dialogflow.com), to get to the home page, which
    displays the product information and links to the documentation. It is always
    a great idea to study the documentation of any product or service you're trying
    to learn because it includes the entirety of the software's workings and functionalities.
    We will refer to sections in the documentation in the upcoming sections of this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the Dialogflow documentation at [https://cloud.google.com/dialogflow/docs/](https://cloud.google.com/dialogflow/docs/).
  prefs: []
  type: TYPE_NORMAL
- en: Dialogflow is closely integrated with GCP and so we must first create a Google
    account. To do so, create an account by going to [https://account.google.com](https://account.google.com).
    You might have to provide a number of permissions on your Google account if you
    are using your account for the first time with Dialogflow.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the steps to explore and understand the Dialogflow account
    creation process and the various parts of the UI.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Opening the Dialogflow console
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You need to click on the Go to console button at the top-right corner of the
    page at [https://dialogflow.com](https://dialogflow.com). Alternatively, you can
    type [https://dialogflow.cloud.google.com/](https://dialogflow.cloud.google.com/)
    in your browser. If you''re a first-time user, you will see a screen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f63c63f-055e-418d-ab6b-1584c6ee3e17.png)'
  prefs: []
  type: TYPE_IMG
- en: The dashboard prompts you to create a new agent.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Creating a new agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now create a Dialogflow agent. In terms of Dialogflow, an agent is another
    name for a chatbot. It is the agent that receives, processes, and responds to
    all input provided by the user.
  prefs: []
  type: TYPE_NORMAL
- en: Click on the Create Agent button and fill in the required information about
    the agent to your liking, which includes the agent's name, the default language,
    the timezone, and the Google project name.
  prefs: []
  type: TYPE_NORMAL
- en: If you haven't used GCP prior to this step, you'll have to create a project.
    We've discussed the creation of GCP projects in [Chapter 6](093890b6-051d-49f9-9330-bdd58b92a762.xhtml),
    *Deep Learning on Google Cloud Platform Using Python*. Alternatively, you can
    simply let GCP automatically create a new project for you when creating the agent.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Understanding the dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After the successful creation of a Dialogflow agent, you''ll be presented with
    a dashboard like that in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9dc140c8-5a57-428c-8d95-fe121fb43532.png)'
  prefs: []
  type: TYPE_IMG
- en: On the left, you can see a menu containing the various components that make
    up the chatbot. This menu is going to be very useful and you should take a good
    look at all its contents to make sure you understand what we're referring to in
    the menu items. When we use sentences such as "Click on Entities", we mean we
    want you to click on the Entities item in this menu.
  prefs: []
  type: TYPE_NORMAL
- en: The center section will hold different content depending upon which component
    in the menu has been clicked on. By default, when you open the Dialogflow console,
    it contains the list of intents of the chatbot. What are intents?
  prefs: []
  type: TYPE_NORMAL
- en: 'An intent is an action that a user wishes to perform by any utterance they
    make to the chatbot. For example, when the user says `Bring me a cup of coffee`,
    their intent is to ask the chatbot to "bring coffee":'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b455813e-a6a5-486d-af4d-83efcfcd4c80.png)'
  prefs: []
  type: TYPE_IMG
- en: On the far right, a panel is provided to test the chatbot at any moment. You
    can write any input text you wish to test the chatbot's response against and you'll
    be presented with a slew of information, along with the response that the chatbot
    produces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following testing input and response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c8a88f2-9d9a-4fbf-92cd-6ed636277b4e.png)'
  prefs: []
  type: TYPE_IMG
- en: When the user inputs `What is my order status`, the chatbot replies asking for
    the order ID of the order in question. This is matched to the `CheckOrderStatus`
    intent and requires a parameter named `OrderId`. We will be using this console
    regularly through this project to debug the chatbot during development.
  prefs: []
  type: TYPE_NORMAL
- en: While in the previous screenshots we've shown you a pre-configured agent with
    intents, your newly created agent won't have any custom intents at this point.
    Let's create them!
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Creating the intents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's create two intents. One intent will offer help to the user and the
    other will carry out a check on the status of the order ID provided by the user.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4.1 – Creating HelpIntent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this sub-step, click on the + button that is to the right of the Intents
    item in the left-hand side menu. You will be presented with a blank intent creation
    form.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be able to see the following headings in the intent creation form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e229400a-7d81-4313-80b8-0ed1a34a5b3f.png)'
  prefs: []
  type: TYPE_IMG
- en: For this intent, fill Intent Name in as `HelpIntent`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, follow the next steps to complete this intent creation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.1.1 – Entering the training phrases for HelpIntent**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to define phrases that are likely to invoke this intent to action.
    To do so, click on the Training Phrases heading and enter a few sample training
    phrases, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7dfccd76-fb68-4aae-8911-22af5e77a48c.png)'
  prefs: []
  type: TYPE_IMG
- en: Make sure you click on Save whenever you make any changes to an intent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.1.2 – Adding a response**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to respond to the user query in this intent, we need to define the
    possible responses. Click on the Responses heading in the intent creation form
    and add a sample response to the query, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64a15276-092b-46b6-9c1e-7a2cf89d5d7b.png)'
  prefs: []
  type: TYPE_IMG
- en: Save the intent. Once we have finished building it, we can test the chatbot
    by entering an input similar to the training phrases we defined for this intent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.1.3 – Testing the intent**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test `HelpIntent`. In the right-hand side testing panel, input `Can
    you help me?`. The agent produces the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5addae4f-c070-4f96-83f6-b2e65a6bf5e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice the matched intent at the bottom of the preceding screenshot. Since `HelpIntent`
    has successfully matched to the input, which was not explicitly defined in the
    training phrases, we can conclude that the agent works well.
  prefs: []
  type: TYPE_NORMAL
- en: Why is it important for the agent to respond to an input it has not been trained
    on? This is because while testing the agent for a particular intent, we want to
    be assured that any utterances exactly or closely matching the training phrases
    are matched by that intent. If it does not match closely related queries to the
    intent that is expected, you need to provide more training phrases and check whether
    there are any conflicting trainings in any other intents of the agent.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an intent telling the user what this chatbot can be expected
    to do—that is, to check the status of the order—let's create an intent that can
    actually check the order status.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4.2 – Creating the CheckOrderStatus intent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Click on the Create Intent button and enter the name of the intent as `CheckOrderStatus`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.2.1 – Entering the training phrases for the CheckOrderStatus intent**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this intent, we enter the following training phrases:'
  prefs: []
  type: TYPE_NORMAL
- en: '`What is the status for order id 12345?`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`When will my product arrive?`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`What has happened to my order?`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`When will my order arrive?`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`What''s my order status?`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that the first training phrase is different from the rest because it contains
    an order ID.
  prefs: []
  type: TYPE_NORMAL
- en: We need to be able to identify it as an order ID and use that to fetch the order
    status.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.2.2 – Extracting and saving the order ID from the input**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first training phrase of the `CheckOrderStatus` intent, double-click
    on 12345 and a menu pops up, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c98bee73-f7c7-4615-b3dc-d54da04384c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Choose @sys.number and then enter the parameter name as `OrderId`. Your training
    phrases will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76dcff96-1ac6-4b4d-a3f9-465c3f178ff2.png)'
  prefs: []
  type: TYPE_IMG
- en: But sometimes, as in the rest of the training phrases, the user will not mention
    the order ID without a prompt. Let's add a prompt and a way to store the order
    ID whenever it is found.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.2.3 – Storing the parameter and prompting if not found**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scroll down to the Actions and parameters heading in the intent creation form.
    Enter `OrderId` for PARAMETER NAME and VALUE and check the REQUIRED checkbox.
    The following screenshot should look similar to what is on your screen now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b57ad591-d3d9-41d2-927b-357920901174.png)'
  prefs: []
  type: TYPE_IMG
- en: On the right-hand side of the `OrderId` parameter, click on Define prompts to
    add a prompt for this parameter. A sample prompt could be `Sure, could you please
    let me know the Order ID? It looks like 12345!`.
  prefs: []
  type: TYPE_NORMAL
- en: We expect that after this prompt, the user will definitely state the order ID,
    which will then match the first training phrase of this intent.
  prefs: []
  type: TYPE_NORMAL
- en: After this, we need to define the response for this intent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4.2.4 – Turning on responses through Fulfillment for the CheckOrderStatus
    intent**'
  prefs: []
  type: TYPE_NORMAL
- en: Remember that this intent would need to fetch the order status from the order
    ID obtained. In such a case, a constant set of responses will not serve the purpose.
    So, we'll take the help of the Fulfillment heading in the intent creation form.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scroll down and turn on the fulfillment method webhook for this intent. This
    section now should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c9f4952-6bd9-4355-82d6-947bb003c29a.png)'
  prefs: []
  type: TYPE_IMG
- en: Fullfillment allows your Dialogflow agent to query external APIs to generate
    the response the agent has to make. The metadata associated with the query received
    by the agent is sent to the external API, which then understands and decides on
    the response the query needs to be given. This is useful for having dynamic responses
    through the chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: We must now define this webhook to handle the fetching of the order status using
    the order ID.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – Creating a webhook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll now create a webhook that will run on the Firebase cloud console and call
    an external API, which is present in our Order management portal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the Fulfillment item in the menu bar. You''ll be presented with the
    option to switch on a webhook or to use a Firebase cloud function. Turn on the
    inline editor. Your screen will resemble the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a462f840-72e8-4bd3-adda-859232692693.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll customize the two files present in the inline editor.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 – Creating a Firebase cloud function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Firebase cloud function runs on the Firebase platform and is billed as the
    provisions on the GCP project that you chose or created during the creation of
    your Dialogflow agent. You can read more about Cloud Functions at [https://dialogflow.com/docs/how-tos/getting-started-fulfillment](https://dialogflow.com/docs/how-tos/getting-started-fulfillment).
  prefs: []
  type: TYPE_NORMAL
- en: Step 6.1 – Adding the required packages to package.json
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `package.json` file on the inline editor, we''ll add the `request` and
    `request-promise-native` packages to the dependencies, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: These packages will be automatically fetched during the build of the agent,
    so you do not need to execute any commands explicitly to install them.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6.2 – Adding logic to index.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll be adding the code required to call the API of our order management
    system. Add the following function inside the `dialogflowFirebaseFulfillment`
    object definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'At the end of the file, just before ending the `dialogflowFirebaseFulfillment`
    object definition, add the mapping for the function you created previously to
    the intent that was matched in the Dialogflow agent before invoking the webhook
    call for generating a response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, click on Deploy to deploy this function. You will get notifications for
    the status of the deployment at the bottom right of the screen. Wait for the deployment
    and build to complete.
  prefs: []
  type: TYPE_NORMAL
- en: Step 7 – Adding a personality to the bot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adding a personality to the bot is more about how you chose your responses to
    be and how you drive the conversation through the responses and prompts in the
    agent.
  prefs: []
  type: TYPE_NORMAL
- en: For example, while we chose a very standard response to the inputs of the user
    in the previous example, we could definitely make it more interesting by using
    real-world language or other decorative elements in the responses. It would appear
    very realistic if instead of directly showing the output from the response fetching
    API, we added conversational decorators, such as `Great, now let me see where
    your order is...` and during the fetching and loading of the response to the agent,
    we made the Fulfillment function generate conversational fillers such as `almost
    there...`, `just getting there...`, `hmmm, let me see...`, and other fillers,
    depending on the requirements of the situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also set some interesting trivia to the chatbot using the Small Talk
    module of Dialogflow. To use it, click on the Small Talk menu item on the left
    and enable small talk. You can add several interesting responses that your bot
    will make if it gets a particular query, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/175d0651-9d60-46d8-9d33-70fc6f938486.png)'
  prefs: []
  type: TYPE_IMG
- en: Small talk is very useful for adding a very unique personality to your chatbot!
  prefs: []
  type: TYPE_NORMAL
- en: In the next step, we will be creating a UI to interact with this chatbot directly
    from the order management website. However, since we're talking about REST API-based
    interfaces, we'll most likely host this UI separately from the API that we created
    for the order management system.
  prefs: []
  type: TYPE_NORMAL
- en: This cloud function calls an HTTPS API that you will need to create. In the
    next section, we will learn how to create an API that can handle HTTPS requests
    on your local machine.
  prefs: []
  type: TYPE_NORMAL
- en: Using ngrok to facilitate HTTPS APIs on localhost
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to create your own order management system API for the cloud function
    script to work so that it can fetch the order status from the API. You can find
    a quick sample at [http://tiny.cc/omsapi](http://tiny.cc/omsapi). Your API must
    run on an HTTPS URL. To achieve this, you can use services such as PythonAnywhere
    and ngrok. While PythonAnywhere hosts your code on their servers and provides
    a fixed URL, ngrok can be installed and run locally to provide a forwarding address
    to `localhost`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say you have to run your Django project for the order management API on port
    `8000` of your system and now wish to provide an HTTPS URL so that you can test
    it; you can do so easily with ngrok by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the ngrok tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, head over to [https://ngrok.com](https://ngrok.com) and click on the
    Download button in the top navigation menu. Choose the correct version of the
    tool according to your needs and download it to your system.
  prefs: []
  type: TYPE_NORMAL
- en: Create an account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, sign up for an account on the website and go to the dashboard. You can
    use GitHub or Google authentication to set up your account quickly.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see the following dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e6d34b11-f143-43a2-bc9b-834b34f9dabc.png)'
  prefs: []
  type: TYPE_IMG
- en: Since you've already downloaded and installed the tool, you can skip directly
    to connecting your account.
  prefs: []
  type: TYPE_NORMAL
- en: Connect your ngrok account with your tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the command given on the ngrok dashboard under the *Connect your account*
    section—it contains the authtoken for your account and, on running, connects the
    ngrok tool on your system to your ngrok account on the website.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we're ready to move on to the `localhost` port.
  prefs: []
  type: TYPE_NORMAL
- en: Set up the ngrok address to forward to `localhost`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, use the following command to start forwarding all requests made to
    a randomly generated ngrok URL to `localhost`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The ngrok service starts and remains active as long as you keep the terminal
    open. You should see an output similar to the following screenshot on your screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/876ab489-46d8-4ced-92a3-32a95fbb08c4.png)'
  prefs: []
  type: TYPE_IMG
- en: All requests made to your ngrok URL will be logged on the terminal. You can
    find your ngrok URL in the `Forwarding` row of the table just above the request
    logs. Notice that both the `http` and `https` ports are being forwarded. You can
    now use the API service running on your local machine to make calls from Firebase,
    which only allows HTTPS calls.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a testing UI using Django to manage orders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've previously used Django in this book, namely in [Chapter 8](3bf31fe1-d41c-4410-a83c-1651da439c70.xhtml),
    *Deep Learning on Microsoft Azure Using Python*, and [Chapter 10](6158dd33-fac9-4a1f-867d-d53c827d7a7f.xhtml),
    *Securing Web Apps with Deep Learning*. So, we will skip over the nitty-gritty
    details of how Django works and how you can get started with it. Let's dive straight
    into creating a UI that you can interact with using your voice!
  prefs: []
  type: TYPE_NORMAL
- en: If you have not installed Django on your system already, please follow the *A
    brief introduction to Django web development* section in [Chapter 8](3bf31fe1-d41c-4410-a83c-1651da439c70.xhtml),
    *Deep Learning on Microsoft Azure Using Python*.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Creating a Django project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Every Django website is a project. To create one, use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'A directory named `ordersui` is created with the following directory structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's proceed with creating the modules for this project.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Creating an app that uses the API of the order management system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Remember that each Django project is composed of several Django apps working
    together. We will now create a Django app in this project that will consume the
    order management system API and provide a UI to see the content contained in the
    API database. This is important for verifying that the Dialogflow agent is properly
    working.
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch to the `ordersui` directory using the `cd` command in a new terminal
    or command prompt. Then, use the following command to create an app:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a directory within the `ordersui` Django project app directory
    with the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Before we begin the development of modules, let's define some project-level
    settings in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Setting up settings.py
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll now make some configurations that are required in the `ordersui/settings.py`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3.1 – Adding the apiui app to the list of installed apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the list of `INSTALLED_APPS`, add the `apiui` app, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The Django framework only includes apps during runtime that are listed in the
    `INSTALLED_APPS` directive, as in the preceding code. We will also need to define
    the database connectivity for the project, which is shown in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3.2 – Removing the database setting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll remove the database connectivity setup configuration since we don't need
    a database connection in this UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Comment out the `DATABASES` dictionary, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Save the file. With this done, we'll set up a URL route to point to the `apiui`
    routes.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Adding routes to apiui
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Change the code in `ordersui/urls.py` to add the path to include the route
    setting file inside the `apiui` app. Your file will contain the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Save the file. After setting the routes at the project level, we will need to
    set routes at the module level, as we'll do in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – Adding routes within the apiui app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''ve directed the project to use the `apiui` URL routes, we need
    to create the file required for this app. Create a file named `urls.py` within
    the `apiui` directory with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Save the file. Now that we've specified the routes available in the application,
    we need to create views for each of these routes, as we'll do in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 – Creating the views required
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the routes we created, we mentioned two views—`indexView`, which does not
    take any parameters, and `viewOrder`, which takes a parameter called `orderId`.
    Create a new file called `views.py` in the `apiui` directory and follow the next
    steps to create the views required.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6.1 – Creating indexView
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This route will simply show the orders placed on the order management system.
    We use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We will create the `viewOrder` view in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 6.2 – Creating viewOrder
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we pass an order ID to the same `/` route in the form of `/orderId`, then
    we should return the status of the order. Use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We have finished creating the different views that we will need for this project;
    however, we're yet to create the templates they will be rendering. Let's create
    the templates required in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 7 – Creating the templates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the view we defined previously, we used two templates—`index.html` and `view.html`.
    But to make them appear in sync with the design, we'll also set up a `base.html`
    template, which will be the master template for the rest of the view templates
    in the UI.
  prefs: []
  type: TYPE_NORMAL
- en: Since the templates are mostly just HTML boilerplate with little consequence
    to the vital content of the website, we have provided the code for these files
    at [http://tiny.cc/ordersui-templates](http://tiny.cc/ordersui-templates). You'll
    have to save the template files in a folder named `templates` inside the `apiui`
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this stage, you''ll be able to start up the Django project server and check
    out the website on your browser by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now that our server is running, we will create a voice interface around it in
    the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition and speech synthesis on a web page using the Web Speech API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A recent and very exciting development in the domain of web development is
    the introduction of the Web Speech API. While Google has rolled out full support
    for the Web Speech API in Google Chrome browsers for both desktop and Android,
    Safari and Firefox only have partial implementations available. The Web Speech
    API consists primarily of two components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech synthesis**: More popularly known as **TTS**. It performs the action
    of generating voice narration for any given text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech recognition**: Also known as **STT**. It performs the function of
    recognizing the words spoken by the user and converting them into corresponding
    text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can go through the very detailed documentation of the Web Speech API, which
    is available at the Mozilla documentation page ( [http://tiny.cc/webspeech-moz](http://tiny.cc/webspeech-moz)
    ). You can find a demonstration of the technology provided by Google at [http://tiny.cc/webspeech-demo](http://tiny.cc/webspeech-demo):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a516e800-2a10-471f-84b2-c76d65e116c1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following steps, we'll add a Web Speech API-based Ask a question button
    to our website UI.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Creating the button element
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the code in this section has to be put into the `base.html` template of
    the UI so that it is available on all of the pages of the website.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the following code to quickly create a button with the Ask a question
    text that will be at the bottom-right corner of the web page sitewide:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, we will need to initialize and configure the Web Speech API, as we will
    do in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Initializing the Web Speech API and performing configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When the web page has finished loading, we need to initialize the Web Speech
    API object and set the necessary configurations for it. To do so, use the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that we''ve initialized a web `SpeechRecognition` API object and
    then performed some configurations on it. Let''s try to understand these configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`recognition.interimResults` (Boolean) directs whether the API should attempt
    to recognize interim results or words that are yet to be spoken. This would add
    overhead to our use case and so is turned off. Having it turned on is more beneficial
    in situations where the speed of the transcription matters more than the accuracy
    of the transcription, such as when generating live transcriptions for a person
    speaking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recognition.maxAlternatives` (number) tells the browser how many alternatives
    can be produced for the same speech segment. This is useful in cases where it
    is not very clear to the browser what was said and the user can be given an option
    to choose the correct recognition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recognition.continuous` (Boolean) tells the browser whether the audio has
    to be captured continuously or whether it should stop after recognizing the speech
    once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, we''ve not yet defined the code that is executed when a result is
    received after performing STT. We do so by adding code to the `recognition.onresult`
    function, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The preceding block of code creates an interim transcript while the user is
    speaking, which is continually updated as more words are spoken. When the user
    stops speaking, the interim transcript is appended to the final transcript and
    passed to the function handling the interaction with Dialogflow. After the response
    is received from the Dialogflow agent, the final transcript is reset for the next
    voice input from the user.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we've sent the final recognized transcript of the user's speech
    to a function named `goDialogFlow()`. Let's define this function.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Making a call to the Dialogflow agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have the text version of the user''s speech-based query, we will send
    it to the Dialogflow agent, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You'll observe that when the API call succeeds, we use the SpeechSynthesis API
    to speak out the result to the user. Its usage is much more simple than the SpeechRecognition
    API and so is the first of the two to appear on Firefox and Safari.
  prefs: []
  type: TYPE_NORMAL
- en: Notice the API URL used in the preceding function. It might look weird currently
    and you might wonder where we obtained this URL from. What we did was essentially
    skip the requirement of setting the Dialogflow agent service account configurations
    using the terminal, which is always local to the system the script is working
    on and is so difficult to transport.
  prefs: []
  type: TYPE_NORMAL
- en: To obtain a similar URL for your project, follow along with the following steps;
    otherwise, skip *step 4* and move directly on to *step 5*.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Creating a Dialogflow API proxy on Dialogflow Gateway by Ushakov
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Head over to [https://dialogflow.cloud.ushakov.co/](https://dialogflow.cloud.ushakov.co/).
    You''ll be presented with an interface, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2de7c84c-4fa8-4746-9387-f965726690e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Dialogflow Gateway facilitates the interactions between your voice UI and the
    Dialogflow agent. This is very useful in situations where our project is hosted
    as a static website. Dialogflow Gateway provides simplified API wrappers around
    the Dialogflow API and is very easy to use.
  prefs: []
  type: TYPE_NORMAL
- en: You'll have to create an account to get started with Dialogflow, shown in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4.1 – Creating an account on Dialogflow Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Click on Get Started to begin the account creation process on the platform.
    You'll be asked to sign in with your Google account. Make sure you use the same
    account that you used to create the Dialogflow agent previously.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4.2 – Creating a service account for your Dialogflow agent project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We previously discussed in detail how to create a service account for GCP projects
    in [Chapter 6](093890b6-051d-49f9-9330-bdd58b92a762.xhtml), *Deep Learning on
    Google Cloud Platform Using Python*. Create a new service key for the project
    linked to your Dialogflow agent, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad8232d2-aff2-47bb-8654-343e8a131ef2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the key has been created successfully, a dialog box will pop up, telling
    you that the key has been saved to your computer, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/caea516d-c88e-49ce-9a31-be83ead57a5b.png)'
  prefs: []
  type: TYPE_IMG
- en: The service account credentials are downloaded to your local system in the form
    of JSON, with the name as shown in the preceding screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will use this service account credentials file to connect Dialogflow
    Gateway to our Dialogflow agent.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4.3 – Uploading the service key file to Dialogflow Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On the Dialogflow Gateway console, you''ll find the Upload Keys button. Click
    on it to upload your generated service account key file. Once uploaded, the console
    will display your Dialogflow API proxy URLs, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0dc2a2ff-d5ff-43e8-9208-afb12d3facbb.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll use the Gateway URL in the function we defined previously.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – Adding a click handler for the button
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, we add a `click` handler to the Ask a question button so that it can
    trigger the speech recognition of the user input and the synthesis of output from
    the Dialogflow agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the document `ready` function defined in *step 2*, add the following
    `click` handler code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Now, when the microphone starts listening for the user input, the button text
    changes to Speak!, prompting the user to start speaking.
  prefs: []
  type: TYPE_NORMAL
- en: Try testing the website on your setup and see how accurately you can get it
    to work!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we combined several technologies to come up with an end-to-end
    project that demonstrates one of the most rapidly growing aspects of applying
    deep learning to websites. We covered tools such as Dialogflow, Dialogflow Gateway,
    GCP IAM, Firebase Cloud Functions, and ngrok. We also demonstrated how to build
    a REST API-based UI and how to make it accessible using the Web Speech API. The
    Web Speech API, although presently at a nascent stage, is a cutting-edge piece
    of technology used in web browsers and is expected to grow rapidly in the coming
    years.
  prefs: []
  type: TYPE_NORMAL
- en: It is safe to say that deep learning on the web has huge potential and will
    be a key factor in the success of many upcoming businesses. In the next chapter,
    we'll explore some of the hottest research areas in deep learning for web development
    and how we can plan to progress in the best way.
  prefs: []
  type: TYPE_NORMAL
