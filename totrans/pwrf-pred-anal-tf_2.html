<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;Putting Data in Place &#x2013; Supervised Learning for Predictive Analytics"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Putting Data in Place – Supervised Learning for Predictive Analytics</h1></div></div></div><p>In this lesson, we will discuss supervised learning from the theoretical and practical perspective. In particular, we will revisit the linear regression model for regression analysis discussed in <a class="link" href="ch01.html" title="Chapter 1. From Data to Decisions – Getting Started with TensorFlow">Lesson 1</a>, <span class="emphasis"><em>From Data to Decisions – Getting Started with TensorFlow</em></span>, using a real dataset. Then we will see how to develop Titanic survival predictive models using <span class="strong"><strong>Logistic Regression</strong></span> (<span class="strong"><strong>LR</strong></span>), Random Forests, and <span class="strong"><strong>Support Vector Machines</strong></span> (<span class="strong"><strong>SVMs</strong></span>).</p><p>In a nutshell, the following topics will be covered in this lesson:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Supervised learning for predictive analytics</li><li class="listitem" style="list-style-type: disc">Linear regression for predictive analytics: revisited</li><li class="listitem" style="list-style-type: disc">Logistic regression for predictive analytics</li><li class="listitem" style="list-style-type: disc">Random forests for predictive analytics</li><li class="listitem" style="list-style-type: disc">SVMs for predictive analytics</li><li class="listitem" style="list-style-type: disc">A comparative analysis</li></ul></div><div class="section" title="Supervised Learning for Predictive Analytics"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec15"/>Supervised Learning for Predictive Analytics</h1></div></div></div><p>Depending on the nature of the learning feedback available, the machine learning process is typically classified into three broad categories: supervised learning, unsupervised learning, and reinforcement learning—see figure 1. A predictive model based on supervised learning algorithms can make predictions based on a labelled dataset that map inputs to outputs aligning with the real world.</p><p>For example, a dataset for spam filtering usually contains spam messages as well as not-spam messages. Therefore, we could know which messages in the training set are spam and which are ham. Nevertheless, we might have the opportunity to use this information to train our model in order to classify new unseen messages:</p><div class="mediaobject"><img alt="Supervised Learning for Predictive Analytics" src="graphics/02_01.jpg"/><div class="caption"><p>Figure 1: Machine learning tasks (containing a few algorithms only)</p></div></div><p>The following figure shows the schematic diagram of supervised learning. After the algorithm has found the required patterns, those patterns can be used to make predictions for unlabeled test data:</p><div class="mediaobject"><img alt="Supervised Learning for Predictive Analytics" src="graphics/02_02.jpg"/><div class="caption"><p>Figure 2: Supervised learning in action</p></div></div><p>Examples include classification and regression for solving supervised learning problems so that predictive models can be built for predictive analytics based on them. We will provide several examples of supervised learning like linear regression, logistic regression, random forest, decision trees, Naive Bayes, multilayer perceptron, and so on.</p><p>In this lesson, we will mainly focus on the supervised learning algorithms for predictive analytics. Let's start from the very simple linear regression algorithm.</p></div></div>
<div class="section" title="Linear Regression &#x2013; Revisited"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec16"/>Linear Regression – Revisited</h1></div></div></div><p>In <a class="link" href="ch01.html" title="Chapter 1. From Data to Decisions – Getting Started with TensorFlow">Lesson 1</a>, <span class="emphasis"><em>From Data to Decisions – Getting Started with TensorFlow</em></span> we have seen an example of linear regression. We have observed how to work TensorFlow on the randomly generated dataset, that is, fake data. We have seen that the regression is a type of supervised machine learning for predicting the continuous-valued output. However, running a linear regression on fake data is just like buying a new car and never driving it. This awesome machinery begs to manifest itself in the real world!</p><p>Fortunately, many datasets are available online to test your new-found knowledge of regression:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The University of Massachusetts Amherst supplies small datasets of various types: <a class="ulink" href="http://www.umass.edu/statdata/statdata/">http://www.umass.edu/statdata/statdata/</a></li><li class="listitem" style="list-style-type: disc">Kaggle contains all types of large-scale data for machine learning competitions: <a class="ulink" href="https://www.kaggle.com/datasets">https://www.kaggle.com/datasets</a></li><li class="listitem" style="list-style-type: disc">Data.gov is an open data initiative by the US government, which contains many interesting and practical datasets: <a class="ulink" href="https://catalog.data.gov">https://catalog.data.gov</a></li></ul></div><p>Therefore, in this section, by defining a set of models, we will see how to reduce the search space of possible functions. Moreover, TensorFlow takes advantage of the differentiable property of the functions by running its efficient gradient descent optimizers to learn the parameters. To avoid overfitting our data, we regularize the cost function by penalizing larger valued parameters.</p><p>The linear regression is shown in <a class="link" href="ch01.html" title="Chapter 1. From Data to Decisions – Getting Started with TensorFlow">Lesson 1</a>, <span class="emphasis"><em>From Data to Decision – Getting Started with TensorFlow</em></span>, shows some tensors that just contained a single scalar value, but you can, of course, perform computations on arrays of any shape. In TensorFlow, operations such as addition and multiplication take two inputs and produce an output. In contrast, constants and variables do not take any input. We will also see an example of how TensorFlow can manipulate 2D arrays to perform linear regression like operations.</p><div class="section" title="Problem Statement"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec15"/>Problem Statement</h2></div></div></div><p>Online movie ratings and recommendations have become a serious business around the world. For example, Hollywood generates about $10 billion at the U.S. box office each year. Websites like Rotten Tomatoes aggregates movie reviews into one overall rating and also reports poor opening weekends. Although a single movie critic or a single negative review can't make or break a film, thousands of reviews and critics do.</p><p>Rotten Tomatoes, Metacritic, and IMDb have their own way of aggregating film reviews and distinct rating systems. On the other hand, Fandango, an NBCUniversal subsidiary uses a five-star rating system in which most of the movies get at least three stars, according to a FiveThirtyEight analysis.</p><p>An exploratory analysis of the dataset used by Fandango shows that out of 510 films, 437 films got at least one review where, hilariously, 98% had a 3-star rating or higher and 75 percent had a 4-star rating or higher. This implies, that using Fandango's standards it's almost impossible for a movie to be a flop at the box office. Therefore, Fandango's rating is biased and skewed:</p><div class="mediaobject"><img alt="Problem Statement" src="graphics/02_03.jpg"/><div class="caption"><p>Figure 3: Fandango's lopsided ratings curve</p></div><div class="caption"><p>(Source: <a class="ulink" href="https://fivethirtyeight.com/features/fandango-movies-ratings/">https://fivethirtyeight.com/features/fandango-movies-ratings/</a>)</p></div></div><p>Since the ratings from Fandango are unreliable, we will instead predict our own ratings based on IMDb ratings. More specifically, this is a multivariate regression problem, since our predictive model will use multiple features to make the rating prediction having many predictors.</p><p>Fortunately, the data is small enough to fit in memory, so plain batch learning should do just fine. Considering these factors and need, we will see that linear regression will meet our requirements. However, for more robust regression, you can still use deep neural network based regression techniques such as deep belief networks Regressor.</p></div><div class="section" title="Using Linear Regression for Movie Rating Prediction"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec16"/>Using Linear Regression for Movie Rating Prediction</h2></div></div></div><p>Now, the first task is downloading the Fandango's rating dataset from GitHub at <a class="ulink" href="https://github.com/fivethirtyeight/data/tree/master/fandango">https://github.com/fivethirtyeight/data/tree/master/fandango</a>. It contains every film that has a Rotten Tomatoes rating, an RT user rating, a Metacritic score, a Metacritic user score, IMDb score, and at least 30 fan reviews on Fandango.</p><p>Table 1: Description of the columns in fandango_score_comparison.csv</p><p>The dataset has 22 columns that can be described as follows:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Column</p>
</th><th style="text-align: left" valign="bottom">
<p>Definition</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">FILM</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Name of the film.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">RottenTomatoes</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Corresponding Tomatometer score for the film by Rotten Tomatoes.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">RottenTomatoes_User</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Rotten Tomatoes user score for the film.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Metacritic critic score for the film.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic_User</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Metacritic user score for the film.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">IMDB</code>
</p>
</td><td style="text-align: left" valign="top">
<p>IMDb user score for the film.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Fandango_Stars</code>
</p>
</td><td style="text-align: left" valign="top">
<p>A number of stars the film had on its Fandango movie page.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Fandango_Ratingvalue</code>
</p>
</td><td style="text-align: left" valign="top">
<p>The Fandango rating value for the film, as pulled from the HTML of each page. This is the actual average score the movie obtained.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">RT_norm</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Tomatometer score for the film. It is normalized to a 0 to 5 point system.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">RT_user_norm</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Rotten Tomatoes user score for the film. It is normalized to a 0 to 5 point system.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic_norm</code>
</p>
</td><td style="text-align: left" valign="top">
<p>The Metacritic critic scores for the film. It is normalized to a 0 to 5 point system.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic_user_nom</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Metacritic user score for the film, normalized to a0 to 5 point system.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">IMDB_norm</code>
</p>
</td><td style="text-align: left" valign="top">
<p>IMDb user score for the film which is normalized to a 0 to 5 point system.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">RT_norm_round</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Rotten Tomatoes Tomatometer score for the film which is normalized to a 0 to 5 point system and rounded to the nearest half-star.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">RT_user_norm_round</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Rotten Tomatoes user score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic_norm_round</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Metacritic critic score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic_user_norm_round</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Metacritic user score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">IMDB_norm_round</code>
</p>
</td><td style="text-align: left" valign="top">
<p>IMDb user score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Metacritic_user_vote_count</code>
</p>
</td><td style="text-align: left" valign="top">
<p>A number of user votes the film had on Metacritic.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">IMDB_user_vote_count</code>
</p>
</td><td style="text-align: left" valign="top">
<p>A number of user votes the film had on IMDb.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Fandango_votes</code>
</p>
</td><td style="text-align: left" valign="top">
<p>A number of user votes the film had on Fandango.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">Fandango_Difference</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Difference between the presented <code class="literal">Fandango_Stars</code> and the actual <code class="literal">Fandango_Ratingvalue</code>.</p>
</td></tr></tbody></table></div><p>We have already seen that a typical linear regression problem using TensorFlow has the following workflow that updates the parameters to minimize the given cost function of Fandango's lopsided rating curve:</p><div class="mediaobject"><img alt="Using Linear Regression for Movie Rating Prediction" src="graphics/02_04.jpg"/><div class="caption"><p>Figure 4: The learning algorithm using linear regression in TensorFlow</p></div></div><p>Now, let's try to follow the preceding figure and reproduce the same for the linear regression:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the required libraries:<div class="informalexample"><pre class="programlisting">import numpy as np
import pandas as pd
from scipy import stats
import sklearn
from sklearn.model_selection import train_test_split
import tensorflow as tf
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns</pre></div></li><li class="listitem">Read the dataset and create a Panda DataFrame:<div class="informalexample"><pre class="programlisting">df = pd.read_csv('fandango_score_comparison.csv')
print(df.head())</pre></div><p>The output is as follows:</p><div class="mediaobject"><img alt="Using Linear Regression for Movie Rating Prediction" src="graphics/02_05.jpg"/><div class="caption"><p>Figure 5: A snap of the dataset showing a typo in the Metacritic_user_nom</p></div></div><p>So, if you look at the preceding DataFrame carefully, there is a typo that could cause a disaster. From our intuition, it is clear that <code class="literal">Metacritic_user_nom</code> should have actually been <code class="literal">Metacritic_user_norm</code>. Let's rename it to avoid further confusion:</p><div class="informalexample"><pre class="programlisting">df.rename(columns={'Metacritic_user_nom':'Metacritic_user_norm'}, inplace=True)</pre></div><p>Moreover, according to a statistical analysis at <a class="ulink" href="https://fivethirtyeight.com/features/fandango-movies-ratings">https://fivethirtyeight.com/features/fandango-movies-ratings</a>/, all the variables don't contribute equally; the following columns have more importance in ranking the movies:</p><div class="informalexample"><pre class="programlisting"> 'Fandango_Stars',
'RT_user_norm',
'RT_norm',
'IMDB_norm',
'Metacritic_user_norm',
'Metacritic_norm'</pre></div><p>Now we can check the correlation coefficients between variables before build the LR model. First, let's create a ranking list for that:</p><div class="informalexample"><pre class="programlisting">rankings_lst = ['Fandango_Stars',
                'RT_user_norm',
                'RT_norm',
                'IMDB_norm',
                'Metacritic_user_norm',
                'Metacritic_norm']</pre></div><p>The following function computes the <code class="literal">Pearson</code> correlation coefficients and builds a full correlation matrix:</p><div class="informalexample"><pre class="programlisting">def my_heatmap(df):    
    import seaborn as sns    
    fig, axes = plt.subplots()
    sns.heatmap(df, annot=True)
    plt.show()
    plt.close()</pre></div><p>Let's call the preceding method to plot the matrix as follows:</p><div class="informalexample"><pre class="programlisting">my_heatmap(df[rankings_lst].corr(method='pearson'))</pre></div><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note12"/>Note</h3><p>
<span class="strong"><strong>Pearson correlation coefficients</strong></span>: A measure of the strength of the linear relationship between two variables. If the relationship between the variables is not linear, then the correlation coefficient cannot accurately and adequately represent the strength of the relationship between those two variables. It is often represented as "ρ" when measured on population and "r" when measured on a sample. Statistically, the range is -1 to 1, where -1 indicates a perfect negative linear relationship, an r of 0 indicates no linear relationship, and an r of 1 indicates a perfect positive linear relationship between variables.</p></div></div><p>The following correlation matrix shows correlation between considered features using the Pearson correlation coefficients:</p><div class="mediaobject"><img alt="Using Linear Regression for Movie Rating Prediction" src="graphics/02_06.jpg"/><div class="caption"><p>Figure 6: The correlation matrix on the ranking list movies</p></div></div><p>So, the correlation between Fandango and Metacritic is still positive. Now, let's do another study by considering only the movies for which RT has provided at least a 4-star rating:</p><div class="informalexample"><pre class="programlisting">RT_lst = df['RT_norm'] &gt;= 4.
my_heatmap(df[RT_lst][rankings_lst].corr(method='pearson'))
&gt;&gt;&gt;</pre></div><p>The output is the correlation matrix on the ranked movies and RT movies having ratings of at least 4 showing a correlation between considered features using the Pearson correlation coefficients:</p><div class="mediaobject"><img alt="Using Linear Regression for Movie Rating Prediction" src="graphics/02_07.jpg"/><div class="caption"><p>Figure 7: The correlation matrix on the ranked movies and RT movies having ratings at least 4</p></div></div><p>This time, we have obtained anticorrelation (that is, negative correlation) between Fandango and Metacritic, with the correlation coefficient-0.23. This means that the correlation of Metacritic in terms of Fandango is significantly biased toward high ratings.</p><p>Therefore, we can train our model without considering Fandango's rating, but before that let's build the LR model using this first. Later on, we will decide which option would produce a better result eventually.</p></li><li class="listitem">Preparing the training and test sets.<p>Let's create a feature matrix <code class="literal">X</code> by selecting two DataFrame columns:</p><div class="informalexample"><pre class="programlisting">feature_cols = ['Fandango_Stars', 'RT_user_norm', 'RT_norm', 'Metacritic_user_norm', 'Metacritic_norm']
X = df.loc[:, feature_cols]</pre></div><p>Here, I have used only the selected column as features and now we need to create a response vector <code class="literal">y</code>:</p><div class="informalexample"><pre class="programlisting">y = df['IMDB_norm']</pre></div><p>We are assuming that the IMDB is the most reliable and the baseline source of ratings. Our ultimate target is to predict the rating of each movie and compare the predicted ratings with the response column <code class="literal">IMDB_norm</code>.</p><p>Now that we have the features and the response columns, it's time to split data into training and testing sets:</p><div class="informalexample"><pre class="programlisting">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=43)</pre></div><p>If you want to change the <code class="literal">random_state</code>, it helps you generate pseudo-random numbers for a random sampling value to obtain differentfinal results.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note13"/>Note</h3><p>
<span class="strong"><strong>Random state</strong></span>: As the name sounds can be used for initializing the internal random number generator, which will decide the splitting of data into train and test indices. This also signifies that every time you run it without specifying <code class="literal">random_state</code>, you will get a different result, this is expected behavior. So, we can have the following three options:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">If <code class="literal">random_state</code> is None (or <code class="literal">np.random</code>), a randomly-initialized <code class="literal">RandomState</code> object is returned</li><li class="listitem" style="list-style-type: disc">If <code class="literal">random_state</code> is an integer, it is used to seed a new <code class="literal">RandomState</code> object</li><li class="listitem" style="list-style-type: disc">If <code class="literal">random_state</code> is a <code class="literal">RandomState</code> object, it is passed through</li></ul></div></div></div><p>Now, we need to have the dimension of the dataset to be passed through the tensors:</p><div class="informalexample"><pre class="programlisting">dim = len(feature_cols)</pre></div><p>We need to include an extra dimension for independent coefficient:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">dim += 1</code>
</pre></div><p>And so we need to create an extra column for the independent coefficient in the training set and test feature set as well:</p><div class="informalexample"><pre class="programlisting">X_train = X_train.assign( independent = pd.Series([1] * len(y_train), index=X_train.index))
X_test = X_test.assign( independent = pd.Series([1] * len(y_train), index=X_test.index))</pre></div><p>So far, we have used and utilized the panda DataFrames but converting it into tensors is troublesome so instead let's convert them into a NumPy array:</p><div class="informalexample"><pre class="programlisting">P_train = X_train.as_matrix(columns=None)
P_test = X_test.as_matrix(columns=None)

q_train = np.array(y_train.values).reshape(-1,1)
q_test = np.array(y_test.values).reshape(-1,1)</pre></div></li><li class="listitem">Creating a place holder for TensorFlow.<p>Now that we have all the training and test sets, before initializing these variables, we have to create the place holder for TensorFlow to feed the training sets across the tensors:</p><div class="informalexample"><pre class="programlisting">P = tf.placeholder(tf.float32,[None,dim])
q = tf.placeholder(tf.float32,[None,1])
T = tf.Variable(tf.ones([dim,1]))</pre></div><p>Let's add some bias to differing from the value in the case where both types are quantized as follows:</p><div class="informalexample"><pre class="programlisting">bias = tf.Variable(tf.constant(1.0, shape = [n_dim]))
q_ = tf.add(tf.matmul(P, T),bias)</pre></div></li><li class="listitem">Creating an optimizer.<p>Let's create an optimizer for the objective function:</p><div class="informalexample"><pre class="programlisting">cost = tf.reduce_mean(tf.square(q_ - q))
learning_rate = 0.0001
training_op = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)</pre></div></li><li class="listitem">Initializing global variables:<div class="informalexample"><pre class="programlisting">init_op = tf.global_variables_initializer()
cost_history = np.empty(shape=[1],dtype=float)</pre></div></li><li class="listitem">Training the LR model.<p>Here we are iterating the training 50,000 times and tracking several parameters, such as means square error that signifies how good the training is; we are keeping the cost history for future visualization, and so on:</p><div class="informalexample"><pre class="programlisting">training_epochs = 50000
with tf.Session() as sess:
    sess.run(init_op)
    cost_history = np.empty(shape=[1], dtype=float)
    t_history = np.empty(shape=[dim, 1], dtype=float)
    for epoch in range(training_epochs):
        sess.run(training_op, feed_dict={P: P_train, q: q_train})
        cost_history = np.append(cost_history, sess.run(cost, feed_dict={P: P_train, q: q_train}))
        t_history = np.append(t_history, sess.run(T, feed_dict={P: P_train, q: q_train}), axis=1)
    q_pred = sess.run(q_, feed_dict={P: P_test})[:, 0]
    mse = tf.reduce_mean(tf.square(q_pred - q_test))
    mse_temp = mse.eval()
    sess.close()</pre></div><p>Finally, we evaluate the <code class="literal">mse</code> to get the scalar value out of the training evaluation on the test set. Now, let's compute the <code class="literal">mse</code> and <code class="literal">rmse</code> values, as follows:</p><div class="informalexample"><pre class="programlisting">print(mse_temp)
RMSE = math.sqrt(mse_temp)
print(RMSE)
&gt;&gt;&gt; 
0.425983107542
0.6526738140461913</pre></div><p>You can also change the feature column, as follows:</p><div class="informalexample"><pre class="programlisting">feature_cols = ['RT_user_norm', 'RT_norm', 'Metacritic_user_norm', 'Metacritic_norm']</pre></div><p>Now that we are not considering the Fandango's stars, I experienced the following result of <code class="literal">mse</code> and <code class="literal">rmse</code> respectively:</p><div class="informalexample"><pre class="programlisting">0.426362842426
0.6529646563375979</pre></div></li><li class="listitem">Observing the training cost throughout iterations:<div class="informalexample"><pre class="programlisting">
<code class="literal">fig, axes = plt.subplots()</code>
<code class="literal">plt.plot(range(len(cost_history)), cost_history)</code>
<code class="literal">axes.set_xlim(xmin=0.95)</code>
<code class="literal">axes.set_ylim(ymin=1.e-2)</code>
<code class="literal">axes.set_xscale("log", nonposx='clip')</code>
<code class="literal">axes.set_yscale("log", nonposy='clip')</code>
<code class="literal">axes.set_ylabel('Training cost')</code>
<code class="literal">axes.set_xlabel('Iterations')</code>
<code class="literal">axes.set_title('Learning rate = ' + str(learning_rate))</code>
<code class="literal">plt.show()</code>
<code class="literal">plt.close()</code>
<code class="literal">&gt;&gt;&gt;</code>
</pre></div><p>The output is as follows:</p><div class="mediaobject"><img alt="Using Linear Regression for Movie Rating Prediction" src="graphics/02_08.jpg"/><div class="caption"><p>Figure 8: The training and training cost become saturated after 10000 iterations</p></div></div><p>The preceding graph shows that the training cost becomes saturated after 10,000 iterations. This also means that, even if you iterate the model more than 10,000 times, the cost is not going to experience a significant decrease.</p></li><li class="listitem">Evaluating the model:<div class="informalexample"><pre class="programlisting">predictedDF = X_test.copy(deep=True)
predictedDF.insert(loc=0, column='IMDB_norm_predicted', value=pd.Series(data=q_pred, index=predictedDF.index))
predictedDF.insert(loc=0, column='IMDB_norm_actual', value=q_test)

print('Predicted vs actual rating using LR with TensorFlow')
print(predictedDF[['IMDB_norm_actual', 'IMDB_norm_predicted']].head())print(predictedDF[['IMDB_norm_actual', 'IMDB_norm_predicted']].tail())
&gt;&gt;&gt;</pre></div><p>The following shows the predicted versus actual rating using LR:</p><div class="informalexample"><pre class="programlisting">          IMDB_norm_actual  IMDB_norm_predicted
45              3.30              3.232061
50              3.35              3.381659
98              3.05              2.869175
119             3.60              3.796200
133             2.15              2.521702
140             4.30              4.033006
143             3.70              3.816177
42              4.10              3.996275
90              3.05              3.226954
40              3.45              3.509809</pre></div><p>We can see that the prediction is a continuous value. Now it's time to see how well the LR model generalizes and fits to the regression line:</p><div class="informalexample"><pre class="programlisting">How the LR fit with the predicted data points:
plt.scatter(q_test, q_pred, color='blue', alpha=0.5)
plt.plot([q_test.min(), q_test.max()], [q_test.min(), q_test.max()], '--', lw=1)
plt.title('Predicted vs Actual')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()
plt.show()

&gt;&gt;&gt;</pre></div><p>The output is as follows:</p><div class="mediaobject"><img alt="Using Linear Regression for Movie Rating Prediction" src="graphics/02_09.jpg"/><div class="caption"><p>Figure 9: Prediction made by the LR model</p></div></div><p>The graph does not tell us that the prediction made by the LR model is good or bad. But we can still improve the performance of such models using layer architectures such as deep neural networks.</p><p>The next example is about applying other supervised learning algorithms such as logistic regression, support vector machines, and random forest for predictive analytics.</p></li></ol></div></div></div>
<div class="section" title="From Disaster to Decision &#x2013; Titanic Example Revisited"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec17"/>From Disaster to Decision – Titanic Example Revisited</h1></div></div></div><p>In <a class="link" href="ch01.html" title="Chapter 1. From Data to Decisions – Getting Started with TensorFlow">Lesson 1</a>, <span class="emphasis"><em>From Data to Decisions – Getting Started with TensorFlow</em></span>, we have seen a minimal data analysis of the Titanic dataset. Now it's our turn to do some analytics on top of the data. Let's look at what kinds of people survived the disaster.</p><p>Since we have enough data, but how could we do the predictive modeling so that we can draw some fairly straightforward conclusions from this data? For example, being a woman, being in first class, and being a child were all factors that could boost a passengers chances of survival during this disaster.</p><p>Using the brute-force approach such as if-else statements with some sort of weighted scoring system, you could write a program to predict whether a given passenger would survive the disaster. However, writing such a program in Python does not make much sense. Naturally, it would be very tedious to write, difficult to generalize, and would require extensive fine-tuning for each variable and samples (that is, each passenger):</p><div class="mediaobject"><img alt="From Disaster to Decision – Titanic Example Revisited" src="graphics/02_10.jpg"/><div class="caption"><p>Figure 10: A regression algorithm is meant to produce continuous output</p></div></div><p>At this point, you might have confusion in your mind about what the basic difference between a classification and a regression problem is. Well, a regression algorithm is meant to produce continuous output. The input is allowed to be either discrete or continuous. In contrast, a classification algorithm is meant to produce discrete output from an input from a set of discrete or continuous values. This distinction is important to know because discrete-valued outputs are handled better by classification, which will be discussed in upcoming sections:</p><div class="mediaobject"><img alt="From Disaster to Decision – Titanic Example Revisited" src="graphics/02_11.jpg"/><div class="caption"><p>Figure 11: A classification algorithm is meant to produce discrete output</p></div></div><p>In this section, we will see how we could develop several predictive models for Titanic survival prediction and do some analytics using them. In particular, we will discuss logistic regression, random forest, and linear SVM. We start with logistic regression. Then we go with SVM since the number of features is not that large. Finally, we will see how we could improve the performance using Random Forests. However, before diving in too deeply, a short exploratory analysis of the dataset is required.</p><div class="section" title="An Exploratory Analysis of the Titanic Dataset"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec17"/>An Exploratory Analysis of the Titanic Dataset</h2></div></div></div><p>We will see how the variables contribute to survival. At first, we need to import the required packages:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">import os</code>
<code class="literal">import pandas as pd</code>
<code class="literal">import numpy as np</code>
<code class="literal">import seaborn as sns</code>
<code class="literal">import matplotlib.pyplot as plt</code>
<code class="literal">from sklearn.model_selection import train_test_split</code>
<code class="literal">from sklearn.metrics import classification_report</code>
<code class="literal">import shutil</code>
</pre></div><p>Now, let's load the data and check what the features available to us are:</p><div class="informalexample"><pre class="programlisting">train = pd.read_csv(os.path.join('input', 'train.csv'))
test = pd.read_csv(os.path.join('input', 'test.csv'))
print("Information about the data")
print(train.info())
&gt;&gt;&gt; 
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object</pre></div><p>So, the training dataset has <code class="literal">12</code> columns and <code class="literal">891</code> rows altogether. Also, the <code class="literal">Age</code>, <code class="literal">Cabin</code>, and <code class="literal">Embarked</code> columns have null or missing values. We will take care of the null values in the feature engineering section, but for the time being, let's see how many have survived:</p><div class="informalexample"><pre class="programlisting">print("How many have survived?")
print(train.Survived.value_counts(normalize=True))
count_plot = sns.countplot(train.Survived)
count_plot.get_figure().savefig("survived_count.png")
&gt;&gt;&gt;</pre></div><p>How many have survived?</p><div class="informalexample"><pre class="programlisting">0    0.616162
1    0.383838</pre></div><p>So, approximately 61% died and only 39% of passengers managed to survive as shown in the following figure:</p><div class="mediaobject"><img alt="An Exploratory Analysis of the Titanic Dataset" src="graphics/02_12.jpg"/><div class="caption"><p>Figure 12: Survived versus dead from the Titanic training set</p></div></div><p>Now, what is the relationship between the class and the rate of survival? At first we should see the counts for each class:</p><div class="informalexample"><pre class="programlisting">train['Name_Title'] = train['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])
print('Title count')
print(train['Name_Title'].value_counts())
print('Survived by title')
print(train['Survived'].groupby(train['Name_Title']).mean())
&gt;&gt;&gt; 	
Title      count
Mr.          517
Miss.        182
Mrs.         125
Master.       40
Dr.            7
Rev.           6
Mlle.          2
Col.           2
Major.         2
Sir.           1
Jonkheer.      1
Lady.          1
Capt.          1
the            1
Don.           1
Ms.            1
Mme.           1</pre></div><p>As you may remember from the movie (that is, Titanic 1997), people from higher classes had better chances of surviving. So, you may assume that the title could be an important factor in survival, too. Another funny thing is that people with longer names have a higher probability of survival. This happens due to most of the people with longer names being married ladies whose husband or family members probably helped them to survive:</p><div class="informalexample"><pre class="programlisting">train['Name_Len'] = train['Name'].apply(lambda x: len(x))
print('Survived by name length')
print(train['Survived'].groupby(pd.qcut(train['Name_Len'],5)).mean())
&gt;&gt;&gt;
Survived by name length 
(11.999, 19.0]    0.220588
(19.0, 23.0]      0.301282
(23.0, 27.0]      0.319797
(27.0, 32.0]      0.442424
(32.0, 82.0]      0.674556</pre></div><p>Women and children had a higher chance to survive, since they are the first to evacuate the shipwreck:</p><div class="informalexample"><pre class="programlisting">print('Survived by sex')
print(train['Survived'].groupby(train['Sex']).mean())
&gt;&gt;&gt; 
Survived by sex
Sex
female    0.742038
male      0.188908</pre></div><p>Cabin has the most nulls (almost 700), but we can still extract information from it, like the first letter of each cabin. Therefore, we can see that most of the cabin letters are associated with survival rate:</p><div class="informalexample"><pre class="programlisting">train['Cabin_Letter'] = train['Cabin'].apply(lambda x: str(x)[0])
print('Survived by Cabin_Letter')
print(train['Survived'].groupby(train['Cabin_Letter']).mean())
&gt;&gt;&gt;
Survived by Cabin_Letter
A    0.466667
B    0.744681
C    0.593220
D    0.757576
E    0.750000
F    0.615385
G    0.500000
T    0.000000
n    0.299854</pre></div><p>Finally, it also seems that people who embarked at Cherbourg had a 20% higher survival rate than those embarked at other embarking locations. This is very likely due to the high percentage of upper-class passengers from that location:</p><div class="informalexample"><pre class="programlisting">print('Survived by Embarked')
print(train['Survived'].groupby(train['Embarked']).mean())
count_plot = sns.countplot(train['Embarked'], hue=train['Pclass'])
count_plot.get_figure().savefig("survived_count_by_embarked.png")

&gt;&gt;&gt; 
Survived by Embarked
C    0.553571
Q    0.389610
S    0.336957</pre></div><p>Graphically, the preceding result can be seen as follows:</p><div class="mediaobject"><img alt="An Exploratory Analysis of the Titanic Dataset" src="graphics/02_13.jpg"/><div class="caption"><p>Figure 13: Survived by embarked</p></div></div><p>Thus, there were several important factors to people's survival. This means we need to consider these facts while developing our predictive models.</p><p>We will train several binary classifiers since this is a binary classification problem having two predictors, that is, 0 and 1 using the training set and will use the test set for making survival predictions.</p><p>But, before we even do that, let's do some feature engineering since you have seen that there are some missing or null values. We will either impute them or drop the entry from the training and test set. Moreover, we cannot use our datasets directly, but need to prepare them such that they could feed our machine learning models.</p></div><div class="section" title="Feature Engineering"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec18"/>Feature Engineering</h2></div></div></div><p>Since we are considering the length of the passenger's name as an important feature, it would be better to remove the name itself and compute the corresponding length and also we extract only the title:</p><p>def create_name_feat(train, test):</p><div class="informalexample"><pre class="programlisting">    for i in [train, test]:
        i['Name_Len'] = i['Name'].apply(lambda x: len(x))
        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])
        del i['Name']
    return train, test</pre></div><p>As there are 177 null values for Age, and those ones have a 10% lower survival rate than the non-nulls. Therefore, before imputing values for the nulls, we are including an Age_null flag, just to make sure we can account for this characteristic of the data:</p><div class="informalexample"><pre class="programlisting">def age_impute(train, test):
    for i in [train, test]:
        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)
        data = train.groupby(['Name_Title', 'Pclass'])['Age']
        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))
    return train, test</pre></div><p>We are imputing the null age values with the mean of that column. This will add some extra bias in the dataset. But, for the betterment of our predictive model, we will have to sacrifice something.</p><p>Then we combine the <code class="literal">SibSp</code> and <code class="literal">Parch</code> columns to create get family size and break it into three levels:</p><div class="informalexample"><pre class="programlisting">def fam_size(train, test):
    for i in [train, test]:
        i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0, 'One',
                                 np.where((i['SibSp']+i['Parch']) &lt;= 3, 'Small', 'Big'))
        del i['SibSp']
        del i['Parch']
    return train, test
We are using the <code class="literal">Ticket</code> column to create <code class="literal">Ticket_Letr</code>, which indicates the first letter of each ticket and <code class="literal">Ticket_Len</code>, which indicates the length of the Ticket field:</pre></div><div class="informalexample"><pre class="programlisting">def ticket_grouped(train, test):
    for i in [train, test]:
        i['Ticket_Letr'] = i['Ticket'].apply(lambda x: str(x)[0])
        i['Ticket_Letr'] = i['Ticket_Letr'].apply(lambda x: str(x))
        i['Ticket_Letr'] = np.where((i['Ticket_Letr']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']),
                                    i['Ticket_Letr'],
                                    np.where((i['Ticket_Letr']).isin(['W', '4', '7', '6', 'L', '5', '8']),'Low_ticket', 'Other_ticket'))
        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))
        del i['Ticket']
    return train, test</pre></div><p>We also need to extract the first letter of the <code class="literal">Cabin</code> column:</p><div class="informalexample"><pre class="programlisting">def cabin(train, test):
    for i in [train, test]:
        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])
        del i['Cabin']
    return train, test</pre></div><p>Fill the null values in the <code class="literal">Embarked</code> column with the most commonly occurring value, which is <code class="literal">'S'</code>:</p><div class="informalexample"><pre class="programlisting">def embarked_impute(train, test):
    for i in [train, test]:
        i['Embarked'] = i['Embarked'].fillna('S')
    return train, test</pre></div><p>We now need to convert our categorical columns. So far, we have considered it important for the predictive models that we will be creating to have numerical values for string variables. The <code class="literal">dummies()</code> function below does a one-hot encoding to the string variables:</p><div class="informalexample"><pre class="programlisting">def dummies(train, test,
            columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Letr', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):
    for column in columns:
        train[column] = train[column].apply(lambda x: str(x))
        test[column] = test[column].apply(lambda x: str(x))
        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]
        train = pd.concat((train, pd.get_dummies(train[column], prefix=column)[good_cols]), axis=1)
        test = pd.concat((test, pd.get_dummies(test[column], prefix=column)[good_cols]), axis=1)
        del train[column]
        del test[column]
    return train, test</pre></div><p>We have the numerical features, finally, we need to create a separate column for the predicted values or targets:</p><div class="informalexample"><pre class="programlisting">def PrepareTarget(data):
    return np.array(data.Survived, dtype='int8').reshape(-1, 1)</pre></div><p>We have seen the data and its characteristics and done some feature engineering to construct the best features for the linear models. The next task is to build the predictive models and make a prediction on the test set. Let's start with the logistic regression.</p></div><div class="section" title="Logistic Regression for Survival Prediction"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec19"/>Logistic Regression for Survival Prediction</h2></div></div></div><p>Logistic regression is one of the most widely used classifiers to predict a binary response. It is a linear machine learning method The <code class="literal">loss</code> function in the formulation given by the logistic loss:</p><div class="mediaobject"><img alt="Logistic Regression for Survival Prediction" src="graphics/02_14.jpg"/></div><p>For the logistic regression model, the loss function is the logistic loss. For a binary classification problem, the algorithm outputs a binary logistic regression model such that, for a given new data point, denoted by <span class="strong"><strong>x</strong></span>, the model makes predictions by applying the logistic function:</p><div class="mediaobject"><img alt="Logistic Regression for Survival Prediction" src="graphics/02_15.jpg"/></div><p>In the preceding equation, <span class="inlinemediaobject"><img alt="Logistic Regression for Survival Prediction" src="graphics/02_21.jpg"/></span> <span class="strong"><strong>and</strong></span> if <span class="inlinemediaobject"><img alt="Logistic Regression for Survival Prediction" src="graphics/02_22.jpg"/></span>, the outcome is positive; otherwise, it is negative. Note that the raw output of the logistic regression model, <span class="strong"><strong>f (z)</strong></span>, has a probabilistic interpretation.</p><p>Well, if you now compare logistic regression with its predecessor linear regression, the former provides you with a higher accuracy of the classification result. Moreover, it is a flexible way to regularize a model for custom adjustment and overall the model responses are measures of probability. And, most importantly, whereas linear regression can predict only continuous values, logistic regression can be generalized enough to make it predict discrete values. From now on, we will often be using the TensorFlow contrib API. So let's have a quick look at it.</p><div class="section" title="Using TensorFlow Contrib"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec06"/>Using TensorFlow Contrib</h3></div></div></div><p>The contrib is a high level API for learning with TensorFlow. It supports the following Estimators:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.BaseEstimator</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.Estimator</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.Trainable</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.Evaluable</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.KMeansClustering</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.ModeKeys</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.ModelFnOps</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.MetricSpec</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.PredictionKey</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.DNNClassifier</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.DNNRegressor</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.DNNLinearCombinedRegressor</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.DNNLinearCombinedClassifier</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.LinearClassifier</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.LinearRegressor</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">tf.contrib.learn.LogisticRegressor</code></li></ul></div><p>Thus, without developing the logistic regression, from scratch, we will use the estimator from the TensorFlow contrib package. When we are creating our own estimator from scratch, the constructor still accepts two high-level parameters for model configuration, <code class="literal">model_fn</code> and <code class="literal">params</code>:</p><div class="informalexample"><pre class="programlisting">nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)</pre></div><p>To instantiate an Estimator we need to provide two parameters such as <code class="literal">model_fn</code> and the <code class="literal">model_params</code> as follows:</p><div class="informalexample"><pre class="programlisting">nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)</pre></div><p>It is to be noted that the <code class="literal">model_fn()</code> function contains all the above mentioned TensorFlow logic to support the training, evaluation, and prediction. Thus, you only need to implement the functionality that could use it efficiently.</p><p>Now, upon invoking the <code class="literal">main()</code> method, <code class="literal">model_params</code> containing the learning rate, instantiates the Estimator. You can define the <code class="literal">model_params</code> as follows:</p><div class="informalexample"><pre class="programlisting">model_params = {"learning_rate": LEARNING_RATE}</pre></div><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note14"/>Note</h3><p>For more information on the TensorFlow contrib, interested readers can refer to this URL at <a class="ulink" href="https://www.tensorflow.org/extend/estimators">https://www.tensorflow.org/extend/estimators</a>
</p></div></div><p>Well, so far we have acquired enough background knowledge to create an LR model with TensorFlow with our dataset. It's time to implement it:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import required packages and modules:<div class="informalexample"><pre class="programlisting">import os
import shutil
import random
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from feature import *
import tensorflow as tf
from tensorflow.contrib.learn.python.learn.estimators import estimator
from tensorflow.contrib import learn</pre></div></li><li class="listitem">Loading and preparing the dataset.<p>At first, we load both the datasets:</p><div class="informalexample"><pre class="programlisting">random.seed(12345) # For the reproducibility 
train = pd.read_csv(os.path.join('input', 'train.csv'))
test = pd.read_csv(os.path.join('input', 'test.csv'))</pre></div><p>Let's do some feature engineering. We will invoke the function we defined in the feature engineering section, but will be provided as separate Python script with name <code class="literal">feature.py</code>:</p><div class="informalexample"><pre class="programlisting">train, test = create_name_feat(train, test)
train, test = age_impute(train, test)
train, test = cabin(train, test)
train, test = embarked_impute(train, test)
train, test = fam_size(train, test)
test['Fare'].fillna(train['Fare'].mean(), inplace=True)
train, test = ticket_grouped(train, test)</pre></div><p>It is to be noted that the sequence of the above invocation is important to make the training and test set consistent. Now, we also need to create numerical values for categorical variables using the <code class="literal">dummies()</code> function from sklearn:</p><div class="informalexample"><pre class="programlisting">train, test = dummies(train, test, columns=['Pclass', 'Sex', 'Embarked', 'Ticket_Letr', 'Cabin_Letter', 'Name_Title', 'Fam_Size'])</pre></div><p>We need to prepare the training and test set:</p><div class="informalexample"><pre class="programlisting">TEST = True
if TEST:
    train, test = train_test_split(train, test_size=0.25, random_state=10)
    train = train.sort_values('PassengerId')
    test = test.sort_values('PassengerId')

X_train = train.iloc[:, 1:]
x_test = test.iloc[:, 1:]</pre></div><p>We then convert the training and test set into a NumPy array since so far we have kept them in Pandas DataFrame format:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">x_train = np.array(x_train.iloc[:, 1:], dtype='float32')</code>
<code class="literal">if TEST:</code>
<code class="literal">    x_test = np.array(x_test.iloc[:, 1:], dtype='float32')</code>
<code class="literal">else:</code>
    x_test = np.array(x_test, dtype='float32')</pre></div><p>Let's prepare the target column for prediction:</p><div class="informalexample"><pre class="programlisting">y_train = PrepareTarget(train)</pre></div><p>We also need to know the feature count to build the LR estimator:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">feature_count = x_train.shape[1]</code>
</pre></div></li><li class="listitem">Preparing the LR estimator.<p>We build the LR estimator. We will utilize the <code class="literal">LinearClassfier</code> estimator for it. Since this is a binary classification problem, we provide two classes:</p><div class="informalexample"><pre class="programlisting">def build_lr_estimator(model_dir, feature_count):
    return estimator.SKCompat(learn.LinearClassifier(
        feature_columns=[tf.contrib.layers.real_valued_column("", dimension=feature_count)],
        n_classes=2, model_dir=model_dir))</pre></div></li><li class="listitem">Training the model.<p>Here, we train the above LR estimator for <code class="literal">10,000</code> iterations. The <code class="literal">fit() </code>method does the trick and the <code class="literal">predict()</code> method computes the prediction on the training set containing the feature, that is, <code class="literal">X_train</code> and the label, that is, <code class="literal">y_train</code>:</p><div class="informalexample"><pre class="programlisting">print("Training...")
try:
    shutil.rmtree('lr/')
except OSError:
    pass
lr = build_lr_estimator('lr/', feature_count)
lr.fit(x_train, y_train, steps=1000)
lr_pred = lr.predict(x_test)
lr_pred = lr_pred['classes']</pre></div></li><li class="listitem">Model evaluation.<p>We will evaluate the model seeing several classification performance metrics such as precision, recall, f1 score, and confusion matrix:</p><div class="informalexample"><pre class="programlisting">
<code class="literal">if TEST:</code>
<code class="literal">    target_names = ['Not Survived', 'Survived']</code>
<code class="literal">    print("Logistic Regression Report")</code>
<code class="literal">    print(classification_report(test['Survived'], lr_pred, target_names=target_names))</code>
<code class="literal">    print("Logistic Regression Confusion Matrix")</code>

<code class="literal">&gt;&gt;&gt;</code>
<code class="literal">Logistic Regression Report</code>
<code class="literal">                  precision    recall  f1-score   support</code>
<code class="literal">Not Survived       0.90         0.88      0.89       147</code>
<code class="literal">Survived           0.78         0.80      0.79        76---------------------------------------------------------</code>
 avg / total       0.86         0.86       0.86       223</pre></div><p>Since we trained the LR model with NumPy data, we now need to convert it back to a Panda DataFrame for confusion matrix creation:</p><div class="informalexample"><pre class="programlisting">cm = confusion_matrix(test['Survived'], lr_pred)
    df_cm = pd.DataFrame(cm, index=[i for i in ['Not Survived', 'Survived']],
                         columns=[i for i in ['Not Survived', 'Survived']])
    print(df_cm)

&gt;&gt;&gt; 
Logistic Regression Confusion Matrix
              Not Survived  Survived
Not Survived           130        17
Survived               15         61</pre></div><p>Now, let's see the count:</p><div class="informalexample"><pre class="programlisting">print("Predicted Counts")
print(sol.Survived.value_counts())

&gt;&gt;&gt; 
Predicted Counts
0    145
1     78</pre></div><p>Since seeing the count graphically is awesome, let's draw it:</p><div class="informalexample"><pre class="programlisting">sol = pd.DataFrame()
sol['PassengerId'] = test['PassengerId']
sol['Survived'] = pd.Series(lr_pred.reshape(-1)).map({True:1, False:0}).values
sns.plt.suptitle("Predicted Survived LR")
count_plot = sns.countplot(sol.Survived)
count_plot.get_figure().savefig("survived_count_lr_prd.png")

&gt;&gt;&gt;</pre></div><p>The output is as follows:</p><div class="mediaobject"><img alt="Using TensorFlow Contrib" src="graphics/02_16.jpg"/><div class="caption"><p>Figure 14: Survival prediction using logistic regression with TensorFlow</p></div></div></li></ol></div><p>So, the accuracy we achieved with the LR model is 86% which is not that bad at all. But it can still be improved with better predictive models. In the next section, we will try to do that using linear <span class="strong"><strong>SVM</strong></span> for survival prediction.</p></div></div><div class="section" title="Linear SVM for Survival Prediction"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec20"/>Linear SVM for Survival Prediction</h2></div></div></div><p>The linear <span class="strong"><strong>SVM</strong></span> is one of the most widely used and standard methods for large-scale classification tasks. Both the multiclass and binary classification problem can be solved using SVM with the loss function in the formulation given by the hinge loss:</p><div class="mediaobject"><img alt="Linear SVM for Survival Prediction" src="graphics/02_17.jpg"/></div><p>Usually, linear SVMs are trained with L2 regularization. Eventually, the linear SVM algorithm outputs an SVM model that can be used to predict the label of unknown data.</p><p>Suppose you have an unknown data point, <span class="strong"><strong>x</strong></span>, the SVM model makes predictions based on the value of <span class="inlinemediaobject"><img alt="Linear SVM for Survival Prediction" src="graphics/02_23.jpg"/></span>. The outcome can be either positive or negative. More specifically, if <span class="inlinemediaobject"><img alt="Linear SVM for Survival Prediction" src="graphics/02_24.jpg"/></span>, then the predicted value is positive; otherwise, it is negative.</p><p>The current version of the TensorFlow contrib package supports only the linear SVM. TensorFlow uses SDCAOptimizer for the underlying optimization. Now, the thing is that if you want to build an SVM model of your own, you need to consider the performance and convergence tuning issues. Fortunately, you can pass the <code class="literal">num_loss_partitions</code> parameter to the SDCAOptimizer function. But you need to set the <span class="strong"><strong>X</strong></span> such that it converges to the concurrent train ops per worker.</p><p>If you set the <code class="literal">num_loss_partitions</code> larger than or equal to this value, convergence is guaranteed, but this makes the overall training slower with the increase of <code class="literal">num_loss_partitions</code>. On the other hand, if you set its value to a smaller one, the optimizer is more aggressive in reducing the global loss, but convergence is not guaranteed.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note15"/>Note</h3><p>For more on the implemented contrib packages, interested readers should refer to this URL at <a class="ulink" href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators</a>.</p></div></div><p>Well, so far we have acquired enough background knowledge for creating an SVM model, now it's time to implement it:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the required packages and modules:<div class="informalexample"><pre class="programlisting">import os
import shutil
import random
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from feature import *
import tensorflow as tf
from tensorflow.contrib.learn.python.learn.estimators import svm</pre></div></li><li class="listitem">Dataset preparation for building SVM model:<p>Now, the data preparation for building an SVM model is more or less the same as an LR model, except that we need to convert the <code class="literal">PassengerId</code> to string which is required for the SVM:</p><div class="informalexample"><pre class="programlisting">train['PassengerId'] = train['PassengerId'].astype(str)
test['PassengerId'] = test['PassengerId'].astype(str)</pre></div></li><li class="listitem">Creating a dictionary for SVM for continuous feature column.<div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note16"/>Note</h3><p>To feed the data to the SVM model, we further need to create a dictionary mapping from each continuous feature column name (k) to the values of that column stored in a constant Tensor. For more information on this issue, refer to this issue on TensorFlow GitHub repository at <a class="ulink" href="https://github.com/tensorflow/tensorflow/issues/9505">https://github.com/tensorflow/tensorflow/issues/9505</a>.</p></div></div><p>I have written two functions for both the feature and labels. Let's see what the first one looks like:</p><div class="informalexample"><pre class="programlisting">def train_input_fn():
    continuous_cols = {k: tf.expand_dims(tf.constant(train[k].values), 1)
                       for k in list(train) if k not in ['Survived', 'PassengerId']}
    id_col = {'PassengerId' : tf.constant(train['PassengerId'].values)}
    feature_cols = continuous_cols.copy()
    feature_cols.update(id_col)
    label = tf.constant(train["Survived"].values)
    return feature_cols, label</pre></div><p>The preceding function creates a dictionary mapping from each continuous feature column and then another for the <code class="literal">passengerId</code> column. Then I merged them into one. Since we want to target the 'Survived' column as the labels, I converted the label column into constant tensor. Finally, through this function, I returned both the feature column and the label.</p><p>Now, the second method does almost the same trick except that it returns only the feature columns as follows:</p><div class="informalexample"><pre class="programlisting">def predict_input_fn():
    continuous_cols = {k: tf.expand_dims(tf.constant(test[k].values), 1)
                       for k in list(test) if k not in ['Survived', 'PassengerId']}
    id_col = {'PassengerId' : tf.constant(test['PassengerId'].values)}
    feature_cols = continuous_cols.copy()
    feature_cols.update(id_col)
    return feature_cols</pre></div></li><li class="listitem">Training the SVM model.<p>Now we will iterate the training 10,000 times over the real valued column only. Finally, it creates a prediction list containing all the prediction values:</p><div class="informalexample"><pre class="programlisting">svm_model = svm.SVM(example_id_column="PassengerId",
                    feature_columns=[tf.contrib.layers.real_valued_column(k) for k in list(train)
                                     if k not in ['Survived', 'PassengerId']], 
                    model_dir="svm/")
svm_model.fit(input_fn=train_input_fn, steps=10000)
svm_pred = list(svm_model.predict_classes(input_fn=predict_input_fn))</pre></div></li><li class="listitem">Evaluation of the model:<div class="informalexample"><pre class="programlisting">target_names = ['Not Survived', 'Survived']
print("SVM Report")
print(classification_report(test['Survived'], svm_pred, target_names=target_names))
&gt;&gt;&gt;
SVM Report
                       precision    recall  f1-score   support
Not Survived       0.94        0.72      0.82       117
Survived           0.63        0.92      0.75        62--------------------------------------------------------
 avg / total       0.84         0.79      0.79       179</pre></div><p>Thus using SVM, the accuracy is only 79%, which is lower than that of an LR model. Well, similar to an LR model, draw and observe the confusion matrix:</p><div class="informalexample"><pre class="programlisting">print("SVM Confusion Matrix")
cm = confusion_matrix(test['Survived'], svm_pred)
df_cm = pd.DataFrame(cm, index=[i for i in ['Not Survived', 'Survived']],
                        columns=[i for i in ['Not Survived', 'Survived']])
print(df_cm)
&gt;&gt;&gt; 
SVM Confusion Matrix
              Not Survived  Survived
Not Survived            84        33
Survived                    5         57</pre></div><p>Then, let's draw the count plot to see the ratio visually:</p><div class="informalexample"><pre class="programlisting">sol = pd.DataFrame()
sol['PassengerId'] = test['PassengerId']
sol['Survived'] = pd.Series(svm_pred).values
sns.plt.suptitle("Titanic Survival prediction using SVM with TensorFlow")
count_plot = sns.countplot(sol.Survived)</pre></div><p>The output is as follows:</p><div class="mediaobject"><img alt="Linear SVM for Survival Prediction" src="graphics/02_18.jpg"/><div class="caption"><p>Figure 15: Survival prediction using linear SVM with TensorFlow</p></div></div><p>Now, the count:</p><div class="informalexample"><pre class="programlisting">print("Predicted Counts")
print(sol.Survived.value_counts())

&gt;&gt;&gt; 
Predicted Counts
1    90
0    89</pre></div></li></ol></div></div><div class="section" title="Ensemble Method for Survival Prediction – Random Forest"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec21"/>Ensemble Method for Survival Prediction – Random Forest</h2></div></div></div><p>One of the most widely used machine learning techniques is using the ensemble methods, which are learning algorithms that construct a set of classifiers. It can then be used to classify new data points by taking a weighted vote of their predictions. In this section, we will mainly focus on the random forest that can be built by combining 100s of decision trees.</p><p>
<span class="strong"><strong>Decision trees</strong></span> (<span class="strong"><strong>DTs</strong></span>) is a technique which is used in supervised learning for solving classification and regression tasks. Where a DT model learns simple decision rules that are inferred from the data features by utilizing a tree-like graph to demonstrate the course of actions. Each branch of a decision tree represents a possible decision, occurrence or reaction in terms of statistical probability:</p><div class="mediaobject"><img alt="Ensemble Method for Survival Prediction – Random Forest" src="graphics/02_19.jpg"/><div class="caption"><p>Figure 16: A sample decision tree on the admission test dataset using the rattle package of R</p></div></div><p>Compared to LR or SVM, the DTs are far more robust classification algorithms. The tree infers predicted labels or classes after splitting available features to the training data based to produce a good generalization. Most interestingly, the algorithm can handle both the binary as well as multiclass classification problems.</p><p>For instance, the decision trees in figure 16 learn from the admission data to approximate a sine curve with a set of <code class="literal">if...else</code> decision rules. The dataset contains the record of each student who applied for admission, say to an American university. Each record contains the graduate record exam score, CGPA score and the rank of the column. Now we will have to predict who is competent based on these three features (variables).</p><p>DTs can be utilized to solve this kind of problem after training the DT model and pruning the unwanted branch of the tree. In general, a deeper tree signifies more complex decision rules and a better-fitted model. Therefore, the deeper the tree, the more complex the decision rules, and the more fitted the model.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note17"/>Note</h3><p>If you would like to draw the above figure, just use my R script and execute on RStudio and feed the admission dataset. The script and the dataset can be found in my GitHub repository at <a class="ulink" href="https://github.com/rezacsedu/AdmissionUsingDecisionTree">https://github.com/rezacsedu/AdmissionUsingDecisionTree</a>.</p></div></div><p>Well, so far we have acquired enough background knowledge for creating a Random Forest (RF) model, now it's time to implement it.</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the required packages and modules:<div class="informalexample"><pre class="programlisting">import os
import shutil
import random
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from feature import *
import tensorflow as tf
from tensorflow.contrib.learn.python.learn.estimators import estimator
from tensorflow.contrib.tensor_forest.client import random_forest
from tensorflow.contrib.tensor_forest.python import tensor_forest</pre></div></li><li class="listitem">Dataset preparation for building an RF model.<p>Now, the data preparation for building an RF model is more or less the same as an LR model. So please refer to the logistic regression section.</p></li><li class="listitem">Building a random forest estimator.<p>The following function builds a random forest estimator. It creates 1,000 trees with maximum 1,000 nodes and 10-fold cross-validation. Since it's a binary classification problem, I put number of classes as 2:</p><div class="informalexample"><pre class="programlisting">def build_rf_estimator(model_dir, feature_count):
    params = tensor_forest.ForestHParams(
        num_classes=2,
        num_features=feature_count,
        num_trees=1000,
        max_nodes=1000,
        min_split_samples=10)
    graph_builder_class = tensor_forest.RandomForestGraphs
    return estimator.SKCompat(random_forest.TensorForestEstimator(
        params, graph_builder_class=graph_builder_class,
        model_dir=model_dir))</pre></div></li><li class="listitem">Training the RF model.<p>Here, we train the above RF estimator. Once the <code class="literal">fit()</code> method does the trick and the <code class="literal">predict()</code> method computes the prediction on the training set containing the feature, that is, <code class="literal">x_train</code> and the label, that is, <code class="literal">y_train</code>:</p><div class="informalexample"><pre class="programlisting">rf = build_rf_estimator('rf/', feature_count)
rf.fit(x_train, y_train, batch_size=100)
rf_pred = rf.predict(x_test)
rf_pred = rf_pred['classes']</pre></div></li><li class="listitem">Evaluating the model.<p>Now let's evaluate the performance of the RF model:</p><div class="informalexample"><pre class="programlisting">    target_names = ['Not Survived', 'Survived']
    print("RandomForest Report")
    print(classification_report(test['Survived'], rf_pred, target_names=target_names))

&gt;&gt;&gt;
RandomForest Report
                         precision    recall  f1-score   support
------------------------------------------------------
Not Survived       0.92         0.85       0.88            117
Survived           0.76         0.85       0.80            62
------------------------------------------------------
avg / total        0.86         0.85       0.86            179</pre></div><p>Thus, using RF, the accuracy is 87% which is higher than that of the LR and SVM models. Well, similar to the LR and SVM model, we'll draw and observe the confusion matrix:</p><div class="informalexample"><pre class="programlisting">    print("Random Forest Confusion Matrix")
    cm = confusion_matrix(test['Survived'], rf_pred)
    df_cm = pd.DataFrame(cm, index=[i for i in ['Not Survived', 'Survived']],
                         columns=[i for i in ['Not Survived', 'Survived']])
    print(df_cm)
&gt;&gt;&gt; 
Random Forest Confusion Matrix
                       Not Survived  Survived
-----------------------------------------------------
Not Survived            100             17
Survived                 9              53</pre></div><p>Then, let's draw the count plot to see the ratio visually:</p><div class="informalexample"><pre class="programlisting">sol = pd.DataFrame()
sol['PassengerId'] = test['PassengerId']
sol['Survived'] = pd.Series(svm_pred).values
sns.plt.suptitle("Titanic Survival prediction using RF with TensorFlow")
count_plot = sns.countplot(sol.Survived)</pre></div><p>The output is as follows:</p><div class="mediaobject"><img alt="Ensemble Method for Survival Prediction – Random Forest" src="graphics/02_20.jpg"/><div class="caption"><p>Figure 17: Titanic survival prediction using random forest with TensorFlow</p></div></div><p>Now, the count for each one:</p><div class="informalexample"><pre class="programlisting">print("Predicted Counts")
print(sol.Survived.value_counts())
&gt;&gt;&gt;  Predicted Counts
-------------------------
0   109
1    70</pre></div></li></ol></div></div><div class="section" title="A Comparative Analysis"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec22"/>A Comparative Analysis</h2></div></div></div><p>From the classification reports, we can see that random forest has the best overall performance. The reason for this may be that it works better with categorical features than the other two methods. Also, since it uses implicit feature selection, overfitting was reduced significantly. Using logistic regression is a convenient probability score for observations. However, it doesn't perform well when feature space is too large that is, doesn't handle a large number of categorical features/variables well. It also solely relies on transformations for non-linear features.</p><p>Finally, using SVM we can handle a large feature space with non-linear feature interactions without relying on the entire dataset. However, it is not very well with a large number of observations. Nevertheless, it can be tricky to find an appropriate kernel sometimes.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec18"/>Summary</h1></div></div></div><p>In this lesson, we have discussed supervised learning from the theoretical and practical perspective. In particular, we have revisited the linear regression model for regression analysis. We have seen how to use regression for predicting continuous values. Later in this lesson, we have discussed some other supervised learning algorithms for predictive analytics. We have seen how to use logistic regression, SVM, and random forests for survival prediction on the Titanic dataset. Finally, we have seen a comparative analysis between these classifiers. We have also seen that random forest, which is based on decision trees ensembles, outperforms logistic regression and linear SVM models.</p><p>In <a class="link" href="ch03.html" title="Chapter 3. Clustering Your Data – Unsupervised Learning for Predictive Analytics">Lesson 3</a>, <span class="emphasis"><em>Clustering Your Data – Unsupervised Learning for Predictive Analytics</em></span>, we will provide some practical examples of unsupervised learning. Particularly, the clustering technique using TensorFlow will be provided for neighborhood clustering and audio clustering from audio features.</p><p>More specifically, we will provide an exploratory analysis of the dataset then we will develop a cluster of the neighborhood using K-means, K-NN, and bisecting K-means with sufficient performance metrics such as cluster cost, accuracy, and so on. In the second part of the lesson, we will see how to do audio feature clustering. Finally, we will provide a comparative analysis of clustering algorithms.</p></div>
<div class="section" title="Assessments"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec19"/>Assessments</h1></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Depending on the nature of the learning feedback available, the machine learning process is typically classified into three broad categories. Name them.</li><li class="listitem">State whether the following statement is True or False: Using the brute-force approach such as if-else statements with some sort of weighted scoring system, you cannot write a program to predict whether a given passenger would survive the disaster.</li><li class="listitem">Upon invoking the main() method, model_params containing the learning rate instantiates the Estimator. How can you define the model_params as?</li><li class="listitem">State whether the following statement is True or False: Each branch of a decision tree represents a possible decision, occurrence, or reaction in terms of statistical probability.</li><li class="listitem">A predictive model based on supervised learning algorithms can make predictions based on a labeled _______ that maps inputs to outputs aligning with the real world.<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Dataflow graph</li><li class="listitem">Linear graph</li><li class="listitem">Regression model</li><li class="listitem">Dataset</li></ol></div></li></ol></div></div></body></html>