<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Emerging Neural Network Designs</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we'll look at some emerging <strong>Neural Network</strong> (<strong>NN</strong>) designs. They haven't reached maturity yet, but hold potential for the future because they try to address fundamental limitations in existing DL algorithms. If one day any of these technologies prove successful and useful for practical applications, we might get one step closer to artificial general intelligence. </p>
<p class="mce-root">One thing that we need to bear in mind is the nature of structured data. So far in this book, we've focused on processing either images or text—in other words, unstructured data. This is not a coincidence, because NNs excel in the seemingly complex task of finding structure in combinations of pixels or text sequences. On the other hand, ML algorithms, such as gradient boosted trees or random forests, seem to perform on a par with, or better than, NNs when it comes to structured data, such as social-network graphs or brain connections. In this chapter, we'll introduce graph NNs to deal with arbitrary structured graphs. </p>
<p>Another NN limitation manifests itself with <strong>Recurrent Networks</strong> (<strong>RNNs</strong>). In theory, these are one of the most powerful NN models because they are Turing-complete, which means that an RNN can theoretically solve any computational problem. This is often not the case in practice. RNNs (even <strong>Long Short-Term Memory </strong>(<strong>LSTM</strong>)) can struggle to carry information over extended periods of time. One possible solution is to extend the RNN with an external addressable memory. W<span>e'll look at how to do this i</span><span>n this chapter.</span></p>
<p>The topics in this chapter are not detached from the rest of the topics in this book. In fact, we'll see that the new network architectures that we'll look at are based on many of the algorithms that we've already covered. These include convolutions, RNNs, and attention models, as well as others. </p>
<p>This chapter will cover the following topics:</p>
<ul>
<li>Introducing graph NNs </li>
<li>Introducing memory-augmented NNs</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing Graph NNs</h1>
                </header>
            
            <article>
                
<p>Before learning about <strong>graph NNs</strong> (<strong>GNNs</strong>), let's look at why we need graph networks in the first place. We'll start by defining a graph, which is a set of objects (also known as <strong>nodes</strong> or <strong>vertices</strong>) where some pairs of objects have connections (or <strong>edges</strong>) between them.</p>
<div class="packt_infobox"><span>In this section, we'll use several survey papers as resources, mo</span>st notably <em>A</em> <em>Comprehensive Survey on Graph Neural Networks</em><span> (</span><a href="https://arxiv.org/abs/1901.00596">https://arxiv.org/abs/1901.00596</a><span>), which contains some quotes and images. </span></div>
<p>A graph has the following properties:</p>
<ul>
<li>We'll represent the graph as <img class="fm-editor-equation" src="assets/40da6b62-68d7-4d59-9247-d8e142246f89.png" style="width:4.00em;height:0.92em;"/>, where <em>V</em> is the set of nodes and <em>E</em> is the set of edges.</li>
<li>The expression <img class="fm-editor-equation" src="assets/88ec490a-336a-4f32-b501-138e471e5801.png" style="width:7.42em;height:1.17em;"/> describes an edge between two nodes, <img class="fm-editor-equation" src="assets/46829fd0-f93c-4710-909c-612208907d50.png" style="width:3.67em;height:1.00em;"/>.</li>
<li>An adjacency matrix, <img class="fm-editor-equation" src="assets/2bd7df0f-0b56-4b25-aef4-9c8855ffcc90.png" style="width:4.33em;height:0.92em;"/>, where <em>n</em> is the number of graph nodes. This is written as <img class="fm-editor-equation" src="assets/f3dd7e83-f3cd-4074-9873-d75fac7463d8.png" style="width:3.08em;height:1.17em;"/> if an edge <img class="fm-editor-equation" src="assets/96f0fb9d-25e2-4d01-bdcc-8bb2f14baa86.png" style="width:5.08em;height:1.08em;"/> exists and <img class="fm-editor-equation" src="assets/d6be8b1c-c944-47bc-9051-aab6d6c44840.png" style="width:2.42em;height:0.92em;"/> if it doesn't. </li>
<li>Graphs can be <strong>directed</strong> when the edges have a direction and <strong>undirected</strong> when they don't. The adjacency matrix of an undirected graph is symmetric—that is <img class="fm-editor-equation" src="assets/8a2dc410-555b-4395-a48d-6034f07430d0.png" style="width:3.42em;height:1.00em;"/>. The <span>adjacency matrix of a directed graph is asymmetric—that is <img class="fm-editor-equation" src="assets/0e4b2a68-8374-496e-b3ef-90c570166d30.png" style="width:3.08em;height:1.08em;"/>.</span></li>
<li>Graphs can be <strong>cyclic</strong> or <strong>acyclic</strong>. As the name suggests, a cyclic graph contains at least one cycle, which is a non-empty path of nodes where only the first and the last node are the same. Acyclic graphs don't contain cycles.</li>
<li>Both graph edges and nodes can have associated attributes, known as feature vectors. We'll denote the<span> </span><em>d</em><span>-dimensional feature vector of node </span><em>v</em> with <img class="fm-editor-equation" src="assets/0f8228cc-225b-44df-bd68-1449db642346.png" style="width:3.42em;height:1.25em;"/>. If a graph has <em>n</em> nodes, we can represent them as a matrix <img class="fm-editor-equation" src="assets/1c5fd1ea-48cd-43c1-854d-e7b081d2ea18.png" style="width:4.58em;height:1.17em;"/>. Analogously, each edge attribute is a <em>c</em>-dimensional feature vector, expressed as <img class="fm-editor-equation" src="assets/500c1356-80bc-4683-8bc8-afb9b4cd5109.png" style="width:3.92em;height:1.17em;"/>, where <em>v</em> and <em>u</em> are nodes. We can represent the set of edge attributes of a graph as a matrix <img class="fm-editor-equation" src="assets/f22c4803-7135-40dc-ae0e-d6ab74e68ee5.png" style="width:4.67em;height:0.92em;"/>.</li>
</ul>
<p>The following diagram shows a directed graph with five nodes and its corresponding adjacency matrix:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1382 image-border" src="assets/4859621a-c3d2-4895-a357-11a006dfefe6.png" style="width:25.00em;height:8.42em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Directed graph with five nodes and its corresponding <img class="fm-editor-equation" src="assets/e6a20be5-c2c0-46cf-82ef-5b766a62dc65.png" style="width:3.58em;height:0.92em;"/> adjacency matrix</span></div>
<p>A graph is a versatile data structure that lends itself well to the way data is organized in many real-world scenarios. The following is a nonexhaustive list of examples:</p>
<ul>
<li>We can use graphs to represent users in a social network (nodes) and their groups of friends (edges). In fact, this is what Facebook does with their social graph (<em>The Anatomy of the Facebook Social Graph, </em><a href="https://arxiv.org/abs/1111.4503">https://arxiv.org/abs/1111.4503</a>). </li>
<li><span>We can represent a molecule as a graph, where the nodes are atoms and the edges are the chemical bonds between them. </span></li>
<li><span>We can represent a street network (a classic example) as a graph, where the streets are edges and their intersections are nodes.</span></li>
<li>In online commerce, we can represent both users and items as nodes and the relationships between them as edges.</li>
</ul>
<p>Next, let's discuss the types of task we can solve with graphs. They fall broadly into three categories:</p>
<ul>
<li><strong>Node-focused</strong>: C<span>lassification and regression of</span> individual nodes. For example, in the famous Zachary's karate club problem (<a href="https://en.wikipedia.org/wiki/Zachary%27s_karate_club">https://en.wikipedia.org/wiki/Zachary%27s_karate_club</a>) we have a number of karate club members (nodes) and the friendships between them (edges). Initially, the club has a single instructor and all the members train as a group under that instructor. Later, the club splits into two groups with two separate instructors. Assuming that all but one club member opts to join one of the two groups, the goal is to determine which group will choose the last undecided member (classification), given its set of friendships with other members.</li>
<li><strong>Edge-focused</strong>: C<span><span>lassification and regression of individual edges of the graph. For example, we can predict how likely it is that two people in a social network know each other. In other words, the task is to determine whether an edge exists between two graph nodes. </span></span></li>
<li><strong>Graph-focused</strong>: C<span>lassification and regression </span>of full graphs. For example, given a molecule represented as a graph, we can predict whether the molecule is toxic. </li>
</ul>
<p>Next, let's outline the main training frameworks of GNNs:</p>
<ul>
<li><strong>Supervised</strong>: All training data is labeled. We can apply supervised learning at node, edge, and graph level. </li>
<li><strong>Unsupervised</strong>: The goal here is to learn some form of graph embedding—for example, using autoencoders (we'll discuss this scenario later in the chapter). We can apply unsupervised learning at node, edge, and graph level.</li>
<li><strong>Semi-supervised</strong>: This<span> is usually applied at node level, where</span> some graph nodes are labeled and some aren't. Semi-supervised learning is especially suited for graphs because we can make the simple (but often true) assumption that neighboring nodes are likely to have the same labels. For example, say that we have two neighboring connected nodes. One of them contains an image of a car and the other contains an image of a truck. Let's assume that the truck node is labeled as a vehicle while the car node is unlabeled. We can safely assume that the car node is also a vehicle because of its proximity to another vehicle node (the truck). There are multiple ways we can utilize this graph property in GNNs. We'll outline two  of them (they are not mutually exclusive):
<ul>
<li>Use this property implicitly by feeding the adjacency matrix of the graph as input to the network. The network will do its magic and hopefully infer that neighboring nodes are likely to have the same labels, thereby increasing the accuracy of the predictions thanks to the additional information. Most GNNs we'll discuss in this chapter use this mechanism.</li>
<li><strong>Label propagation</strong>, where we can use labeled nodes as a seed for assigning labels to unlabeled ones based on their proximity to the labeled. We can do this in an iterative way as far as convergence by going through the following steps:
<ol>
<li>Start with the seed labels.</li>
<li>For all graph nodes (except the seed), assign a label based on the labels of their neighboring nodes. This step creates a new label configuration for the whole graph, where some of the nodes might need a new label, based on the modified neighbors' labels.</li>
</ol>
<ol start="3">
<li>Stop label propagation if a convergence criterion is met; otherwise, repeat step 2.</li>
</ol>
</li>
</ul>
</li>
</ul>
<p><span>We'll use this short introduction to graphs as a base for the next few sections, where we'll discuss various types of graph-focused NN model. The GNN arena is relatively new, and there is no outright perfect mod</span>el rese<span>mbling <strong>convolutional networks</strong> (<strong>CNNs</strong>) in computer vision. Instead, we have different models with various properties. Most of them fall into a few general categories, and there are attempts to create a framework that is generic enough to combine them all. This book doesn't aim to invent new models or model taxonomies but; instead, we'll introduce you to some existing ones.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recurrent GNNs</h1>
                </header>
            
            <article>
                
<p>We'll start this section by looking at <strong>graph neural networks</strong> (<strong>GraphNNs</strong>; <span>see </span><em>The Graph Neural Network Model</em><span>, </span><strong><a href="https://ieeexplore.ieee.org/document/4700287">https://ieeexplore.ieee.org/document/4700287</a></strong>). Although the authors of the paper abbreviated the model to GNN, we'll refer to it with the GraphNN acronym to avoid conflict with the GNN abbreviation, which is reserved for the general class of graph networks. This is one of the first GNN models to be proposed. It extends existing NNs to process graph-structured data. In the same way that we used the context of a word (that is, its surrounding words) to create embedding vectors (<a href="fe6a42c9-f18e-4c2b-9a82-99ec53e727ca.xhtml">Chapter 6</a><em>, Language Modeling</em>), we can use the neighboring graph nodes of a node to do the same. GraphNNs aim to create an <em>s</em>-dimensional vector state <img class="fm-editor-equation" src="assets/e1c524a1-4bb1-4438-966b-00993d86d5af.png" style="width:2.67em;height:0.83em;"/> of a node <em>v</em> based on the neighborhood of that node. In a similar way to language modeling, the vector state can serve as the input for other tasks, such as node classification.</p>
<p>The state of a node is updated by exchanging neighborhood information recurrently until a stable equilibrium is reached. Let's denote the set of neighborhood nodes <em>v</em> with <img class="fm-editor-equation" src="assets/3bd465a0-a7b2-44d0-9ca6-f316a4c15867.png" style="width:1.58em;height:0.83em;"/> and a single node of that neighborhood with <em>u</em>. The hidden state of a node is recurrently updated using the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bc73d220-66ee-4229-9e08-46567127e7c9.png" style="width:21.50em;height:3.67em;"/></p>
<p>Here, <em>f</em> is a parametric function (for example, a <strong>feed-forward NN</strong> (<strong>FFNN</strong>)) and each state <img class="fm-editor-equation" src="assets/e1889615-9da0-42d8-96b9-833d85ff49c1.png" style="width:1.67em;height:1.33em;"/> is initialized randomly. The parametric function <em>f </em>takes as inputs the feature vector <em><img class="fm-editor-equation" src="assets/8e00e0c7-e952-4459-9bda-debeb4a0f2bd.png" style="width:1.08em;height:0.75em;"/></em> of <em>v</em> , the feature vector <img class="fm-editor-equation" src="assets/dda100a7-6d39-42b9-b482-ebfc6882f7e5.png" style="width:1.42em;height:0.92em;"/> of its neighbor <em>u</em>, the feature vector <img class="fm-editor-equation" src="assets/2123d1d9-f3ac-4968-b4fd-c8a1b4633c9e.png" style="width:2.00em;height:1.33em;"/> of the edge connecting <em>u</em> and <em>v</em>, and the state vector <img class="fm-editor-equation" src="assets/b40c18b0-cbc8-4505-9cf3-b9db3e3e3a66.png" style="width:2.25em;height:1.25em;"/> <span>of</span><span> <em>u</em></span> at step <em>t-1</em>. In other words, <em>f</em> uses all known information about the neighborhood of <em>v</em>. The expression <img class="fm-editor-equation" src="assets/161bd9cc-1ccb-4477-972e-908460c7624b.png" style="width:1.58em;height:1.42em;"/> is a sum of the <em>f</em> applied over all neighboring nodes, which allows GraphNN to be independent of the number of neighbors and their ordering. The function <em>f</em> is the same (that is, has the same weights) for all steps of the process.</p>
<p>Note that we have an iterative (or recurrent) process, where the states at step <em>t</em> are based on the number of steps up to <em>t-1</em><span>, as follows</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1383 image-border" src="assets/9e7c34c0-c84f-4979-b13c-02c9e6d344f3.png" style="width:29.42em;height:5.58em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The recurrent process of updating the feature vector states; the <strong>Grec</strong> recurrent layer is the same (that is, has the same weights) for all steps; Source: https://arxiv.org/abs/1901.00596</div>
<p><span>The process continues</span><span> until a stable equilibrium is reached. </span>For this to work, the function <em>f</em> must be a contraction mapping. Let's clarify this: when applied to any two points (or values) A and B, a contraction mapping function <em>f</em> satisfies the condition <img class="fm-editor-equation" src="assets/6a9b9e1e-bd66-4509-9081-1d2371d51fb5.png" style="width:11.50em;height:1.17em;"/>, where γ is a scalar value and <img class="fm-editor-equation" src="assets/20f023c9-77a0-42d0-b88d-6a2f2359c604.png" style="width:4.25em;height:1.08em;"/>. In other words, <span>the contraction mapping shrinks the distance between two points after mapping. This ensures that the system will converge (exponentially quickly) to the equilibrium state vector <img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:0.92em;height:0.83em;"/> for any initial value <img class="fm-editor-equation" src="assets/3601a48a-7d0c-4dd3-98f6-112e93dd8b86.png" style="width:1.75em;height:1.50em;"/>. We can modify an NN to be a contracting function, but this goes beyond the scope of this book. </span></p>
<p>Now that we have the hidden state, we can use it for tasks such as node classification. We can express this with the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/db4574c8-41af-44da-9fb4-7e90b7721985.png" style="width:7.58em;height:1.42em;"/></p>
<p>In this equation, <img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:1.17em;height:1.08em;"/> is the state once an equilibrium is reached and <em>g</em> is a parametric function—for example, a fully connected layer with softmax activation for classification tasks. </p>
<p>Next, let's look at how to train the GraphNN, given a set of training labels <em>t<sub>i</sub></em> for some or all graph nodes and a mini-batch of size <em>m</em>. To train the GraphNN, go through the following steps:</p>
<ol>
<li>Compute <img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:1.25em;height:1.17em;"/>and <em>o<sub>v</sub></em> for all <em>m</em> nodes, following the recurrent process we just described.</li>
<li>Compute the cost function (<em>t<sub>i</sub></em> is the label of node <em>i</em>):</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/bd326435-7a13-4c36-b3ac-25821841be2e.png" style="width:6.33em;height:2.67em;"/></p>
<ol start="3">
<li>Propagate the cost backward. Note that <span>alternating the node state update of step 1 with the gradient propagation of the current step allows GraphNN to process cyclic graphs. </span></li>
<li>Update the weights of the combined network <em>g(f)</em>.</li>
</ol>
<p>GraphNN has several limitations, one of which is that computing the <span>equilibrium state vector </span><img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:1.25em;height:1.17em;"/> is not efficient. Furthermore, as we mentioned previously in this section, GraphNN uses the same parameters (weights) to update <img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:1.17em;height:1.08em;"/> over all steps <em>t</em>. In contrast, other NN models can use multiple stacked layers with different sets of weights, which makes it possible for us to capture the hierarchical structure of the data. It also allows us to compute <img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:1.25em;height:1.17em;"/> in a single forward pass. Finally, it's worth mentioning that, although computing <img class="fm-editor-equation" src="assets/b0bb88a6-0596-4699-a87a-446972438586.png" style="width:1.00em;height:0.92em;"/> is a recurrent process, GraphNN isn't a recurrent network. </p>
<p>The <strong>Gated Graph NN</strong> model (<strong>GGNN</strong>, <a href="https://arxiv.org/abs/1511.05493">https://arxiv.org/abs/1511.05493</a>) tries to overcome these limitations with the help of <strong>Gated Recurrent Unit</strong> cells (or <strong>GRU</strong>; for more information, see <a href="379a4f7b-48da-40f2-99d6-ee57a7a5dcca.xhtml">Chapter 7</a>, <em>Understanding Recurrent Networks</em>) as a recurrent function. We can define <span>GGNN</span> as the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c6865cb0-0fab-4627-b4b6-02ff5cb78f3d.png" style="width:15.75em;height:2.92em;"/></p>
<p>In the preceding formula, <img class="fm-editor-equation" src="assets/e46f22e8-6d32-4c56-8d73-4470554a49de.png" style="width:3.58em;height:1.25em;"/>. To clarify, <span>GGNN updates the state based on its neighboring states <img class="fm-editor-equation" src="assets/d3c1e172-c9e8-4106-a5b6-54d77730e785.png" style="width:1.42em;height:1.25em;"/> of the same step <em>t</em> and its previous hidden state <img class="fm-editor-equation" src="assets/75ceb0fc-8945-42a1-b824-4096c1bb42a0.png" style="width:2.50em;height:1.42em;"/>.</span></p>
<p>From a historical perspective, GraphNNs were one of the first GNN models. But as we mentioned, they have some limitations. In the next section, we'll discuss Convolutional Graph Networks, which are a more recent development.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional Graph Networks</h1>
                </header>
            
            <article>
                
<p><span><strong>Convolutional Graph Networks</strong> (<strong>ConvGNN</strong>) use a stack of special graph convolutional layers (Gconv*) to perform a convolution over the nodes of a graph when updating the state vectors. In a similar way to GraphNNs, the graph convolution takes the neighbors of a node and produces its vector representation <img class="fm-editor-equation" src="assets/6f08cd10-d31e-4f38-ac59-8cabc213aad4.png" style="width:1.25em;height:1.17em;"/>. But whereas GraphNN uses the same layer (that is, the same set of weights) over all steps <em>t</em> of the computation of <img class="fm-editor-equation" src="assets/bf2fd2ce-b2d5-48fa-8702-dbbeeea83486.png" style="width:1.67em;height:1.50em;"/>, ConvGNN uses different layers at every step.</span> The difference between the two approaches is illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1384 image-border" src="assets/75832ae4-bfe8-484e-a504-9eefdee3a8bb.png" style="width:17.92em;height:6.83em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Top: GraphNN uses the same Grec recurrent layer over all steps t; Bottom: GCN uses a different Gconv<sub>*</sub> layer for each step; <span>Source: </span>https://arxiv.org/abs/1901.00596</div>
<p><span>With ConvGNN, the number of steps <em>t</em> is defined by the depth of the network. Although </span><span>we will discuss this from a somewhat different perspective, ConvGNN behaves as a regular</span> FFNN, but with graph convolutions. By stacking multiple layers, the final hidden representation of each node receives messages from a further neighborhood, as we can see in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1385 image-border" src="assets/90f9c2fd-c6b9-4b89-a3af-73dd9243052f.png" style="width:30.50em;height:21.08em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Top: Node-level classification GraphCN; Bottom: Graph-level classification GraphCN. <span>Source: </span>https://arxiv.org/abs/1901.00596 </div>
<p>The diagram shows two scenarios:</p>
<ul>
<li>
<p>Node-level (top), where the output of each convolutional layer (including the last) is a vector for each node of the graph. We can perform node-level operations over these vectors.</p>
</li>
<li>
<p>Graph-level (bottom), which alternates graph convolutions and pooling operations and ends with a readout layer, followed by several fully connected layers that summarize the whole graph to produce a single output. </p>
</li>
</ul>
<p>Now that we have a high-level overview of<span> </span><span>ConvGNN</span>, in the following section, we'll discuss graph convolutions (and after that, we'll talk about the readout and pooling layers).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Spectral-based convolutions</h1>
                </header>
            
            <article>
                
<p>There are various types of graph convolutions (check out <em>A Comprehensive Survey on Graph Neural Networks</em>)<span>, but in this section, we'll discuss the algorithm from <em>Semi-Supervised Classification with Graph Convolutional Networks</em> (<a href="https://arxiv.org/abs/1609.02907">https://arxiv.org/abs/1609.02907</a>). We'll denote this convolution with GCN to avoid confusion with the general ConvGNN notation, which refers to graph convolutional networks in general. </span>GCN is a representative of the so-called <strong>spectral-based</strong> category of<span> </span><span>ConvGNNs</span>. These algorithms define graph convolutions by introducing filters from the perspective of graph-signal processing, where the graph convolutional operation is interpreted as removing noises from graph signals.</p>
<p><span>In the <em>Graph neural network</em> section<em>,</em> we defined the hidden node state <img class="fm-editor-equation" src="assets/b1e6e909-4469-4c99-8193-9c922b7114c7.png" style="width:1.75em;height:1.58em;"/> and noted that <img class="fm-editor-equation" src="assets/f907d77e-60b9-436e-a154-6b69b18be076.png" style="width:4.33em;height:1.50em;"/> in the case of GGNN. Let's extend this notation by stacking the hidden vector states of all nodes in the graph in a matrix <img class="fm-editor-equation" src="assets/b2332c0f-094d-4ecb-94e0-a1d354281c7d.png" style="width:3.33em;height:0.83em;"/>, where <em>n</em> is the total number of nodes in the graph and <em>d</em> is the size of the feature vectors. Each row of the matrix represents the hidden state of a single node. Then, we can define the generic formula for a single GCN layer at step <em>l+1</em> as the following:<br/></span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/145d7088-3fdd-4fae-ae22-91ca8ce6b26c.png" style="width:8.33em;height:1.33em;"/></p>
<p>Here, <strong>A</strong> is the adjacency matrix, <em>f</em> is a nonlinear activation, such as ReLU, and <img class="fm-editor-equation" src="assets/49f58e0e-95c2-4168-b77d-3e0cfa0058e4.png" style="width:3.58em;height:1.00em;"/> (the feature vector matrix). <span>Since </span><img class="fm-editor-equation" src="assets/7562814c-e3e6-4725-83d2-ce4ee25ae57c.png" style="width:1.67em;height:1.42em;"/><span> and </span><img class="fm-editor-equation" src="assets/8630b436-b3bc-4ec0-89fe-8bc4fb72235b.png" style="width:1.25em;height:0.83em;"/><span> have the same size,</span><span> </span><img class="fm-editor-equation" src="assets/95d3840b-a76f-4f57-b8bb-69b70ff60f2f.png" style="width:1.92em;height:1.17em;"/><span> has the same dimensions as the node feature matrix </span><strong>X</strong><span> (see the</span> <em>Graph neural networks </em><span>section</span><span>). </span><span>However, </span><img style="font-size: 1em;width:4.67em;height:1.00em;" class="fm-editor-equation" src="assets/05b65ee5-1076-4b17-a762-c2bd6b74bf16.png"/><span>, where</span> <em>z</em> <span>is the size of the hidden state vector</span> <img style="font-size: 1em;width:1.50em;height:1.33em;" class="fm-editor-equation" src="assets/150965c7-c90c-4a99-99be-972af915b99d.png"/><span> and is not necessarily the same as the initial </span><em>d</em><span>. </span></p>
<p class="mce-root"/>
<p>Let's continue with a <span>simplified but</span> concrete version of the GCN:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/181962b9-f896-49b5-9978-75461955b3af.png" style="width:11.67em;height:1.33em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/b3c301c4-c317-4e82-8ab4-3e9b17d1d5b5.png" style="width:5.67em;height:1.00em;"/> is a weight matrix and σ is the sigmoid function. Since <span>the adjacency matrix <strong>A</strong> represents the graph in matrix form, we can compute the output of the layer in a single operation. The <img class="fm-editor-equation" src="assets/fa44df2d-508c-42aa-a875-20de6c4de0f9.png" style="width:1.92em;height:0.83em;"/> operation allows each node to receive input from its neighboring nodes (it also allows GCN to work with both directed and undirected graphs). Let's see how this works with an example. We'll use the five-node graph that we introduced in the <em>Graph neural networks </em></span><span>section</span><em>.</em> <span>For the sake of readability, we'll assign a one-dimensional vector hidden state </span><img style="font-size: 1em;width:1.00em;height:0.92em;" class="fm-editor-equation" src="assets/712b0558-85ca-42f7-9e12-f4c66e78f352.png"/> <span>for each node with a value equal to the node number</span><img style="font-size: 1em;width:16.83em;height:1.33em;" class="fm-editor-equation" src="assets/ac37c382-7f41-405e-bd39-1cf4acf16e4d.png"/><span>. Then we can compute the example with the following formula:</span></p>
<p style="padding-left: 90px" class="mce-root"><img src="assets/f1d830f5-de0c-4fcd-94f8-5876ec5da8cc.png" style="width:29.08em;height:5.33em;"/></p>
<p>We can see how <img class="fm-editor-equation" src="assets/2a88e6d6-53ea-4b02-977e-90196ff09f68.png" style="width:2.92em;height:1.17em;"/> because it receives input from nodes 2, 3, and 5. If <img class="fm-editor-equation" src="assets/712b0558-85ca-42f7-9e12-f4c66e78f352.png" style="width:0.92em;height:0.83em;"/> had more dimensions, then each cell of the output vector would be a sum of the corresponding cells of the state vectors of the input nodes:</p>
<p style="padding-left: 180px"><img src="assets/72198d96-67d3-4f33-bf65-0a078dfcf0fd.png" style="width:17.58em;height:6.25em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/a64b3256-e78f-4152-b6ae-e3ef4f263258.png" style="width:1.67em;height:1.00em;"/> are the cells of the adjacency matrix. </p>
<p>Although this solution is elegant, it has two limitations:</p>
<ul>
<li>Not all nodes receive input from their own previous state. In the preceding example, only node 2 takes input from itself because it has a loop edge (this is the edge that connects the node to itself). The solution to this problem is to artificially create loop edges for all nodes by setting all values along the main diagonal of the adjacency matrix to ones: <img class="fm-editor-equation" src="assets/7ba61638-6168-435c-8cff-ba793c77c713.png" style="width:4.00em;height:1.00em;"/>. In this equation, <strong>I</strong> is the identity matrix, which has ones along the main diagonal and zeros in all other cells.</li>
<li>Since <strong>A</strong> is not normalized, the state vectors of nodes with a large number of neighbors will change their scale in a different way compared to nodes with a smaller number of neighbors. We can see this in the preceding example, where <img class="fm-editor-equation" src="assets/82a870e8-c31a-4587-a0b3-572fa5aa1099.png" style="width:3.17em;height:1.25em;"/> is larger compared to the other nodes because node 4 has 3 nodes in its neighborhood. The solution to this problem is to normalize the adjacency matrix in such a way that the sum of all elements in one row is equal to 1: <img class="fm-editor-equation" src="assets/d2340045-f977-47fe-98c8-f1f2c167e1f6.png" style="width:9.33em;height:1.00em;"/>. We can achieve this by multiplying <strong>A</strong> by the<span> inverse degree matrix <strong>D</strong><sup>-1</sup>. The degree matrix <strong>D</strong> is a diagonal matrix (that is, all other elements except the main diagonal are zeros) that contains information about the degree of each node. We refer to the number of neighbors of a node as a degree of that node. For example, the degree matrix of our example graph is the following:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d6e2c432-11b2-4ea4-ade3-a9b3e6a13ff0.png" style="width:6.92em;height:4.50em;"/></p>
<p style="padding-left: 60px"><span>Therefore, <strong>D</strong><sup>-1</sup><strong>A</strong> becomes the following:</span></p>
<p style="padding-left: 120px"><img src="assets/441e83ce-02c3-40d5-bfac-0b6e443512a6.png" style="width:28.67em;height:6.42em;"/></p>
<p style="padding-left: 60px">This mechanism assigns the same weight to each of the neighboring nodes. In practice, the authors of the paper discovered that using the symmetric normalization <img class="fm-editor-equation" src="assets/9f5251dd-2d80-411a-b3ed-76f750f333c8.png" style="width:3.83em;height:1.08em;"/>works better.</p>
<p>After we incorporate these two improvements, the final form of the GCN formula can be written as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3baa1355-11c2-4958-9f68-0ce56e796f8c.png" style="width:17.50em;height:2.08em;"/></p>
<p>Note that the GCN we just described includes only the immediate neighborhood of the node as the context. Each stacked layer effectively increases the receptive field of the node beyond its immediate neighbors by 1. The receptive field of the second layer of a ConvGNN includes the immediate neighbors, the receptive field of the second layer includes the nodes that are two hops away from the current node, and so on. </p>
<p>In the next section, we'll look at the second major category of graph convolution operations, called<span> spatial-based convolutions</span>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Spatial-based convolutions with attention</h1>
                </header>
            
            <article>
                
<p><span>The second</span><span> </span><span>ConvGNN</span> <span>category is spatial-based methods, which take inspiration from the computer vision convolution (</span><span><a href="d94e220f-820e-40da-8bb5-9593e0790b21.xhtml">Chapter 2</a>,</span> <em>Understanding Convolutional Networks</em><span>). We can think of an image as a graph, where each pixel is a node, directly connected to its neighboring pixels (the left-hand image in the following diagram). For example, if we use 3 × 3 as a filter, the neighborhood of each pixel consists of eight pixels. In the image convolution, this 3 × 3 weighted filter is applied over the 3 × 3 patch and the result is a weighted sum of the intensities of all nine pixels. Similarly, the spatial-based graph convolution convolves the representation of the central node with the representations of its neighbors to derive an updated representation for the central node, as illustrated in the right-hand image in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><span><img class="aligncenter size-full wp-image-1386 image-border" src="assets/ff69efd8-2240-4c09-91b1-0dc56b8601e9.png" style="width:18.58em;height:8.08em;"/></span></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Left: 2D convolution over a pixel grid; Right: Spatial graph convolution. <span>Source: </span>https://arxiv.org/abs/1901.00596</div>
<p class="mce-root">The generic spatial-based convolution is somewhat similar to the GCN in the sense that both operations rely on graph neighbors. The GCN uses the inverse degree matrix to assign weights to each neighbor. Spatial convolutions use the convolution filter for the same purpose. The main difference between the two is that in the case of GCNs, the weights are fixed and normalized, whereas the filter weights of the spatial convolution are learnable and not normalized. In some sense, we can think of the GCN as a spatial-based approach as well.</p>
<p>We'll continue this section with a specific type of spatial-based model called the <strong>Graph Attention Network</strong> (<strong>GAT</strong>) (for more information, go to <a href="https://arxiv.org/abs/1710.10903">https://arxiv.org/abs/1710.10903</a>), which implements graph convolutions with a special graph self-attention layer. Instead of learning a convolutional filter or using the averaged adjacency matrix as a GCN, GAT uses the attention scores of the self-attention mechanism to assign weights to each of the neighboring nodes. The GAT layer is the main building block of graph attention networks, which consist of multiple stacked GAT layers. As with GCN, each additional layer increases the receptive field of the target node. </p>
<p>Similar to GCN, the GAT layer takes as input a set of node feature vectors <img class="fm-editor-equation" src="assets/c8d92091-850b-429b-9887-f9951f2b976f.png" style="width:5.08em;height:1.08em;"/> and outputs a different set of feature vectors <img class="fm-editor-equation" src="assets/94b3890d-c654-4568-a6e0-7b28defceaa8.png" style="width:6.58em;height:1.08em;"/>, not necessarily of the same cardinality. Following the procedure we outlined in <span><a href="0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml">Chapter 8</a>, </span><em>Sequence-to-Sequence Models and Attention</em>, the operation starts by computing the alignment scores between the feature vectors <img class="fm-editor-equation" src="assets/22e50d7b-c169-4fe9-9244-60ca93fa9882.png" style="width:1.33em;height:1.33em;"/> and <img class="fm-editor-equation" src="assets/25e3efe7-32af-43ac-8b81-e7d78773b0fd.png" style="width:1.42em;height:1.50em;"/> of each two nodes of the neighborhood:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e6e85a94-9570-4d47-9407-50a8683c25e8.png" style="width:10.25em;height:1.33em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/dda45c47-d17b-4ed9-a7ed-3d28f1e198fb.png" style="width:6.25em;height:1.08em;"/> is a weight matrix that transforms the input vectors to the cardinality of the output vectors and provides the necessary learnable parameters. The <em>f<sub>a</sub></em> expression is a simple FFN with a single layer and LeakyReLU activation, which is parameterized by a weight vector <img style="font-size: 1em;width:4.50em;height:1.17em;" class="fm-editor-equation" src="assets/722ace34-34b7-4991-a8e3-5f3ab6c05625.png"/><span> and implements the additive attention mechanism:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c7f67757-7c1b-422f-9386-391ea231573b.png" style="width:15.75em;height:1.33em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/cfa05b0f-6474-45b1-9e53-9721753eb371.png" style="width:6.42em;height:1.25em;"/> represents concatenation.<span> If we don't impose any restrictions</span><span>, each node will be able to attend to all other nodes of the graph, regardless of their proximity to the target node; however, we're only interested in the neighboring nodes. The authors of GAT propose to solve this by using masked attention, where the mask covers all nodes that are not immediate neighbors of the target node. We'll denote the immediate neighbors of node <em>i</em> with <img class="fm-editor-equation" src="assets/aff2d979-9d86-46ce-a910-60474eb51ada.png" style="width:0.92em;height:0.83em;"/>.</span></p>
<p>Next, we compute attention scores by using softmax. The following are the generic formula and the formula with <em>f<sub>a</sub></em> (applied only over the immediate neighbors):</p>
<p style="padding-left: 90px"><img src="assets/d88cf72d-7ec5-4a14-a934-b8d252571566.png" style="width:30.33em;height:7.58em;"/></p>
<p>Once we have the attention scores, we can use them to compute the final output feature vector of each node (we referred to this as the context vector in <a href="0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml">Chapter 8</a>, <em>Sequence-to-Sequence Models and Attention</em>), which is a weighted combination of the input feature vectors of all neighbors:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/78546e42-dca7-43b1-9697-59eab1457c33.png" style="width:10.67em;height:2.50em;"/></p>
<p>Here, σ is the sigmoid function. The authors of the paper also found multihead attention to be beneficial to the performance of the model:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/88571404-92dd-4633-b741-4b6ee1978dcc.png" style="width:16.92em;height:2.42em;"/></p>
<p>Here, <em>k</em> is the index of each head (for a total of <em>K</em> heads), <img class="fm-editor-equation" src="assets/8969baab-d817-478e-b2fe-06e80d6affc7.png" style="width:1.75em;height:1.75em;"/> are the attention scores for each attention head, and <img class="fm-editor-equation" src="assets/152f315b-ca65-41dc-a5b5-2d1e1a86a10b.png" style="width:2.83em;height:1.08em;"/>is the weight matrix of each attention head. <span>Since</span> <img style="font-size: 1em;width:2.25em;height:1.42em;" class="fm-editor-equation" src="assets/2ce5f52e-452e-46cb-8bf7-2bdd2ed5d3a8.png"/><span> is a result of concatenation, its cardinality will be</span> <em>k × z<sub>l+1</sub></em><span>. Because of this, concatenation is not possible in the final attention layer of the network. To solve this, the authors of the paper suggest that you should average the outputs of the attention heads in the final layer (denoted with index </span><em>L</em><span>):</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/07cb2578-7a7a-48e3-ad4c-2f725c517613.png" style="width:18.83em;height:3.58em;"/></p>
<p>The following diagram shows a comparison between regular and multihead attention in the GAT context. In the left image, we can see the regular attention mechanism, applied between two nodes and <em>i</em> and <em>j</em>. In the right image, we can see the multihead attention with <em>k = 3</em> heads of node <em>1</em> with its neighborhood. The aggregated features are either concatenated (for all hidden GAT layers) or averaged (for the final GAT layer):</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1432 image-border" src="assets/7ec5f308-a34d-4a98-9ad7-2afb2b22536f.png" style="width:33.92em;height:16.08em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Left: Regular attention over two nodes; Right: Multihead attention of node 1 with its neighborhood. Source: https://arxiv.org/abs/1710.10903 </div>
<p>Once we have the output of the final GAT layer, we can use it as input to the next task-specific layers. For example, this could be a fully connected layer with softmax activation for node classification. </p>
<p>Before we conclude this section devoted to ConvGNNs, let's discuss two final components that we haven't addressed yet. The first is the readout layer that we introduced in the graph-level classification example at the beginning of the <em>Convolutional</em> <em>Graph</em> <em>Networks</em> sectio<span>n</span><span>. It takes as input all the node states of the last graph convolutional layer</span> <strong>H</strong><sup>(<em>L</em>)</sup><span> and outputs a single vector that summarizes the whole graph. We can define it formally as the following:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/02793365-ff3a-479e-bef6-59c93a6c6798.png" style="width:7.67em;height:1.25em;"/></p>
<p>Here, <em>G</em> represents the set of graph nodes and <em>R</em> is the readout function. There are various ways to implement it, but the simplest is to take the element-wise sum or mean of all node states.</p>
<p>The next (and final) ConvGNN component we'll look at is the pooling operation. Once again, there are various ways to use this, but one of the simplest is to use the same max/average pooling operations as we did in the computer vision convolutions:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/20c1fb51-9f9a-46b6-a295-1e57bf879451.png" style="width:17.50em;height:1.50em;"/></p>
<p>Here, <em>p</em> indicates the size of the pooling window. If the pooling window contains the whole graph, the pooling becomes similar to the readout. </p>
<p>This concludes our discussion about ConvGNNs. In the next section, we'll discuss graph autoencoders, which provide a way to generate new graphs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Graph autoencoders</h1>
                </header>
            
            <article>
                
<p>Let's have a quick recap of autoencoders, which<span> we first introduced in <a href="319c18b2-c733-402e-937c-ace912ff87ca.xhtml">Chapter 5</a>,<em> </em></span><em>Generative Models</em>. An <strong>autoencoder</strong> is an FFN that tries to reproduce its input (<span>more accurately, it tries to learn an identity function, </span><img class="fm-editor-equation" src="assets/9b1a90cb-7d76-4d0a-b2ac-ab69e9a8f07e.png" style="width:5.67em;height:1.25em;"/><span>).</span> We can think of the autoencoder as a virtual composition of two components—the <strong>encoder</strong>, which maps the input data to the network's internal latent feature space (represented as vector <em>z</em>)<em>,</em> and the <strong>decoder</strong><span>, which tries to reconstruct the input from the network's internal data representation. </span>We can train the autoencoder in an unsupervised way by minimizing a loss function (known as a <strong>reconstruction error)</strong>, which measures the distance between the original input and its reconstruction.</p>
<p><strong>Graph autoencoders</strong> (<strong>GAE</strong>) are similar to autoencoders, with the distinction that the encoder maps the graph nodes into the autoencoder latent feature space and then the decoder tries to reconstruct specific graph features from it. In this section, we'll discuss a GAE variant, introduced in <em>Variational Graph Auto-Encoders</em> (<a href="https://arxiv.org/abs/1611.07308">https://arxiv.org/abs/1611.07308</a>), which also outlines the variational version of GAE (<strong>VGAE</strong>). The following <span>diagram </span>shows an example GAE:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1388 image-border" src="assets/ad20131f-4b1e-4cd7-b137-7c2e4b24725b.png" style="width:42.50em;height:11.50em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">An example of graph autoencoder.<span> </span><span>Source: </span>https://arxiv.org/abs/1901.00596</div>
<p><span>The encoder is a GCN model that we defined in the <em>Spectral-based convolutions</em> </span><span>section </span><span>to compute a network embedding</span><img style="font-size: 1em;width:4.08em;height:1.08em;" class="fm-editor-equation" src="assets/e799be66-a517-4c9e-b202-62de22c1ae57.png"/><span> for graph nodes, where the embedding for each of the</span> <em>n</em> <span>total nodes is a</span> <em>d</em><span>-dimensional vector</span> <strong>z</strong><span>. It takes as input the adjacency matrix </span><strong>A</strong><span> and the set of node feature vectors </span><strong>X</strong><span> (like the other GNN models we discussed in this chapter). The encoder is represented by the following formula:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d0753995-166a-4769-8d36-7d50faced583.png" style="width:21.83em;height:1.00em;"/></p>
<p>Here, <strong>W<sub>1</sub></strong> and <strong>W<sub>2</sub></strong> are the learnable parameters (weights) of the two GCN graph convolutions, and <em>f</em> is a nonlinear activation function, like ReLU. <span>The authors of the paper use two graph convolutional layers, although the proposed algorithm can work for any number of layers. </span></p>
<p><span>The decoder tries to reconstruct the graph adjacency matrix <img class="fm-editor-equation" src="assets/3f98fb9c-d5e9-454b-9459-6b3c28bfe9c7.png" style="width:0.92em;height:1.17em;"/>:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2ccf67b6-cb38-47a2-b535-a03c5c14aa87.png" style="width:5.17em;height:1.25em;"/></p>
<p><span>Here, σ is the sigmoid function. It first computes the dot (or inner) product between <strong>Z</strong> and its transpose: <img class="fm-editor-equation" src="assets/c60a2b16-86cd-4a4a-b5ec-5a9ced360624.png" style="width:1.58em;height:0.83em;"/>. </span><span>To clarify, this operation computes a dot product of the vector embedding <em>z<sub>i</sub></em> of each node <em>i</em> and the vector embedding <em>z<sub>j</sub></em> of every other node <em>j</em> of the graph, as shown in the following example:</span></p>
<p style="padding-left: 60px"><img src="assets/8f72a2b2-988f-4043-a076-8ad4bc89f926.png" style="width:36.08em;height:6.25em;"/></p>
<p><span>As we mentioned in <a href="b94f711b-daab-4de7-97b7-b7efccd0b392.xhtml">Chapter 1</a>, <em>The Nuts and Bolts of Neural Networks</em>, we can think of the dot product as a similarity measure between vectors. Therefore, <img class="fm-editor-equation" src="assets/2921f759-7c77-4965-95a0-a5832062c067.png" style="width:1.58em;height:0.83em;"/> measures the distance between every possible pair of nodes. These distances serve as a base for the reconstruction effort. </span><span>After this, the decoder applies a nonlinear activation function and proceeds to reconstruct the graph adjacency matrix.</span><span> </span><span>We can train the GAE by minimizing the discrepancy between the real reconstructed adjacency matrices. </span></p>
<p>Next, let's focus on <strong>Variational Graph Autoencoders</strong> (<strong>VGAE</strong>). Much like the <strong>Variational Autoencoders</strong> (<strong>VAE</strong>) we discussed in <a href="319c18b2-c733-402e-937c-ace912ff87ca.xhtml">Chapter 5</a>, <em>Generative Models</em>, the VGAE is a generative model that can generate new graphs (more specifically, new adjacency matrices). To understand this, let's start with a short recap of VAEs. Unlike regular autoencoders, <span>the VAE bottleneck layer won't directly output latent state vectors. Instead, it will output two vectors, which describe the</span><span> </span><strong>mean</strong><span> μ </span><span>and the</span><span> </span><strong>variance</strong><span> σ </span><span>of the distribution of the latent vector <strong>z</strong>. </span>We'll use them to sample<span> </span>a random vector <span>ε with the same dimensions as <strong>z</strong> </span>from a<span> </span>Gaussian<span> </span>distribution<span class="MathJax"><span class="math"><span><span class="mrow"><span class="mi">. More specifically, we'll shift ε by</span></span></span></span></span><span> </span>the latent distribution's mean <span class="MathJax"><span class="MJX_Assistive_MathML">μ</span></span><span> </span>and scale it by the latent distribution's variance <span class="MathJax"><span class="math"><span><span class="mrow"><span class="mi">σ:</span></span></span></span></span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b8e54537-e06d-4f5f-aa11-7fccb06056bc.png" style="width:5.58em;height:0.92em;"/></p>
<p>This technique is known as the <strong>reparameterization</strong> trick, and it allows the random vector to have the same mean and variance as the original dataset.</p>
<p>We can think of VGAE as a combination of GAE and VAE in the sense that it works with graph inputs (such as GAE) and follows the same principles to generate new data (like VAE). First, let's focus on the encoder, which is split into two paths<span class="MathJax"><span class="math"><span><span class="mrow"><span class="mi">:</span></span></span></span></span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/79b471f1-7bc7-43e7-ae07-ea9e44021ce1.png" style="width:18.00em;height:2.75em;"/></p>
<p>Here, the weights <strong>W<sub>0</sub></strong><span> are shared between the paths, <em><img class="fm-editor-equation" src="assets/37a71eea-c7d9-44c7-9af8-f0b2cc2217cc.png" style="width:0.92em;height:1.17em;"/></em> is the symmetrically normalized adjacency matrix, </span><span class="MathJax"><span class="MJX_Assistive_MathML"><em><strong>μ</strong></em> is the matrix of mean vectors <em><strong>μ</strong><sub>i</sub></em>, and <strong><em>σ</em></strong> is the matrix of variances </span></span><span class="MathJax"><span class="math"><span><span class="mrow"><span class="mi"><em><strong>σ</strong><sub>i</sub></em> of each graph node. Then, the encoder inference step for the full graph is defined as the inner product of the latent representations of all graph nodes <em>i</em>:</span></span></span></span></span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4b4675d4-526e-406a-9f32-a24fb0b4444b.png" style="width:12.17em;height:2.75em;"/></p>
<p>In this formula, <em>n</em> is the number of nodes in the graph and <img class="fm-editor-equation" src="assets/bf7e4027-8056-49cc-ba8d-d2bdc0e9618e.png" style="width:5.00em;height:1.17em;"/> represents the encoder approximation of the real probability distribution <img class="fm-editor-equation" src="assets/9451f080-cacc-4328-a19d-760505c64b27.png" style="width:4.42em;height:1.08em;"/>, where <span><em>φ</em> is the network parameters</span> (here, we have preserved the notation of <a href="319c18b2-c733-402e-937c-ace912ff87ca.xhtml">Chapter 5</a>, <em>Generative Models</em>). The approximation is a<span> Gaussian distribution with node-specific mean </span><em>μ<sub>i</sub></em><span> and diagonal covariance values </span><img class="fm-editor-equation" src="assets/2f51c5e2-c99d-47ca-bb62-40c4b90271e7.png" style="width:1.17em;height:1.50em;"/>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0778279e-d32e-46ba-8829-8147a91ed5ae.png" style="width:16.08em;height:1.50em;"/></p>
<p>Next, we define the generative step, which creates the new adjacency matrix. It is an inner product of the<span> random latent vectors</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/033b088c-576d-467d-b720-253c5476b649.png" style="width:15.25em;height:3.42em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/9ca6cbb0-7521-41d1-a4d5-7c34c4c78dd7.png" style="width:1.92em;height:1.25em;"/><span> indicates whether an edge exists between two nodes </span><em>i</em><span> and </span><em>j</em><span>, and</span> <img class="fm-editor-equation" src="assets/154fcf49-1337-4f63-982d-b95af38be050.png" style="width:5.42em;height:1.08em;"/> represents the decoder approximation of the real probability <img class="fm-editor-equation" src="assets/7daf605e-a4ff-4848-85e4-4628a726bec9.png" style="width:5.75em;height:1.25em;"/>. We can train the VGAE using the already familiar VAE cost:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/98b1075f-740f-4e14-bae3-2ef89538d3d8.png" style="width:29.17em;height:1.42em;"/></p>
<p><span>Here, the first term is the Kullback–Leibler divergence and</span><span> the second is the reconstruction cost.</span></p>
<p>This concludes our description of GAE and VGAE. In the next section, we'll discuss yet another graph-learning paradigm, which makes it possible to mix structured and unstructured data as network inputs. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural graph learning</h1>
                </header>
            
            <article>
                
<p>In this section, we'll describe the <strong>Neural Graph Learning</strong> paradigm (<strong>NGL</strong>) (for more information, see <em>Neural Graph Learning: Training Neural Networks Using Graphs</em> at <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/bbd774a3c6f13f05bf754e09aa45e7aa6faa08a8.pdf">https://storage.googleapis.com/pub-tools-public-publication-data/pdf/bbd774a3c6f13f05bf754e09aa45e7aa6faa08a8.pdf</a>), which makes it possible to augment training based on unstructured data with structured signals. More specifically, we'll discuss the <strong>neural structured learning</strong> framework (<strong>NSL</strong>) (for more information, go to <a href="https://www.tensorflow.org/neural_structured_learning/">https://www.tensorflow.org/neural_structured_learning/</a>), which is based on TensorFlow 2.0 and implements these principles.</p>
<p>To understand how NGL works, we'll use the CORA dataset (<a href="https://relational.fit.cvut.cz/dataset/CORA">https://relational.fit.cvut.cz/dataset/CORA</a>), which consists of <span>2,708 scientific publications classified into 1 of 7 classes (this is the unstructured part of the dataset). The number of unique words in all publications (that is, the vocabulary) in the dataset is 1,433. Each publication is described as a single <strong>multihot</strong> encoded vector. This is a vector of size 1,433 (the same as the vocabulary), where the cell values are either 0 or 1. If a publication contains the <em>i-</em>th word of the vocabulary, then the <em>i</em>th cell of the one-hot encoded vector of that publication is set to 1. If the word is not present in the publication, the cell is set to 0. This mechanism preserves information about the words present in an article, but not information about their order. The dataset also contains a directed graph of 5,429 citations, where the nodes are publications and the edges between them indicate whether publication <em>v</em> cites publication <em>u</em> (this is the structured part of the dataset).</span></p>
<p><span>Next, let's focus on NGL itself, starting with the</span> following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1389 image-border" src="assets/3465ccd4-42ab-4e41-9ebb-38a0638e7460.png" style="width:45.17em;height:16.50em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The <span>NGL</span> framework: green solid lines show the unstructured input data flow; yellow dashed lines show the structured signals data flow; Inspired by: https://www.tensorflow.org/neural_structured_learning/framework</div>
<p class="mce-root"><span>It acts as a kind of wrapper over the regular NN training framework, and it can be applied over any type of network, including FFN and RNN. For example, we can have a regular FFN, which takes as input the multihot encoded publication vector and tries to classify it to one of the 7 classes, using softmax output, as illustrated in the preceding diagram with green uninterrupted lines. NGL allows us to extend this network with structured data, offered by the citations, as illustrated by the yellow dashed lines.</span></p>
<p class="mce-root"><span>Let's look at how this works. We start with the assumption that neighboring nodes in the graph are somewhat similar. We can transfer this assumption to the NN domain by saying that the embedding vector produced by the NN (the embedding is the output of the last hidden layer) of sample <em>i</em> should be somewhat similar to the embedding of sample <em>j</em>, provided that the two samples are neighbors in the associated graph. In our example, we can assume that the embedding vector of publication <em>i</em> should be similar to the embedding of publication <em>j</em>, provided that one of them cites the other (that is, they are neighbors in the graph of citations). In practice, we can implement this with the following steps:</span></p>
<ol>
<li>Start with a dataset that contains both unstructured data (multihot-encoded publications) and structured data (the graph of citations).</li>
<li>Build special types of composite training samples (organized in batches), where each composite sample consists of a single regular input sample (one multihot-encoded publication) and <em>K</em> of its neighboring samples (the multihot-encoded publications that cite or are cited by the initial sample).</li>
<li>Feed the composite sample to the NN and produce embeddings for both the initial sample and its neighbors. Although the preceding <span>diagram </span>shows the two paths running in parallel, this is not the case. The <span>diagram </span>aims to illustrate that the network processes both the central sample and its neighbors, but the actual NN is not privy to this arrangement—it just takes all of the multihot-encoded inputs as part of a single batch and processes them. Instead, the NSL portion on top of the regular NN differentiates the two components.</li>
<li>Compute a special type of composite loss function composed of two parts: regular supervised loss and regularization neighbor loss, which uses a metric to measure the distance between the initial sample embedding and the embedding of its neighbors. The neighbor loss is the mechanism that allows us to augment unstructured training data with structured signals. The composite loss is defined as follows:</li>
</ol>
<p style="padding-left: 90px" class="CDPAlignLeft CDPAlign"><img src="assets/e4f50ba5-e319-41ab-8440-81d100e27716.png" style="width:31.50em;height:5.75em;"/></p>
<p style="padding-left: 60px">This formula has the following features:</p>
<ul>
<li><em>n</em> is the number of composite samples in the mini-batch.</li>
<li><img class="fm-editor-equation" src="assets/7ea30bdb-fb32-4c9b-9c37-4ebfca7b74f5.png" style="width:1.17em;height:1.08em;"/> is the supervised loss function.</li>
<li><em>f<sub>θ</sub></em> is the NN function with weights <span><em>θ.</em></span></li>
<li><span><em>α</em> is a scalar parameter that determines the relative weight between the two loss components.</span></li>
<li><span><img class="fm-editor-equation" src="assets/e380c730-c4df-4fa8-b86d-afe275fc6ed0.png" style="width:2.25em;height:1.00em;"/> is the set of graph neighbors of sample <em>x<sub>i</sub></em>. Note that the neighbor loss iterates over all neighbors of all nodes of the graph (two sums).</span></li>
<li><span><img class="fm-editor-equation" src="assets/8dae52a2-49ba-4628-8a68-369127f9643c.png" style="width:1.83em;height:1.17em;"/> is the weight of the graph edge between samples <em>i</em> and <em>j</em>. If the task doesn't have a notion of weights, we can assume that all weights are 1.</span></li>
<li><span><img class="fm-editor-equation" src="assets/9820c380-205c-4127-8628-991725805d52.png" style="width:0.75em;height:0.92em;"/> is the distance metric between the embedding vectors of samples <em>i</em> and <em>j</em>.</span></li>
</ul>
<p style="padding-left: 60px">Because of the regularization nature of the neighbor loss, NGL is also referred to as <strong>graph regularization</strong>.</p>
<ol start="5">
<li>Propagate the error backward and update the network weights <em>θ</em>.</li>
</ol>
<p>Now that we have an overview of graph regularization, let's implement it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing graph regularization</h1>
                </header>
            
            <article>
                
<p>In this section, we'll implement graph regularization over the Cora dataset with the help of the NSL framework. This example is based on the tutorial available at <a href="https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora">https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora</a>. Before we proceed with the implementation, we have to satisfy some prerequisites. First, we need TensorFlow 2.0 and the <kbd>neural-structured-learning</kbd> 1.1.0 package (available via <kbd>pip</kbd>).</p>
<p>Once we satisfy these requirements, we can proceed with the implementation:</p>
<ol>
<li>We'll start with the package imports:</li>
</ol>
<pre style="padding-left: 60px">import neural_structured_learning as nsl<br/>import tensorflow as tf</pre>
<ol start="2">
<li>We'll continue with some constant parameters of the program (hopefully the constant names and the comments speak for themselves):</li>
</ol>
<pre style="padding-left: 60px"><span># Cora dataset path<br/></span>TRAIN_DATA_PATH = <span>'data/train_merged_examples.tfr'<br/></span>TEST_DATA_PATH = <span>'data/test_examples.tfr'<br/></span><span># Constants used to identify neighbor features in the input.<br/></span>NBR_FEATURE_PREFIX = <span>'NL_nbr_'<br/></span>NBR_WEIGHT_SUFFIX = <span>'_weight'<br/></span><span># Dataset parameters<br/></span>NUM_CLASSES = <span>7<br/></span>MAX_SEQ_LENGTH = <span>1433<br/></span><span># Number of neighbors to consider in the composite loss function<br/></span>NUM_NEIGHBORS = <span>1<br/></span><span># Training parameters<br/></span>BATCH_SIZE = <span>128<br/></span></pre>
<p style="padding-left: 60px">The files under <kbd>TRAIN_DATA_PATH</kbd> and <kbd>TEST_DATA_PATH</kbd> contain <span>the Cora dataset and labels, preprocessed in a TensorFlow-friendly format.</span></p>
<ol start="3">
<li>Next, let's load the dataset. This process is implemented by using two functions: <kbd>make_dataset</kbd>, which builds the whole dataset, and <kbd>parse_example</kbd>, which parses a single composite sample (<span><kbd>make_dataset</kbd> uses <kbd>parse_example</kbd> internally)</span>. We'll start with <kbd>make_dataset</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><span>def </span><span>make_dataset</span>(file_path: <span>str</span><span>, </span>training=<span>False</span>) -&gt; tf.data.TFRecordDataset:<br/><span>    </span>dataset = tf.data.TFRecordDataset([file_path])<br/>    <span>if </span>training:<br/>        dataset = dataset.shuffle(<span>10000</span>)<br/>    dataset = dataset.map(parse_example).batch(BATCH_SIZE)<br/><br/>    <span>return </span>dataset</pre>
<p style="padding-left: 60px">Note that <kbd>dataset.map(parse_example)</kbd> internally applies <kbd>parse_example</kbd> over al<span>l samples of the dataset. </span>Let's continue with the definition of <kbd>parse_example</kbd> , starting from the declaration:</p>
<pre style="padding-left: 60px"><span>def </span><span>parse_example</span>(example_proto: tf.train.Example) -&gt; <span>tuple</span>:</pre>
<p style="padding-left: 60px">The function creates the <kbd>feature_spec</kbd><span> dictionary that represents a kind of template for a single composite sample, which is later filled with actual data from the dataset. First, we fill </span><kbd>feature_spec</kbd><span> with the placeholder instan</span>ces of <kbd>tf.io.FixedLenFeature</kbd> f<span>or </span><kbd>'words'</kbd><span>, which represents a multihot-encoded publication, and</span> <kbd>'label'</kbd><span>, which represents the class of the publication (please bear in mind the indentation as this code is still part of <kbd>parse_example</kbd>):</span></p>
<pre style="padding-left: 60px"><span>    </span>feature_spec = {<br/>        <span>'words'</span>:<br/>            tf.io.FixedLenFeature(<span>shape</span>=[MAX_SEQ_LENGTH]<span>,<br/></span><span>                                  </span><span>dtype</span>=tf.int64<span>,<br/></span><span>                                  </span><span>default_value</span>=tf.constant(<br/>                                      <span>value</span>=<span>0</span><span>,<br/></span><span>                                      </span><span>dtype</span>=tf.int64<span>,<br/></span><span>                                      </span><span>shape</span>=[MAX_SEQ_LENGTH]))<span>,<br/></span><span>        </span><span>'label'</span>:<br/>            tf.io.FixedLenFeature(()<span>, </span>tf.int64<span>, </span><span>default_value</span>=-<span>1</span>)<span>,<br/></span><span>    </span>}</pre>
<p style="padding-left: 60px">Then, we iterate over the first <kbd>NUM_NEIGHBORS</kbd> neighbors and add their multihot vectors and edge weights to <kbd>feature_spec</kbd> under the <kbd>nbr_feature_key</kbd> and <kbd>nbr_weight_key</kbd> keys respectively:</p>
<pre style="padding-left: 60px"><span>    </span><span>for </span>i <span>in </span><span>range</span>(NUM_NEIGHBORS):<br/>        nbr_feature_key = <span>'{}{}_{}'</span>.format(NBR_FEATURE_PREFIX<span>, </span>i<span>, </span><span>'words'</span>)<br/>        nbr_weight_key = <span>'{}{}{}'</span>.format(NBR_FEATURE_PREFIX<span>, </span>i<span>, </span>NBR_WEIGHT_SUFFIX)<br/>        feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(<br/>            <span>shape</span>=[MAX_SEQ_LENGTH]<span>,<br/></span><span>            </span><span>dtype</span>=tf.int64<span>,<br/></span><span>            </span><span>default_value</span>=tf.constant(<br/>                <span>value</span>=<span>0</span><span>, </span><span>dtype</span>=tf.int64<span>, </span><span>shape</span>=[MAX_SEQ_LENGTH]))<br/><br/><span>        </span>feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(<br/>            <span>shape</span>=[<span>1</span>]<span>, </span><span>dtype</span>=tf.float32<span>, </span><span>default_value</span>=tf.constant([<span>0.0</span>]))<br/><br/>    features = tf.io.parse_single_example(example_proto<span>, </span>feature_spec)<br/><br/>    labels = features.pop(<span>'label'</span>)<br/>    <span>return </span>features<span>, </span>labels</pre>
<p style="padding-left: 60px"><span>Note that we populate the template with a real sample from the dataset with the following code snippet:</span></p>
<pre style="padding-left: 60px">    features = tf.io.parse_single_example(example_proto<span>, </span>feature_spec)</pre>
<ol start="4">
<li>Now, we can instantiate the training and testing datasets:</li>
</ol>
<pre style="padding-left: 60px">train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)<br/>test_dataset = make_dataset(TEST_DATA_PATH)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>Next, let's implement the model, which is a simple FFN with two hidden layers and softmax as output. The model takes the multihot-encoded publication vector as input and outputs the publication class. It is independent of NSL and can be trained, in a simple supervised way, as a classification:</li>
</ol>
<pre style="padding-left: 60px"><span>def </span><span>build_model</span>(dropout_rate):<br/>    <span>"""Creates a sequential multi-layer perceptron model."""<br/></span><span>    </span><span>return </span>tf.keras.Sequential([<br/>        <span># one-hot encoded input.<br/></span><span>        </span>tf.keras.layers.InputLayer(<br/>            <span>input_shape</span>=(MAX_SEQ_LENGTH<span>,</span>)<span>, </span><span>name</span>=<span>'words'</span>)<span>,<br/></span><span><br/></span><span>        </span><span># 2 fully connected layers + dropout<br/></span><span>        </span>tf.keras.layers.Dense(<span>64</span><span>, </span><span>activation</span>=<span>'relu'</span>)<span>,<br/></span><span>        </span>tf.keras.layers.Dropout(dropout_rate)<span>,<br/></span><span>        </span>tf.keras.layers.Dense(<span>64</span><span>, </span><span>activation</span>=<span>'relu'</span>)<span>,<br/></span><span>        </span>tf.keras.layers.Dropout(dropout_rate)<span>,<br/></span><span><br/></span><span>        </span><span># Softmax output<br/></span><span>        </span>tf.keras.layers.Dense(NUM_CLASSES<span>, </span><span>activation</span>=<span>'softmax'</span>)<br/>    ])</pre>
<ol start="6">
<li>Next, let's instantiate the model:</li>
</ol>
<pre style="padding-left: 60px">model = build_model(dropout_rate=0.5)</pre>
<ol start="7">
<li>We have all the ingredients that we need to use graph regularization. We'll start by wrapping the <kbd>model</kbd> with the NSL wrapper:</li>
</ol>
<pre style="padding-left: 60px">graph_reg_config = nsl.configs.make_graph_reg_config(<br/>    max_neighbors=NUM_NEIGHBORS,<br/>    multiplier=0.1,<br/>    distance_type=nsl.configs.DistanceType.L2,<br/>    sum_over_axis=-1)<br/>graph_reg_model = nsl.keras.GraphRegularization(model,<br/>                                                graph_reg_config)</pre>
<p style="padding-left: 60px">We instantiate the <kbd>graph_reg_config</kbd> object (an instance of <kbd>nsl.configs.GraphRegConfig</kbd>) with the graph regularization parameters: <kbd>max_neighbors=NUM_NEIGHBORS</kbd> is the number of neighbors to use, <kbd>multiplier=0.1</kbd> is equivalent to the parameter α of the composite loss we introduced in the <em>Neural structured learning </em><span>sect</span>ion, and <kbd>distance_type=nsl.configs.DistanceType.L2</kbd> is th<span>e distance metric between the neighboring node embeddings.</span></p>
<ol start="8">
<li>Next, we can build a training framework and initiate the training for 100 epochs:</li>
</ol>
<pre style="padding-left: 60px">graph_reg_model.compile(<br/>    <span>optimizer</span>=<span>'adam'</span><span>,<br/></span><span>    </span><span>loss</span>=<span>'sparse_categorical_crossentropy'</span><span>,<br/></span><span>    </span><span>metrics</span>=[<span>'accuracy'</span>])<br/><br/><span># run eagerly to prevent epoch warnings<br/></span>graph_reg_model.run_eagerly = <span>True<br/></span><span><br/></span>graph_reg_model.fit(train_dataset<span>, </span><span>epochs</span>=<span>100</span><span>, </span><span>verbose</span>=<span>1</span>)</pre>
<ol start="9">
<li>Once the training is done, we can run the trained model over the test dataset:</li>
</ol>
<pre style="padding-left: 60px">eval_results = dict(<br/>    zip(graph_reg_model.metrics_names,<br/>        graph_reg_model.evaluate(test_dataset)))<br/>print('Evaluation accuracy: {}'.format(eval_results['accuracy']))<br/>print('Evaluation loss: {}'.format(eval_results['loss']))</pre>
<p>If everything goes alright, the output of the program should be:</p>
<pre><strong>Evaluation accuracy: 0.8137432336807251</strong><br/><strong>Evaluation loss: 1.1235489577054978</strong></pre>
<p>This concludes our discussion about GNN. As we mentioned, there are various types of GNNs, and we only included a small set here. If you are interested in learning more, I suggest that you refer to the survey paper we introduced at the beginning of the section or check out the following curated list of GNN-related papers at <a href="https://github.com/thunlp/GNNPapers">https://github.com/thunlp/GNNPapers</a>.</p>
<p>In the next section, we'll discuss a new type of NN that uses external memory to store information.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing memory-augmented NNs</h1>
                </header>
            
            <article>
                
<p>We've already seen the concept of memory (albeit in a strange form) in NNs—for example, the LSTM cell can add or delete information on its hidden cell state with the help of the input and the forget gates. Another example is the attention mechanism, where the set of vectors that represent the encoded source sequence can be viewed as external memory that is written to by the encoder and read from by the decoder. But this ability comes with some limitations. For one, the encoder can only write to a single memory location, which is the current element of the sequence. It also cannot update previously written vectors. On the other hand, the decoder can only read from the database, but cannot write to it. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>In this section, we'll take the concept of memory one </span><span>step further and look at <strong>Memory-Augmented NNs</strong> (<strong>MANNs</strong>), which resolve these limitations.</span><span> This is a new class of algorithm and is still in its early stages, unlike the more mainstream types of NN, such as convolutional and RNNs, which have been around for decades. The first MANN network we'll discuss is the neural Turing machine.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural Turing machines</h1>
                </header>
            
            <article>
                
<p>The concept of MANNs was first introduced with the concept of the <strong>neural Turing machine</strong> (<strong>NTM</strong>) (for more information, go to  <a href="https://arxiv.org/abs/1410.5401">https://arxiv.org/abs/1410.5401</a>). The NTM has two components:</p>
<ul>
<li>A NN controller.</li>
<li>An external memory, represented as a matrix <img class="fm-editor-equation" src="assets/3a804a65-9cd9-4d40-ba70-790164f5d22b.png" style="width:4.50em;height:1.08em;"/>. The matrix contains <em>n</em> rows of <em>d</em>-dimensional vectors.</li>
</ul>
<p>The following <span>diagram </span>provides an overview of the NTM architecture:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1390 image-border" src="assets/63d5e3d7-f148-42f6-b002-0023aba080ea.png" style="width:23.67em;height:16.50em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">NTM Source: https://arxiv.org/abs/1410.5401</div>
<p>An NTM works in a sequential fashion (like an RNN), where the controller takes input vectors and produces output vectors in response. It also reads and writes to memory with the help of multiple parallel read/write heads.</p>
<p>Let's focus on the reading operation, which is very similar to the attention mechanism we looked at in <a href="0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml">Chapter 8</a>, <em>Sequence-to-Sequence Models and Attention</em>. A read head always reads the full memory matrix, but it does so by attending to different memory vectors with different intensities. To do this, the read head emits an <em>n</em>-dimensional vector <img class="fm-editor-equation" src="assets/6daa56ae-2570-4259-8817-ab17c4c9ce79.png" style="width:1.33em;height:1.25em;"/> (at step <em>t</em>) with the following constraints:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1814d2d9-a6b2-452d-9a6d-b3bcc602ba3e.png" style="width:13.50em;height:3.00em;"/></p>
<p><span>The</span><span> </span><img class="fm-editor-equation" src="assets/6d2eb2e7-c39d-4d13-b8bb-caa46bb4c330.png" style="width:1.50em;height:1.33em;"/> implements an attention mechanism, where each cell <em>i</em> of the vector indicates the weight of the <em>i</em>th memory vector (that is, the <em>i</em>th row of the matrix <strong>M</strong>) in forming the output. The output of a read operation at step <em>t</em> is a <em>d</em>-dimensional vector <strong>r</strong><sub><em>t</em></sub>, defined as the weighted sum of all memory vectors:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b280f69c-ef47-48e3-b01b-3aab5fc3bbf2.png" style="width:9.92em;height:3.25em;"/></p>
<p><span>This operation is similar to the soft attention mechanism we discussed in</span><span> <a href="0a021de6-b007-49bf-80e9-b7f6a72cbba7.xhtml">Chapter 8</a>,<em> </em></span><em>Sequence-to-Sequence Models and Attention.</em><span> Soft attention (unlike hard attention) is differentiable, and this also true of this operation. In this way, the whole NTM (controller and memory) is a single differentiable system, which makes it possible to train it with gradient descent and backpropagation.</span></p>
<p>Next, let's focus on the writing operation, which is composed of two steps: <strong>erase</strong> followed by an <strong>add</strong>. The write head emits the same type of attention vector <span><img class="fm-editor-equation" src="assets/3f322f02-bf5f-4755-bf19-2a8c6a629a17.png" style="width:1.58em;height:1.25em;"/></span> as the reading heads. It also emits another <strong>erase</strong> vector <img class="fm-editor-equation" src="assets/16e529ef-8102-4f10-bd67-49b4debee77d.png" style="width:3.33em;height:1.25em;"/>, whose values are all within the (0, 1) range. We can define the erase operation<span> at step </span><em>t</em> over a single row <em>i</em> of the memory as a function of these two vectors and the memory state at step <em>t-1</em>, <em><img class="fm-editor-equation" src="assets/1615bdc5-cb7e-4add-9413-819093aa8950.png" style="width:1.83em;height:0.83em;"/></em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/9ac76018-5dec-4d02-a939-af1502e59eab.png" style="width:14.00em;height:1.42em;"/></p>
<p>Here, <strong>1</strong> is a <em>d</em>-dimensional vector of ones and the multiplication between <img class="fm-editor-equation" src="assets/0a454eb0-2060-4036-8808-ec22c05940af.png" style="width:3.17em;height:1.00em;"/> and the erase component is element-based. According to this formula, a memory location can be erased only if both the weight <img class="fm-editor-equation" src="assets/b683581b-9d4f-4dbb-a5e9-c31f603969ac.png" style="width:3.75em;height:1.83em;"/> and <strong>e</strong><sub><em>t</em></sub> are nonzero. This mechanism can work with multiple attention heads writing in an arbitrary order, because multiplication is commutative.</p>
<p>The erase operation is followed by the add operation. The write head produces an <strong>add</strong> vector <img class="fm-editor-equation" src="assets/0e7b6af0-ab80-48ed-ad62-7615fc08410f.png" style="width:3.08em;height:1.17em;"/>, which is added to the memory after the erase to produce the final memory state at step <em>t</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f5634fb9-b32d-4620-9f0c-f6d4fb9ca6dd.png" style="width:11.17em;height:1.33em;"/></p>
<p>We are now familiar with read and write operations, but we still don't know how to produce attention vectors <img class="fm-editor-equation" src="assets/b68175cd-78ce-4ada-844c-77285e9aa0e9.png" style="width:1.42em;height:0.92em;"/>(we'll omit the superscript index, because the following descriptions apply for both read and write heads)<span>. NTM uses two complementary addressing mechanisms to do this: content-based and location-ba</span>sed. </p>
<p>We'll start with con<span>tent-based addressing, where each head (both reading and writing) emits a key vector <img class="fm-editor-equation" src="assets/199a165e-f567-4c4c-8c71-d4ffd10f4489.png" style="width:3.00em;height:1.08em;"/>. This vector is compared to each memory vector <img class="fm-editor-equation" src="assets/1a7e81ac-d914-400e-98d8-a4e4705d0dc9.png" style="width:1.92em;height:0.83em;"/> using the similarity measure <img class="fm-editor-equation" src="assets/ccf35344-a461-4be5-8eb0-4adf5effc5ba.png" style="width:4.83em;height:1.00em;"/>. The NTM authors propose using cosine similarity, defined as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ff8af2ff-641e-4ad7-a7d7-1e4a2dee9576.png" style="width:12.92em;height:2.67em;"/></p>
<p>Then, we define a single cell of the content-based addressing vector as a softmax over the similarity results of all memory vectors:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/45358260-1d54-47a0-8550-50668fbc10a8.png" style="width:16.50em;height:3.00em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/25c1dc3b-42fa-4009-8b71-1ce5a3b112d2.png" style="width:1.00em;height:1.17em;"/> is a scalar value key strength, which widens or narrows the scope of the focus. For small values of <img class="fm-editor-equation" src="assets/68d864a1-6d82-4cb8-b3e8-8e99f90b6eab.png" style="width:0.92em;height:1.08em;"/>, the attention will diffuse over all memory vectors, and for large <img class="fm-editor-equation" src="assets/fd2b11cb-dc95-4bf1-85f3-26254d747cc3.png" style="width:1.42em;height:1.58em;"/>, the attention will focus only on the most similar memory vectors. </p>
<p>The authors of NTM argue that in some problems, content-based attention is not enough, because the content of a variable can be arbitrary but its address has to be recognizable. They cite arithmetic problems as one such problem: two variables, <em>x</em> and <em>y,</em> can take on any two values, but the procedure <em>f(x, y) = x × y</em> should still be defined. A controller for this task could take the values of the variables <em>x</em> and <em>y</em>, store them in different addresses, then retrieve them and perform a multiplication algorithm. In this case, the variables are addressed by location, not by content, which brings us to the location-based addressing mechanism. It works with both random-access memory jumps and simple iterations across locations. It does this by shifting the attention weights one step forward or backward.</p>
<p>For example, if the current weighting focuses entirely on a single location, a rotation of 1 would shift the focus to the next location. A negative shift would move the weighting in the opposite direction.</p>
<p>Content and location addressing work in combination, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1391 image-border" src="assets/85a0d3f5-3abe-477a-ad36-8d35cf7cf6d4.png" style="width:44.92em;height:17.42em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">Flow diagram of the addressing mechanism. Source: https://arxiv.org/abs/1410.5401</div>
<p>Let's see how it works step by step:</p>
<ol>
<li class="mce-root">Content addressing produces the content addressing vector <img class="fm-editor-equation" src="assets/24698595-cba6-4e49-a5cc-eaa5b7e39db7.png" style="width:1.25em;height:1.08em;"/>, based on the memory <img class="fm-editor-equation" src="assets/0ca2bba2-b305-4317-be6d-f6fb3f8f4706.png" style="width:1.42em;height:1.00em;"/>, the key vector <img class="fm-editor-equation" src="assets/9f276f5b-544b-4fcc-901c-381034e1ce43.png" style="width:1.08em;height:1.17em;"/>, and the key strength <img class="fm-editor-equation" src="assets/05075069-9a60-4db0-a319-edb925e1bee5.png" style="width:0.75em;height:0.83em;"/>.</li>
<li><strong>Interpolation</strong> is the first of three steps in the location addressing mechanism, and it comes before the actual weight shifting. Each head (read or write) emits a scalar <strong>interpolation gate</strong> <em>g<sub>t</sub></em> in the (0, 1) range. The <em>g<sub>t</sub></em><span> </span>dictates whether to preserve the weight <img class="fm-editor-equation" src="assets/913e6859-677b-4e4a-a2a9-f201b25b0b42.png" style="width:2.42em;height:0.92em;"/> produced by the head at step <em>t-1</em> or replace it with the content-based weight <img class="fm-editor-equation" src="assets/24698595-cba6-4e49-a5cc-eaa5b7e39db7.png" style="width:1.17em;height:1.00em;"/> of the current step <em>t.</em> The interpolation is defined as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1b1a66be-56db-4c99-8fbe-eba8c9f4d51a.png" style="width:13.25em;height:1.42em;"/></p>
<p style="padding-left: 60px">If <em>g<sub>t</sub><span> </span>= 0</em>, then we'll preserve the previous addressing vector completely. Alternatively, if <em>g<sub>t</sub><span> </span>= 1</em>, we'll only use the content-based addressing vector.</p>
<ol start="3">
<li>The next step is the <strong>convolutional shift</strong>, which takes interpolation attention <img class="fm-editor-equation" src="assets/2695b5b4-f6e0-4ea2-ad94-4206e85b7c04.png" style="width:1.42em;height:1.33em;"/>and determines how to shift it. Let's assume that the head attention can shift forward (+1), backward (-1), or stay the same (0). Each head emits a shift weighting <em>s<sub>t</sub></em> that defines a normalized distribution over the allowed shifts. In this case, <em>s<sub>t</sub></em> will have three elements, which indicate the degree to which shifts of -1, 0, and 1 are performed. If we assume that the memory vector indices are 0-based (from 0 to <em>n-1</em>), then we can define the rotation of <img class="fm-editor-equation" src="assets/f90f0bf5-bcad-43ac-a5d5-907197941f39.png" style="width:1.33em;height:1.25em;"/> by <em>s<sub>t</sub></em> as a circular convolution:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/575ed1d9-39a1-487c-83c0-ec259ba0c411.png" style="width:14.33em;height:4.08em;"/></p>
<p style="padding-left: 60px">Note that, although we iterate over all memory indices, <em>s<sub>t</sub></em><span> will have nonzero values</span> only at the allowed positions.</p>
<ol start="4">
<li>The final addressing step is the <strong>sharpening</strong> step. One side, effect of the ability to simultaneously shift with different degrees over multiple directions is that the attention might blur. For example, let's say that we shift forward (+1) with a probability of 0.6, shift backward (-1) with a probability of 0.2, and don't shift (0) with a probability of 0.2. When we apply the shifting, the original focused attention will blur between the three locations. To solve this, the authors of NTM suggest that you modify each head to emit another scalar <img class="fm-editor-equation" src="assets/d3f6fbce-c18b-4f0e-9827-0f14088edf05.png" style="width:2.92em;height:1.17em;"/>, which will sharpen the final results using the following formula:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/65574cfa-18eb-4cbe-94c2-3d48206dded0.png" style="width:11.83em;height:3.58em;"/></p>
<p>Now that we know how addressing works, let's focus on the controller, where we can use either RNN (for example, LSTM) or FFN. The authors of NTM argue that an LSTM controller has internal memory, which is complementary to the external memory and also allows the controller to mix information from multiple time steps. However, in the context of NTM, an FFN controller can mimic an RNN one by reading and writing at the same memory location at every step. Additionally, the FFN is more transparent because its read/write pattern is easier to interpret than the internal RNN state. </p>
<p>The authors of the paper illustrate how NTM works with several tasks, one of which is a copy operation where the NTM has to replicate the input sequence as output. The task illustrates the model's ability to store and access information over long periods of time. The input sequence has a random length between 1 and 20. Each element of the sequence is a vector with eight binary elements (representing a single byte). First, the model takes the input sequence step by step until a special delimiter is reached. Then, it starts to generate the output sequence. No additional inputs are presented during the generation phase to ensure that the model can generate the entire sequence without intermediate assistance. The authors compare the performance of NTM- and LSTM-based models and note that NTM converges faster during training and can replicate longer sequences compared to LSTM. Based on these results, and after examining the interactions of the controller and the memory, they conclude that NTM doesn't simply memorize the input sequence; instead, it learns a type of copy algorithm. We can describe the sequence of operations for the algorithm with the following pseudocode:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1caca29c-2202-4f57-b9d7-fe759aca2b8d.png" style="width:11.83em;height:10.42em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The NTM model learns a form of copy algorithm: source: https://arxiv.org/abs/1410.5401</div>
<p>Next, let's focus on the copy algorithm from the perspective of the interaction between the controller and the memory, as illustrated in the following <span>image</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1417 image-border" src="assets/6ca3e380-8db5-43da-9134-41804d670ece.png" style="width:21.33em;height:16.17em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref">The controller/memory interaction during the copy algorithm; Source: https://arxiv.org/abs/1410.5401 <a href="https://arxiv.org/abs/1410.5401"/></div>
<p>The left column shows the input phase. The top-left <span>image </span>represents the input sequence of 8-bit binary vectors, the middle-left image represents the vectors added to the memory, and the bottom-left image represents the memory write attention weights at each step. <span>The right column shows the output phase. The top-right image represents the generated output sequence of 8-bit binary vectors, the middle-right image represents the vectors read from the memory, and the bottom-right image represents the memory-read attention weights at each step. The bottom images illustrate incremental shifts of the head locations during write and read operations. Note that attention weights are clearly focused on a single memory location. At the same time, the input and output sequences read from the same location at each time step and the read vectors are equivalent to the write vectors. This indicates that each element of the input sequence is stored in a single memory location. </span></p>
<p>Before we conclude this section, let's mention that the authors of NTM have released an improved memory network architecture called a <strong>Differential Neural Computer</strong> (<strong>DNC</strong>) (for more information, see <em>Hybrid computing using a neural network with dynamic external memory</em>, at <a href="https://www.nature.com/articles/nature20101">https://www.nature.com/articles/nature20101</a>). The DNC introduces several improvements over NTM:</p>
<ul>
<li>The model only uses content-based addressing (as opposed to content and location in NTM).</li>
<li>The model uses dynamic memory allocation by maintaining a list of available memory locations by adding locations to, and removing them from, a linked list (this is still differentiable). This mechanism allows the model to write new data only at locations that are marked as free.</li>
<li>The model uses temporal memory linkage by maintaining information about the order of the memory locations that the controller writes to, which allows it to store sequential data at different memory locations.</li>
</ul>
<p>This concludes our description of the NTM architecture. In the next section, we'll discuss an improvement to NTM introduced in the <em>One-shot Learning with Memory-Augmented Neural Networks</em> paper (<a href="https://arxiv.org/abs/1605.06065">https://arxiv.org/abs/1605.06065</a>). We'll denote the improved architecture with MANN* to avoid confusion with the MANN acronym, which references the general class of memory networks.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">MANN*</h1>
                </header>
            
            <article>
                
<p>The MANN* read operation is very similar to the NTM read operation, with the exception that it doesn't include the <span>key strength parameter </span><img class="fm-editor-equation" src="assets/8c0a80bc-2768-4808-8e72-f461746e5822.png" style="width:1.00em;height:1.08em;"/>. On the other hand, MANN* introduces a new content-based write addressing mechanism called<span> </span><span><strong>Least Recently Used Access</strong> (<strong>LRUA</strong>) as a replacement for the combined content/location NTM addressing mechanism</span>. The LRUA write operation writes to either the least-used memory location or the most recently used one. There are two reasons for implementing this: to preserve recently stored information by writing new memories to the most rarely-used locations, and by writing new data to the last used location, the new information serves as a kind of update to the previously written state. But how does the model know which of the two options to use? The MANN* addressing mechanism interpolates between the two options by introducing a vector of usage weights <img class="fm-editor-equation" src="assets/942f9145-7af4-4021-91b2-b8273dc3dbc9.png" style="width:3.08em;height:1.08em;"/>. These weights are updated at each time step by adding the usage weights <img class="fm-editor-equation" src="assets/c3d2a1a3-ef5d-4dbe-a8b7-730b11c08666.png" style="width:2.17em;height:1.25em;"/> at step <em>t-1</em> with the current read and write attention weights:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2cbd95cb-891b-4356-8f4d-3d5e2c75332b.png" style="width:10.75em;height:1.25em;"/></p>
<p>Here, the scalar γ is a decay parameter, which determines the balance between the two components of the equation. <span>MANN* also introduces the least recently used weights vector <img class="fm-editor-equation" src="assets/d164f3e8-dc60-4160-a78e-948c3fa5e6d3.png" style="width:1.42em;height:1.17em;"/>, where each element of the vector is defined as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/56e10e46-4b66-48f6-b857-36a016d72d29.png" style="width:17.17em;height:3.17em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/fd4e3e1b-12e6-4f16-b340-f7cce5feb910.png" style="width:4.25em;height:1.25em;"/> is the <em>n</em>th smallest element of the vector <img class="fm-editor-equation" src="assets/069a6770-86b9-4e68-b663-c171e9c6bf2a.png" style="width:1.42em;height:0.92em;"/> and <em>n</em> is equal to the number of memory reads. At this point, we can compute the write weights, which are an interpolation between the read weights and the least-recently used weights at step <em>t-1</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0e93623e-c9b1-448f-a4ef-dc45cd8afea3.png" style="width:17.75em;height:1.67em;"/></p>
<p>Here, σ is the sigmoid function and α is a learnable scalar parameter, which indicates how to balance between the 2 input weights. Now, we can write new data to the memory, which is done in 2 steps: the first is for computing the least recently used location using the weights <img class="fm-editor-equation" src="assets/c3d2a1a3-ef5d-4dbe-a8b7-730b11c08666.png" style="width:2.08em;height:1.25em;"/>. The second step is the actual writing:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/96e22cde-65e1-45cc-92c2-bde6ce8ebecc.png" style="width:14.58em;height:1.42em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/a9d608c2-aecf-41f2-9de9-0bdffed8b1aa.png" style="width:1.08em;height:1.17em;"/> is the key vector we defined when we discussed NTM.</p>
<p>The MANN* paper goes into a bit more detail (compared to the original NTM paper) about the way the controller interacts with the input data and the read/write heads. The authors of the paper noted that their best performing models use LSTM<span> </span><span>(see</span> <a href="379a4f7b-48da-40f2-99d6-ee57a7a5dcca.xhtml">C<span>hapt</span>er 7</a>, <em>Understanding Recurrent</em> <em>Networks</em><span>)</span> controllers. So the following is how the LSTM controller plugs into the MANN* system:</p>
<ul>
<li>The controller inputs at step <em>t</em> are the concatenated vectors <img class="fm-editor-equation" src="assets/70297af4-5d9d-42f7-978d-154a789d8906.png" style="width:3.25em;height:1.00em;"/>, where <img class="fm-editor-equation" src="assets/29facb26-b5e5-4791-b7d2-f46ea48f2edc.png" style="width:1.17em;height:0.92em;"/> is the input data and <img class="fm-editor-equation" src="assets/00d06425-4270-48fc-a1f8-38ad093018f3.png" style="width:2.00em;height:0.92em;"/> is the system's output at step <em>t-1</em>. In classification tasks, the outputs <img class="fm-editor-equation" src="assets/45e28d30-ccfd-4c93-9b00-134ae9ad11e1.png" style="width:1.00em;height:0.83em;"/> are one-hot encoded class representations.</li>
<li>The controller outputs at step <em>t</em> are the concatenated <img class="fm-editor-equation" src="assets/0d1c22f1-5e92-42ed-a861-30e93b59c749.png" style="width:4.50em;height:1.00em;"/>, where <img class="fm-editor-equation" src="assets/da198e0a-707e-4d3a-9631-8823a3723322.png" style="width:1.00em;height:1.08em;"/><span> is the LSTM cell hidden state and <img class="fm-editor-equation" src="assets/109f037d-5344-433d-a0b5-8e60125ed09c.png" style="width:1.00em;height:0.92em;"/> is a result of the read operation. For classification tasks, we can use <img class="fm-editor-equation" src="assets/2672393f-2e20-4718-8c23-0fb701375f61.png" style="width:1.08em;height:0.92em;"/> as an input for a fully connected layer with softmax output, resulting in the expression <img class="fm-editor-equation" src="assets/bc440539-668c-4312-b516-773202d903cc.png" style="width:8.17em;height:1.00em;"/>, where <img class="fm-editor-equation" src="assets/0518e846-b423-4882-9564-61c3c2dca8c8.png" style="width:1.33em;height:0.83em;"/> is the fully connected layer weights. </span></li>
<li>The key vector <img class="fm-editor-equation" src="assets/36e80a51-1d5c-4419-b724-02754ea8fd03.png" style="width:0.92em;height:1.00em;"/>, which serves as a base for the<span> attention weights o</span>f the read/write operations, is the LSTM cell state <img class="fm-editor-equation" src="assets/71582670-adc7-4831-a821-11d6edc829bd.png" style="width:0.92em;height:0.83em;"/>.</li>
</ul>
<p>This concludes our discussion of MANNs and, indeed, the chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we covered two categories of emerging NN models—GNNs and MANNs. We started with a short introduction to graphs and then we looked at several different types of GNN, including GraphNN, graph convolutional networks, graph attention networks, and graph autoencoders. We concluded the graph section by looking at the NGL and we implemented an NGL example using the TensorFlow-based NSL framework. Then we focused on memory-augmented networks, where we looked at the NTM and MANN* architectures. </p>
<p>In the next chapter, we'll look at the emerging field of meta learning, which involves making ML algorithms learn to learn. </p>


            </article>

            
        </section>
    </body></html>