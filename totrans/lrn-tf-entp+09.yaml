- en: 'Chapter 6:'
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to start by looking at three different hyperparameter
    tuning algorithms—Hyperband, Bayesian optimization, and random search. These algorithms
    are implemented in the `tf.keras` API, which makes them relatively easy to understand.
    With this API, you now have access to simplified APIs for these complex and advanced
    algorithms that we will encounter in this chapter. We will learn how to implement
    these algorithms and use the best hyperparameters we can find to build and train
    an image classification model. We will also learn the details of its learning
    process in order to know which hyperparameters to search and optimize. We will
    start by getting and preparing the data, and then we'll apply our algorithm to
    it. Along the way, we will also try to understand key principles and the logic
    to implement user choices for these algorithms as user inputs, and we'll look
    at a template to submit tuning and training jobs in GCP Cloud TPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Delineating hyperparameter types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the syntax and use of Keras Tuner
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delineating hyperparameter search algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Submitting tuning jobs in a local environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Submitting tuning jobs in Google's AI Platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The entire code base for this chapter is in the following GitHub repository.
    Please clone it to your environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_06/](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_06/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be done through a command-line environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Delineating hyperparameter types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we develop a model and its training process, we define variables and set
    their values to determine the training workflow and the model's structure. These
    values (such as the number of hidden nodes in a layer of a multilayer perceptron,
    or the selection of an optimizer and a loss function) are known as hyperparameters.
    These parameters are specified by the model creator. The performance of a machine
    learning model often depends on the model architecture and the hyperparameters
    selected during its training process. Finding a set of optimal hyperparameters
    for the model is not a trivial task. The simplest method to this task is by grid
    search, that is, building all possible combinations of hyperparameter values within
    a search space and then comparing the evaluation metrics across these combinations.
    While this is straightforward and thorough, it is a tedious process. We will see
    how the new `tf.keras` API implements three different search algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of hyperparameters in the context of model training:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model hyperparameters**: These parameters are directly related to the structure
    of a model layer, such as the number of nodes in a layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Algorithm hyperparameters**: These parameters are required to execute the
    learning algorithm, such as the learning rate in the loss function used during
    gradient descent, or the choice of loss function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code modification required to scan through both types of hyperparameters
    would be very complicated if you want to use the grid search technique. This is
    where a more efficient and comprehensive framework would be very helpful for hyperparameter
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to see the latest addition in hyperparameter
    tuning frameworks to the TensorFlow ecosystem. This framework is Keras Tuner.
    As the name suggests, it is for models developed with the TensorFlow 2.x Keras
    API. The minimum requirement for this framework is TensorFlow 2.0+ and Python
    3.6\. It is released as a part of the TensorFlow 2.3 distribution. If you are
    not yet using TensorFlow 2.3, then as long as you are using TensorFlow 2.x, Keras
    Tuner can be installed with the help of the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once Keras Tuner is installed, you can load it in your Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You need not put a dash `-` between `keras-tuner` while importing it. It will
    be imported like this: `import kerastuner as kt`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Keras Tuner is a distributable hyperparameter optimization framework that helps
    to define the search space for collections of hyperparameters. It also includes
    the following three built-in algorithms to help find the best hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Hyperband
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Keras Tuner, whether it is model hyperparameters or algorithm hyperparameters,
    it makes no difference to the syntax or definition style of these hyperparameters.
    Therefore, you have great flexibility in choosing what hyperparameters to tune
    without complicated coding patterns or loops.
  prefs: []
  type: TYPE_NORMAL
- en: The Keras Tuner framework makes it easy for us to modify our training script.
    While there are changes and refactoring involved, the API format and logical flow
    are very much consistent with Keras styles and implementations. Before we jump
    into the examples, let's spend some time understanding this framework and seeing
    how to extend our training code to accommodate it.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the syntax and use of Keras Tuner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the most part, as far as Keras Tuner is concerned, hyperparameters can
    be described by the following three data types: integers, floating points, and
    choices from a list of discrete values or objects. In the following sub-sections,
    we will take a closer look at how to use these data types to define hyperparameters
    in different parts of the model architecture and training workflow.'
  prefs: []
  type: TYPE_NORMAL
- en: Using hp.Int for hyperparameter definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Keras Tuner defines a search space with a very simple and intuitive style.
    To define a set of possible number of nodes in a given layer, you typically would
    have a layer definition like the this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding line of code, `hp_units` is the number of nodes in this layer.
    If you wish to subject `hp_units` to hyperparameter search, then you simply need
    to define the definition for this hyperparameter''s search space. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`hp` is the object that represents an instance of `kerastuner`.'
  prefs: []
  type: TYPE_NORMAL
- en: This is simply an array of integers between `64` and `256` at an increment of
    `16`. When applied to the `Dense` layer, it becomes an array of possible values
    in the search space for `hp_units`.
  prefs: []
  type: TYPE_NORMAL
- en: Using hp.Choice for hyperparameter definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you have a set of values in mind and these values do not fall into incremental
    steps, you may specify a list of values as shown in the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`hp_Choice` is a flexible type for hyperparameters. It can also be used to
    define algorithmic hyperparameters such as activation functions. All it needs
    is the name of possible activation functions. A search space for different activation
    functions may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the definition for the layer that uses this hyperparameter would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Another place where `hp.Choice` may be applied is when you want to try different
    optimizers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in the model compilation step, where an optimizer is specified in the
    training workflow, you would simply define `optimizer` as `hp_optimizer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we pass `hp_optimizer` into the model compilation
    step as our selection for the optimizer to be used in the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Using hp.Float for hyperparameter definition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Floating points frequently appear as parameters in the training workflow, such
    as the learning rate for the optimizer. Here is an example that demonstrates how
    it is defined in a case with the optimizer''s learning rate as a hyperparameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we define a search space for our optimizer's learning
    rate. We then pass the `hp_learning_rate` object into the optimizer definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, I created a `model_builder` function. This function accepts
    `hp object`, which defines the hyperparameter search space, and then passes the
    `hp object` into the model architecture. The function returns the completed model.
    Here is the `model_builder` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: With the Keras Tuner API, the search space format and the way in which the search
    space is referenced inside the model layer or training algorithm are straightforward
    and provide great flexibility. All that was done was defining a search space,
    then passing the object holding the search space into the model definition. It
    would be a daunting task to handle the conditional logic following the grid search
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will take a look at how to use Keras Tuner classes to specify the
    following three different search algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Hyperband
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delineating hyperparameter search algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will take a closer look at three algorithms that traverse
    the hyperparameter search space. These algorithms are implemented by the `tf.keras`
    API.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperband
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hyperparameter search is an inherently tedious process that requires a budget
    `B` to test a finite set of possible hyperparameter configurations `n`. In this
    context, budget simply means compute time as indicated by the epoch, and the training
    data subsets. The hyperband algorithm takes advantage of early stopping and successive
    halving so that it can evaluate more hyperparameter configurations in a given
    time and with a given set of hardware resources. Early stopping helps eliminate
    underperforming configurations before too much training time is invested in them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The successive halving method is very intuitive: for a set of hyperparameter
    configurations, run them through the same budget (that is, epoch, memory, and
    training data subset size). Then we rank the performance of these configurations,
    discarding the configurations in the worst half. This process is repeated until
    only one configuration remains. This is similar to playoff brackets in that at
    every bracket, half of the configurations are eliminated, until only one remains.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two `for` loops in the Hyperband algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: The inner loop, which performs successive halving that discards a portion of
    hyperparameter configurations, thereby reducing the search space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An outer loop, which iterates over different combinations of `B` and `n`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In early iterations, there are many candidate configurations. As each candidate
    is given a portion of budget `B` to train, early stopping ensures that a fraction
    (that is, half) of these configurations are discarded early before too much training
    time is wasted. As brackets become smaller through successive halving, fewer candidate
    configurations remain, and therefore each candidate is more likely to get a higher
    portion of `B`. This continues until the last hyperparameter configuration remains.
    Therefore, you may think of the Hyperband algorithm as an approach for selecting
    the best hyperparameter configurations that cuts the losses early by discarding
    low-performing configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a reference for more information on the Hyperband algorithm: [https://openreview.net/pdf?id=ry18Ww5ee](https://openreview.net/pdf?id=ry18Ww5ee).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s take a look at how to define a tuner instance that uses the Hyperband
    algorithm (for a detailed description of the API and its parameters, see [https://keras-team.github.io/keras-tuner/documentation/tuners/](https://keras-team.github.io/keras-tuner/documentation/tuners/)).
    Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a description of the parameters shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '`hypermodel`: A function of the class that builds a model architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`objective`: Performance metrics for evaluation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_epoch`: The maximum number of epochs to train a model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`factor`: Reduction for the number of epochs and number of models for each
    bracket. It selects configurations ranked in the top 1/`factor` of all configurations.
    A higher `factor` means more pruning and therefore it''s quicker for the search
    process to identify a top performer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`distribution_strategy`: This is used if hardware is available for distributed
    training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`directory`: The target directory or path to write the search results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`project_name`: The name used as a prefix for files saved by the tuner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`overwrite`: This is a Boolean. If `True`, then hyperparameter search will
    start from scratch. Let''s explain a bit more about this API. In this case, `kt`
    is the tuner object. In the hyperband definition, `hypermodel` designates a function
    that builds the model architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this example, we will define the search space for the number of nodes (`hp_units`)
    in the middle `Dense` layer of the model architecture, as well as the search space
    for the activation function (`hp_activation`) of that layer. After these definitions,
    we construct the model architecture, pass these `hp` objects into the destined
    layer, compile the model, and return the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice `hp` in the function signature. It indicates this is the entry function
    for the model structure definition, where the hyperparameters are specified. In
    this example, there are two hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside the model''s sequential API definition, you will find these hyperparameters
    in one of the `Dense` layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Before exiting this function, you would compile the model and return the model
    to the tuner instance. Now let''s begin with the training of the Hyperband hyperparameter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the tuner and its search algorithm are defined, this is how you would
    set up the search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, `train_ds` is the training dataset, while `val_ds` is the cross-validation
    dataset. The rest of the parameters are the same as seen in a typical training
    routine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After the search is done, you may retrieve the best hyperparameter configuration
    through an object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By default, `num_trials = 1` indicates this will return the best model. Since
    this is a list object, we retrieve it by the first index of a list, which is `0`.
    The `print` statement shows how the item in `best_hps` may be referenced.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'It is recommended that once you have `best_hps`, you should retrain your model
    with these parameters. We will start with the `tuner` object initialized with
    `best_hps`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then we may define checkpoints and callbacks for the formal training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let''s call the `fit` function to start training with the best hyperparameter
    configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once training is completed, save the trained model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now the model trained with the hyperband hyperparameter search is saved in
    the file path designated by `model_save_dir`. Next, we are going to take a look
    at another algorithm for hyperparameter search: Bayesian optimization.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This method leverages what is learned from the initial training samples and
    nudges changes in hyperparameter values towards the favorable direction of the
    search space. Actually, what was learned from the initial training samples is
    a probabilistic function that models the value of our objective function. This
    **probabilistic** function, also known as a **surrogate** function, models the
    distribution of our objective (that is, validation loss) as a Gaussian process.
    With a surrogate function ready, the next hyperparameter configuration candidate
    is selected such that it is most likely to improve (that is, minimize, if the
    objective is validation loss) the surrogate function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `tuner` instance invokes this algorithm in a straightforward fashion. Here
    is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: This line of code defines a `tuner` object that I set up to use the Bayesian
    optimization algorithm as a means for hyperparameter optimization. Similar to
    Hyperband, it requires a function definition for `hypermodel`. In this case, `model_builder`
    from Hyperband is used again. The criterion for optimization is validation accuracy.
    The maximum number of trials is set to `50`, and we will specify the directory
    in which to save the model as user input during job submission. The user input
    for `model_dir` is carried by `flags_obj.model_dir`.
  prefs: []
  type: TYPE_NORMAL
- en: As indicated by the `BayesianOptimization` API, there are not many differences
    in the function signature compared to Hyperband. `max_trials` is the maximum number
    of hyperparameter configurations to try. This value may be pre-empted or ignored
    if the search space is exhausted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is the same as seen in the *Hyperband* section when launching
    the search process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: And the rest of it, such as retrieving the best hyperparameter configuration
    and training the model with this configuration, is all the same as in the *Hyperband*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Random search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Random search is simply a random selection of the hyperparameter configuration
    search space. Here''s an example definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: In the `RandomSearch` API in the preceding code, we define the `model_builder`
    function as `hypermodel`. This function contains our hyperparameter objects that
    hold definitions for the hyperparameter name and search space. `hypermodel` specifies
    the name of our function, which will accept the best hyperparameters found by
    the search and use these values to build a model. Our objective is to find the
    best set of hyperparameters that maximizes validation accuracy, and we set `max_trials`
    to `5`. The directory to save the model is provided as user input. The user input
    for `model_dir` is captured by the `flags_obj.model_dir` object.
  prefs: []
  type: TYPE_NORMAL
- en: A few words about `directory`
  prefs: []
  type: TYPE_NORMAL
- en: The `directory` argument is required in all three types of algorithm. It is
    the target where search results will be stored. This argument accepts a text string
    and is very flexible. The text string may indicate text passed by the input flag
    (as in the case of `flags_obj.model_dir`) when this code is run as a script. Alternatively,
    if you are using a notebook environment, the text string may be a file path or
    a cloud storage bucket path.
  prefs: []
  type: TYPE_NORMAL
- en: Submitting tuning jobs in a local environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the hyperparameter tuning process is inherently time-consuming, it is
    more practical to run it from a script rather than in a notebook environment.
    Also, although in a sense, a hyperparameter tuning process consists of multiple
    model training jobs, the tuner API and search workflow require a certain code
    refactoring style. The most obvious point is that we must wrap the model structure
    around a function (in our example, a function named `model_builder`), whose signature
    indicates that hyperparameter arrays are expected to be referenced in the model
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may find the code and instructions in the GitHub repository: [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_06/localtuningwork](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_06/localtuningwork)'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the help of the following code, we will set up user inputs or flags and
    perhaps assign default values to these flags when necessary. Let''s have a quick
    review of how user inputs may be handled and defined in the Python `script.absl`
    library, and the APIs that are commonly used for handling user input:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `absl` library and the relevant APIs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will use the following lines of code to indicate user inputs or flags:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first argument is the name of the input flag, followed by its default value,
    then an explanation. The preceding examples demonstrate commonly used type casting
    to these flags: `string`, `Boolean`, `integer`, and `float`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the code, how do we reference and make use of these flags? It turns out
    we need to use a `flags.FLAGS` object in the function where the input flags are
    used. This function could be `main()` or any function. In many cases, for convenience
    and readability, we will assign this object to a variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, to refer to `model_dir`, we just need to do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This effectively decodes the object the and `model_dir` attribute as a text
    string.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now let''s see an example script. We will start with the `import` statements
    to bring all the libraries we will need into the scope:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the user input argument names, default values, and short explanations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for loading working data. In this case, we will load it directly
    from TensorFlow for convenience:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This function invokes the `tf.keras` API to retrieve the built-in image data
    that comes with TensorFlow. It is hosted in Google's public-facing storage. It
    is compressed, so we need to set `untar` to `True`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We also create a function called `make_generators`. This is a function that
    we will use to make data generators to stream the image data into the model training
    process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function in the preceding code accepts a data path and user input. `train_batch_size`
    is one of the user inputs. This value is used to define `BATCH_SIZE` in this function.
    The validation generator is created first. We may have different preferences for
    training data, such as the options for data augmentation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s continue with the `make_generators` function. In this example, by default
    we are not going to do data augmentation on the training data. At the end of this
    function, `train_generator` is returned alongside `valid_generator`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This function will create two generators: one for training data, the other
    one for cross-validation data. See [*Chapter 4*](B16070_04_Final_JM_ePub.xhtml#_idTextAnchor101),
    *Reusable Models and Scalable Data Pipeline*, the *Creating a generator to feed
    image data at scale* section, for more details.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we define a function to retrieve the index to label mapping. As the model
    outputs a prediction, the prediction is in the form of an integer between `0`
    and `4`. Each integer corresponds to a class name of the flowers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function in the preceding code iterates through the flower type index and
    the corresponding flower type name, and creates a dictionary as a lookup. Now
    let's proceed towards building a model architecture.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following function builds the model architecture, as described in the *Hyperband*
    section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define an object to clear the screen as the hyperparameter search moves around
    the search space:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will help clear some of the printed output during the search process. This
    is passed into a callback.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This is the main driver for the training script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, we set the distributed training strategy, defined the
    data source, and created training and validation data generators. Also, label
    mapping is retrieved.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the following logical block of conditional code, we handle the choice for
    the hyperparameter search algorithm. All three choices are present: Bayesian optimization,
    random search, and Hyperband. The default choice is Hyperband. Within each choice,
    there is a `hypermodel` attribute. This attribute specifies the name of the function
    that will take up the best hyperparameters to build the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'Unless it''s specified via input to use either Bayesian optimization or random
    search, the default choice is Hyperband. This is indicated in the `else` block
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the search algorithm is executed based on the logic of the preceding code;
    we need to pass the best hyperparameters. For our own information, we may use
    the `get_gest_hyperparameters` API to print out the best hyperparameters. We will
    get the optimal hyperparameters with the help of the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: Now we can pass these best hyperparameters, `best_hp`, to the model and train
    the model with these values. The `tuner.hypermodel.build` API handles the passing
    of these values to the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we will set up the training and validation data batches,
    create a callback object, and start the training with the `fit` API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we log the output of the destination directory for the saved model on
    screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: 'To run this as a script (`hp_kt_resnet_local.py`), you could simply invoke
    it with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding command, we invoke the `python3` runtime to execute our training
    script, `hp_kt_resnet_local.py`. `model_dir` is the place we wish to save the
    model. `Tuner_type` designates the selection of the hyperparameter search algorithm.
    Other algorithm choices you may try are *Bayesian optimization and random search*.
  prefs: []
  type: TYPE_NORMAL
- en: Submitting tuning jobs in Google's AI Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we are ready to use Google's AI Platform to perform hyperparameter training.
    You may download everything you need from the GitHub repository for this chapter.
    For the AI Platform code in this section, you can refer to the `gcptuningwork`
    file in this chapter's folder in the GitHub repository for the book.
  prefs: []
  type: TYPE_NORMAL
- en: In the cloud, we have access to powerful machines that can speed up our search
    process. Overall, the approach we will leverage is very similar to what we saw
    in the previous section about submitting a local Python script training job. We
    will use the `tf.compat.v1.flag` method to handle user input or flags. The rest
    of the script follows a similar structure, with the exception of data handling,
    because we will use `TFRecord` instead of `ImageGenerator` and a conditional flag
    for the distributed training strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the tuning job is submitted to AI Platform from a remote node (that is,
    your local compute environment), some prerequisites need to be met (see [*Chapter
    5*](B16070_05_Final_JM_ePub.xhtml#_idTextAnchor145), *Training at Scale*):'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the directory where the tuning job will be invoked, `setup.py` needs to
    be updated to include `keras-tuner`. And while we are at it, let''s also add IPython.
    So, edit the `setup.py` file as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the entire content of `setup.py`. In this file, we specify the libraries
    we need for our training job and instruct the runtime to find these libraries
    with the `find_packages` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You are now ready to submit a tuning job. In the following command, the job
    is submitted to Cloud TPU to run in the distributed training strategy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice the separator `-- \` in the preceding code, before `-- \`, they are Google
    Cloud-specific arguments. We submit a training script from our environment to
    Cloud TPU. For the training script, we need to specify the package path and module
    name. The Python version and TensorFlow runtime are also selected. We will use
    `BASIC_TPU` in the `us-central1` region.
  prefs: []
  type: TYPE_NORMAL
- en: After `-- \` are the custom arguments for training scripts. These arguments
    are defined for and used in the training script. We designated the value `tpu`
    for our choice of distribution training strategy. Further, the training data location
    is designated by `data_dir`. And once the training job is done, the model will
    be saved in `model_dir`. Finally, we select `HYPERBAND` as our `tuner_type` for
    the hyperparameter tuning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: And from the current directory, where the preceding command is invoked, the
    training script is stored in the `/python/ScriptProject/hp_kt_resnet_tpu_act.py`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'This training script performs a hyperparameter search for two hyperparameters:
    the number of units in a middle `Dense` layer of our image classification model,
    and the activation function. The added `tuner_type` flag lets the user select
    the algorithm: Hyperband, Bayesian optimization, or random search. Once the search
    is completed, it then trains the model with the best hyperparameter configuration
    and saves the model to a storage bucket.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is lengthy, so you can find the entire code and instructions in the
    following GitHub repository: [https://github.com/PacktPublishing/learn-tensorflow-enterprise/tree/master/chapter_06/gcptuningwork](https://github.com/PacktPublishing/learn-tensorflow-enterprise/tree/master/chapter_06/gcptuningwork).'
  prefs: []
  type: TYPE_NORMAL
- en: The main driver script for training is available at [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_06/gcptuningwork/tfk/tuner/hp_kt_resnet_tpu_act.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_06/gcptuningwork/tfk/tuner/hp_kt_resnet_tpu_act.py).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the training is completed, you will see an output in the cloud storage
    specified by `model_dir` as shown in Figure 6.1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Hyperparameter tuning and training job output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0012.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Hyperparameter tuning and training job output
  prefs: []
  type: TYPE_NORMAL
- en: In the storage bucket, there are the model assets saved from training using
    the best hyperparameter configuration in the `best_save_model` folder. Further,
    we can see that each trial of the hyperparameter tuning workflow is also saved
    in the `hp_tune_hb` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Of all the search algorithms, Hyperband is the newest approach and offers an
    effective and efficient search experience based on an exploitation-exploration
    strategy. It is often the fastest algorithm to converge to a winning configuration.
    From the hardware choice perspective, for this example, Cloud TPU offers the shortest
    runtime. However, since hyperparameter search is inherently a time-consuming process,
    data size and data I/O also are also important factors that impact the speed of
    the search. Sometimes it is better to start with a smaller dataset or smaller
    search space to eliminate some selections from further analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to use Keras Tuner in Google Cloud AI Platform.
    We learned how to run the hyperparameter search, and we learned how to train a
    model with the best hyperparameter configuration. We have also seen that in a
    typical Keras style, integrating Keras Tuner into our existing model training
    workflow is very easy, especially with the simple treatment of hyperparameters
    as just arrays of a certain data type. This really opens up the choices for hyperparameters,
    and we do not need to implement the search logic or complicated conditional loops
    to keep track of the results.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see the latest model optimization techniques that
    reduce the model size. As a result, our model can be leaner and more compact.
  prefs: []
  type: TYPE_NORMAL
