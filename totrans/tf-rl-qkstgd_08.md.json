["```\n# Reward setting Here #######################################\n# direction-dependent positive reward\ntrack = np.array(obs['track'])\ntrackPos = np.array(obs['trackPos'])\nsp = np.array(obs['speedX'])\ndamage = np.array(obs['damage'])\nrpm = np.array(obs['rpm'])\n```", "```\nprogress = sp*np.cos(obs['angle']) - np.abs(sp*np.sin(obs['angle'])) - sp * np.abs(obs['trackPos'])\nreward = progress\n```", "```\nif (abs(track.any()) > 1 or abs(trackPos) > 1): # Episode is terminated if the car is out of track\n    print(\"Out of track \")\n    reward = -100 #-200\n    episode_terminate = True\n    client.R.d['meta'] = True\n\nif self.terminal_judge_start < self.time_step: # Episode terminates if the progress of agent is small\n    if progress < self.termination_limit_progress:\n         print(\"No progress\", progress)\n         reward = -100 # KAUSHIK ADDED THIS\n         episode_terminate = True\n         client.R.d['meta'] = True\n```", "```\nstate_dim = 29\naction_dim = 3\naction_bound = 1.0\n```", "```\n   def create_actor_network(self, scope):\n       with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n          state = tf.placeholder(name='a_states', dtype=tf.float32, shape=[None, self.s_dim])\n\n          net = tf.layers.dense(inputs=state, units=400, activation=None, kernel_initializer=winit, bias_initializer=binit, name='anet1') \n          net = tf.nn.relu(net)\n\n          net = tf.layers.dense(inputs=net, units=300, activation=None, kernel_initializer=winit, bias_initializer=binit, name='anet2')\n          net = tf.nn.relu(net)\n\n          steering = tf.layers.dense(inputs=net, units=1, activation=tf.nn.tanh, kernel_initializer=rand_unif, bias_initializer=binit, name='steer') \n          acceleration = tf.layers.dense(inputs=net, units=1, activation=tf.nn.sigmoid, kernel_initializer=rand_unif, bias_initializer=binit, name='acc') \n          brake = tf.layers.dense(inputs=net, units=1, activation=tf.nn.sigmoid, kernel_initializer=rand_unif, bias_initializer=binit, name='brake') \n\n          out = tf.concat([steering, acceleration, brake], axis=1) \n\n          return state, out\n```", "```\n    def create_critic_network(self, scope):\n        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n           state = tf.placeholder(name='c_states', dtype=tf.float32, shape=[None, self.s_dim]) \n           action = tf.placeholder(name='c_action', dtype=tf.float32, shape=[None, self.a_dim]) \n\n           net = tf.concat([state, action],1) \n\n           net = tf.layers.dense(inputs=net, units=400, activation=None, kernel_initializer=winit, bias_initializer=binit, name='cnet1') \n           net = tf.nn.relu(net)\n\n           net = tf.layers.dense(inputs=net, units=300, activation=None, kernel_initializer=winit, bias_initializer=binit, name='cnet2') \n           net = tf.nn.relu(net)\n\n           out = tf.layers.dense(inputs=net, units=1, activation=None, kernel_initializer=rand_unif, bias_initializer=binit, name='cnet_out') \n           return state, action, out\n```", "```\nfrom gym_torcs import TorcsEnv\n```", "```\n    # Generate a Torcs environment\n    env = TorcsEnv(vision=False, throttle=True, gear_change=False)\n```", "```\nif np.mod(i, 100) == 0:\n    ob = env.reset(relaunch=True) #relaunch TORCS every N episodes  due to a memory leak error\nelse:\n    ob = env.reset()\n```", "```\ns = np.hstack((ob.angle, ob.track, ob.trackPos, ob.speedX, ob.speedY, ob.speedZ, ob.wheelSpinVel/100.0, ob.rpm))\n```", "```\nmsteps = max_steps\nif (i < 100):\n    msteps = 100\nelif (i >=100 and i < 200):\n    msteps = 100 + (i-100)*9\nelse: \n    msteps = 1000 + (i-200)*5\n    msteps = min(msteps, max_steps)\n```", "```\n# first few episodes step on gas! \nif (i < 10):\n    a[0][0] = 0.0\n    a[0][1] = 1.0\n    a[0][2] = 0.0\n```", "```\npython ddpg.py\n```"]