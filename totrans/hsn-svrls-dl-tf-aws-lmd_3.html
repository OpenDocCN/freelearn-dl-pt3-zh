<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Deploying TensorFlow Models</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will discuss the TensorFlow framework. Initially. We will begin by describing how the various approaches for building the algorithms differ. We will also cover deep learning and how to train neural networks but, more importantly, you will learn how to use pre-trained neural networks in the application and where you can find them.</p>
<p>We will cover the following topics: </p>
<ul>
<li>Approaches for building algorithms</li>
<li>Why neural networks? </li>
<li>Repositories for pre-trained TensorFlow models</li>
<li>An example of image captioning</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical Requirements</h1>
                </header>
            
            <article>
                
<ul>
<li>AWS subscription</li>
<li>Python 3.6</li>
<li>AWS CLI</li>
<li>Serverless framework</li>
<li>You can find all the codes at<span> </span><a href="https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda">https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Approaches for building algorithms</h1>
                </header>
            
            <article>
                
<p>The various approaches for building algorithms are : </p>
<ul>
<li>First of all, there are deterministic algorithms that are very transparent and predictable, but it may be very difficult to build a custom algorithm for complex tasks, which will work in all cases.</li>
<li>Next, there's the machine learning technique, where we train the model based on features we get from data. We don't need a lot of data to train models in a reliable way, but we need to make a separate process for training validation and testing.</li>
<li>Finally, there's the deep learning approach, where we train <span>our own neural networks</span>. The main advantage of this is that we can use raw data without predefined features. The downside is that we need a lot of data and a lot of computing resources for training.</li>
</ul>
<p>The machine learning approach varies greatly from the classic approach. The classic approach uses rules and data as input and answers as output. In the machine learning approach, we use data and answers as input and we produce rules as output, as shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-430 image-border" src="assets/4a39a3c2-c246-4aea-8d6d-3d1c0c931b82.png" style="width:35.58em;height:16.83em;"/></p>
<p>Let's look into why neural networks have become so popular in recent years.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Why neural networks?</h1>
                </header>
            
            <article>
                
<p>The reasons why neural networks have become popular in recent years are as follows:</p>
<ul>
<li>Computing resources have become a lot cheaper now compared to the prices in the past. With the introduction of a public cloud, it became extremely easy and affordable to use these resources at scale.</li>
<li>The machine learning approach requires a lot of data and, right now, there's a lot of public and private data that can be used for training.</li>
<li>Advanced algorithms were allowed to make and train more complex neural networks.</li>
</ul>
<p>Let's discuss why we actually don't need to train neural networks to successfully use them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pre-trained networks</h1>
                </header>
            
            <article>
                
<p>Although training neural networks may require large processing power and a lot of data, deploying them can be done using a simple CPU. In this way, we can say that deploying a deep learning model is close to using an external library in your code. Secondly, there's a large community of people and companies that open source their pre-trained neural networks, which means that you can freely use them.</p>
<p>There are two instances where using pre-trained neural networks can be extremely convenient:</p>
<ul>
<li>The first case is when your task has already been solved. For example, if you want to conduct image captioning with <em>X</em> classification, then you can use already existing neural networks.</li>
<li>The second case is when your task is fairly different from what has been done but it's close. Then, you can use pre-trained models to generate features that you can use later with deterministic or simple machine learning models.</li>
</ul>
<p>Majority of the pre-trained models use TensorFlow and therefore it currently is the most popular framework for deep learning. It has a very large community of people and a lot of people share the models they've trained. Most companies that are using neural networks in their production environment are using the TensorFlow framework. We will, therefore, learn the use of TensorFlow for the pre-trained models through an example in the next section. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Simple TensorFlow example</h1>
                </header>
            
            <article>
                
<p>One of the great use cases for showing the power of deep learning is the <strong>MNIST</strong> (short for <span><strong>Modified National Institute of Standards and Technology</strong>)</span> dataset. It consists of black and white pictures with handwritten digits, as shown in the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-431 image-border" src="assets/95d0fd34-71dd-42a5-bfd9-792414a009ef.png" style="width:30.58em;height:9.75em;"/></p>
<p>Each image is labeled based on the digit that's written on the image. The task, in this case, is to predict the label based on the image. This kind of task is very difficult to implement using deterministic methods; as you can see in the preceding image, there are a lot of different ways of writing the same number. Therefore, you can't use a single template for prediction. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training for MNIST</h1>
                </header>
            
            <article>
                
<p>In this section, we'll discuss model training for MNIST:</p>
<ol>
<li>First, we start with importing the <kbd>tensorflow</kbd> library. For this example, we'll use the Keras deep learning framework, which makes it easy to set up layers for the neural network. In simple terms, Keras acts as a wrapper on top of TensorFlow, so everything is still based on TensorFlow.</li>
<li>Next, we need to load data and present it in a binary format since the original image pixel values are 0 and 255. We'll also divide the dataset into training and test sets. This will allow us to measure the performance of the neural network. A good practice for the machine learning approach is to train the model on the training dataset and measure the final score on the test dataset. It enables us to be sure that the model doesn't see data points on which it'll be measured after training. We'll see the explanation as follows:</li>
</ol>
<pre class="packt_figure CDPAlignLeft CDPAlign" style="padding-left: 60px">import tensorflow as tf<br/><br/>mnist = tf.keras.datasets.mnist<br/><br/>(x_train, y_train),(x_test, y_test) = mnist.load_data()<br/>x_train, x_test = x_train / 255.0, x_test / 255.0</pre>
<ol start="3">
<li>Now, we need to set up the layers for our neural network. Basically, each layer consists of a number of neurons and an activation function. In this case, the first layer tries to get more useful data out of the raw data. The second layer tries to use this data to assign the probability of the image being one of 10 digits.</li>
<li>As part of the  model, you need to choose three parameters for the training process: 
<ul>
<li>First is the <kbd>loss</kbd> function, which the network will use to optimize its performance. The training process basically consists of decreasing the value of the <kbd>loss</kbd> function and trying to find weights for the neural network, so the <kbd>loss</kbd> function will be minimal.</li>
<li>Next is the <kbd>optimizer</kbd>, which handles how the neural network will iterate towards the most optimal solution, and how it'll change weights after each iteration.</li>
<li>Finally, <kbd>metrics</kbd> <span>allows us to measure neural network performance over the dataset. For example,</span> <kbd>accuracy</kbd> <span>allows us to understand which part of the dataset was correctly classified. This metric doesn't participate in the training process directly and mainly allows us to understand whether network performance has improved or not. We can  understand the preceding explanation from the following code:</span></li>
</ul>
</li>
</ol>
<pre class="packt_figure CDPAlignLeft CDPAlign" style="padding-left: 120px">model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(),<br/>  tf.keras.layers.Dense(512, activation=tf.nn.relu),<br/>  tf.keras.layers.Dense(10, activation=tf.nn.softmax)<br/>])<br/>model.compile(optimizer='adam',<br/>              loss='sparse_categorical_crossentropy',<br/>              metrics=['accuracy'])</pre>
<ol start="5">
<li>Once everything is set up, we can just run training on the training part of our dataset. It may take several minutes, depending on the configurations of your computer. After that, we can evaluate model performance and the test set. Our model will produce something around 97% accuracy/test set, which is very impressive, and as demonstrated, it can be achieved with even a simple neural network as shown in the code below:</li>
</ol>
<pre class="packt_figure CDPAlignLeft CDPAlign" style="padding-left: 60px">model.fit(x_train, y_train, epochs=2)<br/>print('Evaluation:')<br/>print(model.evaluate(x_test, y_test))</pre>
<ol start="6">
<li>Finally, once the neural network has been trained, we can save it so that we can use it later. As you can see, it's a pretty simple process. The model file will contain the model architecture, a key composition of layers, the layer's weights and training configuration, and the optimizer state, which allows us to continue training on the already trained model:</li>
</ol>
<pre class="packt_figure CDPAlignLeft CDPAlign" style="padding-left: 60px">model.save('MNISTmodel.h5')<br/>modelImported = tf.keras.models.load_model('MNISTmodel.h5')<br/>print('Evaluation by imported model:')<br/>print(modelImported.evaluate(x_test, y_test))</pre>
<p>Let's discuss the available files. There's only one Python file, the <kbd>testMNIST.py</kbd> file, which we're about to run. In this file, we can see the parts that we've discussed, which include data transformation, model installation, model training, model evaluation, model export, and model import.</p>
<p><span>Now, let's run the <kbd>testMNIST.py</kbd> file in the command line to see the results. </span>By running the code, we can see the process of training, which happens in epochs. This kind of neural network doesn't require a GPU to train and we can achieve very good results, even on the CPU:</p>
<pre><strong>python testMNIST.py</strong></pre>
<p>As you can see in the following screenshot, we achieved 97% accuracy with just two epochs and were able to successfully export and import the model. We can see the exported retrained model, which can now be used in different code:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/01018366-1582-48f2-9652-a36763e05cc8.png"/></p>
<p class="CDPAlignCenter CDPAlign">.In the next section, we talk about the repositories for pre-trained TensorFlow models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Repositories for pre-trained TensorFlow models</h1>
                </header>
            
            <article>
                
<p>The pre-trained models are pretty skilled when it comes to import and export. In a nutshell, declaring deployment consists of importing the trained model and transforming input data into the format that's acceptable by the neural network. There are <span><span>certain things</span></span> that you need to keep in mind during deployment:</p>
<ul>
<li>The model can be pretty large, for example, hundreds of megabytes, which makes deployment more difficult.</li>
<li>We need to keep versions of the model and track their performance. If you train the model by yourself, you might need to update the model based on changes in incoming data or if you find better architecture.</li>
<li>Some models require additional files that translate predicted numbers or values into meaningful information.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow repository</h1>
                </header>
            
            <article>
                
<p>TensorFlow has five main repositories with a number of selected models. They're a bit established and it's very easy to use them with the TensorFlow framework.</p>
<div class="packt_infobox">For more information on the most popular models that are trained using TensorFlow, visit this site: <span class="MsoHyperlink"><a href="https://github.com/tensorflow/models">https://github.com/tensorflow/models</a>.</span></div>
<p>The different examples for the repositories are as follows:</p>
<ul>
<li>Image to text models, which allow what's happening on the image <span>to be described</span></li>
<li>Image captioning, which classifies the image</li>
<li>Deep speech, which allows speech <span>to be recognized</span></li>
<li>Text summarization, which allows you to make a <span>summary of the text article</span> </li>
<li>Vid2depth, which produces a depth map based on the video stream</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow Hub</h1>
                </header>
            
            <article>
                
<p>There's the TensorFlow Hub hosting platform, which was specifically designed for neural networks. TensorFlow Hub has a lot of great models that are free to use and are mainly trained by Google. They're good and are of state-of-the-art quality. The advantage of TensorFlow Hub is that the models are checked before they're added and the disadvantage is that it has a high barrier for entry submissions.</p>
<div class="packt_infobox"><span>TensorFlow Hub for different models</span> can be viewed at the following link: <span class="MsoHyperlink"><a href="https://tfhub.dev/">https://tfhub.dev/</a>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GitHub</h1>
                </header>
            
            <article>
                
<p>GitHub is considered the largest repository of open source code. There are countless models that are published there but, since there's no entry filter, you'll need to be more cautious about using these models in production. The advantage of GitHub is that it has a low barrier for entry and the disadvantages are that it may be difficult to find a relevant model and the user needs to check how the model works before deployment.</p>
<p>In this next section, we learn about Image captioning through an example. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Image captioning example</h1>
                </header>
            
            <article>
                
<p>Image captioning is a task where we need to recognize an object on the image. Although it sounds simple, it was considered one of the most difficult problems in computer vision since it was close to impossible to make a separate detector for each type of object. The main way to test the image captioning algorithm is to run it on the ImageNet dataset. The <span>ImageNet</span> dataset consists of 14 million images with over 20,000 labels. It was introduced in 2010. Every year, there's a competition of different models, and accuracy has significantly improved in recent years due to the introduction of complex neural networks.</p>
<p><span>There are a number of different models with different architectures that successfully work with </span><span>ImageNet.</span> We'll see that errors significantly decreased over the years. <span> </span><span>The following diagram shows a change in the error rate of </span>winner models<span> in the </span><span>ImageNet</span><span> dataset.</span></p>
<p> </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-434 image-border" src="assets/2a33ec83-dd5a-4b2c-9c9f-0649c94e1cae.png" style="width:35.08em;height:17.17em;"/></p>
<p>We'll now discuss Inception v3, which we'll use in the code sample later.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Inception v3</h1>
                </header>
            
            <article>
                
<p>Inception v3 was introduced by Google and achieved an error rate of 3.46%. You'll see that Inception v3 is significantly more complex. It also takes more resources to train this model, but the upside here is that we don't have to train it to use it.</p>
<p class="mce-root"/>
<p>We'll look into what we'll need to start using I<span>nception </span>v3 in our code. The model consists of layers and weight values present in <kbd>classify_image_graph_def.pb</kbd>.</p>
<p>We also have a list of labels, which the model can predict in  <kbd>imagenet_2012_challenge_label_map_proto.pbtxt</kbd>file and a document that allows the mapping of results of the neural network to the labels in<kbd>imagenet_synset_to_human_label_map</kbd><kbd>.txt</kbd>file.</p>
<p>Here's an example of the Panda image. First, we receive the IDs that score. The highest score means that the model has high confidence in the image having this label. After mapping IDs to label names, we can see that the model correctly detected Panda. The following screenshot explains this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-435 image-border" src="assets/579bdbe1-1e38-4c17-9929-b7c3ca5ffd7b.png" style="width:38.50em;height:10.50em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow code for Inception v3</h1>
                </header>
            
            <article>
                
<p>Now, let's see how the code for any Inception v3 model will look like:</p>
<ol>
<li>First, we need to set up a TensorFlow session. A session is an environment in which tensors are evaluated.</li>
<li>We need to read and set up our neural network by loading it from the file.</li>
<li>Next, we need to ask for our image in the format that'll be readable by the neural network.</li>
<li>We will need to run a power model and receive a list of row predictions, and transform these predictions into actual label values, as shown in the following code:</li>
</ol>
<pre>SESSION = tf.InteractiveSession()<br/>softmax_tensor = tf.get_default_graph().get_tensor_by_name('softmax:0')<br/><br/>predictions = SESSION.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})<br/><br/>node_loolup.id_to_string(predictions)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the code</h1>
                </header>
            
            <article>
                
<p>Let's look at the available files, <kbd>inputimage.png</kbd> and <kbd>testinception.py</kbd>, which we're about to run. In this example, we'll be using the Panda image (<kbd><span>inputimage.png</span></kbd>).</p>
<ol>
<li>As shown in the following code, there's the <kbd>NodeLookup</kbd> class, which will help us to translate responses from the model to the label name:</li>
</ol>
<pre class="packt_figure CDPAlignLeft CDPAlign" style="padding-left: 60px">class NodeLookup(object):<br/>    """Converts integer node ID's to human readable labels."""</pre>
<ol start="2">
<li>The following code shows how we can read the image:</li>
</ol>
<pre style="padding-left: 60px">image = 'inputimage.png'<br/>image_data = tf.gfile.FastGFile(image, 'rb').read()</pre>
<ol start="3">
<li>Then, this is the code that tells how we import the pre-trained model:</li>
</ol>
<pre style="padding-left: 60px">with tf.gfile.FastGFile('classify_image_graph_def.pb', 'rb') as f:<br/>  graph_def = tf.GraphDef()<br/>  graph_def.ParseFromString(f.read())<br/>  tf.import_graph_def(graph_def, name='')</pre>
<ol start="4">
<li>Here, we exchange the model:</li>
</ol>
<pre class="CDPAlignLeft CDPAlign" style="padding-left: 60px">SESSION = tf.InteractiveSession()<br/>softmax_tensor = tf.get_default_graph().get_tensor_by_name('softmax:0')<br/><br/>predictions = SESSION.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})</pre>
<ol start="5">
<li>Finally, we translate the results of the model:</li>
</ol>
<pre style="padding-left: 60px">predictions = np.squeeze(predictions)<br/>node_lookup = NodeLookup(label_lookup_path='imagenet_2012_challenge_label_map_proto.pbtxt',<br/>  uid_lookup_path='imagenet_synset_to_human_label_map.txt')<br/><br/>top_k = predictions.argsort()[-5:][::-1]<br/>strResult = '%s (score = %.5f)' % (node_lookup.id_to_string(top_k[0]), predictions[top_k[0]])<br/>print()<br/>for node_id in top_k:<br/>    human_string = node_lookup.id_to_string(node_id)<br/>    score = predictions[node_id]<br/>    print('%s - %s (score = %.5f)' % (node_id, human_string, score))</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="6">
<li>Now, we can run the code and see the response. As you can see from the following output, the model successfully detected a panda on the image. The code will run fast since there's no training involved. You can try the code on different images and get a sense of the possibilities of this model:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-436 image-border" src="assets/ab937d37-75f1-4fa0-8744-75b06c873bd5.png" style="width:51.00em;height:20.83em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we studied different approaches for building algorithms. We discussed how to train TensorFlow models and repositories for pre-trained Tenserflow models. We also learned about image captioning using an Inception v3 TensorFlow example.</p>
<p>In the next chapter, we'll learn how to work with TensorFlow AWS Lambda, where we'll learn more about using TensorFlow models with AWS Lambda.</p>


            </article>

            
        </section>
    </body></html>