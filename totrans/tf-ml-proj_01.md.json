["```\ntf.constant(\n  value,\n  dtype=None,\n  shape=None,\n  name='const_name',\n  verify_shape=False\n  )\n```", "```\nconst1=tf.constant(34,name='x1')\nconst2=tf.constant(59.0,name='y1')\nconst3=tf.constant(32.0,dtype=tf.float16,name='z1')\n```", "```\nprint('const1 (x): ',const1)\nprint('const2 (y): ',const2)\nprint('const3 (z): ',const3)\n```", "```\nconst1 (x):  Tensor(\"x:0\", shape=(), dtype=int32)\nconst2 (y):  Tensor(\"y:0\", shape=(), dtype=float32)\nconst3 (z):  Tensor(\"z:0\", shape=(), dtype=float16)\n```", "```\nprint('run([const1,const2,c3]) : ',tfs.run([const1,const2,const3]))\n```", "```\nrun([const1,const2,const3]) : [34, 59.0, 32.0]\n```", "```\nop1 = tf.add(const2, const3)\nop2 = tf.multiply(const2, const3)\n```", "```\nprint('op1 : ', op1)\nprint('op2 : ', op2)\n```", "```\nop1 :  Tensor(\"Add:0\", shape=(), dtype=float32)\nop2 :  Tensor(\"Mul:0\", shape=(), dtype=float32)\n```", "```\nprint('run(op1) : ', tfs.run(op1))\nprint('run(op2) : ', tfs.run(op2))\n```", "```\nrun(op1) :  91.0\nrun(op2) :  1888.0\n```", "```\ntf.placeholder(\n  dtype,\n  shape=None,\n  name=None\n  )\n```", "```\np1 = tf.placeholder(tf.float32)\np2 = tf.placeholder(tf.float32)\nprint('p1 : ', p1)\nprint('p2 : ', p2)\n```", "```\np1 :  Tensor(\"Placeholder:0\", dtype=float32)\np2 :  Tensor(\"Placeholder_1:0\", dtype=float32)\n```", "```\nmult_op = p1 * p2\n```", "```\nprint('run(mult_op,{p1:13.4, p2:61.7}) : ',tfs.run(mult_op,{p1:13.4, p2:61.7}))\n```", "```\nrun(mult_op,{p1:13.4, p2:61.7}) :  826.77997\n```", "```\nfeed_dict={p1: 15.4, p2: 19.5}\nprint('run(mult_op,feed_dict = {p1:15.4, p2:19.5}) : ',\n      tfs.run(mult_op, feed_dict=feed_dict))\n```", "```\nrun(mult_op,feed_dict = {p1:15.4, p2:19.5}) :  300.3\n```", "```\nfeed_dict={p1: [2.0, 3.0, 4.0], p2: [3.0, 4.0, 5.0]}\nprint('run(mult_op,feed_dict={p1:[2.0,3.0,4.0], p2:[3.0,4.0,5.0]}):',\n      tfs.run(mult_op, feed_dict=feed_dict))\n```", "```\nrun(mult_op,feed_dict={p1:[2.0,3.0,4.0],p2:[3.0,4.0,5.0]}):[  6\\.  12\\.  20.]\n```", "```\ntf.convert_to_tensor(\n  value,\n  dtype=None,\n  name=None,\n  preferred_dtype=None\n  )\n```", "```\ntf_t=tf.convert_to_tensor(5.0,dtype=tf.float64)\n\nprint('tf_t : ',tf_t)\nprint('run(tf_t) : ',tfs.run(tf_t))\n```", "```\ntf_t : Tensor(\"Const_1:0\", shape=(), dtype=float64)\nrun(tf_t) : 5.0\n```", "```\na1dim = np.array([1,2,3,4,5.99])\nprint(\"a1dim Shape : \",a1dim.shape)\n\ntf_t=tf.convert_to_tensor(a1dim,dtype=tf.float64)\n\nprint('tf_t : ',tf_t)\nprint('tf_t[0] : ',tf_t[0])\nprint('tf_t[0] : ',tf_t[2])\nprint('run(tf_t) : \\n',tfs.run(tf_t))\n```", "```\na1dim Shape :  (5,)\ntf_t :  Tensor(\"Const_2:0\", shape=(5,), dtype=float64)\ntf_t[0] :  Tensor(\"strided_slice:0\", shape=(), dtype=float64)\ntf_t[0] :  Tensor(\"strided_slice_1:0\", shape=(), dtype=float64)\nrun(tf_t) : \n [ 1\\.    2\\.    3\\.    4\\.    5.99]\n```", "```\na2dim = np.array([(1,2,3,4,5.99),\n                  (2,3,4,5,6.99),\n                  (3,4,5,6,7.99)\n                 ])\nprint(\"a2dim Shape : \",a2dim.shape)\n\ntf_t=tf.convert_to_tensor(a2dim,dtype=tf.float64)\n\nprint('tf_t : ',tf_t)\nprint('tf_t[0][0] : ',tf_t[0][0])\nprint('tf_t[1][2] : ',tf_t[1][2])\nprint('run(tf_t) : \\n',tfs.run(tf_t))\n```", "```\na2dim Shape :  (3, 5)\ntf_t :  Tensor(\"Const_3:0\", shape=(3, 5), dtype=float64)\ntf_t[0][0] :  Tensor(\"strided_slice_3:0\", shape=(), dtype=float64)\ntf_t[1][2] :  Tensor(\"strided_slice_5:0\", shape=(), dtype=float64)\nrun(tf_t) : \n [[ 1\\.    2\\.    3\\.    4\\.    5.99]\n  [ 2\\.    3\\.    4\\.    5\\.    6.99]\n  [ 3\\.    4\\.    5\\.    6\\.    7.99]]\n```", "```\na3dim = np.array([[[1,2],[3,4]],\n                  [[5,6],[7,8]]\n                 ])\nprint(\"a3dim Shape : \",a3dim.shape)\n\ntf_t=tf.convert_to_tensor(a3dim,dtype=tf.float64)\n\nprint('tf_t : ',tf_t)\nprint('tf_t[0][0][0] : ',tf_t[0][0][0])\nprint('tf_t[1][1][1] : ',tf_t[1][1][1])\nprint('run(tf_t) : \\n',tfs.run(tf_t))\n```", "```\na3dim Shape :  (2, 2, 2)\ntf_t :  Tensor(\"Const_4:0\", shape=(2, 2, 2), dtype=float64)\ntf_t[0][0][0] :  Tensor(\"strided_slice_8:0\", shape=(), dtype=float64)\ntf_t[1][1][1] :  Tensor(\"strided_slice_11:0\", shape=(), dtype=float64)\nrun(tf_t) : \n [[[ 1\\.  2.][ 3\\.  4.]]\n  [[ 5\\.  6.][ 7\\.  8.]]]\n```", "```\nw = tf.Variable([.3], tf.float32)\nb = tf.Variable([-.3], tf.float32)\n```", "```\nx = tf.placeholder(tf.float32)\ny = w * x + b\n```", "```\nprint(\"w:\",w)\nprint(\"x:\",x)\nprint(\"b:\",b)\nprint(\"y:\",y)\n```", "```\nw: <tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\nx: Tensor(\"Placeholder_2:0\", dtype=float32)\nb: <tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\ny: Tensor(\"add:0\", dtype=float32)\n```", "```\ntfs.run(w.initializer)\n```", "```\ntfs.run(tf.global_variables_initializer())\n```", "```\ntf.global_variables_initializer().run()\n```", "```\nprint('run(y,{x:[1,2,3,4]}) : ',tfs.run(y,{x:[1,2,3,4]}))\n```", "```\nrun(y,{x:[1,2,3,4]}) :  [ 0\\.          0.30000001  0.60000002  0.90000004]\n```", "```\na=tf.zeros((100,))\nprint(tfs.run(a))\n```", "```\nw = tf.get_variable(name='w',shape=[1],dtype=tf.float32,initializer=[.3])\nb = tf.get_variable(name='b',shape=[1],dtype=tf.float32,initializer=[-.3])\n```", "```\ngraph = tf.get_default_graph()\n```", "```\n# Linear Model y = w * x + b\n# Define the model parameters\nw = tf.Variable([.3], tf.float32)\nb = tf.Variable([-.3], tf.float32)\n# Define model input and output\nx = tf.placeholder(tf.float32)\ny = w * x + b\noutput = 0\n\nwith tf.Session() as tfs:\n   # initialize and print the variable y\n   tf.global_variables_initializer().run()\n   output = tfs.run(y,{x:[1,2,3,4]})\nprint('output : ',output)\n```", "```\nwith graph_variable.control_dependencies([n,o]):\n  # other statements here\n```", "```\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n```", "```\n[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 12900903776306102093\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 611319808\nlocality {\n  bus_id: 1\n}\nincarnation: 2202031001192109390\nphysical_device_desc: \"device: 0, name: Quadro P5000, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n]\n```", "```\ntf.reset_default_graph()\n\n# Define model parameters\nw = tf.Variable([.3], tf.float32)\nb = tf.Variable([-.3], tf.float32)\n# Define model input and output\nx = tf.placeholder(tf.float32)\ny = w * x + b\n\nconfig = tf.ConfigProto()\nconfig.log_device_placement=True\n\nwith tf.Session(config=config) as tfs:\n   # initialize and print the variable y\n   tfs.run(global_variables_initializer())\n   print('output',tfs.run(y,{x:[1,2,3,4]}))\n```", "```\nb: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\nb/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\nb/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\nw: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0\nw/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0\nmul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\nadd: (Add): /job:localhost/replica:0/task:0/device:GPU:0\nw/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0\ninit: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0\nx: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\nb/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nConst_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nw/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0\nConst: (Const): /job:localhost/replica:0/task:0/device:GPU:0\n```", "```\ntf.reset_default_graph()\n\nwith tf.device('/device:CPU:0'):\n    # Define model parameters\n    w = tf.get_variable(name='w',initializer=[.3], dtype=tf.float32)\n    b = tf.get_variable(name='b',initializer=[-.3], dtype=tf.float32)\n    # Define model input and output\n    x = tf.placeholder(name='x',dtype=tf.float32)\n    y = w * x + b\n\nconfig = tf.ConfigProto()\nconfig.log_device_placement=True\n\nwith tf.Session(config=config) as tfs:\n   # initialize and print the variable y\n   tfs.run(tf.global_variables_initializer())\n   print('output',tfs.run(y,{x:[1,2,3,4]}))\n```", "```\nb: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0\nb/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\nb/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0\nw: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0\nw/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\nmul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0\nadd: (Add): /job:localhost/replica:0/task:0/device:CPU:0\nw/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0\ninit: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0\nx: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0\nb/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0\nConst_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0\nw/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0\nConst: (Const): /job:localhost/replica:0/task:0/device:CPU:0\n```", "```\nIf the graph was previously run, \n    then the node is left on the device where it was placed earlier\nElse If the tf.device() block is used,\n    then the node is placed on the specified device\nElse If the GPU is present\n    then the node is placed on the first available GPU\nElse If the GPU is not present\n    then the node is placed on the CPU\n```", "```\nconfig.allow_soft_placement = True\n```", "```\nos.environ['CUDA_VISIBLE_DEVICES']='0'\n```", "```\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n```", "```\nconfig.gpu_options.allow_growth = True\n```", "```\ng = tf.Graph()\noutput = 0\n\n# Assume Linear Model y = w * x + b\n\nwith g.as_default():\n # Define model parameters\n w = tf.Variable([.3], tf.float32)\n b = tf.Variable([-.3], tf.float32)\n # Define model input and output\n x = tf.placeholder(tf.float32)\n y = w * x + b\n\nwith tf.Session(graph=g) as tfs:\n # initialize and print the variable y\n tf.global_variables_initializer().run()\n output = tfs.run(y,{x:[1,2,3,4]})\n\nprint('output : ',output)\n```", "```\nDSLIB_HOME = '../datasetslib'\nimport sys\nif not DSLIB_HOME in sys.path:\n    sys.path.append(DSLIB_HOME)\n%reload_ext autoreload\n%autoreload 2\nimport datasetslib as dslib\n\nfrom datasetslib.utils import imutil\nfrom datasetslib.utils import nputil\nfrom datasetslib.mnist import MNIST\n```", "```\nimport os\ndatasets_root = os.path.join(os.path.expanduser('~'),'datasets')\n```", "```\nmnist=MNIST()\n\nx_train,y_train,x_test,y_test=mnist.load_data()\n\nmnist.y_onehot = True\nmnist.x_layout = imutil.LAYOUT_NP\nx_test = mnist.load_images(x_test)\ny_test = nputil.onehot(y_test)\n\nprint('Loaded x and y')\nprint('Train: x:{}, y:{}'.format(len(x_train),y_train.shape))\nprint('Test: x:{}, y:{}'.format(x_test.shape,y_test.shape))\n```", "```\nlearning_rate = 0.001\nn_epochs = 5\nmnist.batch_size = 100\n```", "```\n# define input images\nx = tf.placeholder(dtype=tf.float32, shape=[None, mnist.n_features])\n# define output labels\ny = tf.placeholder(dtype=tf.float32, shape=[None, mnist.n_classes])\n\n# model parameters\nw = tf.Variable(tf.zeros([mnist.n_features, mnist.n_classes]))\nb = tf.Variable(tf.zeros([mnist.n_classes]))\n```", "```\nlogits = tf.add(tf.matmul(x, w), b)\ny_hat = tf.nn.softmax(logits)\n```", "```\nepsilon = tf.keras.backend.epsilon()\ny_hat_clipped = tf.clip_by_value(y_hat, epsilon, 1 - epsilon)\ny_hat_log = tf.log(y_hat_clipped)\ncross_entropy = -tf.reduce_sum(y * y_hat_log, axis=1)\nloss_f = tf.reduce_mean(cross_entropy)\n```", "```\noptimizer = tf.train.GradientDescentOptimizer\noptimizer_f = optimizer(learning_rate=learning_rate).minimize(loss_f)\n```", "```\npredictions_check = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))\naccuracy_f = tf.reduce_mean(tf.cast(predictions_check, tf.float32))\n```", "```\nn_batches = int(60000/mnist.batch_size)\n\nwith tf.Session() as tfs:\n    tf.global_variables_initializer().run()\n    for epoch in range(n_epochs):\n        mnist.reset_index()\n        for batch in range(n_batches):\n            x_batch, y_batch = mnist.next_batch()\n            feed_dict={x: x_batch, y: y_batch}\n            batch_loss,_ = tfs.run([loss_f, optimizer_f],feed_dict=feed_dict )\n            #print('Batch loss:{}'.format(batch_loss))\n\n```", "```\nfeed_dict = {x: x_test, y: y_test}\naccuracy_score = tfs.run(accuracy_f, feed_dict=feed_dict)\nprint('epoch {0:04d}  accuracy={1:.8f}'\n      .format(epoch, accuracy_score))\n```", "```\nepoch 0000 accuracy=0.73280001 epoch 0001 accuracy=0.72869998 epoch 0002 accuracy=0.74550003 epoch 0003 accuracy=0.75260001 epoch 0004 accuracy=0.74299997\n```", "```\nx_train_im = mnist.load_images(x_train)\n\nx_train_im, x_test_im = x_train_im / 255.0, x_test / 255.0\n```", "```\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n```", "```\nmodel.compile(optimizer='sgd',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n```", "```\nmodel.fit(x_train_im, y_train, epochs=5)\n\nEpoch 1/5\n60000/60000 [==============================] - 3s 45us/step - loss: 0.7874 - acc: 0.8095\nEpoch 2/5\n60000/60000 [==============================] - 3s 42us/step - loss: 0.4585 - acc: 0.8792\nEpoch 3/5\n60000/60000 [==============================] - 2s 42us/step - loss: 0.4049 - acc: 0.8909\nEpoch 4/5\n60000/60000 [==============================] - 3s 42us/step - loss: 0.3780 - acc: 0.8965\nEpoch 5/5\n60000/60000 [==============================] - 3s 42us/step - loss: 0.3610 - acc: 0.9012\n10000/10000 [==============================] - 0s 24us/step\n```", "```\nmodel.evaluate(x_test_im, nputil.argmax(y_test))\n```", "```\n[0.33530342621803283, 0.9097]\n```"]