["```\n%matplotlib inline\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n```", "```\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist_dataset = input_data.read_data_sets('MNIST_data', validation_size=0)\n\nOutput:\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n```", "```\n# Plotting one image from the training set.\nimage = mnist_dataset.train.images[2]\nplt.imshow(image.reshape((28, 28)), cmap='Greys_r')\n```", "```\nOutput:\n```", "```\n# Plotting one image from the training set.\nimage = mnist_dataset.train.images[2]\nplt.imshow(image.reshape((28, 28)), cmap='Greys_r')\n\nOutput:\n```", "```\n# The size of the encoding layer or the hidden layer.\nencoding_layer_dim = 32 \n\nimg_size = mnist_dataset.train.images.shape[1]\n\n# defining placeholder variables of the input and target values\ninputs_values = tf.placeholder(tf.float32, (None, img_size), name=\"inputs_values\")\ntargets_values = tf.placeholder(tf.float32, (None, img_size), name=\"targets_values\")\n\n# Defining an encoding layer which takes the input values and incode them.\nencoding_layer = tf.layers.dense(inputs_values, encoding_layer_dim, activation=tf.nn.relu)\n\n# Defining the logit layer, which is a fully-connected layer but without any activation applied to its output\nlogits_layer = tf.layers.dense(encoding_layer, img_size, activation=None)\n\n# Adding a sigmoid layer after the logit layer\ndecoding_layer = tf.sigmoid(logits_layer, name = \"decoding_layer\")\n\n# use the sigmoid cross entropy as a loss function\nmodel_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_layer, labels=targets_values)\n\n# Averaging the loss values accross the input data\nmodel_cost = tf.reduce_mean(model_loss)\n\n# Now we have a cost functiont that we need to optimize using Adam Optimizer\nmodel_optimizier = tf.train.AdamOptimizer().minimize(model_cost)\n```", "```\n# creating the session\n sess = tf.Session()\n```", "```\nnum_epochs = 20\ntrain_batch_size = 200\n\nsess.run(tf.global_variables_initializer())\nfor e in range(num_epochs):\n    for ii in range(mnist_dataset.train.num_examples//train_batch_size):\n        input_batch = mnist_dataset.train.next_batch(train_batch_size)\n        feed_dict = {inputs_values: input_batch[0], targets_values: input_batch[0]}\n        input_batch_cost, _ = sess.run([model_cost, model_optimizier], feed_dict=feed_dict)\n\n        print(\"Epoch: {}/{}...\".format(e+1, num_epochs),\n              \"Training loss: {:.3f}\".format(input_batch_cost))\n```", "```\nOutput:\n.\n.\n.\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.089\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.096\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.096\nEpoch: 20/20... Training loss: 0.092\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.096\nEpoch: 20/20... Training loss: 0.089\nEpoch: 20/20... Training loss: 0.090\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.088\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.090\nEpoch: 20/20... Training loss: 0.091\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.095\nEpoch: 20/20... Training loss: 0.094\nEpoch: 20/20... Training loss: 0.092\nEpoch: 20/20... Training loss: 0.092\nEpoch: 20/20... Training loss: 0.093\nEpoch: 20/20... Training loss: 0.093\n```", "```\nfig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n\ninput_images = mnist_dataset.test.images[:10]\nreconstructed_images, compressed_images = sess.run([decoding_layer, encoding_layer], feed_dict={inputs_values: input_images})\n\nfor imgs, row in zip([input_images, reconstructed_images], axes):\n    for img, ax in zip(imgs, row):\n        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\nfig.tight_layout(pad=0.1)\n```", "```\n%matplotlib inline\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n```", "```\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist_dataset = input_data.read_data_sets('MNIST_data', validation_size=0)\n\nOutput:\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nmnist_dataset = input_data.read_data_sets('MNIST_data', validation_size=0)\n\nExtracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n```", "```\n# Plotting one image from the training set.\nimage = mnist_dataset.train.images[2]\nplt.imshow(image.reshape((28, 28)), cmap='Greys_r')\n```", "```\nlearning_rate = 0.001\n\n# Define the placeholder variable sfor the input and target values\ninputs_values = tf.placeholder(tf.float32, (None, 28,28,1), name=\"inputs_values\")\ntargets_values = tf.placeholder(tf.float32, (None, 28,28,1), name=\"targets_values\")\n\n# Defining the Encoder part of the netowrk\n# Defining the first convolution layer in the encoder parrt\n# The output tenosor will be in the shape of 28x28x16\nconv_layer_1 = tf.layers.conv2d(inputs=inputs_values, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 14x14x16\nmaxpool_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=(2,2), strides=(2,2), padding='same')\n\n# The output tenosor will be in the shape of 14x14x8\nconv_layer_2 = tf.layers.conv2d(inputs=maxpool_layer_1, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 7x7x8\nmaxpool_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=(2,2), strides=(2,2), padding='same')\n\n# The output tenosor will be in the shape of 7x7x8\nconv_layer_3 = tf.layers.conv2d(inputs=maxpool_layer_2, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 4x4x8\nencoded_layer = tf.layers.max_pooling2d(conv_layer_3, pool_size=(2,2), strides=(2,2), padding='same')\n\n# Defining the Decoder part of the netowrk\n# Defining the first upsampling layer in the decoder part\n# The output tenosor will be in the shape of 7x7x8\nupsample_layer_1 = tf.image.resize_images(encoded_layer, size=(7,7), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n# The output tenosor will be in the shape of 7x7x8\nconv_layer_4 = tf.layers.conv2d(inputs=upsample_layer_1, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 14x14x8\nupsample_layer_2 = tf.image.resize_images(conv_layer_4, size=(14,14), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n# The output tenosor will be in the shape of 14x14x8\nconv_layer_5 = tf.layers.conv2d(inputs=upsample_layer_2, filters=8, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 28x28x8\nupsample_layer_3 = tf.image.resize_images(conv_layer_5, size=(28,28), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n# The output tenosor will be in the shape of 28x28x16\nconv6 = tf.layers.conv2d(inputs=upsample_layer_3, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 28x28x1\nlogits_layer = tf.layers.conv2d(inputs=conv6, filters=1, kernel_size=(3,3), padding='same', activation=None)\n\n# feeding the logits values to the sigmoid activation function to get the reconstructed images\ndecoded_layer = tf.nn.sigmoid(logits_layer)\n\n# feeding the logits to sigmoid while calculating the cross entropy\nmodel_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_values, logits=logits_layer)\n\n# Getting the model cost and defining the optimizer to minimize it\nmodel_cost = tf.reduce_mean(model_loss)\nmodel_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(model_cost)\n```", "```\nsess = tf.Session()\nnum_epochs = 20\ntrain_batch_size = 200\nsess.run(tf.global_variables_initializer())\n\nfor e in range(num_epochs):\n    for ii in range(mnist_dataset.train.num_examples//train_batch_size):\n        input_batch = mnist_dataset.train.next_batch(train_batch_size)\n        input_images = input_batch[0].reshape((-1, 28, 28, 1))\n        input_batch_cost, _ = sess.run([model_cost, model_optimizer], feed_dict={inputs_values: input_images,targets_values: input_images})\n\n        print(\"Epoch: {}/{}...\".format(e+1, num_epochs),\n              \"Training loss: {:.3f}\".format(input_batch_cost))\n```", "```\nOutput:\n.\n.\n.\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.098\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.104\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.098\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.098\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.104\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.105\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.104\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.098\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.098\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.096\nEpoch: 20/20... Training loss: 0.104\nEpoch: 20/20... Training loss: 0.104\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.103\nEpoch: 20/20... Training loss: 0.104\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.101\nEpoch: 20/20... Training loss: 0.099\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.102\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.098\nEpoch: 20/20... Training loss: 0.100\nEpoch: 20/20... Training loss: 0.097\nEpoch: 20/20... Training loss: 0.102\n```", "```\nfig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\ninput_images = mnist_dataset.test.images[:10]\nreconstructed_images = sess.run(decoded_layer, feed_dict={inputs_values: input_images.reshape((10, 28, 28, 1))})\n\nfor imgs, row in zip([input_images, reconstructed_images], axes):\n    for img, ax in zip(imgs, row):\n        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\nfig.tight_layout(pad=0.1)\n\nOutput:\n```", "```\nlearning_rate = 0.001\n\n# Define the placeholder variable sfor the input and target values\ninputs_values = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs_values')\ntargets_values = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets_values')\n\n# Defining the Encoder part of the netowrk\n# Defining the first convolution layer in the encoder parrt\n# The output tenosor will be in the shape of 28x28x32\nconv_layer_1 = tf.layers.conv2d(inputs=inputs_values, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 14x14x32\nmaxpool_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=(2,2), strides=(2,2), padding='same')\n\n# The output tenosor will be in the shape of 14x14x32\nconv_layer_2 = tf.layers.conv2d(inputs=maxpool_layer_1, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 7x7x32\nmaxpool_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=(2,2), strides=(2,2), padding='same')\n\n# The output tenosor will be in the shape of 7x7x16\nconv_layer_3 = tf.layers.conv2d(inputs=maxpool_layer_2, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 4x4x16\nencoding_layer = tf.layers.max_pooling2d(conv_layer_3, pool_size=(2,2), strides=(2,2), padding='same')\n\n# Defining the Decoder part of the netowrk\n# Defining the first upsampling layer in the decoder part\n# The output tenosor will be in the shape of 7x7x16\nupsample_layer_1 = tf.image.resize_images(encoding_layer, size=(7,7), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n# The output tenosor will be in the shape of 7x7x16\nconv_layer_4 = tf.layers.conv2d(inputs=upsample_layer_1, filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 14x14x16\nupsample_layer_2 = tf.image.resize_images(conv_layer_4, size=(14,14), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n# The output tenosor will be in the shape of 14x14x32\nconv_layer_5 = tf.layers.conv2d(inputs=upsample_layer_2, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 28x28x32\nupsample_layer_3 = tf.image.resize_images(conv_layer_5, size=(28,28), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n# The output tenosor will be in the shape of 28x28x32\nconv_layer_6 = tf.layers.conv2d(inputs=upsample_layer_3, filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu)\n\n# The output tenosor will be in the shape of 28x28x1\nlogits_layer = tf.layers.conv2d(inputs=conv_layer_6, filters=1, kernel_size=(3,3), padding='same', activation=None)\n\n# feeding the logits values to the sigmoid activation function to get the reconstructed images\ndecoding_layer = tf.nn.sigmoid(logits_layer)\n\n# feeding the logits to sigmoid while calculating the cross entropy\nmodel_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_values, logits=logits_layer)\n\n# Getting the model cost and defining the optimizer to minimize it\nmodel_cost = tf.reduce_mean(model_loss)\nmodel_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(model_cost)\n```", "```\nsess = tf.Session()\n```", "```\nnum_epochs = 100\ntrain_batch_size = 200\n\n# Defining a noise factor to be added to MNIST dataset\nmnist_noise_factor = 0.5\nsess.run(tf.global_variables_initializer())\n\nfor e in range(num_epochs):\n    for ii in range(mnist_dataset.train.num_examples//train_batch_size):\n        input_batch = mnist_dataset.train.next_batch(train_batch_size)\n\n        # Getting and reshape the images from the corresponding batch\n        batch_images = input_batch[0].reshape((-1, 28, 28, 1))\n\n        # Add random noise to the input images\n        noisy_images = batch_images + mnist_noise_factor * np.random.randn(*batch_images.shape)\n\n        # Clipping all the values that are above 0 or above 1\n        noisy_images = np.clip(noisy_images, 0., 1.)\n\n        # Set the input images to be the noisy ones and the original images to be the target\n        input_batch_cost, _ = sess.run([model_cost, model_optimizer], feed_dict={inputs_values: noisy_images,\n                                                         targets_values: batch_images})\n\n        print(\"Epoch: {}/{}...\".format(e+1, num_epochs),\n              \"Training loss: {:.3f}\".format(input_batch_cost))\n```", "```\nOutput:\n.\n.\n.\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.101\nEpoch: 100/100... Training loss: 0.103\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.103\nEpoch: 100/100... Training loss: 0.101\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.096\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.103\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.101\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.096\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.101\nEpoch: 100/100... Training loss: 0.102\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.103\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.098\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.097\nEpoch: 100/100... Training loss: 0.099\nEpoch: 100/100... Training loss: 0.100\nEpoch: 100/100... Training loss: 0.101\nEpoch: 100/100... Training loss: 0.101\n```", "```\n#Defining some figures\nfig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n\n#Visualizing some images\ninput_images = mnist_dataset.test.images[:10]\nnoisy_imgs = input_images + mnist_noise_factor * np.random.randn(*input_images.shape)\n\n#Clipping and reshaping the noisy images\nnoisy_images = np.clip(noisy_images, 0., 1.).reshape((10, 28, 28, 1))\n\n#Getting the reconstructed images\nreconstructed_images = sess.run(decoding_layer, feed_dict={inputs_values: noisy_images})\n\n#Visualizing the input images and the noisy ones\nfor imgs, row in zip([noisy_images, reconstructed_images], axes):\n    for img, ax in zip(imgs, row):\n        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\nfig.tight_layout(pad=0.1)\n```", "```\n\nOutput:\n```"]