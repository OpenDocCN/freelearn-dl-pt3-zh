- en: 11\. Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduces you to generative models—their components, how they
    function, and what they can do. You will start with generative **long short-term
    memory** (**LSTM**) networks and how to use them to generate new text. You will
    then learn about **generative adversarial networks** (**GANs**) and how to create
    new data, before moving on to **deep convolutional generative adversarial networks**
    (**DCGANs**) and creating your own images.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the chapter, you will know how to effectively use different types
    of GANs and generate various types of new data.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will explore generative models, which are types of unsupervised
    learning algorithms that generate completely new artificial data. Generative models
    differ from predictive models in that they aim to generate new samples from the
    same distribution of training data. While the purpose of these models may be very
    different from those covered in other chapters, you can and will use many of the
    concepts learned in prior chapters, including loading and preprocessing various
    data files, hyperparameter tuning, and building convolutional and **recurrent
    neural networks** (**RNNs**). In this chapter, you will learn about one way to
    generate new samples from a training dataset, which is to use LSTM models to complete
    sequences of data based on initial seed data.
  prefs: []
  type: TYPE_NORMAL
- en: Another way that you will learn about is the concept of two neural networks
    competing against one another in an adversarial way, that is, a generator generating
    samples and a discriminator trying to distinguish between the generated and real
    samples. As both models train simultaneously, the generator generates more realistic
    samples as the discriminator can more accurately distinguish between the "real"
    and "fake" data over time. These networks working together are called GANs. Generative
    models can be used to generate new text data, audio samples, and images.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will focus primarily on three areas of generative models
    – text generation or language modeling, GANs, and DCGANs.
  prefs: []
  type: TYPE_NORMAL
- en: Text Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Chapter 9*, *Recurrent Neural Networks*, you were introduced to **natural
    language processing** (**NLP**) and text generation (also known as language modeling),
    as you worked with some sequential data problems. In this section, you will be
    extending your sequence model for text generation using the same dataset to generate
    extended headlines.
  prefs: []
  type: TYPE_NORMAL
- en: Previously in this book, you saw that sequential data is data in which each
    point in the dataset is dependent on the point prior and the order of the data
    is important. Recall the example with the bag of words from *Chapter 9*, *Recurrent
    Neural Networks*. With the *bag-of-words* approach, you simply used a set of word
    counts to derive meaning from their use. As you can see in *Figure 11.1*, these
    two sentences have completely opposite semantic meanings, but would be identical
    in a bag-of-words format. While this may be an effective strategy for some problems,
    it's not an ideal approach for predicting the next word or words.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1: An example of identical words with differing semantics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.1: An example of identical words with differing semantics'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following example of a language model. You are given a sentence
    or a phrase, `yesterday I took my car out for a`, and are asked to predict the
    word that comes next in the sequence. Here, an appropriate word to complete the
    sequence would be `drive`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2: Sentence example'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.2: Sentence example'
  prefs: []
  type: TYPE_NORMAL
- en: To be successful in working with sequential data, you need a neural network
    capable of storing the value of the sequence. For this, you can use RNNs and LSTMs.
    LSTMs that are used for generating new sequences, such as text generation or language
    modeling, are known as generative LSTMs.
  prefs: []
  type: TYPE_NORMAL
- en: Let's do a simple review of RNNs and LSTMs.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, RNNs loop back on themselves, storing information and repeating
    the process, in a continuous cycle. Information is first transformed into vectors
    so that it can be processed by machines. The RNN then processes the vector sequence
    one at a time. As the RNN processes each vector, the vector gets passed through
    the previous hidden state. In this way, the hidden state retains information from
    the previous step, acting as a type of memory. It does this by combining the input
    and the previous hidden state with a tanh function that compresses the values
    between `-1` and `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, this is how the RNN functions. RNNs don't need a lot of computation
    and work well with short sequences. Simply put, RNNs are networks that have loops
    that allow information to persist over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3: RNN data flow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.3: RNN data flow'
  prefs: []
  type: TYPE_NORMAL
- en: RNNs do come with a couple of challenges—most notably, the exploding and vanishing
    gradient problems.
  prefs: []
  type: TYPE_NORMAL
- en: The **exploding gradient problem** is what happens when gradients become too
    large for optimization. The opposite problem may occur where your gradients are
    too small. This is what is known as the **vanishing gradient problem**. This happens
    when gradients become increasingly smaller as you make repeated multiplications.
    Since the size of the gradient determines the size of the weight updates, exploding
    or vanishing gradients mean that the network can no longer be trained. This is
    a very real problem when it comes to training RNNs since the output of the networks
    feeds back into the input. The vanishing and exploding gradient issues were covered
    in *Chapter 9*, *Recurrent Neural Networks*, and more details of how these issues
    are solved can be found there.
  prefs: []
  type: TYPE_NORMAL
- en: LSTMs can selectively control the flow of information within each LSTM node.
    With added control, you can more easily adjust the model to prevent potential
    problems with gradients.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4: LSTM architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.4: LSTM architecture'
  prefs: []
  type: TYPE_NORMAL
- en: So, what enables LSTMs to track and store information throughout many time steps?
    You'll recall from *Chapter 9*, *Recurrent Neural Networks*, that the key building
    block behind the LSTM is the structure called a *gate*, which allows the LSTM
    to selectively add or remove information to its cell state.
  prefs: []
  type: TYPE_NORMAL
- en: Gates consist of a bounding function such as sigmoid or tanh. For example, if
    the function were sigmoid, it would force its input to be between zero and one.
    Intuitively, you can think of this as capturing how much of the information passed
    through the gate should be retained. This should be between zero and one, effectively
    *gating* the flow of information.
  prefs: []
  type: TYPE_NORMAL
- en: LSTMs process information through four simple steps.
  prefs: []
  type: TYPE_NORMAL
- en: They first forget their irrelevant history. Second, they perform a computation
    to store relevant parts of new information, and thirdly, they use these two steps
    together to selectively update their internal state. Finally, they generate an
    output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5: LSTM processing steps'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.5: LSTM processing steps'
  prefs: []
  type: TYPE_NORMAL
- en: This was a bit of a refresher on LSTMs and how they can selectively control
    and regulate the flow of information. Now that you've reviewed LSTMs and their
    architecture, you can put some of these concepts to work by reviewing your code
    and LSTM model.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create an LSTM model in the following manner using a sequential model.
    This LSTM contains four hidden layers, each with `50`, `60`, `80`, and `120` units
    and a ReLU activation function. The `return_sequences` parameter is set to `True`
    for all but the last layer since they are not the final LSTM layer in the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now that you've recalled how to create RNNs with LSTM layers, you'll next learn
    how to apply them to natural language text and generate new text in a sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Extending NLP Sequence Models to Generate Text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**NLP** takes data in the form of natural language that has traditionally been
    very difficult for machines to make sense of and turns it into data that can be
    useful for machine learning applications. This data can take the form of characters,
    words, sentences, or paragraphs. You will be focusing on text generation in this
    section.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a quick review, *preprocessing* generally entails all the steps needed to
    train your model. Some common steps include *data cleaning*, *transformation*,
    and *data reduction*. For NLP, more specifically, the steps could be all or some
    of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset cleaning** encompasses the conversion of the case to lowercase, removing
    punctuation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tokenization** is breaking up a character sequence into specified units called tokens.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Padding** is a way to make input sentences of different sizes the same by
    padding them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Padding the sequences** refers to making sure that the sequences have a uniform
    length.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rainy` and `raining` both have the stem `rain`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's take a closer look at what the process looks like.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset Cleaning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, you create a function, `clean_text`, that returns a list of words after
    cleaning. Now, save all text as lowercase with `lower()` method, encoded with
    `utf8` for character standardization. Finally, output 10 headlines from your corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Cleaning the text in this manner is a great way to standardize text to input
    into a model. Converting all words to lowercase in the same encoding ensures consistency
    of the text. It also ensures that capitalization or different encodings of the
    same words are not treated as different words by any model that is created.
  prefs: []
  type: TYPE_NORMAL
- en: Generating a Sequence and Tokenization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Neural networks expect input data in a consistent, numerical format. Much like
    how images are processed for image classification models, where each image is
    represented as a three-dimensional array, and are often resized to meet the expectations
    of the model, text must be processed similarly. Luckily, Keras has a number of
    utility classes and functions to aid with processing text data for neural networks.
    One such class is `Tokenizer`, which vectorizes a text corpus by converting the
    corpus into a sequence of integers. The following code imports the `Tokenizer`
    class from Keras:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Generating a Sequence of n-gram Tokens
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, you create a function named `get_seq_of_tokens`. With `tokenizer.fit_on_texts`,
    you extract tokens from the corpus. Each integer output corresponds with a specific
    word. The `input_seq` parameter is initialized as an empty list, `[]`. With `token_list
    =` `tokenizer.texts_to_sequences`, you convert text to the tokenized equivalent.
    With `n_gram_sequence` `= token_list`, you generate the n-gram sequences. Using
    `input_seq.append(n_gram_sequence)`, you append each sequence to the list of your
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`get_seq_of_tokens` ensures that a corpus is broken up into sequences of equal
    length. If a corpus is too short for the network''s expected input, the resultant
    sequence will have to be padded.'
  prefs: []
  type: TYPE_NORMAL
- en: Padding Sequences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, you create a `generate_padded_sequences` function that takes `input_seq`
    as input. The `pad_sequences` function is used to pad the sequences to make their
    lengths equal. In the function, first, the maximum sequence length is determined
    by calculating the length of each input sequence. Once the maximum sequence length
    is determined, all other sequences are padded to match. Next, the `predictors`
    and `label` parameters are created. The `label` parameter is the last word of
    the sequence, and the `predictors` parameter is all the preceding words. Finally,
    the `label` parameter is converted to a categorical array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have learned some preprocessing and cleaning steps for working
    with natural language, including cleaning, generating n-gram sequences, and padding
    sequences for consistent lengths, you are ready for your first exercise of the
    chapter, that is, text generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 11.01: Generating Text'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will use the LSTM model from *Exercise 9.02*, *Building
    an RNN with LSTM Layer Nvidia Stock Prediction*, to extend your prediction sequence
    and generate new text. In that exercise, you created an LSTM model to predict
    the stock price of Nvidia by feeding the historical stock prices to the model.
    The model was able to use LSTM layers to understand patterns in the historical
    stock prices for future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you will use the same principle applied to text, by feeding
    the historical headlines to the model. You will use the `articles.csv` dataset
    for this exercise. The dataset contains 831 news headlines from the New York Times
    in CSV format. Along with the headlines, the dataset also contains several attributes
    about the news article, including the publication date, print page, and keywords.
    You are required to generate new news headlines using the given dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find `articles.csv` here: [http://packt.link/RQVoB](http://packt.link/RQVoB).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter or Colab notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the following libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the dataset locally by setting `your_dir` to `content/`. Create a `your_headlines`
    parameter as an empty list and use a `for` loop to iterate over:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will represent the number of headlines in your dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a `clean_text` function to return a list of cleaned words. Convert
    the text to lowercase with `lower()` method and encode it with `utf8` for character
    standardization. Finally, output 20 headlines from your corpus:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.6: Corpus'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.6: Corpus'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With `tokenizer.fit`, extract tokens from the corpus. Each integer output corresponds
    to a specific word. The `input_seq` parameter is initialized as an empty list,
    `[]`. With `token_list =` `tokenizer.texts_to_sequences`, you convert each sentence
    into its tokenized equivalent. With `n_gram_sequence = token_list`, you generate
    the n-gram sequences. Using `input_seq.append(n_gram_sequence)`, you append each
    sequence to a list of features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.7: n-gram tokens'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.7: n-gram tokens'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The output shows the n-gram tokens of the headlines. For each headline, the
    number of n-grams is determined by the length of the headline.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Pad the sequences and obtain the variables, `predictors` and `target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare your model for training. Add an input embedding layer with `model.add(Embedding)`,
    a hidden LSTM layer with `model.add(LSTM(100))`, and a dropout of 10%. Then, add
    the output layer with `model.add(Dense)` using the softmax activation function.
    With `compile()` method, configure your model for training, setting your loss
    function to `categorical_crossentropy`. Use the Adam optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.8: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.8: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fit the model and set `epochs` to `200` and `verbose` to `5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.9: Training the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.9: Training the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a function that will generate a headline given a starting seed text,
    the number of words to generate, the model, and the maximum sequence length. The
    function will include a `for` loop to iterate over the number of words to generate.
    In each iteration, the tokenizer will tokenize the text, and then pad the sequence
    before predicting the next word in the sequence. Next, the iteration will convert
    the token back into a word and add it to the sentence. Once the `for` loop completes,
    the generated headline will be returned:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, output some of your generated text with the `print` function by printing
    the output of the function you created in *Step 9*. Use the `10 ways`, `europe
    looks to`, `best way`, `homeless in`, `unexpected results`, and `critics warn`
    seed words with the corresponding number of words to generate; that is, `11`,
    `8`, `10`, `10`, `10`, and `10`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.10: Generated text'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.10: Generated text'
  prefs: []
  type: TYPE_NORMAL
- en: The output shows the generated headlines with the seed text provided. The words
    generated are limited to what was included in the training dataset, which itself
    was fairly limited in size, leading to some nonsensical results.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you've generated text with an LSTM in your first exercise, let's move
    on to working with images by using GANs to generate new images based on a given dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GANs are networks that generate new, synthetic data by learning patterns and
    underlying representations from a training dataset. The GAN does this by using
    two networks that compete with one another in an adversarial fashion. These networks
    are called the **generator** and **discriminator**.
  prefs: []
  type: TYPE_NORMAL
- en: To see how these networks compete with one another, consider the following example.
    The example will skip over a few details that will make more sense as you get
    to them later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine two entities: a money counterfeiter and a business owner. The counterfeiter
    attempts to make a currency that looks authentic to fool the business owner into
    thinking the currency is legitimate. By contrast, the business owner tries to
    identify any fake bills, so that they don''t end up with just a piece of worthless
    paper instead of real currency.'
  prefs: []
  type: TYPE_NORMAL
- en: This is essentially what GANs do. The counterfeiter in this example is the generator,
    and the business owner is the discriminator. The generator creates an image and
    passes it to the discriminator. The discriminator checks whether the image is
    real or not, and both networks compete against each other, driving improvements
    within one another.
  prefs: []
  type: TYPE_NORMAL
- en: The generator's mission is to create a synthetic sample of data that can fool
    the discriminator. The generator will try to trick the discriminator into thinking
    that the sample is real. The discriminator's mission is to be able to correctly
    classify a synthetic sample created by the generator.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.11: GAN-generated images'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.11: GAN-generated images'
  prefs: []
  type: TYPE_NORMAL
- en: The next sections will look a bit closer at the generator and discriminator
    and how they function individually, before considering both in combination in
    the *The Adversarial Network* section.
  prefs: []
  type: TYPE_NORMAL
- en: The Generator Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed, GANs are utilized for unsupervised learning tasks in machine learning.
    GANs consist of two models (a generator and a discriminator) that automatically
    discover and learn the patterns in input data. The two models compete with one
    another to analyze, capture, and create variations within data. GANs can be used
    to generate new data that looks like it could have come from the original data.
  prefs: []
  type: TYPE_NORMAL
- en: First up is the generator model. How does the generator create synthetic data?
  prefs: []
  type: TYPE_NORMAL
- en: The generator receives input as a *fixed-length random vector* called the **latent
    vector**, which goes into the generator network. This is sometimes referred to
    as the **random noise seed**. A new sample is generated from it. The generated
    instance is then sent to the discriminator for classification. Through random
    noise, the generator learns which outputs were more convincing and continues to
    improve in that direction.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.12: Input and output model in the generator network'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.12: Input and output model in the generator network'
  prefs: []
  type: TYPE_NORMAL
- en: In the following figure, you can see that the discriminator takes input from
    both real data and the generator. The generator neural network attempts to generate
    data that looks real to the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: The generator doesn't get to see what the real data is. The main goal of the
    generator is to convince the discriminator to classify its output as real.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.13: Two sources of data for the discriminator model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.13: Two sources of data for the discriminator model'
  prefs: []
  type: TYPE_NORMAL
- en: 'The GAN includes the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Noisy input vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discriminator network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generator loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backpropagation is used to adjust the weights in the optimal direction by calculating
    a weight's impact on the output. The backpropagation method is used to obtain
    gradients and these gradients can help change the generator weights.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.14: Backpropagation in GAN'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.14: Backpropagation in GAN'
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic procedure of a single generator iteration looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Based on real data from a dataset, *sample random noise* is used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The *generator* produces *output* from the noise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The *discriminator* classifies the output as "*real*" or "*fake*."
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The *loss* from this classification is calculated, followed by *backpropagation
    through the generator* and *discriminator* to obtain the *gradients*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The *gradients* are used to adjust the generator *weights*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, to code the generator, the first step is to define your generator model.
    You begin by creating your generator function with `define_your_gen`. The number
    of outputs of your generator should match the size of the data you are trying
    to synthesize. Therefore, the final layer of your generator should be a dense
    layer with the number of units equal to the expected size of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The model will not compile because it does not directly fit the generator model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code block will look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The generator composes one half of the GAN; the other half is the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: The Discriminator Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A **discriminator** is a neural network model that learns to identify real
    data from the fake data that the generator sends as input. The two sources of
    training data are the authentic data samples and the fake generator samples:'
  prefs: []
  type: TYPE_NORMAL
- en: Real data instances are used by the discriminator as positive samples during
    the training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data instances created by the generator are used as fake examples
    during the training process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 11.15: Inputs for the discriminator network'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.15: Inputs for the discriminator network'
  prefs: []
  type: TYPE_NORMAL
- en: During the discriminator training process, the discriminator is connected to
    the generator and discriminator loss. It requires both real data and synthetic
    data from the generator, but only uses the discriminator loss for weight updates.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.16: Backpropagation with discriminator loss'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.16: Backpropagation with discriminator loss'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's take a look at how the discriminator works with some code.
  prefs: []
  type: TYPE_NORMAL
- en: Your first step is to define your discriminator model with `define_disc()`.
  prefs: []
  type: TYPE_NORMAL
- en: The model takes a vector from your generator and makes a prediction as to whether
    the sample is real or fake. Therefore, you use binary classification.
  prefs: []
  type: TYPE_NORMAL
- en: You're creating a simple GAN, so you will only need one hidden layer. Use `model.add(Dense(25)`
    to create the hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: Again, your activation function will be ReLU with `activation='relu'` and the
    `he_uniform` weight initialization with `kernel_initializer='he_uniform'`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your output layer will only need a single node for binary classification. To
    ensure your output is zero or one, you will use the sigmoid activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The model will attempt to minimize your loss function. Use Adam for your stochastic
    gradient descent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s a look at your discriminator model code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now that you know how to create both models that compose the GAN, you can learn
    how to combine them to create your GAN in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The Adversarial Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GANs consist of two networks, a generator, which is represented as ![16a](img/B16341_11_16a.png),
    and a discriminator, represented as ![16b](img/B16341_11_16b.png). Both networks
    play an adversarial game. The generator network tries to learn the underlying
    distribution of the training data and generates similar samples, while the discriminator
    network tries to catch the fake samples generated by the generator.
  prefs: []
  type: TYPE_NORMAL
- en: The generator network takes a sample and generates a fake sample of data. The
    generator is trained to increase the probability of the discriminator network
    making mistakes. The discriminator network decides whether the data is generated
    or taken from the real sample using binary classification with the help of a sigmoid
    function. The sigmoid function ensures that the output is zero or one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following list represents an overview of a typical GAN at work:'
  prefs: []
  type: TYPE_NORMAL
- en: First, a *noise vector* or the *input vector* is fed to the generator network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The generator creates synthetic data samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Authentic data is passed to the discriminator along with the synthetic data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The discriminator then identifies the data and classifies it as real or fake.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model is trained and the loss backpropagated into both the discriminator
    and generator networks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.17: GAN model with input and output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.17: GAN model with input and output'
  prefs: []
  type: TYPE_NORMAL
- en: 'To code an adversarial network, the following steps are necessary. Each of
    these is described in detail in the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Combine the generator and discriminator models in your GAN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate real samples with class labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create points in latent space to use as input for the generator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the generator to create fake samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the discriminator performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the generator and discriminator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the latent space, generator, discriminator, and GAN, and train the GAN
    on the training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you've explored the inner workings of the generator and discriminator,
    take a look at how you can combine the models to compete with one another.
  prefs: []
  type: TYPE_NORMAL
- en: Combining the Generative and Discriminative Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `define_your_gan()` function creates your combined model.
  prefs: []
  type: TYPE_NORMAL
- en: While creating the combined GAN model, freeze the weights of the discriminator
    model by specifying `discriminator.trainable = False`. This prevents the discriminator
    weights from getting updated while you update the generator weights.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can add both models with `model.add(generator)` and `model.add(discriminator)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, specify `binary_crossentropy` as the loss function and Adam as your optimizer
    while compiling your model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Generating Real Samples with Class Labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now extract real samples from the dataset to inspect fake samples against them.
    You can use the `generate_real()` function defined previously. In the first line
    of the function, `rand(n) – 0.5`, create random numbers on `n` in the range of
    `-0.5` to `0.5`. Use `hstack` to stack your array. Now you can generate class
    labels with `y = ones((n, 1))`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Creating Latent Points for the Generator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next, use the generator model to create fake samples. You need to generate
    the same number of points in the latent space with your `gen_latent_points()`
    function. These latent points will be passed to the generator to create samples.
    This function generates uniformly random samples from NumPy''s `randn` function.
    The number will correspond to the latent dimension multiplied by the number of
    samples to generate. This array of random numbers will then be reshaped to match
    the expected input of the generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Using the Generator to Generate Fake Samples and Class Labels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `gen_fake()` function generates fake samples with a class label of zero.
    This function generates the latent points using the function created in the previous
    step. Then, the generator will generate samples based on the latent points. Finally,
    the class label, `y`,is generated as an array of zeros representing the fact that
    this is synthetic data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the Discriminator Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following `performance_summary()` function is used to plot both real and
    fake data points. The function generates real values and synthetic data and evaluates
    the performance of the discriminator via its accuracy in identifying the synthetic
    images. Then, it finally plots both the real and synthetic images for visual review:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Training the Generator and Discriminator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, train your model with the `train()` function. This function contains a
    `for` loop to iterate through the epochs. At each epoch, real data is sampled
    with a size equal to half the batch, and then synthetic data is generated. Then,
    the discriminator trains on the real, followed by the synthetic, data. Then, the
    GAN model is trained. When the epoch number is a multiple of the input argument,
    `n_eval`, a performance summary is generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Creating the Latent Space, Generator, Discriminator, GAN, and Training Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can combine all the steps to build and train the model. Here, `latent_dim`
    is set to `5`, representing five latent dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In this section, you learned about GANs, different components, the generator
    and discriminator, and how you combine them to create an adversarial network.
    You will now use these concepts to generate sequences with your own GAN.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 11.02: Generating Sequences with GANs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will use a GAN to create a model that generates a quadratic
    function (`y=x`2) for values of `x` between `-0.5` and `0.5`. You will create
    a generator that will simulate the normal distribution and then square the values
    to simulate the quadratic function. You will also create a discriminator that
    will discriminate between a true quadratic function and the output from the generator.
    Next, you will combine them to create your GAN model. Finally, you will train
    your GAN model and evaluate your model, comparing the results from the generator
    against a true quadratic function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter or Colab notebook and import the following libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Define the generator model. Begin by creating your generator function with `define_gen`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use Keras'' `linear` activation function for the last layer of the generator
    network because the output vector should consist of continuous real values as
    a normal distribution does. The first element of the output vector has a range
    of `[-0.5,0.5]`. Since you will only consider values of `x` between these two
    values, the second element has a range of `[0.0,0.25]`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, with `define_disc()`, define your discriminator. The discriminator network
    has a binary output that identifies whether the input is real or fake. For this
    reason, use sigmoid as the activation function and binary cross-entropy as your
    loss.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You''re creating a simple GAN, so use one hidden layer with `25` nodes. Use
    ReLU activation and `he_uniform` weight initialization. Your output layer will
    only need a single node for binary classification. Use Adam as your optimizer.
    The model will attempt to minimize your loss function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, add both models with `model.add(generator)` and `model.add(discriminator)`.
    Then, specify binary cross-entropy as your loss function and Adam as your optimizer,
    while compiling your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract real samples from your dataset to inspect fake samples against them.
    Use the `generate_real()` function defined previously. `rand(n) – 0.5` creates
    random numbers on `n` in the range of `-0.5` to `0.5`. Use `hstack` to stack your
    array. Now, generate class labels with `y = ones((n, 1))`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, set the generator model to create fake samples. Generate the same number
    of points in the latent space with your `gen_latent_points()` function. Then,
    pass them to the generator and use them to create samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the generator to generate fake samples with class labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate the discriminator model. The `performance_summary()` function will
    plot both real and fake data points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, train your model with the `train()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a parameter for the latent dimension and set it equal to `5`. Then,
    create a generator, discriminator, and GAN using the respective functions. Train
    the generator, discriminator, and GAN models using the `train` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.18: Distribution of real and fake data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.18: Distribution of real and fake data'
  prefs: []
  type: TYPE_NORMAL
- en: The output shows the generator progressively improving by generating points
    that more closely resemble a quadratic function. In early epochs, the points generated
    by the generator, indicated by the blue dots, show little similarity to the true
    quadratic function, indicated by the red dots. However, by the final epoch, the
    points generated by the generator almost lie on top of the true points, demonstrating
    that the generator has almost captured the true underlying function – the quadratic.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you utilized the different components of a generative model
    to create data that fits a quadratic function. As you can see in *Figure 11.18*,
    by the final epoch, the fake data resembles the real data, showing that the generator
    can capture the quadratic function well.
  prefs: []
  type: TYPE_NORMAL
- en: Now it's time for the final section of the book, on DCGANs, where you'll be
    creating your own images.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Convolutional Generative Adversarial Networks (DCGANs)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DCGANs use convolutional neural networks instead of simple neural networks for
    both the discriminator and the generator. They can generate higher-quality images
    and are commonly used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: The generator is a set of convolutional layers with fractional stride convolutions,
    also known as transpose convolutions. Layers with transpose convolutions upsample
    the input image at every convolutional layer, which increases the spatial dimensions
    of the images after each layer.
  prefs: []
  type: TYPE_NORMAL
- en: The discriminator is a set of convolutional layers with stride convolutions,
    so it downsamples the input image at every convolutional layer, decreasing the
    spatial dimensions of the images after each layer.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following two images. Can you identify which one is fake and which
    one is real? Take a moment and look carefully at each of them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.19: Face example'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.19: Face example'
  prefs: []
  type: TYPE_NORMAL
- en: You may be surprised to find out that neither of the images shown is of real
    people. These images were created using images of real people, but they are not
    of real people. They were created by two competing neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you know, a GAN is composed of two different neural networks: the discriminator
    and the generator. What looks different right away is that each of these networks
    has different inputs and outputs. This is key to understanding how GANs can do
    what they do.'
  prefs: []
  type: TYPE_NORMAL
- en: For the discriminator, the input is an image—a 3D tensor (height, width, color).
    The output is a single number that is used to make the classification. In *Figure
    11.20*, you can see `[0.95]`. It implies there is a 95% chance that the tomato
    image is real.
  prefs: []
  type: TYPE_NORMAL
- en: For the generator, the input is a generated random seed vector of numbers. The
    output is an image.
  prefs: []
  type: TYPE_NORMAL
- en: The generator network learns to generate images similar to the ones in the dataset,
    while the discriminator learns to discriminate the original images from the generated
    ones. In this competitive fashion, they learn to generate realistic images like
    the ones in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.20: Discriminator and generator networks'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.20: Discriminator and generator networks'
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at how the generator trains. One of the key points to take
    away from *Figure 11.20* is that the generator network has *weights static*, while
    the discriminator network shows *weights trained*. This is important because this
    enables you to differentiate how the GAN loss function changes from updates to
    the weights on the generator and discriminator independently.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `X` (the random seed) is fed into the model to produce `y`. Your model
    outputs what you predict.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.21: How the generator is trained'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.21: How the generator is trained'
  prefs: []
  type: TYPE_NORMAL
- en: Another important point to keep in mind is that the generator trains without
    ever seeing any of the real data. The generator's only goal is to fool the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: Now, consider the training process of the discriminator network. The discriminator
    is trained on a training dataset consisting of an equal number of real and fake
    (generated) images. The real images are sampled randomly from the original dataset
    and are labeled as one. An equal number of fake images is generated using the
    generator network and are labeled as zero.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.22: How the discriminator is trained'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.22: How the discriminator is trained'
  prefs: []
  type: TYPE_NORMAL
- en: The core differences between the original "vanilla" GAN and DCGAN correspond
    to the differences in the architecture. Pooling layers of the vanilla GAN are
    replaced with transposed convolutions in the generator and stride convolutions
    in the discriminator of the DCGAN. The generator and discriminator of DCGANs both
    use batch normalization layers, except for the generator output layer and the
    discriminator input layer. Also, the fully connected hidden layers of DCGANs are
    removed. Finally, the activation functions in DCGANs are generally different to
    reflect the use of convolutional layers. In the generator, ReLU is used for all
    layers except for the output layer, where tanh is used, and for the discriminator,
    Leaky ReLU is used for all layers.
  prefs: []
  type: TYPE_NORMAL
- en: Training a DCGAN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start, you're going to set all the constants that will define your DCGAN.
  prefs: []
  type: TYPE_NORMAL
- en: The resolution of the images that you want to generate is specified by the `gen_res`
    parameter. The final resolution will be `32*gen_res` for the height and width
    of the image. You will use `gen_res = 3`, which results in an image resolution
    of `96x96`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Image channels, `img_chan`, are simply how many numbers per pixel the image
    has. For color, you need a pixel value for each of the three color channels: `3`.'
  prefs: []
  type: TYPE_NORMAL
- en: Your preview image rows and columns (`img_rows` and `img_cols`) will be how
    many images you want to display in a row and a column. For example, if you were
    to choose a preview image row of `4`, and a preview column value of `4`, you would
    get a total of 16 images displayed.
  prefs: []
  type: TYPE_NORMAL
- en: '`data_path` is where your data is stored on your computer. This provides the
    path needed for the code to access and store data.'
  prefs: []
  type: TYPE_NORMAL
- en: '`epoch` is the number of passes when training the data.'
  prefs: []
  type: TYPE_NORMAL
- en: Batch size, `num_batch`, is the number of training samples per iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Buffer size, `num_buffer`, is the random shuffle that is used. You will simply
    set this to your dataset size.
  prefs: []
  type: TYPE_NORMAL
- en: Seed vector, `seed_vector`, is the size of the vector of seeds that will be
    used to generate images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following sample to see how to initialize all the constants that
    define your DCGAN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can build the generator and the discriminator. Start by defining your
    generator function with `def create_generator`, using `seed_size` and `channels`
    as arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Now, you will create the generated image that is going to come from an *input
    seed*; different seed numbers will generate different images and your seed size
    will determine how many different images are generated.
  prefs: []
  type: TYPE_NORMAL
- en: Next, add a dense layer with `4*4*256` as the dimensionality of your output
    space, and use the ReLU activation function. `input_dim` is an input shape, which
    you will have equal to `seed_size`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following code to add a layer that reshapes your inputs to match your
    output space of `4*4*256`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Your `UpSampling2D` layer is a simple layer that doubles the dimensions of
    input. It must be followed by a convolutional layer (`Conv2D`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Add your `Conv2D` layer with `256` as your input. You can choose `kernel_size=3`
    for your `3x3` convolution filter. With `padding="same"`, you can ensure that
    the layer''s outputs will have the same spatial dimensions as its inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Use batch normalization to normalize your individual layers and help prevent
    gradient problems. Momentum can be anywhere in the range of `0.0` to `0.99`. Here,
    use `momentum=0.8`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'On your final CNN layer, you will use the tanh activation function to ensure
    that your output images are in the range `-1` to `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete code block should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can define your discriminator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, use a `Conv2D` layer. You can choose `kernel_size=3` for your `3x3` convolution
    filter. With `strides=2`, you specify how many strides are for your "sliding window."
    Set `input_shape=image_shape` to ensure they match, and again, with `padding="same"`,
    you ensure that the layer''s outputs will have the same spatial dimensions as
    its inputs. Add a LeakyReLU activation function after the `Conv2D` layer for all
    discriminator layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Flatten` layer converts your data into a single feature vector for input
    into your last layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'For your activation function, use sigmoid for binary classification output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete code block should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Next, create your loss functions. Since the outputs of the discriminator and
    generator networks are different, you need to define two separate loss functions
    for them. Moreover, they need to be trained separately in independent passes through
    the networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This
    calculates the loss between true and predicted labels. Then, define the `discrim_loss`
    function from your `real_output` and `fake_output` parameters using `tf.ones`
    and `tf.zeros` to calculate `total_loss`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The Adam optimizer is used for the generator and discriminator, with the same
    learning rate and momentum:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Here, you have your individual training step. It's very important that you only
    modify one network's weights at a time. With `tf.GradientTape()`, you can train
    the discriminator and generator at the same time, but separately from one another.
    This is how TensorFlow does automatic differentiation. It calculates the derivatives.
    You'll see that it creates two "tapes" – `gen_tape` and `disc_tape`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, create `real_output` and `fake_output` for the discriminator. Use this
    for the generator loss (`g_loss`). Now, you can calculate the discriminator loss
    (`d_loss`), calculate the gradients of both the generator and discriminator with
    `gradients_of_generator` and `gradients_of_discriminator`, and apply them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a number of fixed seeds with `fixed_seeds`, a seed for each image
    displayed, and for each seed vector. This is done so you can track the same images,
    observing the changes over time. With `for epoch in range`, you are tracking your
    time. Loop through each batch with `for image_batch in dataset`. Now, continue
    to track your loss for both the generator and discriminator with `generator_loss`
    and `discriminator_loss`. Now you have a nice display of all this information
    as it trains:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: In this last section, you took an additional step in using generative networks.
    You learned how to train a DCGAN and how to utilize the generator and discriminator
    together to create your very own images.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, you will implement what you have learned so far in this
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 11.03: Generating Images with DCGAN'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will generate your own images from scratch using a DCGAN.
    You will build your DCGAN with a generator and discriminator that both have convolutional
    layers. Then, you will train your DCGAN on images of a tomato, and throughout
    the training process, you will output generated images from the generator to track
    the performance of the generator.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find `tomato-or-apple` dataset here: [https://packt.link/6Z8vW](https://packt.link/6Z8vW).'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, it is recommended that you use Google Colab:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load Google Colab and Google Drive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the relevant libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Format a time string to track your time usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Set the generation resolution to `3`. Also, set `img_rows` and `img_cols` to
    `5` and `img_margin` to `16` so that your preview images will be a `5x5` array
    (25 images) with a 16-pixel margin.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set `seed_vector` equal to `200`. Set `data_path` to where you stored your image
    dataset. As you can see, you are using Google Drive here. If you don't know your
    data path, you can simply locate where your files are, right-click, and select
    `Copy Path`. Set your epochs to `1000`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, print the parameters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.23: Output showing parameters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.23: Output showing parameters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load and preprocess the images. Here, you will save a NumPy preprocessed file.
    Load the previous training NumPy file. The name of the binary file of the images
    has the dimensions of the images encoded in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Batch and shuffle the data. Use the `tensorflow.data.Dataset` object library
    to use its functions to shuffle the dataset and create batches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the generator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the discriminator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'During the training process, display generated images to get some insight into
    the progress that''s been made. Save the images. At regular intervals of 100 epochs,
    save a grid of images to evaluate the progress:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a generator that generates noise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.24: Output showing noise'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.24: Output showing noise'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View one of the images generated by typing in the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create your loss functions. Since the outputs of the discriminator and generator
    networks are different, you need to define two separate loss functions for them.
    Moreover, they need to be trained separately in independent passes through the
    networks. Use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This calculates
    the loss between true and predicted labels. Then, define the `discrim_loss` function
    from `real_output` and `fake_output` using `tf.ones` and `tf.zeros` to calculate
    `total_loss`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two Adam optimizers (one for the generator and one for the discriminator),
    using the same learning rate and momentum for each:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a function to implement an individual training step. With `tf.GradientTape()`,
    train the discriminator and generator at the same time, but separately from one
    another.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, create `real_output` and `fake_output` for the discriminator. Use this for
    the generator loss (`g_loss`). Then, calculate the discriminator loss (`d_loss`)
    and calculate the gradients of both the generator and discriminator with `gradients_of_generator`
    and `gradients_of_discriminator`, and apply them:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an array number of fixed seeds with `fixed_seeds` equal to the number
    of images displayed along one dimension and the seed vector along the other dimension
    so that you can track the same images. This allows you to see how individual seeds
    evolve over time. Loop through each batch with `for image_batch in dataset`. Continue
    to track your loss for both the generator and discriminator with `generator_loss`
    and `discriminator_loss`. You get a nice display of all this information as it trains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train on your training dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.25: Training output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.25: Training output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Take a closer look at the generated images, `train-0`, `train-100`, `train-250`,
    `train-500`, and `train-999`. These images were automatically saved during the
    training process, as specified in the `train` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.26: Output images after first epoch completed'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.26: Output images after first epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.27: Output images after 101st epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.27: Output images after 101st epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.28: Output images after 501st epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.28: Output images after 501st epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.29: Output images after 1,000th epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_11_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.29: Output images after 1,000th epoch completed'
  prefs: []
  type: TYPE_NORMAL
- en: The output shows that after 1,000 epochs, the images of the synthetic tomatoes
    generated by the generator look very similar to real tomatoes and the images improve
    during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you created your own images with a DCGAN. As you can see from
    *Figure 11.29*, the results are impressive. While some of the images are easy
    to determine as fake, others look very real.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will complete a final activity to put all that you've
    learned in this chapter to work and generate your own images with a GAN.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 11.01: Generating Images Using GANs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, you will build a GAN to generate new images. You will then
    compare the results between a DCGAN and a vanilla GAN by creating one of each
    and training them on the same dataset for the same 500 epochs. This activity will
    demonstrate the difference that model architecture can have on the output and
    show why having an appropriate model is so important. You will use the `banana-or-orange`
    dataset. You'll only be using the banana training set images to train and generate
    new images.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find `banana-or-orange` dataset here: [https://packt.link/z6TCy](https://packt.link/z6TCy).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Load Google Colab and Google Drive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the relevant libraries, including `tensorflow`, `numpy`, `zipfile`, `tqdm`,
    `zipfile`, `skimage`, `time`, and `os`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a function to format a time string to track your time usage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the generation resolution to `3`. Also, set `img_rows` and `img_cols` to
    `5` and `img_margin` to `16` so that your preview images will be a `5x5` array
    (25 images) with a 16-pixel margin. Set `seed_vector` equal to `200`, `data_path`
    to where you stored your image dataset, and `epochs` to `500`. Finally, print
    the parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a NumPy preprocessed file exists from prior execution, then load it into
    memory; otherwise, preprocess the data and save the image binary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Batch and shuffle the data. Use the `tensorflow.data.Dataset` object library
    to use its functions to shuffle the dataset and create batches.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the generator for the DCGAN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the discriminator for the DCGAN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the generator for the vanilla GAN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the discriminator for the vanilla GAN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to generate and save images that can be used to view progress
    during the model's training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, initialize the generator for the DCGAN and view the output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the generator for the vanilla GAN and view the output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the decision of the DCGAN discriminator evaluated on the seed image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the decision of the vanilla GAN discriminator evaluated on the seed image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create your loss functions. Since the output of both the discriminator and generator
    networks is different, you can define two separate loss functions for them. Moreover,
    they need to be trained separately in independent passes through the networks.
    Both GANs can utilize the same loss functions for their discriminators and generators.
    You can use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This calculates
    the loss between true and predicted labels. Then, define the `discrim_loss` function
    from `real_output` and `fake_output` using `tf.ones` and `tf.zeros` to calculate
    `total_loss`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create two Adam optimizers, one for the generator and one for the discriminator.
    Use the same learning rate and momentum for each.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create `real_output` and `fake_output` for the discriminator. Use this for the
    generator loss (`g_loss`). Then, calculate the discriminator loss (`d_loss`) and
    the gradients of both the generator and discriminator with `gradients_of_generator`
    and `gradients_of_discriminator` and apply them. Encapsulate these steps within
    a function, passing in the generator, discriminator, and images and returning
    the generator loss (`g_loss`) and discriminator loss (`d_loss`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, create a number of fixed seeds with `fixed_seeds` equal to the number
    of images to display so that you can track the same images. This allows you to
    see how individual seeds evolve over time, tracking your time with `for epoch
    in range`. Now, loop through each batch with `for image_batch in dataset`. Continue
    to track your loss for both the generator and discriminator with `generator_loss`
    and `discriminator_loss`. Now, you have a nice display of all this information
    as it trains.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the DCGAN model on your training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the vanilla model on your training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: View your images generated by the DCGAN model after the 100th epoch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: View your images generated by the DCGAN model after the 500th epoch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: View your images generated by the vanilla GAN model after the 100th epoch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: View your images generated by the vanilla GAN model after the 500th epoch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor285).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about a very exciting class of machine learning
    models called generative models. You discovered the amazing potential of this
    new and continually developing field in machine learning by using a generative
    LSTM on a language modeling challenge to generate textual output.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you learned about generative adversarial models. You implemented a GAN
    to generate data for a normal distribution of points. You also went even further
    into deep convolutional neural networks (DCGANS), discovering how to use one of
    the most powerful applications of GANs while creating new images of tomatoes and
    bananas that exhibited human-recognizable characteristics of the fruits on which
    they were trained.
  prefs: []
  type: TYPE_NORMAL
- en: We hope you enjoyed the final chapter of *The TensorFlow Workshop* and the book
    as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look back at the amazing journey that you have completed. First,
    you started by learning the basics of TensorFlow and how to perform operations
    on the building blocks of ANNs—tensors. Then, you learned how to load and preprocess
    a variety of data types in TensorFlow, including tabular data, images, audio files,
    and text.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you learned about a variety of resources that can be used in conjunction
    with TensorFlow to aid in your development, including TensorBoard for visualizing
    important components of your model, TensorFlow Hub for accessing pre-trained models,
    and Google Colab for building and training models in a managed environment. Then,
    you dived into building sequential models to solve regression and classification.
  prefs: []
  type: TYPE_NORMAL
- en: To improve model performance, you then learned about regularization and hyperparameter
    tuning, which are used to ensure that your models perform well not only on the
    data they are trained upon, but also on new, unseen data. From there, you explored
    convolutional neural networks, which are an excellent choice when working with
    image data. After that, you learned in-depth how to utilize pre-trained networks
    to solve your own problems and fine-tune them to your own data. Then, you learned
    how to build and train RNNs, which are best used when working with sequential
    data, such as stock prices or even natural language. In the later part of the
    book, you explored more advanced TensorFlow capabilities using the Functional
    API and how to develop anything you might need in TensorFlow, before finally learning
    how to use TensorFlow for more creative endeavors via generative models.
  prefs: []
  type: TYPE_NORMAL
- en: With this book, you have not only taken your first steps in TensorFlow, but
    also now learned how to create models and provide solutions to complex problems.
    It's been an exciting journey from beginning to end, and we wish you luck in your
    continuing progress.
  prefs: []
  type: TYPE_NORMAL
