- en: Appendix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1\. Introduction to Machine Learning with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 1.01: Performing Tensor Addition in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two tensors with a rank `0` using TensorFlow''s `Variable` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new variable to add the two scalars created and print the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This output shows the total revenue for `Product A` at `Location X`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create two tensors, a scalar of rank `0` and a vector of rank `1`, using TensorFlow''s
    `Variable` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new variable as the sum of the scalar and vector created and print
    the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result is the new sales goal for `Salesperson 1` at `Location X`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now create three tensors with a rank of 2, representing the revenue for each
    product, salesperson, and location, using TensorFlow''s `Variable` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new variable as the sum of the three tensors created and print the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.42: The output of the matrix summation as a NumPy variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.42: The output of the matrix summation as a NumPy variable'
  prefs: []
  type: TYPE_NORMAL
- en: The result represents the total revenue for each product at each location.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you performed addition on tensors with ranks `0`, `1`, and
    `2`, and showed that scalars (tensors of rank 0) can be added to tensors of other
    ranks, known as scalar addition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.02: Performing Tensor Reshaping and Transposition in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a one-dimensional array with 24 elements using TensorFlow''s `Variable`
    class. Verify the shape of the matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the matrix so that it has 12 rows and 2 columns using TensorFlow''s
    `reshape` function. Verify the shape of the new matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Reshape the matrix so that it has a shape of `3x4x2` using TensorFlow''s `reshape`
    function. Verify the shape of the new matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify that the rank of this new tensor is of rank `3` by using TensorFlow''s
    `rank` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Transpose the tensor created in *step 3*. Verify the shape of the new tensor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this activity, you have practiced performing tensor reshaping and transposition
    on tensors of various ranks and learned how to change the rank of a tensor by
    reshaping it. You simulated the grouping of 24 school children into class projects
    of varying sizes using TensorFlow's `reshape` and `transpose` functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.03: Applying Activation Functions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `3x4` tensor as an input in which the rows represent the sales from
    various sales representatives, the columns represent various vehicles available
    at the dealership, and values represent the average percentage difference from
    the MSRP. The values can be positive or negative depending on whether the salesperson
    was able to sell for more or less than the MSRP:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `4x1` `weights` tensor with a shape of `4x1` representing the MSRP
    of the cars:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a bias tensor of size `3x1` representing the fixed costs associated
    with each salesperson:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Matrix multiply the input by the weight to show the average deviation from
    the MSRP on all cars and add the bias to subtract the fixed costs of the salesperson:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.43: The output of the matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.43: The output of the matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Apply a ReLU activation function to highlight the net-positive salespeople:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.44: The output after applying the activation function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.44: The output after applying the activation function'
  prefs: []
  type: TYPE_NORMAL
- en: This result shows the result of salespeople that had net-positive sales; those
    with net-negative sales are zeroed.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you performed tensor multiplication on tensors of various
    sizes, tensor addition, and also applied an activation function. You began by
    defining the tensors, followed by matrix multiplying two of them, then adding
    a bias tensor, and finally applying an activation function to the result.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Loading and Processing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 2.01: Loading Tabular Data and Rescaling Numerical Fields with a MinMax
    Scaler'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook to implement this activity. Save the file as `Activity2-01.ipnyb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a new Jupyter Notebook cell, import the pandas library, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new pandas DataFrame named `df` and read the `Bias_correction_ucl.csv`
    file into it. Examine whether your data is properly loaded by printing the resultant
    DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure you change the path (highlighted) to the CSV file based on its location
    on your system. If you're running the Jupyter notebook from the same directory
    where the CSV file is stored, you can run the preceding code without any modification.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Drop the `date` column using the `drop` method. Since you''re dropping the
    columns, pass `1` to the `axis` argument and `True` to the `inplace` argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot a histogram of the `Present_Tmax` column that represents the maximum temperature
    across dates and weather stations across the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.20: A Temperature versus Frequency histogram of the Present_Tmax
    column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_02_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.20: A Temperature versus Frequency histogram of the Present_Tmax column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The resultant histogram shows the distribution of values for the `Present_Tmax`
    column.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import `MinMaxScaler` and use it to fit and transform the feature DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot a histogram of the transformed `Present_Tmax` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.21: A histogram of the rescaled Present_Tmax column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_02_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.21: A histogram of the rescaled Present_Tmax column'
  prefs: []
  type: TYPE_NORMAL
- en: The resultant histogram shows that the temperature values range from `0` to
    `1`, as evidenced by the range on the *x* axis of the histogram. By using `MinMaxScaler`,
    the values will always have a minimum value of `0` and a maximum value of `1`.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you have performed some further preprocessing of the numerical
    fields. Here, you scaled the numerical fields so that they have a minimum value
    of `0` and a maximum value of `1`. This could be beneficial over the standard
    scaler if the numerical fields are not normally distributed. It also ensures the
    resulting fields are bound between a minimum and maximum value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.02: Loading Image Data for Batch Processing'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook to implement this activity. Save the file as `Activity2-02.ipnyb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a new Jupyter Notebook cell, import the `ImageDataGenerator` class from
    Keras'' preprocessing package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the `ImageDataGenerator` class and pass the `rescale` argument
    with a value of `1/255` to convert image values so that they''re between `0` and
    `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the data generator''s `flow_from_directory` method to direct the data generator
    to the image data. Pass in the arguments of the target size, the batch size, and
    the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function to display the images in the batch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Take a batch from the data generator and pass it to the function to display
    the images and their labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.22: Augmented images from a batch'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_02_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.22: Augmented images from a batch'
  prefs: []
  type: TYPE_NORMAL
- en: he output shows a batch of 25 images and their respective labels that have been
    augmented by rotation, zooming, and shearing. The augmented images show the same
    objects but with different pixel values, which helps create more robust models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 2.03: Loading Audio Data for Batch Processing'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook to implement this activity. Save the file as `Activity2-03.ipnyb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a new Jupyter Notebook cell, import the TensorFlow and `os` libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function that will load and then return an audio file using TensorFlow''s
    `read_file` function followed by the `decode_wav` function, respectively. Return
    the transpose of the resultant tensor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load in the paths to the audio data as a list using `os.list_dir`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function that will take a dataset object, shuffle it, and load the
    audio using the function you created in *Step 2*. Then, apply the absolute value
    and the `log1p` function to the dataset. This function adds `1` to each value
    then takes the logarithm. Next, repeat the dataset object, batch it, and prefetch
    it with a buffer size equal to the batch size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a dataset object using TensorFlow''s `from_tensor_slices` function and
    pass in the paths to the audio files. Then, apply the function you created in
    *Step 5* to the dataset object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Take the first batch of the dataset and print it out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.23: A batch of the audio data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_02_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.23: A batch of the audio data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The output shows the first batch of MFCC spectrum values in tensor form.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot the first audio file from the batch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will look as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.24: A visual representation of the batch of the preprocessed audio
    data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_02_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.24: A visual representation of the batch of the preprocessed audio
    data'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding plot shows the preprocessed audio data. You can see that the values
    are non-negative, with a minimum value of `0`, and that the data is logarithmically
    scaled.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. TensorFlow Development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 3.01: Using TensorBoard to Visualize Tensor Transformations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library and set a seed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the log directory and initialize a file writer object to write the trace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a TensorFlow function to multiply two tensors and add a value of `1`
    to all elements in the resulting tensor using the `ones_like` function to create
    a tensor of the same shape as the result of the matrix multiplication. Then, apply
    a sigmoid function to each value of the tensor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two tensors with the shape `5x5x5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Turn on graph tracing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the function to the two tensors and export the trace to the log directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Launch TensorBoard in the command line and view the graph in a browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get something like the following image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.19: A visual representation of tensor transformation in TensorBoard'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_03_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.19: A visual representation of tensor transformation in TensorBoard'
  prefs: []
  type: TYPE_NORMAL
- en: The result represents the graph created for the tensor transformation. You can
    see in the bottom left at the beginning of the graph that a matrix multiplication
    is performed on the tensors named `x` and `y` on the node named `MatMul`. In the
    bottom right is the creation of the tensor using the `ones_like` function. The
    input nodes represent the shape of the tensor and the value, which is a constant
    value. Upon the creation of the two tensors, they are input into a node representing
    the addition function, after which the output is input to a node representing
    the application of the sigmoid function. The final nodes represent the creation
    of the output tensor.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you created functions for tensor transformation, and then
    presented a visual representation of the transformation in TensorBoard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 3.02: Performing Word Embedding from a Pre-Trained Model from TensorFlow
    Hub'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import TensorFlow and TensorFlow Hub and print the version of the library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should get the versions of TensorFlow and TensorFlow Hub.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.20: The output of the versions of TensorFlow and TensorFlow Hub
    in Google Colab'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_03_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.20: The output of the versions of TensorFlow and TensorFlow Hub in
    Google Colab'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set the handle for the module for the universal sentence encoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the TensorFlow Hub `KerasLayer` class to create a hub layer, passing in
    the following arguments: `module_handle`, `input_shape`, and `dtype`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a list containing a string to encode with the encoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply `hub_layer` to the text to embed the sentence as a vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.21: The output of the embedding vector'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_03_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.21: The output of the embedding vector'
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see that the text has been converted to a 512-dimensional embedding
    vector. The embedding vector is a one-dimensional tensor that maps the text into
    a vector of continuous variables as shown in the preceding figure.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you used the Google Colab environment to download a model
    from TensorFlow Hub. You used a universal sentence encoder to embed a sentence
    into a 512-dimensional vector. This activity has shown that with a few short lines
    of code on powerful remote servers, you can access state-of-the-art machine learning
    models for any application.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Regression and Classification Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 4.01: Creating a Multi-Layer ANN with TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook to implement this activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow and pandas libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load in the dataset using the pandas `read_csv` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure you change the path (highlighted) to the CSV file based on its location
    on your system. If you're running the Jupyter notebook from the same directory
    where the CSV file is stored, you can run the preceding code without any modification.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Drop the `date` column and drop any rows that have null values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create target and feature datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Rescale the feature dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize a Keras model of the `Sequential` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an input layer to the model using the model''s `add` method, and set `input_shape`
    to be the number of columns in the feature dataset. Add four hidden layers of
    sizes `64`, `32`, `16`, and `8` to the model with the first having a ReLU activation
    function, then add an output layer with one unit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model with an RMSprop optimizer with a learning rate equal to `0.001`
    and the mean squared error for the loss:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a TensorBoard callback:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model to the training data for `100` epochs, with a batch size equal
    to `32` and a validation split equal to 20%:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.16: The output of the fitting process showing the epoch,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: training time per sample, and loss after each epoch
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_04_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.16: The output of the fitting process showing the epoch, training
    time per sample, and loss after each epoch'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Evaluate the model on the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the model architecture and model-fitting process in TensorBoard by
    calling the following on the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The model architecture should look like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.17: A visual representation of the model architecture in TensorBoard'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_04_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.17: A visual representation of the model architecture in TensorBoard'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Visualize the model-fitting process in TensorBoard. You should get the following output:![Figure
    4.18: A visual representation of the loss as a function of an epoch'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: on the training and validation split in TensorBoard
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_04_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.18: A visual representation of the loss as a function of an epoch
    on the training and validation split in TensorBoard'
  prefs: []
  type: TYPE_NORMAL
- en: During the model-fitting process, the loss on the training and validation sets
    is calculated after each epoch and displayed in TensorBoard in the `SCALARS` tab.
    From TensorBoard, you can see that the mean squared error reduces after each epoch
    consistently on the training set but plateaus on the validation set.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you have further practiced building models in TensorFlow and
    viewing its architecture and training process in TensorBoard. During this section,
    you have learned how to build, train, and evaluate ANNs using TensorFlow for regression
    tasks. You used Keras layers of the `Dense` class as an easy way to create fully
    connected layers that include activation functions on the output of the layers.
    The layers can be created simply by passing in the number of units desired in
    the layer. Keras configures the initialization of the weights and biases, as well
    as any other additional parameters that are common in a machine learning workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4.02: Creating a Multi-Layer Classification ANN with TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook to implement this activity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow and pandas libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load in the dataset using the pandas `read_csv` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure you change the path (highlighted) to the CSV file based on its location
    on your system. If you're running the Jupyter notebook from the same directory
    where the CSV file is stored, you can run the preceding code without any modification.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Drop any rows that have null values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the target values to `true` when values of the `critical_temp` column are
    above `77.36` and `false` when below. The feature dataset is the remaining columns
    in the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Rescale the feature dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize a Keras model of the `Sequential` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add an input layer to the model using the model''s `add` method and set `input_shape`
    to the number of columns in the feature dataset. Add three hidden layers of sizes
    `32`, `16`, and `8` to the model, then add an output layer with `1` unit and a
    sigmoid activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model with an RMSprop optimizer with a learning rate equal to `0.0001`
    and binary cross-entropy for the loss and compute the accuracy metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a TensorBoard callback:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model to the training data for `50` epochs and a validation split equal
    to 20%:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.19: The output of the fitting process showing the epoch, training
    time per sample, loss, and accuracy after each epoch, and evaluated on the validation
    split'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_04_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.19: The output of the fitting process showing the epoch, training
    time per sample, loss, and accuracy after each epoch, and evaluated on the validation
    split'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Evaluate the model on the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will display the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the model architecture and model-fitting process in TensorBoard by
    calling the following on the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get a screen similar to the following in the browser:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.20: A visual representation of the model architecture in TensorBoard'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_04_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.20: A visual representation of the model architecture in TensorBoard'
  prefs: []
  type: TYPE_NORMAL
- en: 'The loss function can be visualized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.21: A visual representation of the accuracy and loss as a function
    of an epoch on the training and validation split in TensorBoard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_04_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.21: A visual representation of the accuracy and loss as a function
    of an epoch on the training and validation split in TensorBoard'
  prefs: []
  type: TYPE_NORMAL
- en: During the model-fitting process, the accuracy and loss on the training and
    validation sets are calculated after each epoch and displayed in TensorBoard in
    the `SCALARS` tab. From TensorBoard, you can see that the loss metric (binary
    cross-entropy) reduces after each epoch consistently on the training set but plateaus
    on the validation set.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you have practiced building classification models in TensorFlow
    by building a multi-layer ANN to determine whether a material will exhibit superconductivity
    above or below the boiling point of nitrogen. Moreover, you used TensorBoard to
    view the models' architecture and monitor key metrics during the training process,
    including the loss and the accuracy of the models.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Classification Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 5.01: Building a Character Recognition Model with TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution**:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the pandas library and use `pd` as the alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Load the dataset into a `DataFrame()` function called `data` using `read_csv()`
    method, provide the URL to the CSV file, and set `header=None` as the dataset
    doesn't provide column names. Print the first five rows using `head()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.42: First five rows of the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.42: First five rows of the data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can see that the dataset contains `17` columns and they are all numeric.
    Column `0` is the `target` variable, and each value corresponds to a letter of
    the alphabet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the target variable (column `0`) using the `pop()` method and save
    it in a variable called `target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Split `data` into a training set by keeping the first 15,000 observations and
    save it in a variable called `X_train`. Perform the same split on `target` and
    save the first 15,000 cases in a variable called `y_train`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Split `data` into a test set by keeping the last 5,000 observations and save
    it in a variable called `X_test`. Perform the same split on `target` and save
    the last 5,000 cases in a variable called `y_test`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the TensorFlow library and use `tf` as the alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the seed as `8` using `tf.random.set_seed()` to get reproducible results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a sequential model using `tf.keras.Sequential()` and store it in
    a variable called `model`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `Dense()` class from `tensorflow.keras.layers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function and the input shape as `(16,)`, which corresponds to
    the number of features from the dataset. Save it in a variable called `fc1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `26` units with `Dense()` and specify softmax
    as the activation function. Save it in a variable called `fc5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Sequentially add all five fully connected layers to the model using `add()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Print the summary of the model using `summary()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.43: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.43: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding output shows that there are five layers in your model (as expected)
    and also tells you the number of parameters at each layer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Instantiate `SparseCategoricalCrossentropy()` from `tf.keras.losses` and save
    it in a variable called `loss`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate `Adam()` from `tf.keras.optimizers` with `0.001` as the learning
    rate and save it in a variable called `optimizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model using `compile()` method, specify the optimizer and loss
    parameters you just created, and use accuracy as the metric to be reported:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the model training process using `fit()` method on the training set for
    five epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.44: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.44: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding output shows the logs of each epoch during the training of the
    model. Note that it took around 2 seconds to process a single epoch, and the accuracy
    score increased from `0.6229` (first epoch) to `0.9011` (fifth epoch).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Evaluate the performance of the model on the test set using `evaluate()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.45: Performance of the model on the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_45.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.45: Performance of the model on the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Predict the probabilities for each class on the test set using `predict()`
    method. Save it in a variable called `preds_proba`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the class probabilities into a single predicted value using `argmax()`
    method with `axis=1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `confusion_matrix` from `tensorflow.math`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the confusion matrix on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.46: Confusion matrix of the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_39.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.46: Confusion matrix of the test set'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding output shows the model is correctly predicting the 26 letters
    of the alphabet most of the time (most of the values are located on the diagonal).
    It achieved an accuracy score of around 0.89 for both the training and test sets.
    This activity concludes the section on multi-class classification. In the section
    ahead, you will look at another type of classification called multi-label.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 5.02: Building a Movie Genre Tagging a Model with TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the pandas library and use `pd` as the alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `feature_url` that contains the URL to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the dataset into a DataFrame called `feature` using `read_csv()` method
    and provide the URL to the CSV file. Print the first five rows using the `head()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.47: The first five rows of the features'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_47.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.47: The first five rows of the features'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a variable called `target_url` that contains the URL to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the dataset into a DataFrame called `target` using `read_csv()` method
    and provide the URL to the CSV file. Print the first five rows using the `head()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.48: The first five rows of the targets'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_48.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.48: The first five rows of the targets'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Split the data into a training set by keeping the first 15,000 observations
    and save it in a variable called `X_train`. Perform the same split on `target`
    and save the first 15,000 cases in a variable called `y_train`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Split the data into a test set by keeping the last 5,000 observations and save
    it in a variable called `X_test`. Perform the same split on `target` and save
    the last 5,000 cases in a variable called `y_test`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the TensorFlow library and use `tf` as the alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the seed for `tensorflow` as `8` using `tf.random.set_seed()`. This will
    help to get reproducible results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a sequential model using `tf.keras.Sequential()` and store it in
    a variable called `model`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `Dense()` class from `tensorflow.keras.layers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function and the input shape as `(1001,)` which corresponds
    to the number of features from the dataset. Save it in a variable called `fc1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `28` units with `Dense()` and specify sigmoid
    as the activation function. Save it in a variable called `fc5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Sequentially add all five fully connected layers to the model using `add()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Print the summary of the model using `summary()` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.49: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_49.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.49: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Instantiate `BinaryCrossentropy()` from `tf.keras.losses` and save it in a
    variable called `loss`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate `Adam()` from `tf.keras.optimizers` with `0.001` as the learning
    rate and save it in a variable called `optimizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model using `compile()` method and specify the optimizer and loss
    parameters that were just created, with accuracy as the metric to be reported:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the model training process using the `fit()` method on the training set
    for `20` epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.50: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_50.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.50: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can observe that the model is trained for 20 epochs and that accuracy is
    improving, achieving `61.67%` after the ninth epoch.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Evaluate the performance of the model on the test set using the `evaluate()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.51: Performance of the model on the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_05_51.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 5.51: Performance of the model on the test set'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding output shows the model achieved an accuracy score of `0.13` on
    the test set, which is extremely low, while it got an accuracy of `0.62` on the
    training set. This model is struggling to learn the relevant pattern to correctly
    predict the different genres of movies. You could try different architectures
    with different numbers of hidden layers and units on your own. You can also try
    different learning rates and optimizers. As the scores are very different on the
    training and test sets, the model is overfitting and has simply learned patterns
    relevant to just the training set.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Regularization and Hyperparameter Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 6.01: Predicting Income with L1 and L2 Regularizers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the pandas library and use `pd` as the alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a list called `usecols` containing the column names `AAGE`, `ADTIND`,
    `ADTOCC`, `SEOTR`, `WKSWORK`, and `PTOTVAL`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `train_url` that contains the URL to the training
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the training dataset into a DataFrame, `train_data`, using the `read_csv()`
    method. Provide the URL to the CSV file and the `usecols` list to the `usecols`
    parameter. Print the first five rows using the `head()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.23: First five rows of the training set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.23: First five rows of the training set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the target variable (`PTOTVAL`) using the `pop()` method and save it
    in a variable called `train_target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `test_url` that contains the URL to the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the test dataset into a DataFrame, `X_test`, using the `read_csv()` method.
    Provide the URL to the CSV file and the `usecols` list to the `usecols` parameter.
    Print the first five rows using the `head()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.24: First five rows of the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.24: First five rows of the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the target variable (`PTOTVAL`) using the `pop()` method and save it
    in a variable called `test_target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the TensorFlow library and use `tf` as the alias. Then, import the `Dense`
    class from `tensorflow.keras.layers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the seed as `8` using `tf.random.set_seed()` to get reproducible results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a sequential model using `tf.keras.Sequential()` and store it in
    a variable called `model`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `Dense` class from `tensorflow.keras.layers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of `1048` units with `Dense()` and specify ReLu
    as the activation function and the input shape as `(5,)`, which corresponds to
    the number of features from the dataset. Save it in a variable called `fc1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three fully connected layers of `512`, `128`, and `64` units with `Dense()`
    and specify ReLu as the activation function. Save them in three variables, called
    `fc2`, `fc3`, and `fc4`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of three units (corresponding to the number
    of classes) with `Dense()` and specify softmax as the activation function. Save
    it in a variable called `fc5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fully connected layer of a single unit with `Dense()`. Save it in
    a variable called `fc5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Sequentially add all five fully connected layers to the model using the `add()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the summary of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.25: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.25: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Instantiate `Adam()` from `tf.keras.optimizers` with `0.05` as the learning
    rate and save it in a variable called `optimizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model, specify the optimizer, and set `mse` as the loss and metric
    to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the model training process using the `fit()` method for five epochs and
    split the data into a validation set with 20% of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.26: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.26: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding output shows the model is overfitting. It achieved an MSE score
    of `1005740` on the training set and only `1070237` on the validation set. Now,
    train another model with L1 and L2 regularization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create five fully connected layers similar to the previous models and specify
    both L1 and L2 regularizers for the `kernel_regularizer` parameters. Use the value
    `0.001` for the regularizer factor. Save them into five variables, called `reg_fc1`,
    `reg_fc2`, `reg_fc3`, `reg_fc4`, and `reg_fc5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a sequential model using `tf.keras.Sequential()`, store it in a
    variable called `model2`, and add all five fully connected layers sequentially
    to the model using the `add()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the summary of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.27: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.27: Summary of the model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile the model using the `compile()` method, specify the optimizer, and
    set `mse` as the loss and metric to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the model training process using the `fit()` method for five epochs and
    split the data into a validation set with 20% of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.28: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.28: Logs of the training process'
  prefs: []
  type: TYPE_NORMAL
- en: With the addition of L1 and L2 regularization, the model has similar accuracy
    scores between the training (`4028182`) and test (`3970020`) sets. Therefore,
    the model is not overfitting much.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6.02: Predicting Income with Bayesian Optimization from Keras Tuner'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the pandas library and use `pd` as the alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a list called `usecols` containing the following column names: `AAGE`,
    `ADTIND`, `ADTOCC`, `SEOTR`, `WKSWORK`, and `PTOTVAL`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `train_url` that contains the URL to the training
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the training dataset into a DataFrame called `train_data` using the `read_csv()`
    method, and provide the URL to the CSV file and the `usecols` list to the `usecols`
    parameter. Print the first five rows using the `head()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get the following output:![Figure 6.29: First five rows of the training
    set'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16341_06_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.29: First five rows of the training set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the target variable (`PTOTVAL`) using the `pop()` method, and save
    it in a variable called `train_target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `test_url` that contains the URL to the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the test dataset into a DataFrame called `X_test` using the `read_csv()`
    method and provide the URL to the CSV file and the `usecols` list to the `usecols`
    parameter. Print the first five rows using the `head()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.30: First five rows of the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.30: First five rows of the test set'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the target variable (`PTOTVAL`) using the `pop()` method, and save
    it in a variable called `test_target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the TensorFlow library and use `tf` as the alias. Then, import the `Dense`
    class from `tensorflow.keras.layers`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the seed as `8` using `tf.random.set_seed()` to get reproducible results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function called `model_builder` to create a sequential model with
    the same architecture as *Activity 6.01*, *Predicting Income with L1 and L2 Regularizers*.
    But this time, provide a hyperparameter, `hp.Choice`, for the learning rate, `hp.Int`
    for the number of units for the input layer, and `hp.Choice` for L2 regularization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the `keras-tuner` package and then import it and assign it the `kt`
    alias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `BayesianOptimization` tuner, and assign `val_mse` to `objective`
    and `10` to `max_trials`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Launch the hyperparameter search with `search()` on the training and test sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the best hyperparameter combination (index `0`) with `get_best_hyperparameters()`
    and save it in a variable called `best_hps`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the best value for the number of units for the input layer, save it
    in a variable called `best_units`, and print its value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The best value for the number of units of the input layer found by Hyperband
    is `128`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract the best value for the learning rate, save it in a variable called
    `best_lr`, and print its value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The best value for the learning rate hyperparameter found by Hyperband is `0.001`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the best value for the L2 regularization, save it in a variable called
    `best_l2`, and print its value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The best value for the learning rate hyperparameter found by Hyperband is `0.001`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the model training process using the `fit()` method for five epochs and
    use the test set for `validation_data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.31: Logs of the training process'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_06_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 6.31: Logs of the training process'
  prefs: []
  type: TYPE_NORMAL
- en: With Bayesian optimization, you found the best combination of hyperparameters
    for the number of units for the input layer (`128`), learning rate (`0.001`),
    and L2 regularization (`0.001`). With these hyperparameters, the final model achieved
    an MSE score of `994174` on the training set and `989335` on the test set. This
    is a great improvement from *Activity 6.01*, *Predicting Income with L1 and L2
    Regularizers*, and the model is not overfitting much.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Convolutional Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 7.01: Building a CNN with More ANN Layers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several possible ways to arrive at a solution for this activity.
    The following steps describe one of these methods and are similar to those used
    on the `CIFAR-10` dataset earlier in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the additional libraries needed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the `CIFAR-100` dataset directly from `tensorflow_datasets` and view its
    properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will give the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.42: Properties of the CIFAR-100 dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_07_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.42: Properties of the CIFAR-100 dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use a rescaling layer to rescale images. Then, build a test and train data
    pipeline by rescaling, caching, shuffling, batching, and prefetching the images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the model using the functional API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile and fit the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE184]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will look like the following image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.43: Model fit'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_07_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.43: Model fit'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot the loss and accuracy by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE185]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Loss plot would look like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.44: Loss plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_07_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.44: Loss plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Accuracy plot would look like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.45: Accuracy plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_07_45.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.45: Accuracy plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Display a misclassified example. Use the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will produce the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.46: Wrong classification example'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_07_46.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.46: Wrong classification example'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output shows an example of a wrong classification: the prediction was lion,
    and the true value was mouse. In this activity, the number of classes was 100,
    which makes it significantly more difficult than in *Exercise 7.05*, *Building
    a CNN*, in which there were only 10 classes. Nevertheless, you can see that after
    15 epochs, the accuracy continued to increase, and loss continued to decrease
    even on the validation dataset. You could then expect better model performance
    if you were to let the model train for more epochs.'
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Pre-Trained Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 8.01: Fruit Classification with Fine-Tuning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library as `tf`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE187]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `file_url` containing a link to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the dataset using `tf.keras.get_file` with `''fruits360.zip''`, `origin=file_url`,
    and `extract=True` as parameters, and save the result to a variable called `zip_dir`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE189]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pathlib` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `path` containing the full path to the `fruits360_filtered`
    directory using `pathlib.Path(zip_dir).parent`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `train_dir` and `validation_dir` that take the
    full path to the train (`Training`) and validation (`Test`) folders, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE192]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `total_train` and `total_val` that get the number
    of images for the training and validation sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE193]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageDataGenerator` model called `train_img_gen` with data augmentation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageDataGenerator` mode called `val_img_gen` with rescaling by
    dividing by `255`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables called `batch_size`, `img_height`, `img_width`, and `channel`
    that take the values `32`, `224`, `224`, and `3`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE197]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `flow_from_directory()`
    and specify the batch size, training folder, and target size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE198]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `flow_from_directory()`
    and specify the batch size, validation folder, and target size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE199]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE200]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set `8` as the seed for `numpy` and `tensorflow`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE201]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `NASNetMobile` from `tensorflow.keras.applications`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE202]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `NASNetMobile` model into a variable called `base_model`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE203]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print a summary of this `NASNetMobile` model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE204]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.8: Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.8: Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a new model using `tf.keras.Sequential()` by adding the base model to
    the `Flatten` and `Dense` layers. Save this model to a variable called `model`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE205]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `tf.keras.optimizers.Adam()` class with `0.001` as the learning
    rate and save it to a variable called `optimizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE206]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the neural network using the `compile()` method with `categorical_crossentropy`
    as the loss function, an Adam optimizer with a learning rate of `0.001`, and `accuracy`
    as the metric to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE207]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the neural networks with `fit()` method. This model may take a few minutes
    to train:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE208]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.9: Epochs of the trained model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.9: Epochs of the trained model'
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you used fine-tuning to customize a `NASNetMobile` model pre-trained
    on ImageNet on a dataset containing images of fruit. You froze the first 700 layers
    of this model and trained only the last few on five epochs. You achieved an accuracy
    score of `0.9549` for the training set and `0.8264` for the test set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 8.02: Transfer Learning with TensorFlow Hub'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE209]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `file_url` containing a link to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE210]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the dataset using `tf.keras.get_file` with `cats_and_dogs.zip`, `origin=file_url`,
    and `extract=True` as parameters and save the result to a variable called `zip_dir`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE211]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pathlib` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE212]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `path` containing the full path to the `cats_and_dogs_filtered`
    directory using `pathlib.Path(zip_dir).parent`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE213]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `train_dir` and `validation_dir` that take the
    full path to the `train` and `validation` folders:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE214]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `total_train` and `total_val` that will get the
    number of images for the training and validation sets (`2000` and `1000`, respectively):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE215]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE216]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate two `ImageDataGenerator` classes and call them `train_image_generator`
    and `validation_image_generator`. These will rescale images by dividing by `255`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE217]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three variables called `batch_size`, `img_height`, and `img_width` that
    take the values `32`, `224`, and `224`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE218]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `flow_from_directory()`
    and specify the batch size, the path to the training folder, target size, and
    mode of the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE219]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `flow_from_directory()`
    and specify the batch size, paths to the validation folder, target size, and mode
    of the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE220]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE221]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set `8` (this is totally arbitrary) as `seed` for numpy and tensorflow:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE222]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `tensorflow_hub`, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE223]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the EfficientNet B0 feature vector from TensorFlow Hub:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE224]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new model that combines the EfficientNet B0 module with two new top
    layers, with `500` and `1` as units, and ReLu and sigmoid as the activation functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE225]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile this model by providing `binary_crossentropy` as the `loss` function,
    an Adam optimizer with a learning rate of `0.001`, and `accuracy` as the metric
    to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE226]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model and provide the train and validation data generators. Run it
    for five epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE227]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.10: Model training output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.10: Model training output'
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you achieved a very high accuracy score (with `1` and `0.99`
    for the training and test sets, respectively), using transfer learning from TensorFlow
    Hub. You used the **EfficientNet B0** feature vector combined with two custom
    final layers, and your final model is almost perfectly predicting images of cats
    and dogs.
  prefs: []
  type: TYPE_NORMAL
- en: 9\. Recurrent Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 9.01: Building an RNN with Multiple LSTM Layers to Predict Power Consumption'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: Perform the following steps to complete this activity.
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter or Colab notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the libraries needed. Use `numpy`, `pandas`, `datetime`, and `MinMaxScaler`
    to scale the dataset between zero and one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE228]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `read_csv()` function to read in your CSV file and store your dataset
    in a pandas DataFrame, `data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE229]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new column, `Datetime`, by combining `Date` and `Time` columns using
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE230]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Sort the DataFrame in ascending order using the `Datetime` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE231]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a list called `num_cols` containing the columns that have numeric values
    – `Global_active_power`, `Global_reactive_power`, `Voltage`, `Global_intensity`,
    `Sub_metering_1`, `Sub_metering_2`, and `Sub_metering_3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE232]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert all columns listed in `num_cols` to a numeric datatype:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE233]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Call the `head()` function on your data to take a look at the first five rows
    of your DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE234]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.40: First five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.40: First five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Call `tail()` on your data to take a look at the last five rows of your DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE235]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.41: Last five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.41: Last five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Iterate through columns in `num_cols` and fill in missing values with the average
    using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE236]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `drop()` to remove `Date`, `Time`, `Global_reactive_power`, and `Datetime`
    columns from your DataFrame and save the results in a variable called `df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE237]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a scaler from `MinMaxScaler` to your DataFrame to numbers between zero
    and one. Use `fit_transform` to fit the model to the data and then transform the
    data according to the fitted model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE238]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.42: Standardized training data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.42: Standardized training data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding screenshot shows the data has been standardized. Values sit between
    0 and 1 now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create two empty lists called `X` and `y` that will be used to store features
    and target variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE239]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a training dataset that has the previous 60 minutes'' power consumption
    so that you can predict the value for the next minute. Use a `for` loop to create
    data in 60 time steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE240]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert `X` and `y` into NumPy arrays in preparation for training your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE241]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Split the dataset into training and testing sets with data before and after
    the index `217440`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE242]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will need some additional libraries for building LSTM. Use `Sequential`
    to initialize the neural net, `Dense` to add a dense layer, `LSTM` to add an LSTM
    layer, and `Dropout` to help prevent overfitting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE243]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize your neural network. Add LSTM layers with `20`, `40`, and `80` units.
    Use a ReLU activation function and set `return_sequences` to `True`. The `input_shape`
    should be the dimensions of your training set (the number of features and days).
    Finally, add your dropout layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE244]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the architecture of the model using the `summary()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE245]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding command gives valuable information about the model, layers, and
    parameters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.43: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.43: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `compile()` method to configure your model for training. Select Adam
    as your optimizer and mean squared error to measure your loss function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE246]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit your model and set it to run on two epochs. Set your batch size to `32`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE247]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Save the predictions on the test set in a variable called `y_pred` using `regressor.predict(X_test)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE248]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Take a look at the real household power consumption and your predictions for
    the last hour of data from your test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE249]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.44: Household power consumption prediction visualization'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_44.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.44: Household power consumption prediction visualization'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Figure 9.44*, your results are pretty good. You can observe
    that for the most part, your predictions are close to the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 9.02: Building an RNN for Predicting Tweets'' Sentiment'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter or Colab notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the libraries needed. Use `numpy` for computation and `pandas` to work
    with your dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE250]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `read_csv` method to read in your CSV file and store your dataset in
    a pandas DataFrame, `data`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE251]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Call the `head()` method on your data to take a look at the first five rows
    of your DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE252]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.45: First five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_45.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.45: First five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the preceding screenshot, you can see the different sentiments stored in
    the `airline_sentiment` column.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Call `tail()` on your data to take a look at the last five rows of your DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE253]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.46: Last five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_46.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.46: Last five rows of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a new DataFrame called `df` that will have only `text` as features and
    `airline_sentiment` as the target variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE254]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Subset `df` by removing all rows where `airline_sentiment` is equal to `neutral`
    by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE255]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Transform the `airline_sentiment` column to a numeric type by replacing `negative`
    with `0` and `positive` with `1`. Save the result to a variable, `y`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE256]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `X`, that will contain the data from the text column in
    `df`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE257]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `Tokenizer` from `tensorflow.keras.preprocessing.text` and `pad_sequences`
    from `tensorflow.keras.preprocessing.sequence`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE258]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `Tokenizer()` class with `num_words` equal to `10000`. This will
    keep only the first 10,000 most frequent words. Save it into a variable, `tokenizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE259]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit `tokenizer` on the data `X`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE260]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the vocabulary from `tokenizer`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE261]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.47: Vocabulary defined by tokenizer'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_47.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.47: Vocabulary defined by tokenizer'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the output vocabulary, you can see the word `to` has been assigned the
    index `1`, `the` is assigned `2`, and so on. You can use it to map the raw text
    into a numerical version of it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create the `vocab_size` variable, to contain the length of the tokenizer vocabulary
    plus an additional character that will be used for unknown words:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE262]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Transform the raw text from `X` to an encoded version using the vocabulary
    from `tokenizer`. Save the result in a variable called `encoded_tweets`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE263]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pad `encoded_tweets` with `0` at the end for a maximum of 280 characters. Save
    the result in a variable called `padded_tweets`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE264]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the shape of `padded_tweets`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE265]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE266]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, prepared tweets now all have the same length, that is, 280 characters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Randomly permute the indices of `padded_tweets`. Save the result in the `indices`
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE267]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables, `train_idx` and `test_idx`, to contain the first 10,000
    indices and the remaining ones respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE268]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `padded_tweets` and `y`, split the data into training and testing sets.
    Save them into four different variables called `X_train`, `X_test`, `y_train`,
    and `y_test`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE269]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will need some additional libraries to build your model. Import `Sequential`,
    `Dense`, `LSTM`, `Dropout`, and `Embedding` using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE270]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize your neural network. Add an embedding layer by providing the length
    of the vocabulary, the length of the embedding layer, and the input length. Add
    two LSTM layers with `50` and `100` units. Use a ReLU activation function and
    set `return_sequences` to `True`. Then, add a dropout layer for each LSTM with
    a dropout of 20%. Finally, add a fully-connected layer with sigmoid as the final
    activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE271]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the summary of the model using the `summary()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE272]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.48: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_48.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.48: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `compile()` method to configure your model for training. Select `adam`
    as your optimizer, `binary_crossentropy` to measure your loss function, and `accuracy`
    as the metric to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE273]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit your model and set it to run on two epochs. Set your batch size to `32`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE274]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9\. 49: Training the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_09_49.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9\. 49: Training the model'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Figure 9.49*, your model achieved an accuracy of `0.7978`
    on the training set with minimal data preparation. You can try to improve this
    by removing stop words or extremely frequent words such as `the` and `a` that
    don't really help to assess the sentiment of a tweet and see if you can achieve
    the same performance on the testing set. You can deduce that the model can correctly
    predict almost 80% of the sentiments for the tweets in the training data.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Custom TensorFlow Components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 10.01: Building a Model with Custom Layers and a Custom Loss Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook or Google Colab notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you are using Google Colab, you can upload your dataset locally with the
    following code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate
    to the CSV file and click `Open`. Save the file as `uploaded`. Then, go to the
    folder where you saved the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE275]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Unzip the dataset in the current folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE276]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE277]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import all the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE278]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `path`, that contains the full path to the data using `pathlib.Path`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE279]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables, called `train_dir` and `validation_dir`, that take the
    full paths to the train and validation folders, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE280]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables, called `train_table_dir`, `train_glass_dir`, `validation_table_dir`,
    and `validation_glass_dir`, that take the full paths to the glass and table folders
    for the train and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE281]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables that will contain the number of images of glasses and
    tables for the training and validation sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE282]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display a bar chart with the total number of images of glasses and tables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE283]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.12: Number of images of glasses and tables'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.12: Number of images of glasses and tables'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding chart shows you the dataset is well balanced. There are almost
    as many images of glasses as tables, around 3,500 images each.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create two variables, called `total_train` and `total_val`, that will get the
    number of images for the training and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE284]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `ImageDataGenerator` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE285]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate two `ImageDataGenerator` classes, `train_image_generator` and `validation_image_generator`,
    that will rescale the images by dividing by 255:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE286]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `100`, and `100`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE287]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `flow_from_directory()`
    method and specify the batch size, the path to the training folder, the value
    of the `shuffle` parameter, the size of the target, and the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE288]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `flow_from_directory()`
    method and specify the batch size, the path to the validation folder, the size
    of the target, and the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE289]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create your custom loss function. Use `def` and choose a name for your custom
    loss, `custom_loss_function`, in this case. Then, add your two arguments, `y_true`
    and `y_pred`. Now, create a variable, `squared_difference`, to store the square
    of `y_true` minus `y_pred`. Finally, return the calculated loss using your `tf.reduce_mean`
    from `squared_difference`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE290]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build a function that takes your input as a tensor and adds ReLU and batch
    normalization to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE291]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a function to build the residual block. You will need to take a tensor
    as your input and pass it to two Conv2D layers. Next, add the input to the output,
    followed by ReLU and batch normalization.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since you used an `Add` layer for the skip connection in your `residual_block`,
    you need to make sure that its inputs are always of the same shape. The `downsample`
    parameter is used to specify the strides of the first Conv2D layer. It specifies
    `strides=2` if `True` and `strides=1` if `False`. When `strides=1`, the output
    (`int_output`) is the same size as the input. But when `strides=2`, the dimensions
    of `int_ouput` are halved. To take this into account, add a Conv2D layer with
    `kernel_size=1` to the skip connection:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE292]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, use the `keras.layers.Input()` layer to define the input layer of your
    model. Here, your shape is 100 pixels by 100 pixels and has three colors (RGB).
    Then, create your model with your custom architecture. Finally, reference your
    input and output tensors with `model = Model (inputs, outputs)`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE293]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get a summary of your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE294]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The summary will be shown on running the preceding command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.13: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.13: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile this model by providing your custom loss function, using Adam as the
    optimizer and accuracy as the metric to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE295]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model and provide the train and validation data generators, the number
    of epochs, the steps per epoch, and the validation steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE296]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.14: Screenshot of the training progress'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.14: Screenshot of the training progress'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch. On the fifth epoch, the model is `85.9%` accurate
    on the training set and `88.5%` on the validation set.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot your training and validation accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE297]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.15: Training and validation accuracy'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.15: Training and validation accuracy'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding chart shows the accuracy scores for the training and validation
    sets for each epoch.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot your training and validation loss:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE298]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.16: Training and validation loss'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.16: Training and validation loss'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding chart shows the loss scores for the training and validation sets
    for each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: With this activity, you have successfully built a custom MSE loss function and
    a custom residual block layer and trained this custom deep learning model on the
    glass versus table dataset. You now know how to go beyond the default classes
    offered by TensorFlow and build your own custom deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activity 11.01: Generating Images Using GANs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Solution**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load Google Colab and Google Drive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE299]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE300]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the libraries that you will be using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE301]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function to format a time string to track your time usage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE302]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the generation resolution to `3`. Also, set `img_rows` and `img_cols` to
    `5` and `img_margin` to `16` so that your preview images will be a `5x5` array
    (25 images) with a 16-pixel margin. Set `seed_vector` equal to `200`, `data_path`
    to where you stored your image dataset, and `epochs` to `500`. Finally, print
    the parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE303]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.30: Output showing the parameters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.30: Output showing the parameters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If a NumPy preprocessed file exists from prior execution, then load it into
    memory; otherwise, preprocess the data and save the image binary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE304]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Batch and shuffle the data. Use the `tensorflow.data.Dataset` object library
    to use its functions to shuffle the dataset and create batches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE305]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the generator for the DCGAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE306]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the discriminator for the DCGAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE307]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the generator for the vanilla GAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE308]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the discriminator for the vanilla GAN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE309]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function to generate and save images that can be used to view progress
    during the model''s training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE310]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize the generator for the DCGAN and view the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE311]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.31: Output showing noise from the DCGAN generator'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.31: Output showing noise from the DCGAN generator'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Initialize the generator for the vanilla GAN and view the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE312]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.31: Output showing noise from the DCGAN generator'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.32: Output showing noise from the vanilla GAN generator'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the decision of the DCGAN discriminator evaluated on the seed image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE313]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE314]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the decision of the vanilla GAN evaluated on the seed image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE315]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE316]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create your loss functions. Since the output of both the discriminator and generator
    networks is different, you can define two separate loss functions for them. Moreover,
    they need to be trained separately in independent passes through the networks.
    Both GANs can utilize the same loss functions for their discriminators and generators.
    You can use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This calculates
    the loss between true and predicted labels. Then, define the `discrim_loss` function
    from `real_output` and `fake_output` using `tf.ones` and `tf.zeros` to calculate
    `total_loss`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE317]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two Adam optimizers, one for the generator and one for the discriminator.
    Use the same learning rate and momentum for each:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE318]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you have your individual training step. It's very important that you only
    modify one network's weights at a time. With `tf.GradientTape()`, you can train
    the discriminator and generator at the same time, but separately from one another.
    This is how TensorFlow does automatic differentiation. It calculates the derivatives.
    You'll see that it creates two "tapes" – `gen_tape` and `disc_tape`. Think of
    these as recordings of the calculations for each.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create `real_output` and `fake_output` for the discriminator. Use this for
    the generator loss (`g_loss`). Then, calculate the discriminator loss (`d_loss`)
    and the gradients of both the generator and discriminator with `gradients_of_generator`
    and `gradients_of_discriminator` and apply them. Encapsulate these steps within
    a function, passing in the generator, discriminator, and images, and returning
    the generator loss (`g_loss`) and discriminator loss (`d_loss`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE319]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a number of fixed seeds with `fixed_seeds` equal to the number of images
    to display so that you can track the same images. This allows you to see how individual
    seeds evolve over time, tracking your time with `for epoch in range`. Now, loop
    through each batch with `for image_batch in dataset`. Continue to track your loss
    for both the generator and discriminator with `generator_loss` and `discriminator_loss`.
    Now, you have a nice display of all this information as it trains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE320]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the DCGAN model on your training dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE321]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.33: Output during training of the DCGAN model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.33: Output during training of the DCGAN model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The output shows the loss for the generator and discriminator at each epoch.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Train the vanilla model on your training dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE322]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your output should look something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.34: Output during training of the vanilla GAN model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.34: Output during training of the vanilla GAN model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View your images generated by the DCGAN model after the 100th epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE323]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.35: Output images from the DCGAN model after 100 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.35: Output images from the DCGAN model after 100 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View your images generated by the DCGAN model after the 500th epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE324]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.36: Output images from the DCGAN model after 500 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.36: Output images from the DCGAN model after 500 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View your images generated by the vanilla GAN model after the 100th epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE325]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.37: Output images from the vanilla GAN model after 100 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.37: Output images from the vanilla GAN model after 100 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View your images generated by the vanilla GAN model after the 500th epoch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE326]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.38: Output images from the vanilla GAN model after 500 epochs'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_11_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 11.38: Output images from the vanilla GAN model after 500 epochs'
  prefs: []
  type: TYPE_NORMAL
- en: The output shows the images generated by the vanilla GAN after 500 epochs. You
    can see that they are very different from those generated by the DCGAN.
  prefs: []
  type: TYPE_NORMAL
- en: You've just completed the last activity of the book. You created your own images
    with a DCGAN and compared them to a vanilla GAN model. As you can see from *Figure
    11.36* and *Figure 11.38*, the results are very different from those of the DCGAN
    model, which were clearly recognizable as banana-like with different variations
    and orientations. With that model, though some images were more banana-like than
    others, all still exhibit at least some identifiable characteristics of bananas,
    such as color, shape, and presence of the black tip. The results from the vanilla
    GAN model, however, look more like pixel averages of the training dataset, which
    is overall not a good representation of real-life bananas. All images seem to
    have the same orientation, which may be another indicator that the results are
    more of a pixel average of the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Rayon](img/Matthew_Moocarme.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Matthew Moocarme**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rayon](img/Anthony_So.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Anthony So**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rayon](img/Anthony_Maddalone.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Anthony Maddalone**'
  prefs: []
  type: TYPE_NORMAL
- en: Hey!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We're Matthew Moocarme, Anthony So, and Anthony Maddalone, the authors of this
    book. We really hope you enjoyed reading our book and found it useful for learning
    TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: It would really help us (and other potential readers!) if you could leave a
    review on Amazon sharing your thoughts on *The TensorFlow Workshop*.
  prefs: []
  type: TYPE_NORMAL
- en: Go to the link [https://packt.link/r/1800205252](https://packt.link/r/1800205252).
  prefs: []
  type: TYPE_NORMAL
- en: OR
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code to leave your review.
  prefs: []
  type: TYPE_NORMAL
- en: '![Barcode](img/qr-code-https___packt.link_r_1800205252.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Your review will help us to understand what's worked well in this book and what
    could be improved upon for future editions, so it really is appreciated.
  prefs: []
  type: TYPE_NORMAL
- en: Best wishes,
  prefs: []
  type: TYPE_NORMAL
- en: Matthew Moocarme, Anthony So, and Anthony Maddalone
  prefs: []
  type: TYPE_NORMAL
- en: '![Packt Logo](img/Packt_Logo.png)'
  prefs: []
  type: TYPE_IMG
