["```\n$> pip install opencv-contrib-python\n```", "```\n    import cv2\n    import numpy as np\n    from tensorflow.keras import Model\n    from tensorflow.keras.datasets import fashion_mnist\n    from tensorflow.keras.layers import *\n    ```", "```\n    def build_autoencoder(input_shape=784, encoding_dim=128):\n        input_layer = Input(shape=(input_shape,))\n        encoded = Dense(units=512)(input_layer)\n        encoded = ReLU()(encoded)\n        encoded = Dense(units=256)(encoded)\n        encoded = ReLU()(encoded)\n        encoded = Dense(encoding_dim)(encoded)\n        encoding = ReLU()(encoded)\n        decoded = Dense(units=256)(encoding)\n        decoded = ReLU()(decoded)\n        decoded = Dense(units=512)(decoded)\n        decoded = ReLU()(decoded)\n        decoded = Dense(units=input_shape)(decoded)\n        decoded = Activation('sigmoid')(decoded)\n        return Model(input_layer, decoded)\n    ```", "```\n    def plot_original_vs_generated(original, generated):\n        num_images = 15\n        sample = np.random.randint(0, len(original), \n                                   num_images)\n    ```", "```\n        def stack(data):\n            images = data[sample]\n            return np.vstack([np.hstack(images[:5]),\n                              np.hstack(images[5:10]),\n                              np.hstack(images[10:15])])\n    ```", "```\n        def add_text(image, text, position):\n            pt1 = position\n            pt2 = (pt1[0] + 10 + (len(text) * 22),\n                   pt1[1] - 45)\n            cv2.rectangle(image,\n                          pt1,\n                          pt2,\n                          (255, 255, 255),\n                          -1)\n            cv2.putText(image, text,\n                        position,\n                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                        fontScale=1.3,\n                        color=(0, 0, 0),\n                        thickness=4)\n    ```", "```\n        original = stack(original)\n        generated = stack(generated)\n        mosaic = np.vstack([original,\n                            generated])\n        mosaic = cv2.resize(mosaic, (860, 860), \n                            interpolation=cv2.INTER_AREA)\n        mosaic = cv2.cvtColor(mosaic, cv2.COLOR_GRAY2BGR)\n        add_text(mosaic, 'Original', (50, 100))\n        add_text(mosaic, 'Generated', (50, 520))\n        cv2.imshow('Mosaic', mosaic)\n        cv2.waitKey(0)\n    ```", "```\n    (X_train, _), (X_test, _) = fashion_mnist.load_data()\n    ```", "```\n    X_train = X_train.astype('float32') / 255.0\n    X_test = X_test.astype('float32') / 255.0\n    ```", "```\n    X_train = X_train.reshape((X_train.shape[0], -1))\n    X_test = X_test.reshape((X_test.shape[0], -1))\n    ```", "```\n    autoencoder = build_autoencoder()\n    autoencoder.compile(optimizer='adam', loss='mse')\n    ```", "```\n    EPOCHS = 300\n    BATCH_SIZE = 1024\n    autoencoder.fit(X_train, X_train,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    validation_data=(X_test, X_test))\n    ```", "```\n    predictions = autoencoder.predict(X_test)\n    ```", "```\n    original_shape = (X_test.shape[0], 28, 28)\n    predictions = predictions.reshape(original_shape)\n    X_test = X_test.reshape(original_shape)\n    ```", "```\n    plot_original_vs_generated(X_test, predictions)\n    ```", "```\n$> pip install opencv-contrib-python\n```", "```\n    import cv2\n    import numpy as np\n    from tensorflow.keras import Model\n    from tensorflow.keras.datasets import fashion_mnist\n    from tensorflow.keras.layers import * \n    ```", "```\n    def build_autoencoder(input_shape=(28, 28, 1),\n                          encoding_size=32,\n                          alpha=0.2):\n        inputs = Input(shape=input_shape)\n        encoder = Conv2D(filters=32,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(inputs)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n    ```", "```\n        encoder = Conv2D(filters=64,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(encoder)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n    ```", "```\n        encoder_output_shape = encoder.shape\n        encoder = Flatten()(encoder)\n        encoder_output = Dense(units=encoding_size)(encoder)\n        encoder_model = Model(inputs, encoder_output)\n    ```", "```\n        decoder_input = Input(shape=(encoding_size,))\n        target_shape = tuple(encoder_output_shape[1:])\n        decoder = Dense(np.prod(target_shape))(decoder_input)\n        decoder = Reshape(target_shape)(decoder)\n        decoder = Conv2DTranspose(filters=64,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n    ```", "```\n        decoder = Conv2DTranspose(filters=32,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n    ```", "```\n        decoder = Conv2DTranspose(filters=1,\n                                  kernel_size=(3, 3),\n                                  padding='same')(decoder)\n        outputs = Activation('sigmoid')(decoder)\n        decoder_model = Model(decoder_input, outputs)\n    ```", "```\n        encoder_model_output = encoder_model(inputs)\n        decoder_model_output = \n           decoder_model(encoder_model_output)\n        autoencoder_model = Model(inputs, \n           decoder_model_output)\n      return encoder_model, decoder_model, autoencoder_model\n    ```", "```\n    def plot_original_vs_generated(original, generated):\n        num_images = 15\n        sample = np.random.randint(0, len(original), \n                                   num_images)\n    ```", "```\n        def stack(data):\n            images = data[sample]\n            return np.vstack([np.hstack(images[:5]),\n                              np.hstack(images[5:10]),\n                              np.hstack(images[10:15])])\n    ```", "```\n    def add_text(image, text, position):\n            pt1 = position\n            pt2 = (pt1[0] + 10 + (len(text) * 22),\n                   pt1[1] - 45)\n            cv2.rectangle(image,\n                          pt1,\n                          pt2,\n                          (255, 255, 255),\n                          -1)\n            cv2.putText(image, text,\n                        position,\n                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                        fontScale=1.3,\n                        color=(0, 0, 0),\n                        thickness=4)\n    ```", "```\n        original = stack(original)\n        generated = stack(generated)\n        mosaic = np.vstack([original,\n                            generated])\n        mosaic = cv2.resize(mosaic, (860, 860),\n                            interpolation=cv2.INTER_AREA)\n        mosaic = cv2.cvtColor(mosaic, cv2.COLOR_GRAY2BGR)\n        add_text(mosaic, 'Original', (50, 100))\n        add_text(mosaic, 'Generated', (50, 520))\n        cv2.imshow('Mosaic', mosaic)\n        cv2.waitKey(0)\n    ```", "```\n    (X_train, _), (X_test, _) = fashion_mnist.load_data()\n    ```", "```\n    X_train = X_train.astype('float32') / 255.0\n    X_test = X_test.astype('float32') / 255.0\n    X_train = np.expand_dims(X_train, axis=-1)\n    X_test = np.expand_dims(X_test, axis=-1)\n    ```", "```\n    _, _, autoencoder = build_autoencoder(encoding_size=256)\n    autoencoder.compile(optimizer='adam', loss='mse')\n    ```", "```\n    EPOCHS = 300\n    BATCH_SIZE = 512\n    autoencoder.fit(X_train, X_train,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    validation_data=(X_test, X_test),\n                    verbose=1)\n    ```", "```\n    predictions = autoencoder.predict(X_test)\n    ```", "```\n    original_shape = (X_test.shape[0], 28, 28)\n    predictions = predictions.reshape(original_shape)\n    X_test = X_test.reshape(original_shape)\n    predictions = (predictions * 255.0).astype('uint8')\n    X_test = (X_test * 255.0).astype('uint8')\n    ```", "```\n    plot_original_vs_generated(X_test, predictions)\n    ```", "```\n$> pip install opencv-contrib-python\n```", "```\n    import cv2\n    import numpy as np\n    from tensorflow.keras import Model\n    from tensorflow.keras.datasets import fashion_mnist\n    from tensorflow.keras.layers import *\n    ```", "```\n    def build_autoencoder(input_shape=(28, 28, 1),\n                          encoding_size=128,\n                          alpha=0.2):\n        inputs = Input(shape=input_shape)\n        encoder = Conv2D(filters=32,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(inputs)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n        encoder = Conv2D(filters=64,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(encoder)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n        encoder_output_shape = encoder.shape\n        encoder = Flatten()(encoder)\n        encoder_output = \n          Dense(units=encoding_size)(encoder)\n        encoder_model = Model(inputs, encoder_output)\n    ```", "```\n        decoder_input = Input(shape=(encoding_size,))\n        target_shape = tuple(encoder_output_shape[1:])\n        decoder = \n        Dense(np.prod(target_shape))(decoder_input)\n        decoder = Reshape(target_shape)(decoder)\n        decoder = Conv2DTranspose(filters=64,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n        decoder = Conv2DTranspose(filters=32,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n        decoder = Conv2DTranspose(filters=1,\n                                  kernel_size=(3, 3),\n                                  padding='same')(decoder)\n        outputs = Activation('sigmoid')(decoder)\n        decoder_model = Model(decoder_input, outputs)\n    ```", "```\n        encoder_model_output = encoder_model(inputs)\n        decoder_model_output = \n        decoder_model(encoder_model_output)\n        autoencoder_model = Model(inputs, \n                                  decoder_model_output)\n        return encoder_model, decoder_model, autoencoder_model\n    ```", "```\n    def plot_original_vs_generated(original, generated):\n        num_images = 15\n        sample = np.random.randint(0, len(original), \n                                  num_images)\n    ```", "```\n        def stack(data):\n            images = data[sample]\n            return np.vstack([np.hstack(images[:5]),\n                              np.hstack(images[5:10]),\n                              np.hstack(images[10:15])])\n    ```", "```\n    def add_text(image, text, position):\n            pt1 = position\n            pt2 = (pt1[0] + 10 + (len(text) * 22),\n                   pt1[1] - 45)\n            cv2.rectangle(image,\n                          pt1,\n                          pt2,\n                          (255, 255, 255),\n                          -1)\n            cv2.putText(image, text,\n                        position,\n                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                        fontScale=1.3,\n                        color=(0, 0, 0),\n                        thickness=4)\n    ```", "```\n        original = stack(original)\n        generated = stack(generated)\n        mosaic = np.vstack([original,\n                            generated])\n        mosaic = cv2.resize(mosaic, (860, 860),\n                            interpolation=cv2.INTER_AREA)\n        mosaic = cv2.cvtColor(mosaic, cv2.COLOR_GRAY2BGR)\n        add_text(mosaic, 'Original', (50, 100))\n        add_text(mosaic, 'Generated', (50, 520))\n        cv2.imshow('Mosaic', mosaic)\n        cv2.waitKey(0)\n    ```", "```\n    (X_train, _), (X_test, _) = fashion_mnist.load_data()\n    ```", "```\n    X_train = X_train.astype('float32') / 255.0\n    X_test = X_test.astype('float32') / 255.0\n    X_train = np.expand_dims(X_train, axis=-1)\n    X_test = np.expand_dims(X_test, axis=-1)\n    ```", "```\n    train_noise = np.random.normal(loc=0.5, scale=0.5,\n                                   size=X_train.shape)\n    test_noise = np.random.normal(loc=0.5, scale=0.5,\n                                  size=X_test.shape)\n    ```", "```\n    X_train_noisy = np.clip(X_train + train_noise, 0, 1)\n    X_test_noisy = np.clip(X_test + test_noise, 0, 1)\n    ```", "```\n    _, _, autoencoder = build_autoencoder(encoding_size=128)\n    autoencoder.compile(optimizer='adam', loss='mse')\n    ```", "```\n    EPOCHS = 300\n    BATCH_SIZE = 1024\n    autoencoder.fit(X_train_noisy, X_train,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    validation_data=(X_test_noisy,X_test))\n    ```", "```\n    predictions = autoencoder.predict(X_test)\n    original_shape = (X_test_noisy.shape[0], 28, 28)\n    predictions = predictions.reshape(original_shape)\n    X_test_noisy = X_test_noisy.reshape(original_shape)\n    predictions = (predictions * 255.0).astype('uint8')\n    X_test_noisy = (X_test_noisy * 255.0).astype('uint8')\n    ```", "```\n    plot_original_vs_generated(X_test_noisy, predictions)\n    ```", "```\n$> pip install opencv-contrib-python\n```", "```\n    import cv2\n    import numpy as np\n    from sklearn.model_selection import train_test_split\n    from tensorflow.keras import Model\n    from tensorflow.keras.datasets import fashion_mnist as fmnist\n    from tensorflow.keras.layers import *\n    ```", "```\n    SEED = 84\n    np.random.seed(SEED)\n    ```", "```\n    def build_autoencoder(input_shape=(28, 28, 1),\n                          encoding_size=96,\n                          alpha=0.2):\n        inputs = Input(shape=input_shape)\n        encoder = Conv2D(filters=32,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(inputs)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n        encoder = Conv2D(filters=64,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(encoder)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n        encoder_output_shape = encoder.shape\n        encoder = Flatten()(encoder)\n        encoder_output = Dense(encoding_size)(encoder)\n        encoder_model = Model(inputs, encoder_output)\n    ```", "```\n        decoder_input = Input(shape=(encoding_size,))\n        target_shape = tuple(encoder_output_shape[1:])\n        decoder = Dense(np.prod(target_shape))(decoder_input)\n        decoder = Reshape(target_shape)(decoder)\n        decoder = Conv2DTranspose(filters=64,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n        decoder = Conv2DTranspose(filters=32,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n        decoder = Conv2DTranspose(filters=1,\n                                  kernel_size=(3, 3),\n                                  padding='same')(decoder)\n        outputs = Activation('sigmoid')(decoder)\n        decoder_model = Model(decoder_input, outputs)\n    ```", "```\n        encoder_model_output = encoder_model(inputs)\n        decoder_model_output = \n        decoder_model(encoder_model_output)\n        autoencoder_model = Model(inputs, \n                                  decoder_model_output)\n        return encoder_model, decoder_model, autoencoder_model\n    ```", "```\n    def create_anomalous_dataset(features,\n                                 labels,\n                                 regular_label,\n                                 anomaly_label,\n                                 corruption_proportion=0.01):\n        regular_data_idx = np.where(labels == \n                                    regular_label)[0]\n        anomalous_data_idx = np.where(labels == \n                                      anomaly_label)[0]\n        np.random.shuffle(regular_data_idx)\n        np.random.shuffle(anomalous_data_idx)\n    ```", "```\n        num_anomalies = int(len(regular_data_idx) *\n                            corruption_proportion)\n        anomalous_data_idx = \n                anomalous_data_idx[:num_anomalies]\n        data = np.vstack([features[regular_data_idx],\n                          features[anomalous_data_idx]])\n        np.random.shuffle(data)\n        return data\n    ```", "```\n    (X_train, y_train), (X_test, y_test) = fmnist.load_data()\n    X = np.vstack([X_train, X_test])\n    y = np.hstack([y_train, y_test])\n    ```", "```\n    REGULAR_LABEL = 5  # Sandal\n    ANOMALY_LABEL = 0  # T-shirt/top\n    data = create_anomalous_dataset(X, y,\n                                    REGULAR_LABEL,\n                                    ANOMALY_LABEL)\n    ```", "```\n    data = np.expand_dims(data, axis=-1)\n    data = data.astype('float32') / 255.0\n    X_train, X_test = train_test_split(data,\n                                       train_size=0.8,\n                                       random_state=SEED)\n    ```", "```\n    _, _, autoencoder = build_autoencoder(encoding_size=256)\n    autoencoder.compile(optimizer='adam', loss='mse')\n    ```", "```\n    EPOCHS = 300\n    BATCH_SIZE = 1024\n    autoencoder.fit(X_train, X_train,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    validation_data=(X_test, X_test))\n    ```", "```\n    decoded = autoencoder.predict(data)\n    mses = []\n    for original, generated in zip(data, decoded):\n        mse = np.mean((original - generated) ** 2)\n        mses.append(mse)\n    ```", "```\n    threshold = np.quantile(mses, 0.999)\n    outlier_idx = np.where(np.array(mses) >= threshold)[0]\n    print(f'Number of outliers: {len(outlier_idx)}')\n    ```", "```\n    decoded = (decoded * 255.0).astype('uint8')\n    data = (data * 255.0).astype('uint8')\n    for i in outlier_idx:\n        image = np.hstack([data[i].reshape(28, 28),\n                           decoded[i].reshape(28, 28)])\n        cv2.imwrite(f'{i}.jpg', image)\n    ```", "```\n$> pip install opencv-python\n```", "```\n    import cv2\n    import numpy as np\n    from tensorflow.keras import Model\n    from tensorflow.keras.datasets import fashion_mnist\n    from tensorflow.keras.layers import *\n    ```", "```\n    def build_autoencoder(input_shape=(28, 28, 1),\n                          encoding_size=32,\n                          alpha=0.2):\n        inputs = Input(shape=input_shape)\n        encoder = Conv2D(filters=32,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(inputs)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n        encoder = Conv2D(filters=64,\n                         kernel_size=(3, 3),\n                         strides=2,\n                         padding='same')(encoder)\n        encoder = LeakyReLU(alpha=alpha)(encoder)\n        encoder = BatchNormalization()(encoder)\n        encoder_output_shape = encoder.shape\n        encoder = Flatten()(encoder)\n        encoder_output = Dense(units=encoding_size,\n                               name='encoder_output')(encoder)\n    ```", "```\n        target_shape = tuple(encoder_output_shape[1:])\n        decoder = Dense(np.prod(target_shape))(encoder _output)\n        decoder = Reshape(target_shape)(decoder)\n        decoder = Conv2DTranspose(filters=64,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n        decoder = Conv2DTranspose(filters=32,\n                                  kernel_size=(3, 3),\n                                  strides=2,\n                                  padding='same')(decoder)\n        decoder = LeakyReLU(alpha=alpha)(decoder)\n        decoder = BatchNormalization()(decoder)\n        decoder = Conv2DTranspose(filters=1,\n                                  kernel_size=(3, 3),\n                                  padding='same')(decoder)\n        outputs = Activation(activation='sigmoid',\n\n                         name='decoder_output')(decoder)\n    ```", "```\n        autoencoder_model = Model(inputs, outputs)\n        return autoencoder_model\n    ```", "```\n    def euclidean_dist(x, y):\n        return np.linalg.norm(x - y)\n    ```", "```\n    def search(query_vector, search_index, \n               max_results=16):\n        vectors = search_index['features']\n        results = []\n        for i in range(len(vectors)):\n            distance = euclidean_dist(query_vector, \n                                       vectors[i])\n            results.append((distance, \n                           search_index['images'][i]))\n        results = sorted(results, \n                         key=lambda p: p[0])[:max_results]\n        return results\n    ```", "```\n    (X_train, _), (X_test, _) = fashion_mnist.load_data()     \n    ```", "```\n    X_train = X_train.astype('float32') / 255.0\n    X_test = X_test.astype('float32') / 255.0\n    X_train = np.expand_dims(X_train, axis=-1)\n    X_test = np.expand_dims(X_test, axis=-1)\n    ```", "```\n    autoencoder = build_autoencoder()\n    autoencoder.compile(optimizer='adam', loss='mse')\n    ```", "```\n    EPOCHS = 50\n    BATCH_SIZE = 512\n    autoencoder.fit(X_train, X_train,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    validation_data=(X_test, X_test))\n    ```", "```\n    fe_input = autoencoder.input\n    fe_output = autoencoder.get_layer('encoder_output').output\n    feature_extractor = Model(inputs=fe_input, \n                             outputs=fe_output)\n    ```", "```\n    train_vectors = feature_extractor.predict(X_train)\n    X_train = (X_train * 255.0).astype('uint8')\n    X_train = X_train.reshape((X_train.shape[0], 28, 28))\n    search_index = {\n        'features': train_vectors,\n        'images': X_train\n    }\n    ```", "```\n    test_vectors = feature_extractor.predict(X_test)\n    X_test = (X_test * 255.0).astype('uint8')\n    X_test = X_test.reshape((X_test.shape[0], 28, 28))\n    ```", "```\n    sample_indices = np.random.randint(0, X_test.shape[0],16)\n    sample_images = X_test[sample_indices]\n    sample_queries = test_vectors[sample_indices]\n    ```", "```\n    for i, (vector, image) in \\\n            enumerate(zip(sample_queries, sample_images)):\n        results = search(vector, search_index)\n        results = [r[1] for r in results]\n        query_image = cv2.resize(image, (28 * 4, 28 * 4),\n                              interpolation=cv2.INTER_AREA)\n        results_mosaic = \n                 np.vstack([np.hstack(results[0:4]),\n                            np.hstack(results[4:8]),\n                            np.hstack(results[8:12]),\n                            np.hstack(results[12:16])])\n        result_image = np.hstack([query_image, \n                                 results_mosaic])\n        cv2.imwrite(f'{i}.jpg', result_image)\n    ```", "```\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import Model\n    from tensorflow.keras import backend as K\n    from tensorflow.keras.datasets import fashion_mnist\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import mse\n    from tensorflow.keras.optimizers import Adam\n    ```", "```\n    tf.config.experimental_run_functions_eagerly(True)\n    ```", "```\n            self.z_log_var = None\n            self.z_mean = None\n    ```", "```\n            self.inputs = None\n            self.outputs = None\n            self.encoder = None\n            self.decoder = None\n            self.vae = None\n    ```", "```\n        def build_vae(self):\n            self.inputs = Input(shape=(self.original_dimension,))\n            x = Dense(self.encoding_dimension)(self.inputs)\n            x = ReLU()(x)\n            self.z_mean = Dense(self.latent_dimension)(x)\n            self.z_log_var = Dense(self.latent_dimension)(x)\n            z = Lambda(sampling)([self.z_mean, \n                                 self.z_log_var])\n            self.encoder = Model(self.inputs,\n                                 [self.z_mean, \n                                 self.z_log_var, z])\n    ```", "```\n            latent_inputs = Input(shape=(self.latent_dimension,))\n            x = Dense(self.encoding_dimension)(latent_inputs)\n            x = ReLU()(x)\n            self.outputs = Dense(self.original_dimension)(x)\n            self.outputs = Activation('sigmoid')(self.outputs)\n            self.decoder = Model(latent_inputs, \n                                 self.outputs)\n    ```", "```\n            self.outputs = self.encoder(self.inputs)[2]\n            self.outputs = self.decoder(self.outputs)\n            self.vae = Model(self.inputs, self.outputs)\n    ```", "```\n        @tf.function\n        def train(self, X_train,\n                  X_test, \n                  epochs=50, \n                  batch_size=64):\n    ```", "```\n            reconstruction_loss = mse(self.inputs, \n                                      self.outputs)\n            reconstruction_loss *= self.original_dimension\n    ```", "```\n            kl_loss = (1 + self.z_log_var -\n                       K.square(self.z_mean) -\n                       K.exp(self.z_log_var))\n            kl_loss = K.sum(kl_loss, axis=-1)\n            kl_loss *= -0.5\n            vae_loss = K.mean(reconstruction_loss + kl_loss)\n    ```", "```\n            self.vae.add_loss(vae_loss)\n            self.vae.compile(optimizer=Adam(lr=1e-3))\n            self.vae.fit(X_train,\n                         epochs=epochs,\n                         batch_size=batch_size,\n                         validation_data=(X_test, None))\n            return self.encoder, self.decoder, self.vae\n    ```", "```\n    def sampling(arguments):\n        z_mean, z_log_var = arguments\n        batch = K.shape(z_mean)[0]\n        dimension = K.int_shape(z_mean)[1]\n        epsilon = K.random_normal(shape=(batch, dimension))\n        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n    ```", "```\n    def generate_and_plot(decoder, grid_size=5):\n        cell_size = 28\n        figure_shape = (grid_size * cell_size,\n                        grid_size * cell_size)\n        figure = np.zeros(figure_shape)\n    ```", "```\n        grid_x = np.linspace(-4, 4, grid_size)\n        grid_y = np.linspace(-4, 4, grid_size)[::-1]\n    ```", "```\n        for i, z_log_var in enumerate(grid_y):\n            for j, z_mean in enumerate(grid_x):\n                z_sample = np.array([[z_mean, z_log_var]])\n                generated = decoder.predict(z_sample)[0]\n    ```", "```\n                fashion_item = \n                       generated.reshape(cell_size,\n                                        cell_size)\n                y_slice = slice(i * cell_size, \n                                (i + 1) * cell_size)\n                x_slice = slice(j * cell_size, \n                                (j + 1) * cell_size)\n                figure[y_slice, x_slice] = fashion_item\n    ```", "```\n        plt.figure(figsize=(10, 10))\n        start = cell_size // 2\n        end = (grid_size - 2) * cell_size + start + 1\n        pixel_range = np.arange(start, end, cell_size)\n        sample_range_x = np.round(grid_x, 1)\n        sample_range_y = np.round(grid_y, 1)\n        plt.xticks(pixel_range, sample_range_x)\n        plt.yticks(pixel_range, sample_range_y)\n        plt.xlabel('z_mean')\n        plt.ylabel('z_log_var')\n        plt.imshow(figure)\n        plt.show()\n    ```", "```\n    (X_train, _), (X_test, _) = fashion_mnist.load_data()\n    X_train = X_train.astype('float32') / 255.0\n    X_test = X_test.astype('float32') / 255.0\n    X_train = X_train.reshape((X_train.shape[0], -1))\n    X_test = X_test.reshape((X_test.shape[0], -1))\n    ```", "```\n    vae = VAE(original_dimension=784,\n              encoding_dimension=512,\n              latent_dimension=2)\n    vae.build_vae()\n    ```", "```\n    _, decoder_model, vae_model = vae.train(X_train, X_test, \n                                            epochs=100)\n    ```", "```\n    generate_and_plot(decoder_model, grid_size=7)\n    ```"]