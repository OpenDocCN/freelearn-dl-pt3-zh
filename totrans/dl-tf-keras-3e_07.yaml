- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unsupervised Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The book till now has focused on supervised learning and the models that learn
    via supervised learning. Starting from this chapter we will explore a less explored
    and more challenging area of unsupervised learning, self-supervised learning,
    and contrastive learning. In this chapter, we will delve deeper into some popular
    and useful unsupervised learning models. In contrast to supervised learning, where
    the training dataset consists of both the input and the desired labels, unsupervised
    learning deals with a case where the model is provided with only the input. The
    model learns the inherent input distribution by itself without any desired label
    guiding it. Clustering and dimensionality reduction are the two most commonly
    used unsupervised learning techniques. In this chapter, we will learn about different
    machine learning and neural network techniques for both. We will cover techniques
    required for clustering and dimensionality reduction, and go into the detail about
    Boltzmann machines, and finally, cover the implementation of the aforementioned
    techniques using TensorFlow. The concepts covered will be extended to build **Restricted
    Boltzmann Machines** (**RBMs**). The chapter will include:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Principal component analysis
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-means clustering
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-organizing maps
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boltzmann machines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RBMs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code files for this chapter can be found at [https://packt.link/dltfchp7](https://packt.link/dltfchp7).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Let us start with the most common and frequently used technique for dimensionality
    reduction, the principal component analysis method.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Principal component analysis
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Principal component analysis** (**PCA**) is the most popular multivariate
    statistical technique for dimensionality reduction. It analyzes the training data
    consisting of several dependent variables, which are, in general, intercorrelated,
    and extracts important information from the training data in the form of a set
    of new orthogonal variables called principal components.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: We can perform PCA using two methods, either **eigen decomposition** or **singular
    value decomposition** (**SVD**).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'PCA reduces the *n*-dimensional input data to *r*-dimensional input data, where
    *r<n*. In simple terms, PCA involves translating the origin and performing rotation
    of the axis such that one of the axes (principal axis) has the highest variance
    with data points. A reduced-dimensions dataset is obtained from the original dataset
    by performing this transformation and then dropping (removing) the orthogonal
    axes with low variance. Here, we employ the SVD method for PCA dimensionality
    reduction. Consider *X*, the *n*-dimensional data with *p* points, that is, *X*
    is a matrix of size *p × n*. From linear algebra we know that any real matrix
    can be decomposed using singular value decomposition:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_001.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: Where *U* and *V* are orthonormal matrices (that is, *U.U*^T *= V.V*^T *= 1*)
    of size *p × p* and *n × n* respectively. ![](img/B18331_07_002.png) is a diagonal
    matrix of size *p × n*. The *U* matrix is called the **left singular matrix**,
    and *V* the **right singular matrix**, and ![](img/B18331_07_002.png), the diagonal
    matrix, contains the singular values of *X* as its diagonal elements. Here we
    assume that the *X* matrix is centered. The columns of the *V* matrix are the
    principal components, and columns of ![](img/B18331_07_004.png) are the data transformed
    by principal components.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*U* 和 *V* 是正交矩阵（即 *U.U*^T *= V.V*^T *= 1*），其大小分别为 *p × p* 和 *n × n*。![](img/B18331_07_002.png)
    是一个大小为 *p × n* 的对角矩阵。*U* 矩阵称为**左奇异矩阵**，*V* 矩阵称为**右奇异矩阵**，而 ![](img/B18331_07_002.png)
    这个对角矩阵包含了 *X* 的奇异值，作为其对角元素。这里假设 *X* 矩阵是已居中的。*V* 矩阵的列是主成分，而 ![](img/B18331_07_004.png)
    的列是经过主成分变换后的数据。
- en: 'Now to reduce the dimensions of the data from *n* to *k* (where *k < n*), we
    will select the first *k* columns of *U* and the upper-left *k × k* part of ![](img/B18331_07_002.png).
    The product of the two gives us our reduced-dimensions matrix:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了将数据从 *n* 维降至 *k* 维（其中 *k < n*），我们将选择 *U* 的前 *k* 列和 ![](img/B18331_07_002.png)
    左上角的 *k × k* 部分。两者的乘积将给出我们的降维矩阵：
- en: '![](img/B18331_07_006.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_07_006.png)'
- en: The data *Y* obtained will be of reduced dimensions. Next, we implement PCA
    in TensorFlow 2.0.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的 *Y* 数据将是降维后的数据。接下来，我们将在 TensorFlow 2.0 中实现 PCA。
- en: PCA on the MNIST dataset
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 MNIST 数据集上进行 PCA
- en: 'Let us now implement PCA in TensorFlow 2.0\. We will be definitely using TensorFlow;
    we will also need NumPy for some elementary matrix calculation, and Matplotlib,
    Matplotlib toolkits, and Seaborn for plotting:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在 TensorFlow 2.0 中实现 PCA。我们一定会使用 TensorFlow；此外，我们还需要 NumPy 来进行一些基础的矩阵计算，并使用
    Matplotlib、Matplotlib 工具包以及 Seaborn 来进行绘图：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next we load the MNIST dataset. Since we are doing dimension reduction using
    PCA, we do not need a test dataset or even labels; however, we are loading labels
    so that after reduction we can verify the PCA performance. PCA should cluster
    similar data points in one cluster; hence, if we see that the clusters formed
    using PCA are similar to our labels, it would indicate that our PCA works:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载 MNIST 数据集。由于我们使用 PCA 进行降维，因此不需要测试数据集或标签；然而，我们加载标签是为了在降维后验证 PCA 的效果。PCA
    应该将相似的数据点聚集在一个簇中；因此，如果我们看到使用 PCA 形成的簇与我们的标签相似，那么这就表明我们的 PCA 有效：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Before we do PCA, we should preprocess the data. We first normalize it so that
    all data has values between 0 and 1, and then reshape the image from being a 28
    × 28 matrix to a 784-dimensional vector, and finally, center it by subtracting
    the mean:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行 PCA 之前，我们需要预处理数据。我们首先对数据进行归一化，使其值介于 0 和 1 之间，然后将图像从 28 × 28 矩阵重塑为一个 784
    维的向量，最后通过减去均值来居中数据：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now that our data is in the right format, we make use of TensorFlow’s powerful
    linear algebra (`linalg`) module to calculate the SVD of our training dataset.
    TensorFlow provides the function `svd()` defined in `tf.linalg` to perform this
    task. And then use the `diag` function to convert the sigma array (`s`, a list
    of singular values) to a diagonal matrix:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据已经是正确的格式，我们利用 TensorFlow 强大的线性代数模块 (`linalg`) 来计算训练数据集的 SVD。TensorFlow
    提供了 `svd()` 函数，定义在 `tf.linalg` 中，用来执行这个任务。然后，使用 `diag` 函数将 sigma 数组（`s`，即奇异值的列表）转换为对角矩阵：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This provides us with a diagonal matrix *s* of size 784 × 784; a left singular
    matrix *u* of size 60,000 × 784; and a right singular matrix *v* of size 784 ×
    784\. This is so because the argument `full_matrices` of the function `svd()`
    is by default set to `False`. As a result it does not generate the full *U* matrix
    (in this case, of size 60,000 × 60,000); instead, if input *X* is of size *m ×
    n*, it generates *U* of size *p = min(m,n)*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供一个大小为 784 × 784 的对角矩阵 *s*；一个大小为 60,000 × 784 的左奇异矩阵 *u*；以及一个大小为 784 ×
    784 的右奇异矩阵 *v*。这是因为函数 `svd()` 的参数 `full_matrices` 默认设置为 `False`。因此，它不会生成完整的 *U*
    矩阵（在这种情况下是 60,000 × 60,000 的矩阵）；相反，如果输入 *X* 的大小为 *m × n*，它会生成大小为 *p = min(m, n)*
    的 *U* 矩阵。
- en: 'The reduced-dimension data can now be generated by multiplying respective slices
    of *u* and *s*. We reduce our data from 784 to 3 dimensions; we can choose to
    reduce to any dimension less than 784, but we chose 3 here so that it is easier
    for us to visualize later. We make use of `tf.Tensor.getitem` to slice our matrices
    in the Pythonic way:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以通过乘以 *u* 和 *s* 的相应切片来生成降维后的数据。我们将数据从 784 维降至 3 维；我们可以选择降至任何小于 784 的维度，但这里我们选择了
    3 维，以便稍后更容易可视化。我们使用 `tf.Tensor.getitem` 以 Pythonic 方式对矩阵进行切片：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A comparison of the original and reduced data shape is done in the following
    code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, let us plot the data points in the three-dimensional space:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Chart, scatter chart, surface chart  Description automatically generated](img/B18331_07_01.png)Figure
    7.1: Scatter plot of MNIST dataset after dimensionality reduction using PCA'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the points corresponding to the same color and, hence, the
    same label are clustered together. We have therefore successfully used PCA to
    reduce the dimensions of MNIST images. Each original image was of size 28 × 28\.
    Using the PCA method we can reduce it to a smaller size. Normally for image data,
    dimensionality reduction is necessary. This is because images are large in size
    and contain a significant amount of redundant data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Embedding API
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TensorFlow also offers an Embedding API where one can find and visualize PCA
    and tSNE [1] clusters using TensorBoard. You can see the live PCA on MNIST images
    here: [http://projector.tensorflow.org](http://projector.tensorflow.org). The
    following image is reproduced for reference:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B18331_07_02.png)Figure
    7.2: A visualization of a principal component analysis, applied to the MNIST dataset'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'You can process your data using TensorBoard. It contains a tool called **Embedding
    Projector** that allows one to interactively visualize embedding. The Embedding
    Projector tool has three panels:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Panel**: It is located at the top left, and you can choose the data,
    labels, and so on in this panel.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Projections Panel**: Available at the bottom left, you can choose the type
    of projections you want here. It offers three choices: PCA, t-SNE, and custom.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inspector Panel**: On the right-hand side, here you can search for particular
    points and see a list of nearest neighbors.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Graphical user interface, chart, scatter chart  Description automatically
    generated](img/B18331_07_03.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: Screenshot of the Embedding Projector tool'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: PCA is a useful tool for visualizing datasets and for finding linear relationships
    between variables. It can also be used for clustering, outlier detection, and
    feature selection. Next, we will learn about the k-means algorithm, a method for
    clustering data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'K-means clustering, as the name suggests, is a technique to cluster data, that
    is, to partition data into a specified number of data points. It is an unsupervised
    learning technique. It works by identifying patterns in the given data. Remember
    the sorting hat of Harry Potter fame? What it is doing in the book is clustering—dividing
    new (unlabelled) students into four different clusters: Gryffindor, Ravenclaw,
    Hufflepuff, and Slytherin.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Humans are very good at grouping objects together; clustering algorithms try
    to give a similar capability to computers. There are many clustering techniques
    available, such as hierarchical, Bayesian, or partitional. K-means clustering
    belongs to partitional clustering; it partitions data into *k* clusters. Each
    cluster has a center, called the centroid. The number of clusters *k* has to be
    specified by the user.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'The k-means algorithm works in the following manner:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Randomly choose *k* data points as the initial centroids (cluster centers).
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign each data point to the closest centroid; there can be different measures
    to find closeness, the most common being the Euclidean distance.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recompute the centroids using current cluster membership, such that the sum
    of squared distances decreases.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the last two steps until convergence is met.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the previous TensorFlow versions, the `KMeans` class was implemented in the
    `Contrib` module; however, the class is no longer available in TensorFlow 2.0\.
    Here we will instead use the advanced mathematical functions provided in TensorFlow
    2.0 to implement k-means clustering.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: K-means in TensorFlow
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To demonstrate k-means in TensorFlow, we will use randomly generated data in
    the code that follows. Our randomly generated data will contain 200 samples, and
    we will divide them into three clusters. We start by importing all the required
    modules, defining the variables, and determining the number of sample points (`points_n`),
    the number of clusters to be formed (`clusters_n`), and the number of iterations
    we will be doing (`iteration_n`). We also set the seed for a random number to
    ensure that our work is reproducible:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we randomly generate data and from the data select three centroids randomly:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let us now plot the points:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can see the scatter plot of all the points and the randomly selected three
    centroids in the following graph:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B18331_07_04.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Randomly generated data, from three randomly selected centroids,
    plotted'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'We define the function `closest_centroids()` to assign each point to the centroid
    it is closest to:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We create another function `move_centroids()`. It recalculates the centroids
    such that the sum of squared distances decreases:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now we call these two functions iteratively for 100 iterations. We have chosen
    the number of iterations arbitrarily; you can increase and decrease it to see
    the effect:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let us now visualize how the centroids have changed after 100 iterations:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In *Figure 7.5*, you can see the final centroids after 100 iterations. We have
    also colored the points based on which centroid they are closest to. The yellow
    points correspond to one cluster (nearest the cross in its center), and the same
    is true for the purple and green cluster points:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_05.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: Plot of the final centroids after 100 iterations'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the `plot` command works in `Matplotlib 3.1.1` or higher versions.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding code, we decided to limit the number of clusters to three,
    but in most cases with unlabelled data, one is never sure how many clusters exist.
    One can determine the optimal number of clusters using the elbow method. The method
    is based on the principle that we should choose the cluster number that reduces
    the **sum of squared error** (**SSE**) distance. If *k* is the number of clusters,
    then as *k* increases, the SSE decreases, with SSE = 0; when *k* is equal to the
    number of data points, each point is its own cluster. It is clear we do not want
    this as our number of clusters, so when we plot the graph between SSE and the
    number of clusters, we should see a kink in the graph, like the elbow of the hand,
    which is how the method gets its name – the elbow method. The following code calculates
    the sum of squared errors for our data:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let us use the elbow method now for finding the optimum number of clusters
    for our dataset. To do that we will start with one cluster, that is, all points
    belonging to a single cluster, and increase the number of clusters sequentially.
    In the code, we increase the clusters by one, with eleven being the maximum number
    of clusters. For each cluster number value, we use the code above to find the
    centroids (and hence the clusters) and find the SSE:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Figure 7.6* shows the different cluster values for the dataset. The kink is
    clearly visible when the number of clusters is four:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_06.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.6: Plotting SSE against the number of clusters'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering is very popular because it is fast, simple, and robust. It
    also has some disadvantages, the biggest being that the user has to specify the
    number of clusters. Second, the algorithm does not guarantee global optima; the
    results can change if the initial randomly chosen centroids change. Third, it
    is very sensitive to outliers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Variations in k-means
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the original k-means algorithm each point belongs to a specific cluster (centroid);
    this is called **hard clustering**. However, we can have one point belong to all
    the clusters, with a membership function defining how much it belongs to a particular
    cluster (centroid). This is called *fuzzy clustering* or *soft clustering*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: This variation was proposed in 1973 by J. C. Dunn and later improved upon by
    J. C. Bezdek in 1981\. Though soft clustering takes longer to converge, it can
    be useful when a point is in multiple classes, or when we want to know how similar
    a given point is to different clusters.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: The accelerated k-means algorithm was created in 2003 by Charles Elkan. He exploited
    the triangle inequality relationship (that is, a straight line is the shortest
    distance between two points). Instead of just doing all distance calculations
    at each iteration, he also kept track of the lower and upper bounds for distances
    between points and centroids.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: In 2006, David Arthur and Sergei Vassilvitskii proposed the k-means++ algorithm.
    The major change they proposed was in the initialization of centroids. They showed
    that if we choose centroids that are distant from each other, then the k-means
    algorithm is less likely to converge on a suboptimal solution.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Another alternative can be that at each iteration we do not use the entire dataset,
    instead using mini-batches. This modification was proposed by David Sculey in
    2010\. Now, that we have covered PCA and k-means, we move toward an interesting
    network called self-organized network or winner-take-all units.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Self-organizing maps
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both k-means and PCA can cluster the input data; however, they do not maintain
    a topological relationship. In this section, we will consider **Self-Organizing
    Maps** (**SOMs**), sometimes known as **Kohonen networks** or **Winner-Take-All
    Units** (**WTUs**). They maintain the topological relation. SOMs are a very special
    kind of neural network, inspired by a distinctive feature of the human brain.
    In our brain, different sensory inputs are represented in a topologically ordered
    manner. Unlike other neural networks, neurons are not all connected to each other
    via weights; instead, they influence each other’s learning. The most important
    aspect of SOM is that neurons represent the learned inputs in a topographic manner.
    They were proposed by Teuvo Kohonen [7] in 1982.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'In SOMs, neurons are usually placed on the nodes of a (1D or 2D) lattice. Higher
    dimensions are also possible but are rarely used in practice. Each neuron in the
    lattice is connected to all the input units via a weight matrix. *Figure 7.7*
    shows a SOM with 6 × 8 (48 neurons) and 5 inputs. For clarity, only the weight
    vectors connecting all inputs to one neuron are shown. In this case, each neuron
    will have seven elements, resulting in a combined weight matrix of size 40 × 5:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_07.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: A self-organized map with 5 inputs and 48 neurons'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: A SOM learns via competitive learning. It can be considered as a nonlinear generalization
    of PCA and, thus, like PCA, can be employed for dimensionality reduction.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to implement SOM, let’s first understand how it works. As a first
    step, the weights of the network are initialized either to some random value or
    by taking random samples from the input. Each neuron occupying a space in the
    lattice will be assigned specific locations. Now as an input is presented, the
    neuron with the least distance from the input is declared the winner (WTU). This
    is done by measuring the distance between the weight vectors (*W*) and input vectors
    (*X*) of all neurons:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_007.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Here, *d*[j] is the distance of the weights of neuron *j* from input *X*. The
    neuron with the lowest *d* value is the winner.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Next, the weights of the winning neuron and its neighboring neurons are adjusted
    in a manner to ensure that the same neuron is the winner if the same input is
    presented next time.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'To decide which neighboring neurons need to be modified, the network uses a
    neighborhood function ![](img/B18331_07_008.png); normally, the Gaussian Mexican
    hat function is chosen as a neighborhood function. The neighborhood function is
    mathematically represented as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_009.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B18331_07_010.png) is a time-dependent radius of the influence
    of a neuron and *d* is its distance from the winning neuron. Graphically, the
    function looks like a hat (hence its name), as you can see in *Figure 7.8*:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_08.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.8: The “Gaussian Mexican hat” function, visualized in graph form'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Another important property of the neighborhood function is that its radius reduces
    with time. As a result, in the beginning, many neighboring neurons’ weights are
    modified, but as the network learns, eventually a few neurons’ weights (at times,
    only one or none) are modified in the learning process.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'The change in weight is given by the following equation:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_011.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
- en: The process is repeated for all the inputs for a given number of iterations.
    As the iterations progress, we reduce the learning rate and the radius by a factor
    dependent on the iteration number.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: SOMs are computationally expensive and thus are not really useful for very large
    datasets. Still, they are easy to understand, and they can very nicely find the
    similarity between input data. Thus, they have been employed for image segmentation
    and to determine word similarity maps in NLP.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Colour mapping using a SOM
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some of the interesting properties of the feature map of the input space generated
    by a SOM are:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: The feature map provides a good representation of the input space. This property
    can be used to perform vector quantization so that we may have a continuous input
    space, and using a SOM we can represent it in a discrete output space.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The feature map is topologically ordered, that is, the spatial location of a
    neuron in the output lattice corresponds to a particular feature of the input.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The feature map also reflects the statistical distribution of the input space;
    the domain that has the largest number of input samples gets a wider area in the
    feature map.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These features of SOM make them the natural choice for many interesting applications.
    Here we use SOM for clustering a range of given R, G, and B pixel values to a
    corresponding color map. We start with the importing of modules:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The main component of the code is our class `WTU`. The class `__init__` function
    initializes various hyperparameters of our SOM, the dimensions of our 2D lattice
    (`m, n`), the number of features in the input (`dim`), the neighborhood radius
    (`sigma`), the initial weights, and the topographic information:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The most important function of the class is the `training()` function, where
    we use the Kohonen algorithm as discussed before to find the winner units and
    then update the weights based on the neighborhood function:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `fit()` function is a helper function that calls the `training()` function
    and stores the centroid grid for easy retrieval:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit()` 函数是一个辅助函数，它调用 `training()` 函数并存储质心网格，以便于后续检索：'
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then there are some more helper functions to find the winner and generate a
    2D lattice of neurons, and a function to map input vectors to the corresponding
    neurons in the 2D lattice:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后有一些更多的辅助函数来找到胜者并生成一个二维神经元格，还有一个将输入向量映射到二维格中相应神经元的函数：
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We will also need to normalize the input data, so we create a function to do
    so:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要对输入数据进行归一化处理，因此我们创建了一个函数来实现这一操作：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let us read the data. The data contains red, green, and blue channel values
    for different colors. Let us normalize them:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们读取数据。数据包含不同颜色的红色、绿色和蓝色通道值。让我们对它们进行归一化处理：
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let us create our SOM and fit it:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建我们的自组织映射（SOM）并进行拟合：
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The fit function takes slightly longer to run, since our code is not optimized
    for performance but for explaining the concept. Now, let’s look at the result
    of the trained model. Let us run the following code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合函数运行稍微长一些，因为我们的代码并没有针对性能优化，而是为了说明概念。现在，让我们看看训练模型的结果。让我们运行以下代码：
- en: '[PRE25]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You can see the color map in the 2D neuron lattice:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到二维神经元格中的彩色图：
- en: '![](img/B18331_07_09.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_07_09.png)'
- en: 'Figure 7.9: A plotted color map of the 2D neuron lattice'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9：二维神经元格的彩色映射图
- en: You can see that neurons that win for similar colors are closely placed. Next,
    we move to an interesting architecture, the restricted Boltzmann machines.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，对于相似颜色的神经元，它们会被紧密地放置在一起。接下来，我们进入一个有趣的架构——限制玻尔兹曼机（RBM）。
- en: Restricted Boltzmann machines
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机（RBM）
- en: The RBM is a two-layered neural network—the first layer is called the **visible
    layer** and the second layer is called the **hidden layer**. They are called **shallow
    neural networks** because they are only two layers deep. They were first proposed
    in 1986 by Paul Smolensky (he called them Harmony Networks [1]) and later by Geoffrey
    Hinton who in 2006 proposed **Contrastive Divergence** (**CD**) as a method to
    train them. All neurons in the visible layer are connected to all the neurons
    in the hidden layer, but there is a **restriction**—no neuron in the same layer
    can be connected. All neurons in the RBM are binary by nature; they will either
    fire or not fire.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 是一个两层的神经网络——第一层称为 **可见层**，第二层称为 **隐藏层**。它们被称为 **浅层神经网络**，因为它们只有两层深。最早由 Paul
    Smolensky 于1986年提出（他称其为和谐网络 [1]），后由 Geoffrey Hinton 在2006年提出 **对比散度**（**CD**）作为训练方法。可见层的所有神经元都与隐藏层的所有神经元相连，但存在一个
    **限制**——同一层中的神经元不能相连。RBM 中的所有神经元本质上是二值的；它们要么激活，要么不激活。
- en: 'RBMs can be used for dimensionality reduction, feature extraction, and collaborative
    filtering. The training of RBMs can be divided into three parts: forward pass,
    backward pass, and then a comparison.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 可以用于降维、特征提取和协同过滤。RBM 的训练可以分为三个部分：前向传播、反向传播，然后进行比较。
- en: 'Let us delve deeper into the math. We can divide the operation of RBMs into
    two passes:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地研究一下数学原理。我们可以将 RBM 的操作分为两次传播：
- en: '**Forward pass**: The information at visible units (*V*) is passed via weights
    (*W*) and biases (*c*) to the hidden units (*h*[0]). The hidden unit may fire
    or not depending on the stochastic probability (![](img/B18331_07_010.png) is
    the stochastic probability), which is basically the sigmoid function:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**前向传播**：可见单元（*V*）的信息通过权重（*W*）和偏置（*c*）传递到隐藏单元（*h*[0]）。隐藏单元是否激活取决于随机概率（![](img/B18331_07_010.png)
    是随机概率），该概率基本上是一个 Sigmoid 函数：'
- en: '![](img/B18331_07_013.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_07_013.png)'
- en: '**Backward pass**: The hidden unit representation (*h*[0]) is then passed back
    to the visible units through the same weights, *W*, but a different bias, *c*,
    where the model reconstructs the input. Again, the input is sampled:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**反向传播**：然后，隐藏单元表示（*h*[0]）通过相同的权重 *W* 传回可见单元，但使用不同的偏置 *c*，此时模型重建输入。同样，输入会被采样：'
- en: '![](img/B18331_07_014.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_07_014.png)'
- en: These two passes are repeated for *k* steps or until the convergence [4] is
    reached. According to researchers, *k=1* gives good results, so we will keep *k
    = 1*.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这两次传播会重复 *k* 步骤，或者直到收敛[4]达到为止。根据研究人员的说法，*k=1* 已经能够得到良好的结果，所以我们将设置 *k = 1*。
- en: 'The joint configuration of the visible vector *V* and the hidden vector *h*
    has energy given as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 可见向量 *V* 和隐藏向量 *h* 的联合配置具有如下能量：
- en: '![](img/B18331_07_015.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_07_015.png)'
- en: 'Also associated with each visible vector *V* is free energy, the energy that
    a single configuration would need to have in order to have the same probability
    as all of the configurations that contain *V*:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_016.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: 'Using the contrastive divergence objective function, that is, *Mean(F(V*[original]*))
    - Mean(F(V*[reconstructed]*))*, the change in weights is given by:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_017.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B18331_01_025.png) is the learning rate. Similar expressions exist
    for the biases *b* and *c*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Reconstructing images using an RBM
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us build an RBM in TensorFlow. The RBM will be designed to reconstruct
    handwritten digits. This is the first generative model that you are learning;
    in the upcoming chapters, we will learn a few more. We import the TensorFlow,
    NumPy, and Matplotlib libraries:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We define a class `RBM`. The class `__init_()` function initializes the number
    of neurons in the visible layer (`input_size`) and the number of neurons in the
    hidden layer (`output_size`). The function initializes the weights and biases
    for both hidden and visible layers. In the following code, we have initialized
    them to zero. You can try with random initialization as well:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We define methods to provide the forward and backward passes:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We create a function to generate random binary values. This is because both
    hidden and visible units are updated using stochastic probability, depending upon
    the input to each unit in the case of the hidden layer (and the top-down input
    to visible layers):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We will need functions to reconstruct the input:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To train the RBM created we define the `train()` function. The function calculates
    the positive and negative gradient terms of contrastive divergence and uses the
    weight update equation to update the weights and biases:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now that our class is ready, we instantiate an object of `RBM` and train it
    on the MNIST dataset:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let us plot the learning curve:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In the figure below, you can see the learning curve of our RBM:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_10.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: Learning curve for the RBM model'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we present the code to visualize the reconstructed images:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'And the reconstructed images:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_07_11.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.11: Image reconstruction using an RBM'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: The top row is the input handwritten image, and the bottom row is the reconstructed
    image. You can see that the images look remarkably similar to the human handwritten
    digits. In the upcoming chapters, you will learn about models that can generate
    even more complex images such as artificial human faces.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Deep belief networks
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a good understanding of RBMs and know how to train them using
    contrastive divergence, we can move toward the first successful deep neural network
    architecture, the **deep belief networks** (**DBNs**), proposed in 2006 by Hinton
    and his team in the paper *A fast learning algorithm for deep belief nets*. Before
    this model it was very difficult to train deep architectures, not just because
    of the limited computing resources, but also, as will be discussed in *Chapter
    8*, *Autoencoders*, because of the vanishing gradient problem. In DBNs it was
    first demonstrated how deep architectures can be trained via greedy layer-wise
    training.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: In the simplest terms, DBNs are just stacked RBMs. Each RBM is trained separately
    using the contrastive divergence. We start with the training of the first RBM
    layer. Once it is trained, we train the second RBM layer. The visible units of
    the second RBM are now fed the output of the hidden units of the first RBM, when
    it is fed the input data. The procedure is repeated with each RBM layer addition.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us try stacking our `RBM` class. To make the DBN, we will need to define
    one more function in the `RBM` class; the output of the hidden unit of one RBM
    needs to feed into the next RBM:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now we can just use the `RBM` class to create a stacked RBM structure. In the
    following code we create an RBM stack: the first RBM will have 500 hidden units,
    the second will have 200 hidden units, and the third will have 50 hidden units:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'For the first RBM, the MNIST data is the input. The output of the first RBM
    is then fed as input to the second RBM, and so on through the consecutive RBM
    layers:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Our DBN is ready. The three stacked RBMs are now trained using unsupervised
    learning. DBNs can also be trained using supervised training. To do so we need
    to fine-tune the weights of the trained RBMs and add a fully connected layer at
    the end. In their publication *Classification with Deep Belief Networks*, Hebbo
    and Kim show how they used a DBN for MNIST classification; it is a good introduction
    to the subject.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the major unsupervised learning algorithms. We went
    through algorithms best suited for dimension reduction, clustering, and image
    reconstruction. We started with the dimension reduction algorithm PCA, then we
    performed clustering using k-means and self-organized maps. After this we studied
    the restricted Boltzmann machine and saw how we can use it for both dimension
    reduction and image reconstruction. Next, we delved into stacked RBMs, that is,
    deep belief networks, and we trained a DBN consisting of three RBM layers on the
    MNIST dataset.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore another model using an unsupervised learning
    paradigm – autoencoders.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Smith, Lindsay. (2006). *A tutorial on Principal Component Analysis*: [http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf](http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf)'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Movellan, J. R. *Tutorial on Principal component Analysis*: [http://mplab.ucsd.edu/tutorials/pca.pdf](http://mplab.ucsd.edu/tutorials/pca.pdf)'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'TensorFlow Projector: [http://projector.tensorflow.org/](http://projector.tensorflow.org/)'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Singular Value Decomposition** (**SVD**) tutorial. MIT: [https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm](https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm)'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Shlens, Jonathon. (2014). *A tutorial on principal component analysis*. arXiv
    preprint arXiv:1404.1100: [https://arxiv.org/abs/1404.1100](https://arxiv.org/abs/1404.1100)'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Goodfellow, I., Bengio, Y., and Courville, A. (2016). *Deep learning*. MIT
    press: [https://www.deeplearningbook.org](https://www.deeplearningbook.org)'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kohonen, T. (1982). *Self-organized formation of topologically correct feature
    maps*. Biological cybernetics 43, no. 1: 59-69.'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kanungo, Tapas, et al. (2002). *An Efficient k-Means Clustering Algorithm:
    Analysis and Implementation*. IEEE transactions on pattern analysis and machine
    intelligence 24.7: 881-892.'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ortega, Joaquín Pérez, et al. *Research issues on K-means Algorithm: An Experimental
    Trial Using Matlab*. CEUR Workshop Proceedings: Semantic Web and New Technologies.'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Chen, K. (2009). *On Coresets for k-Median and k-Means Clustering in Metric
    and Euclidean Spaces and Their Applications.* SIAM Journal on Computing 39.3:
    923-947.'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Determining the number of clusters in a data set*: [https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set)'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Lloyd, S. P. (1982). *Least Squares Quantization in PCM*: [http://mlsp.cs.cmu.edu/courses/fall2010/class14/lloyd.pdf](http://mlsp.cs.cmu.edu/courses/fall2010/class14/lloyd.pdf)'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Dunn, J. C. (1973-01-01). *A Fuzzy Relative of the ISODATA Process and Its
    Use in Detecting Compact Well-Separated Clusters*. Journal of Cybernetics. 3(3):
    32–57.'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bezdek, James C. (1981). *Pattern Recognition with Fuzzy Objective Function
    Algorithms*.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Peters, G., Crespo, F., Lingras, P., and Weber, R. (2013). *Soft clustering–Fuzzy
    and rough approaches and their extensions and derivatives*. International Journal
    of Approximate Reasoning 54, no. 2: 307-322.'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sculley, D. (2010). *Web-scale k-means clustering*. In Proceedings of the 19th
    international conference on World wide web, pp. 1177-1178\. ACM.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Smolensky, P. (1986). *Information Processing in Dynamical Systems: Foundations
    of Harmony Theory*. No. CU-CS-321-86\. COLORADO UNIV AT BOULDER DEPT OF COMPUTER
    SCIENCE.'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Salakhutdinov, R., Mnih, A., and Hinton, G. (2007). *Restricted Boltzmann Machines
    for Collaborative Filtering*. Proceedings of the 24th international conference
    on Machine learning. ACM.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Hinton, G. (2010). *A Practical Guide to Training Restricted Boltzmann Machines*.
    Momentum 9.1: 926.'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 2000 members at: [https://packt.link/keras](https://packt.link/keras)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1831217224278819687.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
