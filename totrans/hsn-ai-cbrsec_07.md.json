["```\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.linear_model import *\nfrom sklearn.tree import *\nfrom sklearn.naive_bayes import *\nfrom sklearn.neighbors import *\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Load the data\ndataset = pd.read_csv('../datasets/network-logs.csv')\n\nsamples = dataset.iloc[:, [1, 2]].values\ntargets = dataset['ANOMALY'].values\n\ntraining_samples, testing_samples, training_targets, testing_targets =\ntrain_test_split(samples, targets, test_size=0.3, random_state=0)\n\n# k-Nearest Neighbors model\nknc = KNeighborsClassifier(n_neighbors=2)\nknc.fit(training_samples,training_targets)\nknc_prediction = knc.predict(testing_samples)\nknc_accuracy = 100.0 * accuracy_score(testing_targets, knc_prediction)\nprint (\"K-Nearest Neighbours accuracy: \" + str(knc_accuracy))\n\nK-Nearest Neighbours accuracy: 95.90163934426229\n\n# Decision tree model\ndtc = DecisionTreeClassifier(random_state=0)\ndtc.fit(training_samples,training_targets)\ndtc_prediction = dtc.predict(testing_samples)\ndtc_accuracy = 100.0 * accuracy_score(testing_targets, dtc_prediction)\nprint (\"Decision Tree accuracy: \" + str(dtc_accuracy))\n\nDecision Tree accuracy: 96.72131147540983\n\n# Gaussian Naive Bayes model\ngnb = GaussianNB()\ngnb.fit(training_samples,training_targets)\ngnb_prediction = gnb.predict(testing_samples)\ngnb_accuracy = 100.0 * accuracy_score(testing_targets, gnb_prediction)\nprint (\"Gaussian Naive Bayes accuracy: \" + str(gnb_accuracy))\n\nGaussian Naive Bayes accuracy: 98.36065573770492\n```", "```\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndataset = pd.read_csv('../datasets/network-logs.csv')\n```", "```\nhist_dist = dataset[['LATENCY', 'THROUGHPUT']].hist(grid=False, figsize=(10,4))\n```", "```\ndata = dataset[['LATENCY', 'THROUGHPUT']].values\n\nplt.scatter(data[:, 0], data[:, 1], alpha=0.6)\nplt.xlabel('LATENCY')\nplt.ylabel('THROUGHPUT')\nplt.title('DATA FLOW')\nplt.show()\n```", "```\n\"\"\"\nAnomaly Detection Module\nThanks to Oleksii Trekhleb:\nhttps://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/anomaly_detection/gaussian_anomaly_detection.py\n\"\"\"\nfrom gaussian_anomaly_detection import GaussianAnomalyDetection\n\ngaussian_anomaly_detection = GaussianAnomalyDetection(data)\n\nprint('mu param estimation: ')\nprint(gaussian_anomaly_detection.mu_param)\n\nprint('\\n')\n\nprint('sigma squared estimation: ')\nprint(gaussian_anomaly_detection.sigma_squared)\n\nmu param estimation:  \n[14.42070163 15.39209133]\n\nsigma squared estimation: \n[2.09674794 1.37224807]\n```", "```\ntargets = dataset['ANOMALY'].values.reshape((data.shape[0], 1))\nprobs = gaussian_anomaly_detection.multivariate_gaussian(data)\n\n(threshold, F1, precision_, recall_, f1_) =\ngaussian_anomaly_detection.select_threshold(targets, probs)\n\nprint('\\n')\n\nprint('threshold estimation: ')\nprint(threshold)\n\nthreshold estimation: \n0.00027176836728971885\n```", "```\noutliers = np.where(probs < threshold)[0]\nplt.scatter(data[:, 0], data[:, 1], alpha=0.6, label='Dataset')\nplt.xlabel('LATENCY')\nplt.ylabel('THROUGHPUT')\nplt.title('DATA FLOW')\n\nplt.scatter(data[outliers, 0], data[outliers, 1], alpha=0.6, c='red', label='Outliers')\n\nplt.legend()\nplt.plot()\n```", "```\nSensitivity or True Positive Rate (TPR) = True Positive / (True Positive + False Negative);\n```", "```\nFalse Positive Rate (FPR) = False Positive / (False Positive + True Negative);\n\nPrecision = True Positive / (True Positive + False Positive);\n```", "```\nF1 = 2 * Precision * Sensitivity / (Precision + Sensitivity);\n```", "```\nprint('F1 score: ')\nprint(F1)\n\nF1 score: \n0.6666666666666666\n```", "```\nfrom sklearn.metrics import roc_curve\n\nFPR, TPR, OPC = roc_curve(targets, probs)\n```", "```\n# Plotting Sensitivity\n\nplt.plot(OPC,TPR)\n```", "```\n# Plotting ROC curve\n\nplt.plot(FPR,TPR)\n```"]