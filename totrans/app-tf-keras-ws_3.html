<html><head></head><body>
		<div>
			<div id="_idContainer059" class="Content">
			</div>
		</div>
		<div id="_idContainer060" class="Content">
			<h1 id="_idParaDest-68"><a id="_idTextAnchor069"/>3. Real-World Deep Learning: Evaluating the Bitcoin Model</h1>
		</div>
		<div id="_idContainer081" class="Content">
			<p class="callout-heading"><a id="_idTextAnchor070"/>Overview</p>
			<p class="callout">This chapter focuses on how to evaluate a neural network model. We'll modify the network's hyperparameters to improve its performance. However, before altering any parameters, we need to measure how the model performs. By the end of this chapter, you will be able to evaluate a model using different functions and techniques. You will also learn about hypermeter optimization by implementing functions and regularization strategies.</p>
			<h1 id="_idParaDest-69"><a id="_idTextAnchor071"/>Introduction</h1>
			<p>In the previous chapter, you trained your model. But how will you check its performance and whether it is performing well or not? Let's find out by evaluating a model. In machine learning, it is common to define two distinct terms: <strong class="bold">parameter</strong> and <strong class="bold">hyperparameter</strong>. Parameters are properties that affect how a model makes predictions from data, say from a particular dataset. Hyperparameters refer to how a model learns from data. Parameters can be learned from the data and modified dynamically. Hyperparameters, on the other hand, are higher-level properties defined before the training begins and are not typically learned from data. In this chapter, you will learn about these factors in detail and understand how to use them with different evaluation techniques to improve the performance of a model.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For a more detailed overview of machine learning, refer to <em class="italic">Python Machine Learning</em>, <em class="italic">Sebastian Raschka and Vahid Mirjalili, Packt Publishing, 2017)</em>.</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor072"/>Problem Categories</h2>
			<p>Generally, there are two categories of problems that can be solved by neural networks: <strong class="bold">classification</strong> and <strong class="bold">regression</strong>. Classification problems concern the prediction of the right categories from data—for instance, whether the temperature is hot or cold. Regression problems are about the prediction of values in a continuous scalar—for instance, what the actual temperature value is.</p>
			<p>The problems in these two categories are characterized by the following properties:</p>
			<ul>
				<li><strong class="bold">Classification</strong>: These are problems that are characterized by categories. The categories can be different, or not. They can also be about a binary problem, where the outcome can either be <strong class="source-inline">yes</strong> or <strong class="source-inline">no</strong>. However, they must be clearly assigned to each data element. An example of a classification problem would be to assign either the <strong class="source-inline">car</strong> or <strong class="source-inline">not a car</strong> labels to an image using a convolutional neural network. The MNIST example we explored in <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Neural Networks and Deep Learning</em>, is another example of a classification problem.</li>
				<li><strong class="bold">Regression</strong>: These are problems that are characterized by a continuous variable (that is, a scalar). They are measured in terms of ranges, and their evaluations consider how close to the real values the network is. An example is a time-series classification problem in which a recurrent neural network is used to predict the future temperature values. The Bitcoin price-prediction problem is another example of a regression problem.</li>
			</ul>
			<p>While the overall structure of how to evaluate these models is the same for both of these problem categories, we employ different techniques to evaluate how models perform. In the next section, we'll explore these techniques for either classification or regression problems.</p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor073"/>Loss Functions, Accuracy, and Error Rates</h2>
			<p>Neural networks utilize functions that measure how the networks perform compared to a <strong class="bold">validation set</strong>—that is, a part of the data that is kept separate to be used as part of the training process. These functions are called <strong class="bold">loss functions</strong>.</p>
			<p>Loss functions evaluate how wrong a neural network's predictions are. Then, they propagate those errors back and make adjustments to the network, modifying how individual neurons are activated. Loss functions are key components of neural networks, and choosing the right loss function can have a significant impact on how the network performs. Errors are propagated through a process called <strong class="bold">backpropagation</strong>, which is a technique for propagating the errors that are returned by the loss function to each neuron in a neural network. Propagated errors affect how neurons activate, and ultimately, how they influence the output of that network.</p>
			<p>Many neural network packages, including Keras, use this technique by default.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For more information about the mathematics of backpropagation, please refer to <em class="italic">Deep Learning</em> by <em class="italic">Ian Goodfellow et. al., MIT Press, 2016</em>.</p>
			<p>We use different loss functions for regression and classification problems. For classification problems, we use accuracy functions (that is, the proportion of the number of times the predictions were correct to the number of times predictions were made). For example, if you predict a toss of a coin that will result in <em class="italic">m</em> times as heads when you toss it <em class="italic">n</em> times and your prediction is correct, then the accuracy will be calculated as <em class="italic">m/n</em>. For regression problems, we use error rates (that is, how close the predicted values were to the observed ones).</p>
			<p>Here's a summary of common loss functions that can be utilized, alongside their common applications:</p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B15911_03_01.jpg" alt="Figure 3.1: Common loss functions used for classification and regression problems&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1: Common loss functions used for classification and regression problems</p>
			<p>For regression problems, the MSE function is the most common choice, while for classification problems, binary cross-entropy (for binary category problems) and categorical cross-entropy (for multi-category problems) are common choices. It is advised to start with these loss functions, then experiment with other functions as you evolve your neural network, aiming to gain performance.</p>
			<p>The network we developed in <em class="italic">Chapter 2</em>, <em class="italic">Real-World Deep Learning with TensorFlow and Keras: Predicting the Price of Bitcoin</em>, uses MSE as its loss function. In the next section, we'll explore how that function performs as the network trains.</p>
			<h2 id="_idParaDest-72"><a id="_idTextAnchor074"/>Different Loss Functions, Same Architecture</h2>
			<p>Before moving ahead to the next section, let's explore, in practical terms, how these problems are different in the context of neural networks.</p>
			<p>The <em class="italic">TensorFlow Playground</em> (<a href="https://playground.tensorflow.org/">https://playground.tensorflow.org/</a>) application has been made available by the TensorFlow team to help us understand how neural networks work. Here, we can see a neural network represented with its layers: input (on the left), hidden layers (in the middle), and output (on the right).</p>
			<p class="callout-heading">Note:</p>
			<p class="callout">These images can be viewed in the repository on GitHub at: <a href="https://packt.live/2Cl1t0H">https://packt.live/2Cl1t0H</a>.</p>
			<p>We can also choose different sample datasets to experiment with on the far left-hand side. And, finally, on the far right-hand side, we can see the output of the network:</p>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="image/B15911_03_02.jpg" alt="Figure 3.2: TensorFlow Playground web application&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2: TensorFlow Playground web application</p>
			<p>Take the parameters for a neural network shown in this visualization to gain an idea of how each parameter affects the model's results. This application helps us explore the different problem categories we discussed in the previous section. When we choose <strong class="source-inline">Regression</strong> (upper right-hand corner), the colors of the dots are colored in a range of color values between orange and blue:</p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B15911_03_03.jpg" alt="Figure 3.3: Regression problem example in TensorFlow Playground&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3: Regression problem example in TensorFlow Playground</p>
			<p>When we choose <strong class="source-inline">Classification</strong> as the <strong class="source-inline">Problem type</strong>, the dots in the dataset are colored with only two color values: either blue or orange. When working on classification problems, the network evaluates its loss function based on how many blues and oranges the network has gotten wrong. It checks how far away to the right the color values are for each dot in the network, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B15911_03_04.jpg" alt="Figure 3.4: Details of the TensorFlow Playground application. Different colors are assigned to different classes in classification problems&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4: Details of the TensorFlow Playground application. Different colors are assigned to different classes in classification problems</p>
			<p>After clicking on the play button, we notice that the numbers in the <strong class="source-inline">Training loss</strong> area keep going down as the network continuously trains. The numbers are very similar in each problem category because the loss functions play the same role in both neural networks.</p>
			<p>However, the actual loss function that's used for each category is different and is chosen depending on the problem type.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor075"/>Using TensorBoard</h2>
			<p>Evaluating neural networks is where TensorBoard excels. As we explained in <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Neural Networks and Deep Learning</em>, TensorBoard is a suite of visualization tools that's shipped with TensorFlow. Among other things, we can explore the results of loss function evaluations after each epoch. A great feature of TensorBoard is that we can organize the results of each run separately and compare the resulting loss function metrics for each run. We can then decide on which hyperparameters to tune and have a general sense of how the network is performing. The best part is that this is all done in real time.</p>
			<p>In order to use TensorBoard with our model, we will use Keras' <strong class="source-inline">callback</strong> function. We do this by importing the TensorBoard <strong class="source-inline">callback</strong> and passing it to our model when calling its <strong class="source-inline">fit()</strong> function. The following code shows an example of how this would be implemented in the Bitcoin model we created in the <em class="italic">Chapter 2</em>, <em class="italic">Real-World Deep Learning with TensorFlow and Keras: Predicting the Price of Bitcoin</em>:</p>
			<p class="source-code">from tensorflow.keras.callbacks import TensorBoard</p>
			<p class="source-code">model_name = 'bitcoin_lstm_v0_run_0'</p>
			<p class="source-code">tensorboard = TensorBoard(log_dir='logs\\{}'.format(model_name)) \</p>
			<p class="source-code">                          model.fit(x=X_train, y=Y_validate, \</p>
			<p class="source-code">                          batch_size=1, epochs=100, verbose=0, \</p>
			<p class="source-code">                          callbacks=[tensorboard])</p>
			<p>Keras <strong class="source-inline">callback</strong> functions are called at the end of each epoch run. In this case, Keras calls the TensorBoard <strong class="source-inline">callback</strong> to store the results from each run on the disk. There are many other useful <strong class="source-inline">callback</strong> functions available, and you can create custom ones using the Keras API.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Please refer to the Keras callback documentation (<a href="https://keras.io/callbacks/">https://keras.io/callbacks/</a>) for more information.</p>
			<p>After implementing the TensorBoard callback, the loss function metrics are now available in the TensorBoard interface. You can now run a TensorBoard process (with <strong class="source-inline">tensorboard --logdir=./logs</strong>) and leave it running while you train your network with <strong class="source-inline">fit()</strong>. </p>
			<p>The main graphic to evaluate is typically called loss. We can add more metrics by passing known metrics to the metrics parameter in the <strong class="source-inline">fit()</strong> function. These will then be available for visualization in TensorBoard, but will not be used to adjust the network weights. The interactive graphics will continue to update in real time, which allows you to understand what is happening on every epoch. In the following screenshot, you can see a TensorBoard instance showing loss function results, alongside other metrics that have been added to the metrics parameter:</p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B15911_03_05.jpg" alt="Figure 3.5: Screenshot of a TensorBoard instance showing the loss function results&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5: Screenshot of a TensorBoard instance showing the loss function results</p>
			<p>In the next section, we will talk more about how to implement the different metrics we discussed in this section.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor076"/>Implementing Model Evaluation Metrics</h2>
			<p>In both regression and classification problems, we split the input dataset into three other datasets: train, validation, and test. Both the train and the validation sets are used to train the network. The train set is used by the network as input, while the validation set is used by the loss function to compare the output of the neural network to the real data and compute how wrong the predictions are. Finally, the test set is used after the network has been trained to measure how the network can perform on data it has never seen before.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">There isn't a clear rule for determining how the train, validation, and test datasets must be divided. It is a common approach to divide the original dataset into 80 percent train and 20 percent test, then to further divide the train dataset into 80 percent train and 20 percent validation. For more information about this problem, please refer to <em class="italic">Python Machine Learning</em>, by <em class="italic">Sebastian Raschka and Vahid Mirjalili (Packt Publishing, 2017)</em>.</p>
			<p>In classification problems, you pass both the data and the labels to the neural network as related but distinct data. The network then learns how the data is related to each label. In regression problems, instead of passing data and labels, we pass the variable of interest as one parameter and the variables that are used for learning patterns as another. Keras provides an interface for both of those use cases with the <strong class="source-inline">fit()</strong> method. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">The <strong class="source-inline">fit()</strong> method can use either the <strong class="source-inline">validation_split</strong> or the <strong class="source-inline">validation_data</strong> parameter, but not both at the same time.</p>
			<p>See the following snippet to understand how to use the <strong class="source-inline">validation_split</strong> and <strong class="source-inline">validation_data</strong> parameters:</p>
			<p class="source-code">model.fit(x=X_train, y=Y_ train, \</p>
			<p class="source-code">          batch_size=1, epochs=100, verbose=0, \</p>
			<p class="source-code">          callbacks=[tensorboard], validation_split=0.1, \</p>
			<p class="source-code">          validation_data=(X_validation, Y_validation))</p>
			<p><strong class="source-inline">X_train</strong>: features from training set</p>
			<p><strong class="source-inline">Y_train</strong>: labels from training set</p>
			<p><strong class="source-inline">batch_size</strong>: the size of one batch</p>
			<p><strong class="source-inline">epochs</strong>: the number of iterations</p>
			<p><strong class="source-inline">verbose</strong>: the level of output you want</p>
			<p><strong class="source-inline">callbacks</strong>: call a function after every epoch</p>
			<p><strong class="source-inline">validation_split</strong>: validation percentage split if you have not created it explicitly</p>
			<p><strong class="source-inline">validation_data</strong>: validation data if you have created it explicitly</p>
			<p>Loss functions evaluate the progress of models and adjust their weights on every run. However, loss functions only describe the relationship between training data and validation data. In order to evaluate if a model is performing correctly, we typically use a third set of data—which is not used to train the network—and compare the predictions made by our model to the values available in that set of data. That is the role of the test set.</p>
			<p>Keras provides the <strong class="source-inline">model.evaluate()</strong> method, which makes the process of evaluating a trained neural network against a test set easy. The following code illustrates how to use the <strong class="source-inline">evaluate()</strong> method:</p>
			<p class="source-code">model.evaluate(x=X_test, y=Y_test)</p>
			<p>The <strong class="source-inline">evaluate()</strong> method returns both the results of the loss function and the results of the functions passed to the <strong class="source-inline">metrics</strong> parameter. We will be using that function frequently in the Bitcoin problem to test how the model performs on the test set.</p>
			<p>You will notice that the Bitcoin model we trained previously looks a bit different than this example. That is because we are using an LSTM architecture. LSTMs are designed to predict sequences.</p>
			<p>Because of that, we do not use a set of variables to predict a different single variable—even if it is a regression problem. Instead, we use previous observations from a single variable (or set of variables) to predict future observations of that same variable (or set). The <strong class="source-inline">y</strong> parameter on <strong class="source-inline">keras.fit()</strong> contains the same variable as the <strong class="source-inline">x</strong> parameter, but only the predicted sequences. So, let's have a look at how to evaluate the bitcoin model we trained previously.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor077"/>Evaluating the Bitcoin Model</h2>
			<p>We created a test set during our activities in <em class="italic">Chapter 1</em>, <em class="italic">Introduction to Neural Networks and Deep Learning</em>. That test set contains 21 weeks of daily Bitcoin price observations, which is equivalent to about 10 percent of the original dataset.</p>
			<p>We also trained our neural network using the other 90 percent of data (that is, the train set with 187 weeks of data, minus 1 for the validation set) in <em class="italic">Chapter 2</em>, <em class="italic">Real-World Deep Learning with TensorFlow and Keras: Predicting the Price of Bitcoin</em>, and stored the trained network on disk (<strong class="source-inline">bitcoin_lstm_v0</strong>). We can now use the <strong class="source-inline">evaluate()</strong> method in each of the 21 weeks of data from the test set and inspect how that first neural network performs.</p>
			<p>In order to do that, though, we have to provide 186 preceding weeks. We have to do this because our network has been trained to predict one week of data using exactly 186 weeks of continuous data (we will deal with this behavior by retraining our network periodically with larger periods in <em class="italic">Chapter 4</em>, <em class="italic">Productization</em>, when we deploy a neural network as a web application). The following snippet implements the <strong class="source-inline">evaluate()</strong> method to evaluate the performance of our model in a test dataset:</p>
			<p class="source-code">combined_set = np.concatenate((train_data, test_data), axis=1) \</p>
			<p class="source-code">               evaluated_weeks = []</p>
			<p class="source-code">for i in range(0, validation_data.shape[1]):</p>
			<p class="source-code">    input_series = combined_set[0:,i:i+187]</p>
			<p class="source-code">X_test = input_series[0:,:-1].reshape(1, \</p>
			<p class="source-code">         input_series.shape[1] – 1, ) \</p>
			<p class="source-code">         Y_test = input_series[0:,-1:][0]</p>
			<p class="source-code">result = B.model.evaluate(x=X_test, y=Y_test, verbose=0) \</p>
			<p class="source-code">         evaluated_weeks.append(result)</p>
			<p>In the preceding code, we evaluate each week using Keras' <strong class="source-inline">model.evaluate()</strong> method, then store its output in the <strong class="source-inline">evaluated_weeks</strong> variable. We then plot the resulting MSE for each week, as shown in the following plot:</p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B15911_03_06.jpg" alt="Figure 3.6: MSE for each week in the test set&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6: MSE for each week in the test set</p>
			<p>The resulting MSE from our model suggests that our model performs well during most weeks, except for weeks 2, 8, 12, and 16, when its value increases from about 0.005 to 0.02. Our model seems to be performing well for almost all of the other test weeks.</p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor078"/>Overfitting</h2>
			<p>Our first trained network (<strong class="source-inline">bitcoin_lstm_v0</strong>) may be suffering from a phenomenon known as <strong class="bold">overfitting</strong>. Overfitting is when a model is trained to optimize a validation set, but it does so at the expense of more generalizable patterns from the phenomenon we are interested in predicting. The main issue with overfitting is that a model learns how to predict the validation set, but fails to predict new data.</p>
			<p>The loss function we used in our model reaches very low levels at the end of our training process. Not only that, but this happens early: the MSE loss function that's used to predict the last week in our data decreases to a stable plateau around epoch 30. This means that our model is predicting the data from week 187 almost perfectly, using the preceding 186 weeks. Could this be the result of overfitting?</p>
			<p>Let's look at the preceding plot again. We know that our LSTM model reaches extremely low values in our validation set (about 2.9 × 10<span class="superscript">-6</span>), yet it also reaches low values in our test set. The key difference, however, is in the scale. The MSE for each week in our test set is about 4,000 times bigger (on average) than in the test set. This means that the model is performing much worse in our test data than in the validation set. This is worth considering.</p>
			<p>The scale, though, hides the power of our LSTM model; even performing much worse in our test set, the predictions' MSE errors are still very, very low. This suggests that our model may be learning patterns from the data.</p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor079"/>Model Predictions</h2>
			<p>It's one thing is to measure our model comparing MSE errors, and another to be able to interpret its results intuitively.</p>
			<p>Using the same model, let's create a series of predictions for the following weeks, using 186 weeks as input. We do that by sliding a window of 186 weeks over the complete series (that is, train plus test sets) and making predictions for each of those windows.</p>
			<p>The following snippet makes predictions for all the weeks of the test dataset using the <strong class="source-inline">Keras model.predict()</strong> method:</p>
			<p class="source-code">combined_set = np.concatenate((train_data, test_data), \</p>
			<p class="source-code">               axis=1) predicted_weeks = []</p>
			<p class="source-code">for i in range(0, validation_data.shape[1] + 1): </p>
			<p class="source-code">    input_series = combined_set[0:,i:i+186]</p>
			<p class="source-code">    predicted_weeks.append(B.predict(input_series))</p>
			<p>In the preceding code, we make predictions using the <strong class="source-inline">model.predict()</strong> method, then store these predictions in the <strong class="source-inline">predicted_weeks</strong> variable. Then, we plot the resulting predictions, making the following plot:</p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B15911_03_07.jpg" alt="Figure 3.7: MSE for each week in the test set&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.7: MSE for each week in the test set</p>
			<p>The results of our model suggest that its performance isn't all that bad. By observing the pattern from the <strong class="source-inline">Predicted</strong> line (grey), we can see that the network has identified a fluctuating pattern happening on a weekly basis, in which the normalized prices go up in the middle of the week, then down by the end of it but. However, there's still a lot of room for improvement as it is unable to pick up higher fluctuations. With the exception of a few weeks—the same as with our previous MSE analysis—most weeks fall close to the correct values.</p>
			<p>Now, let's denormalize the predictions so that we can investigate the prediction values using the same scale as the original data (that is, US dollars). We can do this by implementing a denormalization function that uses the day index from the predicted data to identify the equivalent week on the test data. After that week has been identified, the function then takes the first value of that week and uses that value to denormalize the predicted values by using the same point-relative normalization technique but inverted. The following snippet denormalizes data using an inverted point-relative normalization technique:</p>
			<p class="source-code">def denormalize(reference, series, normalized_variable=\</p>
			<p class="source-code">                'close_point_relative_normalization', \</p>
			<p class="source-code">                denormalized_variable='close'):</p>
			<p class="source-code">    if('iso_week' in list(series.columns)):</p>
			<p class="source-code">        week_values = reference[reference['iso_week'] \</p>
			<p class="source-code">                      == series['iso_week'].values[0]]</p>
			<p class="source-code">        last_value = week_values[denormalized_variable].values[0]</p>
			<p class="source-code">        series[denormalized_variable] = \</p>
			<p class="source-code">        last_value * (series[normalized_variable] + 1)</p>
			<p class="source-code">    return series</p>
			<p class="source-code">predicted_close = predicted.groupby('iso_week').apply(lambda x: \</p>
			<p class="source-code">                  denormalize(observed, x))</p>
			<p>The <strong class="source-inline">denormalize()</strong> function takes the first closing price from the test's first day of an equivalent week.</p>
			<p>Our results now compare the predicted values with the test set using US dollars. As shown in the following plot, the <strong class="source-inline">bitcoin_lstm_v0</strong> model seems to perform quite well in predicting the Bitcoin prices for the following 7 days. But how can we measure that performance in interpretable terms?</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B15911_03_08.jpg" alt="Figure 3.8: De-normalized predictions per week&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.8: De-normalized predictions per week</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor080"/>Interpreting Predictions</h2>
			<p>Our last step is to add interpretability to our predictions. The preceding plot seems to show that our model prediction matches the test data somewhat closely, but how closely?</p>
			<p>Keras' <strong class="source-inline">model.evaluate()</strong> function is useful for understanding how a model is performing at each evaluation step. However, given that we are typically using normalized datasets to train neural networks, the metrics that are generated by the <strong class="source-inline">model.evaluate()</strong> method are also hard to interpret.</p>
			<p>In order to solve that problem, we can collect the complete set of predictions from our model and compare it with the test set using two other functions from <em class="italic">Figure 3.1</em> that are easier to interpret: MAPE and RMSE, which are implemented as <strong class="source-inline">mape()</strong> and <strong class="source-inline">rmse()</strong>, respectively. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">These functions are implemented using NumPy. The original implementations come from <a href="https://stats.stackexchange.com/questions/58391/mean-absolute-percentage-error-mape-in-scikit-learn">https://stats.stackexchange.com/questions/58391/mean-absolute-percentage-error-mape-in-scikit-learn</a> and <a href="https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy">https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy</a></p>
			<p>We can see the implementation of these methods in the following snippet:</p>
			<p class="source-code">def mape(A, B):</p>
			<p class="source-code">    return np.mean(np.abs((A - B) / A)) * 100</p>
			<p class="source-code">def rmse(A, B):</p>
			<p class="source-code">    return np.sqrt(np.square(np.subtract(A, B)).mean())</p>
			<p>After comparing our test set with our predictions using both of those functions, we have the following results:</p>
			<ul>
				<li><strong class="bold">Denormalized RMSE</strong>: $596.6 USD</li>
				<li><strong class="bold">Denormalized MAPE</strong>: 4.7 percent</li>
			</ul>
			<p>This indicates that our predictions differ, on average, about $596 from real data. This represents a difference of about 4.7 percent from real Bitcoin prices.</p>
			<p>These results facilitate the understanding of our predictions. We will continue to use the <strong class="source-inline">model.evaluate()</strong> method to keep track of how our LSTM model is improving, but will also compute both <strong class="source-inline">rmse()</strong> and <strong class="source-inline">mape()</strong> on the complete series on every version of our model to interpret how close we are to predicting Bitcoin prices.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor081"/>Exercise 3.01: Creating an Active Training Environment</h2>
			<p>In this exercise, we'll create a training environment for our neural network that facilitates both its training and evaluation. This environment is particularly important for the next topic, in which we'll search for an optimal combination of hyperparameters.</p>
			<p>First, we will start both a Jupyter Notebook instance and a TensorBoard instance. Both of these instances can remain open for the remainder of this exercise. Let's get started:</p>
			<ol>
				<li>Using your Terminal, navigate to the <strong class="source-inline">Chapter03/Exercise3.01</strong> directory and execute the following code to start a Jupyter Notebook instance:<p class="source-code">$ jupyter-lab</p><p>The server should open in your browser automatically.</p></li>
				<li>Open the Jupyter Notebook named <strong class="source-inline">Exercise3.01_Creating_an_active_training_environment.ipynb</strong>:<p> </p><div id="_idContainer069" class="IMG---Figure"><img src="image/B15911_03_09.jpg" alt="Figure 3.9: Jupyter Notebook highlighting the section, Evaluate LSTM Model&#13;&#10;"/></div><p class="figure-caption">Figure 3.9: Jupyter Notebook highlighting the section, Evaluate LSTM Model</p></li>
				<li>Also using your Terminal, start a TensorBoard instance by executing the following command:<p class="source-code">$ cd ./Chapter03/Exercise3.01/</p><p class="source-code">$ tensorboard --logdir=logs/</p><p>Ensure the <strong class="source-inline">logs</strong> directory is empty in the repository.</p></li>
				<li>Open the URL that appears on screen and leave that browser tab open, as well. Execute the initial cells containing the import statements to ensure that the dependencies are loaded.</li>
				<li>Execute the two cells under Validation Data to load the train and test datasets in the Jupyter Notebook:<p class="source-code">train = pd.read_csv('<strong class="bold">data/train_dataset.csv</strong>')</p><p class="source-code">test = pd.read_csv('<strong class="bold">data/test_dataset.csv</strong>')</p><p class="callout-heading">Note</p><p class="callout">Don't forget to change the path (highlighted) of the files based on where they are saved on your system. </p></li>
				<li>Add TensorBoard callback and retrain the model. Execute the cells under Re-Train model with TensorBoard.<p>Now, let's evaluate how our model performed against the test data. Our model is trained using 186 weeks to predict a week into the future—that is, the following sequence of 7 days. When we built our first model, we divided our original dataset between a training and a test set. Now, we will take a combined version of both datasets (let's call it a combined set) and move a sliding window of 186 weeks. At each window, we execute Keras' <strong class="source-inline">model.evaluate()</strong> method to evaluate how the network performed on that specific week.</p></li>
				<li>Execute the cells under the header, <strong class="source-inline">Evaluate LSTM Model</strong>. The key concept of these cells is to call the <strong class="source-inline">model.evaluate()</strong> method for each of the weeks in the test set. This line is the most important:<p class="source-code">result = model.evaluate(x=X_test, y=Y_test, verbose=0)</p></li>
				<li>Each evaluation result is now stored in the <strong class="source-inline">evaluated_weeks</strong> variable. That variable is a simple array containing the sequence of MSE predictions for every week in the test set. Go ahead and plot the results:<div id="_idContainer070" class="IMG---Figure"><img src="image/B15911_03_10.jpg" alt="Figure 3.10: MSE results from the model.evaluate() method for each week of the test set&#13;&#10;"/></div><p class="figure-caption">Figure 3.10: MSE results from the model.evaluate() method for each week of the test set</p><p>As we've already discussed, the MSE loss function is difficult to interpret. To facilitate our understanding of how our model is performing, we also call the <strong class="source-inline">model.predict()</strong> method on each week from the test set and compare its predicted results with the set's values.</p></li>
				<li>Navigate to the <em class="italic">Interpreting Model Results</em> section and execute the code cells under the <strong class="source-inline">Make Predictions</strong> subheading. Notice that we are calling the <strong class="source-inline">model.predict()</strong> method, but with a slightly different combination of parameters. Instead of using both the <strong class="source-inline">X</strong> and <strong class="source-inline">Y</strong> values, we only use <strong class="source-inline">X</strong>:<p class="source-code">predicted_weeks = []</p><p class="source-code">for i in range(0, test_data.shape[1]):</p><p class="source-code">    input_series = combined_set[0:,i:i+186]</p><p class="source-code">    predicted_weeks.append(model.predict(input_series))</p><p>At each window, we will issue predictions for the following week and store the results. Now, we can plot the normalized results alongside the normalized values from the test set, as shown in the following plot:</p><div id="_idContainer071" class="IMG---Figure"><img src="image/B15911_03_11.jpg" alt="Figure 3.11: Plotting the normalized values returned from model.predict() for each &#13;&#10;week of the test set"/></div><p class="figure-caption">Figure 3.11: Plotting the normalized values returned from model.predict() for each week of the test set</p><p>We will also make the same comparisons but using denormalized values. In order to denormalize our data, we must identify the equivalent week between the test set and the predictions. Then, we can take the first price value for that week and use it to reverse the point-relative normalization equation from <em class="italic">Chapter 2</em>, <em class="italic">Real-World Deep Learning with TensorFlow and Keras: Predicting the Price of Bitcoin</em>.</p></li>
				<li>Navigate to the <strong class="source-inline">De-normalized Predictions</strong> header and execute all the cells under that header.</li>
				<li>In this section, we defined the <strong class="source-inline">denormalize()</strong> function, which performs the complete denormalization process. In contrast to the other functions, this function takes in a pandas DataFrame instead of a NumPy array. We do this to use dates as an index. This is the most relevant cell block from that header:<p class="source-code">predicted_close = predicted.groupby('iso_week').apply(\</p><p class="source-code">                  lambda x: denormalize(observed, x))</p><p>Our denormalized results (as seen in the following plot) show that our model makes predictions that are close to the real Bitcoin prices. But how close?</p><div id="_idContainer072" class="IMG---Figure"><img src="image/B15911_03_12.jpg" alt="Figure 3.12: Plotting the denormalized values returned from model.predict() &#13;&#10;for each week of the test set&#13;&#10;"/></div><p class="figure-caption">Figure 3.12: Plotting the denormalized values returned from model.predict() for each week of the test set</p><p>The LSTM network uses MSE values as its loss function. However, as we've already discussed, MSE values are difficult to interpret. To solve this, we need to implement two functions (loaded from the <strong class="source-inline">utilities.py</strong> script) that implement the <strong class="source-inline">rmse()</strong> and <strong class="source-inline">mape()</strong> functions. These functions add interpretability to our model by returning a measurement on the same scale that our original data used, and by comparing the difference in scale as a percentage.</p></li>
				<li>Navigate to the <strong class="source-inline">De-normalizing Predictions</strong> header and load two functions from the <strong class="source-inline">utilities.py</strong> script:<p class="source-code">from scripts.utilities import rmse, mape</p><p>The functions from this script are actually really simple:</p><p class="source-code">def mape(A, B):</p><p class="source-code">  return np.mean(np.abs((A - B) / A)) * 100</p><p class="source-code">def rmse(A, B):</p><p class="source-code">  return np.sqrt(np.square(np.subtract(A, B)).mean())</p><p>Each function is implemented using NumPy's vector-wise operations. They work well in vectors of the same length. They are designed to be applied on a complete set of results.</p><p>Using the <strong class="source-inline">mape()</strong> function, we can now understand that our model predictions are about 4.7 percent away from the prices from the test set. This is equivalent to a RSME (calculated using the <strong class="source-inline">rmse()</strong> function) of about $596.6.</p><p>Before moving on to the next section, go back into the Notebook and find the <strong class="source-inline">Re-train Model with TensorBoard</strong> header. You may have noticed that we created a helper function called <strong class="source-inline">train_model()</strong>. This function is a wrapper around our model that trains (using <strong class="source-inline">model.fit()</strong>) our model, storing its respective results under a new directory. Those results are then used by TensorBoard in order to display statistics for different models.</p></li>
				<li>Go ahead and modify some of the values for the parameters that were passed to the <strong class="source-inline">model.fit()</strong> function (try epochs, for instance). Now, run the cells that load the model into memory from disk (this will replace your trained model):<p class="source-code">model = load_model('bitcoin_lstm_v0.h5')</p></li>
				<li>Now, run the <strong class="source-inline">train_model()</strong> function again, but with different parameters, indicating a new run version. When you run this command, you will be able to train a newer version of the model and specify the newer version in the version parameter:<p class="source-code">train_model(model=model, X=X_train, Y=Y_train, \</p><p class="source-code">            epochs=10, version=0, run_number=0)</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2ZhK4z3">https://packt.live/2ZhK4z3</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2Dvd9i3">https://packt.live/2Dvd9i3</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>In this exercise, we learned how to evaluate a network using loss functions. We learned that loss functions are key elements of neural networks since they evaluate the performance of a network at each epoch and are the starting point for the propagation of adjustments back into layers and nodes. We also explored why some loss functions can be difficult to interpret (for instance, the MSE function) and developed a strategy using two other functions—RMSE and MAPE—to interpret the predicted results from our LSTM model.</p>
			<p>Most importantly, we've concluded this exercise with an active training environment. We now have a system that can train a deep learning model and evaluate its results continuously. This will be key when we move on to optimizing our network in the next topic.</p>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor082"/>Hyperparameter Optimization</h1>
			<p>So far, we have trained a neural network to predict the next 7 days of Bitcoin prices using the preceding 76 weeks of prices. On average, this model issues predictions that are about 8.4 percent distant from real Bitcoin prices.</p>
			<p>This section describes common strategies for improving the performance of neural network models:</p>
			<ul>
				<li>Adding or removing layers and changing the number of nodes</li>
				<li>Increasing or decreasing the number of training epochs</li>
				<li>Experimenting with different activation functions</li>
				<li>Using different regularization strategies</li>
			</ul>
			<p>We will evaluate each modification using the same active learning environment we developed by the end of the <em class="italic">Model Evaluation</em> section, measuring how each one of these strategies may help us develop a more precise model.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor083"/>Layers and Nodes – Adding More Layers</h2>
			<p>Neural networks with single hidden layers can perform fairly well on many problems. Our first Bitcoin model (<strong class="source-inline">bitcoin_lstm_v0</strong>) is a good example: it can predict the next 7 days of Bitcoin prices (from the test set) with error rates of about 8.4 percent using a single LSTM layer. However, not all problems can be modeled with single layers.</p>
			<p>The more complex the function you are working to predict, the higher the likelihood that you will need to add more layers. A good way to determine whether adding new layers is a good idea is to understand what their role in a neural network is.</p>
			<p>Each layer creates a model representation of its input data. Earlier layers in the chain create lower-level representations, while later layers create higher-level representations.</p>
			<p>While this description may be difficult to translate into real-world problems, its practical intuition is simple: when working with complex functions that have different levels of representation, you may want to experiment with adding layers.</p>
			<h3 id="_idParaDest-82"><a id="_idTextAnchor084"/>Adding More Nodes</h3>
			<p>The number of neurons that your layer requires is related to how both the input and output data is structured. For instance, if you are working on a binary classification problem to classify a 4 x 4 pixel image, then you can try out the following:</p>
			<ul>
				<li>Have a hidden layer that has 12 neurons (one for each available pixel)</li>
				<li>Have an output layer that has only two neurons (one for each predicted class)</li>
			</ul>
			<p>It is common to add new neurons alongside the addition of new layers. Then, we can add a layer that has either the same number of neurons as the previous one, or a multiple of the number of neurons from the previous layer. For instance, if your first hidden layer has 12 neurons, you can experiment with adding a second layer that has either 12, 6, or 24 neurons.</p>
			<p>Adding layers and neurons can have significant performance limitations. Feel free to experiment with adding layers and nodes. It is common to start with a smaller network (that is, a network with a small number of layers and neurons), then grow according to its performance gains.</p>
			<p>If this comes across as imprecise, your intuition is right. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">To quote <em class="italic">Aurélien Géron</em>, YouTube's former lead for video classification, "<em class="italic">Finding the perfect amount of neurons is still somewhat of a black art</em>."</p>
			<p>Finally, a word of caution: the more layers you add, the more hyperparameters you have to tune—and the longer your network will take to train. If your model is performing fairly well and not overfitting your data, experiment with the other strategies outlined in this chapter before adding new layers to your network.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor085"/>Layers and Nodes – Implementation</h2>
			<p>Now, we will modify our original LSTM model by adding more layers. In LSTM models, we typically add LSTM layers in a sequence, making a chain between LSTM layers. In our case, the new LSTM layer has the same number of neurons as the original layer, so we don't have to configure that parameter.</p>
			<p>We will name the modified version of our model <strong class="source-inline">bitcoin_lstm_v1</strong>. It is good practice to name each one of the models in terms of which one is attempting different hyperparameter configurations. This helps you to keep track of how each different architecture performs, and also to easily compare model differences in TensorBoard. We will compare all the different modified architectures at the end of this chapter.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Before adding a new LSTM layer, we need to set the <strong class="source-inline">return_sequences</strong> parameter to <strong class="source-inline">True</strong> on the first LSTM layer. We do this because the first layer expects a sequence of data with the same input as that of the first layer. When this parameter is set to <strong class="source-inline">False</strong>, the LSTM layer outputs the predicted parameters in a different, incompatible output.</p>
			<p>The following code example adds a second LSTM layer to the original <strong class="source-inline">bitcoin_lstm_v0</strong> model, making it <strong class="source-inline">bitcoin_lstm_v1</strong>:</p>
			<p class="source-code">period_length = 7</p>
			<p class="source-code">number_of_periods = 186</p>
			<p class="source-code">batch_size = 1</p>
			<p class="source-code">model = Sequential() </p>
			<p class="source-code">model.add(LSTM(</p>
			<p class="source-code">units=period_length,</p>
			<p class="source-code">batch_input_shape=(batch_size, number_of_periods, period_length), \</p>
			<p class="source-code">                  input_shape=(number_of_periods, period_length), \</p>
			<p class="source-code">                  return_sequences=True, stateful=False))</p>
			<p class="source-code">model.add(LSTM(units=period_length,\</p>
			<p class="source-code">               batch_input_shape=(batch_size, number_of_periods, \</p>
			<p class="source-code">                                  period_length), \</p>
			<p class="source-code">               input_shape=(number_of_periods, period_length), \</p>
			<p class="source-code">               return_sequences=False, stateful=False))</p>
			<p class="source-code">model.add(Dense(units=period_length)) \</p>
			<p class="source-code">model.add(Activation("linear"))</p>
			<p class="source-code">model.compile(loss="mse", optimizer="rmsprop")</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor086"/>Epochs</h2>
			<p><strong class="bold">Epochs</strong> are the number of times the network adjusts its weights in response to the data passing through and its resulting loss function. Running a model for more epochs can allow it to learn more from data, but you also run the risk of overfitting.</p>
			<p>When training a model, prefer to increase the epochs exponentially until the loss function starts to plateau. In the case of the <strong class="source-inline">bitcoin_lstm_v0</strong> model, its loss function plateaus at about 100 epochs.</p>
			<p>Our LSTM model uses a small amount of data to train, so increasing the number of epochs does not affect its performance in a significant way. For instance, if we attempt to train it at 103 epochs, the model barely gains any improvements. This will not be the case if the model being trained uses enormous amounts of data. In those cases, a large number of epochs is crucial to achieve good performance.</p>
			<p>I suggest you use the following rule of thumb:<em class="italic"> the larger the data used to train your model, the more epochs it will need to achieve good performance</em>.</p>
			<h3 id="_idParaDest-85"><a id="_idTextAnchor087"/>Epochs – Implementation</h3>
			<p>Our Bitcoin dataset is rather small, so increasing the epochs that our model trains may have only a marginal effect on its performance. In order to have the model train for more epochs, we only have to change the <strong class="source-inline">epochs</strong> parameter in the <strong class="source-inline">model.fit()</strong> method. In the following snippet, you will see how to change the number of epochs that our model trains for:</p>
			<p class="source-code">number_of_epochs = 10**3 </p>
			<p class="source-code">model.fit(x=X, y=Y, batch_size=1,\</p>
			<p class="source-code">          epochs=number_of_epochs, \</p>
			<p class="source-code">          verbose=0, \</p>
			<p class="source-code">          callbacks=[tensorboard])</p>
			<p>This change bumps our model to <strong class="source-inline">v2</strong>, effectively making it <strong class="source-inline">bitcoin_lstm_v2</strong>.</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor088"/>Activation Functions</h2>
			<p><strong class="bold">Activation functions</strong> evaluate how much you need to activate individual neurons. They determine the value that each neuron will pass to the next element of the network, using both the input from the previous layer and the results from the loss function—or if a neuron should pass any values at all.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Activation functions are a topic of great interest for those in the scientific community researching neural networks. For an overview of research currently being done on the topic and a more detailed review on how activation functions work, please refer to <em class="italic">Deep Learning by Ian Goodfellow et. al., MIT Press, 2017</em>.</p>
			<p>TensorFlow and Keras provide many activation functions—and new ones are occasionally added. As an introduction, three are important to consider; let's explore each of them.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">This section has been greatly inspired by the article <em class="italic">Understanding Activation Functions in Neural Networks</em> by Avinash Sharma V, available at <a href="https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0">https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0</a>.</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor089"/>Linear (Identity) Functions</h2>
			<p>Linear functions only activate a neuron based on a constant value. They are defined by the following equation:</p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B15911_03_13.jpg" alt="Figure 3.13: Formula for linear functions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.13: Formula for linear functions</p>
			<p>Here, <em class="italic">c</em> is the constant value. When <em class="italic">c = 1</em>, neurons will pass the values as is, without any modification needed by the activation function. The issue with using linear functions is that, due to the fact that neurons are activated linearly, chained layers now function as a single large layer. In other words, we lose the ability to construct networks with many layers, in which the output of one influences the other:</p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B15911_03_14.jpg" alt="Figure 3.14: Illustration of a linear function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.14: Illustration of a linear function</p>
			<p>The use of linear functions is generally considered obsolete for most networks because they do not compute complex features and do not induce proper non-linearity in neurons.</p>
			<h3 id="_idParaDest-88"><a id="_idTextAnchor090"/>Hyperbolic Tangent (Tanh) Function</h3>
			<p>Tanh is a non-linear function, and is represented by the following formula:</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B15911_03_15.jpg" alt="Figure 3.15: Formula for hyperbolic tangent function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.15: Formula for hyperbolic tangent function</p>
			<p>This means that the effect they have on nodes is evaluated continuously. Also, because of its non-linearity, we can use this function to change how one layer influences the next layer in the chain. When using non-linear functions, layers activate neurons in different ways, making it easier to learn different representations from data. However, they have a sigmoid-like pattern that penalizes extreme node values repeatedly, causing a problem called vanishing gradients. Vanishing gradients have negative effects on the ability of a network to learn:</p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B15911_03_16.jpg" alt="Figure 3.16: Illustration of a tanh function&#13;&#10;"/>
				</div>
			</div>
			<p> </p>
			<p class="figure-caption">Figure 3.16: Illustration of a tanh function</p>
			<p>Tanhs are popular choices, but due to the fact that they are computationally expensive, ReLUs are often used instead.</p>
			<h3 id="_idParaDest-89"><a id="_idTextAnchor091"/>Rectified Linear Unit Functions</h3>
			<p><strong class="bold">ReLU</strong> stands for <strong class="bold">Rectified Linear Unit</strong>. It filters out negative values and keeps only the positive values. ReLU functions are often recommended as great starting points before trying other functions. They are defined by the following formula:</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B15911_03_17.jpg" alt="Figure 3.17: Formula for ReLU functions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.17: Formula for ReLU functions</p>
			<p>ReLUs have non-linear properties:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B15911_03_18.jpg" alt="Figure 3.18: Illustration of a ReLU function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.18: Illustration of a ReLU function</p>
			<p>ReLUs tend to penalize negative values. So, if the input data (for instance, normalized between -1 and 1) contains negative values, those will now be penalized by ReLUs. That may not be the intended behavior.</p>
			<p>We will not be using ReLU functions in our network because our normalization process creates many negative values, yielding a much slower learning model.</p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor092"/>Activation Functions – Implementation</h2>
			<p>The easiest way to implement activation functions in Keras is by instantiating the <strong class="source-inline">Activation()</strong> class and adding it to the <strong class="source-inline">Sequential()</strong> model. <strong class="source-inline">Activation()</strong> can be instantiated with any activation function available in Keras (for a complete list, see <a href="https://keras.io/activations/">https://keras.io/activations/</a>).</p>
			<p>In our case, we will use the <strong class="source-inline">tanh</strong> function. After implementing an activation function, we bump the version of our model to <strong class="source-inline">v2</strong>, making it <strong class="source-inline">bitcoin_lstm_v3</strong>:</p>
			<p class="source-code">model = Sequential() model.add(LSTM(</p>
			<p class="source-code">                               units=period_length,\</p>
			<p class="source-code">                               batch_input_shape=(batch_size, \</p>
			<p class="source-code">                               number_of_periods, period_length), \</p>
			<p class="source-code">                               input_shape=(number_of_periods, \</p>
			<p class="source-code">                                            period_length), \</p>
			<p class="source-code">                               return_sequences=True, \</p>
			<p class="source-code">                               stateful=False))</p>
			<p class="source-code">model.add(LSTM(units=period_length,\</p>
			<p class="source-code">          batch_input_shape=(batch_size, number_of_periods, \</p>
			<p class="source-code">                             period_length), \</p>
			<p class="source-code">          input_shape=(number_of_periods, period_length), \</p>
			<p class="source-code">          return_sequences=False, stateful=False))</p>
			<p class="source-code">model.add(Dense(units=period_length)) \</p>
			<p class="source-code">model.add(Activation("tanh"))</p>
			<p class="source-code">model.compile(loss="mse", optimizer="rmsprop")</p>
			<p>After executing the <strong class="source-inline">compile</strong> command, your model has been built according to the layers specified and is now ready to be trained. There are a number of other activation functions worth experimenting with. Both TensorFlow and Keras provide a list of implemented functions in their respective official documentations. Before implementing your own, start with the ones we've already implemented in both TensorFlow and Keras.</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor093"/>Regularization Strategies</h2>
			<p>Neural networks are particularly prone to overfitting. Overfitting happens when a network learns the patterns of the training data but is unable to find generalizable patterns that can also be applied to the test data.</p>
			<p>Regularization strategies refer to techniques that deal with the problem of overfitting by adjusting how the network learns. In the following sections, we'll discuss two common strategies:</p>
			<ul>
				<li>L2 Regularization </li>
				<li>Dropout</li>
			</ul>
			<h3 id="_idParaDest-92"><a id="_idTextAnchor094"/>L2 Regularization</h3>
			<p><strong class="bold">L2 regularization</strong> (or <strong class="bold">weight decay</strong>) is a common technique for dealing with overfitting models. In some models, certain parameters vary in great magnitudes. L2 regularization penalizes such parameters, reducing the effect of these parameters on the network.</p>
			<p>L2 regularizations use the <img src="image/B15911_03_Formula_01.png" alt="3"/> parameter to determine how much to penalize a model neuron. We typically set that to a very low value (that is, 0.0001); otherwise, we risk eliminating the input from a given neuron completely.</p>
			<h3 id="_idParaDest-93"><a id="_idTextAnchor095"/>Dropout</h3>
			<p>Dropout is a regularization technique based on a simple question: <em class="italic">if we randomly take away a proportion of the nodes from the layers, how will the other node adapt?</em> It turns out that the remaining neurons adapt, learning to represent patterns that were previously handled by those neurons that are missing.</p>
			<p>The dropout strategy is simple to implement and is typically very effective at avoiding overfitting. This will be our preferred regularization.</p>
			<h3 id="_idParaDest-94"><a id="_idTextAnchor096"/>Regularization Strategies – Implementation</h3>
			<p>In order to implement the dropout strategy using Keras, we'll import the <strong class="source-inline">Dropout()</strong> method and add it to our network immediately after each LSTM layer. This addition effectively makes our network <strong class="source-inline">bitcoin_lstm_v4</strong>. In this snippet, we're adding the <strong class="source-inline">Dropout()</strong> step to our model (<strong class="source-inline">bitcoin_lstm_v3</strong>), making it <strong class="source-inline">bitcoin_lstm_v4</strong>:</p>
			<p class="source-code">model = Sequential()</p>
			<p class="source-code">model.add(LSTM(\</p>
			<p class="source-code">          units=period_length,\</p>
			<p class="source-code">          batch_input_shape=(batch_size, number_of_periods, \</p>
			<p class="source-code">                             period_length), \</p>
			<p class="source-code">          input_shape=(number_of_periods, period_length), \</p>
			<p class="source-code">          return_sequences=True, stateful=False))</p>
			<p class="source-code">model.add(Dropout(0.2))</p>
			<p class="source-code">model.add(LSTM(\</p>
			<p class="source-code">          units=period_length,\</p>
			<p class="source-code">          batch_input_shape=(batch_size, number_of_periods, \</p>
			<p class="source-code">                             period_length), \</p>
			<p class="source-code">          input_shape=(number_of_periods, period_length), \</p>
			<p class="source-code">          return_sequences=False, stateful=False))</p>
			<p class="source-code">model.add(Dropout(0.2))</p>
			<p class="source-code">model.add(Dense(units=period_length))</p>
			<p class="source-code">model.add(Activation("tanh"))</p>
			<p class="source-code">model.compile(loss="mse", optimizer="rmsprop")</p>
			<p>We could have used L2 regularization instead of dropout. Dropout drops out random neurons in each epoch, whereas L2 regularization penalizes neurons that have high weight values. In order to apply L2 regularization, simply instantiate the <strong class="source-inline">ActivityRegularization()</strong> class with the L2 parameter set to a low value (for instance, 0.0001). Then, place it in the place where the <strong class="source-inline">Dropout()</strong> class has been added to the network. Feel free to experiment by adding that to the network while keeping both <strong class="source-inline">Dropout()</strong> steps, or simply replace all the <strong class="source-inline">Dropout()</strong> instances with <strong class="source-inline">ActivityRegularization()</strong> instead.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor097"/>Optimization Results</h2>
			<p>All in all, we have created four versions of our model. Three of these versions, that is, <strong class="source-inline">bitcoin_lstm_v1</strong>, <strong class="source-inline">bitcoin_lstm_v2</strong>, and <strong class="source-inline">bitcoin_lstm_v3</strong>, were created by applying different optimization techniques that were outlined in this chapter. Now, we have to evaluate which model performs best. In order to do that, we will use the same metrics we used in our first model: MSE, RMSE, and MAPE. MSE is used to compare the error rates of the model on each predicted week. RMSE and MAPE are computed to make the model results easier to interpret. The following table shows this:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B15911_03_19.jpg" alt="Figure 3.19: Model results for all models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.19: Model results for all models</p>
			<p>Interestingly, our first model (<strong class="source-inline">bitcoin_lstm_v0</strong>) performed the best in nearly all defined metrics. We will be using that model to build our web application and continuously predict Bitcoin prices.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor098"/>Activity 3.01: Optimizing a Deep Learning Model</h2>
			<p>In this activity, we'll implement different optimization strategies on the model we created in <em class="italic">Chapter 2</em>, <em class="italic">Real-World Deep Learning with TensorFlow and Keras: Predicting the Price of Bitcoin</em> (<strong class="source-inline">bitcoin_lstm_v0</strong>). This model achieves a MAPE performance on the complete de-normalization test set of about 8.4 percent. We will try to reduce that gap and get more accurate predictions.</p>
			<p>Here are the steps:</p>
			<ol>
				<li value="1">Start TensorBoard from a Terminal.</li>
				<li>Start a Jupyter Notebook.</li>
				<li>Load the train and test data and split the <strong class="source-inline">lstm</strong> input in the format required by the model.</li>
				<li>In the previous exercise, we create a model architecture. Copy that model architecture and add a new LSTM layer. Compile and create a model.</li>
				<li>Change the number of epochs in <em class="italic">step 4</em> by creating a new model. Compile and create a new model.</li>
				<li>Change the activation function to <strong class="source-inline">tanh</strong> or <strong class="source-inline">relu</strong> and create a new model. Compile and train a new model.</li>
				<li>Add a new layer for dropout after the LSTM layer and create a new model. Keep values such as <strong class="source-inline">0.2</strong> or <strong class="source-inline">0.3</strong> for dropout. Compile and train a new model.</li>
				<li>Evaluate and compare all the models that were trained in this activity.<p class="callout-heading">Note</p><p class="callout">The solution to this activity can be found on page 141.</p></li>
			</ol>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor099"/>Summary</h1>
			<p>In this chapter, we learned how to evaluate our model using the MSE, RMSE, and MAPE metrics. We computed the latter two metrics in a series of 19-week predictions made by our first neural network model. By doing this, we learned that it was performing well.</p>
			<p>We also learned how to optimize a model. We looked at optimization techniques, which are typically used to increase the performance of neural networks. Also, we implemented a number of these techniques and created a few more models to predict Bitcoin prices with different error rates.</p>
			<p>In the next chapter, we will be turning our model into a web application that does two things: retrains our model periodically with new data and is able to make predictions using an HTTP API interface.</p>
		</div>
		<div>
			<div id="_idContainer082" class="Content">
			</div>
		</div>
	</body></html>