<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Digit Classification Using TensorFlow Lite</h1>
                </header>
            
            <article>
                
<p>There has been a lot of progress in the field of <strong>machine learning</strong> (<strong>ML</strong>) in the last five years. These days, a variety of ML applications are being used in our daily lives and we don't even realize it. Since ML has taken the spotlight, it would be helpful if we could use it to run deep models on mobile devices, which is one of the most used devices in our daily life.</p>
<p>Innovation in mobile hardware, coupled with new software frameworks for deploying ML models on mobile devices, is proving to be one of the major accelerators for developing ML based applications on mobile or other edge devices like tablet..</p>
<p>In this chapter, we will learn about Google's new library, <span>TensorFlow Lite,</span> which can be used to deploy ML models on mobile devices. We will train a deep learning model on the MNIST digits dataset and look at how we can convert this model into a mobile-friendly format by understanding the following concepts:</p>
<ul>
<li>A brief introduction to TensorFlow Lite and its architecture</li>
<li>Introduction to Classification model evaluation metrics</li>
<li>Developing a deep learning model on the MNIST dataset</li>
<li>Converting the trained model into a mobile-friendly format using TensorFlow Lite</li>
</ul>
<div class="packt_tip">Note that this chapter will not discuss building an Android application to deploy these models since this has been extensively documented in Google's TensorFlow tutorials (<a href="https://www.tensorflow.org/lite/">https://www.tensorflow.org/lite/</a>). </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is TensorFlow Lite?</h1>
                </header>
            
            <article>
                
<p><span>Before we take a deep dive into TensorFlow Lite, let's try to understand what are the advantages of doing ML on edge devices like mobile/tablet and others.</span></p>
<ul>
<li><strong>Privacy</strong><span>: If inference on a ML model can be performed on a device, user data doesn't need to leave the device, which helps in preserving the privacy of the user.</span></li>
<li><strong>Offline predictions</strong>:<span> </span>The device doesn't need to be connected to a network to make predictions on a ML model. This unlocks a lot of use cases in developing nations such as India where network connectivity is not so great.</li>
<li><strong>Smart devices</strong>:<span> </span>This can also enable the development of smart home devices such as microwaves and thermostats with on-device intelligence.</li>
<li><strong>Power efficient</strong>:<span> An o</span>n-device ML can be more power-efficient as there is no need to transfer data back and forth to the server.</li>
<li><strong>Sensor data utilization</strong>:<span> </span>ML models can make use of rich sensor data since it is easily available on mobile.</li>
</ul>
<p>However, mobile devices are not same as our desktops and laptops. There are different considerations when deploying the model on mobile or embedded devices such as:</p>
<ul>
<li><strong>Model size</strong>:<strong> </strong>As we know, mobiles have limited memory and we can't store a memory-heavy model on a device. There are two ways of handling this:
<ul>
<li>We can round or quantize the weights of the model so that they require fewer floating-point representations. This is in line with our understanding that integers always require less memory to store than the floating point numbers.</li>
<li>Since we only use devices for inferences or predictions, we can strip out all the training operations in our Tensorflow graph which are not useful for making predictions.</li>
</ul>
</li>
<li><strong>Speed</strong>:<strong> </strong>One of the important things for deploying models on mobile devices is the speed with which we can run an inference so that we gain a better user experience. Models have to be optimized in such a manner that they don't exceed the latency budget on the phone but are still fast.</li>
<li><strong>Ease of deployment</strong>: We need efficient frameworks/libraries so that deployment on mobile devices is very straightforward.</li>
</ul>
<p>With these considerations in mind, Google has developed TensorFlow Lite, which is a lightweight version of original Tensorflow for deploying deep learning models on mobile and embedded devices.</p>
<p>To understand TensorFlow Lite, take a look at the following diagram, which shows its high-level<span><span> a</span></span><span><span>rchitecture</span></span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-677 image-border" src="assets/7ee6c212-fbed-4caf-b6fc-bd44dc9b4ee3.png" style="width:41.92em;height:39.75em;"/></p>
<p>This architecture makes it evident that we need to convert a trained TF model into <kbd>.tflite</kbd> format. This format is different from usual TF models as it is optimized for inference on devices. We will learn about the conversion process in detail later in the chapter. </p>
<p><span>For now, let's try to understand the major features of using TF Lite</span> format:</p>
<ul>
<li class="mce-root"><span>The model is serialized and converted to a Flatbuffer format<strong> </strong>(<a href="https://google.github.io/flatbuffers/">https://google.github.io/flatbuffers/</a>). Flatbuffers have the advantage that data can be directly accessed without</span><span> </span><span>parsing/unpacking of large files that contain weights.</span></li>
<li>Weights and biases of the model are pre-fused into TF lite format.</li>
</ul>
<p>TF lite is cross-platform and can be deployed on Android, iOS, Linux, and hardware devices such as Raspberry Pi.</p>
<p>It includes an on-device interpreter that has been optimized for faster execution on mobile. The core interpreter with all of the supported operations is around 400 KB, and 75 KB without the supported operations. This means that the model takes up little space on the device. Overall, the idea is to keep the parts of the model that are essential for inference and strip out all the other parts.</p>
<p>With innovation in hardware, many companies are also developing GPUs and Digital Signal Processors (DSPs) that are optimized for neural network inference. TF Lite provides the Android Neural Networks API, which can perform hardware acceleration on these devices.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Classification Model Evaluation Metrics</h1>
                </header>
            
            <article>
                
<p>Just building a model does not suffice; we need to make sure that our model functions well and gives us a good and accurate output. To do this, we need to understand some classification metrics that will be used to evaluate the model throughout this book.</p>
<p>Let's begin by defining some building blocks of the metrics that will be used to evaluate the classification models. To do this, take a simple example of spam detection that is done by any online mailbox for reference. A spam email shall be considered to be of a positive class and the normal email to be of a negative class. We can summarize this spam detection model into four categories, which are illustrated in the following matrix:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>True positives</strong><span> </span>(<strong>TP</strong>)</td>
<td><strong>False positives</strong><span> </span>(<strong>FP</strong>)</td>
</tr>
<tr>
<td><span>Reality: Email is spam</span></td>
<td><span>Reality: Email is NOT spam</span></td>
</tr>
<tr>
<td>Model Prediction: Email is spam</td>
<td>Model Prediction: Email is spam</td>
</tr>
<tr>
<td><strong>False negatives</strong><span> </span>(<strong>FN</strong>)</td>
<td><strong>True negatives</strong><span> </span>(<strong>TN</strong>)</td>
</tr>
<tr>
<td><span>Reality: Email is spam</span></td>
<td>
<p>Reality: Email is NOT spam</p>
</td>
</tr>
<tr>
<td>Model Prediction: Email is NOT spam</td>
<td><span>Model Prediction: Email is NOT spam</span></td>
</tr>
</tbody>
</table>
<p>This matrix is also commonly known as the<span> </span><strong>confusion matrix.</strong></p>
<p>The three major metrics that we will use to define classifier quality, primarily in an unbalanced dataset, are as follows:</p>
<ul>
<li><strong>Accuracy: </strong>Accuracy is the most basic metric used for classification problems. It is defined as follows:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8f86fe08-4b08-4072-ade1-c38090aa1b26.png" style="width:43.42em;height:2.83em;"/></p>
<ul>
<li><strong>Precision: </strong><span>Precision tries to measure the true positives out of all predicted positives from the model. If your Gmail doesn't misclassify a lot of emails from your friends (or normal emails) and put them into spam, then it has very high precision. It is mathematically represented as follows: </span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f1baadc5-fcc9-4bcc-b39e-5fa42314b6d0.png" style="width:23.83em;height:2.58em;"/></p>
<ul>
<li><strong>Recall: </strong><span>Recall tries to measure the number of values classified as positive out of all real positives in the dataset. In simple terms, if your Gmail doesn't misclassify a lot of your spam emails as normal emails and sends them to your inbox, then it has very high recall:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/aa450a95-27b8-4bc7-940c-50fd19ba4e4b.png" style="width:22.67em;height:2.67em;"/></p>
<div class="packt_infobox">Ideally, we want a model with high precision and high recall. However, there is always a trade-off between high precision and high recall in machine learning.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Classifying digits using TensorFlow Lite</h1>
                </header>
            
            <article>
                
<p>To complete this project, we will use the MNIST digit dataset, which is available in the TensorFlow datasets library (<a href="https://www.tensorflow.org/guide/datasets">https://www.tensorflow.org/guide/datasets</a>). It consists of images of handwritten digits from 0 to 9. The training dataset has 60,000 images and the testing set has 10,000 images. Some of the images in the dataset are as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-666 image-border" src="assets/dc9f7e6e-15de-4103-9800-449c941e283c.png" style="width:26.25em;height:27.92em;"/></p>
<p><span>If we take a l</span><span>ook at TensorFlow</span> <span>Lite tutorials, we will see that the focus is on using pre-trained models such as Mobilenet or retraining the existing ones. However, none of these tutorials talk about building new models, which is something we will be doing here. </span></p>
<div class="packt_infobox packt_tip">Note that we specifically choose a simple model because at the time of writing this book, TensorFlow Lite doesn't have adequate support for all types of complex models</div>
<p>We will use <span>categorical cross entropy as the loss function for this classification problem. Categorical cross entropy was explained in detail in <a href="60549866-497e-4dfa-890c-6651f34cf8e4.xhtml">Chapter 3</a>, <em>Sentiment Analysis in Your Browser Using TensorFlow.js</em>, of this book. In this chapter, w</span>e have 10 different digits in the dataset, so we will use the categorical cross entropy over 10 classes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pre-processing data and defining the model</h1>
                </header>
            
            <article>
                
<p>We need to pre-process our data for making it ready to feed into our model, define our model, and create an evaluation metric:</p>
<ol>
<li>Pre-process the data by ensuring the images are of shape 28x28x1 and converting the pixels into a float type variable for training. Also, here we define NUM_CLASSES = 10 as there are 10 different digits in the images.</li>
</ol>
<pre style="padding-left: 60px">x_train = x_train.reshape(x_train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)<br/>x_test = x_test.reshape(x_test.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)<br/>x_train = x_train.astype('float32')<br/>x_test = x_test.astype('float32')<br/>Next, we normalize the image pixels by 255 as follows:<br/>x_train /= 255<br/>x_test /= 255<br/>And finally, we convert the class labels to one hot for training as follows:<br/>y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)<br/>y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)<br/><br/></pre>
<ol start="2">
<li>Define the model as having <span><span>two convolutional layers with the same filter sizes, </span></span>two fully connected layers, <span>two dropout layers with dropout probabilities of 0.25 and 0.5 respectively, a Rectified Linear (</span>ReLU) after every fully connected or convolutional layer except the last one, and one max pool layer. Also we add a Softmax activation to convert the output of the model to probabilities for each of the 10 digits. Note that we use this model as it produces good results. You can try improving the model by adding more layers or trying different shapes of the existing layers.</li>
</ol>
<pre style="padding-left: 60px">model = Sequential()<br/>model.add(Conv2D(32, kernel_size=(3, 3),<br/>activation='relu',<br/>input_shape=INPUT_SHAPE))<br/>model.add(Conv2D(64, (3, 3), activation='relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(NUM_CLASSES))model.add(Activation('softmax', name = 'softmax_tensor'))</pre>
<div class="packt_infobox">Note that we have named our output tensor <kbd>softmax_tensor</kbd>, which will come in pretty handy when we try to convert this model into a TensorFlow Lite format.</div>
<ol start="3">
<li>Further define the following parameters for the model:
<ul>
<li>Loss = Categorical Cross Entropy</li>
<li>Optimizer = AdaDelta. Adam optimizer, defined in <span> </span><a href="60549866-497e-4dfa-890c-6651f34cf8e4.xhtml">Chapter 3</a><span>, </span><em>Sentiment Analysis in Your Browser Using TensorFlow.js</em><span>,</span> is an extension of AdaDelta. We use AdaDelta as it gives good result for this model. You can find more details about AdaDelta in the original paper (<a href="https://arxiv.org/abs/1212.5701">https://arxiv.org/abs/1212.5701</a>).</li>
<li>Evaluation Metric = Classification Accuracy </li>
</ul>
</li>
</ol>
<p style="padding-left: 60px">Code for defining these is as follows:</p>
<pre style="padding-left: 60px">model.compile(loss=keras.losses.categorical_crossentropy,<br/><br/>optimizer=keras.optimizers.Adadelta(),<br/><br/>metrics=['accuracy'])</pre>
<ol start="4">
<li> Enable Tensorboard logging to visualize the model graph and training progress. Code is defined as follows:</li>
</ol>
<pre style="padding-left: 60px">tensorboard = TensorBoard(log_dir=MODEL_DIR)</pre>
<ol start="5">
<li>Train the model using the following parameters:
<ul>
<li>Epochs = 12</li>
<li>Batch Size = 128:</li>
</ul>
</li>
</ol>
<pre style="padding-left: 60px">self.model.fit(self.x_train, self.y_train,<br/>batch_size=BATCH_SIZE,<br/><br/>epochs=EPOCHS,<br/><br/>verbose=1,<br/><br/>validation_data=(self.x_test, self.y_test),<br/><br/>callbacks = [self.tensorboard])<br/><br/>score = self.model.evaluate(self.x_test, self.y_test, verbose=0)</pre>
<p>We achieved <strong>99.24% </strong>accuracy on the test dataset with just 12 epochs.</p>
<div class="mce-root packt_infobox"><span>Note that we use the <kbd>callbacks</kbd> parameter to log the training progress on TensorBoard.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting TensorFlow model to TensorFlow Lite</h1>
                </header>
            
            <article>
                
<p>Now that we have trained the model in the usual way, let's look at how we can convert this model into a TensorFlow Lite format.</p>
<p>The general procedure for conversion is illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-835 image-border" src="assets/5c787e53-0ca7-404e-82ad-051bff8c99c5.png" style="width:36.75em;height:35.75em;"/></p>
<p>The procedure is simple: we take a trained model, freeze the graph, optimize it for inference/prediction, and convert it into <kbd>.tflite</kbd> format. Before going further, let's understand what we mean by Freeze Graph and Optimize For Inference:</p>
<ul>
<li><strong>Freeze Graph : </strong>Freeze graph operation effectively freezes the weights of the model by converting all the of the TF Variables as Constants. <span>As you can imagine, having all of the weights as constants can save space compared to keeping them as variables. As we only perform inference on mobile (and not training), we don't want to change the model weights anyway</span></li>
<li><strong>Optimize For Inference</strong>: Once the graph is frozen, we remove all the operations in the graph which are not useful for inference. For example, Dropout operation is used to train the model such that it doesn't overfit. However, there is absolutely no use of this operation during prediction on mobile.</li>
</ul>
<p>For the rest of this section, we will heavily use TensorBoard visualization (<a href="https://www.tensorflow.org/guide/summaries_and_tensorboard">https://www.TensorFlow.org/guide/summaries_and_tensorboard</a>) for graph visualization. :</p>
<ol>
<li><span>Once you have trained the model, you must have a file with the prefix </span><kbd>events.out.tfevents.</kbd><span> in your model folder. </span>Go to the <kbd>logs</kbd> folder and type the following into terminal:</li>
</ol>
<pre style="padding-left: 60px"><strong>tensorboard --logdir &lt;model_folder&gt;</strong></pre>
<p style="padding-left: 60px">TensorBoard will start in port <kbd>6006</kbd> by default. Launch it by going to your browser and typing <kbd>localhost:6006</kbd> into the address bar<em>. </em>Once the Tensorboard opens, if you navigate to the Graphs tab at the top, you will be able to see the Tensorflow Graph of your model. <span><span>In the following diagram</span></span>, we illustrate the main graph, with annotations for the input tensor, output tensor, and training part of the graph. As we can see, we shouldn't keep anything from the training graph for inference/making predictions on mobile. </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-668 image-border" src="assets/7d23c048-2039-40ad-87e5-922447fddf5b.png" style="width:162.50em;height:88.50em;"/></p>
<ol start="2">
<li>Next implement a function <kbd>freeze_sesssion</kbd><span> which takes TF session as input, converts all variables into constants, and returns the frozen graph. After executing this function, you will obtain a frozen graph file named <kbd>MNIST_model.pb</kbd> in the <kbd>&lt;model_folder&gt;/logs/freeze</kbd> folder.</span></li>
</ol>
<pre style="padding-left: 60px">from TensorFlow.python.framework.graph_util import convert_variables_to_constants<br/><br/>def<span> freeze_session(</span>session<span>, </span>keep_var_names<span>=</span>None<span>, </span>output_names<span>=</span>None<span>, </span>clear_devices<span>=</span>True<span>):<br/></span><br/>graph = session<span>.graph<br/></span><br/>with<span> graph.as_default():<br/></span><br/>freeze_var_names = list(set(v.op.name for<span> v </span>in<span> tf.global_variables()).difference(</span>keep_var_names<span> </span>or<span> []))<br/></span><br/>output_names = output_names<span> </span>or<span> []<br/></span><br/>output_names<span> += [v.op.name </span>for<span> v </span>in<span> tf.global_variables()]<br/></span><br/>input_graph_def = graph.as_graph_def()<br/><br/>if<span> </span>clear_devices<span>:<br/></span><br/>for<span> node </span>in<span> input_graph_def.node:<br/></span><br/>node.device = ""<br/><br/>frozen_graph = convert_variables_to_constants(session<span>, input_graph_def,<br/></span><br/>output_names<span>, freeze_var_names)<br/></span><br/>return<span> frozen_graph</span><span><br/></span></pre>
<ol start="3">
<li>Now, here is where it gets really strange: you can't visualize the <kbd>MNIST_model.pb</kbd> file directly through TensorBoard. You need to write the graph in a format that TensorBoard can pick up. Execute the function <kbd>pb_to_tensorboard</kbd><span><span> mentioned below and you will see another file in</span></span> <kbd>&lt;model_folder&gt;/logs/freeze</kbd> folder with prefix <kbd>events.out.tfevents</kbd>.</li>
</ol>
<pre style="padding-left: 60px"><br/>def<span> pb_to_tensorboard(</span>input_graph_dir<span>,</span>graph_type<span> ="freeze"):<br/><br/></span>  file_name = ""<br/><br/>  if<span> </span>graph_type<span> == "freeze":<br/><br/></span>      file_name = FREEZE_FILE_NAME<br/><br/>  elif<span> </span>graph_type<span> == "optimize":<br/></span><br/>      file_name = OPTIMIZE_FILE_NAME<br/><br/>  with<span> tf.Session() </span>as<span> sess:<br/></span><br/>      model_filename = input_graph_dir<span> + "/" + file_name<br/></span><br/>      with<span> gfile.FastGFile(model_filename, 'rb') </span>as<span> f:<br/></span>   <br/>           graph_def = tf.GraphDef()<br/>  <br/>           graph_def.ParseFromString(f.read())<br/>  <br/>  train_writer = tf.summary.FileWriter(input_graph_dir<span>)<br/></span><br/>  train_writer.add_graph(sess.graph)<span><br/></span></pre>
<ol start="4">
<li> Next, start TensorBoard again with <kbd>logdir</kbd> as <kbd>&lt;model_folder&gt;/logs/freeze</kbd> and visualize the frozen graph. <span>You will observe the you have stripped out most of the variables from the graph. </span>The following diagram illustrates the frozen graph you will obtain:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-669 image-border" src="assets/8c2b389b-9f29-42ec-b89a-3baa069e4159.png" style="width:25.67em;height:54.17em;"/></p>
<ol start="5">
<li>Next step is further trim to optimize it for inference. As explained before, we will remove Dropout variables from the graph as they are not useful for inference on mobile. However, there is no perfect way to remove those from the graph based on the existing TensorFlow functions/programs. The new improvements to TensorFlow Lite don't work for this example, which suggests that they are still under development. Instead, you will have to manually specify the operations you want to remove and connect the input of the Dropout operations to the operations after them in the graph. For example, in the frozen graph, let's say we want to remove the <kbd>dropout_3</kbd> operation. The following diagram shows the zoomed-in version of the frozen graph:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-670 image-border" src="assets/001f621c-afb7-42cb-ba3c-42b2af5ae316.png" style="width:12.83em;height:17.75em;"/></p>
<p style="padding-left: 60px">In such a case, you will have to connect the <kbd>max_pooling2</kbd> operation directly to the <kbd>flatten_2</kbd> operation, thereby skipping the <kbd>dropout_3</kbd> op in the graph.</p>
<p style="padding-left: 60px">Execute the function<span> </span><kbd>optimize_graph</kbd><span> mentioned below to </span>remove all of the dropout ops in the graph. It manually flushes out all the Dropout operations from the graph. <span>This will result in a new file named </span><kbd>MNIST_optimized.pb</kbd><span> under the </span><kbd>&lt;model_folder&gt;/logs/optimized</kbd><span> folder.</span></p>
<pre style="padding-left: 60px">def optimize_graph(input_dir, output_dir):<br/>input_graph = os.path.join(input_dir, FREEZE_FILE_NAME)<br/>output_graph = os.path.join(output_dir, OPTIMIZE_FILE_NAME)<br/>input_graph_def = tf.GraphDef()<br/>with tf.gfile.FastGFile(input_graph, "rb") as f:<br/>input_graph_def.ParseFromString(f.read())<br/>output_graph_def = strip(input_graph_def, u'dropout_1', u'conv2d_2/bias', u'dense_1/kernel', u'training')<br/>output_graph_def = strip(output_graph_def, u'dropout_3', u'max_pooling2d_2/MaxPool', u'flatten_2/Shape',<br/>u'training')<br/>output_graph_def = strip(output_graph_def, u'dropout_4', u'dense_3/Relu', u'dense_4/kernel', u'training')<br/>output_graph_def = strip(output_graph_def, u'Adadelta_1', u'softmax_tensor_1/Softmax',<br/>u'training/Adadelta/Variable', u'training')<br/>output_graph_def = strip(output_graph_def, u'training', u'softmax_tensor_1/Softmax',<br/>u'_', u'training')<br/>with tf.gfile.GFile(output_graph, "wb") as f:<br/>f.write(output_graph_def.SerializeToString())</pre>
<ol start="6">
<li>Again, to visualize the graph in TensorBoard, you need to convert it using the function<span> </span><kbd>pb_to_tensorboar</kbd> defined in step 3 so that it's TensorBoard-friendly and obtain a new file with the prefix <kbd>events.out.tfevents</kbd> in the same folder. The following figure illustrates the graph you will obtain after removing the Dropout operations. </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-671 image-border" src="assets/30c933b9-110b-4297-8945-76860bc3e017.png" style="width:27.00em;height:45.17em;"/></p>
<div class="packt_tip" style="padding-left: 60px">Note that getting rid of Dropout from the graph will not affect testing set accuracy as Dropout is not used for inference.</div>
<ol start="7">
<li>The last step in obtaining the model in a mobile-friendly format is to convert it into a <kbd>.tflite</kbd> file. For this step, you will use <kbd>toco</kbd> command, which stands for TensorFlow Lite Optimizing Converter (<a href="https://www.tensorflow.org/lite/convert/">https://www.tensorflow.org/lite/convert/</a>). The code is provided as follows:</li>
</ol>
<pre style="padding-left: 60px">toco \<br/>--input_file=&lt;model_folder&gt;/logs/optimized/MNIST_optimized.pb\<br/>--input_format=TensorFlow_GRAPHDEF \<br/>--output_format=TFLITE \<br/>--inference_type=FLOAT \<br/>--input_type=FLOAT \<br/>--input_arrays=conv2d_1_input \<br/>--output_arrays=softmax_tensor_1/Softmax \<br/>--input_shapes=1,28,28,1 \<br/>--output_file=&lt;model_folder&gt;//mnist.tflite</pre>
<p>This will produce a file named <kbd>mnist.tflite</kbd> in <kbd>&lt;model_folder&gt;</kbd>. <span>Essentially, this step is trying to convert the optimized graph into a Flatbuffer for efficient on-device inference.</span></p>
<div class="packt_infobox">We will not cover deploying our project to the mobile device as its development is outside the scope of this book. However, feel free to take a look at TensorFlow Lite tutorials on how to deploy the TF Lite models Android (<a href="https://www.tensorflow.org/lite/demo_android">https://www.tensorflow.org/lite/demo_android</a>) or iOS (<a href="https://www.tensorflow.org/lite/demo_ios">https://www.tensorflow.org/lite/demo_ios</a>).</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Machine learning is at the edge of the next wave, where we try to make ML ubiquitous in our everyday life. It has several advantages such as offline access, data privacy, and so on.</p>
<p>In this chapter, we looked at a new library from Google known as TensorFlow Lite, which has been optimized for deploying ML models on mobile and embedded devices. We understood the architecture of TensorFlow Lite, which converts the trained TensorFlow model into <kbd>.tflite</kbd> format. This is designed for inference at fast speed and low memory on devices. TensorFlow Lite also supports multiple platforms, such as Android, iOS, Linux, and Raspberry Pi.</p>
<p>Next, we used the MNIST handwritten digit dataset to train a deep learning model. Subsequently, we followed the necessary steps to convert the trained model into <kbd>.tflite</kbd> format. The steps are as follows:</p>
<ol>
<li>Froze the graph with variables converted to constants</li>
<li>Optimized the graph for inference by removing the unused ops like Dropout</li>
<li>Used <strong>TensorFlow Optimization Converter Tool</strong> (<strong>toco</strong>) to convert the optimized model to <kbd>.tflitte</kbd> format</li>
</ol>
<p>At every step, we used TensorBoard to visualize the state of the graph.</p>
<p>This is a very exciting field that is continuing to evolve, both in terms of hardware and software. Once this technology reaches maturity, it will open up new use cases and business models across the world.</p>
<p>In the next chapter, we'll create a project that will help us convert text to speech. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<p>The following are the questions:</p>
<ol>
<li>How is TensorFlow Lite different from usual TensorFlow?</li>
<li>Can you try and if you can build the model on a movie review dataset in <span> </span><a href="60549866-497e-4dfa-890c-6651f34cf8e4.xhtml">Chapter 3</a><span>, </span><em>Sentiment Analysis in Your Browser Using TensorFlow.js</em>? Do you face some issues with Tensorflow Lite in that case?</li>
<li>Can you try Adam optimizer and see if it improves the performance of the model?</li>
<li>Can you think you operations other than Dropout which are also not important for inference on mobile?</li>
</ol>


            </article>

            
        </section>
    </body></html>