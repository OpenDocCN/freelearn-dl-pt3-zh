- en: Beginning with Serverless Computing and AWS Lambda
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book will encourage you to use your own custom-trained models with AWS
    Lambda and work with a simplified serverless computing approach. Later on, you
    will implement sample projects that signify the use of AWS Lambda for serving
    TensorFlow models.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss serverless deep learning and you will explore
    why serverless is so popular and the advantages of deploying applications using
    serverless. Also, you will look into the data science process and how serverless
    can enable an easy and convenient way to deploy deep learning applications. You
    will also briefly look into the sample projects that we will make in the forthcoming
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: You will also get to learn about the workings of the AWS implementation, including
    the traditional and serverless ways of deploying deep learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is serverless computing?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why serverless deep learning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Lambda function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sample projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is serverless computing?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Serverless computing is a type of architecture for which the code execution
    is managed by a cloud provider, which means that the developers do not have to
    worry about managing, provisioning and maintaining servers when deploying the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the possible ways of application deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '**On-premise** deployment, let''s you control the entire infrastructure including
    the hardware. In other words, it means that the application runs on our machine,
    which you can access physically.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, you have **Infrastructure as a Service** (**IaaS**), which means that
    you can't access the servers physically, but you control everything that is happening
    in it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, you have **Platform as a Service** (**PaaS**), where you don't control
    the operating system or runtime, but you can control our code and container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, you have **Function as a Service** (**FaaS**) which is a serverless
    model, and the only thing which you control is the code itself. It can significantly
    enable us to work on different applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why serverless deep learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's understand why the severless infrastructure is extremely useful for deploying
    deep learning models in a data science process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The usual data science process looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Business understanding: You need to understand the business needs, which includes
    defining the objectives and the possible data sources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data acquisition: You need to look into the data you are planning to use, explore
    it, and try to find correlations and gaps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Modeling: You start with the selection of most promising features, building
    the model, and training it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deployment: You need to operationalize the model and deploy it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Customer acceptance: You can provide the result to the customer and receive
    feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The preceding points are represented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6ec15de7-70ec-4696-8074-e8eaaa992a7f.png)'
  prefs: []
  type: TYPE_IMG
- en: Based on the feedback received from the customer, you can update the model and
    change the way you deploy it. The deployment and customer acceptance phases are
    iterative in nature. It means that you will have to get feedback from the user
    as early as possible. To achieve this, our infrastructure for the deployment has
    to be both simple and scalable at the same time, which can be done with the help
    of serverless infrastructure used for deploying the deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: You need to be aware that our deep learning infrastructure has to be integratable
    with our existing infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Where serverless deep learning works and where it doesn't work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Serverless deep learning deployment is very scalable, simple, and cheap to start.
    The downsides of it are the time limitations, CPU limitations, and memory limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Where serverless deep learning works?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following section, you will start by reiterating the advantages of serverless
    deep learning deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: It is extremely useful for your project. If you train your model and want to
    show it to the world, serverless deep learning will allow you to do so without
    complicated deployment and any upfront costs. AWS also provides free usage per
    month. It means that a number of invocations in AWS Lambda will be completely
    free. For example, in the image recognition project, which we will discuss in
    the following chapters, the number of runs will be about 100,000 times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless deep learning is great for early-stage startups that want to test
    their business hypotheses as early as possible. Simplicity and scalability allows
    small teams to start without expertise in AWS. AWS Lambda allows you to calculate
    the cost per customer in an easy way and to understand your startup cost per user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless deep learning is extremely convenient if you already have an existing
    infrastructure and want to optimize your costs. Serverless architecture will be
    a lot simpler and cheaper than the cluster one and it will be easier to maintain.
    Significantly, it reduces costs since you don't need to retain the unused servers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless deep learning would be extremely useful for cases where you have
    extremely high loads. For example, a lot of companies struggle to maintain the
    system in cases where there are 1 million requests during the first minute and
    zero requests in the next minute. The cluster will either be too large or it will
    take a certain time to scale. Serverless, on the other hand, has unmatched scalability,
    which allows the system to work on high load without rolling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where serverless deep learning doesn't work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deep learning will not work in the following situations:'
  prefs: []
  type: TYPE_NORMAL
- en: If one of the main features of your system is to provide a real-time response
    that is a very complex model; for example, if it is the part of an interaction
    between your user and the system, then the serverless architecture may not be
    enough for you. AWS Lambda has a cold start delay and the delay for the unloading
    and loading of the model into the memory. It does work fast, but it may take more
    than several seconds to run. Speed highly depends on the size and complexity of
    the model, so this is something you have to test beforehand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless deep learning may fail if your model utilizes a lot of data. AWS
    Lambda has certain limitations, such as three gigabytes for run and half a gigabyte
    for the hard disk, which means you either have to optimize your code in terms
    of memory usage or use the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your model has requirements on the CPU power or number of cores, then it
    may not be able to start on Lambda. There are no certain limits that could predict
    whether your model will or will not be able to start on AWS Lambda, so it is something
    which you need to test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An extremely complex model may not work well on serverless infrastructure. By
    complex, we mean larger than 1 or 2 gigabytes. It would take more time to download
    it from S3, and Lambda may not have enough memory to load it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These use cases mentioned above have shown us the landscape for the uses of
    serverless learning and it will help us to make a decision as to whether to use
    it or not. Finally, in a lot of cases, there isn't a definitive answer and it
    makes sense to continue testing your model on serverless.
  prefs: []
  type: TYPE_NORMAL
- en: Now we'll discuss the Lambda function as a serverless model.
  prefs: []
  type: TYPE_NORMAL
- en: Lambda function – AWS implementation of FaaS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss the workings of the AWS implementation of FaaS. The
    Lambda function is an AWS implementation of FaaS. The AWS service keeps Lambda
    configuration, which is basically code, libraries, and parameters within the service. Once
    it receives the trigger, it takes the container from the pool and puts the configuration
    inside the container. Then, it runs the code inside the container with the data
    from the event trigger. Once the container produces results, the service returns
    it in the Response.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram is a representation of the workings of the Lambda function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79b19130-55a3-4ec6-8f7b-bdac02657b00.png)'
  prefs: []
  type: TYPE_IMG
- en: Lambda scales automatically for up to 10,000 concurrent executions. Also, Lambda
    pricing is a pay per use service, so you would only have to pay for each round
    of Lambda that you use and you don't have to pay when it doesn't run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Lambda configuration consists of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code**: This is what you want to run within the function. The code needs
    to have an explicit declaration of the function, which you want for the service
    to run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Libraries**: These enable us to run more complicated processes. You will
    need to keep them inside the same package as the code itself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configurations**: These are various parameters that dictate how Lambda works.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The main parameters are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The relational memory and time out
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The runtime (for example, Python or node)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Triggers, which we will describe in the next section
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IAM role, which provides Lambda access to other interval services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environmental parameters, which allow us to customize the input parameter to
    our code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda triggers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are various AWS services that can act as a trigger for AWS Lambda, they
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DynamoDB**: This enables us to start the Lambda function on each new entry
    to the database'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon S3**: This helps the Lambda function start files in the bucket'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CloudWatch**: This enables us to run Lambda functions according to the shadow
    (for example, each minute, each day, or only at noon each Thursday)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lex**: This starts by looking at what the usual data science process looks
    like'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kinesis, SQS, and SNS**: These enable us to start the Lambda function on
    each object in the event stream'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a lot of different triggers, which means you can bind Lambda with
    a lot of different services.
  prefs: []
  type: TYPE_NORMAL
- en: Why deep learning on AWS Lambda?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here, you will see the advantages of AWS Lambda :'
  prefs: []
  type: TYPE_NORMAL
- en: Coding on an AWS Lambda is very easy. You will just need the package code and
    libraries, not the Docker containers. It enables you to start early and deploy
    the same code, which you would run locally. This is therefore perfect for early
    stage projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Lambda is extremely scalable and, more importantly, you don't have to manage
    the scalability or write separate logic for it because your data science application
    will be able to easily process a large number of tasks or work with multiple users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Lambda is priced conveniently. You only need to pay for what you're actually
    using and the price itself is very affordable. For example, for the image recognition
    model, the cost will be $1 for 20,000 to 30,000 runs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section you will know the difference between traditional and serverless
    architecture using Lamda.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional versus Serverless architecture using Lambda
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at the difference between traditional and serverless architecture.
    The following diagram represents the deep learning API through traditional architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/068b50de-a0b5-46b9-955a-a1ee4b2bdcb8.png)'
  prefs: []
  type: TYPE_IMG
- en: In the above traditional architecture, you will not only have to handle the
    cluster itself, but you will also have to handle all the balancing of API requests.
    Also, you have to manage the Docker container with the code and libraries and
    find a way to deploy it using the container registry.
  prefs: []
  type: TYPE_NORMAL
- en: You need to have extensive knowledge of AWS to understand this architecture.
    Although it is not very difficult, it can be a real issue to begin with. You will
    need to keep in mind that the AWS architecture for deep learning will have static
    costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the serverless implementations of the above application. The
    following diagram represents the architecture for deep learning using Lambda:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b379b00d-e659-489b-86f7-f9fe4516088f.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, you can see that it looks a lot easier than traditional
    architecture. you don't need to manage node balance scalability or containers—you
    just need to put in your coated libraries and Lambda manages everything else.
    Also, you can make a number of different prototypes with it and you will only
    need to pay for invocations. This makes Lambda the perfect way for making your
    deep learning model available to users. In the next section, you briefly be introduced
    to the projects that you will develop in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Sample projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will cover projects, which you will develop during the
    course of this book. you will create three projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning batch processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless deep learning workflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The deep learning API project provides a great hands-on experience since you
    are able to see results immediately from your browser. You will start with the
    deep learning API for image recognition. Image recognition is one of the tasks
    where deep learning shows incredible results, which are impossible to implement
    using any other approach. you will be using a contemporary, publicly available
    pre-trained inception model, which is version free. This project will also show
    you how easy it is to take an open source model and create an API interface on
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning batch processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the deep learning batch processing project, you will take a closer look at
    how a lot of companies run deep learning applications nowadays. In this project,
    you will build deep learning batch processing for image recognition. It will show
    us how high Lambda scalability allows us to process thousands of prediction drops
    at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless deep learning workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the serverless deep learning workflow project, you will highlight the patterns
    of deep learning models on the serverless infrastructure. You will make a serverless
    deep learning workflow for image recognition. This project will show you how you
    can use contemporary deployment techniques using AWS step functions. You will
    also learn how you can conduct A/B testing of the model during deployment, error
    handling, and a multistep process. This project will help you to understand the
    possible applications of serverless deployment and how to apply this knowledge
    to either your personal project or within your company.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you were introduced to the serverless functions, the AWS implementation,
    and the services. You looked at the Lambda function, which is an AWS implementation
    of FaaS. You also covered the workings of the AWS implementation of FaaS. Later,
    you understood why the serverless infrastructure is extremely useful for deploying
    deep learning models and the challenges you might face during its deployment.
    You also compared the traditional and serverless ways of deploying deep learning
    applications. You looked into the possible scenarios where the serverless deep
    learning works and where it doesn't work. Finally, you covered the various example
    projects that you will be learning about during the course of this book.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to work with AWS Lambda and its deployment.
  prefs: []
  type: TYPE_NORMAL
