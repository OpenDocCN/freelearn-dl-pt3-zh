- en: Creating Your First Deep Learning Web Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After developing an understanding of neural networks and their setup for use
    in real-world projects, the natural next step is to develop a web-based deep learning
    application. This chapter is dedicated to creating a complete web application—albeit
    a very simplistic one—that, in a very simple way, demonstrates how the integration
    of deep learning in applications is done.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will introduce several terms that will be used throughout this
    book, and so it is a recommended read even for those of you who already have a
    basic understanding of deep learning web applications so that you are able to
    understand the terms used in future chapters. We will begin by structuring a deep
    learning web application and learning how to understand datasets. We will then
    implement a simple neural network using Python and create a Flask API to work
    with server-side Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, the following topics will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Structuring a deep learning web application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a simple neural network using Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Flask API that works with server-side Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using cURL and the web client with Flask
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving the deep learning backend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can access the code used in this chapter at [https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-web/tree/master/Chapter3](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter3).
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, you''ll need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.6+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flask 1.1.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow 2.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structuring a deep learning web application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When solving a jigsaw puzzle, it is important that the parts fit, rather than
    them being forced together. Similarly, when developing a software solution, the
    parts of the solution must seamlessly work together and their interaction must
    be simple to understand. Good software requires proper software planning. Hence,
    providing a solid structure to the software is essential for its long-term use
    and for easy future maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin creating our first deep learning application that works on the
    web, we must chalk out a blueprint of the solution, keeping in mind the problems
    we wish to solve and the solutions to them. This is much like how we plan authentication
    systems or pass form values from one page to another during website development.
  prefs: []
  type: TYPE_NORMAL
- en: 'A general deep learning web solution would need the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: A server that can store data and respond with queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A system that can use the stored data and process it to produce deep learning-based
    responses to queries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A client that can send data to the server for storage, send queries with new
    data, and finally, accept and use the responses the server sends after querying
    the deep learning system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's try to visualize this structure using a diagram.
  prefs: []
  type: TYPE_NORMAL
- en: A structure diagram of a general deep learning web application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following diagram depicts the interaction between the web client, web server,
    and the deep learning model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f8763b49-1e75-456b-85d4-6b65ae1d8286.png)'
  prefs: []
  type: TYPE_IMG
- en: We will be creating three software parts—the client, the server, and the deep
    learning model—which will all work together. To do so, the client will make HTTP
    requests to the server and the server, in return, will produce output fetched
    from the separately trained deep learning model. This model may or may not be
    executed in the files present on the server that respond to the HTTP requests
    made by the client. In most cases, the deep learning model is separated from the
    file that handles the HTTP requests.
  prefs: []
  type: TYPE_NORMAL
- en: In the example presented in this chapter, we will present the server, the client,
    and the deep learning model in separate files. Our client will send simple HTTP
    requests to the server, such as a page-load request or a `GET` request for URLs,
    which will produce the output from the deep learning model based on the queries
    passed. However, it is very common practice for the client to communicate with
    the server via REST APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on to understanding the dataset that our application will work
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is of the utmost importance that we properly understand the dataset that
    we are working on in order to produce the best results—in terms of execution time
    and space for the data—with the most efficient code. The dataset we will be using
    here is probably the most popular dataset when it comes to using neural networks
    with images—the MNIST database of handwritten digits.
  prefs: []
  type: TYPE_NORMAL
- en: The MNIST dataset of handwritten digits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This dataset was created by a team made up of Yann LeCun, Corinna Cortes, and
    Christopher J.C. Burges. It is a large collection of images of handwritten digits,
    containing 60,000 training samples and 10,000 testing samples. The dataset is
    publicly available for download at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
    where it is present in the form of four `.gz` compressed files.
  prefs: []
  type: TYPE_NORMAL
- en: 'The four files are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`train-images-idx3-ubyte.gz`: The training set images. These images will be
    used to train the neural network classifier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train-labels-idx1-ubyte.gz`: The training set labels. Every image in the training
    set will have a label associated with it, which is the corresponding digit visible
    in that image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t10k-images-idx3-ubyte.gz`: The test set images. We will use these images
    to test our neural network prediction accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t10k-labels-idx1-ubyte.gz`: The labels for the images in the test set. When
    our neural network makes predictions on the test set, we will compare them against
    these values to check our results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The images stored in this dataset are not directly available for viewing due
    to their custom format. The developer working on the dataset is expected to create
    their own simple viewer for the images. Once you have done this, you will be able
    to see the images, which look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1fb5c7a-789d-4a36-88df-0aab844dd80a.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's talk about the images in a bit more depth. They are, as you can see, a
    little over the 25 pixels mark on both axes. To be exact, the images are all in
    the form of 28 x 28 pixels. Now, since the images are grayscale, it is possible
    for them to be stored in a single layer 28 x 28 matrix. Hence, we have a total
    of 784 values, ranging from 0 to 1, where 0 represents an entirely dark pixel
    and 1 represents a white pixel. Anything inside that range is a shade of black.
    In the MNIST dataset, these images are present in the form of a flattened array
    of 784 floating point numbers. In order to view these images, you need to convert
    the single dimension array into a two-dimensional array with a 28 x 28 shape and
    then plot the image using any self-developed or publicly available tools, such
    as Matplotlib or the Pillow library.
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss this method in the upcoming section.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s begin by downloading all four files from the MNIST dataset web page,
    available at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist).
    Once downloaded, extract all the files and you should have folders that resemble
    the names in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '`train-images.idx3-ubyte`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train-labels.idx1-ubyte`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t10k-images.idx3-ubyte`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t10k-labels.idx1-ubyte`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep these files in your working directory. We will now create a Jupyter notebook
    to perform **exploratory data analysis** (**EDA**) on the dataset files we have
    extracted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open your Jupyter Notebook environment in your browser and create a new Python
    notebook. Let''s begin by importing the necessary modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding lines import the `numpy` module and `matplotlib.pyplot` to the
    project. The `numpy` module provides high-performance mathematical functions in
    Python while the `matplotlib.pyplot` module provides a simple interface to plot
    and visualize graphs and images. In order to view all the output from this library
    in the Jupyter notebook, add the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you are on Windows, to extract a `.gz` file you can use the 7-zip software,
    which is an excellent compression/decompression tool that is available to download
    for free at [https://www.7-zip.org](https://www.7-zip.org).
  prefs: []
  type: TYPE_NORMAL
- en: Creating functions to read the image files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned earlier, it is not possible to directly view the images in your
    downloaded image files. So, we will now create a function in Python that the `matplotlib`
    module will be able to use to display the images in the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding `loadImageFile` function takes a single parameter, which is the
    name of the file that contains the images. We have two such files available for
    us in our downloaded files folder: `train-images-idx3-ubyte` and `t10k-images-idx3-ubyte`.
    The output of the preceding function is a `numpy` array of images. We can store
    the result in a Python variable, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to view the images that are in the variable holding the `numpy` array
    of images, we can define another function that takes a single image''s pixel array
    of 784 floating point numbers and plots them into a single image. The function
    can be defined as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, say we want to display the first of the test images; because we have stored
    the `numpy` array of images in the `test_images` variable, we can run the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We are able to see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67d8fcf8-1084-4a0e-aa5e-39b2ee798280.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we are able to view the images, we can proceed to building a function
    that will allow us to extract the corresponding digit from the labels.
  prefs: []
  type: TYPE_NORMAL
- en: Creating functions to read label files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two label files available to us in the MNIST dataset: `train-labels-idx1-ubyte`
    and `t10k-labels-idx1-ubyte`. To view these files, we can use the following function,
    which takes input of the filename as an argument and produces an array of one-hot-encoded
    labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns a `numpy` array of labels in one-hot encoding, with the
    dimensions of the number of samples in the dataset times by 10\. Let''s observe
    a single entry in order to understand the nature of one-hot encoding. Run the
    following code, which essentially makes a print of the one-hot-encoded label set
    from the first sample in the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We can understand this by noting that since the digit at the seventh index is
    `1`, the label of the first image in the test dataset is `7`.
  prefs: []
  type: TYPE_NORMAL
- en: A summary of the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After a very concise exploration of the available dataset, we are able to come
    up with the following results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training dataset contains 60,000 images with a dimension of 60,000 x 784,
    where each image is 28 x 28 pixels. The distribution of samples among the digits
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Digit** | **Number of Samples** | **Digit** | **Number of Samples** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 5,923 | 5 | 5,421 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 6,742 | 6 | 5,918 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5,958 | 7 | 6,265 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 6,131 | 8 | 5,851 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5,842 | 9 | 5,949 |'
  prefs: []
  type: TYPE_TB
- en: Observe that digit `5` has a smaller number of samples than digit `1`. So, it
    is quite possible that a model that isn't finely trained will make mistakes in
    recognizing digit `5`.
  prefs: []
  type: TYPE_NORMAL
- en: The summary of the number of labels present tells us that all 60,000 samples
    have their corresponding labels and none of their labels are missing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, on the test dataset, we have 10,000 images and labels and the distribution
    of the number of samples is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Digit** | **Number of Samples** | **Digit** | **Number of Samples** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 980 | 5 | 892 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1,135 | 6 | 958 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 1,032 | 7 | 1,028 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 1,010 | 8 | 974 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 982 | 9 | 1,009 |'
  prefs: []
  type: TYPE_TB
- en: The number of samples in the test dataset is quite evenly spread.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a simple neural network using Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After doing a very basic data analysis, we can move on to coding our first neural
    network in Python. You can revise the concepts of neural networks in [Chapter
    2](9a68dbce-f50e-4c5a-80e2-2b7f40e082ca.xhtml), *Getting Started With Deep Learning
    Using Python*, before moving on. We will now be creating a **convolutional neural
    network** (**CNN**), which will predict the handwritten digit labels.
  prefs: []
  type: TYPE_NORMAL
- en: We start by creating a new Jupyter notebook. You could name this `Model.ipynb`
    for convention. This notebook will be used to develop a **pickled** version of
    the deep learning model, which will later be put in a script that will generate
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the necessary modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The modules that will be needed for `Model.ipynb` are imported as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `keras` module is required to quickly implement high-performance neural
    networks with the TensorFlow backend. We have talked about Keras in earlier chapters.
    To install Keras, you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command will install Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Reusing our functions to load the image and label files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Remember the `loadImageFile` and `loadLabelFile` functions we created during
    the exploration of the dataset? We will need them again and so we will copy those
    same functions into this notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'Together, they produce two cells of code for each of the functions:'
  prefs: []
  type: TYPE_NORMAL
- en: The `loadImageFile()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `loadLabelFile()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In a new code cell, we create the `loadImageFile()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In another new code cell, the `loadLabelFile()` function is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then import the images and label files in the form of `numpy` arrays
    by using the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates the `train_images`, `train_labels`, `test_images`, and `test_labels`
    NumPy arrays. We can observe their shape and we get the following output for `train_images`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will learn how to reshape the arrays for processing with Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Reshaping the arrays for processing with Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The current shape of the image arrays are not Keras-friendly. We must convert
    the image arrays into a shape of `(60000, 28, 28, 1)` and `(10000, 28, 28, 1)`,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, we use the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we observe the shape of `x_train`, we get an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We have no changes to make in the labels arrays and so we directly assign them
    to `y_train` and `y_test`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will create a neural network using Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a neural network using Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we are ready to proceed with the creation of the neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first create a `Sequential` neural network model in Keras:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To add a neuron layer to the network, we use the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This adds a two-dimensional convolutional neuron layer to the network with an
    input shape that is the same as the shape of the images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s add the activation layer with `relu` as the activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'After adding the activation layer, we can perform a batch normalization. During
    training, the data passes through several computational layers and may become
    too large or too small. This is known as the **covariate shift** and batch normalization
    helps bring back the data to a central region. This helps the neural network train
    faster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now add more hidden layers to the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'At the last layer of the neural network, we need an output of 10 values, in
    the form of one-hot encoding, to denote the digit that has been predicted. To
    do this, we add a final layer of `10` neurons. This will hold 10 values in the
    continuous range of `0` to `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, to convert these 10 floating point values to a one-hot encoding, we
    use a `softmax` activation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Let's now compile and train the Keras neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling and training a Keras neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are now ready to compile and train the neural network. To compile the neural
    network, we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In our model, which we compiled in the previous block of code, we have set categorical
    cross-entropy as the `loss` function; the optimizer function used is the `Adam`
    optimizer and the metric for evaluation is `accuracy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then train the neural network with the `fit()` method of the Keras model
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: It is recommended that you perform a split of the training data into further
    validation and training data, while leaving the test set untouched but for this
    dataset, it is fine.
  prefs: []
  type: TYPE_NORMAL
- en: The training is done for 10 batches and the batch size is of 100 samples.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating and storing the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After training the model, we are now ready to evaluate its accuracy. To do
    so, we will use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We will get the following output for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/523c24c1-f2c0-4d35-88e5-10b86c746140.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We get 99% accuracy, which is a very good accuracy score. Now, we can save
    the model, which will be used in the future to make predictions for user input
    through the web portal. We will split the model into two parts—the model structure
    and the model weights. To save the structure, we will use the JSON format, as
    shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to save the weights of the Keras model, we use the `save_weights()` method
    for the object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will create a Flask API to work with server-side Python.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Flask API to work with server-side Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have completed our deep learning model and stored its structure in the `model.json`
    file and the weights for the model in the `weights.h5` file. We are now ready
    to wrap the model data in an API so that we can expose the model to web-based
    calls via the `GET` or `POST` methods. Here, we will be discussing the `POST`
    method. Let's begin with the required setup on the server.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the server, we will require the Flask module—which will be service requests—which
    in turn will be running code that requires Keras (and so, TensorFlow), NumPy,
    and many other modules. In order to quickly set up the environment for our project,
    we follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Anaconda.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install TensorFlow and Keras.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install Pillow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install Flask.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can refer to the following block of commands to install TensorFlow, Keras,
    Pillow, and Flask:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to start developing our API.
  prefs: []
  type: TYPE_NORMAL
- en: Uploading the model structure and weights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The model structure file, `model.json`, and the weights file, `weights.h5`,
    need to be present in the working directory. You can copy the files to a new folder—say,
    `flask_api`—or upload them to the correct path if you are using a remote server.
  prefs: []
  type: TYPE_NORMAL
- en: Creating our first Flask server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new file in the working directory and name it `flask_app.py`. This
    file will be the one that handles all requests made to the server. Put the following
    code in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code first imports the necessary modules into the script. Then,
    it sets the app as the Flask server object and defines the `index` function with
    a directive of handling all the requests made to the `"/"` address, regardless
    of the type of request. At the end of the script, the `run()` method of the Flask
    object app is used to bind the script to a specified port on the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now deploy this simple *Hello World* Flask server. We run the following
    command in a Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now, when we open the `http://localhost/` URL in the browser, we are greeted
    with a page presenting *Hello World*. The `index` function handles the requests
    made at the root of the server, since it's route is set to `"/"`. Let's now extend
    this example toward creating an API that can handle requests specifically for
    prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the necessary modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the preceding example, we will extend the `flask import` statement to import
    an additional method, `request`, which will allow us how to handle the `POST`
    requests made to the server. The line then looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We then import the modules necessary for the reading and storing of the images.
    Also, the `numpy` module is imported as in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we import the `model_from_json()` method of the Keras module to load
    the saved model files. We then import `tensorflow`, as Keras is dependent on it
    to execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Next, we load data into the script runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Loading data into the script runtime and setting the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have imported the necessary modules, we load the saved model JSON and
    weights, as in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Note that we have also created a default `graph` item for the session ahead.
    This was implicitly created during the model training but is not carried over
    in the saved `model` and `weights` files, so we must explicitly create it here.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the app and index function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we set the `app` variable to a Flask object and set the `"/"` route to
    be handled by the `index` function, which actually produces no meaningful output.
    This is because we will be using the `/predict` route to serve our prediction
    API as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We will cover the convert image function in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Converting the image function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We might sometimes get images in the form of `base64` encoded strings if the
    user makes an image `POST` request with a suitable setting. We can create a function
    to handle that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We use the `re` module for regex to determine whether the data passed is in
    the form of a `base64` string. The `base64` module is needed to decode the string
    and then the file is saved as `image.png`.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s define the `/predict` route, which will be our API to respond to
    the predicted digit with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `predict()` function takes in a `POST` method input, makes a check
    on the format that the file is passed in, and then saves it to the disk with the
    name of `image.png`. Then, the image is read into the program and resized to 28
    x 28 dimensions. Next, the image array is reshaped, such that it can be put into
    the Keras model for prediction. Then, we use the `predict()` method of the Keras
    model and get a one-hot-encoded output with the predicted digit's index set to
    `1`, while the rest remains as `0`. We determine the digit and send it to the
    output of the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we must, at the end of the file, add the code to bind the server to a
    port and set the required configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We have set the `debug=True` parameter in order to be able to see—in the server's
    console—whether any error occurs on the server. This is always a good idea during
    development but in production, this line of code can be skipped.
  prefs: []
  type: TYPE_NORMAL
- en: 'A final step before we run the application is to update the code for the `''/''`
    route. We will load the `index.html` item that we created whenever a person calls
    this route, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We are now all set to start up the server and check whether it is working correctly.
    We use the same command as used previously to start up the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command will start up the server.
  prefs: []
  type: TYPE_NORMAL
- en: Using the API via cURL and creating a web client using Flask
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With our server running, we can send `POST` requests to it with the image content
    and expect a predicted digit in the output. Two ways to test any API without any
    third-party tools are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Use cURL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop a client to call the API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will be covering both of these methods.
  prefs: []
  type: TYPE_NORMAL
- en: Using the API via cURL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we develop a client to send `POST` requests to the API server, let's
    test the API via cURL, which is a command-line tool used to simulate `GET` and
    `POST` requests to URLs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command in Terminal or Command Prompt to make a `curl` request
    to your prediction API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `-F` flag is used to indicate that the `POST` request will contain
    files. The name of the `POST` variable that will hold the file is `img`,`path_to_file`
    should be replaced with the full path to the file that you wish to send to the
    server for the image that the prediction is to be made on.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how the API works with an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say we have the following image with the `self2.png` filename and dimensions
    of 275 x 275:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1178ecc-74c4-4240-9fa9-5fa0ff8e6c67.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Clearly, the image dimensions on the serverside must be adjusted. To make the
    request, we use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9e4c932-14ec-410e-81ec-255822daa48e.png)'
  prefs: []
  type: TYPE_IMG
- en: The output of the API is a single integer—`2`. So, the API works successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple web client for the API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now be creating a bare-bones web Client to call the API. To do so,
    we must modify our current code. In `flask_app.py`, first change the `import`
    statement for Flask in order to extend it to another module—`render_template`—as
    shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we create a folder, `templates`, in the working directory and add a file,
    `index.html`, to it with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Essentially, all we do here is create a form with a single input element of
    the file type, called `img`. We then add jQuery to the page and create a link
    to a static file, `index.js`, which is served in the `static` folder of the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create the `index.js` file. First, create a folder, `static`, in the
    root directory and then create a new file, `index.js`, with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The preceding jQuery code makes a `POST` request to the `/predict/` route and
    then updates the `result` divide on the page with the value that is returned from
    the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a sample run on this web client. First, we need to restart the
    Flask server. Then, we open `http://localhost/` in the browser to get a web page
    that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/216dfe04-0135-4771-979f-4cd732b1d1e5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Say we choose a file named `mnist7.png`, which is essentially the first image
    of the test dataset and looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ea2f8b5-6d27-47cc-9670-0bb3f2e5e4f9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The expected output is `7`. After clicking Submit, we get the following output
    on the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ac49e88-f2b8-4b42-b530-eaffc91dcb4a.png)'
  prefs: []
  type: TYPE_IMG
- en: We can observe that that is the correct output and conclude that the web client
    works correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the deep learning backend
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The simple model we have trained here is hardly one that we can claim is close
    to a perfect model. There are several methods that we can use to extend this model
    to make it better. For instance, some of the most basic steps that we can take
    to improve our deep learning model are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increase training epochs**: We have only trained our model for 10 epochs,
    which is usually a very small value for any deep learning model. Increasing the
    number of training epochs can improve the accuracy of the model. However, it can
    also lead to overfitting and so the number of epochs must be experimented with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**More training samples**: Our web client currently doesn''t do much more than
    show the predicted value. However, we could extend it to get feedback from the
    user on whether the prediction we made was correct. We can then add the user''s
    input image to the training samples and train with the user-provided label for
    the image. We must, however, take caution against spammy user input images and
    labels and only provide this feature to trusted users or beta testers for our
    web app.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Create a deeper network**: We could increase the number of hidden layers
    in the network to make the predictions more accurate. Again, this method is susceptible
    to overfitting and must be carefully experimented with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered, in complete detail, how you can create a deep learning
    model and then facilitate its usage through an API via a web client or using cURL.
    The chapter began by discussing how deep learning web applications are structured,
    the various components of such applications, and how they interact with each other.
    Then, a short discussion and exploration of the MNIST handwritten digits dataset
    was presented. This led us on to the next section, where we built a deep learning
    model and stored it in files for future use. These files were then imported to
    the server API scripts and executed there whenever the API was called. Finally,
    the chapter presented a very basic client for the API and also instructed you
    on how to use the API over cURL through the command-line interface.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss how deep learning can be performed within
    the browser window using TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
