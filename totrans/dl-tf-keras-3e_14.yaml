- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Math Behind Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discuss the math behind deep learning. This topic is quite
    advanced and not necessarily required for practitioners. However, it is recommended
    reading if you are interested in understanding what is going on *under the hood*
    when you play with neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what you will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: A historical introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concepts of derivatives and gradients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent and backpropagation algorithms commonly used to optimize deep
    learning networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s begin!
  prefs: []
  type: TYPE_NORMAL
- en: History
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The basics of continuous backpropagation were proposed by Henry J. Kelley [1]
    in 1960 using dynamic programming. Stuart Dreyfus proposed using the chain rule
    in 1962 [2]. Paul Werbos was the first to use backpropagation (backprop for short)
    for neural nets in his 1974 PhD thesis [3]. However, it wasn’t until 1986 that
    backpropagation gained success with the work of David E. Rumelhart, Geoffrey E.
    Hinton, and Ronald J. Williams published in Nature [4]. In 1987, Yann LeCun described
    the modern version of backprop currently used for training neural networks [5].
  prefs: []
  type: TYPE_NORMAL
- en: The basic intuition of **Stochastic Gradient Descent** (**SGD**) was introduced
    by Robbins and Monro in 1951 in a context different from neural networks [6].
    In 2012 – or 52 years after the first time backprop was first introduced – AlexNet
    [7] achieved a top-5 error of 15.3% in the ImageNet 2012 Challenge using GPUs.
    According to The Economist [8], *Suddenly people started to pay attention, not
    just within the AI community but across the technology industry as a whole.* Innovation
    in this field was not something that happened overnight. Instead, it was a long
    walk lasting more than 50 years!
  prefs: []
  type: TYPE_NORMAL
- en: Some mathematical tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before introducing backpropagation, we need to review some mathematical tools
    from calculus. Don’t worry too much; we’ll briefly review a few areas, all of
    which are commonly covered in high school-level mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will review two basic concepts of geometry and algebra that are quite useful
    for machine learning: vectors and the cosine of angles. We start by giving an
    explanation of vectors. Fundamentally, a vector is a list of numbers. Given a
    vector, we can interpret it as a direction in space. Mathematicians most often
    write vectors as either a column *x* or row vector *x*^T. Given two column vectors
    *u* and *v*, we can form their dot product by computing ![](img/B18331_14_001.png).
    It can be easily proven that ![](img/B18331_14_002.png) where ![](img/B18331_10_024.png)
    is the angle between the two vectors.'
  prefs: []
  type: TYPE_NORMAL
- en: Here are two easy questions for you. What is the result when the two vectors
    are very close? And what is the result when the two vectors are the same?
  prefs: []
  type: TYPE_NORMAL
- en: Derivatives and gradients everywhere
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Derivatives are a powerful mathematical tool. We are going to use derivatives
    and gradients to optimize our network. Let’s look at the definition. The derivative
    of a function *y* = *f*(*x*) of a variable *x* is a measure of the rate at which
    the value *y* of the function changes with respect to the change of the variable
    *x*.
  prefs: []
  type: TYPE_NORMAL
- en: If *x* and *y* are real numbers, and if the graph of *f* is plotted against
    *x*, the derivative is the “slope” of this graph at each point.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the function is linear ![](img/B18331_14_004.png), the slope is ![](img/B18331_14_005.png).
    This is a simple result of calculus, which can be derived by considering that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_006.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B18331_14_007.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B18331_14_008.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In *Figure 14.1*, we show the geometrical meaning of ![](img/B18331_14_009.png),
    ![](img/B18331_14_010.png), and the angle ![](img/B18331_10_024.png) between the
    linear function and the *x*-cartesian axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B18331_14_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.1: An example of a linear function and rate of change'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the function is not linear, then computing the rate of change as the mathematical
    limit value of the ratio of the differences ![](img/B18331_14_012.png) as ![](img/B18331_14_013.png)
    becomes infinitely small. Geometrically, this is the tangent line at ![](img/B18331_14_014.png)
    as shown in *Figure 14.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing chart  Description automatically generated](img/B18331_14_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.2: Rate of change for ![](img/B18331_14_015.png) and the tangential
    line as ![](img/B18331_14_016.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, considering ![](img/B18331_14_015.png) and the derivative ![](img/B18331_14_018.png)
    in a given point, say *x* = 2, we can see that the derivative is positive ![](img/B18331_14_019.png),
    as shown in *Figure 14.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B18331_14_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.3: ![](img/B18331_14_015.png) and ![](img/B18331_14_018.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'A gradient is a generalization of the derivative for multiple variables. Note
    that the derivative of a function of a single variable is a scalar-valued function,
    whereas the gradient of a function of several variables is a vector-valued function.
    The gradient is denoted with an upside-down delta ![](img/B18331_14_022.png),
    and called “del” or *nabla* from the Greek alphabet. This makes sense as delta
    indicates the change in one variable, and the gradient is the change in all variables.
    Suppose ![](img/B18331_14_023.png) (e.g. the space of real numbers with *m* dimensions)
    and *f* maps from ![](img/B18331_14_024.png) to ![](img/B18331_14_025.png); the
    gradient is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_026.png)'
  prefs: []
  type: TYPE_IMG
- en: In math, a partial derivative ![](img/B18331_14_027.png) of a function of several
    variables is its derivative with respect to one of those variables, with the others
    held constant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that it is possible to show that the gradient is a vector (a direction
    to move) that:'
  prefs: []
  type: TYPE_NORMAL
- en: Points in the direction of the greatest increase of a function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is 0 at a local maximum or local minimum. This is because if it is 0, it cannot
    increase or decrease further.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The proof is left as an exercise to the interested reader. (Hint: consider
    *Figure 14.2* and *Figure 14.3*.)'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If the gradient points in the direction of the greatest increase for a function,
    then it is possible to move toward a local minimum for the function by simply
    moving in a direction opposite to the gradient. That’s the key observation used
    for gradient descent algorithms, which will be used shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example is provided in *Figure 14.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, radar chart  Description automatically generated](img/B18331_14_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig.14.4: Gradient descent for a function in 3 variables'
  prefs: []
  type: TYPE_NORMAL
- en: Chain rule
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The chain rule says that if we have a function *y* = *g*(*x*) and ![](img/B18331_14_028.png),
    then the derivative is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_029.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This chaining can be generalized beyond the scalar case. Suppose ![](img/B18331_14_023.png)
    and ![](img/B18331_14_031.png) with *g*, which maps from ![](img/B18331_14_032.png)
    to ![](img/B18331_14_024.png), and *f*, which maps from ![](img/B18331_14_024.png)
    to ![](img/B18331_14_025.png). With *y* = *g*(*x*) and *z* = *f*(*y*), we can
    deduce:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_036.png)'
  prefs: []
  type: TYPE_IMG
- en: The generalized chain rule using partial derivatives will be used as a basic
    tool for the backpropagation algorithm when dealing with functions in multiple
    variables. Stop for a second and make sure that you fully understand it.
  prefs: []
  type: TYPE_NORMAL
- en: A few differentiation rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It might be useful to remind ourselves of a few additional differentiation
    rules that will be used later:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Constant differentiation: *c’ = 0*, where *c* is a constant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Variable differentiation: ![](img/B18331_14_037.png), when deriving the differentiation
    of a variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Linear differentiation: ![](img/B18331_14_038.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reciprocal differentiation: ![](img/B18331_14_039.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exponential differentiation: ![](img/B18331_14_040.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many books about matrix calculus. Here we focus only on only a few
    basic operations used for neural networks. Recall that a matrix ![](img/B18331_14_041.png)
    can be used to represent the weights *w*[ij], with ![](img/B18331_14_042.png),
    ![](img/B18331_14_043.png) associated with the arcs between two adjacent layers.
    Note that by adjusting the weights we can control the “behavior” of the network
    and that a small change in a specific *w*[ij] will be propagated through the network
    following its topology (see *Figure 14.5*, where the edges in bold are the ones
    impacted by the small change in a specific *w*[ij]):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_14_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.5: Propagating *w*[ij] changes through the network via the edges
    in bold'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have reviewed some basic concepts of calculus, let’s start applying
    them to deep learning. The first question is how to optimize activation functions.
    Well, I am pretty sure that you are thinking about computing the derivative, so
    let’s do it!
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Chapter 1*, *Neural Network Foundations with TF*, we saw a few activation
    functions including sigmoid, tanh, and ReLU. In the section below, we compute
    the derivative of these activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Derivative of the sigmoid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember that the sigmoid is defined as ![](img/B18331_14_044.png) (see *Figure
    14.6*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.6: Sigmoid activation function'
  prefs: []
  type: TYPE_NORMAL
- en: 'The derivative can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_045.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore the derivative of ![](img/B18331_14_046.png) can be computed as a
    very simple form: ![](img/B18331_14_047.png).'
  prefs: []
  type: TYPE_NORMAL
- en: Derivative of tanh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remember that the arctan function is defined as ![](img/B18331_14_048.png)
    as seen in *Figure 14.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B18331_14_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.7: Tanh activation function'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you remember that ![](img/B18331_14_049.png) and ![](img/B18331_14_050.png),
    then the derivative is computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_051.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore the derivative of ![](img/B18331_14_052.png) can be computed as a
    very simple form: ![](img/B18331_14_053.png).'
  prefs: []
  type: TYPE_NORMAL
- en: Derivative of ReLU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ReLU function is defined as ![](img/B18331_14_054.png) (see *Figure 14.8*).
    The derivative of ReLU is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_055.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that ReLU is non-differentiable at zero. However, it is differentiable
    anywhere else, and the value of the derivative at zero can be arbitrarily chosen
    to be a 0 or 1, as demonstrated in *Figure 14.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B18331_14_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.8: ReLU activation function'
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have computed the derivative of the activation functions, we can
    describe the backpropagation algorithm — the mathematical core of deep learning.
    Sometimes, backpropagation is called *backprop* for short.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that a neural network can have multiple hidden layers, as well as one
    input layer and one output layer.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to that, recall from *Chapter 1*, *Neural Network Foundations with
    TF*, that backpropagation can be described as a way of progressively correcting
    mistakes as soon as they are detected. In order to reduce the errors made by a
    neural network, we must train the network. The training needs a dataset including
    input values and the corresponding true output value. We want to use the network
    for predicting output as close as possible to the true output value. The key intuition
    of the backpropagation algorithm is to update the weights of the connections based
    on the measured error at the output neuron(s). In the remainder of this section,
    we will explain how to formalize this intuition.
  prefs: []
  type: TYPE_NORMAL
- en: 'When backpropagation starts, all the weights have some random assignment. Then
    the net is activated for each input in the training set; values are propagated
    forward from the input stage through the hidden stages to the output stage where
    a prediction is made (note that we keep the figure below simple by only representing
    a few values with green dotted lines, but in reality, all the values are propagated
    forward through the network):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, schematic  Description automatically generated](img/B18331_14_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.9: Forward step in backpropagation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we know the true observed value in the training set, it is possible to
    calculate the error made in the prediction. The easiest way to think about backtracking
    is to propagate the error back (see *Figure 14.10*), using an appropriate optimizer
    algorithm such as gradient descent to adjust the neural network weights, with
    the goal of reducing the error (again, for the sake of simplicity only a few error
    values are represented here):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_14_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.10: Backward step in backpropagation'
  prefs: []
  type: TYPE_NORMAL
- en: The process of forward propagation from input to output and backward propagation
    of errors is repeated several times until the error goes below a predefined threshold.
    The whole process is represented in *Figure 14.11*. A set of features is selected
    as input to a machine learning model that produces predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The predictions are compared with the (true) label, and the resulting loss
    function is minimized by the optimizer, which updates the weights of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_14_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.11: Forward propagation and backward propagation'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see in detail how the forward and backward steps are realized. It might
    be useful to have a look back at *Figure 14.5* and recall that a small change
    in a specific *w*[ij] will be propagated through the network following its topology
    (see *Figure 14.5*, where the edges in bold are the ones impacted by the small
    change in specific weights).
  prefs: []
  type: TYPE_NORMAL
- en: Forward step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'During the forward steps, the inputs are multiplied with the weights and then
    all summed together. Then the activation function is applied (see *Figure 14.12*).
    This step is repeated for each layer, one after another. The first layer takes
    the input features as input and it produces its output. Then, each subsequent
    layer takes as input the output of the previous layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Arrow  Description automatically generated with medium confidence](img/B18331_14_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.12: Forward propagation'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we look at one single layer, mathematically we have two equations:'
  prefs: []
  type: TYPE_NORMAL
- en: The transfer equation ![](img/B18331_14_056.png), where *x*[i] are the input
    values, *w*[i] are the weights, and *b* is the bias. In vector notation ![](img/B18331_14_057.png).
    Note that *b* can be *absorbed* in the summatory by setting ![](img/B18331_14_058.png)
    and ![](img/B18331_14_059.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The activation function: ![](img/B18331_14_060.png), where ![](img/B18331_07_010.png)
    is the chosen activation function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An artificial neural network consists of an input layer *I*, an output layer
    *O*, and any number of hidden layers *H*[i] situated between the input and the
    output layers. For the sake of simplicity, let’s assume that there is only one
    hidden layer, since the results can be easily generalized.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in *Figure 14.12*, the features *x*[i] from the input layer are multiplied
    by a set of fully connected weights *w*[ij] connecting the input layer to the
    hidden layer (see the left side of *Figure 14.12*). The weighted signals are summed
    together and with the bias to calculate the result ![](img/B18331_14_062.png)
    (see the center of *Figure 14.12*). The result is passed through the activation
    function ![](img/B18331_14_063.png), which leaves the hidden layer to the output
    layer (see the right side of *Figure 14.12*).
  prefs: []
  type: TYPE_NORMAL
- en: 'In summary, during the forward step we need to run the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: For each neuron in a layer, multiply each input by its corresponding weight.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then for each neuron in the layer, sum all input weights together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, for each neuron, apply the activation function on the result to compute
    the new output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'At the end of the forward step, we get a predicted vector ![](img/B18331_14_064.png)
    from the output layer *o* given the input vector *x* presented at the input layer.
    Now the question is: how close is the predicted vector ![](img/B18331_14_064.png)
    to the true value vector *t*?'
  prefs: []
  type: TYPE_NORMAL
- en: That’s where the backstep comes in.
  prefs: []
  type: TYPE_NORMAL
- en: Backstep
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand how close the predicted vector ![](img/B18331_14_064.png) is
    to the true value vector *t*, we need a function that measures the error at the
    output layer *o*. That is the *loss function* defined earlier in the book. There
    are many choices for loss function. For instance, we can define the mean squared
    error defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_067.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that *E* is a quadratic function and, therefore, the difference is quadratically
    larger when *t* is far away from ![](img/B18331_14_064.png), and the sign is not
    important. Note that this quadratic error (loss) function is not the only one
    that we can use. Later in this chapter, we will see how to deal with cross-entropy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, remember that the key point is that during the training, we want to adjust
    the weights of the network to minimize the final error. As discussed, we can move
    toward a local minimum by moving in the opposite direction to the gradient ![](img/B18331_14_069.png).
    Moving in the opposite direction to the gradient is the reason why this algorithm
    is called *gradient descent*. Therefore, it is reasonable to define the equation
    for updating the weight *w*[ij] as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_070.png)'
  prefs: []
  type: TYPE_IMG
- en: For a function in multiple variables, the gradient is computed using partial
    derivatives. We introduce the hyperparameter ![](img/B18331_01_025.png) – or,
    in ML lingo, the learning rate – to account for how large a step should be in
    the direction opposite to the gradient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the error, *E*, we have the equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_072.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding equation is simply capturing the fact that a slight change will
    impact the final error, as seen in *Figure 14.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_14_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.13: A small change in *w*[ij] will impact the final error *E*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define the notation used throughout our equations in the remaining section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_073.png) is the input to node *j* for layer *l*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18331_14_074.png) is the activation function for node *j* in layer
    *l* (applied to ![](img/B18331_14_073.png)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18331_14_076.png) is the output of the activation of node *j* in layer
    *l*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18331_14_077.png) is the matrix of weights connecting the neuron *i*
    in layer ![](img/B18331_14_078.png) to the neuron *j* in layer *l*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18331_14_079.png) is the bias for unit *j* in layer *l*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18331_14_080.png) is the target value for node *o* in the output layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now we need to compute the partial derivative for the error at the output layer
    ![](img/B18331_14_081.png) when the weights change by ![](img/B18331_14_082.png).
    There are two different cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1:** Weight update equation for a neuron from hidden (or input) layer
    to output layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Case 2:** Weight update equation for a neuron from hidden (or input) layer
    to hidden layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll begin with Case 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Case 1: From hidden layer to output layer'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this case, we need to consider the equation for a neuron from hidden layer
    *j* to output layer *o*. Applying the definition of *E* and differentiating we
    have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_083.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here the summation disappears because when we take the partial derivative with
    respect to the *j*-th dimension, the only term that is not zero in the error is
    the *j*-th. Considering that differentiation is a linear operation and that ![](img/B18331_14_084.png)
    – because the true ![](img/B18331_14_085.png) value does not depend on ![](img/B18331_14_086.png)
    – we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_087.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Applying the chain rule again and remembering that ![](img/B18331_14_088.png),
    we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_089.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Remembering that ![](img/B18331_14_090.png), we have ![](img/B18331_14_091.png)
    again because when we take the partial derivative with respect to the *j*-th dimension
    the only term that is not zero in the error is the *j*-th. By definition ![](img/B18331_14_092.png),
    so putting everything together we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_093.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The gradient of the error *E* with respect to the weights *w*[j] from the hidden
    layer *j* to the output layer *o* is therefore simply the product of three terms:
    the difference between the prediction ![](img/B18331_14_064.png) and the true
    value ![](img/B18331_14_080.png), the derivative ![](img/B18331_14_096.png) of
    the output layer activation function, and the activation output ![](img/B18331_14_097.png)
    of node *j* in the hidden layer. For simplicity we can also define ![](img/B18331_14_098.png)
    and get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_099.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In short, for Case 1, the weight update equation for each of the hidden-output
    connections is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_100.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note: if we want to explicitly compute the gradient with respect to the output
    layer biases, the steps to follow are similar to the ones above with only one
    difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_101.png)'
  prefs: []
  type: TYPE_IMG
- en: so in this case ![](img/B18331_14_102.png).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll look at Case 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'Case 2: From hidden layer to hidden layer'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this case, we need to consider the equation for a neuron from a hidden layer
    (or the input layer) to a hidden layer. *Figure 14.13* showed that there is an
    indirect relationship between the hidden layer weight change and the output error.
    This makes the computation of the gradient a bit more challenging. In this case,
    we need to consider the equation for a neuron from hidden layer *i* to hidden
    layer *j*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying the definition of *E* and differentiating we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_103.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this case, the sum will not disappear because the change of weights in the
    hidden layer is directly affecting the output. Substituting ![](img/B18331_14_104.png)
    and applying the chain rule we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_105.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The indirect relation between ![](img/B18331_14_106.png) and the internal weights
    *w*[ij] (*Figure 14.13*) is mathematically expressed by the expansion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_107.png)'
  prefs: []
  type: TYPE_IMG
- en: since ![](img/B18331_14_108.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'This suggests applying the chain rule again:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_109.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Applying the chain rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_110.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Substituting ![](img/B18331_14_106.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_112.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Deriving:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_113.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Substituting ![](img/B18331_14_076.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_115.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Applying the chain rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_116.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Substituting ![](img/B18331_14_117.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_118.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Deriving:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_119.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we can combine the above two results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_120.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B18331_14_121.png)'
  prefs: []
  type: TYPE_IMG
- en: 'and get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_122.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Remembering the definition: ![](img/B18331_14_098.png), we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_124.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This last substitution with ![](img/B18331_14_125.png) is particularly interesting
    because it backpropagates the signal ![](img/B18331_14_125.png) computed in the
    subsequent layer. The rate of change ![](img/B18331_14_081.png) with respect to
    the rate of change of the weights *w*[ij] is therefore the multiplication of three
    factors: the output activations *y*[i] from the layer below, the derivative of
    hidden layer activation function ![](img/B18331_14_128.png), and the sum of the
    backpropagated signal ![](img/B18331_14_125.png) previously computed in the subsequent
    layer weighted by ![](img/B18331_14_086.png). We can use this idea of backpropagating
    the error signal by defining ![](img/B18331_14_131.png) and therefore ![](img/B18331_14_132.png).
    This suggests that in order to calculate the gradients at any layer ![](img/B18331_14_133.png)
    in a deep neural network, we can simply multiply the backpropagated error signal
    ![](img/B18331_14_134.png) and multiply it by the feed-forward signal ![](img/B18331_14_135.png),
    arriving at the layer *l*. Note that the math is a bit complex but the result
    is indeed very very simple! The intuition is given in *Figure 14.14*. Given a
    function ![](img/B18331_14_136.png), computed locally to a neuron with the input
    ![](img/B18331_14_137.png), and ![](img/B18331_14_138.png), the gradients ![](img/B18331_14_139.png)
    are backpropagated. Then, they are combined via the chain rule with the local
    gradients ![](img/B18331_14_140.png) and ![](img/B18331_14_141.png) for further
    backpropagation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, *L* denotes the error from the generic previous layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_14_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.14: An example of the math behind backpropagation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: if we want to explicitly compute the gradient with respect to the output
    layer biases, it can be proven that ![](img/B18331_14_142.png). We leave this
    as an exercise for you.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, for Case 2 (hidden-to-hidden connection) the weight delta is ![](img/B18331_14_143.png)
    and the weight update equation for each of the hidden-hidden connections is simply:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_144.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We have arrived at the end of this section and all the mathematical tools are
    defined to make our final statement. The essence of the backstep is nothing more
    than applying the weight update rule one layer after another, starting from the
    last output layer and moving back toward the first input layer. Difficult to derive,
    to be sure, but extremely easy to apply once defined. The whole forward-backward
    algorithm at the core of deep learning is then the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the feedforward signals from the input to the output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the output error *E* based on the predictions ![](img/B18331_14_064.png)
    and the true value ![](img/B18331_14_080.png).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Backpropagate the error signals; multiply them with the weights in previous
    layers and with the gradients of the associated activation functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the gradients ![](img/B18331_14_147.png) for all of the parameters ![](img/B18331_10_024.png)
    based on the backpropagated error signal and the feedforward signals from the
    inputs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the parameters using the computed gradients ![](img/B18331_14_149.png).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that the above algorithm will work for any choice of differentiable error
    function *E* and for any choice of differentiable activation ![](img/B18331_14_150.png)
    function. The only requirement is that both must be differentiable.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent with backpropagation is not guaranteed to find the global minimum
    of the loss function, but only a local minimum. However, this is not necessarily
    a problem observed in practical application.
  prefs: []
  type: TYPE_NORMAL
- en: Cross entropy and its derivative
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Gradient descent can be used when cross-entropy is adopted as the loss function.
    As discussed in *Chapter 1*, *Neural Network Foundations with TF*, the logistic
    loss function is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_151.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where *c* refers to one-hot-encoded classes (or labels) whereas *p* refers
    to softmax-applied probabilities. Since cross-entropy is applied to softmax-applied
    probabilities and to one-hot-encoded classes, we need to take into account the
    chain rule for computing the gradient with respect to the final weights *score*[i].
    Mathematically, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_152.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Computing each part separately, let’s start from ![](img/B18331_14_153.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_154.png)'
  prefs: []
  type: TYPE_IMG
- en: (noting that for a fixed ![](img/B18331_14_155.png) all the terms in the sum
    are constant except the chosen one).
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_156.png)'
  prefs: []
  type: TYPE_IMG
- en: (applying the partial derivative to the sum and considering that ![](img/B18331_14_157.png))
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_158.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let’s compute the other part ![](img/B18331_14_159.png) where *p*[i] is
    the softmax function defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_160.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The derivative is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_161.png)'
  prefs: []
  type: TYPE_IMG
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_162.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the Kronecker delta ![](img/B18331_14_163.png) we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_164.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, considering that we are computing the partial derivative, all the
    components are zeroed with the exception of only one, and we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_165.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Combining the results, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_166.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where *c*[i] denotes the one-hot-encoded classes and *p*[i] refers to the softmax
    probabilities. In short, the derivative is both elegant and easy to compute:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_167.png)'
  prefs: []
  type: TYPE_IMG
- en: Batch gradient descent, stochastic gradient descent, and mini-batch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we generalize the previous discussion, then we can state that the problem
    of optimizing a neural network consists of adjusting the weights *w* of the network
    in such a way that the loss function is minimized. Conveniently, we can think
    about the loss function in the form of a sum, as in this form it’s indeed representing
    all the loss functions commonly used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_168.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this case, we can perform a derivation using steps very similar to those
    discussed previously, following the update rule, where ![](img/B18331_01_025.png)
    is the learning rate and ![](img/B18331_14_022.png) is the gradient:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_171.png)'
  prefs: []
  type: TYPE_IMG
- en: In many cases, evaluating the above gradient might require an expensive evaluation
    of the gradients from all summand functions. When the training set is very large,
    this can be extremely expensive. If we have three million samples, we have to
    loop through three million times or use the dot product. That’s a lot! How can
    we simplify this? There are three types of gradient descent, each different in
    the way they handle the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Batch gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Batch Gradient Descent** (**BGD**) computes the change of error but updates
    the whole model only once the entire dataset has been evaluated. Computationally
    it is very efficient, but it requires that the results for the whole dataset be
    held in the memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Instead of updating the model once the dataset has been evaluated, **Stochastic
    Gradient Descent** (**SGD**) does so after every single training example. The
    key idea is very simple: SGD samples a subset of summand functions at every step.'
  prefs: []
  type: TYPE_NORMAL
- en: Mini-batch gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Mini-Batch Gradient Descent** (**MBGD**) is very frequently used in deep
    learning. MBGD (or mini-batch) combines BGD and SGD in one single heuristic. The
    dataset is divided into small batches of about size *bs*, generally 64 to 256\.
    Then each of the batches is evaluated separately.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that *bs* is another hyperparameter to fine-tune during training. MBGD
    lies between the extremes of BGD and SGD – by adjusting the batch size and the
    learning rate parameters, we sometimes find a solution that descends closer to
    the global minimum than what can be achieved by either of the extremes.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast with gradient descent, where the cost function is minimized more
    smoothly, the mini-batch gradient has a bit more of a noisy and bumpy descent,
    but the cost function still trends downhill. The reason for the noise is that
    mini-batches are a sample of all the examples and this sampling can cause the
    loss function to oscillate.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking about backpropagation and ConvNets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will examine backprop and ConvNets. For the sake of simplicity,
    we will focus on an example of convolution with input *X* of size 3x3, one single
    filter *W* of size 2x2 with no padding, stride 1, and no dilation (see *Chapter
    3*, *Convolutional Neural Networks*). The generalization is left as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard convolution operation is represented in *Figure 14.15*. Simply
    put, the convolutional operation is the forward pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input****X11****X12****X13****X21****X22****X23****X31****X32****X33**
    | **Weights****W11****W12****W21****W22** | **Convolution****W11X11+W12X12+W21X21+W22X22****W11X12+W12X13+W21X21+W22X23****W11X21+W12X22+W21X31+W22X32****W11X22+W12X23+W21X32+W22X33**
    |'
  prefs: []
  type: TYPE_TB
- en: 'Figure 14.15: Forward pass for our ConvNet toy example'
  prefs: []
  type: TYPE_NORMAL
- en: Following the examination of *Figure 14.15*, we can now focus our attention
    on the backward pass for the current layer. The key assumption is that we receive
    a backpropagated signal ![](img/B18331_14_172.png) as input, and we need to compute
    ![](img/B18331_14_173.png) and ![](img/B18331_14_174.png). This computation is
    left as an exercise, but please note that each weight in the filter contributes
    to each pixel in the output map or, in other words, any change in a weight of
    a filter affects all the output pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking about backpropagation and RNNs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remember from *Chapter 5*, *Recurrent Neural Networks*, the basic equation for
    an RNN is ![](img/B18331_14_175.png), the final prediction is ![](img/B18331_14_176.png)
    at step *t*, the correct value is *y*[t], and the error *E* is the cross-entropy.
    Here *U*, *V*, and *W* are learning parameters used for the RNN’s equations. These
    equations can be visualized as shown in *Figure 14.16*, where we unroll the recurrency.
    The core idea is that total error is just the sum of the errors at each time step.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we used SGD, we need to sum the errors and the gradients at each time step
    for one given training example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.16: RNN unrolled with equations'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are not going to write all the tedious math behind all the gradients but
    rather focus only on a few peculiar cases. For instance, with math computations
    similar to the ones made in the previous sections, it can be proven by using the
    chain rule that the gradient for *V* depends only on the value at the current
    time step *s*[3], *y*[3] and ![](img/B18331_14_177.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_178.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, ![](img/B18331_14_179.png) has dependencies carried across time steps
    because, for instance, ![](img/B18331_14_180.png) depends on *s*[2], which depends
    on *W*[2] and *s*[1]. As a consequence, the gradient is a bit more complicated
    because we need to sum up the contributions of each time step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_181.png)'
  prefs: []
  type: TYPE_IMG
- en: To understand the preceding equation, imagine that we are using the standard
    backpropagation algorithm used for traditional feedforward neural networks but
    for RNNs. We need to additionally add the gradients of *W* across time steps.
    That’s because we can effectively make the dependencies across time explicit by
    unrolling the RNN. This is the reason why backprop for RNNs is frequently called
    **Backpropagation Through Time** (**BPTT**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The intuition is shown in *Figure 14.17*, where the backpropagated signals
    are represented:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_14_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.17: RNN equations and backpropagated signals'
  prefs: []
  type: TYPE_NORMAL
- en: 'I hope that you have been following up to this point because now the discussion
    will be slightly more difficult. If we consider:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_182.png)'
  prefs: []
  type: TYPE_IMG
- en: 'then we notice that ![](img/B18331_14_183.png) should be again computed with
    the chain rule, producing a number of multiplications. In this case, we take the
    derivative of a vector function with respect to a vector, so we need a matrix
    whose elements are all the pointwise derivatives (in math, this matrix is called
    a Jacobian). Mathematically, it can be proven that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_184.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_14_185.png)'
  prefs: []
  type: TYPE_IMG
- en: The multiplication in the above equation is particularly problematic since both
    the sigmoid and tanh get saturated at both ends and their derivative goes to 0\.
    When this happens, they drive other gradients in previous layers toward 0\. This
    makes the gradient vanish completely after a few time steps and the network stops
    learning from “far away.”
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 5*, *Recurrent Neural Networks*, discussed how to use **Long Short-Term
    Memory** (**LSTM**) and **Gated Recurrent Units** (**GRUs**) to deal with the
    problem of vanishing gradients and efficiently learn long-range dependencies.
    In a similar way, the gradient can explode when one single term in the multiplication
    of the Jacobian matrix becomes large. *Chapter 5* discussed how to use gradient
    clipping to deal with this problem.'
  prefs: []
  type: TYPE_NORMAL
- en: We have now concluded this journey, and you should now understand how backpropagation
    works and how it is applied in neural networks for dense networks, CNNs, and RNNs.
    In the next section, we will discuss how TensorFlow computes gradients, and why
    this is useful for backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: A note on TensorFlow and automatic differentiation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow can automatically calculate derivatives, a feature called automatic
    differentiation. This is achieved by using the chain rule. Every node in the computational
    graph has an attached gradient operation for calculating the derivatives of input
    with respect to output. After that, the gradients with respect to parameters are
    automatically computed during backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic differentiation is a very important feature because you do not need
    to hand-code new variations of backpropagation for each new model of a neural
    network. This allows for quick iteration and running many experiments faster.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed the math behind deep learning. Put simply, a
    deep learning model computes a function given an input vector to produce the output.
    The interesting part is that it can literally have billions of parameters (weights)
    to be tuned. Backpropagation is a core mathematical algorithm used by deep learning
    for efficiently training artificial neural networks, following a gradient descent
    approach that exploits the chain rule. The algorithm is based on two steps repeated
    alternatively: the forward step and the backstep.'
  prefs: []
  type: TYPE_NORMAL
- en: During the forward step, inputs are propagated through the network to predict
    the outputs. These predictions might be different from the true values given to
    assess the quality of the network. In other words, there is an error and our goal
    is to minimize it. This is where the backstep plays a role, by adjusting the weights
    of the network to minimize the error. The error is computed via loss functions
    such as **Mean Squared Error** (**MSE**), or cross-entropy for non-continuous
    values such as Boolean (*Chapter 1*, *Neural Network Foundations with TF*). A
    gradient-descent-optimization algorithm is used to adjust the weight of neurons
    by calculating the gradient of the loss function. Backpropagation computes the
    gradient, and gradient descent uses the gradients for training the model. A reduction
    in the error rate of predictions increases accuracy, allowing machine learning
    models to improve. SGD is the simplest thing you could possibly do by taking one
    step in the direction of the gradient. This chapter does not cover the math behind
    other optimizers such as Adam and RMSProp (*Chapter 1*). However, they involve
    using the first and the second moments of the gradients. The first moment involves
    the exponentially decaying average of the previous gradients, and the second moment
    involves the exponentially decaying average of the previous squared gradients.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three big properties of our data that justify using deep learning;
    otherwise, we might as well use regular machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Very-high-dimensional input (text, images, audio signals, videos, and temporal
    series are frequently a good example).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with complex decision surfaces that cannot be approximated with a low-order
    polynomial function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having a large amount of training data available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning models can be thought of as a computational graph made up of stacking
    together several basic components such as dense networks (*Chapter 1*), CNNs (*Chapter
    3*), embeddings (*Chapter 4*), RNNs (*Chapter 5*), GANs (*Chapter 9*), autoencoders
    (*Chapter 8*) and, sometimes, adopting shortcut connections such as “peephole,”
    “skip,” and “residual” because they help data flow a bit more smoothly. Each node
    in the graph takes tensors as input and produces tensors as output. As discussed,
    training happens by adjusting the weights in each node with backprop, where the
    key idea is to reduce the error in the final output node(s) via gradient descent.
    GPUs and TPUs (*Chapter 15*) can significantly accelerate the optimization process
    since it is essentially based on (hundreds of) millions of matrix computations.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few other mathematical tools that might be helpful to improve your
    learning process. Regularization (L1, L2, and Lasso (*Chapter 1*)) can significantly
    improve learning by keeping weights normalized. Batch normalization (*Chapter
    1*) helps to basically keep track of the mean and the standard deviation of your
    dataset across multiple deep layers. The key idea is to have data resembling a
    normal distribution while it flows through the computational graph. Dropout (Chapters
    *1*, *3*, *5*, *6*, *9*, and *20*) helps by introducing some elements of redundancy
    in your computation; this prevents overfitting and allows better generalization.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has presented the mathematical foundation behind intuition. As
    discussed, this topic is quite advanced and not necessarily required for practitioners.
    However, it is recommended reading if you are interested in understanding what
    is going on “under the hood” when you play with neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will introduce the **Tensor Processing Unit** (**TPU**), a
    special chip developed at Google for ultra-fast execution of many mathematical
    operations described in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kelley, Henry J. (1960). *Gradient theory of optimal flight paths*. ARS Journal.
    30 (10): 947–954\. Bibcode:1960ARSJ...30.1127B. doi:10.2514/8.5282.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Dreyfus, Stuart. (1962). *The numerical solution of variational problems*.
    Journal of Mathematical Analysis and Applications. 5 (1): 30–45\. doi:10.1016/0022-247x(62)90004-5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Werbos, P. (1974). *Beyond Regression: New Tools for Prediction and Analysis
    in the Behavioral Sciences*. PhD thesis, Harvard University.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rumelhart, David E.; Hinton, Geoffrey E.; Williams, Ronald J. (1986-10-09).
    *Learning representations by back-propagating errors*. Nature. 323 (6088): 533–536\.
    Bibcode:1986Natur.323..533R. doi:10.1038/323533a0.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: LeCun, Y. (1987). *Modèles Connexionnistes de l’apprentissage (Connectionist
    Learning Models)*, Ph.D. thesis, Université P. et M. Curie.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Herbert Robbins and Sutton Monro. (1951). *A Stochastic Approximation Method.
    The Annals of Mathematical Statistics, Vol. 22, No. 3*. pp. 400–407.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E. (June 2017). *ImageNet
    classification with deep convolutional neural networks* (PDF). Communications
    of the ACM. 60 (6): 84–90\. doi:10.1145/3065386\. ISSN 0001-0782\.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*From not working to neural networking*. The Economist. (25 June 2016)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 2000 members at: [https://packt.link/keras](https://packt.link/keras)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1831217224278819687.png)'
  prefs: []
  type: TYPE_IMG
