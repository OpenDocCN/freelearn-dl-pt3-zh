<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Neural Networks and Deep Learning</h1>
                </header>
            
            <article>
                
<p>Neural networks are the main machine learning models that we will be looking at in this book. Their applications are countless, as are their application fields. These range from computer vision applications (where an object should be localized in an image), to finance (where neural networks are applied to detect frauds), passing trough trading, to reaching even the art field, where neural networks are used together with the adversarial training process to create models that are able to generate new and unseen kinds of art with astonishing results.</p>
<p>This chapter, which is perhaps the richest in terms of theory in this whole book, shows you how to define neural networks and how to make them learn. To begin, the mathematical formula for artificial neurons will be presented, and we will highlight why a neuron must have certain features to be able to learn. After that, fully connected and convolutional neuronal topologies will be explained in detail since these are the building blocks of almost every neural network architecture. At the same time, the concept of deep learning and deep architectures will be introduced. Introducing this concept is a must since it is because of deep architectures that, nowadays, neural networks are used to solve challenging problems with super-human performance.</p>
<p>To conclude, the optimization process that's required to train a parametric model, together with some regularization techniques that are used to improve the model's performance, will be shown. Gradient descent, the chain rule, and the graphical representation of the computations all have their own dedicated sections since it is extremely important for any machine learning practitioner to know what happens when a framework is used to train a model.</p>
<p>If you are already familiar with the concepts presented in this chapter, you can jump directly to the next chapter, <a href="f62be9d4-c8e0-4590-8299-2fdad139830f.xhtml">Chapter 3</a>, <em>TensorFlow Graph Architecture</em>, which is dedicated to the TensorFlow graph architecture.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Neural networks</li>
<li>Optimization</li>
<li>Convolutional neural networks</li>
<li>Regularization</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural networks</h1>
                </header>
            
            <article>
                
<p>The definition of a neural network, as provided by the inventor of one of the first neurocomputers, <em>Dr. Robert Hecht-Nielson,</em><span> </span>in<span> </span><em>Neural Network Primer—Part I</em><span>, </span>is as follows:</p>
<div class="packt_quote">"A <span>computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs."</span></div>
<p>In practice, we can think of artificial neural networks<span> </span>as a computational model that is based on how the brain is believed to work. Hence, the mathematical model is inspired by biological neurons.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Biological neurons</h1>
                </header>
            
            <article>
                
<p>The main computational units of the brain are known as neurons; in the human nervous system, approximately 86 billion neurons can be found, all of which are connected by synapses. The following diagram shows a biological neuron and the mathematical model that draws inspiration from it:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-900 image-border" src="assets/a05f5586-0ad6-4a20-8935-4c44a2176e6f.png" style="width:42.42em;height:15.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Representation of the biological neuron, (a), on the left and its mathematical model, (b), on the right. <span>Source: Stanford cs231n</span></div>
<p>Biological neurons are made up of the following:</p>
<ul>
<li><strong>Dendrites</strong>: Minor fibers that carry information, in the form of an electric signal, from the outside to the nucleus.</li>
<li><strong>Synapses</strong>: These are the connection points among neurons. Neurons receive input signals on the synapses that are connected to the dendrites.</li>
<li><strong>Nucleus</strong>: This receives the signals from the dendrites, elaborates on them, and produces a response (output signal) that it sends to the axon.</li>
<li><strong>Axon</strong>: The output channel of the neuron. It can be connected to other neuron synapses.</li>
</ul>
<p>Each neuron receives input signals from its dendrites and transports them to the nucleus where they are processed; dendrites process the signals, thereby integrating (adding up or combining) excitation and inhibition from every input synapse. The nucleus receives the integrated signals and adds them. If the final sum is above a certain threshold, the neuron fires and the resulting information is carried down through the axon and thus to any other connected neuron.</p>
<p>The amount of signal that's transmitted among neurons depends on the strength of the connections. It is the arrangement of the neurons and the strength of these synapses that establish the function of the neural network.</p>
<p>The learning phase of biological neurons is based on the modification of the output signal generated by the nucleus over time, as a function of certain types of input signals. Neurons specialize themselves in recognizing certain stimuli during their lifetime.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Artificial neurons</h1>
                </header>
            
            <article>
                
<p class="mce-root">Artificial neurons are based on the structure of the biological neuron and use mathematical functions with real values to simulate their behavior. Such artificial neurons are called <strong>perceptrons</strong>, a concept that was developed in the 50s and 60s by the scientist Frank Rosenblatt. Taking this mathematical analogy into account, we can talk about the biological neurons as follows:</p>
<ul>
<li><strong>Dendrites</strong>: The number of inputs the neuron accepts. It can also be seen as the number of dimensions, <em>D</em>, of the input data.</li>
</ul>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Synapses</strong>:  <img class="fm-editor-equation" src="assets/c63ff61c-545a-41e4-b0ec-57332f0d83b3.png" style="font-size: 1em;text-align: center;color: #333333;width:10.50em;height:1.00em;"/>  weights associated with the dendrites. These are the values that change during the training phase. At the end of the training phase, we say the neuron is specialized (it learned to extract particular features from the input).</li>
</ul>
<p style="padding-left: 60px"/>
<p style="padding-left: 60px">If <img class="fm-editor-equation" src="assets/747cd994-4daa-4673-940e-a76a4d293266.png" style="width:0.75em;height:0.83em;"/> is a D-dimensional input vector, the operation that's executed by the synapses is <img class="fm-editor-equation" src="assets/e7a6566e-2a4d-4bb1-892c-93e979c5ef86.png" style="width:9.42em;height:1.17em;"/></p>
<ul>
<li><strong>Nucleus</strong> (body cell): This is a function that bonds the values coming from the synapses, thereby defining the behavior of the neuron. To simulate the action of the biological neuron, that is, firing (activating) only when there are certain stimuli in the input, the nucleus is modeled with <strong>non-linear</strong> functions.<br/>
If <img class="fm-editor-equation" src="assets/e49a8892-74d1-462d-b219-ead61cd07dd1.png" style="width:3.67em;height:0.92em;"/> is a non-linear function, the output of the neuron, which takes into account all input stimuli, is given by the following equation:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"> <img class="fm-editor-equation" src="assets/c5c1b918-f08f-4320-9f07-991087923360.png" style="width:9.50em;height:2.92em;"/>.</p>
<ul>
<li>Here, <img class="fm-editor-equation" src="assets/5b69a829-f2ab-4c5a-a836-2c82601b0cf4.png" style="width:0.58em;height:1.17em;"/> is the <strong>bias term</strong>, which is of fundamental importance. It allows you to learn about a decision boundary that's not centered on the origin of the D-dimensional space.</li>
</ul>
<p style="padding-left: 60px">If we remove the non-linear (also called <strong>activation</strong>) function for a moment, we can easily see that the synapses define a hyper-plane with the following equation:</p>
<p class="CDPAlignCenter CDPAlign" style="padding-left: 60px"><sub><img class="fm-editor-equation" src="assets/7a2788a7-db86-43dc-8480-78a4609c1c88.png" style="width:5.08em;height:3.00em;"/></sub>.</p>
<p style="padding-left: 60px">A single neuron is able to perform <span><em>only</em> </span>binary classification because the D-dimensional vector, <img class="fm-editor-equation" src="assets/a99782dc-877b-4629-b277-f9ee1ba29535.png" style="width:0.75em;height:0.83em;"/>, can just be over or under the hyperplane it defines.<br/>
A perceptron can correctly classify samples in a D-dimensional space if—and only if—those samples are linearly separable.</p>
<p style="padding-left: 60px">The nucleus, with its non-linearity, maps the hyperplane defined by the dendrites in a more general hypersurface, which is the learned decision boundary. Non-linearity, in the best-case scenario, transforms the hyperplane into a hypersurface that's able to correctly classify points in a D-dimensional space. However, it only does this if those points are separable in two regions by a single hypersurface.</p>
<p style="padding-left: 60px">This is the main reason we need multi-layer neural networks: if the input data is not separable by a single hypersurface, adding another layer on top that works by transforming the learned hypersurface into a new hypersurface with an additional classification region allows it to learn complex classification boundaries that are capable of separating the regions correctly.</p>
<p style="padding-left: 60px">Moreover, it is worth noting that feed-forward neural networks, such as neural networks with connections among neurons that do not form a cycle, are universal function approximators. This means that, if a way to separate regions exists, a well-trained neural network with enough capacity will learn to approximate that function.</p>
<ul>
<li><strong>Axon</strong>: This is the output value of the neuron. It can be used as input by other neurons.</li>
</ul>
<p>It's important to stress that this model of a biological neuron is very coarse: for example, there are many different types of neuron, each with different properties. The dendrites in biological neurons perform complex nonlinear computations. The synapses are not just a single weight; they are a complex non-linear dynamical system. There are many other simplifications in the model because the reality is way more complicated and tougher to model than this. Hence, this biological inspiration is just a nice way to think about neural networks, but don't be fooled by all of these similarities: artificial neural networks are only loosely inspired by biological neurons.</p>
<div class="packt_infobox"><em>"Why we should use neural networks and not other machine learning models?"<br/></em><br/>
Traditional machine learning models are powerful but usually not as flexible as neural networks. Neural networks can be arranged in different topologies, and the geometry changes what the neural networks see (the input stimuli). Moreover, it's straightforward to create layers upon layers of neural networks with different topologies, creating deep models.<br/>
One of the greatest strengths of neural networks is their ability to become feature extractors: other machine learning models need the input data to be processed, have their meaningful features extracted, and only on those features (manually defined!) can the model be applied.<br/>
Neural networks, on the other hand, can extract meaningful features from any input data by themselves (depending on the topology of the layers that are used).</div>
<p><span>The single perceptron illustrates how it is possible to weigh and add different types of input to make a simple decision; a complex network of perceptrons could make a quite subtle decision. A <strong>neural network architecture</strong>, therefore, is made up of neurons, all of which are connected through synapses (biologically) where the information flows through them. During training, the neurons fire when they learn specific patterns from the data.</span></p>
<p><span>This fire rate is modeled using an activation function. More precisely, the neurons are connected in an acyclic graph; c</span></p>
<p><span>ycles are not allowed since that would imply an infinite loop in the forward pass of the network (these types of networks are called <strong>feed-forward neural networks</strong>). Instead of amorphous blobs of connected neurons, neural network models are often organized into distinct layers of neurons. The most common layer type is the fully connected layer.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fully connected layers</h1>
                </header>
            
            <article>
                
<p>The fully connected configuration is a particular network topology <span>in which neurons between two adjacent layers are fully pairwise-connected, but neurons within a single layer share no connections.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>Organizing networks into layers allows us to create stacks of fully connected layers, with a different number of neurons per layer. We can think about a multi-layer neural network as a model with visible and hidden layers. The visible layers are just the input and output layers; the hidden layers are the ones that aren't connected to the outside:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-901 image-border" src="assets/ef4794f3-77ae-4d57-a534-cc05481441aa.png" style="width:38.33em;height:27.83em;"/></p>
<div class="mce-root packt_figref CDPAlignCenter CDPAlign">A typical representation of a fully connected neural network, with two hidden layers. Every layer reduces the dimensionality of its input with the aim of producing two different outputs given the ten input features.</div>
<p>The number of neurons in the hidden layers is entirely arbitrary, and it changes the learning capacity of the network. The input and output layers, instead, have a fixed dimension due to the task we are going to solve (for example, if we want to solve an <em>n</em>-classes classification on D-dimensional inputs, then we need an input layer with D inputs and an output layer with n outputs).</p>
<p>Mathematically, it is possible to define the output of a fully connected layer as the result of a matrix product. Let's say we have the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d2192c7e-2156-49c3-a22d-842fd589f073.png" style="width:23.00em;height:4.67em;"/></p>
<p>The output, <em>O</em>, is given by the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0f1acf9a-a09f-43f9-ad9e-293314aab109.png" style="width:11.25em;height:1.08em;"/></p>
<p>Here, M is the arbitrary number of neurons in the layer.</p>
<p>While the design of the input and output layers of a neural network is straightforward, the design of the hidden layers is not so simple. There are no rules; neural networks researchers have developed many design heuristics for hidden layers which help to get the correct behavior (for example, when there's a trade-off between the number of hidden layers and the time to train the network).</p>
<p>In general, increasing the number of neurons per layer and/or the number of layers in a neural network means having to increase the network capacity. This means that the neural network can express more complicated functions and that the space of representable functions grows; however, this is good and bad at the same time. It's good because we can learn more complicated functions, but it's bad because having more trainable parameters increases the risk of overfitting the training data.</p>
<p>In general, smaller neural networks should be preferred if the data is not complex or we are working with small datasets. Fortunately, there are different techniques that allow you to prevent overfitting the data when you're using high-capacity models. These techniques are called regularization techniques (L2 penalties on the parameters, dropout, batch normalization, data augmentation, and so on). We will dig into them in upcoming chapters.</p>
<p>The activation function is another important part of the design of every neural network. It is applied to every single neuron: nobody forces us to use the same non-linear function on every neuron, but it is a convention to pick a form of nonlinearity and use it for every neuron in the same layer.</p>
<p>If we are building a classifier, we are interested in evaluating the output layer of the network and being able to interpret the output values to understand what the network predicted. Let's say we have a linear activation function that's been applied to every single neuron of the output layer, where every neuron is associated with a particular class (looking at the preceding image, we have a 3-dimensional input and two output neurons, one for each class) <span>– </span>how can we interpret those values, since their codomain is the whole set of real numbers? It's hard to interpret values that are expressed in this way.</p>
<p>The most natural way is to constrain the sum of the output values to the [0,1] range so that we can consider the output values as sampled from the probability distribution over the predicted classes and we can consider the neuron with the highest value as the predicted class. Alternatively, we could choose to apply a thresholding operation on the values in order to simulate the biological neurons firing: if the output of a neuron is greater then a certain threshold value, we can output a value of 1, or 0 otherwise.</p>
<p>Another thing we can do is squash every single neuron's output in the [0,1] range if, for instance, we are solving a multi-class classification task where the classes are not mutually exclusive.</p>
<p>It's easy to understand why a certain non-linearity in the output layer is important <span>– </span>it can change the behavior of the network since the way we interpret the network's output depends on it. However, understanding why non-linearity is important in every single layer is mandatory for a complete understanding of neural networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Activation functions</h1>
                </header>
            
            <article>
                
<p>As we already know, the output value of the <em>i</em>-th neuron in a layer is computed as follows:</p>
<p>The activation function, <img class="fm-editor-equation" src="assets/cc9f57ec-e305-4b23-a956-360d0bf40fe8.png" style="width:0.42em;height:0.83em;"/>, is important for several reasons:</p>
<ul>
<li>As stated in the previous section, depending on the layer we are applying the non-linearity to, it allows us to interpret the result of the neural network.</li>
<li>If the input data is not linearly separable, it's non-linearity allows you to approximate a non-linear function that's capable of separating data in a non-linear way (just think about the transformation of a hyperplane into a generic hypersurface).</li>
<li>Without non-linearities among adjacent layers, multi-layer neural networks are equivalent to a single neural network with a single hidden layer, and so they are able to separate only two regions of the input data. In fact, given:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"> <sub><img class="fm-editor-equation" src="assets/840f8ae1-cb55-4dee-a6f9-afb63507b410.png" style="width:7.58em;height:1.17em;"/></sub> </p>
<p style="padding-left: 60px">And two perceptrons stacked:</p>
<p class="CDPAlignCenter CDPAlign"> <sub><img class="fm-editor-equation" src="assets/89dacb54-3f48-42e0-97a3-038597d46210.png" style="width:15.67em;height:1.00em;"/></sub>,</p>
<p class="CDPAlignLeft CDPAlign" style="padding-left: 30px">We know that the output of the second perceptron is equivalent to the output of a single perceptron: </p>
<p class="CDPAlignCenter" style="padding-left: 30px"><sub><img class="fm-editor-equation" src="assets/ba89ea59-dade-46b2-bd23-18f3ce03eda9.png" style="width:19.33em;height:1.17em;"/></sub>,</p>
<ul>
<li>Where <sub><img class="fm-editor-equation" src="assets/025f29e7-7378-415e-a1f1-470c0576b486.png" style="width:1.42em;height:0.92em;"/></sub> and <sub><img class="fm-editor-equation" src="assets/3dff90d5-1a3e-4cbf-9e5e-b3c69ce83826.png" style="width:1.08em;height:1.00em;"/></sub> are the matrix of weights and the bias vector is equivalent to the product of the single weight matrices and bias vectors.</li>
</ul>
<p style="padding-left: 60px">This means that, when <sub><img class="fm-editor-equation" src="assets/cc9f57ec-e305-4b23-a956-360d0bf40fe8.png" style="width:0.50em;height:1.00em;"/></sub> is<span> linear, </span>a multi-layer neural network is always equal to a single layer neural network (hence, it has the same learning capacity). If not, the last equation doesn't hold.</p>
<ul>
<li>Non-linearities make the network robust to noisy input. If the input data contains noise (the training set contains values that are not perfect <span>–</span> it happens, and it happens often), the non-lineary avoids its propagation to the output. This can be demonstrated as follows: </li>
</ul>
<p class="CDPAlignCenter CDPAlign"><sub><img class="fm-editor-equation" src="assets/60b167dc-c66d-4b10-9223-20e985ab5cb5.png" style="width:28.75em;height:3.75em;"/></sub>.</p>
<p>Two of the most frequently used activation functions are the sigmoid (<img class="fm-editor-equation" src="assets/098ad987-518d-4116-88e6-0046e571c631.png" style="width:0.75em;height:0.83em;"/>)and the hyperbolic tangent (<img class="fm-editor-equation" src="assets/995ab973-a9e9-4291-827b-987f67f5a715.png" style="width:2.75em;height:1.17em;"/>).</p>
<p>The first is used as the activation function of the output layer in almost every classification problem since it squashes the output in the [0,1] range and allows you to interpret the prediction as a probability:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/2c0d2c3a-c044-4063-b46e-3845f2c0e6f9.png" style="width:11.42em;height:2.50em;"/></p>
<p>The hyperbolic tangent, instead, is used as the activation function of the output layer of almost every generative model that's trained to generate images. Even in this case, the reason we use it is to correctly interpret the output and to create a meaningful bond among the input images and the generated images. We are used to scaling the input values from [0,255] to [-1,1], which is the range of the <img class="fm-editor-equation" src="assets/7e4d457c-5fc1-4a06-8529-8210d777dcc1.png" style="width:2.75em;height:1.17em;"/> function.</p>
<p class="mce-root"/>
<p>However, using functions such as <img class="fm-editor-equation" src="assets/6be6bd2c-1dad-4e1f-8349-0a473db8694d.png" style="width:2.75em;height:1.17em;"/> and <img class="fm-editor-equation" src="assets/6b3d6095-8a78-4677-803e-481b6e8ae40c.png" style="width:0.75em;height:0.83em;"/> as activations in the hidden layer isn't the best choice for reasons related to training via backpropagation (as we will see in the following sections, saturating nonlinearities can be a problem). Many other activation functions have been developed in order to overcome the problems that have been introduced by saturating nonlinearities. A short visual overview of the most common nonlinearities that have been developed is shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="aligncenter size-full wp-image-902 image-border" src="assets/fefa202a-4a07-4467-821d-2f0c8716a113.png" style="width:39.67em;height:18.08em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>A list of the most common activation functions. Source: Stanford cs231n.</span></div>
<p>Once the network structure has been defined, as well as the activation functions to use in the hidden and the output layers, it's time to define the relation among the training data and the network's output in order to be able to train the network and make it solve the task at hand.</p>
<p>In the upcoming sections, we will talk about a discrete classification problem that follows on from <a href="0dff1bba-f231-45fa-9a89-b4f127309579.xhtml">Chapter 1</a>, <em>What is Machine Learning? </em>We're talking about the fact that everything that holds for a classification problem also holds for continuous variables since we are using neural networks as a tool to solve a supervised learning problem. Since a neural network is a parametric model, training it means that we need to update the parameters, <br/>
<img class="fm-editor-equation" src="assets/d054cd5a-5fb8-4652-83d5-1e63d2b345ce.png" style="width:0.92em;height:0.75em;"/>, to find the configuration that solves the problem in the best possible way.</p>
<p>Training a neural network is mandatory if we wish to define a relationship among the input data and the desired output: an objective function—or loss function, since we want to minimize the loss as our objective.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loss function</h1>
                </header>
            
            <article>
                
<p>After defining the network architecture, the model must be trained. It's now time to define the relationship between the model's output and the real data. To do so, a loss function must be defined.</p>
<p>The loss function is used to assesses the goodness-of-fit of a model.</p>
<p>There are several loss functions, each one expressing a relationship among the network output and the real data, and their form completely influences the quality of the model's prediction.</p>
<p>For a discrete classification problem over <img class="fm-editor-equation" src="assets/df395d74-ce33-4d18-bf37-ae6953cd08fa.png" style="width:1.00em;height:0.83em;"/> classes, we can model the defined neural network that accepts a D-dimensional input vector, <img class="fm-editor-equation" src="assets/4226cdb4-79cd-473b-b532-e842f7ee12c8.png" style="width:0.75em;height:0.83em;"/>, and produces an <img class="fm-editor-equation" src="assets/cf076cfb-87a0-49bd-a1ee-b1b1f7ebbacf.png" style="width:0.92em;height:0.75em;"/>-dimensional vector of predictions as a function of its parameters,<img class="fm-editor-equation" src="assets/50596d95-1217-443a-884b-c017f8359979.png" style="width:1.08em;height:0.83em;"/>, like so:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c25c25e7-a0eb-47ac-a593-e2a2de349c83.png" style="width:11.75em;height:1.42em;"/></p>
<p>The model produces an M-dimensional output vector that contains the probabilities the model assigns to the input, <img class="fm-editor-equation" src="assets/fb3cf79f-e92c-4dd7-8c10-1204ce356b49.png" style="width:0.75em;height:0.83em;"/>, for every possible class (if we applied the sigmoid activation to the output layer, we can interpret the output in this way).</p>
<p>It's easy to extract the position of the neuron in the output layer that produced the highest value. The equation for the predicted class is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/85b9814f-fc1e-4196-8202-a64e6ab3f9bc.png" style="width:7.67em;height:2.58em;"/></p>
<p>By using this, we can find the index of the neuron that produced the highest classification score. Since we know the label associated with the input, <img class="fm-editor-equation" src="assets/25a9a721-29f9-4e85-8410-f1fc7554e79e.png" style="width:0.75em;height:0.83em;"/>, we are almost ready to define the relationship between the prediction and the label. The last problem we will face is the label format: the label is a scalar value, whereas the network output is an M-dimensional vector. Although we can find the position of the neuron with the highest probability value, we are interested in the whole output layer, since we want to increase the probability of the correct class and penalize the incorrect ones.</p>
<p>For this reason, the label must be converted into an M-dimensional representation so that we can create a bond between every output neuron and the label.</p>
<p class="mce-root"/>
<p>The most natural conversion from a scalar value to an M-dimensional representation is called <strong>one-hot</strong> encoding. This encoding consists of the creation of an M-dimensional vector that has a value of 1 in the position of the label and 0 in every other position. Therefore, we can consider the one-hot encoded-label as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4b47d8b8-13b3-455e-8991-b107a617fb45.png" style="width:23.75em;height:4.75em;"/></p>
<p>It's now possible to define the general formulation of the loss-function for the <em>i</em>-th training set instance as a real-valued function that creates a bond between the ground truth (the label that's been correctly encoded) and the predicted value:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/fd197327-5b89-4c4b-9687-4892f9fd2c9f.png" style="width:11.67em;height:1.50em;"/></p>
<p>The general formulation of a loss function that's applied to the complete training set of cardinality, <em>k</em>, can be expressed as the mean of the loss that's computed on the single instances:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/06ef012e-6bec-4994-a209-11a815a73b75.png" style="width:14.08em;height:3.25em;"/></p>
<p>The loss must be chosen (or defined) based on the problem at hand. The simplest and most intuitive loss function for a classification problem (of mutually exclusive classes) is the L2 distance among the one-hot encoded representation of the label and the network output. The aim is to minimize the distance between the network output and the one-hot encoded label, thereby making the network predict an M-dimensional vector that looks like the correct label:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/6b3e944a-47a2-4d41-ab21-32e54add72da.png" style="width:11.00em;height:3.58em;"/></p>
<p><span>The minimization of the loss function occurs through small iterative adjustments of the model's parameter values.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Parameter initialization</h1>
                </header>
            
            <article>
                
<p><span>The initial model parameter values are the solution to the problem the training phase iteratively refines: there's no unique way of initializing the network parameters, and perhaps the only working suggestions regarding the parameter's initialization are as follows:<br/></span></p>
<ul>
<li><strong>Do not initialize the network parameters to zero</strong>: It is impossible to find a new solution using gradient descent<span> (as we will see in the next section)</span> since the whole gradient is 0 and therefore there's no indication of the update direction.</li>
<li><strong>Break symmetry between different units</strong>: If two hidden units with the same activation function are connected to the same input, then these two inputs must have a different initial parameter value. This is required because almost every solution requires a set of different parameters to be assigned to each neuron to find a meaningful solution. If we start with all the parameters with the same value instead, every update step will update all the network parameters by the same amount since the updated value depends on the error, which is equal for every neuron in the network. Due to this, we will be unable to find a meaningful solution.</li>
</ul>
<p>Usually, the initial solution to the problem is sampled by a random normal distribution with zero mean and unary variance. This distribution ensures that network parameters are small and equally distributed around the zero value while being different among them, therefore breaking the symmetry.</p>
<p><span>Now that we have defined the network architecture, correctly formatted the input labels, and defined the input-output relation with the loss function, how can we minimize the loss? How can we iteratively adjust the model parameters to minimize the loss and thus solve the problem?</span></p>
<p>It's all a matter of optimization and optimization algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Optimization</h1>
                </header>
            
            <article>
                
<p>Operation research gives us efficient algorithms that we can use to solve optimization problems by finding the global optimum (the global minimum point) if the problems are expressed as a function with well-defined characteristics (for instance, convex optimization requires the function to be a convex).</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Artificial neural networks are universal function approximators; therefore, it is not possible to make assumptions about the shape of the function the neural network is approximating. Moreover, the most common optimization methods exploit geometric considerations, but we know from <a href="0dff1bba-f231-45fa-9a89-b4f127309579.xhtml">Chapter 1</a><span>, </span><em>What is Machine Learning?</em><em>,</em> that geometry works in an unusual way when dimensionality is high due to the curse of dimensionality.</p>
<p>For these reasons, it is not possible to use operation research methods that are capable of finding the global optimum of an optimization (minimization) problem. Instead, we have to use an iterative refinement method that, starting from an initial solution tries, to refine it (by updating the model parameters that represent the solution) with the aim of finding a good, local optimum.</p>
<p>We can think about the model parameters, <img class="fm-editor-equation" src="assets/58b62beb-2225-4afb-9f44-73127d592942.png" style="width:1.08em;height:0.92em;"/>, as the initial solution to a minimization problem. Therefore, we can start evaluating the loss function at the training step, 0 <img class="fm-editor-equation" src="assets/1432f8ae-a8cc-4427-ba37-04412b6a62db.png" style="width:1.92em;height:1.00em;"/>, so that we have an idea about the value it assumes with the actual initial configuration of parameters, <img class="fm-editor-equation" src="assets/c14904a6-26e2-4c70-8cd8-265c03f0efa3.png" style="width:2.50em;height:1.08em;"/>. Now, we have to decide on how to update the model parameters. To do this, we need to perform the first update step, which we do by following the information that the loss gives us. We can proceed in two ways:</p>
<ul>
<li><strong>Random perturbations</strong>: We can apply a random perturbation, <img class="fm-editor-equation" src="assets/6b4079db-023b-4ab2-a317-528be4f62854.png" style="width:1.92em;height:0.83em;"/>, to the current set of parameters and compute the loss value on the obtained new set of parameters, <img class="fm-editor-equation" src="assets/d7c875ab-85c7-45d7-bc2a-64f076174514.png" style="width:9.92em;height:1.17em;"/>.</li>
</ul>
<p style="padding-left: 60px">If the loss value at the training step, <img class="fm-editor-equation" src="assets/36c33b0c-8754-4502-95f6-12fd0e510b73.png" style="width:0.67em;height:0.83em;"/>, is less than the value at the previous one, we can accept the found solution and move on with a new random perturbation that's applied to the new set of parameters. Otherwise, we have to repeat the random perturbation until a better solution is found.</p>
<ul>
<li><strong>Estimation of the update direction</strong>: Instead of generating a new set of parameters randomly, is it possible to guide the local optimum research process toward the direction of the maximum descent of the function.</li>
</ul>
<p>The second approach is the <span>de facto </span>standard for training parametric machine learning models that are expressed as differentiable functions.</p>
<p><span>To properly understand this gradient descent method, we have to think about the loss function as a way of defining a surface in the parameter space—our objective, that is, minimizing the loss, means that we need to find the lowest point on this surface.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gradient descent</h1>
                </header>
            
            <article>
                
<p>Gradient descent is a method that's used to calculate the best direction to move in when we're searching for the solution to a minimization/maximization problem. This method suggests the direction to follow when we're updating the model parameters: the direction that's found, depending on the input data that's used, is the direction of the steepest descent of the loss surface. The data that's used is of extreme importance since it follows the evaluation of the loss function and therefore the surface that's used to evaluate the update direction.</p>
<p>The update direction is given by the gradient of the loss function. It's known from calculus that the derivative operation for a single variable differentiable function, <img class="fm-editor-equation" src="assets/b2f0595a-05ea-4981-b131-dd0467a0a09f.png" style="width:1.75em;height:1.08em;"/>, in point <img class="fm-editor-equation" src="assets/f07ae0c3-7f9d-4a9d-90e8-77fa60aa7f42.png" style="width:0.75em;height:0.83em;"/> is given by the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4b9aced6-e6f2-4851-9807-f9acae93e082.png" style="width:14.42em;height:2.50em;"/></p>
<p>This operation gives us a description of the behavior of the function in <img class="fm-editor-equation" src="assets/4ba59bc9-d41e-4b45-8758-2e5f68c35f5b.png" style="width:0.75em;height:0.83em;"/>: it shows us how much the function varies with respect to the <img class="fm-editor-equation" src="assets/2fa106b7-259a-4b3c-9f1f-19004dda9d59.png" style="width:0.75em;height:0.83em;"/> variable in an infinitely small region centered in <img class="fm-editor-equation" src="assets/ad1c59c0-9c33-4535-a361-51106af7897f.png" style="width:0.75em;height:0.83em;"/>.</p>
<p>The generalization of the derivative operation for an n-variables function is given by the gradient, that is, the vector of the partial derivatives (the vector of the derivatives of the function with respect to a single variable considering constants any other variable). In the case of our loss function, it is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8f89ad48-7a5d-4489-b34f-9d6b627052be.png" style="width:12.33em;height:2.42em;"/></p>
<p><img class="fm-editor-equation" src="assets/d29ed3ba-8018-45d0-b3dc-28b5c014d4ff.png" style="width:2.83em;height:1.00em;"/> indicates the direction along which the function is growing. Hence, since our objective is to find the minimum, we have to move along the direction indicated by the anti-gradient, like so:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d10a5132-7220-453a-b128-126bd8af5117.png" style="width:6.67em;height:1.25em;"/></p>
<p>Here, the anti-gradient represents the direction to follow when performing the parameter update. The parameter update step now looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/de3e35e9-2313-406e-8607-058f113a430e.png" style="width:18.58em;height:1.50em;"/></p>
<p>The <img class="fm-editor-equation" src="assets/b39bcd22-c232-4adb-aff2-c3b55ed3d1d2.png" style="width:0.50em;height:0.92em;"/> parameter is the learning rate and is a hyperparameter of the training phase with gradient descent. Choosing the correct value for the learning rate is more of an art than a science, and the only thing we can do is use our intuition to choose a value that works well for our model and dataset. We have to keep in mind that the anti-gradient only tells us the direction to follow; it doesn't give us any information about the distance from the current solution to the minimum point. The distance, or the strength of the update, is regulated by the learning rate:</p>
<ul>
<li>A learning rate that's too high could make the training phase unstable due to jumps around the local minima. This causes oscillations of the loss function's value. To remember this, we can just think about a U shaped surface. If the learning rate is too high, we jump from the left to the right of the U, and vice versa in the next update step, without ever descending the valley (because the distance from the two peaks of the U is greater than <img class="fm-editor-equation" src="assets/b39bcd22-c232-4adb-aff2-c3b55ed3d1d2.png" style="width:0.42em;height:0.75em;"/>).</li>
<li>A learning rate that's too small could make the training phase suboptimal since we never jump out of a valley that is not the point of the global minimum. Hence, there's a risk of being stuck in a local minimum. Moreover, another risk with a learning rate that's too small is never finding a good solution <span>–</span> not because we are stuck in a local minimum, but because we are moving too slowly toward the direction at hand. Since this is an iterative process, the research could take too long.</li>
</ul>
<p>In order to face the challenge of choosing the learning rate value, various strategies have been developed that change its value during the training phase, usually reducing it in order to find a trade-off between the exploration of the landscape using a big learning rate and the refinement of the found solution (descending the valley) using a smaller learning rate value.</p>
<p>So far, we'<span>ve looked at updating parameters by</span><span> considering a loss function that's computed using the complete dataset, all at once. This method is called</span> <strong>batch gradient descent</strong><span>. This method, in practice, can never be applied to a real scenario since modern applications of neural networks deal with huge amounts of data that rarely fit inside the computer's memory. </span></p>
<p>Several variants of batch gradient descent have been developed to overcome its limitations, together with different strategies for updating the model parameters, that will help us solve face some challenges related to the gradient methods themselves.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stochastic gradient descent</h1>
                </header>
            
            <article>
                
<p>Stochastic gradient descent updates the model parameter for every element of the training dataset—one example, one update step:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/cf9fde1e-c705-4e1e-8dc5-b3ecac1f28c1.png" style="width:17.08em;height:1.33em;"/></p>
<p>If the dataset has high variance, stochastic gradient descent causes huge fluctuations of the loss value during the training phase. This can be both an advantage and a disadvantage:</p>
<ul>
<li>It can be an advantage because, due to the fluctuations of the loss, we jump into unexplored zones of the solution space that could contain a better minimum.</li>
<li>It is a method suited for online training. This means training with new data during the whole lifetime of the model (which means we can continue to train the model with new data, usually coming from a sensor).</li>
<li>The convergence is slower and finding a good minimum is more difficult since the updates have high variance.</li>
</ul>
<p>The de facto method for training neural networks that try to keep the advantages of both batch and stochastic gradient descent is known as mini-batch gradient descent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mini-batch gradient descent</h1>
                </header>
            
            <article>
                
<p>Mini-batch gradient descent keeps the best parts of the batch and stochastic gradient descent methods. It updates the model parameters using a subset of cardinality, <img class="fm-editor-equation" src="assets/9e376903-315b-45f3-9d66-ab20fde2b198.png" style="width:0.42em;height:0.83em;"/>, of the training set, which is a mini-batch:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3923a990-cd69-4524-910a-1e4a0d1f6093.png" style="width:22.75em;height:1.58em;"/></p>
<p>This is the most widely used approach due to the following reasons:</p>
<ul>
<li>Using mini-batches reduces the parameter's update variance, and so it causes faster convergence in the training process</li>
<li>Using a mini-batch of cardinality allows you to reuse the same method for online training</li>
</ul>
<p class="mce-root"/>
<p>It's possible to write down a generic formula for gradient descent at the update step, <em>s</em>, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ccb450d2-31b0-4728-a205-a43e450ad77e.png" style="width:29.00em;height:4.25em;"/></p>
<ul>
<li>For <img class="fm-editor-equation" src="assets/213bad97-a25e-469a-8e6b-328f9f15ea2a.png" style="width:2.67em;height:1.00em;"/>, the method is stochastic gradient descent</li>
<li>For <img class="fm-editor-equation" src="assets/4fba78fd-d5ec-4b11-b2f2-8a010fd4ead7.png" style="width:6.25em;height:1.33em;"/>, the method is batch gradient descent</li>
<li>For <img class="fm-editor-equation" src="assets/7776fe65-4456-4dcd-a3f2-14f4cdad03bb.png" style="width:7.83em;height:1.25em;"/>, the method is mini-batch gradient descent</li>
</ul>
<p>The three methods that have been shown here update the model parameters in a so-called <strong>vanilla</strong> way that only considers the current parameter's value and the anti-gradient that's computed by applying the definition. They all use a fixed value for the learning rate.</p>
<p>Other parameter optimization algorithms exist, and all of them have been developed with the aim of finding better solutions, exploring the parameter space in a better way, and overcoming all the problems that a vanilla approach can face when searching for a good minimum:</p>
<ul>
<li><strong>Choose the learning rate</strong>: The learning rate is probably the most important hyperparameter of the whole training phase. These reasons were explained at the end of the <em>Gradient descent</em> section.</li>
<li><strong>Constant learning rate</strong>: The vanilla update strategy doesn't change the learning rate value during the training phase. Moreover, it uses the same learning rate to update every parameter. Is this always desirable? Probably not, since treating parameters associated with input features with a different frequency of appearance in the same manner is not reasonable. Intuitively, we want to update the parameters associated with low appearance frequency features and the others with smaller steps.</li>
<li><strong>Saddle points and plateau</strong>: The loss functions that are used to train neural networks are a function of a huge number of parameters and thus are non-convex functions. During the optimization process, it is possible to run into saddle points (points in which the value of the function increases along one dimension, but decreases along other dimensions) or plateaus (locally constant regions of the loss surface).</li>
</ul>
<p style="padding-left: 60px">In these cases, the gradient is almost zero along every dimension, and so the direction that's pointed to by the anti-gradient is nearly 0. This means we are stuck, and the optimization process can't go on. We have been fooled by the constant value that was assumed by the loss function during several training steps; we think we have found a good minimum, but in reality, we are stuck inside a meaningless region of the solution space.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gradient descent optimization algorithms</h1>
                </header>
            
            <article>
                
<p>Several optimization algorithms have been developed to improve the efficiency of vanilla optimization. In the upcoming sections, we will recap on vanilla optimization and show the two most common optimization algorithms: momentum and ADAM. The former will be discussed because it shows how a physical interpretation of the loss surface can lead to successful results, while the latter will be discussed because it is the most widely adaptive optimization method that's used.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Vanilla</h1>
                </header>
            
            <article>
                
<p>As we saw previously, the update formula only requires an estimation of the direction, which it gets by using the anti-gradient and the learning rate:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d3109de1-4053-4766-8911-7b7452387ed1.png" style="width:12.33em;height:1.25em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Momentum</h1>
                </header>
            
            <article>
                
<p>The momentum optimization algorithm is based on a physical interpretation of the loss surface. Let's think about the loss surface as a messy landscape where a particle is moving around, with the aim of finding the global minimum.</p>
<p>The vanilla algorithm updates the position of the particle as a function of the direction that was found by calculating the anti-gradient, making the particle jump from one position to another without any physical meaning. This can be seen as an unstable system rich in energy.</p>
<p>The basic idea that was introduced in the momentum algorithm is to update the model parameters by considering the interaction between the surface and the particle, just like you would in a physical system.</p>
<p class="mce-root"/>
<p>In the real world, a system that teleports a particle from one point to a new point in zero time and without loss of energy does not exist. The initial energy of the system is lost due to external forces and because the velocity changes over time.</p>
<p>In particular, we can use the analogy of an object (the particle) that slides over a surface (the loss surface) and is subject to a kinetic friction force that reduces its energy and speed over time. In machine learning, we call friction coefficient momentum, but in practice, we can reason exactly like we do in physics. Hence, given a friction coefficient, <img class="fm-editor-equation" src="assets/a2851ec3-fff2-4c9b-aaeb-46744da7521c.png" style="width:0.67em;height:0.92em;"/> (a hyperparameter with values in the [0,1] range but usually in the [0.9, 0.999] range), the update rule of the Momentum algorithm is given by the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a433d5f6-3b77-4117-9181-d718dec9110a.png" style="width:55.17em;height:3.42em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/0a3a3069-a338-4782-9c96-d2f1aa775173.png" style="width:0.67em;height:0.83em;"/> is the vectorial velocity of the particle (every component if the vector is the velocity in a particular dimension). The analogy of velocity is natural since, in one dimension, the derivative of the position with respect to time is the velocity.</p>
<p>This method takes into account the vectorial velocity that's reached by the particle at the previous step and reduces it for those components that go in a different direction, while increasing it for points that go in the same direction for subsequent updates.</p>
<p>In this way, the overall energy of the system is reduced, which in turn reduces the oscillations and gets faster convergence, as we can see from the following diagram, which shows the difference between the vanilla (on the left) and the momentum (on the right) optimization algorithms:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-903 image-border" src="assets/614fe9e7-0b9c-4e74-88a8-dcd0d3d0f74d.png" style="width:34.17em;height:7.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Visual representation of the vanilla (left) and momentum (right) optimization algorithms. Momentum causes fewer loss oscillations and reaches the minimum faster.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ADAM</h1>
                </header>
            
            <article>
                
<p>The vanilla and the momentum optimization algorithms consider the <img class="fm-editor-equation" src="assets/c7fc9572-6b26-4936-9b82-1a12bd1643d8.png" style="width:0.67em;height:1.17em;"/> parameter as being constant: the strength of the update (the step size) is the same for every parameter in the network; there's no distinction among parameters associated with high or low occurrence features. To face this problem and increase the efficiency of the optimization algorithms, a whole set of new algorithms has been developed, known as <strong>adaptive learning rate optimization methods</strong>.</p>
<p>The idea behind these algorithms is to associate a different learning rate to every parameter of the network and thus update them using a learning rate that adapts itself to the type of feature the neuron is specialized to extract (or in general, to adapt itself to the different features the neuron sees as input): small updates associated with a high frequency of occurrence features, bigger otherwise. <strong>Adaptive Moment Estimation</strong> (<span><strong>ADAM</strong>) </span>wasn't the first adaptive method to be developed, but it is the most commonly used because it outperforms almost every other adaptive and non-adaptive algorithm on many different tasks: it increases the model's generalization capabilities while speeding up its convergence.</p>
<p> Being an adaptive method, it creates a learning rate for every parameter in the model, like so:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e71fd61d-2aec-4659-8daa-4c1657fb8141.png" style="width:9.67em;height:1.25em;"/></p>
<p>The algorithm's authors decided to take into account how the (square of the) gradients changes, as well as their variance:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/dfdb2e60-2894-4f3d-9bf5-5773ed6086ef.png" style="width:39.42em;height:2.67em;"/></p>
<p>The first term is the exponential moving average of the gradients (estimation of the first-order momentum), while the second term is the exponential moving average of the square of the gradients (estimation of the second-order momentum). Both <img class="fm-editor-equation" src="assets/04814af9-ae83-463b-acdf-2a56da1b6dc7.png" style="width:1.50em;height:0.92em;"/> and <img class="fm-editor-equation" src="assets/3cd62c43-3e77-4bc8-8204-7c0c7cec70e7.png" style="width:1.08em;height:0.92em;"/> are vectors with <img class="fm-editor-equation" src="assets/ee8135dc-044d-436e-a90d-af3333d49492.png" style="width:1.42em;height:1.00em;"/> components, and both have been initialized to 0.</p>
<p><img class="fm-editor-equation" src="assets/e2512472-c9ac-4f41-9914-54c65afce56a.png" style="width:1.17em;height:1.17em;"/> and <img class="fm-editor-equation" src="assets/3f4b443e-eab4-4386-8620-403ff099e5c0.png" style="width:1.08em;height:1.08em;"/> are the decaying factors of the exponential moving average and are hyperparameters of the algorithm.</p>
<p>The zero initializations of the <img class="fm-editor-equation" src="assets/056848f6-156e-44ac-b37e-4fb49ae57c72.png" style="width:1.58em;height:1.00em;"/> and <img class="fm-editor-equation" src="assets/a6e47090-46d4-4fc5-83bf-e028c5e1a316.png" style="width:1.08em;height:0.92em;"/> vectors make their value close to 0, especially if the decaying factors are close to 1 (hence a low decay rate).</p>
<p>This is a problem since we are estimating values close to zero, and without any influence from any possible update rule. To solve this, the authors suggested to correct the first and second-order momentums by computing them in the following way:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/9b927b51-ccdf-40de-899c-476d3f6ce1ed.png" style="width:43.75em;height:5.25em;"/></p>
<p>Finally, they suggested an update rule that was inspired by other adaptive algorithms (Adadelta and RMSProp, which are not explained in this book):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b1662318-f34e-4fd1-8095-4fd508488548.png" style="width:14.08em;height:2.83em;"/></p>
<p>They suggested that we use decaying rates close to 1 and a very small value for the epsilon parameter (it's only there to avoid divisions by zero).</p>
<p>Why should using the first and second-order moment estimation and this update rule to update every single parameter of the network improve the model's speed convergence and improve the generalization capabilities of the model?</p>
<p>The effective learning rate, <img class="fm-editor-equation" src="assets/e55675c7-89ab-4d5a-842b-4e7ac2d62027.png" style="width:3.83em;height:2.33em;"/>, adapts itself during training for every single parameter and takes the frequency of occurrence of the input features for every neuron into account. The denominator will increase if the computed partial derivatives associated with the current parameter are different from zero, such as if the input feature associated with that neuron occurs frequently. The higher the occurrence frequency, the smaller the update steps becomes during training.</p>
<p>If, instead, the partial derivatives are almost zero every time, the update steps are almost constant and never change their size during training.</p>
<p>Every gradient descent optimization algorithm that we've presented thus far requires that we compute the gradient of the loss function. Since neural networks can approximate any function and their topology can be very complex, how can we compute the gradient of a complex function efficiently? Representing the computation using data flow graphs and the backpropagation algorithm is the solution.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backpropagation and automatic differentiation</h1>
                </header>
            
            <article>
                
<p>Computing partial derivatives is a process that's repeated thousands upon thousands of times while training a neural network and for this reason, this process must be as efficient as possible.</p>
<p>In the previous sections, we showed you how, by using a loss function, is it possible to create a bond between the model's output, the input, and the label. If we represent the whole neural network architecture using a graph, it's easy to see how, given an input instance, we are just performing a mathematical operation (input multiplied by a parameter, adding those multiplication results, and applying the non-linearity function to the sum) in an ordinate manner. At the input of this graph, we have the input samples from the dataset. The output nodes of the graph are the predictions; the graph can be seen as a set of compound functions of the type:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/40ed459e-d6d6-4ce6-bba4-33cb8dfdaa1d.png" style="width:3.25em;height:1.17em;"/></p>
<p>The output of a neuron with two inputs, <img class="fm-editor-equation" src="assets/d1f9677a-f85f-4ae5-9c01-479169f35aa4.png" style="width:1.17em;height:0.92em;"/> and <img class="fm-editor-equation" src="assets/f2207421-d662-4328-8211-5c93b6445f3c.png" style="width:1.17em;height:0.92em;"/>, that uses the ReLU activation function is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7c8e664a-cc1b-4ee8-8406-d27969c1f4c8.png" style="width:12.75em;height:1.17em;"/></p>
<p>The functions that are used in the previous equations are as follows:</p>
<ul>
<li><img class="fm-editor-equation" src="assets/545dc695-bfba-4e29-9f85-173a3109fdc3.png" style="width:6.92em;height:1.42em;"/> is the product function of an input for a parameter</li>
<li><img class="fm-editor-equation" src="assets/6ccab198-d7d3-4f7c-9529-8d994a2993c2.png" style="width:6.83em;height:1.25em;"/> is the sum function of two values</li>
<li><img class="fm-editor-equation" src="assets/3ee445bc-073b-4e55-9224-32842ad10fd8.png" style="width:9.25em;height:1.17em;"/> is the rectified linear unit activation function</li>
</ul>
<p>Hence, we can represent the output neuron as a composition of these functions:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/173342e1-c695-4e41-8625-3cccac226f70.png" style="width:16.67em;height:1.25em;"/></p>
<p>Keep in mind that the variables are not the input values of the functions, but the model parameters <img class="fm-editor-equation" src="assets/69090582-e723-4b1f-9841-d2f4c95c7484.png" style="width:1.42em;height:1.08em;"/>. We are interested in computing the partial derivatives of the loss function in order to train the network. We do this using the gradient descent algorithm. As a simple example, we can just consider a simple loss function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/974b9d87-bb4b-4144-95f0-27453fa5d2ba.png" style="width:28.00em;height:1.33em;"/></p>
<p class="mce-root"/>
<p>To compute the loss gradient with respect to the variables (<img class="fm-editor-equation" src="assets/7afc4997-4f59-4c23-92dd-825d86f6975c.png" style="width:2.92em;height:1.25em;"/>), it is possible to apply the chain rule (the rule of the derivatives of compound functions):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1b903714-fdfe-4978-bf9e-ed2e70f79be2.png" style="width:14.17em;height:1.50em;"/></p>
<p>Using the Leibniz notation, it is easier to see how the chain rule can be applied to compute the partial derivatives of any differentiable function, which is represented as a graph (and thus represented as a set of compound functions):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/28203b41-9d23-4285-9d9e-99163c6301ec.png" style="width:5.58em;height:2.17em;"/></p>
<p>In the end, it is just a matter of expressing the operations as compound functions, and using a graph is a natural way to do this. We can associate a graph node with a function: its inputs are the function inputs; the node performs the function computation and outputs the result. Moreover, a node can have attributes, such as a formula to apply when calculating the partial derivative with respect to its inputs.</p>
<p>Moreover, a graph can be traversed in both directions. We can traverse it in the forward direction (forward pass of the backpropagation algorithm), and thus compute the loss value. We can also traverse it in the backward direction, applying the formula of the derivative of the output with respect to the input associated with every node and multiplying the value coming from the previous node with the current to compute the partial derivative. This is the application of the chain rule.</p>
<p>Representing computations as graphs allow us to perform automatic differentiation by <span>computing the gradient of complex functions. We only consider operations singularly, and just look at the node's inputs and outputs.</span></p>
<p>There are two different ways of applying the chain rule on a graph <span>– </span>forward and backward mode. A detailed explanation of the automatic differentiation in both forward and backward mode is beyond the scope of this book; however, in upcoming chapters, we will see how TensorFlow implements automatic differentiation in backward mode and how it applies the chain rule to compute the loss value and then traverse the graph in a backward fashion <img class="fm-editor-equation" src="assets/da51f7dc-33d2-4d02-9bbf-e4d33d34bfd9.png" style="width:0.83em;height:0.92em;"/> times. Automatic differentiation in backward mode depends on the input cardinality and not on the number of parameters of the network, compared to implementing it in forwarding mode (it's now easy to imagine why TensorFlow implements automatic differentiation in backward mode; neural networks can have millions of parameters).</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>So far, we've described optimization algorithms and strategies that can be applied to compute the loss function so that it fits the training data. We do this by using a generic function that's been approximated by our neural network. In practice, we only introduced one neural network architecture: the fully connected architecture. However, there are several different neural network architectures that can be applied to solve different problems, depending on the dataset type.</p>
<p>One of the strengths of neural networks is their ability to be able to perform different tasks, depending on the neuron topology that's used.</p>
<p>The fully connected configuration is a global view on the input—every neuron sees everything. However, there are certain types of data that do not require a complete view to be correctly used by a neural network, or that are computationally intractable with a fully connected configuration. Think about a high-resolution image with millions of pixels; we have to connect every neuron to every single pixel, creating a network with a number of parameters equal to the number of pixels times the number of neurons: a network with only two neurons will lead to <sub><img class="fm-editor-equation" src="assets/5a2a2927-7a40-46f2-ac81-728913b0e5ba.png" style="width:10.58em;height:1.25em;"/></sub> parameters—that is completely intractable!</p>
<p>The architecture that's been developed to work with images, and maybe the most important neuronal layer that's been developed in the past years, is the convolutional neural network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Convolutional neural networks</h1>
                </header>
            
            <article>
                
<p><strong>Convolutional Neural Networks</strong> (<strong>CNNs</strong>) are the fundamental building blocks of modern computer vision, speech recognition, and even natural language processing applications. In this section, we are going to describe the convolution operator, how it is used in the signal analysis domain, and how convolution is used in machine learning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The convolution operator</h1>
                </header>
            
            <article>
                
<p>Signal theory gives us all the tools we need to properly understand the convolution operation: why it is so widely used in many different domains and why CNNs are so powerful. The convolution operation is used to study the response of certain physical systems when a signal is applied to their input. Different input stimuli can make a system, <em>S</em>, produce a different output, and the behavior of a system can be modeled using the convolution operation.</p>
<p class="mce-root">Let's start from the one-dimensional case by introducing the concept of the <strong>Linear Time-Invariant</strong> (<strong>LTI</strong>) system.</p>
<p class="mce-root"/>
<p class="mce-root">A system, <em>S</em>, that accepts an input signal and produces an output signal, <img class="fm-editor-equation" src="assets/fddf2624-e066-4e73-99ea-5cac2ac7559a.png" style="width:1.75em;height:1.25em;"/>, is an LTI system if the following properties hold:</p>
<ul>
<li class="mce-root"><strong>Linearity</strong>: <img class="fm-editor-equation" src="assets/9aad29ea-c241-4282-a0a8-5fa019acfc75.png" style="width:22.33em;height:1.17em;"/></li>
<li class="mce-root"><strong>Time invariance</strong>:<strong> <img class="fm-editor-equation" src="assets/cb68d1a7-4a82-4132-90f9-88cfd0bd2d59.png" style="width:10.58em;height:1.25em;"/></strong></li>
</ul>
<p class="mce-root">Is it possible to analyze the behavior of an LTI system by analyzing its response to the Dirac Delta function, δ(t). δ(t) is a function with a value of zero in every point of its domain, except in <img class="fm-editor-equation" src="assets/a7944924-1073-48ec-8c6b-c738690a2b37.png" style="width:3.00em;height:1.17em;"/>. In <img class="fm-editor-equation" src="assets/8509f617-d95d-429c-b9fa-00b13a3a2cda.png" style="width:3.00em;height:1.17em;"/>, it assumes a value that makes its definition true:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f04b13a9-d157-4643-90d0-a1917bbd6961.png" style="width:10.58em;height:2.50em;"/></p>
<p class="mce-root">Intuitively, applying δ(t) to a function, φ(t), means sample the φ(t) in 0. Hence, if we put δ(t) as the input of a system, <em>S</em>, we get its response to a unitary impulse centered on zero. The system output when the input is the Dirac Delta function is called the system impulse response, and is noted with the following equation:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d22c5c09-6adc-4339-8e02-08a6ceac1d0d.png" style="width:6.50em;height:1.25em;"/></p>
<p class="mce-root">The system impulse response is of fundamental importance since it allows us to compute the response of an LTI system to any input.</p>
<p class="mce-root">A generic signal, <em>x(t)</em>, can be seen as the sum of the value it assumes on every instant, <em>t</em>. This can be modeled as the application of δ(t) that's translated in every point of the <em>x</em> domain:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1c557149-3270-4106-ac6e-779476a177a7.png" style="width:18.17em;height:2.58em;"/></p>
<p class="mce-root">This formula is the definition of convolution among two signals.</p>
<p class="mce-root">So, why is the convolution operation important for the study of LTI systems?<br/>
Given <em>x(t)</em> as a generic input signal and <em>h(t)</em> as the impulse response of an LTI system, we get the following:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/86a0aff0-a8b6-4c20-b30f-d304290e08af.png" style="width:27.67em;height:3.08em;"/></p>
<p class="mce-root"><span>The result of the convolution </span>represents the behavior of the LTI system that's modeled by its impulse response, <em>h(t)</em>, when <em>x(t)</em> is its input. This is an important result since it shows us how the impulse response completely characterizes the system and how the convolution operation can be used to analyze the output of an LTI system when given any input signal.</p>
<p class="mce-root">The convolution operation is commutative and the result of the operation is a function (a signal).</p>
<p class="mce-root">So far, we've only considered the continuous case, but there's a natural generalization on the discrete domain. If <img class="fm-editor-equation" src="assets/b4bdd466-10c1-410d-bed3-9878b3d6eed8.png" style="width:1.92em;height:1.33em;"/> and <img class="fm-editor-equation" src="assets/79ef65c0-fdd6-4c59-915c-aaa424f1c1e3.png" style="width:1.75em;height:1.17em;"/> are defined on <img class="fm-editor-equation" src="assets/f25a2724-cd2b-46c9-98fe-31b0ba0d6db3.png" style="width:0.58em;height:0.75em;"/>, the convolution is computed as follows:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0a67c9c0-107b-4ef7-ba03-8a5846dd779d.png" style="width:14.83em;height:3.00em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">2D convolution</h1>
                </header>
            
            <article>
                
<p class="mce-root">The generalization of the 1D convolution we've introduced in terms of the 2D case is natural. Images, in particular, can be seen as 2D discrete signals. In the 2D case, the counterpart of the Dirac Delta function is the Kronecker Delta function, and it can be expressed independently from the dimensionality of the space it is used in. It's seen as a tensor, δ, with components:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8d7511bf-bc0d-4aad-af0e-9f18c591c32c.png" style="width:10.58em;height:3.00em;"/></p>
<p class="mce-root">Images can be thought as 2D versions of LTI systems. In this case, we are talking about <strong>Linear Space-Invariant</strong> (<strong>LSI</strong>) systems.</p>
<p class="mce-root"><span>In the bi-dimensional discrete case, the convolution operation is defined as follows:</span></p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b018f87c-2eed-4f71-b9e1-296ddccd3d9e.png" style="width:22.33em;height:3.58em;"/></p>
<p class="mce-root CDPAlignLeft CDPAlign">Images are finite dimension signals with a well-defined spatial extent. This means that the previously introduced formula becomes the following:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/61bcc68e-9af0-4468-94a9-e919c41fb19a.png" style="width:19.42em;height:3.58em;"/></p>
<p class="mce-root">Here, we have the following:</p>
<ul>
<li class="mce-root"><img class="fm-editor-equation" src="assets/db207dad-9299-4a07-8d20-8fbe4dff1c48.png" style="width:0.67em;height:1.17em;"/> is the input image</li>
<li class="mce-root"><img class="fm-editor-equation" src="assets/3e983129-600b-4904-a5aa-9c3f107ea69e.png" style="width:1.00em;height:1.17em;"/> is the convolutional filter (also called the kernel) itself and <img class="fm-editor-equation" src="assets/60df3516-8d34-4750-9402-3dc8fa95cf63.png" style="width:1.42em;height:1.17em;"/> is its side</li>
<li class="mce-root"><img class="fm-editor-equation" src="assets/63514cb4-bf69-4077-9c2f-65eefa156bc9.png" style="width:3.75em;height:1.58em;"/>is the output pixel, in the <img class="fm-editor-equation" src="assets/a4367dd5-d676-43a4-bd56-ac5183ac20b3.png" style="width:2.67em;height:1.58em;"/> position</li>
</ul>
<p>The operation that we've described is performed for every <em>(i,j)</em> position of the input image that has a complete overlap with the convolutional filter, as it slides over the input image:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-904 image-border" src="assets/b73289d2-6c28-4abf-a4d9-80f5b6aacce0.png" style="width:25.58em;height:10.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The convolution operation between the input image (on the left) and the convolution kernel produces the feature map on the right</div>
<p class="mce-root">As shown in the preceding diagram, different convolutional filters extract different features from the input image. In fact, in the preceding diagram, we can see how that rectangular filter (Sobel filter) is able to extract the edges of the input image. Convolving an image with a different convolutional filter means having to extract different input features that the kernel can capture. Before the introduction of convolutional neural networks, as we will see in the next section, we would had to manually design convolutional kernels that were able to extract the features needed that were to solve the task at hand.</p>
<p class="mce-root">There are two additional parameters that aren't shown in the preceding formula that control how the convolution operation is performed. These parameters are the horizontal and vertical stride; they tell the operation how many pixels to skip when we move the kernel over the input image over the horizontal and vertical directions. Usually, the horizontal and vertical strides are equal, and they are noted with the letter S.</p>
<p class="mce-root"/>
<p class="mce-root">If the input image has side <img class="fm-editor-equation" src="assets/80e97c32-8975-4de7-81ac-fafe3b917468.png" style="width:3.92em;height:1.17em;"/>, then the resolution of the output signal resulting from the convolution with a kernel of size <em>k</em> can be computed as follows:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8371c927-70bc-4fd4-ab37-073cbad71ede.png" style="width:12.50em;height:2.50em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">2D convolutions among volumes</h1>
                </header>
            
            <article>
                
<p class="mce-root">So far, we've only considered the case of a grayscale image, that is, an image with a single channel. The images we are used to seeing in real life are all RGB images, which are images with three color channels. The convolution operation also works well when the input image has more than one channel; in fact, its definition has been slightly changed in order to make the convolution operation span every channel. </p>
<p class="mce-root">This extended version requires the convolution filter to have the same number of channels as the input image; in short, if the input image has three channels, the convolutional kernel must have three channels too. This way, we are treating images as stacks of 2D signals; we call these volumes.</p>
<p class="mce-root">As a volume, every image (or convolutional kernel) is identified by the triple (W, H, D), where W, H, and D are the width, height, and depth, respectively.</p>
<p class="mce-root">By considering images and kernels as volumes, we can treat them as unordered sets. In fact, the order (RGB, BGR) of the channels only changes how the software interprets the data, while the content remains the same:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e9634856-f0df-4107-a316-d797f326060e.png" style="width:16.33em;height:1.17em;"/></p>
<p class="mce-root">This reasoning allows us to extend the previous formula, thereby making it take the input depth into account:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8dc9046b-f480-4014-8808-36a8d9ba40e9.png" style="width:23.33em;height:3.75em;"/></p>
<p class="mce-root">The result of this convolution operation is called a feature map. Even though the convolution is performed among volumes, the output is a feature map with unitary depth since the convolution operation sums the feature maps that have been produced to take into account all the information of the pixels that share the same spatial (x,y) location. In fact, summing the resulting D feature maps is a way to treat a set of 2D convolutions as a single 2D convolution.</p>
<p class="mce-root">This means that every single position of the resulting activation map, <em>O</em>, contains the information that was captured from the same input location through its complete depth. <span>This is the intuitive idea behind the convolution operation.</span></p>
<p class="mce-root">Alright; we now have a grasp of the convolution operation in 1 and two spatial dimensions; we also introduced the concept of convolutional kernel highlighting whereby defining the kernel value is a manual operation where different kernels can extract different features from the input image/volume.</p>
<p class="mce-root">The process of kernel definition is pure engineering, and defining them is not easy: different tasks can require different kernels; some of them have never been defined, and most of them can be simply impossible to design since certain features can only be extracted by processing a processed signal, which means we would have to apply the convolution operation on the result of another convolution operation (a cascade of convolution operations).</p>
<p class="mce-root">Convolutional neural networks solve this problem: instead of manually defining the convolutional kernels, we can just define convolutional kernels made of neurons.</p>
<p class="mce-root">We can extract features from the input volume by convolving it with multiple volumes of filters and combining them while considering the feature maps that extract new input for a new convolutional layer.</p>
<p class="mce-root">The deeper the network becomes, the more abstract the extracted feature becomes. One of the greatest strengths of CNNs is their ability to combine features that have been extracted, ranging from raw, basic features that were extracted by the first convolutional layers to high-level abstract features that were extracted by the last layers and learned as a combination of the low-level features that were extracted by the other layers:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-906 image-border" src="assets/15c9bc11-2a4e-426e-a274-c813b1901dcd.png" style="width:24.25em;height:14.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">CNNs learn to extract low-level features in the first layers; as the networks become deeper, the abstraction level of the extracted features increases. Image from Zeiler and Fergus, 2013.</div>
<p><span>Another advantage of convolutional layers with respect to fully connected layers is their local-view nature.</span></p>
<p class="mce-root">To process an image, a fully connected layer has to linearize the input image and create a connection from every pixel value to every neuron of the layer. The memory requirements are huge, and making every neuron see the whole input isn't the ideal way to extract meaningful features.</p>
<p class="mce-root">There are certain features that, due to their nature, are not global like the ones that are captured by a fully connected layer. Instead, they are local. For example, the edges of an object are local features to a certain input region, not the whole image. Therefore, CNNs can learn to extract only local features and combine them in the following layers. Another advantage of convolutional architectures is their low number of parameters: they don't need to see (and thus create connections) the whole input; they only need to have a view of their local receptive field. Convolution operations requires fewer parameters to extract meaningful feature maps, all of which capture the local features of the input volume.</p>
<p class="mce-root">CNNs are usually used with another layer, known as the pooling layer. Without digging too much into the details of this operation (it tends to be avoided in today's architectures), we can just think about it as an operation with the same structure as the convolution operation (hence a window that moves in the horizontal and vertical direction of the input) but without a learnable kernel. In every region of the input, a non-learnable function is applied. The aim of this operation is to reduce the size of the feature maps that are produced by a convolution operation in order to reduce the number of parameters of the network.</p>
<p class="mce-root">So that we have an idea of what the common convolutional neural network architecture looks like, the following diagram presents the LeNet 5 architecture that uses a convolutional layer, max-pooling (a pooling operation where the non-learnable function is the max operation over the window), and fully connected layers with the aim of classifying images of handwritten digits in 10 classes:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-907 image-border" src="assets/c66bb426-c824-4e25-bd3a-f95e53bb6147.png" style="width:35.00em;height:11.83em;"/></p>
<div class="packt_figref">LeNet 5 architecture <span>–</span> each plane is a feature map. Source: Gradient-Based Learning Applied to Document Recognition, Yann LeCun at al—1998</div>
<p class="mce-root">Defining network architectures such as LeNet 5 is an art <span>– t</span>here are no precise rules on the number of layers you can use, the number of convolutional filters to learn, or the number of neurons in the fully connected layers. Moreover, even picking the right activation function for the hidden layer is another hyperparameter to search for. Complex models are not only rich in terms of learnable parameters, but also rich in terms of hyperparameters to tune, making the definition of deep architectures non-trivial and challenging.</p>
<p class="mce-root">Convolutions among volumes allow us to do fancy things such as replace every fully connected layer with a 1 x 1 x D convolutional layer and use a 1 x 1 x D convolution inside the network to reduce the dimensionality of the input.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">1 x 1 x D convolutions</h1>
                </header>
            
            <article>
                
<p><img class="fm-editor-equation" src="assets/a17c5c54-a4e3-4ba9-ba02-982cc9de6279.png" style="width:4.58em;height:0.92em;"/> convolutions are important building blocks of state-of-the-art models because they can be used for different goals.</p>
<p class="mce-root">One goal is the use them as a dimensionality reduction technique. Let's understand this by going through an example.</p>
<p class="mce-root">If the convolution operation is applied to an input volume of <img class="fm-editor-equation" src="assets/f4d95ccf-5747-4e0b-8f50-8fc3ca4eb3ef.png" style="width:7.42em;height:0.92em;"/> and it is convolved with a set of <img class="fm-editor-equation" src="assets/a8512514-2b3d-43f7-8829-10aed76735cc.png" style="width:0.92em;height:1.00em;"/> filters, each one being <img class="fm-editor-equation" src="assets/2696cd65-26ca-4860-bc34-741a5e6a5cf9.png" style="width:4.25em;height:0.75em;"/> in size, the number of features is reduced from 512 to <img class="fm-editor-equation" src="assets/741dd8e9-80e5-4610-a8a6-7769d32a5ea7.png" style="width:0.83em;height:0.92em;"/>. The output volume now has a shape of <img class="fm-editor-equation" src="assets/62854add-6e95-40c1-a316-a9ba6e08a489.png" style="width:6.67em;height:0.92em;"/>.</p>
<p class="mce-root">A <img class="fm-editor-equation" src="assets/a17c5c54-a4e3-4ba9-ba02-982cc9de6279.png" style="width:4.58em;height:0.92em;"/> convolution is also equivalent to a fully connected layer. The main difference lies in the nature of the convolution operator and the architectural structure of the fully connected layer: while the latter requires the input to have a fixed size, the former accepts every volume with a spatial extent greater than or equal to<img class="fm-editor-equation" src="assets/fb51544f-def0-408d-90f3-c2f30f12a92c.png" style="width:2.25em;height:0.83em;"/> as input. A <img class="fm-editor-equation" src="assets/583a75a4-89fe-4dee-933c-49a54a4111b7.png" style="width:4.17em;height:0.83em;"/> convolution can therefore substitute any fully connected layer because of this equivalence.</p>
<p class="mce-root">Additionally, the <img class="fm-editor-equation" src="assets/09084700-e4d3-441f-ada9-d1696ab3e2e4.png" style="width:4.17em;height:0.83em;"/> convolutions not only reduce the features in the input to the next layer but also introduce new parameters and new non-linearity into the network that could help increase the model's accuracy.</p>
<p class="mce-root">When a <img class="fm-editor-equation" src="assets/6a28df78-051d-47f5-80d7-98940333115d.png" style="width:4.58em;height:0.92em;"/> convolution is placed at the end of a classification network, it acts exactly like a fully connected layer, but instead of thinking about it as a dimensionality reduction technique, it's more intuitive to think about it as a layer that will output a tensor with a shape of <img class="fm-editor-equation" src="assets/139f5c3a-ae49-4e6e-b7a6-826f91453690.png" style="width:10.50em;height:1.00em;"/>. The spatial extent of the output tensor (identified by W and H) is dynamic and is determined by the locations of the input image that the network analyzed.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root CDPAlignLeft CDPAlign">If the network has been defined with an input of 200 x 200 x 3 and we give it an image with this size as input, the output will be a map with <img class="fm-editor-equation" src="assets/b5135bd2-7d73-4628-a087-69cc2ce2241b.png" style="width:5.42em;height:0.92em;"/> and <img class="fm-editor-equation" src="assets/b2f3fa0e-99ca-4682-8263-47b7d2e77e70.png" style="width:10.92em;height:1.25em;"/>. However, if the input image has a spatial extent greater than <img class="fm-editor-equation" src="assets/68dd81b4-620a-4db0-a698-8cf7be4d6ff0.png" style="width:4.92em;height:1.00em;"/>, then the convolutional network will analyze different locations of the input image (just like a standard convolution does, since it's not possible to consider the whole convolutional architecture as a convolution operation with its own kernel side and stride parameters) and will produce a tensor with <img class="fm-editor-equation" src="assets/b431996f-3149-42b6-83d2-e24390645ef7.png" style="width:2.75em;height:0.83em;"/> and <img class="fm-editor-equation" src="assets/50c37809-537b-4428-bbd0-d6739caf3158.png" style="width:2.92em;height:0.92em;"/>. This is not possible with a fully connected layer that constrains the network to accept a fixed-size input and produce a fixed-size output.</p>
<p class="mce-root CDPAlignLeft CDPAlign"><img class="fm-editor-equation" src="assets/441b5a58-8d8a-4a9e-a518-d4b64f64ccad.png" style="font-size: 1em;width:4.58em;height:0.92em;"/> <span>convolutions are also the fundamental building blocks of semantic segmentation networks, as we will see in the upcoming chapters.</span></p>
<p class="mce-root">Convolutional, pooling, and fully connected layers are the building blocks of almost every neural network architecture that's used nowadays to solve computer vision tasks such as image classification, object detection, semantic segmentation, image generation, and many others!</p>
<p class="mce-root">We will implement all of these neural network architectures using TensorFlow 2.0 in the upcoming chapters.</p>
<p class="mce-root">Although CNNs have a reduced number of parameters, even this model can suffer from the problem of overfitting when used in a deep configuration (a stack of convolutional layers).</p>
<p class="mce-root">Hence, another fundamental topic any ML practitioner should be aware of is regularization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Regularization</h1>
                </header>
            
            <article>
                
<p>Regularization is a way to deal with the problem of overfitting: the goal of regularization is to modify the learning algorithm, or the model itself, to make the model perform well—not just on the training data, but also on new inputs.</p>
<p>One of the most widely used solutions to the overfitting problem—and probably one of the most simple to understand and analyze—is known as <strong>dropout</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dropout</h1>
                </header>
            
            <article>
                
<p>The idea of dropout is to train an ensemble of neural networks and average the results instead of training only a single standard network. Dropout builds new neural networks, starting from a standard neural network, by dropping out neurons with <img class="fm-editor-equation" src="assets/6e9b401e-2a38-422f-b6b8-4c4d06475673.png" style="width:0.75em;height:1.08em;"/> probability.</p>
<p>When a neuron is dropped out, its output is set to zero. This is shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-908 image-border" src="assets/e5a3e4ba-804f-4bb5-aa91-1769ceb28f2b.png" style="width:27.17em;height:14.92em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">On the left, a standard fully connected architecture. On the right, a possible network architecture that's been obtained by dropping out neurons, which means it used dropout during the training phase. Source: Dropout: A simple way to Prevent Neural Networks from Overfitting - N. Srivastava—2014</div>
<p>The dropped neurons do not contribute to the training phase. Since neurons are dropped randomly at each new training iteration, using dropout makes the training phase different every time. In fact, using dropout means that every training step is performed on a new network—<span>and even </span>better, a network with a different topology.</p>
<p><span> N. Srivastava et al. in <em>Dropout: A simple way to Prevent Neural Networks from Overfitting (the </em></span>paper that introduced this regularization technique) explained this concept very well:</p>
<div class="packt_quote"><q>"In a standard neural network, the derivative that's received by each parameter tells it how it should change, so the final loss function is reduced, given what all the other units are doing. Therefore, units may change in a way that they fix the mistakes of the other units.<br/></q> This may lead to complex co-adaptations. This, in turn, leads to overfitting because these co-adaptations do not generalize to unseen data. We hypothesize that, for each hidden unit, dropout prevents co-adaptation by making the presence of other hidden units unreliable.<br/>
Therefore, a hidden unit cannot rely on other specific units to correct its mistakes."</div>
<p>Dropout works well in practice because it prevents the co-adaption of neurons during the training phase. In the upcoming sections, we will analyze how dropout works and how it is implemented.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How dropout works</h1>
                </header>
            
            <article>
                
<p class="mce-root">We can analyze how dropout works by looking at its application on a single neuron. Let's say we have the following:</p>
<ul>
<li><img class="fm-editor-equation" src="assets/2c58e518-fe94-4e6a-84d1-2f6a7c08b864.png" style="width:6.00em;height:1.08em;"/> as a linear neuron</li>
<li><img class="fm-editor-equation" src="assets/fbbd7bb5-e61d-42bb-a8eb-5805dd1050b4.png" style="width:1.50em;height:0.92em;"/> as an activation function</li>
</ul>
<p>By using these, it is possible to model the application of dropout <span>–</span> in the training phase only <span>–</span> as a modification of the activation function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/0a39aef6-94c0-4700-a6e8-4c5dbdbe0c41.png" style="width:6.67em;height:1.08em;"/></p>
<p>Here,</p>
<p class="CDPAlignCenter CDPAlign"> <img class="fm-editor-equation" src="assets/708655cb-6a8c-4fa3-be9b-8dafaa1e374d.png" style="width:8.08em;height:1.17em;"/></p>
<p>Is a <img class="fm-editor-equation" src="assets/1eb41971-a3f1-4a84-b7a0-9adad3a37fd1.png" style="width:1.08em;height:1.08em;"/>-dimensional vector of Bernoulli random variables, <img class="fm-editor-equation" src="assets/cab4fb0c-9771-43f5-9c00-c146c6d1b89c.png" style="width:1.00em;height:0.83em;"/>.</p>
<p>A Bernoulli random variable has the following probability mass distribution:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ae9d177b-578f-4440-b6c8-3ad4776e6568.png" style="width:11.92em;height:2.50em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/5e33fffd-7b0c-461f-8cbf-feb02b635fe5.png" style="width:0.67em;height:1.17em;"/> is the possible outcomes. The Bernoulli random variable correctly models the dropout application on a neuron since the neuron is turned off with the probability of <img class="fm-editor-equation" src="assets/b8b68122-db98-4ed8-a819-97393c50ea2a.png" style="width:6.17em;height:1.25em;"/> and kept on otherwise. It can be useful to see the application of dropout on the generic <em>i</em>-th neuron of a fully-connected layer (but the same holds for the application on a single neuron of a convolutional layer):</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/46bc5ccb-a72c-42ae-b8a2-105927df6069.png" style="width:28.58em;height:3.33em;"/></p>
<p>Here, <img class="fm-editor-equation" src="assets/f7f094f4-5367-4d05-9ebc-a0db16b34ad1.png" style="width:6.00em;height:1.08em;"/>.</p>
<p class="CDPAlignLeft CDPAlign"><span>During training, a neuron is kept on with probability <img class="fm-editor-equation" src="assets/28839481-ee56-4492-9416-b00020fdda79.png" style="width:0.58em;height:1.08em;"/>. Therefore, during the test phase, we have to emulate the behavior of the ensemble of networks that were used in the training phase. To do this, we need to scale the neuron's output by a factor of <img class="fm-editor-equation" src="assets/5cc47d91-61c6-4c8b-b790-b78ccdcb4bdd.png" style="width:0.50em;height:0.92em;"/> d. </span></p>
<p class="mce-root"/>
<p class="CDPAlignLeft CDPAlign"><span>Thus, we have the following: </span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d3d37f89-abe1-4b0d-9aea-ecb48f55661f.png" style="width:21.42em;height:6.92em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Inverted dropout</h1>
                </header>
            
            <article>
                
<p><span>A slightly different approach—and the one that's used in practice in almost every deep learning framework – is to use inverted dropout. This approach consists of scaling the activations during the training phase, with the obvious advantage of not having to change the network architecture during the test phase.</span></p>
<p><span>The scale factor is the inverse of the keep probability,<img class="fm-editor-equation" src="assets/0e09929f-15bb-4375-9347-a236fcc47928.png" style="width:4.58em;height:2.25em;"/>, and so we have the following:</span></p>
<p class="CDPAlignCenter CDPAlign"><span><strong><img class="fm-editor-equation" src="assets/f300107d-65f3-4b9c-8596-814671b1644d.png" style="width:22.42em;height:6.83em;"/></strong></span></p>
<p><span>Inverted dropout is how dropout is implemented in practice because it helps us define the model and just change a parameter (the keep/drop probability) to train and test on the same model.</span></p>
<p><span>Direct dropout, which is the version that was presented in the previous section, forces you to modify the network during the test phase because, if you don't multiply by <img class="fm-editor-equation" src="assets/7831c757-0f28-4927-8ee2-c8d3114b6cbd.png" style="width:0.58em;height:1.08em;"/>, the neuron will produce values that are higher with respect to the one expected by the successive neurons (thus the following neurons can saturate or explode). This is why inverted dropout is the more common implementation.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dropout and L2 regularization</h1>
                </header>
            
            <article>
                
<p><span>Dropout is often used with L2 normalization and other parameter constraint techniques, but this is not always the case.</span></p>
<p class="mce-root"/>
<p><span>Normalization helps keep model parameter values low. In this way, a parameter can't grow too much. In brief, the L2 normalization is an additional term to the loss, where </span><span><img class="fm-editor-equation" src="assets/c7924e24-0afd-429a-be70-96b6044340c5.png" style="width:3.92em;height:1.17em;"/> i</span><span>s a hyperparameter called regularization strength,</span><span> <img class="fm-editor-equation" src="assets/178b99c3-c3e5-4a59-90b3-ee4614ce70ab.png" style="width:3.08em;height:1.00em;"/> i</span><span>s the model, and <img class="fm-editor-equation" src="assets/67310229-1d29-4969-8e5e-c61e2a05b3b7.png" style="width:0.50em;height:0.75em;"/> is the error function between the real <img class="fm-editor-equation" src="assets/9f579730-4561-4fcb-8f58-63013856e698.png" style="width:0.67em;height:1.17em;"/> and the predicted <img class="fm-editor-equation" src="assets/11375194-8a2b-43b3-85bc-f999060f0900.png" style="width:0.75em;height:1.42em;"/> value:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f15888b1-63ed-4ab7-9fa1-be92c76fefe6.png" style="width:15.00em;height:2.33em;"/></p>
<p><span>It's easy to understand that this additional term, when we're doing back-propagation via gradient descent, reduces the update amount. If <img class="fm-editor-equation" src="assets/2a9e1749-082f-4022-9843-3626a2515e02.png" style="width:0.67em;height:1.17em;"/> is the learning rate, the update amount of the parameter <img class="fm-editor-equation" src="assets/a69ccf6f-1f31-4683-ac2e-37595c5e3715.png" style="width:3.25em;height:0.92em;"/> is as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/ee04dc3e-0b77-4110-b2e5-28d38c70d816.png" style="width:15.25em;height:2.92em;"/></p>
<p><span>Dropout alone does not have any way of preventing parameter values from becoming too large during this update phase.</span></p>
<p>There are two other solutions that are extremely easy to implement that do not even require the model to be changed or for the loss to have additional terms. These are known as data augmentation and early stopping.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data augmentation</h1>
                </header>
            
            <article>
                
<p class="mce-root">Data augmentation is a simple way to increase the dataset's size. This is done by applying a set of transformations on the train data. Its aim is to make the model aware that certain input variations are possible and thus make it perform better on a variety of input data.</p>
<p class="mce-root">The set of transformations highly depends on the dataset itself. Usually, when working with an image dataset, the transformations to apply are as follows:</p>
<ul>
<li class="mce-root">Random flip left/right</li>
<li class="mce-root">Random flip up/down</li>
<li class="mce-root">Adding random noise to the input image</li>
<li class="mce-root">Random brightness variation</li>
<li class="mce-root">Random saturation variation</li>
</ul>
<p class="mce-root">However, before applying any of these transformations to our training set, we have to ask: <em>is this transformation meaningful for this data type, for my dataset, and for the task at hand?</em></p>
<p class="mce-root">Just think about the random flip left/right of the input image: if our dataset is a dataset of drawn arrows, each labeled with its direction, and we are training a model to predict the arrow's direction, mirroring the image will just break our training set.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Early stopping</h1>
                </header>
            
            <article>
                
<p class="mce-root">As we introduced in <a href="0dff1bba-f231-45fa-9a89-b4f127309579.xhtml">Chapter 1</a><span>, </span><em>What is Machine Learning?</em><em>, </em>measuring the performance of the model during the training phase on both the validation and training sets is a good habit.<br/>
This good habit can help us prevent overfitting and save us a lot of training time since the measured metrics tell us whether the model is starting to overfit the training data and thus if it is time to stop the training process.</p>
<p class="mce-root">Let's think about a classifier—we measure the validation accuracy, the training accuracy, and the loss value.</p>
<p>Looking at the loss value, we can see that, as the training process goes on, the loss decreases. Of course, this is true only for healthy training. Training is healthy when the loss trend decreases. It is possible to just observe the fluctuation that was introduced by mini-batch gradient descent or the usage of the stochastic regularization process (dropout).</p>
<p>If the training process is healthy and the loss trend decreases, the training accuracy will increase. Training accuracy measures how well the model learns the training set—it does not capture its generalization capabilities. Validation accuracy, on the other hand, is the measure of how good the predictions of your model are on unseen data.</p>
<p class="mce-root">If the model is learning, the validation accuracy increases. If the model is overfitting, the validation accuracy stops increasing and can even start to decrease, while the accuracy measured on the training set reaches the maximum value.</p>
<p class="mce-root">If you stop training the model as soon as the validation accuracy (or whatever the monitored metric is) stops increasing, then you are facing the overfitting problem easily and effectively.</p>
<p>Data augmentation and early stopping are two ways of reducing overfitting without changing the model's architecture.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>However, similar to dropout, there is another common regularization technique, known as batch normalization, that requires that we change the model architecture that we use. This helps speed up the training process and lets us achieve better performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Batch normalization</h1>
                </header>
            
            <article>
                
<p class="mce-root">Batch normalization is not only a regularization technique—it is also a good way to speed up the training process. To increase the stability of the learning process, and thus reduce the oscillation of the loss function, batch normalization normalizes the output of a layer by subtracting the batch mean and dividing it by the batch standard deviation.</p>
<p>After this normalization, which is not a learned process, batch normalization adds two trainable parameters: the standard deviation parameter (gamma) and the mean parameter (beta).</p>
<p>Batch normalization not only helps speed up convergence by reducing the training oscillations, <span>it </span><span>also helps in reducing overfitting since it introduces stochasticity in the training process in a way that's similar to dropout. The difference is that, while dropout adds noise in an explicit manner, batch normalization introduces stochasticity by computing the mean and the variance over the batch.</span></p>
<p>The following image, which was taken from the original paper, <span><em>Batch Normalization – Accelerating Deep Network Training</em>, by Reducing Internal Covariate Shift (Ioffe et al. 2015), shows the algorithm that's applied during the training process:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/42174206-4adb-457d-9c54-396c7322aeca.png" style="width:24.67em;height:20.00em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The batch normalization algorithm. Source: <em>Batch Normalization <span>–</span> Accelerating Deep Network Training by Reducing Internal Covariate Shift</em>, Ioffe et al. 2015</div>
<p>At the end of the training process, it is required that you apply the same affine transformation that was learned during the training process. However, instead of computing the mean and the variance over the input batch, the mean and the variance that accumulated during the training process are used. In fact, batch normalization, just like dropout, has a different behavior during the training and inference phases. During the training phase, it computes the mean and variance over the current input batch, while it accumulates the moving mean and variance use during the inference phase.</p>
<p>Fortunately, since this is a very common operation, TensorFlow has a BatchNormalization layer ready to use, so we don't have to worry about the accumulation of statistics during the training and having to change the layer's behavior during the inference phase.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This chapter is probably the most theory intensive of this whole book; however, it is required that you have at least an intuitive idea of the building blocks of neural networks and of the various algorithms that are used in machine learning so that you can start developing a meaningful understanding of what's going on.</p>
<p>We have looked at what a neural network is, what it means to train it, and how to perform a parameter update with some of the most common update strategies. You should now have a basic understanding of how the chain rule can be applied in order to compute the gradient of a function efficiently.</p>
<p>We haven't explicitly talked about deep learning<span>,</span> but in practice, that is what we did; keep in mind that stacking layers of neural networks is like stacking different classifiers that combine their expressive power. We indicated this with the term deep learning. In practice, we can say that deep neural networks (a deep learning model) are just neural networks with more than one hidden layer.</p>
<p>Later in this chapter, we introduced a lot of important concepts about parametric model training, the origin of neural networks, as well as their mathematical formulation. It is of extreme importance to have at least an intuitive idea of what happens when we define a fully connected (among others) layer when we define the loss and use a certain optimization strategy to train a model using a machine learning framework such as TensorFlow.</p>
<p>TensorFlow hides the complexity of everything we've described in this chapter, but having an understanding of what happens under the hood will allow you to debug a model just by looking at its behavior. You will also have an idea of why certain things happen during the training phase and how to solve certain problems. For instance, knowledge of optimization strategies will help you understand why your loss function value follows a certain trend and assumes certain values during the training phase, and will give you an idea of how to choose the right hyperparameters.</p>
<p>In <span>the next chapter, </span><a href="f62be9d4-c8e0-4590-8299-2fdad139830f.xhtml">Chapter 3</a><span>, </span><em>TensorFlow Graph Architecture</em><span>,</span> we will see how all the theoretical concepts presented in this chapter, using the graph representation of the computation, can be effectively implemented in TensorFlow.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercises</h1>
                </header>
            
            <article>
                
<p><span>This chapter was filled with various theoretical concepts to understand so, just like the previous chapter, don't skip the exercises:</span></p>
<ol>
<li>What are the similarities between artificial and biological neurons?</li>
<li>Does the neuron's topology change the neural network's behavior?</li>
<li>Why do neurons require a non-linear activation function?</li>
<li>If the activation function is linear, a multi-layer neural network is the same as a single layer neural network. Why?</li>
<li>How is an error in input data treated by a neural network?</li>
<li>Write the mathematical formulation of a generic neuron.</li>
<li>Write the mathematical formulation of a fully connected layer.</li>
<li>Why can a multi-layer configuration solve problems with non-linearly separable solutions?</li>
<li>Draw the graph of the sigmoid, tanh, and ReLu activation functions.</li>
<li>Is it always required to format training set labels into a one-hot encoded representation? What if the task is regression?</li>
<li>The loss function creates a bond between the desired outcome and the model output: why is this required for the loss function to be differentiable?</li>
<li>What does the gradient of the loss function indicate? What about the anti-gradient?</li>
<li>What is a parameter update rule? Explain the<span> v</span>anilla<span> </span>update rule.</li>
<li>Write the mini-batch gradient descent algorithm and explain the three possible scenarios.</li>
</ol>
<ol start="15">
<li>Is random perturbation a good update strategy? Explain the pros and cons of this approach.</li>
<li>What's the difference between a non-adaptive and adaptive optimization algorithm?</li>
<li>What's the relationship between the concept of velocity and momentum update? Describe the momentum update algorithm.</li>
<li>What is an LTI system? How is it related to the convolution operation?</li>
<li>What is a feature vector?</li>
<li>Are CNNs feature extractors? If yes, can a fully connected layer be used to classify the output of a convolutional layer?</li>
</ol>
<ol start="21">
<li>What are the guidelines for model parameter initialization? Is assigning a constant value of 10 to every parameter of the network a good initialization strategy?</li>
<li>What are the differences between direct and inverted<span> </span>dropout? Why does TensorFlow implement the inverted version?</li>
<li>Why is the L2 normalization of network parameters useful when using<span> </span>dropout?</li>
<li>Write the formula of convolution among volumes: show how it behaves in the case of a 1 x 1 x D convolutional kernel. Why is there an equivalence between the fully connected layer and a 1 x 1 x D convolution?</li>
<li>If, while training a classifier, the validation accuracy stops increasing, what does this mean? Can adding<span> </span>dropout<span> </span>or increasing the drop probability if<span> </span>dropout<span> </span>layers are already present make the network improve the validation accuracy again? Why or why not?</li>
</ol>


            </article>

            
        </section>
    </body></html>