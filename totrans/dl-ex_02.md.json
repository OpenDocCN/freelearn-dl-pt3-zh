["```\nimport pandas as pd\n```", "```\n# read advertising data samples into a DataFrame\n```", "```\nadvertising_data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n```", "```\n# DataFrame.head method shows the first n rows of the data where the   \n# default value of n is 5, DataFrame.head(n=5)\nadvertising_data.head()\n```", "```\n# print the shape of the DataFrame\nadvertising_data.shape\nOutput:\n(200, 4)\n```", "```\nimport matplotlib.pyplot as plt\n\n# The next line will allow us to make inline plots that could appear directly in the notebook\n# without poping up in a different window\n%matplotlib inline\n```", "```\nfig, axs = plt.subplots(1, 3, sharey=True)\n\n# Adding the scatterplots to the grid \nadvertising_data.plot(kind='scatter', x='TV', y='sales', ax=axs[0], figsize=(16, 8))\nadvertising_data.plot(kind='scatter', x='radio', y='sales', ax=axs[1])\nadvertising_data.plot(kind='scatter', x='newspaper', y='sales', ax=axs[2])\n```", "```\n# To use the formula notation below, we need to import the module like the following\nimport statsmodels.formula.api as smf\n# create a fitted model in one line of code(which will represent the least squares line)\nlm = smf.ols(formula='sales ~ TV', data=advertising_data).fit()\n# show the trained model coefficients\nlm.params\n```", "```\nIntercept    7.032594\nTV           0.047537\ndtype: float64\n```", "```\n# manually calculating the increase in the sales based on $50k\n7.032594 + 0.047537*50000\n```", "```\n9,409.444\n```", "```\n# creating a Pandas DataFrame to match Statsmodels interface expectations\nnew_TVAdSpending = pd.DataFrame({'TV': [50000]})\nnew_TVAdSpending.head()\n```", "```\n# use the model to make predictions on a new value\npreds = lm.predict(new_TVAdSpending)\n```", "```\narray([ 9.40942557])\n```", "```\n# create a DataFrame with the minimum and maximum values of TV\nX_min_max = pd.DataFrame({'TV': [advertising_data.TV.min(), advertising_data.TV.max()]})\nX_min_max.head()\n```", "```\n# predictions for X min and max values\npredictions = lm.predict(X_min_max)\npredictions\n```", "```\narray([  7.0658692,  21.12245377])\n```", "```\n# plotting the acutal observed data\nadvertising_data.plot(kind='scatter', x='TV', y='sales')\n#plotting the least squares line\nplt.plot(new_TVAdSpending, preds, c='red', linewidth=2)\n```", "```\nimport matplotlib.pyplot as plt\n %matplotlib inline\n\n from statsmodels.nonparametric.kde import KDEUnivariate\n from statsmodels.nonparametric import smoothers_lowess\n from pandas import Series, DataFrame\n from patsy import dmatrices\n from sklearn import datasets, svm\n\n import numpy as np\n import pandas as pd\n import statsmodels.api as sm\n\nfrom scipy import stats\nstats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n```", "```\ntitanic_data = pd.read_csv(\"data/titanic_train.csv\")\n```", "```\ntitanic_data.shape\n\n Output:\n (891, 12)\n```", "```\nlist(titanic_data)\n\n Output:\n ['PassengerId',\n 'Survived',\n 'Pclass',\n 'Name',\n 'Sex',\n 'Age',\n 'SibSp',\n 'Parch',\n 'Ticket',\n 'Fare',\n 'Cabin',\n 'Embarked']\n```", "```\ntitanic_data[500:510]\n\n```", "```\ntitanic_data = titanic_data.drop(['Ticket','Cabin'], axis=1)\n```", "```\ntitanic_data = titanic_data.dropna()\n```", "```\n# declaring graph parameters\nfig = plt.figure(figsize=(18,6))\nalpha=alpha_scatterplot = 0.3\nalpha_bar_chart = 0.55\n# Defining a grid of subplots to contain all the figures\nax1 = plt.subplot2grid((2,3),(0,0))\n# Add the first bar plot which represents the count of people who survived vs not survived.\ntitanic_data.Survived.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n# Adding margins to the plot\nax1.set_xlim(-1, 2)\n# Adding bar plot title\nplt.title(\"Distribution of Survival, (1 = Survived)\")\nplt.subplot2grid((2,3),(0,1))\nplt.scatter(titanic_data.Survived, titanic_data.Age, alpha=alpha_scatterplot)\n# Setting the value of the y label (age)\nplt.ylabel(\"Age\")\n# formatting the grid\nplt.grid(b=True, which='major', axis='y')\nplt.title(\"Survival by Age, (1 = Survived)\")\nax3 = plt.subplot2grid((2,3),(0,2))\ntitanic_data.Pclass.value_counts().plot(kind=\"barh\", alpha=alpha_bar_chart)\nax3.set_ylim(-1, len(titanic_data.Pclass.value_counts()))\nplt.title(\"Class Distribution\")\nplt.subplot2grid((2,3),(1,0), colspan=2)\n# plotting kernel density estimate of the subse of the 1st class passengerâ€™s age\ntitanic_data.Age[titanic_data.Pclass == 1].plot(kind='kde')\ntitanic_data.Age[titanic_data.Pclass == 2].plot(kind='kde')\ntitanic_data.Age[titanic_data.Pclass == 3].plot(kind='kde')\n# Adding x label (age) to the plot\nplt.xlabel(\"Age\")\nplt.title(\"Age Distribution within classes\")\n# Add legend to the plot.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best')\nax5 = plt.subplot2grid((2,3),(1,2))\ntitanic_data.Embarked.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\nax5.set_xlim(-1, len(titanic_data.Embarked.value_counts()))\nplt.title(\"Passengers per boarding location\")\n```", "```\nplt.figure(figsize=(6,4))\nfig, ax = plt.subplots()\ntitanic_data.Survived.value_counts().plot(kind='barh', color=\"blue\", alpha=.65)\nax.set_ylim(-1, len(titanic_data.Survived.value_counts()))\nplt.title(\"Breakdown of survivals(0 = Died, 1 = Survived)\")\n```", "```\nfig = plt.figure(figsize=(18,6))\n#Plotting gender based analysis for the survivals.\nmale = titanic_data.Survived[titanic_data.Sex == 'male'].value_counts().sort_index()\nfemale = titanic_data.Survived[titanic_data.Sex == 'female'].value_counts().sort_index()\nax1 = fig.add_subplot(121)\nmale.plot(kind='barh',label='Male', alpha=0.55)\nfemale.plot(kind='barh', color='#FA2379',label='Female', alpha=0.55)\nplt.title(\"Gender analysis of survivals (raw value counts) \"); plt.legend(loc='best')\nax1.set_ylim(-1, 2)\nax2 = fig.add_subplot(122)\n(male/float(male.sum())).plot(kind='barh',label='Male', alpha=0.55)  \n(female/float(female.sum())).plot(kind='barh', color='#FA2379',label='Female', alpha=0.55)\nplt.title(\"Gender analysis of survivals\"); plt.legend(loc='best')\nax2.set_ylim(-1, 2)\n```", "```\n# model formula\n# here the ~ sign is an = sign, and the features of our dataset\n# are written as a formula to predict survived. The C() lets our\n# regression know that those variables are categorical.\n# Ref: http://patsy.readthedocs.org/en/latest/formulas.html\nformula = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + C(Embarked)'\n# create a results dictionary to hold our regression results for easy analysis later\nresults = {}\n# create a regression friendly dataframe using patsy's dmatrices function\ny,x = dmatrices(formula, data=titanic_data, return_type='dataframe')\n# instantiate our model\nmodel = sm.Logit(y,x)\n# fit our model to the training data\nres = model.fit()\n# save the result for outputing predictions later\nresults['Logit'] = [res, formula]\nres.summary()\nOutput:\nOptimization terminated successfully.\n Current function value: 0.444388\n Iterations 6\n```", "```\n# Plot Predictions Vs Actual\nplt.figure(figsize=(18,4));\nplt.subplot(121, axisbg=\"#DBDBDB\")\n# generate predictions from our fitted model\nypred = res.predict(x)\nplt.plot(x.index, ypred, 'bo', x.index, y, 'mo', alpha=.25);\nplt.grid(color='white', linestyle='dashed')\nplt.title('Logit predictions, Blue: \\nFitted/predicted values: Red');\n# Residuals\nax2 = plt.subplot(122, axisbg=\"#DBDBDB\")\nplt.plot(res.resid_dev, 'r-')\nplt.grid(color='white', linestyle='dashed')\nax2.set_xlim(-1, len(res.resid_dev))\nplt.title('Logit Residuals');\n```"]