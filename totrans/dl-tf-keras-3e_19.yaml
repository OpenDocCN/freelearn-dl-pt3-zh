- en: '19'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow 2 Ecosystem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the different components of the TensorFlow
    ecosystem. The chapter will elaborate upon TensorFlow Hub – a repository for pretrained
    deep learning models – and TensorFlow Datasets – a collection of ready-to-use
    datasets for ML tasks. TensorFlow JS, the solution for training and deploying
    ML models on the web, will be introduced. We will also learn about TensorFlow
    Lite, an open-source deep learning framework for mobile and edge devices. Some
    examples of Android, iOS, and Raspberry Pi applications will be discussed, together
    with examples of deploying pretrained models such as MobileNet v1, v2, v3 (image
    classification models designed for mobile and embedded vision applications), PoseNet
    for pose estimation (a vision model that estimates the poses of people in image
    or video), DeepLab segmentation (an image segmentation model that assigns semantic
    labels (for example, dog, cat, and car) to every pixel in the input image), and
    MobileNet SSD object detection (an image classification model that detects multiple
    objects with bounding boxes). The chapter will conclude with an example of federated
    learning, a decentralized machine learning framework that is thought to respect
    user privacy. The chapter includes:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow Datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow Lite and using it for mobile and edge applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Federated learning at edge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow JS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Node.js with TensorFlow models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code files for this chapter can be found at [https://packt.link/dltfchp19](https://packt.link/dltfchp19)
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin with TensorFlow Hub.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Hub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even if you have a powerful computer, training a machine learning model can
    take days or weeks. And once you’ve trained the model, deploying it to different
    devices can be difficult and time-consuming. Depending upon the platform you want
    to deploy, you might need it in different formats.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can think of TensorFlow Hub as a library with many pretrained models. It
    contains hundreds of trained, ready-to-deploy deep learning models. TensorFlow
    Hub provides pretrained models for image classification, image segmentation, object
    detection, text embedding, text classification, video classification and generation,
    and much more. The models in TF Hub are available in SavedModel, TFLite, and TF.js
    formats. We can use these pretrained models directly for inference or fine-tune
    them. With its growing community of users and developers, TensorFlow Hub is the
    go-to place for finding and sharing machine learning models. To use TensorFlow
    Hub, we first need to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once installed, we can import it simply using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'and load the model using the `load` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here `handle` is a string, which contains the link of the model we wants to
    use. If we want to use it as part of our existing model, we can wrap it as a Keras
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: By changing the parameter `trainable` to `True`, we can fine-tune the model
    for our specific data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 19.1* shows the easy-to-use web interface to select different models
    at the `tfhub.dev` site. Using the filters, we can easily find a model to solve
    our problem.'
  prefs: []
  type: TYPE_NORMAL
- en: We can choose which type and format we need, as well as who published it!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.1: The tfhub.dev site showing different filters'
  prefs: []
  type: TYPE_NORMAL
- en: Using pretrained models for inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us see how you can leverage pretrained models from TensorFlow Hub. We will
    consider an example of image classification:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us import the necessary modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We define a function for loading an image from a URL. The functions get the
    image from the web, and we reshape it by adding batch indexes for inference. Also,
    the image is normalized and resized according to the pretrained model chosen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Another helper function to show the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The model we are using is EfficientNet-B2 ([https://arxiv.org/abs/1905.11946](https://arxiv.org/abs/1905.11946))
    trained on the ImageNet dataset. It gives better accuracy, is smaller in size,
    and gives faster inference. For convenience, we choose images to be resized to
    330 x 330 pixels. We use the helper function defined in step 2 to download the
    image from Wikimedia:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![](img/B18331_19_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.2: The image taken from the web for classification, scaled to size
    330 x 330 pixels'
  prefs: []
  type: TYPE_NORMAL
- en: 'For completeness, we also get all the labels of ImageNet data so that we can
    infer the label from the model prediction; we download it from a public repository
    of TensorFlow:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that all the ingredients are ready, we download the model from `tfhub.dev`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We get the softmax probabilities for all the classes for the image downloaded
    in step 5:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let us see the top prediction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![](img/B18331_19_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.3: The image with the label prediction of lion'
  prefs: []
  type: TYPE_NORMAL
- en: So, as we can see, in a few lines of code we get a perfect inference – the image
    is of a lioness, and the closest label for it in the ImageNet dataset is that
    of a lion, which the model has correctly predicted. By using the pretrained models
    of TF Hub, we can focus on our product workflow, and get better models and faster
    production.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TensorFlow Datasets** (**TFDS**) is a powerful tool for anyone working with
    machine learning. It provides a collection of ready-to-use datasets that can be
    easily used with TensorFlow or any other Python ML framework. All datasets are
    exposed as `tf.data.Datasets`, making it easy to use them in your input pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With TFDS, you can quickly get started with your machine learning projects
    and save time by not having to collect and prepare your own data. The library
    currently contains a wide variety of datasets, including image classification,
    object detection, text classification, and more. In addition, the library provides
    tools for creating new datasets from scratch, which can be useful for researchers
    or developers who need to create custom datasets for their own projects. TFDS
    is open source and released under the Apache 2.0 license. To be able to use TFDS,
    you will need to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Once installed, you can import it as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'At the time of writing this book, TFDS contained 224 public datasets for a
    large range of tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we will introduce you to TFDS and show how it can simplify
    your training process by exploring its underlying structure as well as providing
    some best practices for loading large amounts into machine learning models efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Load a TFDS dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each dataset in TFDS is identified by its unique name, and associated with
    each dataset is also a publisher and dataset version. To get the data, you can
    use the TFDS `load` function (it is a powerful function with a lot of flexibility;
    you can read more about the function at [https://www.tensorflow.org/datasets/api_docs/python/tfds/load](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You only need to specify the dataset name; the rest of the parameters are optional.
    You can read more about the optional arguments from TFDS docs. For example, below,
    we are downloading the famous MNIST dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The preceding statement downloads both the training and test dataset of MNIST
    into the variable data. Since the `as_supervised` flag is set to `True`, the labels
    are downloaded with the data, and the detailed information about the dataset is
    downloaded in `info`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us first check the info:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we can see that the information is quite extensive. It tells us about the
    splits and the total number of samples in each split, the keys available if used
    for supervised learning, the citation details, and so on. The variable data here
    is a list of two TFDS dataset objects – the first one corresponding to the test
    dataset and the second one corresponding to the train dataset. TFDS dataset objects
    are `dict` by default. Let us take one single sample from the train dataset and
    explore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the sample is an image of handwritten digits of the shape
    28 x 28 x 1 and its label is `2`. For image data, TFDS also has a method `show_examples`,
    which you can use to view the sample images from the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![A picture containing diagram  Description automatically generated](img/B18331_19_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.4: Sample from test dataset of MNIST dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Building data pipelines using TFDS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us build a complete end-to-end example using the TFDS data pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, we start with importing the necessary modules. Since we will be
    using TensorFlow to build the model, and TFDS for getting the dataset, we are
    including only these two for now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using the Keras Sequential API, we build a simple convolutional neural network
    with three convolutional layers and two dense layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will be building a binary classifier, so we choose binary cross entropy
    as the loss function, and Adam as the optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we come to the dataset. We are using the `horses_or_humans` dataset,
    so we use the `tfds.load` function to get the training and validation data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The images need to be normalized; additionally, for better performance, we
    will augment the images while training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'So now we build the pipeline; we start with `cache` for better memory efficiency,
    apply the pre-processing steps (normalization and augmentation), ensure that data
    is shuffled while training, define the batch size, and use `prefetch` so that
    the next batch is brought in as the present batch is being trained on. We repeat
    the same steps for the validation data. The difference is that validation data
    need not be augmented or shuffled:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And finally, we train the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Play around with different parameters of the data pipeline and see how it affects
    the training time. For example, try removing `prefetch` and `cache` and not specifying
    `num_parallel_calls`.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Lite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TensorFlow Lite is a lightweight platform designed by TensorFlow. This platform
    is focused on mobile and embedded devices such as Android, iOS, and Raspberry
    Pi. The main goal is to enable machine learning inference directly on the device
    by putting a lot of effort into three main characteristics: (1) a small binary
    and model size to save on memory, (2) low energy consumption to save on the battery,
    and (3) low latency for efficiency. It goes without saying that battery and memory
    are two important resources for mobile and embedded devices. To achieve these
    goals, Lite uses a number of techniques such as quantization, FlatBuffers, mobile
    interpreter, and mobile converter, which we are going to review briefly in the
    following sections.'
  prefs: []
  type: TYPE_NORMAL
- en: Quantization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quantization refers to a set of techniques that constrains an input made of
    continuous values (such as real numbers) into a discrete set (such as integers).
    The key idea is to reduce the space occupancy of **Deep Learning** (**DL**) models
    by representing the internal weight with integers instead of real numbers. Of
    course, this implies trading space gains for some amount of performance of the
    model. However, it has been empirically shown in many situations that a quantized
    model does not suffer from a significant decay in performance. TensorFlow Lite
    is internally built around a set of core operators supporting both quantized and
    floating-point operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Model quantization is a toolkit for applying quantization. This operation is
    applied to the representations of weights and, optionally, to the activations
    for both storage and computation. There are two types of quantization available:'
  prefs: []
  type: TYPE_NORMAL
- en: Post-training quantization quantizes weights and the result of activations post-training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantization-aware training allows for the training of networks that can be
    quantized with minimal accuracy drop (only available for specific CNNs). Since
    this is a relatively experimental technique, we are not going to discuss it in
    this chapter, but the interested reader can find more information in [1].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TensorFlow Lite supports reducing the precision of values from full floats
    to half-precision floats (`float16`) or 8-bit integers. TensorFlow reports multiple
    trade-offs in terms of accuracy, latency, and space for selected CNN models (see
    *Figure 19.5*, source: [https://www.tensorflow.org/lite/performance/model_optimization](https://www.tensorflow.org/lite/performance/model_optimization)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B18331_19_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.5: Trade-offs for various quantized CNN models'
  prefs: []
  type: TYPE_NORMAL
- en: FlatBuffers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FlatBuffers ([https://google.github.io/flatbuffers/](https://google.github.io/flatbuffers/))
    is an open-source format optimized to serialize data on mobile and embedded devices.
    The format was originally created at Google for game development and other performance-critical
    applications. FlatBuffers supports access to serialized data without parsing/unpacking
    for fast processing. The format is designed for memory efficiency and speed by
    avoiding unnecessary multiple copies in memory. FlatBuffers works across multiple
    platforms and languages such as C++, C#, C, Go, Java, JavaScript, Lobster, Lua,
    TypeScript, PHP, Python, and Rust.
  prefs: []
  type: TYPE_NORMAL
- en: Mobile converter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A model generated with TensorFlow needs to be converted into a TensorFlow Lite
    model. The converter can introduce optimizations for improving the binary size
    and performance. For instance, the converter can trim away all the nodes in a
    computational graph that are not directly related to inference but instead are
    needed for training.
  prefs: []
  type: TYPE_NORMAL
- en: Mobile optimized interpreter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow Lite runs on a highly optimized interpreter that is used to optimize
    the underlying computational graphs, which in turn are used to describe the machine
    learning models. Internally, the interpreter uses multiple techniques to optimize
    the computational graph by inducing a static graph order and by ensuring better
    memory allocation. The interpreter core takes ~100 kb alone or ~300 kb with all
    supported kernels.
  prefs: []
  type: TYPE_NORMAL
- en: Computational graphs are the graphical representation of the learning algorithm;
    here, nodes describe the operations to be performed and edges connecting the nodes
    represent the flow of data. These graphs provide the deep learning frameworks
    with performance efficiency, which we are not able to achieve if we construct
    a neural network in pure NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: Supported platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On Android, the TensorFlow Lite inference can be performed using either Java
    or C++. On iOS, TensorFlow Lite inference can run in Swift and Objective-C. On
    Linux platforms (such as Raspberry Pi), inferences run in C++ and Python. TensorFlow
    Lite for microcontrollers is an experimental port of TensorFlow Lite designed
    to run machine learning models on microcontrollers based on Arm Cortex-M ([https://developer.arm.com/ip-products/processors/cortex-m](https://developer.arm.com/ip-products/processors/cortex-m))
    and series processors, including Arduino Nano 33 BLE Sense ([https://store.arduino.cc/nano-33-ble-sense-with-headers](https://store.arduino.cc/nano-33-ble-sense-with-headers)),
    SparkFun Edge ([https://www.sparkfun.com/products/15170](https://www.sparkfun.com/products/15170)),
    and the STM32F746 Discovery kit ([https://www.st.com/en/evaluation-tools/32f746gdiscovery.xhtml](https://www.st.com/en/evaluation-tools/32f746gdiscovery.xhtml)).
    These microcontrollers are frequently used for IoT applications.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The architecture of TensorFlow Lite is described in *Figure 19.6* (from [https://www.tensorflow.org/lite/convert/index](https://www.tensorflow.org/lite/convert/index)).
    As you can see, both **tf.keras** (for example, TensorFlow 2.x) and **low-Level
    APIs** are supported. A standard TensorFlow 2.x model can be converted by using
    **TFLite Converter** and then saved in a **TFLite FlatBuffer** format (named `.tflite`),
    which is then executed by the **TFLite interpreter** on available devices (GPUs
    and CPUs) and on native device APIs. The concrete function in *Figure 19.6* defines
    a graph that can be converted to a TensorFlow Lite model or be exported to a **SavedModel**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B18331_19_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.6: TensorFlow Lite internal architecture'
  prefs: []
  type: TYPE_NORMAL
- en: Using TensorFlow Lite
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using TensorFlow Lite involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model selection**: A standard TensorFlow 2.x model is selected for solving
    a specific task. This can be either a custom-built model or a pretrained model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model conversion**: The selected model is converted with the TensorFlow Lite
    converter, generally invoked with a few lines of Python code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model deployment**: The converted model is deployed on the chosen device,
    either a phone or an IoT device, and then run by using the TensorFlow Lite interpreter.
    As discussed, APIs are available for multiple languages.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model optimization**: The model can be optionally optimized by using the
    TensorFlow Lite optimization framework.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A generic example of an application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we are going to see how to convert a model to TensorFlow Lite
    and then run it. Note that training can still be performed by TensorFlow in the
    environment that best fits your needs. However, inference runs on the mobile device.
    Let’s see how with the following code fragment in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The code is self-explanatory. A standard TensorFlow 2.x model is opened and
    converted by using `tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)`.
    Pretty simple! Note that no specific installation is required. We simply use the
    `tf.lite` API ([https://www.tensorflow.org/api_docs/python/tf/lite](https://www.tensorflow.org/api_docs/python/tf/lite)).
    It is also possible to apply a number of optimizations. For instance, post-training
    quantization can be applied by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model is converted, it can be copied onto the specific device. Of
    course, this step is different for each different device. Then the model can run
    by using the language you prefer. For instance, in Java the invocation happens
    with the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Again, pretty simple! What is very useful is that the same steps can be followed
    for a heterogeneous collection of mobile and IoT devices.
  prefs: []
  type: TYPE_NORMAL
- en: Using GPUs and accelerators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Modern phones frequently have accelerators on board that allow floating-point
    matrix operations to be performed faster. In this case, the interpreter can use
    the concept of Delegate, and specifically, `GpuDelegate()`, to use GPUs. Let’s
    look at an example in Java:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Again, the code is self-commenting. A new `GpuDelegate()` is created and then
    it is used by the interpreter to run the model on a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: An example of an application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we are going to use TensorFlow Lite for building an example
    application that is later deployed on Android. We will use Android Studio ([https://developer.android.com/studio/](https://developer.android.com/studio/))
    to compile the code. The first step is to clone the repo with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Then we open an existing project (see *Figure 19.7*) with the path `examples/lite/examples/image_classification/android`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then you need to install Android Studio from [https://developer.android.com/studio/install](https://developer.android.com/studio/install)
    and an appropriate distribution of Java. In my case, I selected the Android Studio
    macOS distribution and installed Java via `brew` with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, you can launch the `sdkmanager` and install the required packages.
    In my case, I decided to use the internal emulator and deploy the application
    on a virtual device emulating a Google Pixel 3 XL. The required packages are reported
    in *Figure 19.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text  Description automatically generated](img/B18331_19_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.7: Required packages to use a Google Pixel 3 XL emulator'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, start Android Studio and select **Open an existing Android Studio project**,
    as shown in *Figure 19.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B18331_19_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.8: Opening a new Android project'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open **Adv Manager** (under the **Tool** menu) and follow the instructions
    for how to create a virtual device, like the one shown in *Figure 19.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.9: Creating a virtual device'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the virtual device ready, let us dive into the TensorFlow
    Lite models and see how we can use them.
  prefs: []
  type: TYPE_NORMAL
- en: Pretrained models in TensorFlow Lite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For many interesting use cases, it is possible to use a pretrained model that
    is already suitable for mobile computation. This is a field of active research
    with new proposals coming pretty much every month. Pretrained TensorFlow Lite
    models are available on TensorFlow Hub; these models are ready to use ([https://www.tensorflow.org/lite/models/](https://www.tensorflow.org/lite/models/)).
    As of August 2022, these include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image classification**: Used to identify multiple classes of objects such
    as places, plants, animals, activities, and people.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object detection**: Used to detect multiple objects with bounding boxes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Audio speech synthesis**: Used to generate speech from text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text embedding**: Used to embed textual data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Segmentations**: Identifies the shape of objects together with semantic labels
    for people, places, animals, and many additional classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Style transfers**: Used to apply artistic styles to any given image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text classification**: Used to assign different categories to textual content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question and answer**: Used to provide answers to questions provided by users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will discuss some of the optimized pretrained models available
    in TensorFlow Lite out of the box as of August 2022\. These models can be used
    for a large number of mobile and edge computing use cases. Compiling the example
    code is pretty simple.
  prefs: []
  type: TYPE_NORMAL
- en: You just import a new project from each example directory and Android Studio
    will use Gradle ([https://gradle.org/](https://gradle.org/)) for synching the
    code with the latest version in the repo and for compiling.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you compile all the examples, you should be able to see them in the emulator
    (see *Figure 19.10*). Remember to select **Build** | **Make Project**, and Android
    Studio will do the rest:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.10: Emulated Google Pixel 3 XL with TensorFlow Lite example applications'
  prefs: []
  type: TYPE_NORMAL
- en: Edge computing is a distributed computing model that brings computation and
    data closer to the location where it is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Image classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As of August 2022, the list of available models for pretrained classification
    is rather large, and it offers the opportunity to trade space, accuracy, and performance
    as shown in *Figure 19.11* (source: [https://www.tensorflow.org/lite/models/trained](https://www.tensorflow.org/lite/models/trained)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.11: Space, accuracy, and performance trade-offs for various mobile
    models'
  prefs: []
  type: TYPE_NORMAL
- en: MobileNet V1 is a quantized CNN model described in Benoit Jacob [2]. MobileNet
    V2 is an advanced model proposed by Google [3]. Online, you can also find floating-point
    models, which offer the best balance between model size and performance. Note
    that GPU acceleration requires the use of floating-point models. Note that recently,
    AutoML models for mobile have been proposed based on an automated **mobile neural
    architecture search** (**MNAS**) approach [4], beating the models handcrafted
    by humans.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed AutoML in *Chapter 13*, *An Introduction to AutoML*, and the interested
    reader can refer to MNAS documentation in the references [4] for applications
    to mobile devices.
  prefs: []
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow Lite format models are included in TF Hub. There is a large number
    of pretrained models that can detect multiple objects within an image, with bounding
    boxes. Eighty different classes of objects are recognized. The network is based
    on a pretrained quantized COCO SSD MobileNet V1 model. For each object, the model
    provides the class, the confidence of detection, and the vertices of the bounding
    boxes ([https://tfhub.dev/s?deployment-format=lite&module-type=image-object-detection](https://tfhub.dev/s?deployment-format=lite&module-type=image-object-detection)).
  prefs: []
  type: TYPE_NORMAL
- en: Pose estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TF Hub has a TensorFlow Lite format pretrained model for detecting parts of
    human bodies in an image or a video. For instance, it is possible to detect noses,
    left/right eyes, hips, ankles, and many other parts. Each detection comes with
    an associated confidence score ([https://tfhub.dev/s?deployment-format=lite&module-type=image-pose-detection](https://tfhub.dev/s?deployment-format=lite&module-type=image-pose-detection)).
  prefs: []
  type: TYPE_NORMAL
- en: Smart reply
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TF Hub also has a TensorFlow Lite format pretrained model for generating replies
    to chat messages. These replies are contextualized and similar to what is available
    on Gmail ([https://tfhub.dev/tensorflow/lite-model/smartreply/1/default/1](https://tfhub.dev/tensorflow/lite-model/smartreply/1/default/1)).
  prefs: []
  type: TYPE_NORMAL
- en: Segmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are pretrained models ([https://tfhub.dev/s?deployment-format=lite&module-type=image-segmentation](https://tfhub.dev/s?deployment-format=lite&module-type=image-segmentation))
    for image segmentation, where the goal is to decide what the semantic labels (for
    example, person, dog, and cat) assigned to every pixel in the input image are.
    Segmentation is based on the DeepLab algorithm [5].
  prefs: []
  type: TYPE_NORMAL
- en: Style transfer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow Lite also supports artistic style transfer (see *Chapter 20*, *Advanced
    Convolutional Neural Networks*) via a combination of a MobileNet V2-based neural
    network, which reduces the input style image to a 100-dimension style vector,
    and a style transform model, which applies the style vector to a content image
    to create the stylized image ([https://tfhub.dev/s?deployment-format=lite&module-type=image-style-transfer](https://tfhub.dev/s?deployment-format=lite&module-type=image-style-transfer)).
  prefs: []
  type: TYPE_NORMAL
- en: Text classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are models for text classification and sentiment analysis ([https://tfhub.dev/s?deployment-format=lite&module-type=text-classification](https://tfhub.dev/s?deployment-format=lite&module-type=text-classification))
    trained on the Large Movie Review Dataset v1.0 ([http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/))
    with IMDb movie reviews that are positive or negative. An example of text classification
    is given in *Figure 19.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.12: An example of text classification on Android with TensorFlow
    Lite'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are pretrained large language models based on transformer architecture
    ([https://tfhub.dev/s?deployment-format=lite&q=bert](https://tfhub.dev/s?deployment-format=lite&q=bert)).
    The models are based on a compressed variant of BERT [6] (see *Chapter 6*, *Transformers*)
    called MobileBERT [7], which runs 4x faster and has a 4x smaller size. An example
    of Q&A is given in *Figure 19.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.13: An example of Q&A on Android with TensorFlow Lite and BERT'
  prefs: []
  type: TYPE_NORMAL
- en: A note about using mobile GPUs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section concludes the overview of pretrained models for mobile devices
    and IoT. Note that modern phones are equipped with internal GPUs. For instance,
    on Pixel 3, TensorFlow Lite GPU inference accelerates inference to 2–7x faster
    than CPUs for many models (see *Figure 19.14*, source: [https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.xhtml](https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.xhtml)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.14: GPU speed-up over CPU for various learning models running on
    various phones'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of federated learning at the edge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed, edge computing is a distributed computing model that brings computation
    and data closer to the location where it is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s introduce **Federated Learning** (**FL**) [8] at the edge, starting
    with two use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you built an app for playing music on mobile devices and then you want
    to add recommendation features aimed at helping users to discover new songs they
    might like. Is there a way to build a distributed model that leverages each user’s
    experience without disclosing any private data?
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you are a car manufacturer producing millions of cars connected via
    5G networks, and then you want to build a distributed model for optimizing each
    car’s fuel consumption. Is there a way to build such a model without disclosing
    the driving behavior of each user?
  prefs: []
  type: TYPE_NORMAL
- en: Traditional machine learning requires you to have a centralized repository for
    training data either on your desktop, in your data center, or in the cloud. Federated
    learning pushes the training phase at the edge by distributing the computation
    among millions of mobile devices. These devices are ephemeral in that they are
    not always available for the learning process, and they can disappear silently
    (for instance, a mobile phone can be switched off all of a sudden). The key idea
    is to leverage the CPUs and the GPU of each mobile phone that is made available
    for an FL computation. Each mobile device that is part of the distributed FL training
    downloads a (pretrained) model from a central server, and it performs local optimization
    based on the local training data collected on each specific mobile device. This
    process is similar to the transfer learning process (see *Chapter 20*, *Advanced
    Convolutional Neural Networks*), but it is distributed at the edge. Each locally
    updated model is then sent back by millions of edge devices to a central server
    to build an averaged shared model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, there are many issues to be considered. Let’s review them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Battery usage**: Each mobile device that is part of an FL computation should
    save as much as possible on local battery usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Encrypted communication**: Each mobile device belonging to an FL computation
    has to use encrypted communication with the central server to update the locally
    built model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficient communication**: Typically, deep learning models are optimized
    with optimization algorithms such as SGD (see *Chapter 1*, *Neural Network Foundations
    with TF*, and *Chapter 14*, *The Math Behind Deep Learning*). However, FL works
    with millions of devices and there is, therefore, a strong need to minimize the
    communication patterns. Google introduced a Federated Averaging algorithm [8],
    which is reported to reduce the amount of communication 10x–100x when compared
    with vanilla SGD. Plus, compression techniques [9] reduce communication costs
    by an additional 100x with random rotations and quantization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ensure user privacy**: This is probably the most important point. All local
    training data acquired at the edge must stay at the edge. This means that the
    training data acquired on a mobile device cannot be sent to a central server.
    Equally important, any user behavior learned in locally trained models must be
    anonymized so that it is not possible to understand any specific action performed
    by specific individuals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Figure 19.15* shows a typical FL architecture [10]. An FL server sends a model
    and a training plan to millions of devices. The training plan includes information
    on how frequently updates are expected and other metadata.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each device runs the local training and sends a model update back to the global
    services. Note that each device has an FL runtime providing federated learning
    services to an app process that stores data in a local example store. The FL runtime
    fetches the training examples from the example store:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.15: An example of federated learning architecture'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow FL APIs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**The TensorFlow Federated** (**TTF**) platform has two layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Federated learning** (**FL**), as discussed earlier, is a high-level interface
    that works well with `tf.keras` and non-`tf.keras` models. In the majority of
    situations, we will use this API for distributed training that is privacy-preserving.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Federated core** (**FC**), a low-level interface that is highly customizable
    and allows you to interact with low-level communications and with federated algorithms.
    You will need this API only if you intend to implement new and sophisticated distributed
    learning algorithms. This topic is rather advanced, and we are not going to cover
    it in this book. If you wish to learn more, you can find more information online
    ([https://www.tensorflow.org/federated/federated_core](https://www.tensorflow.org/federated/federated_core)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The FL API has three key parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Models**: Used to wrap existing models for enabling federating learning.
    This can be achieved via the `tff.learning.from_keras_model()`, or via the subclassing
    of `tff.learning.Model()`. For instance, you can have the following code fragment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Builders**: This is the layer where the federated computation happens. There
    are two phases: compilation, where the learning algorithm is serialized into an
    abstract representation of the computation, and execution, where the represented
    computation is run.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Datasets**: This is a large collection of data that can be used to simulate
    federated learning locally – a useful step for initial fine-tuning.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We conclude this overview by mentioning that you can find a detailed description
    of the APIs online and also a number of coding examples ([https://www.tensorflow.org/federated/federated_learning](https://www.tensorflow.org/federated/federated_learning)).
    Start by using the Colab notebook made available by Google ([https://colab.research.google.com/github/tensorflow/federated/blob/v0.10.1/docs/tutorials/federated_learning_for_image_classification.ipynb](https://colab.research.google.com/github/tensorflow/federated/blob/v0.10.1/docs/tutorials/federated_learning_for_image_classification.ipynb)).
    The framework allows us to simulate the distributed training before running it
    in a real environment. The library in charge of FL learning is `tensorflow_federated`.
    *Figure 19.16* discusses all the steps used in federated learning with multiple
    nodes, and it might be useful to better understand what has been discussed in
    this section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.16: An example of federated learning with multiple nodes (source:
    https://upload.wikimedia.org/wikipedia/commons/e/e2/Federated_learning_process_central_case.png)'
  prefs: []
  type: TYPE_NORMAL
- en: The next section will introduce TensorFlow.js, a variant of TensorFlow that
    can be used natively in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow.js is a JavaScript library for machine learning models that can work
    either in vanilla mode or via Node.js. In this section, we are going to review
    both of them.
  prefs: []
  type: TYPE_NORMAL
- en: Vanilla TensorFlow.js
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow.js is a JavaScript library for training and using machine learning
    models in a browser. It is derived from deeplearn.js, an open-source, hardware-accelerated
    library for doing deep learning in JavaScript, and is now a companion library
    to TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: The most common use of TensorFlow.js is to make pretrained ML/DL models available
    on the browser. This can help in situations where it may not be feasible to send
    client data back to the server due to network bandwidth or security concerns.
    However, TensorFlow.js is a full-stack ML platform, and it is possible to build
    and train an ML/DL model from scratch, as well as fine-tune an existing pretrained
    model with new client data.
  prefs: []
  type: TYPE_NORMAL
- en: An example of a TensorFlow.js application is the TensorFlow Projector ([https://projector.tensorflow.org](https://projector.tensorflow.org)),
    which allows a client to visualize their own data (as word vectors) in 3-dimensional
    space, using one of several dimensionality reduction algorithms provided. There
    are a few other examples of TensorFlow.js applications listed on the TensorFlow.js
    demo page ([https://www.tensorflow.org/js/demos](https://www.tensorflow.org/js/demos)).
  prefs: []
  type: TYPE_NORMAL
- en: Similar to TensorFlow, TensorFlow.js also provides two main APIs – the Ops API,
    which exposes low-level tensor operations such as matrix multiplication, and the
    Layers API, which exposes Keras-style high-level building blocks for neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, TensorFlow.js runs on three different backends. The
    fastest (and also the most complex) is the WebGL backend, which provides access
    to WebGL’s low-level 3D graphics APIs and can take advantage of GPU hardware acceleration.
    The other popular backend is the Node.js backend, which allows the use of TensorFlow.js
    in server-side applications. Finally, as a fallback, there is the CPU-based implementation
    in plain JavaScript that will run in any browser.
  prefs: []
  type: TYPE_NORMAL
- en: In order to gain a better understanding of how to write a TensorFlow.js application,
    we will walk through an example of classifying MNIST digits using a CNN provided
    by the TensorFlow.js team ([https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml](https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml)).
  prefs: []
  type: TYPE_NORMAL
- en: The steps here are similar to a normal supervised model development pipeline
    – load the data, define, train, and evaluate the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'JavaScript works inside a browser environment, within an HTML page. The HTML
    file (named `index.xhtml`) below represents this HTML page. Notice the two imports
    for TensorFlow.js (`tf.min.js`) and the TensorFlow.js visualization library (`tfjs-vis.umd.min.js`)
    – these provide library functions that we will use in our application. The JavaScript
    code for our application comes from `data.js` and `script.js` files, located in
    the same directory as our `index.xhtml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'For deployment, we will deploy these three files (`index.xhtml`, `data.js`,
    and `script.js`) on a web server, but for development, we can start a web server
    up by calling a simple one bundled with the Python distribution. This will start
    up a web server on port `8000` on `localhost`, and the `index.xhtml` file can
    be rendered on the browser at `http://localhost:8000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to load the data. Fortunately, Google provides a JavaScript
    script that we have called directly from our `index.xhtml` file. It downloads
    the images and labels from GCP storage and returns shuffled and normalized batches
    of image and label pairs for training and testing. We can download this to the
    same folder as the `index.xhtml` file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'For Windows users, you will need to first download Wget: [https://eternallybored.org/misc/wget/](https://eternallybored.org/misc/wget/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Model definition, training, and evaluation code is all specified inside the
    `script.js` file. The function to define and build the network is shown in the
    following code block. As you can see, it is very similar to the way you would
    build a sequential model with `tf.keras`. The only difference is the way you specify
    the arguments, as a dictionary of name-value pairs instead of a list of parameters.
    The model is a sequential model, that is, a list of layers. Finally, the model
    is compiled with the Adam optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The model is then trained for 10 epochs with batches from the training dataset
    and validated inline using batches from the test dataset. A best practice is to
    create a separate validation dataset from the training set. However, to keep our
    focus on the more important aspect of showing how to use TensorFlow.js to design
    an end-to-end DL pipeline, we are using the external `data.js` file provided by
    Google, which provides functions to return only a training and test batch. In
    our example, we will use the test dataset for validation as well as evaluation
    later.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is likely to give us better accuracies compared to what we would have
    achieved with an unseen (during training) test set, but that is unimportant for
    an illustrative example such as this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model finishes training, we want to make predictions and evaluate
    the model on its predictions. The following functions will do the predictions
    and compute the overall accuracy for each of the classes over all the test set
    examples, as well as produce a confusion matrix across all the test set samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `run()` function will call all these functions in sequence to
    build an end-to-end ML pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Refreshing the browser location, `http://localhost:8000/index.xhtml`, will invoke
    the `run()` method above. *Figure 19.17* shows the model architecture and the
    plots of the progress of the training.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the left are the loss and accuracy values on the validation dataset observed
    at the end of each batch, and on the right are the same loss and accuracy values
    observed on the training dataset (blue) and validation dataset (red) at the end
    of each epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_17.1.png)![](img/B18331_19_17.2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.17: Model loss and accuracy as it is being trained'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, the following figure shows the accuracies across different classes
    for predictions from our trained model on the test dataset, as well as the confusion
    matrix of predicted versus actual classes for test dataset samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_19_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.18: Confusion metrics and accuracy for each class as obtained by
    the trained model'
  prefs: []
  type: TYPE_NORMAL
- en: 'Readers might enjoy seeing this live example from the TensorFlow team training
    a TFJS model on the MNIST dataset: [https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml](https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: We have seen how to use TensorFlow.js within the browser. The next section will
    explain how to convert a model from Keras into TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: Converting models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes it is convenient to convert a model that has already been created
    with `tf.keras`. This is very easy and can be done offline with the following
    command, which takes a Keras model from `/tmp/model.h5` and outputs a JavaScript
    model into `/tmp/tfjs_model`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'To be able to use this command, you will need a Python environment with TensorFlow
    JS installed using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: This will install the above converter. The next section will explain how to
    use pretrained models in TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: Pretrained models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow.js comes with a significant number of pretrained models for deep
    learning with image, video, and text. The models are hosted on npm, so it’s very
    simple to use them if you are familiar with Node.js development.
  prefs: []
  type: TYPE_NORMAL
- en: '*Table 19.1* summarizes some of the pretrained models available as of August
    2022 (source: [https://github.com/tensorflow/tfjs-models](https://github.com/tensorflow/tfjs-models)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Images** |'
  prefs: []
  type: TYPE_TB
- en: '| **Model** | **Details** | **Install** |'
  prefs: []
  type: TYPE_TB
- en: '| MobileNet ([https://github.com/tensorflow/tfjs-models/tree/master/mobilenet](https://github.com/tensorflow/tfjs-models/tree/master/mobilenet))
    | Classify images with labels from the ImageNet database. | `npm i @tensorflow-models/mobilenet`
    |'
  prefs: []
  type: TYPE_TB
- en: '| PoseNet ([https://github.com/tensorflow/tfjs-models/tree/master/posenet](https://github.com/tensorflow/tfjs-models/tree/master/posenet))
    | A machine learning model that allows for real-time human pose estimation in
    the browser; see a detailed description here: [https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5](https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5).
    | `npm i @tensorflow-models/posenet` |'
  prefs: []
  type: TYPE_TB
- en: '| Coco SSD ([https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd](https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd))
    | Object detection model that aims to localize and identify multiple objects in
    a single image; based on the TensorFlow object detection API ([https://github.com/tensorflow/models/blob/master/research/object_detection/README.md](https://github.com/tensorflow/models/blob/master/research/object_detection/README.md)).
    | `npm i @tensorflow-models/coco-ssd` |'
  prefs: []
  type: TYPE_TB
- en: '| BodyPix ([https://github.com/tensorflow/tfjs-models/tree/master/body-pix](https://github.com/tensorflow/tfjs-models/tree/master/body-pix))
    | Real-time person and body-part segmentation in the browser using TensorFlow.js.
    | `npm i @tensorflow-models/body-pix` |'
  prefs: []
  type: TYPE_TB
- en: '| DeepLab v3([https://github.com/tensorflow/tfjs-models/tree/master/deeplab](https://github.com/tensorflow/tfjs-models/tree/master/deeplab))
    | Semantic segmentation. | `npm i @tensorflow-models/deeplab` |'
  prefs: []
  type: TYPE_TB
- en: '| **Audio** |'
  prefs: []
  type: TYPE_TB
- en: '| **Model** | **Details** | **Install** |'
  prefs: []
  type: TYPE_TB
- en: '| Speech Commands ([https://github.com/tensorflow/tfjs-models/tree/master/speech-commands](https://github.com/tensorflow/tfjs-models/tree/master/speech-commands))
    | Classify 1-second audio snippets from the speech commands dataset ([https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md)).
    | `npm i @tensorflow-models/speech-commands` |'
  prefs: []
  type: TYPE_TB
- en: '| **Text** |'
  prefs: []
  type: TYPE_TB
- en: '| **Model** | **Details** | **Install** |'
  prefs: []
  type: TYPE_TB
- en: '| Universal Sentence Encoder ([https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder](https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder))
    | Encode text into a 512-dimensional embedding to be used as inputs to natural
    language processing tasks such as sentiment classification and textual similarity.
    | `npm i @tensorflow-models/universal-sentence-encoder` |'
  prefs: []
  type: TYPE_TB
- en: '| Text Toxicity ([https://github.com/tensorflow/tfjs-models/tree/master/toxicity](https://github.com/tensorflow/tfjs-models/tree/master/toxicity))
    | Score the perceived impact a comment might have on a conversation, from “Very
    toxic” to “Very healthy”. | `npm i @tensorflow-models/toxicity` |'
  prefs: []
  type: TYPE_TB
- en: '| **General Utilities** |'
  prefs: []
  type: TYPE_TB
- en: '| **Model** | **Details** | **Install** |'
  prefs: []
  type: TYPE_TB
- en: '| KNN Classifier ([https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier](https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier))
    | This package provides a utility for creating a classifier using the K-nearest
    neighbors algorithm; it can be used for transfer learning. | `npm i @tensorflow-models/knn-classifier`
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 19.1: A list of some of the pretrained models on TensorFlow.js'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each pretrained model can be directly used from HTML. For instance, this is
    an example with the KNN classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The next section will explain how to use pretrained models in Node.js.
  prefs: []
  type: TYPE_NORMAL
- en: Node.js
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will give an overview of how to use TensorFlow with Node.js.
    Let’s start.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CPU package is imported with the following line of code, which will work
    for all macOS, Linux, and Windows platforms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The GPU package is imported with the following line of code (as of November
    2019, this will work only on a GPU in a CUDA environment):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of Node.js code for defining and compiling a simple dense model
    is reported below. The code is self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Training can then start with the typical Node.js asynchronous invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we have discussed how to use TensorFlow.js with both vanilla
    JavaScript and Node.js using sample applications for both the browser and backend
    computation.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed different components of the TensorFlow ecosystem.
    We started with TensorFlow Hub, the place where many pretrained models are available.
    Next, we talked about the TensorFlow Datasets and learned how to build a data
    pipeline using TFDS. We learned how to use TensorFlow Lite for mobile devices
    and IoT and deployed real applications on Android devices. Then, we also talked
    about federated learning for distributed learning across thousands (millions)
    of mobile devices, taking into account privacy concerns. The last section of the
    chapter was devoted to TensorFlow.js for using TensorFlow with vanilla JavaScript
    or with Node.js.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is about advanced CNNs, where you will learn some advanced
    CNN architectures and their applications.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Quantization-aware training: [https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize](https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., and
    Kalenichenko, D. (Submitted on 15 Dec 2017). *Quantization and Training of Neural
    Networks for Efficient Integer-Arithmetic-Only Inference*. [https://arxiv.org/abs/1712.05877](https://arxiv.org/abs/1712.05877)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L-C. (Submitted on 13
    Jan 2018 (v1), last revised 21 Mar 2019 (v4)). *MobileNetV2: Inverted Residuals
    and Linear Bottlenecks*. [https://arxiv.org/abs/1806.08342](https://arxiv.org/abs/1806.08342)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
    Q. V. *MnasNet: Platform-Aware Neural Architecture Search for Mobile*. [https://arxiv.org/abs/1807.11626](https://arxiv.org/abs/1807.11626)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Chen, L-C., Papandreou, G., Kokkinos, I., Murphy, K., and Yuille, A. L. (May
    2017). *DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous
    Convolution, and Fully Connected CRFs*. [https://arxiv.org/pdf/1606.00915.pdf](https://arxiv.org/pdf/1606.00915.pdf)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Devlin, J., Chang, M-W., Lee, K., and Toutanova, K. (Submitted on 11 Oct 2018
    (v1), last revised 24 May 2019 v2). *BERT: Pre-training of Deep Bidirectional
    Transformers for Language Understanding*. [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Anonymous authors, Paper under double-blind review. (modified: 25 Sep 2019).
    *MOBILEBERT: TASK-AGNOSTIC COMPRESSION OF BERT BY PROGRESSIVE KNOWLEDGE TRANSFER*.
    ICLR 2020 Conference Blind Submission Readers: Everyone. [https://openreview.net/pdf?id=SJxjVaNKwB](https://openreview.net/pdf?id=SJxjVaNKwB)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: McMahan, H. B., Moore, E., Ramage, D., Hampson, and S., Arcas, B. A. y. (Submitted
    on 17 Feb 2016 (v1), last revised 28 Feb 2017 (this version, v3)). *Communication-Efficient
    Learning of Deep Networks from Decentralized Data*. [https://arxiv.org/abs/1602.05629](https://arxiv.org/abs/1602.05629)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Konečný, J., McMahan, H. B., Yu, F. X., Richtárik, P., Suresh, A. T., and Bacon,
    D. (Submitted on 18 Oct 2016 (v1), last revised 30 Oct 2017 (this version, v2)).
    *Federated Learning: Strategies for Improving Communication Efficiency*. [https://arxiv.org/abs/1610.05492](https://arxiv.org/abs/1610.05492)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bonawitz, K. et al. (22 March 2019). *TOWARDS FEDERATED LEARNING AT SCALE:
    SYSTEM DESIGN*. [https://arxiv.org/pdf/1902.01046.pdf](https://arxiv.org/pdf/1902.01046.pdf%20)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 2000 members at: [https://packt.link/keras](https://packt.link/keras)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1831217224278819687.png)'
  prefs: []
  type: TYPE_IMG
