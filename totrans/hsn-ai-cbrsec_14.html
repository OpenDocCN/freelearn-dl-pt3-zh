<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Assessing your AI Arsenal</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In addition to evaluating the effectiveness of their algorithms, it is also important to know the techniques that attackers exploit to evade Our AI-empowered tools. </span><span class="koboSpan" id="kobo.2.2">Only in this way is it possible to gain a realistic idea of the effectiveness and reliability of the solutions adopted. </span><span class="koboSpan" id="kobo.2.3">Also, the aspects related to the scalability of the solutions must be taken into consideration, along with their continuous monitoring, in order to guarantee reliability.</span></p>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we will learn </span><span><span class="koboSpan" id="kobo.4.1">about the following</span></span><span class="koboSpan" id="kobo.5.1">:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.6.1">How attackers leverage </span><strong><span class="koboSpan" id="kobo.7.1">Artificial Intelligence</span></strong><span class="koboSpan" id="kobo.8.1"> (</span><strong><span class="koboSpan" id="kobo.9.1">AI</span></strong><span class="koboSpan" id="kobo.10.1">) to evade </span><strong><span class="koboSpan" id="kobo.11.1">Machine Learning</span></strong><span><span class="koboSpan" id="kobo.12.1"> (</span></span><strong><span class="koboSpan" id="kobo.13.1">ML</span></strong><span><span class="koboSpan" id="kobo.14.1">)</span></span><span class="koboSpan" id="kobo.15.1"> anomaly detectors</span></li>
<li><span class="koboSpan" id="kobo.16.1">The challenges we face when implementing ML anomaly detection</span></li>
<li><span class="koboSpan" id="kobo.17.1">How to test our solutions for data and model quality</span></li>
<li><span class="koboSpan" id="kobo.18.1">How to ensure security and reliability of our AI solutions for cybersecurity</span></li>
</ul>
<p><span class="koboSpan" id="kobo.19.1">Let's begin with learning how attackers evade ML anomaly detectors.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Evading ML detectors</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In </span><a href="18f56dc2-fd40-4669-bef1-0b594d9e1572.xhtml"><span class="koboSpan" id="kobo.3.1">Chapter 8</span></a><span class="koboSpan" id="kobo.4.1">, </span><em><span class="koboSpan" id="kobo.5.1">GANs </span></em><span class="koboSpan" id="kobo.6.1">– </span><em><span class="koboSpan" id="kobo.7.1">Attacks and Defenses</span></em><span class="koboSpan" id="kobo.8.1">, we showed how to use </span><strong><span class="koboSpan" id="kobo.9.1">Generative Adversarial Networks</span></strong><span class="koboSpan" id="kobo.10.1"> (</span><strong><span class="koboSpan" id="kobo.11.1">GANs</span></strong><span class="koboSpan" id="kobo.12.1">) to deceive detection algorithms. </span><span class="koboSpan" id="kobo.12.2">Now, we will see that, it is not only GANs that pose a threat to our AI-based cybersecurity solutions, but more generally, it is possible to exploit Reinforcement Learning (RL) to render our detection tools ineffective.</span></p>
<p><span class="koboSpan" id="kobo.13.1">To understand how, we need to briefly introduce the fundamental concepts of RL.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Understanding RL</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Compared to the various forms of AI, RL is characterized by implementing a trial and error fashion of automated learning. In fact, the RL algorithms adapt their learning processes based on the feedback obtained from the environment. </span><span class="koboSpan" id="kobo.2.2">This feedback can be positive, that is, rewards; or negative, that is, punishments. </span><span class="koboSpan" id="kobo.2.3">In addition, feedback differs according to the successes and errors of the </span><span><span class="koboSpan" id="kobo.3.1">predictions</span></span><span class="koboSpan" id="kobo.4.1">.</span></p>
<p><span class="koboSpan" id="kobo.5.1">Therefore, we can say that learning takes place on the basis of rewards and punishments obtained by an intelligent software: as such, the intelligent software (also known as the </span><strong><span class="koboSpan" id="kobo.6.1">agent</span></strong><span class="koboSpan" id="kobo.7.1">) learns from the feedbacks obtained from a given domain contest (also known as the </span><strong><span class="koboSpan" id="kobo.8.1">environment</span></strong><span class="koboSpan" id="kobo.9.1">).</span></p>
<p><span><span class="koboSpan" id="kobo.10.1">Unlike ML, in RL the learning process does not take place on the basis of a training dataset, but on the mutual interaction of the agent with an environment that models real-world use cases. </span></span><span class="koboSpan" id="kobo.11.1">Each environment, on the other hand, is characterized by a substantial number of parameters and information on the basis of which the agent learns how to achieve its goals.</span></p>
<p><span class="koboSpan" id="kobo.12.1">In learning how to achieve its goals, the agent receives various feedback from the environment in the form of rewards and punishments.</span></p>
<p><span class="koboSpan" id="kobo.13.1">A typical example of a RL agent's goal consists of learning how to find the solution to games, such as mazes:</span></p>
<p class="CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.14.1"><img class="aligncenter size-full wp-image-575 image-border" src="assets/a6d49b53-2eaf-498e-962c-429dd599564c.png" style="width:20.33em;height:20.17em;"/></span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><span class="koboSpan" id="kobo.15.1">(Image Credits: https://commons.wikimedia.org/wiki/File:Reinforcement_learning_diagram.svg)</span></div>
<p><span class="koboSpan" id="kobo.16.1">The environment in which the learning process takes place can be known or even unknown to the agent. </span><span class="koboSpan" id="kobo.16.2">In achieving its goals, the agent follows the learning strategy that maximizes rewards.</span></p>
<p><span class="koboSpan" id="kobo.17.1">These characteristics make RL particularly suitable for solving problems in unknown contexts, such as learning the solutions of mazes.</span></p>
<p><span class="koboSpan" id="kobo.18.1">In solving the maze, the agent's ultimate goal consists of reaching the exit as soon as possible, without knowing the maze scheme in advance, by learning the route based on trial and error (that is, by leveraging the feedback obtained from the environment).</span></p>
<p><span class="koboSpan" id="kobo.19.1">To summarize, RL is characterized by the following elements:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.20.1">One or more agents</span></li>
<li><span class="koboSpan" id="kobo.21.1">An environment</span></li>
<li><span class="koboSpan" id="kobo.22.1">States (places reached by the agent)</span></li>
<li><span class="koboSpan" id="kobo.23.1">Actions (moves performed by the agent to reach the different states)</span></li>
<li><span class="koboSpan" id="kobo.24.1">Feedback (the scores associated with specific states)</span></li>
</ul>
<p><span class="koboSpan" id="kobo.25.1">Let's see how all these elements interact in the learning process.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">RL feedback and state transition</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">We have said that, in RL, the learning process is guided by feedback, emulating a decision-making approach led by trial and error. </span><span class="koboSpan" id="kobo.2.2">In achieving a goal such as finding the exit of the maze, the agent will perform actions (moves) that are associated with feedback (rewards or punishments) from </span><span><span class="koboSpan" id="kobo.3.1">different environments</span></span><span class="koboSpan" id="kobo.4.1">.</span></p>
<p><span class="koboSpan" id="kobo.5.1">The feedback is emitted based on the state assumed by the agent after each action, that is, the place occupied by the agent after each move. </span><span class="koboSpan" id="kobo.5.2">Feedback is then sent from the environment to the agent. As a consequence, the agent iteratively updates its predictions for the next states, based on the rewards received, weighing the subsequent action's success with probabilistic estimates. By leveraging feedback, the agent adapts its behavior to the environment. </span><span class="koboSpan" id="kobo.5.3">This adaptation occurs in the transition from one state to another, during which the learning process takes place. </span><span class="koboSpan" id="kobo.5.4">This transition from one state to another is also known as the </span><strong><span class="koboSpan" id="kobo.6.1">state transition process</span></strong><span class="koboSpan" id="kobo.7.1">.</span></p>
<p><span class="koboSpan" id="kobo.8.1">After having quickly introduced the fundamental concepts of RL, let's see how we can apply them to evading malware ML detectors.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Evading malware detectors with RL</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In </span><a href="3311e837-18a2-4a50-8322-f7b9c12bcbc8.xhtml"><span class="koboSpan" id="kobo.3.1">Chapter 4</span></a><span class="koboSpan" id="kobo.4.1">, </span><em><span class="koboSpan" id="kobo.5.1">Malware Threat Detection</span></em><span class="koboSpan" id="kobo.6.1">, we thoroughly analyzed the advantages deriving from the implementation of malware detectors using ML algorithms.</span></p>
<p><span class="koboSpan" id="kobo.7.1">In </span><a href="18f56dc2-fd40-4669-bef1-0b594d9e1572.xhtml"><span class="koboSpan" id="kobo.8.1">Chapter 8</span></a><span class="koboSpan" id="kobo.9.1">, </span><em><span class="koboSpan" id="kobo.10.1">GANs </span></em><span class="koboSpan" id="kobo.11.1">– </span><em><span class="koboSpan" id="kobo.12.1">Attacks and Defenses</span></em><span class="koboSpan" id="kobo.13.1">, we also showed how it is possible to use GANs to deceive these detectors.</span></p>
<p><span class="koboSpan" id="kobo.14.1">We said that the attack methods based on GANs can be distinguished as follows:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.15.1">White-box attacks</span></strong><span class="koboSpan" id="kobo.16.1">: The attacker knows the structure of the model on which the detector is based, and is able to perform queries to understand how to evade the detector</span></li>
<li><strong><span class="koboSpan" id="kobo.17.1">Black-box attacks</span></strong><span class="koboSpan" id="kobo.18.1">: The attacker does not know the structure or the characteristics of the detector, but has indirect access to the underlying model in order to perform a model substitution</span></li>
</ul>
<p><span class="koboSpan" id="kobo.19.1">Even in the case of black-box attacks, the attacker, although not aware of the structure and properties of the detector, must however know the complete features (feature space) of the target model. </span><span class="koboSpan" id="kobo.19.2">Therefore, to train the substitute model and carry out the attack via model substitution, the attacker must be aware of the features that characterize the original model, and this is where RL comes into play.</span></p>
<p><span class="koboSpan" id="kobo.20.1">Thanks to RL, in fact, the attacker can perform the attack despite being totally unaware, not only of the structure and implementation features of the model underlying the malware detector, but also of the detection features.</span></p>
<p><span class="koboSpan" id="kobo.21.1">One of the first examples of using RL to attack malware detectors was described in the paper entitled </span><em><span class="koboSpan" id="kobo.22.1">Evading Machine Learning Malware Detection</span></em><span class="koboSpan" id="kobo.23.1">, by Hyrum S. </span><span class="koboSpan" id="kobo.23.2">Anderson, Anant Kharkar, Phil Roth, and Bobby Filar, whose results were presented at Black Hat USA 2017, July 22–27, 2017, Las Vegas, NV, USA.</span></p>
<p><span class="koboSpan" id="kobo.24.1">The cited paper shows an example of a black-box attack conducted against classifiers using the RL, in which not only the target classifier structure, but also its feature space, are completely unknown to the attacker. </span><span class="koboSpan" id="kobo.24.2">Nonetheless, the reduced information available to the attacker results in a lower attack rate than black-box attacks with GANs.</span></p>
<p><span class="koboSpan" id="kobo.25.1">However, the paper demonstrates the possibility of carrying out a black-box attack, despite having limited information, by exploiting the RL.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Black-box attacks with RL</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In the paper mentioned previously, an RL model is implemented to carry out a black-box attack against a malware detector, with the aim of evading a static Windows </span><strong><span class="koboSpan" id="kobo.3.1">Portable Executable</span></strong><span class="koboSpan" id="kobo.4.1"> (</span><strong><span class="koboSpan" id="kobo.5.1">PE</span></strong><span class="koboSpan" id="kobo.6.1">) malware classifier.</span></p>
<p><span class="koboSpan" id="kobo.7.1">The attack scenario includes the following elements:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.8.1">The RL model consists of an agent and an environment.</span></li>
<li><span class="koboSpan" id="kobo.9.1">The agent iteratively chooses an action A to execute.</span></li>
<li><span class="koboSpan" id="kobo.10.1">Each action A is associated with a change in state space S.</span></li>
<li><span class="koboSpan" id="kobo.11.1">Every change of state is associated with feedback from the environment, in the form of a scalar award.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.12.1">The feedback and their scalar awards are then fed back to the agent. </span><span class="koboSpan" id="kobo.12.2">The agent determines his next action based on such feedback, following a strategy, that is, an objective function that maximizes rewards. </span><span class="koboSpan" id="kobo.12.3">This objective function determines what action to perform next.</span></p>
<p><span class="koboSpan" id="kobo.13.1">In particular, the set of A actions represents the corresponding set of modifications that can be performed on the PE format executable file, in order to deceive the malware classifier, while maintaining the malware's functionality.</span></p>
<p><span class="koboSpan" id="kobo.14.1">In relation to each action, the scalar award is evaluated by the environment based on the outcome returned by the malware classifier.</span></p>
<p><span class="koboSpan" id="kobo.15.1">The authors of the paper also developed an evasion environment malware called </span><strong><span class="koboSpan" id="kobo.16.1">EvadeRL </span></strong><span class="koboSpan" id="kobo.17.1">(</span><a href="https://github.com/drhyrum/gym-malware"><span class="koboSpan" id="kobo.18.1">https://github.com/drhyrum/gym-malware</span></a><span class="koboSpan" id="kobo.19.1">) and its source code is released as an open source.</span></p>
<p><span class="koboSpan" id="kobo.20.1">EvadeRL is based on the OpenAI Gym framework (</span><a href="https://gym.openai.com/"><span class="koboSpan" id="kobo.21.1">https://gym.openai.com/</span></a><span class="koboSpan" id="kobo.22.1">) that offers standardized preconfigured RL environments.</span></p>
<p><span class="koboSpan" id="kobo.23.1">The malware evasion environment consists of the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.24.1">An initial malware sample</span></li>
<li><span class="koboSpan" id="kobo.25.1">A customizable antimalware engine</span></li>
</ul>
<p><span class="koboSpan" id="kobo.26.1">Each step provides the following feedback to the agent:</span></p>
<ul>
<li><strong><span class="koboSpan" id="kobo.27.1">Reward</span></strong><span class="koboSpan" id="kobo.28.1">: A value of </span><kbd><span class="koboSpan" id="kobo.29.1">10.0</span></kbd><span class="koboSpan" id="kobo.30.1"> if the malware sample passes the malware engine control, or </span><kbd><span class="koboSpan" id="kobo.31.1">0.0</span></kbd><span class="koboSpan" id="kobo.32.1"> if the malware sample fails</span></li>
<li><strong><span class="koboSpan" id="kobo.33.1">Observation space</span></strong><span class="koboSpan" id="kobo.34.1">: A vector of features summarizing the composition of the malware sample</span></li>
</ul>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.35.1">Based on this feedback, the agent chooses the next action consisting of a modification performed on the malware sample PE file format, which does not alter the original functionality of the executable.</span></p>
<p><span class="koboSpan" id="kobo.36.1">The representation of the malware sample inside the environment takes the form of a 2,350-dimensional features vector, which includes the usual PE file format artifacts categories, such as the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.37.1">PE header</span></li>
<li><span class="koboSpan" id="kobo.38.1">PE sections</span></li>
<li><span class="koboSpan" id="kobo.39.1">Import and export tables</span></li>
<li><span class="koboSpan" id="kobo.40.1">ASCII strings, such as file paths, URLs, and registry keys</span></li>
</ul>
<p><span class="koboSpan" id="kobo.41.1">Each action of the agent corresponds to a change of state that represents one of the possible modifications of the sample malware PE file format.</span></p>
<p><span class="koboSpan" id="kobo.42.1">Having to preserve both the integrity of the PE file format and the integrity of the functionality of the malware, the number of possible modifications is therefore relatively small, and some examples include the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.43.1">Adding a new function to the </span><strong><span class="koboSpan" id="kobo.44.1">Import Address Table</span></strong><span class="koboSpan" id="kobo.45.1"> (</span><strong><span class="koboSpan" id="kobo.46.1">IAT</span></strong><span class="koboSpan" id="kobo.47.1">), without this being called by the executable</span></li>
<li><span class="koboSpan" id="kobo.48.1">Modification of the names of the exiting sections</span></li>
<li><span class="koboSpan" id="kobo.49.1">Adding new unused sections</span></li>
<li><span class="koboSpan" id="kobo.50.1">Extra space padding at the end of each section</span></li>
</ul>
<p><span class="koboSpan" id="kobo.51.1">In the experiment conducted by the authors of the cited paper, a gradient-boosted decision tree classifier, whose training was carried out with a training dataset of 100,000 samples (both malicious and benign), is successfully attacked, achieving a </span><strong><span class="koboSpan" id="kobo.52.1">Area Under the ROC curve</span></strong><span class="koboSpan" id="kobo.53.1"> (</span><strong><span class="koboSpan" id="kobo.54.1">AUC</span></strong><span class="koboSpan" id="kobo.55.1">) score equal to </span><kbd><span class="koboSpan" id="kobo.56.1">0.96</span></kbd><span class="koboSpan" id="kobo.57.1">.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Challenging ML anomaly detection</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">As we saw in </span><a href="a6eab48a-f031-44c9-ae4a-0cfd5db2e05e.xhtml"><span class="koboSpan" id="kobo.3.1">Chapter 5</span></a><span class="koboSpan" id="kobo.4.1">, </span><em><span class="koboSpan" id="kobo.5.1">Network Anomaly Detection with AI</span></em><span class="koboSpan" id="kobo.6.1">, one of the areas in which ML has proved particularly useful is that of anomaly detection. </span><span class="koboSpan" id="kobo.6.2">However, even in the case of anomaly detection, the adoption of AI-based cybersecurity solutions must be carefully evaluated in light of the challenges that the complexity of these solutions inevitably introduces.</span></p>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.7.1">In particular, the possible negative impact, both on the business and on the security of the errors originating from the anomaly detection systems, induced by both false positives and false negatives, must be carefully evaluated.</span></p>
<p><span class="koboSpan" id="kobo.8.1">As we know, there is usually a trade-off between false positives and false negatives; therefore, attempting to reduce the number of false negatives (the number of attacks that go undetected), almost inevitably leads to an increase in false positives (the detection of false attacks).</span></p>
<p><span class="koboSpan" id="kobo.9.1">More often than not, the costs deriving from classification errors are relevant: if, in fact, a false negative (that is, an attack that went undetected) can lead to the compromise of the integrity of the corporate's sensitive data (or even the compromise of the system). </span><span class="koboSpan" id="kobo.9.2">At the same time, an excessive number of false positives (that is, the detection of actually non-existent attacks) can determine the unreliability of the detection system, preventing the timely recognition of real attacks.</span></p>
<p><span class="koboSpan" id="kobo.10.1">These are some of the reasons why </span><strong><span class="koboSpan" id="kobo.11.1">pure</span></strong><span class="koboSpan" id="kobo.12.1"> anomaly detection systems (that is, detection systems that are based solely on automated procedures), are extremely rare in practice.</span></p>
<p><span class="koboSpan" id="kobo.13.1">Both in the cases of the anomaly detection systems, and fraud detection and prevention systems (see </span><a href="98ce7db1-f53d-47ca-b6ca-ec0e5f882566.xhtml"><span class="koboSpan" id="kobo.14.1">Chapter 7</span></a><span class="koboSpan" id="kobo.15.1">, </span><em><span class="koboSpan" id="kobo.16.1">Fraud Prevention with Cloud AI Solutions</span></em><span class="koboSpan" id="kobo.17.1">), reliability is increased by integrating the automated procedures with the feedback deriving from human operators (therefore achieving, for example, a greater reliability of the labels associated with the supervised algorithms).</span></p>
<p><span class="koboSpan" id="kobo.18.1">Another order of problems has to do with the requisite of algorithm explainability, since the results obtained by the algorithms are often difficult to interpret (not surprisingly, the ML algorithms are often treated as black boxes).</span></p>
<p><span class="koboSpan" id="kobo.19.1">The difficulty in interpreting the results obtained by the algorithms can result in overwhelming investigative activities, due to the impenetrability of the reasons that led the algorithms to detect certain anomalies.</span></p>
<p><span class="koboSpan" id="kobo.20.1">In other words, with the inevitable opacity associated with algorithms, learning processes, it is often difficult to reconcile with the need to reconstruct—in a precise (and repeatable) way—the process that led the system to report the anomaly.</span></p>
<p><span class="koboSpan" id="kobo.21.1">These difficulties are aggravated if we consider the substantially dynamic nature of the concrete reality in which the detection systems are employed (due to the fact that, in a constantly evolving reality, there are always new </span><strong><span class="koboSpan" id="kobo.22.1">anomalous</span></strong><span class="koboSpan" id="kobo.23.1"> cases that have not been previously encountered).</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Incident response and threat mitigation</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Obviously, the implementation of an anomaly detection system assumes that the alerts generated are properly managed.</span></p>
<p><span class="koboSpan" id="kobo.3.1">With incident response, we indicate the set of activities carried out after alerts are delivered.</span></p>
<p><span class="koboSpan" id="kobo.4.1">These activities are usually managed by human operators who are specialized in the various sectors of competence, engaged in investigating and deepening the evidence associated with alerts.</span></p>
<p><span class="koboSpan" id="kobo.5.1">Given the high level of specialization required to carry out such investigations (just think, for example, of digital forensics activities that originate from the reporting of a data breach), the adoption of automated procedures are usually limited to supporting human operators in their specialized activities, rather than replacing them.</span></p>
<p><strong><span class="koboSpan" id="kobo.6.1">Threat mitigation</span></strong><span class="koboSpan" id="kobo.7.1">, </span><span><span class="koboSpan" id="kobo.8.1">instead, </span></span><span class="koboSpan" id="kobo.9.1">involves the prevention of future attacks or intrusions, or the countering of ongoing attacks.</span></p>
<p><span class="koboSpan" id="kobo.10.1">Although algorithmic procedures that automatically block suspicious activities can be successfully implemented in threat mitigation, they can also be exploited by attackers (for example, think of an attacker who wants to damage the reputation of an e-commerce website by causing the automated block of most parts of customers' IP addresses by simulating a </span><strong><span class="koboSpan" id="kobo.11.1">Distributed Denial of Service</span></strong><span class="koboSpan" id="kobo.12.1"> (</span><strong><span class="koboSpan" id="kobo.13.1">DDoS</span></strong><span class="koboSpan" id="kobo.14.1">) attack).</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Empowering detection systems with human feedback</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">From what we have seen so far, the best use of anomaly detection systems sees the interaction of automated procedures with the specialized activities carried out by human operators.</span></p>
<p><span class="koboSpan" id="kobo.3.1">Therefore, the use of the anomaly detection systems as a support tool for human specialists allows the mitigation of the costs deriving from false positives, </span><span><span class="koboSpan" id="kobo.4.1">at the same time </span></span><span class="koboSpan" id="kobo.5.1">improving the ability to reduce false negatives by exploiting human feedback (as in the aforementioned case of improving the reliability of the classification sample labels used to train supervised algorithms).</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.6.1">However, this human-machine synergy presupposes that algorithms are less opaque and more easily interpreted by humans, therefore increasing the transparency of the reasons that led the algorithm to report a specific anomaly (transparency that must be reserved only to insiders, to prevent attackers from exploiting it to their advantage).</span></p>
<p><span class="koboSpan" id="kobo.7.1">In the same way, an anomaly detection system must be easily maintainable, both in the sense of quickly adapting the algorithms to the inevitable changes of context, and in the sense of easily correcting the algorithms' classification errors reported by operator feedback.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Testing for data and model quality</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">So far, we have seen the technical difficulties that we face in the implementation of our detection systems.</span></p>
<p><span class="koboSpan" id="kobo.3.1">More generally, every time we decide to use algorithms within our cybersecurity solutions, we must take into account the aspects of data quality and model quality, in order to ensure not only the accuracy of predictions, but also their reliability.</span></p>
<p><span class="koboSpan" id="kobo.4.1">Let's continue by analyzing the aspects concerning the data quality process.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Assessing data quality</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">As we have repeated several times throughout the book, and particularly in </span><a href="55892989-888d-4407-ac91-7f939c0802bd.xhtml"><span class="koboSpan" id="kobo.3.1">Chapter 9</span></a><span class="koboSpan" id="kobo.4.1">, </span><em><span class="koboSpan" id="kobo.5.1">Evaluating Algorithms</span></em><span class="koboSpan" id="kobo.6.1">,</span><em><span class="koboSpan" id="kobo.7.1"> </span></em><span class="koboSpan" id="kobo.8.1">the choice of algorithm is undoubtedly important, but the selection of data is even more crucial for the achievement of our objectives.</span></p>
<p><span class="koboSpan" id="kobo.9.1">In many cases, it is even preferable to use more data to feed a non-optimal algorithm, rather than trying to optimize the algorithm.</span></p>
<p><span class="koboSpan" id="kobo.10.1">It is therefore particularly important to make sure that the data used is reliable, as well as available in sufficient quantities to train our algorithms.</span></p>
<p><span class="koboSpan" id="kobo.11.1">One of the tasks performed by the data quality process is therefore the verification of the presence of bias within the sample datasets (not to be confused with the bias concerning the algorithms, which is the cause of underfitting, as we saw in the previous chapter).</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Biased datasets</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The presence of bias within the sample datasets is often the result of the selection methods used to gather the data (known as </span><strong><span class="koboSpan" id="kobo.3.1">selection bias</span></strong><span class="koboSpan" id="kobo.4.1">). </span><span class="koboSpan" id="kobo.4.2">For example, in the training of malware detectors, we </span><span><span class="koboSpan" id="kobo.5.1">often </span></span><span class="koboSpan" id="kobo.6.1">use samples obtained from honeypots within the corporate security perimeter.</span></p>
<p><span class="koboSpan" id="kobo.7.1">Honeypots are effective tools for gathering security information: they unveil the specific risks of tailored attacks to which the organization is exposed. However, honeypots are unlikely to ensure that the samples collected resemble all the different types of malware threats in the wild. </span><span class="koboSpan" id="kobo.7.2">Therefore, the use of honeypots may introduce selection bias into training datasets.</span></p>
<p><span class="koboSpan" id="kobo.8.1">Similar considerations can be made regarding the training of anti-spam classifiers: the collection of samples will hardly contain all the possible cases of threats that make use of emails as the attack vector, as such appropriately representing the complete population of possible attacks.</span></p>
<p><span class="koboSpan" id="kobo.9.1">In this case, we may face an </span><strong><span class="koboSpan" id="kobo.10.1">exclusion bias</span></strong><span class="koboSpan" id="kobo.11.1">, meaning that some representative samples of the population are excluded from the datasets.</span></p>
<p><span class="koboSpan" id="kobo.12.1">One of the most effective strategies to prevent the presence of bias within the datasets is to limit the scope of our algorithmic detectors, specifically identifying the threats that we intend to manage.</span></p>
<p><span class="koboSpan" id="kobo.13.1">In this way, even the data samples we collect to train the algorithms will be selected based on the chosen use cases.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Unbalanced and mislabeled datasets</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Similarly, as we saw in </span><a href="98ce7db1-f53d-47ca-b6ca-ec0e5f882566.xhtml"><span class="koboSpan" id="kobo.3.1">Chapter 7</span></a><span class="koboSpan" id="kobo.4.1">, </span><em><span class="koboSpan" id="kobo.5.1">Frauds Prevention with Cloud AI Solutions</span></em><span class="koboSpan" id="kobo.6.1">, when we analyze data on credit card fraud, we may face strongly unbalanced data distributions, or incorrectly classified sample datasets, which reduce the effectiveness of supervised algorithms.</span></p>
<p><span class="koboSpan" id="kobo.7.1">We have seen how it is possible to tackle and solve the problems related to mislabeled datasets by exploiting the feedback obtained from human operators (even if this solution is often burdensome in terms of both time and specialized resources employed).</span></p>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.8.1">In the case of unbalanced datasets (such as credit card transactions, where the samples belonging to the class of legitimate transactions largely exceed the samples of fraud transactions), we have seen how useful it is to resort to sampling techniques such as the </span><strong><span class="koboSpan" id="kobo.9.1">Synthetic Minority Over-sampling Technique</span></strong><span class="koboSpan" id="kobo.10.1"> (</span><strong><span class="koboSpan" id="kobo.11.1">SMOTE</span></strong><span class="koboSpan" id="kobo.12.1">).</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Missing values in datasets</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">One of the most frequent problems that needs to be addressed during the data quality process has to do with missing values ​​within datasets.</span></p>
<p><span class="koboSpan" id="kobo.3.1">This problem occurs, for example, in cases where not all the values ​​of the columns are present, giving rise to null fields. </span><span class="koboSpan" id="kobo.3.2">The presence of null fields not only represents a problem for relational databases, but also for many ML algorithms. </span><span class="koboSpan" id="kobo.3.3">It is therefore necessary to eliminate these null fields to allow the algorithms to work correctly, without incurring classification errors.</span></p>
<p><span class="koboSpan" id="kobo.4.1">Some of the most common remedies to the problem of missing values ​​include the practice of the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.5.1">Excluding</span><span><span class="koboSpan" id="kobo.6.1"> the lines that have null fields</span></span><span class="koboSpan" id="kobo.7.1"> from the dataset</span></li>
<li><span class="koboSpan" id="kobo.8.1">Excluding </span><span><span class="koboSpan" id="kobo.9.1">the columns that present null fields </span></span><span class="koboSpan" id="kobo.10.1">from the dataset</span></li>
<li><span class="koboSpan" id="kobo.11.1">Replacing the null fields with default values ​​(for example, 0) or recalculating the values on the basis of other values ​​in the dataset</span></li>
</ul>
<p><span class="koboSpan" id="kobo.12.1">Each of these remedies has disadvantages: in general, the exclusion of rows and columns that have null fields can result in the loss of important information contained in other non-null fields of the row or column we excluded.</span></p>
<p><span class="koboSpan" id="kobo.13.1">Similarly, the insertion of predefined or recalculated data can introduce bias within the dataset, especially in cases where the missing values ​​are numerous.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Missing values example</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">To solve the problem of missing values in datasets, the </span><kbd><span class="koboSpan" id="kobo.3.1">scikit-learn</span></kbd><span class="koboSpan" id="kobo.4.1"> library provides specialized classes for the purpose.</span></p>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.5.1">The strategy followed by </span><kbd><span class="koboSpan" id="kobo.6.1">scikit-learn</span></kbd><span class="koboSpan" id="kobo.7.1"> consists of the imputation of the missing values by inferring new values from the known part of the dataset.</span></p>
<p><span class="koboSpan" id="kobo.8.1">The value imputation can be of two types:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">Univariate imputation</span></li>
<li><span class="koboSpan" id="kobo.10.1">Multivariate imputation</span></li>
</ul>
<p><span class="koboSpan" id="kobo.11.1">In the case of univariate imputation, the </span><kbd><span class="koboSpan" id="kobo.12.1">SimpleImputer</span></kbd><span class="koboSpan" id="kobo.13.1"> class is used. </span><span class="koboSpan" id="kobo.13.2">This allows you to replace null values with a constant value, or with a positional statistics metric, such as mean, median, or mode, which is calculated on the remaining values of the column that contains the null value.</span></p>
<p><span class="koboSpan" id="kobo.14.1">In the following example, we see the replacement of null values (encoded as </span><kbd><span class="koboSpan" id="kobo.15.1">np.nan</span></kbd><span class="koboSpan" id="kobo.16.1">) with the mean value calculated on the values belonging to the same columns in which the null values are found:</span></p>
<pre><span class="koboSpan" id="kobo.17.1">"""</span><br/><span class="koboSpan" id="kobo.18.1">Univariate missing value imputation with SimpleImputer class </span><br/><span class="koboSpan" id="kobo.19.1">"""</span><br/> <br/><span class="koboSpan" id="kobo.20.1">import numpy as np</span><br/><span class="koboSpan" id="kobo.21.1">from sklearn.impute import SimpleImputer</span><br/><br/><span class="koboSpan" id="kobo.22.1">simple_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')</span><br/><br/><span class="koboSpan" id="kobo.23.1">simple_imputer.fit([[3, 2], [np.nan, 4], [np.nan, 3], [7, 9]])</span><br/><br/><span class="koboSpan" id="kobo.24.1">X_test = [[np.nan, 3], [5, np.nan], [6, 8], [np.nan, 4],]</span><br/><br/><span class="koboSpan" id="kobo.25.1">simple_imputer.transform(X_test)</span><br/><br/></pre>
<p><span class="koboSpan" id="kobo.26.1">In the case of multivariate imputation, the missing values are estimated using a round robin strategy that takes into consideration the remaining features.</span></p>
<p><span class="koboSpan" id="kobo.27.1">With the round robin strategy (iteratively performed for each feature), a feature column is treated as input. </span><span class="koboSpan" id="kobo.27.2">The missing value is then estimated by applying a regression function.</span></p>
<p><span class="koboSpan" id="kobo.28.1">In the following example, we use the </span><kbd><span class="koboSpan" id="kobo.29.1">IterativeImputer</span></kbd><span class="koboSpan" id="kobo.30.1"> class available in the </span><kbd><span class="koboSpan" id="kobo.31.1">scikit-learn</span></kbd><span class="koboSpan" id="kobo.32.1"> package, </span><kbd><span class="koboSpan" id="kobo.33.1">sklearn.impute</span></kbd><span class="koboSpan" id="kobo.34.1">, to perform the multivariate imputation of the missing values:</span></p>
<pre><span class="koboSpan" id="kobo.35.1">"""</span><br/><span class="koboSpan" id="kobo.36.1">Multivariate missing value imputation with IterativeImputer class</span><br/><span class="koboSpan" id="kobo.37.1">"""</span><br/> <br/><span class="koboSpan" id="kobo.38.1">import numpy as np</span><br/><span class="koboSpan" id="kobo.39.1">from sklearn.experimental import enable_iterative_imputer</span><br/><span class="koboSpan" id="kobo.40.1">from sklearn.impute import IterativeImputer</span><br/><br/><span class="koboSpan" id="kobo.41.1">iterative_imputer = IterativeImputer(imputation_order='ascending',</span><br/><span class="koboSpan" id="kobo.42.1">initial_strategy='mean',max_iter=15, missing_values=nan, random_state=0, tol=0.001)</span><br/><br/><span class="koboSpan" id="kobo.43.1">iterative_imputer.fit([[3, 2], [np.nan, 4], [np.nan, 3], [7, 9]])</span><br/><br/><span class="koboSpan" id="kobo.44.1">X_test = [[np.nan, 3], [5, np.nan], [6, 8], [np.nan, 4],]</span><br/><br/><span class="koboSpan" id="kobo.45.1">np.round(iterative_imputer.transform(X_test))</span><br/><br/><br/></pre>
<p><span class="koboSpan" id="kobo.46.1">The time has come to take care of the model quality process.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Assessing model quality</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">We have emphasized the importance of data over algorithms, and we have seen which strategies to follow in the data quality process.</span></p>
<p><span class="koboSpan" id="kobo.3.1">Once we are sure that the data is reliable and complete, we must feed it to the algorithms selected for the implementation of our AI solutions, submitting the results obtained to the model quality process.</span></p>
<p><span class="koboSpan" id="kobo.4.1">The model quality process involves all the phases of algorithm deployment.</span></p>
<p><span class="koboSpan" id="kobo.5.1">In fact, it is essential to monitor the performance of our algorithms, in order to constantly perform the fine tuning of the hyperparameters.</span></p>
<p><span class="koboSpan" id="kobo.6.1">By hyperparameters, we mean all the parameters that the algorithm receives from the outside (that is, </span><span><span class="koboSpan" id="kobo.7.1">parameters </span></span><span class="koboSpan" id="kobo.8.1">that are not set or updated in consequence of the learning process), but are decided by the analyst even before starting the training (such as the parameter </span><em><span class="koboSpan" id="kobo.9.1">k</span></em><span class="koboSpan" id="kobo.10.1"> of the k-means clustering algorithm, or the number of perceptrons to be used in multilayer perceptron classifiers).</span></p>
<p><span class="koboSpan" id="kobo.11.1">This is why it is important to constantly monitor the performance of the algorithms, in order to be able to optimize these hyperparameters.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Fine-tuning hyperparameters</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">While fine-tuning algorithm hyperparameters, we must keep in mind that there is no configuration that can be used in all cases; however, we must perform optimization on the basis of different scenarios we face, taking into account the different goals we want to achieve.</span></p>
<p><span class="koboSpan" id="kobo.3.1">The fine tuning of hyperparameters presupposes in-depth knowledge of the algorithm and its characteristics, in addition to the knowledge of the application domain (scenarios and use cases) in which our solution is deployed.</span></p>
<p><span class="koboSpan" id="kobo.4.1">Moreover, fine-tuning must also take into consideration the possible impact caused by changes in input data (as we saw in </span><a href="aaf59353-00b3-4625-8732-63aad02cc8e5.xhtml"><span class="koboSpan" id="kobo.5.1">Chapter 3</span></a><span class="koboSpan" id="kobo.6.1">, </span><em><span class="koboSpan" id="kobo.7.1">Ham or Spam? </span><span class="koboSpan" id="kobo.7.2">Detecting Email Cybersecurity Threats with AI</span></em><span class="koboSpan" id="kobo.8.1">, with regard to phishing detection, the use of decision trees involves a high sensitivity, even to small changes in input data).</span></p>
<p><span class="koboSpan" id="kobo.9.1">In many cases, the analyst can resort to his own experience or decide to follow empirical heuristics in an attempt to optimize hyperparameters.</span></p>
<p><span class="koboSpan" id="kobo.10.1">Also in this case, the </span><kbd><span class="koboSpan" id="kobo.11.1">scikit-learn</span></kbd><span class="koboSpan" id="kobo.12.1"> library comes to our aid by providing us with the </span><kbd><span class="koboSpan" id="kobo.13.1">GridSearchCV</span></kbd><span class="koboSpan" id="kobo.14.1"> class, which helps us to compare the performances of different algorithms by leveraging cross validation.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Model optimization with cross validation</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The following example shows how to use the </span><kbd><span class="koboSpan" id="kobo.3.1">GridSearchCV</span></kbd><span class="koboSpan" id="kobo.4.1"> class, available in the </span><kbd><span class="koboSpan" id="kobo.5.1">sklearn.model_selection</span></kbd><span><span class="koboSpan" id="kobo.6.1"> package,</span></span><span class="koboSpan" id="kobo.7.1"> to perform the hyperparameter optimization of a classifier using cross validation (please refer to the </span><em><span class="koboSpan" id="kobo.8.1">Algorithms Cross Validation</span></em><span class="koboSpan" id="kobo.9.1"> paragraph of </span><a href="55892989-888d-4407-ac91-7f939c0802bd.xhtml"><span class="koboSpan" id="kobo.10.1">Chapter 9</span></a><span class="koboSpan" id="kobo.11.1">, </span><em><span class="koboSpan" id="kobo.12.1">Evaluating Algorithms</span></em><span class="koboSpan" id="kobo.13.1">, for the explanation of cross validation).</span></p>
<p><span class="koboSpan" id="kobo.14.1">We use the digit sample dataset that comes with the </span><kbd><span class="koboSpan" id="kobo.15.1">scikit-learn</span></kbd><span class="koboSpan" id="kobo.16.1"> library.</span></p>
<p><span class="koboSpan" id="kobo.17.1">The dataset is equally divided into training subset and testing subset, using the </span><kbd><span class="koboSpan" id="kobo.18.1">train_test_split()</span></kbd><span class="koboSpan" id="kobo.19.1"> method, which is assigned the </span><kbd><span class="koboSpan" id="kobo.20.1">test_size=0.5</span></kbd><span><span class="koboSpan" id="kobo.21.1"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.22.1">The different performances of the </span><strong><span class="koboSpan" id="kobo.23.1">support vector classifier</span></strong><span class="koboSpan" id="kobo.24.1"> (</span><strong><span class="koboSpan" id="kobo.25.1">SVC</span></strong><span class="koboSpan" id="kobo.26.1">) are then compared—in consequence of fine tuning the precision and recall metrics with different combinations of hyperparameters (defined in the </span><kbd><span class="koboSpan" id="kobo.27.1">tuned_parameters</span></kbd><span class="koboSpan" id="kobo.28.1"> </span><span><span class="koboSpan" id="kobo.29.1">variable</span></span><span class="koboSpan" id="kobo.30.1">)—using the cross validation strategy implemented by the </span><kbd><span class="koboSpan" id="kobo.31.1">GridSearchCV</span></kbd><span class="koboSpan" id="kobo.32.1"> class:</span></p>
<pre><span class="koboSpan" id="kobo.33.1">"""</span><br/><span class="koboSpan" id="kobo.34.1">Cross Validation Model Optimization</span><br/><span class="koboSpan" id="kobo.35.1">"""</span><br/><br/><span class="koboSpan" id="kobo.36.1">from sklearn import datasets</span><br/><span class="koboSpan" id="kobo.37.1">from sklearn.model_selection import train_test_split</span><br/><span class="koboSpan" id="kobo.38.1">from sklearn.model_selection import GridSearchCV</span><br/><span class="koboSpan" id="kobo.39.1">from sklearn.metrics import classification_report</span><br/><span class="koboSpan" id="kobo.40.1">from sklearn.svm import SVC</span><br/><br/><span class="koboSpan" id="kobo.41.1"># Loading the scikit-learn Digits dataset</span><br/><span class="koboSpan" id="kobo.42.1">digit_dataset = datasets.load_digits()</span><br/><br/><span class="koboSpan" id="kobo.43.1">num_images = len(digit_dataset.images)</span><br/><span class="koboSpan" id="kobo.44.1">X_images  = digit_dataset.images.reshape((num_images, -1))</span><br/><span class="koboSpan" id="kobo.45.1">y_targets = digit_dataset.target</span><br/><br/><br/><span class="koboSpan" id="kobo.46.1"># Split the dataset in two equal parts</span><br/><span class="koboSpan" id="kobo.47.1">X_train, X_test, y_train, y_test = train_test_split(</span><br/><span class="koboSpan" id="kobo.48.1">    X_images, y_targets, test_size=0.5, random_state=0)</span><br/><br/><br/><span class="koboSpan" id="kobo.49.1"># Set Cross Validation parameters </span><br/><span class="koboSpan" id="kobo.50.1">cv_params = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],</span><br/><span class="koboSpan" id="kobo.51.1">                     'C': [1, 10, 100, 1000]},</span><br/><span class="koboSpan" id="kobo.52.1">                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]</span><br/><br/><br/><span class="koboSpan" id="kobo.53.1"># Tuning hyper-parameters for precision </span><br/><span class="koboSpan" id="kobo.54.1"># using Support Vector Classifier</span><br/><br/><span class="koboSpan" id="kobo.55.1">precision_clf = GridSearchCV(SVC(), cv_params, cv=5, scoring='precision_micro')</span><br/><br/><span class="koboSpan" id="kobo.56.1">precision_clf.fit(X_train, y_train)</span><br/><br/><span class="koboSpan" id="kobo.57.1">print("Best parameters set found for 'precision' tuning: \n")</span><br/><br/><span class="koboSpan" id="kobo.58.1">print(precision_clf.best_params_)</span><br/><br/><span class="koboSpan" id="kobo.59.1">print("\nDetailed report for 'precision':\n")</span><br/><br/><span class="koboSpan" id="kobo.60.1">y_true, y_pred = y_test, precision_clf.predict(X_test)</span><br/><br/><span class="koboSpan" id="kobo.61.1">print(classification_report(y_true, y_pred))</span><br/><br/><span class="koboSpan" id="kobo.62.1"># Tuning hyper-parameters for recall</span><br/><span class="koboSpan" id="kobo.63.1"># using Support Vector Classifier</span><br/><br/><span class="koboSpan" id="kobo.64.1">recall_clf = GridSearchCV(SVC(), cv_params, cv=5, scoring='recall_micro')</span><br/><br/><span class="koboSpan" id="kobo.65.1">recall_clf.fit(X_train, y_train)</span><br/><br/><span class="koboSpan" id="kobo.66.1">print("Best parameters set found for 'recall' tuning:\n")</span><br/><br/><span class="koboSpan" id="kobo.67.1">print(recall_clf.best_params_)</span><br/><br/><span class="koboSpan" id="kobo.68.1">print("\nDetailed report for 'recall':\n")</span><br/><br/><span class="koboSpan" id="kobo.69.1">y_true, y_pred = y_test, recall_clf.predict(X_test)</span><br/><br/><span class="koboSpan" id="kobo.70.1">print(classification_report(y_true, y_pred))</span><br/><br/></pre>
<p><span class="koboSpan" id="kobo.71.1">The preceding script generates the following output:</span></p>
<pre> <br/><span class="koboSpan" id="kobo.72.1"> Best parameters set found for 'precision' tuning:</span><br/> <br/><span class="koboSpan" id="kobo.73.1"> {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</span><br/> <br/><span class="koboSpan" id="kobo.74.1"> Detailed classification report for 'precision':</span><br/>  <br/><span class="koboSpan" id="kobo.75.1">               precision    recall  f1-score   support</span><br/> <br/><span class="koboSpan" id="kobo.76.1">            0       1.00      1.00      1.00        89</span><br/><span class="koboSpan" id="kobo.77.1">            1       0.97      1.00      0.98        90</span><br/><span class="koboSpan" id="kobo.78.1">            2       0.99      0.98     0.98        92</span><br/><span class="koboSpan" id="kobo.79.1">            3       1.00      0.99      0.99        93</span><br/><span class="koboSpan" id="kobo.80.1">            4       1.00      1.00      1.00        76</span><br/><span class="koboSpan" id="kobo.81.1">            5       0.99      0.98      0.99       108</span><br/><span class="koboSpan" id="kobo.82.1">            6       0.99      1.00      0.99        89</span><br/><span class="koboSpan" id="kobo.83.1">            7       0.99      1.00      0.99        78</span><br/><span class="koboSpan" id="kobo.84.1">            8       1.00      0.98      0.99        92</span><br/><span class="koboSpan" id="kobo.85.1">            9       0.99      0.99      0.99        92</span><br/> <br/><span class="koboSpan" id="kobo.86.1">     accuracy                           0.99       899</span><br/><span class="koboSpan" id="kobo.87.1">    macro avg       0.99      0.99      0.99       899</span><br/><span class="koboSpan" id="kobo.88.1"> weighted avg       0.99      0.99      0.99       899</span><br/> <br/> <br/><span class="koboSpan" id="kobo.89.1"> Best parameters set found for 'recall' tuning:</span><br/> <br/><span class="koboSpan" id="kobo.90.1"> {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</span><br/> <br/><span class="koboSpan" id="kobo.91.1"> Detailed classification report for 'recall':</span><br/>  <br/><span class="koboSpan" id="kobo.92.1">               precision    recall  f1-score   support</span><br/> <br/><span class="koboSpan" id="kobo.93.1">            0       1.00      1.00      1.00        89</span><br/><span class="koboSpan" id="kobo.94.1">            1       0.97      1.00      0.98        90</span><br/><span class="koboSpan" id="kobo.95.1">            2       0.99      0.98      0.98        92</span><br/><span class="koboSpan" id="kobo.96.1">            3       1.00      0.99      0.99        93</span><br/><span class="koboSpan" id="kobo.97.1">            4       1.00      1.00      1.00        76</span><br/><span class="koboSpan" id="kobo.98.1">            5       0.99      0.98      0.99       108</span><br/><span class="koboSpan" id="kobo.99.1">            6       0.99      1.00      0.99        89</span><br/><span class="koboSpan" id="kobo.100.1">            7       0.99      1.00      0.99        78</span><br/><span class="koboSpan" id="kobo.101.1">            8       1.00      0.98      0.99        92</span><br/><span class="koboSpan" id="kobo.102.1">            9       0.99      0.99      0.99        92</span><br/> <br/><span class="koboSpan" id="kobo.103.1">     accuracy                           0.99       899</span><br/><span class="koboSpan" id="kobo.104.1">    macro avg       0.99      0.99      0.99       899</span><br/><span class="koboSpan" id="kobo.105.1"> weighted avg       0.99      0.99      0.99       899</span></pre>
<p><span class="koboSpan" id="kobo.106.1">Our assessment continues (and concludes) with our AI-empowered cybersecurity solutions.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Ensuring security and reliability</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Managing the security and reliability of our solutions is a critical aspect, which can determine its success or failure, regardless of the quality of the models implemented.</span></p>
<p><span class="koboSpan" id="kobo.3.1">Therefore, ensuring security and reliability of AI-empowered solutions translates into the following:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.4.1">Ensuring performance and scalability</span></li>
<li><span class="koboSpan" id="kobo.5.1">Ensuring resilience and availability</span></li>
<li><span class="koboSpan" id="kobo.6.1">Ensuring confidentiality and privacy</span></li>
</ul>
<p><span class="koboSpan" id="kobo.7.1">We begin by analyzing how the performance and scalability requisites affect algorithms' reliability.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Ensuring performance and scalability</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">Without a doubt, the performances of AI-based cybersecurity solutions are crucial to guarantee their success, especially if the objective to be achieved is to detect intrusion attempts or se</span><span><span class="koboSpan" id="kobo.3.1">curity breaches as quickly as possible. </span><span class="koboSpan" id="kobo.3.2">This translates</span></span><span><span class="koboSpan" id="kobo.4.1"> into ensuring the low latency of the responses. </span><span class="koboSpan" id="kobo.4.2">However, the requirement of low latency contrasts with the very nature of the algorithms, which usually entail high computational loads. </span><span class="koboSpan" id="kobo.4.3">Furthermore, it is often difficult to guarantee the scalability of AI solutions when the amount of data to be processed grows explosively (as is typical in modern big data scenarios).</span></span></p>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.5.1">In order to guarantee an adequate level of performance, it is therefore necessary to act on the various components of the solution, starting with the choice of the best performing algorithms, even at the expense of precision. </span><span class="koboSpan" id="kobo.5.2">At the same time, reducing the dataset dimensionality (that is, the number and type of features used) can dramatically improve the performance of our algorithms.</span></p>
<p><span class="koboSpan" id="kobo.6.1">In </span><a href="f467340a-244d-4714-8a39-68b230db2404.xhtml"><span class="koboSpan" id="kobo.7.1">Chapter 6</span></a><span class="koboSpan" id="kobo.8.1">, </span><em><span class="koboSpan" id="kobo.9.1">Securing User Authentication</span></em><span class="koboSpan" id="kobo.10.1">, </span><span><span class="koboSpan" id="kobo.11.1">we saw </span></span><span class="koboSpan" id="kobo.12.1">how it is possible to reduce the dimensionality of heavy datasets (such as those of images), even </span><span><span class="koboSpan" id="kobo.13.1">those</span></span><span><span class="koboSpan" id="kobo.14.1"> </span></span><span><span class="koboSpan" id="kobo.15.1">using simple technical expedients, such as the</span></span> <strong><span class="koboSpan" id="kobo.16.1">Principal components analysis</span></strong> <span><span class="koboSpan" id="kobo.17.1">(</span></span><strong><span class="koboSpan" id="kobo.18.1">PCA</span></strong><span><span class="koboSpan" id="kobo.19.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.20.1">Also, the scalability of the algorithms is an essential element to improve performances, especially if we intend to deploy our solutions into the cloud.</span></p>
<p><span class="koboSpan" id="kobo.21.1">However, not all algorithms have been designed to guarantee scalability, while some algorithms (such as SVMs) are by their nature less efficient, as they are particularly slow in the training phase and require high hardware resources (in terms of memory, computational load, and other aspects).</span></p>
<p><span class="koboSpan" id="kobo.22.1">It is therefore necessary to carefully evaluate the advantages and disadvantages of each algorithm (as we did in the various chapters of the book) before making our decisions.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Ensuring resilience and availability</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">When we talk about security, we do not </span><span><span class="koboSpan" id="kobo.3.1">only </span></span><span class="koboSpan" id="kobo.4.1">mean </span><span><span class="koboSpan" id="kobo.5.1">t</span></span><span><span class="koboSpan" id="kobo.6.1">he protection from attacks carried out through the use of traditional measures, such as the definition of the network security perimeter, or the use of antivirus software.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">The requirement of security in complex contexts (such as those in which cloud computing is used for both the development and the deployment of solutions) translates into assuring the requirements of resilience and high availability.</span></p>
<p><span class="koboSpan" id="kobo.8.1">The same traditional security measures, starting with antiviruses, up to the </span><strong><span class="koboSpan" id="kobo.9.1">intrusion detection system</span></strong><span class="koboSpan" id="kobo.10.1"> (</span><strong><span class="koboSpan" id="kobo.11.1">IDS</span></strong><span class="koboSpan" id="kobo.12.1">) depend more and more on AI cloud-based solutions to achieve their goals (just think, for example, of the malware detection performed by an antivirus software that exploits cloud-based neural networks to carry out behavioral analysis of a suspect executable).</span></p>
<p><span class="koboSpan" id="kobo.13.1">By now, AI permeates all the value-added services offered to clients by corporates that use the internet and the web in their business.</span></p>
<p><span class="koboSpan" id="kobo.14.1">This is even more true for the cybersecurity sector: for example, consider biometric procedures that all adopt some form of AI for user recognition.</span></p>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.15.1">It is therefore essential to continuously monitor the health status of the systems on which the AI-based cybersecurity solutions are deployed.</span></p>
<p><span class="koboSpan" id="kobo.16.1">Similarly, guaranteeing the integrity and confidentiality of the data that feeds the algorithms is of fundamental importance to assure not only their security, but also their reliability.</span></p>
<p><span class="koboSpan" id="kobo.17.1">An attacker who managed to access the datasets used by the algorithms, would not only be able to emulate the behavior of the underlying predictive models, but could even poison the data, therefore modifying the predictions of the algorithms to their liking.</span></p>
<p><span class="koboSpan" id="kobo.18.1">We will deal with this topic in the next section.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Ensuring confidentiality and privacy</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">The centrality of data in the correct functioning of data-driven solutions is attested by the principle known as </span><strong><span class="koboSpan" id="kobo.3.1">garbage in</span></strong><span class="koboSpan" id="kobo.4.1">, </span><strong><span class="koboSpan" id="kobo.5.1">garbage out</span></strong><span class="koboSpan" id="kobo.6.1">. Protecting the integrity of data is equally important in the AI, since—unlike what is commonly thought—algorithms are not </span><strong><span class="koboSpan" id="kobo.7.1">objective</span></strong><span class="koboSpan" id="kobo.8.1">, but can formulate radically different predictions based on the data supplied to them in the training phase.</span></p>
<p><span class="koboSpan" id="kobo.9.1">It is therefore possible to condition the results of predictive models simply by altering the data on which the algorithms work.</span></p>
<p><span class="koboSpan" id="kobo.10.1">This aspect is particularly delicate, as it transversally raises the need to guarantee the security and integrity of the data, together with the explicability and repeatability of the results obtained by the algorithms, and can have important negative repercussions, especially in the context of the privacy law compliance.</span></p>
<p><span class="koboSpan" id="kobo.11.1">As is known, the pervasive diffusion of data-driven technologies (such as AI and big data analytics) that make extensive use of users' and consumers' personal data, poses serious problems, not only of data security, but also of protection of confidentiality.</span></p>
<p><span class="koboSpan" id="kobo.12.1">In particular, by aggregating a sufficient amount of personal data, it is possible to reconstruct the profile of each individual with a high degree of statistical verisimilitude.</span></p>
<p><span class="koboSpan" id="kobo.13.1">When we add the fact that most business decisions are taken on the basis of an automated analysis of individual profiles to this, we realize the risks that can arise from the incorrect profiling of individuals.</span></p>
<p class="mce-root"/>
<p><span class="koboSpan" id="kobo.14.1">Specifically, if a financial or insurance company denies an individual the signing of a financial contract on the basis of incorrect profiling, the individual is negatively discriminated because of the inadequate treatment of their personal data.</span></p>
<p><span class="koboSpan" id="kobo.15.1">Similarly, if a fraud detection algorithm reports a financial transaction as suspect by assessing the creditworthiness of the person who executed the transaction on the basis of incorrect profiling, in addition to reputational damage, there is a risk of incurring the sanctions envisaged for the illicit treatment of personal data.</span></p>
<p><span class="koboSpan" id="kobo.16.1">Even more serious consequences can be determined if the data being processed belongs to special categories (for example, biometric data </span><span><span class="koboSpan" id="kobo.17.1">such as</span></span><span class="koboSpan" id="kobo.18.1"> iris, voice, fingerprints, face, </span><span><span class="koboSpan" id="kobo.19.1">and</span></span><span class="koboSpan" id="kobo.20.1"> DNA) that are widely used in the cybersecurity field, for all the purposes of authentication, authorization, and detection.</span></p>
<p><span class="koboSpan" id="kobo.21.1">It therefore appears evident that guaranteeing the confidentiality and integrity of the data is of importance, not only in terms of security, but also in terms of legal liabilities deriving from failing to comply with national laws protecting privacy.</span></p>
<p><span class="koboSpan" id="kobo.22.1">To this end, it is appropriate to assure the adoption of data encryption in AI-based solutions, making sure to apply encryption to all the different states that the data can assume (data </span><strong><span class="koboSpan" id="kobo.23.1">in motion</span></strong><span class="koboSpan" id="kobo.24.1">, </span><strong><span class="koboSpan" id="kobo.25.1">in use</span></strong><span class="koboSpan" id="kobo.26.1">, and </span><strong><span class="koboSpan" id="kobo.27.1">at rest</span></strong><span class="koboSpan" id="kobo.28.1">).</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title"><span class="koboSpan" id="kobo.1.1">Summary</span></h1>
                </header>
            
            <article>
                
<p><span class="koboSpan" id="kobo.2.1">In this chapter, we dealt with the assessment of our AI-based cybersecurity solutions, analyzing the aspects of security, data, and model quality, in order to guarantee the reliability and high availability of solutions deployed in production environments, without neglecting the requirements of privacy and confidentiality of the sensitive data used by algorithms.</span></p>


            </article>

            
        </section>
    </body></html>