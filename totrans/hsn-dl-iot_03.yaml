- en: Deep Learning Architectures for IoT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 物联网的深度学习架构
- en: In the era of the **Internet of Things** (**IoT**), an enormous amount of sensory
    data for a wide range of fields and applications is being generated and collected
    from numerous sensing devices. Applying analytics over such data streams to discover
    new information, predict future insights, and make controlled decisions, is a
    challenging task, which makes IoT a worthy paradigm for business intelligence
    and quality-of-life improving technology. However, analytics on IoT—enabled devices
    requires a platform consisting of **machine learning** (**ML**) and **deep learning**
    (**DL**) frameworks, a software stack, and hardware (for example, a **Graphical
    Processing Unit** (**GPU**) and **Tensor Processing Unit** (**TPU**)).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在**物联网**（**IoT**）时代，来自众多传感设备的大量感知数据正被生成和收集，这些数据涵盖了广泛的领域和应用。对这些数据流进行分析，发现新信息、预测未来洞察并做出控制决策，是一项具有挑战性的任务，这使得物联网成为商业智能和提高生活质量技术的一个有价值的范式。然而，在物联网启用的设备上进行分析需要一个平台，该平台包括**机器学习**（**ML**）和**深度学习**（**DL**）框架、软件堆栈和硬件（例如，**图形处理单元**（**GPU**）和**张量处理单元**（**TPU**））。
- en: 'In this chapter, we will discuss some basic concepts of DL architectures and
    platforms, which will be used in all subsequent chapters. We will start with a
    brief introduction to ML. Then, we will move onto DL, which is a branch of ML
    based on a set of algorithms that attempts to model high-level abstractions in
    data. We will briefly discuss some of the most well-known and widely used neural
    network architectures. Then, we will look at various features of DL frameworks
    and libraries that can be used for developing DL applications on IoT-enabled devices.
    Briefly, the following topics will be covered:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论一些深度学习（DL）架构和平台的基本概念，这些概念将在后续章节中使用。我们将从简要介绍机器学习（ML）开始。然后，我们将转向深度学习，深度学习是机器学习的一个分支，它基于一组算法，旨在对数据中的高级抽象进行建模。我们将简要讨论一些最著名且广泛使用的神经网络架构。接着，我们将探讨用于在物联网（IoT）设备上开发深度学习应用的各种深度学习框架和库的特性。简而言之，以下主题将被涵盖：
- en: A soft introduction to ML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的软介绍
- en: Artificial neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: Deep neural network architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络架构
- en: DL frameworks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习框架
- en: A soft introduction to ML
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的软介绍
- en: ML approaches are based on a set of statistical and mathematical algorithms
    carrying out tasks such as classification, regression analysis, concept learning,
    predictive modeling, clustering, and mining of useful patterns. Using ML, we aim
    to improve the whole learning process automatically so that we may not need complete
    human interactions, or so that we can at least reduce the level of such interactions
    as much as possible.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法基于一组统计和数学算法，执行分类、回归分析、概念学习、预测建模、聚类和有用模式挖掘等任务。通过使用机器学习，我们旨在自动改进整个学习过程，从而不再需要完全依赖人工干预，或者至少能够尽可能减少这种干预。
- en: Working principle of a learning algorithm
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习算法的工作原理
- en: 'Tom M. Mitchell explained what learning really means from a computer science
    perspective:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Tom M. Mitchell 从计算机科学的角度解释了学习的真正含义：
- en: '"A computer program is said to learn from experience E with respect to some
    class of tasks T and performance measure P, if its performance at tasks in T,
    as measured by P, improves with experience E."'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: “一个计算机程序如果在某类任务T和性能衡量P下，随着经验E的积累，其在任务T上的表现（由P衡量）得到改进，则该程序被认为从经验E中学习。”
- en: 'Based on this definition, we can conclude that a computer program or machine
    can do the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这一定义，我们可以得出结论，一个计算机程序或机器可以做到以下几点：
- en: Learn from data and histories
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据和历史中学习
- en: Improve with experience
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随经验改进
- en: Iteratively enhance a model that can be used to predict outcomes of questions
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代地增强一个可用于预测问题结果的模型
- en: 'Since the preceding points are at the core of predictive analytics, almost
    every ML algorithm we use can be treated as an optimization problem. This is about
    finding parameters that minimize an objective function; for example, a weighted
    sum of two terms such as a cost function and regularization. Typically, an objective
    function has two components:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于前述要点是预测分析的核心，几乎我们使用的每个机器学习算法都可以视为一个优化问题。这涉及到寻找最小化目标函数的参数；例如，两个项的加权和，如代价函数和正则化。通常，目标函数有两个组成部分：
- en: A regularizer that controls the complexity of the model
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制模型复杂度的正则化器
- en: The loss that measures the error of the model on the training data
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 衡量模型在训练数据上误差的损失函数
- en: On the other hand, the regularization parameter defines the trade-off between
    minimizing the training error and the model's complexity in an effort to avoid
    overfitting problems. Now, if both of these components are convex, then their
    sum is also convex. So, when using an ML algorithm, the goal is to obtain the
    best hyperparameters of a function that return the minimum error when making predictions.
    Therefore, by using a convex optimization technique, we can minimize the function
    until it converges toward the minimum error.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，正则化参数定义了在最小化训练误差和模型复杂度之间的权衡，以避免过拟合问题。如果这两个组件都是凸的，那么它们的和也是凸的。因此，在使用机器学习算法时，目标是获得最佳超参数，使得在进行预测时返回最小误差。因此，通过使用凸优化技术，我们可以最小化该函数，直到它收敛到最小误差。
- en: Given that a problem is convex, it is usually easier to analyze the asymptotic
    behavior of the algorithm, which shows how fast it converges as the model observes
    more and more training data. The task of ML is to train a model so that it can
    recognize complex patterns from the given input data and can make decisions in
    an automated way. Thus, making predictions is all about testing the model against
    new (that is, unobserved) data and evaluating the performance of the model itself.
    However, in the process as a whole, and for making the predictive model a successful
    one, data acts as the first-class citizen in all ML tasks. In reality, the data
    that we feed to our ML systems must be made up of mathematical objects, such as
    vectors, so that they can consume such data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个问题是凸的，通常更容易分析算法的渐进行为，这表明随着模型观察到越来越多的训练数据，它的收敛速度如何。机器学习的任务是训练一个模型，使其能够从给定的输入数据中识别复杂的模式，并以自动化的方式做出决策。因此，进行预测的关键是将模型应用于新的（即未观察到的）数据，并评估模型本身的性能。然而，在整个过程中，为了使预测模型成为成功的，数据在所有机器学习任务中都扮演着第一类公民的角色。实际上，我们馈送给机器学习系统的数据必须由数学对象组成，如向量，以便它们可以处理这些数据。
- en: Depending on the available data and feature types, the performance of your predictive
    model can vacillate dramatically. Therefore, selecting the right features is one
    of the most important steps before the model evaluation takes place. This is called
    **feature engineering**, where the domain knowledge pertaining to the data is
    used to create only selective or useful features that help prepare the feature
    vectors to be used so that an ML algorithm works.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 根据可用数据和特征类型，预测模型的性能可能会发生剧烈波动。因此，选择正确的特征是模型评估前最重要的步骤之一。这被称为**特征工程**，其中使用与数据相关的领域知识来创建仅对模型有用的选择性特征，以帮助准备特征向量供机器学习算法使用。
- en: For example, comparing hotels is quite difficult unless we already have a personal
    experience of staying in multiple hotels. However, with the help of an ML model,
    which is already trained with quality features out of thousands of reviews and
    features (for example, how many stars does a hotel have, the size of the room,
    the location, and room service, and so on), it is pretty feasible now. We'll see
    several examples throughout the chapters. However, before developing such an ML
    model, knowing a number of ML concepts is also important.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，比较酒店是相当困难的，除非我们已经有多次住酒店的个人经验。然而，在一个已经通过成千上万的评论和特征（例如酒店的星级、房间大小、位置、客房服务等）训练好的机器学习模型的帮助下，这变得相当可行。我们将在各章中看到几个例子。然而，在开发这样一个机器学习模型之前，了解一些机器学习概念也是很重要的。
- en: General ML rule of thumb
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通用机器学习经验法则
- en: 'The general ML rule of thumb is that the more data there is, the better the
    predictive model. However, having more features often creates a mess, to the extent
    that the performance degrades drastically, especially if the dataset is multidimensional.
    The entire learning process requires input datasets that can be split into three
    types (or are already provided as such):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通用的机器学习经验法则是，数据越多，预测模型越好。然而，拥有更多特征往往会制造混乱，甚至会严重降低性能，特别是在数据集是多维的情况下。整个学习过程需要将输入数据集拆分为三种类型（或者已经提供为这种类型）：
- en: A **training set** is the knowledge base coming from historical or live data
    that is used to fit the parameters of the ML algorithm. During the training phase,
    the ML model utilizes the training set to find optimal weights of the network
    and reach the objective function by minimizing the training error. Here, the backpropagation
    rule, or an optimization algorithm, is used to train the model, but all the hyperparameters
    are needed to be set before the learning process starts.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**是来自历史或实时数据的知识库，用于拟合机器学习算法的参数。在训练阶段，机器学习模型利用训练集找到网络的最优权重，并通过最小化训练误差来达到目标函数。在这里，反向传播规则或优化算法被用来训练模型，但所有超参数必须在学习过程开始之前设置好。'
- en: A **validation set** is a set of examples used to tune the parameters of an
    ML model. It ensures that the model is trained well and generalizes toward avoiding
    overfitting. Some ML practitioners refer to it as a development set, or dev set
    as well.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证集**是一组用于调整机器学习模型参数的示例。它确保模型训练得当，并且能够避免过拟合。一些机器学习实践者也将其称为开发集（dev集）。'
- en: A **test set** is used for evaluating the performance of the trained model on
    unseen data. This step is also referred to as **model inferencing**. After assessing
    the final model on the test set (that is, when we're fully satisfied with the
    model's performance), we do not have to tune the model any further, but the trained
    model can be deployed in a production-ready environment.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**用于评估训练好的模型在未见数据上的表现。这个步骤也被称为**模型推理**。在测试集上评估最终模型之后（即，当我们完全满意模型的表现时），我们不再需要调整模型，训练好的模型可以部署到生产环境中。'
- en: A common practice is splitting the input data (after the necessary preprocessing
    and feature engineering) into 60% for training, 10% for validation, and 20% for
    testing, but it really depends on use cases. Sometimes, we also need to perform
    upsampling or downsampling on the data, based on the availability and quality
    of the datasets. This rule of thumb of learning on different types of training
    sets can differ across ML tasks, as we will cover in the next section. However,
    before that, let's take a quick look at a few common phenomena in ML.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的做法是将输入数据（经过必要的预处理和特征工程后）分为60%用于训练，10%用于验证，20%用于测试，但这实际上取决于具体的使用场景。有时，我们还需要根据数据集的可用性和质量对数据进行上采样或下采样。这种关于不同类型训练集的经验法则在不同的机器学习任务中可能会有所不同，我们将在下一节讨论这一点。然而，在此之前，让我们快速回顾一下机器学习中的一些常见现象。
- en: General issues in ML models
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型中的常见问题
- en: 'When we use this input data for training, validation, and testing, usually,
    the learning algorithms cannot learn 100% accurately, which involves training,
    validation, and test error (or loss). There are two types of errors that you may
    encounter in an ML model:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用这些输入数据进行训练、验证和测试时，通常学习算法无法做到100%准确，这涉及训练、验证和测试误差（或损失）。在机器学习模型中，你可能会遇到两种类型的误差：
- en: Irreducible error
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可约误差
- en: Reducible error
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可约误差
- en: The irreducible error cannot be reduced even with the most robust and sophisticated
    model. However, the reducible error, which has two components, called bias and
    variance, can be reduced. Therefore, to understand the model (that is, prediction
    errors), we need to focus on bias and variance only. Bias means how far the predicted
    values are from the actual values. Usually, if the average predicted values are
    very different from the actual values (labels), then the bias is higher.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 不可约误差即使使用最强大、最复杂的模型也无法减少。然而，可约误差有两个组成部分，分别称为偏差和方差，它们是可以减少的。因此，为了理解模型（即预测误差），我们需要专注于偏差和方差。偏差是指预测值与实际值之间的距离。通常，如果平均预测值与实际值（标签）之间的差距很大，则偏差较高。
- en: 'An ML model will have a high bias because it can''t model the relationship
    between input and output variables (can''t capture the complexity of data well)
    and becomes very simple. Thus, an overly simple model with high variance causes
    underfitting of the data. The following diagram gives some high-level insights,
    and also shows what a just-right fit model should look like:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一个机器学习模型可能会有较高的偏差，因为它无法建模输入和输出变量之间的关系（无法很好地捕捉数据的复杂性），因此变得非常简单。因此，一个过于简单且具有高方差的模型会导致数据的欠拟合。下图提供了一些高级的见解，并展示了一个恰到好处的拟合模型应该是什么样子：
- en: '![](img/4e475e9e-0922-45e1-8a36-afdca4dc93cd.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e475e9e-0922-45e1-8a36-afdca4dc93cd.png)'
- en: 'Variance signifies the variability between the predicted values and the actual
    values (how scattered they are). If the model has a high training error as well
    as the validation error or test error being the same as the training error, the
    model has a high bias. On the other hand, if the model has a low training error
    but has a high validation or high test error, the model has a high variance. An
    ML model usually performs very well on the training set, but doesn''t work well
    on the test set (because of high error rates). Ultimately, it results in an underfit
    model. We can recap the overfitting and underfitting once more:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Underfitting**: If your training and validation errors are both relatively
    equal and very high, then your model is most likely underfitting your training
    data.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overfitting**: If your training error is low and your validation error is
    high, then your model is most likely overfitting your training data. The just-right
    fit model learns very well and performs better on unseen data too.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bias-variance trade-off: the high bias and high variance issue is often called
    bias-variance trade-off, because a model cannot be too complex or too simple at
    the same time. Ideally, we strive for the best model that has both low bias and
    low variance.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Now we know the basic working principle of an ML algorithm. However, based on
    problem type and the method used to solve a problem, ML tasks can be different;
    for example, supervised learning, unsupervised learning, and reinforcement learning.
    We'll discuss these learning tasks in more detail in the next section.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: ML tasks
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although every ML problem is more or less an optimization problem, the way
    in which they are solved can vary. In fact, learning tasks can be categorized
    into three types: supervised learning, unsupervised learning, and reinforcement
    learning.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Supervised learning is the simplest and most well-known automatic learning
    task. It is based on a number of predefined examples, in which the category to
    which each of the inputs should belong is already known, as shown in the following
    diagram:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7da0267f-7bf5-4811-bf54-5a19375ab274.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows a typical workflow of supervised learning. An actor
    (for example, a data scientist or data engineer) performs the **extraction**,
    **transformation**, **and load** (**ETL**) and the necessary feature engineering
    (including feature extraction, selection, and so on) to get the appropriate data
    with features and labels so that they can be fed into the model. Then, they split
    the data into training, development, and test sets. The training set is used to
    train an ML model, the validation set is used to validate the training against
    the overfitting problem and regularization, and then the actor would evaluate
    the model's performance on the test set (that is, unseen data).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if the performance is not satisfactory, the actor can perform additional
    tuning to get the best model based on hyperparameter optimization. Finally, they
    will deploy the best model in a production-ready environment. In the overall life
    cycle, there might be many actors involved (for example, a data engineer, data
    scientist, or an ML engineer), performing each step independently or collaboratively.
    The supervised learning context includes classification and regression tasks;
    classification is used to predict which class a data point is a part of (discrete
    value). It is also used for predicting the label of the class attribute. The following
    diagram summarizes these steps in a nutshell:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果性能不尽如人意，执行者可以通过超参数优化进行额外的调整，以获得最佳模型。最终，他们会将最佳模型部署到生产环境中。在整个生命周期中，可能会涉及许多执行者（例如，数据工程师、数据科学家或机器学习工程师），每个人独立或协作地执行每一步。监督学习的背景包括分类和回归任务；分类用于预测一个数据点属于哪个类别（离散值），也用于预测类别属性的标签。下图简要总结了这些步骤：
- en: '![](img/3ec8d6c2-8f14-485a-a124-40e74f65de64.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ec8d6c2-8f14-485a-a124-40e74f65de64.png)'
- en: On the other hand, regression is used to predict continuous values and make
    a numeric prediction of the class attribute. In the context of supervised learning,
    the learning process required for the input dataset is split randomly into three
    sets; for example, 60% for the training set, 10% for the validation set, and the
    remaining 30% for the testing set.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，回归用于预测连续值，并对类别属性进行数值预测。在监督学习的背景下，输入数据集的学习过程通常会随机划分成三个子集；例如，60% 用于训练集，10%
    用于验证集，剩下的30% 用于测试集。
- en: Unsupervised learning
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: 'How would you summarize and group a dataset if the labels were not given? You''ll
    probably try to answer this question by finding the underlying structure of a
    dataset and measuring the statistical properties, such as the frequency distribution,
    mean, and standard deviation. If the question is how would you effectively represent
    data in a compressed format, you''ll probably reply saying that you''ll use some
    software for doing the compression, although you might have no idea how that software
    would do it. The following diagram shows the typical workflow of an unsupervised
    learning task:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有给定标签，你将如何总结和归类一个数据集？你可能会通过找到数据集的潜在结构，并衡量其统计特性，如频率分布、均值和标准差来回答这个问题。如果问题是如何有效地以压缩格式表示数据，你可能会回答说你会使用某些软件进行压缩，尽管你可能不知道这些软件是如何实现压缩的。下图展示了一个典型的无监督学习任务的工作流程：
- en: '![](img/cf93f6bf-f0b4-486d-aae2-4e13e70a2012.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cf93f6bf-f0b4-486d-aae2-4e13e70a2012.png)'
- en: 'These are precisely two of the main goals of unsupervised learning, which is
    largely a data-driven process. We call this type of learning unsupervised because
    you will have to deal with unlabeled data. The following quote comes from Yann
    LeCun, director of AI research (source: *Predictive Learning*, NIPS 2016, Yann
    LeCun, Facebook Research):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是无监督学习的两个主要目标，它在很大程度上是一个数据驱动的过程。我们称这种学习方式为无监督，因为你将不得不处理无标签数据。以下引述来自 AI 研究负责人
    Yann LeCun（来源：*预测学习*，NIPS 2016，Yann LeCun，Facebook 研究）：
- en: '"Most human and animal learning is unsupervised learning. If intelligence was
    a cake, unsupervised learning would be the cake, supervised learning would be
    the icing on the cake, and reinforcement learning would be the cherry on the cake.
    We know how to make the icing and the cherry, but we don''t know how to make the
    cake. We need to solve the unsupervised learning problem before we can even think
    of getting to true AI."'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '"大多数人类和动物的学习都是无监督学习。如果智力是一块蛋糕，那么无监督学习就是蛋糕本身，监督学习是蛋糕上的糖霜，强化学习则是蛋糕上的樱桃。我们知道如何制作糖霜和樱桃，但我们不知道如何做蛋糕。在我们甚至开始考虑实现真正的人工智能之前，我们需要解决无监督学习的问题。"'
- en: 'A few most widely used unsupervised learning tasks include the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最广泛使用的无监督学习任务包括以下内容：
- en: '**Clustering**: Grouping data points based on similarity (or statistical properties),
    for example, a company such as Airbnb often groups its apartments and houses into
    neighborhoods so that customers can navigate the listed ones more easily'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：根据相似性（或统计特性）将数据点分组，例如，像 Airbnb 这样的公司通常会将其公寓和房屋按邻里分组，以便客户更容易地浏览列出的房源'
- en: '**Dimensionality reduction**: Compressing the data with the structure and statistical
    properties preserved as much as possible, for example, often, the number of dimensions
    of the dataset needs to be reduced for the modelling and visualization'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**：尽可能保留数据的结构和统计特性来压缩数据，例如，通常需要减少数据集的维度以便进行建模和可视化'
- en: '**Anomaly detection**: Useful in several applications, such as identification
    of credit card fraud detection, identifying faulty pieces of hardware in an industrial
    engineering process, and identifying outliers in large-scale datasets'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**：在多个应用中非常有用，例如识别信用卡欺诈、在工业工程过程中识别故障硬件以及识别大规模数据集中的异常值'
- en: '**Association rule mining**: Often used in market basket analysis, for example,
    asking which items are bought together frequently'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联规则挖掘**：通常用于市场篮子分析，例如，询问哪些商品经常一起购买'
- en: Reinforcement learning
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: 'Reinforcement learning is an artificial intelligence approach that focuses
    on the learning of the system through its interactions with the environment. In
    reinforcement learning, the system''s parameters are adapted based on the feedback
    obtained from the environment, which, in turn, provides feedback on the decisions
    made by the system. The following diagram shows a person making decisions in order
    to arrive at their destination. Let''s take an example of the route you take from
    home to work:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是一种人工智能方法，专注于通过与环境的互动来学习。在强化学习中，系统的参数会根据从环境中获得的反馈进行调整，而环境会根据系统做出的决策提供反馈。下面的图示展示了一个人为了到达目的地而做出决策的过程。让我们举一个你从家到公司通勤路线的例子：
- en: '![](img/78d85aba-6e21-4d7d-9256-878b8542d641.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78d85aba-6e21-4d7d-9256-878b8542d641.png)'
- en: We can take a look at one more example in terms of a system modeling a chess
    player. In order to improve its performance, the system utilizes the result of
    its previous moves; such a system is said to be a system learning with reinforcement.
    In this case, you take the same route to work every day. However, out of the blue
    one day, you get curious and decide to try a different route with a view to finding
    the shortest path. Similarly, based on your experience and the time taken with
    the different route, you'll decide whether you should take that specific route
    more often. We can take a look at one more example in terms of a system modeling
    a chess player.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个建模象棋选手的系统来再举一个例子。为了提高其表现，系统会利用之前行动的结果；这样的系统被称为通过强化学习的系统。在这种情况下，你每天都走相同的路线去上班。然而，有一天，你突然产生了好奇心，决定尝试一条不同的路线，目的是找到最短的路径。类似地，基于你在不同路线上的经验和所花的时间，你会决定是否应该更频繁地走这条特定路线。我们可以再举一个关于建模象棋选手的系统的例子。
- en: So far, we have learned the basic working principles of ML and different learning
    tasks. Let's have a look at each learning task with some example use cases in
    the next section.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了机器学习的基本工作原理以及不同的学习任务。接下来，让我们通过一些示例用例来看看每个学习任务。
- en: Learning types with applications
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带应用的学习类型
- en: 'We have seen the basic working principles of ML algorithms, and we have seen
    what the basic ML tasks are, and how they formulate domain-specific problems.
    However, each of these learning tasks can be solved using different algorithms.
    The following diagram provides a glimpse into this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了机器学习算法的基本工作原理，知道了基本的机器学习任务是什么，并且它们是如何构建领域特定问题的。然而，每个学习任务都可以通过不同的算法来解决。下面的图示给我们提供了一个简要的了解：
- en: '![](img/4352c6ad-bcbf-4f21-9866-b0a6537c871e.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4352c6ad-bcbf-4f21-9866-b0a6537c871e.png)'
- en: However, the preceding diagram lists only a few use cases and applications using
    different ML tasks. In practice, ML is used in numerous use cases and applications.
    We will try to cover a few of them throughout this book.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，上述图示仅列出了使用不同机器学习任务的一些用例和应用。实际上，机器学习在众多用例和应用中都有广泛的使用。我们将在本书中尽力覆盖其中的一些。
- en: Delving into DL
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解深度学习
- en: Simple ML methods that were used in the normal-size data analysis are no longer
    effective and should be replaced by more robust ML methods. Although classical
    ML techniques allow researchers to identify groups or clusters of related variables,
    the accuracy and effectiveness of these methods diminish with large and multidimensional
    data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规数据分析中使用的简单机器学习方法已经不再有效，应当用更强大的机器学习方法来替代。尽管经典的机器学习技术能够帮助研究者识别相关变量的组或簇，但随着数据量增大和维度增多，这些方法的准确性和有效性会降低。
- en: How did DL take ML to the next level?
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习是如何将机器学习提升到一个新水平的？
- en: 'Simple ML methods used in small-scale data analysis are not effective when
    dealing with large and high-dimensional datasets. However, deep learning (DL),
    which is a branch of ML based on a set of algorithms that attempt to model high-level
    abstractions in data, can handle this issue. Ian Goodfellow defined DL in his
    book "*Deep Learning*, MIT Press, 2016" as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在小规模数据分析中使用的简单机器学习方法，在处理大规模和高维数据集时并不有效。然而，深度学习（DL）作为机器学习的一个分支，基于一组算法，试图对数据进行高层次抽象建模，能够解决这一问题。Ian
    Goodfellow在他的书《*深度学习*，MIT出版社，2016年》中是这样定义深度学习的：
- en: '"Deep learning is a particular kind of machine learning that achieves great
    power and flexibility by learning to represent the world as a nested hierarchy
    of concepts, with each concept defined in relation to simpler concepts, and more
    abstract representations computed in terms of less abstract ones."'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: “深度学习是一种特殊的机器学习方式，通过学习将世界表示为概念的嵌套层次结构，每个概念是相对于更简单的概念来定义的，更抽象的表示通过更不抽象的表示来计算，从而实现了强大的能力和灵活性。”
- en: Similar to the ML model, a DL model also takes in an input, `X`, and learns
    high-level abstractions or patterns from it to predict an output of `Y`. For example,
    based on the stock prices of the past week, a DL model can predict the stock price
    for the next day. When performing training on such historical stock data, a DL
    model tries to minimize the difference between the prediction and the actual values.
    This way, a DL model tries to generalize to inputs that it hasn't seen before
    and makes predictions on test data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与机器学习模型类似，深度学习模型也接受一个输入`X`，并从中学习高层次的抽象或模式，从而预测输出`Y`。例如，基于过去一周的股价，深度学习模型可以预测下一天的股价。当在这样的历史股数据上进行训练时，深度学习模型会尽量减少预测值和实际值之间的差异。通过这种方式，深度学习模型尝试对之前未见过的输入进行泛化，并对测试数据做出预测。
- en: Now, you might be wondering, if an ML model can do the same tasks, why do we
    need DL for this? Well, DL models tend to perform well with large amounts of data,
    whereas old ML models stop improving after a certain point. The core concept of
    DL, inspired by the structure and function of the brain, is called **artificial
    neural networks** (**ANNs**).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能会想，如果机器学习模型可以完成相同的任务，为什么我们还需要深度学习呢？其实，深度学习模型在处理大量数据时表现得很好，而传统的机器学习模型在达到某个点后就不再改进。深度学习的核心概念，受到大脑结构和功能的启发，被称为**人工神经网络**（**ANNs**）。
- en: 'Being at the core of DL, ANNs help you to learn the associations between sets
    of inputs and outputs in order to make more robust and accurate predictions. However,
    DL is not only limited to ANNs; there have been many theoretical advances, software
    stacks, and hardware improvements that bring DL to the masses. Let''s look at
    an example in which we want to develop a predictive analytics model, such as an
    animal recognizer, where our system has to resolve two problems:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习的核心，人工神经网络（ANNs）帮助你学习输入和输出之间的关联，从而做出更强大、更准确的预测。然而，深度学习不仅限于人工神经网络；随着理论的进步、软件堆栈的完善和硬件的改进，深度学习已经普及到大众中。让我们来看一个例子，假设我们要开发一个预测分析模型，比如一个动物识别器，我们的系统必须解决两个问题：
- en: To classify whether an image represents a cat or a dog
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判断一张图片是猫还是狗
- en: To cluster images of dogs and cats.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对猫狗图片进行聚类。
- en: 'If we solve the first problem using a typical ML method, we must define the
    facial features (ears, eyes, whiskers, and so on) and write a method to identify
    which features (typically non-linear) are more important when classifying a particular
    animal. However, at the same time, we cannot address the second problem because
    classical ML algorithms for clustering images (such as k-means) cannot handle
    nonlinear features. Take a look at the following diagram, which shows a workflow
    that we would follow to classify if the given image is of a cat:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用典型的机器学习方法来解决第一个问题，我们必须定义面部特征（耳朵、眼睛、胡须等），并编写方法来识别哪些特征（通常是非线性的）在分类特定动物时更为重要。然而，同时我们无法解决第二个问题，因为经典的机器学习聚类算法（如k-means）无法处理非线性特征。看看下面的图示，它展示了我们在分类给定图像是否为猫时需要遵循的工作流程：
- en: '![](img/6774fd8b-9b85-47e3-af7e-f9b28f882e9f.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6774fd8b-9b85-47e3-af7e-f9b28f882e9f.png)'
- en: DL algorithms take these two problems one step further, and the most important
    features will be extracted automatically after determining which features are
    the most important for classification or clustering. In contrast, when using a
    classical ML algorithm, we would have to provide the features manually. A DL algorithm
    takes more sophisticated steps instead. For example, first, it identifies the
    edges that are the most relevant when clustering cats or dogs. It then tries to
    find various combinations of shapes and edges hierarchically, which is called
    ETL.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: DL算法将这两个问题进一步推进，最重要的特征将在确定哪些特征对分类或聚类最为重要后自动提取。相比之下，使用经典的机器学习算法时，我们必须手动提供特征。而DL算法则采取更复杂的步骤。例如，首先，它识别出在聚类猫或狗时最相关的边缘。然后，它尝试以层次结构的方式找到各种形状和边缘的组合，这被称为ETL。
- en: Then, after several iterations, it carries out the hierarchical identification
    of complex concepts and features. Following that, based on the features identified,
    the DL algorithm will decide which of the features are most significant for classifying
    the animal. This step is known as feature extraction. Finally, it takes out the
    label column and performs unsupervised training using **autoencoders** (**AEs**)
    to extract the latent features to be redistributed to k-means for clustering.
    Then, the **clustering assignment hardening loss** (**CAH loss**) and reconstruction
    loss are jointly optimized toward an optimal clustering assignment.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在经过几次迭代后，它进行复杂概念和特征的层次化识别。接着，基于已识别的特征，DL算法将决定哪些特征对分类动物最为重要。这个步骤被称为特征提取。最后，它提取出标签列，并使用**自编码器**（**AEs**）进行无监督训练，提取潜在特征，然后将其重新分配给k-means进行聚类。接着，**聚类分配硬化损失**（**CAH损失**）和重建损失被共同优化，以达到最佳的聚类分配。
- en: 'However, in practice, a DL algorithm is fed with a raw image representation,
    which doesn''t see an image as we see it because it only knows the position of
    each pixel and its color. The image is divided into various layers of analysis.
    For example, at a lower level, there is the software analysis—a grid of a few
    pixels with the task of detecting a type of color or various nuances. If it finds
    something, it informs the next level, which, at this point, checks whether or
    not that given color belongs to a larger form, such as a line. The process continues
    to the upper levels until the algorithm understands what is shown in the following
    diagram:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实际应用中，DL算法接收到的是原始图像表示，这并不像我们看到的图像那样理解图像，因为它只知道每个像素的位置和颜色。图像被分解成多个分析层次。例如，在较低层次，软件会分析一小块像素网格，任务是检测某种颜色或各种细微的色调变化。如果检测到某些信息，它会通知下一层，此时这一层检查该颜色是否属于更大的形态，如一条线。这个过程一直持续到更高层次，直到算法理解以下图所示的内容：
- en: '![](img/6be27318-8090-42f0-8d8c-005086271f80.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6be27318-8090-42f0-8d8c-005086271f80.png)'
- en: Although a dog versus a cat is an example of a very simple classifier, software
    that's capable of doing these types of things is now widespread and is found in
    systems for recognizing faces, or in those for searching an image on Google, for
    example. This kind of software is based on DL algorithms. By contrast, if we are
    using a linear ML algorithm we cannot build such applications, since these algorithms
    are incapable of handling non-linear image features.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然区分狗与猫是一个非常简单的分类器示例，但能够做这些事情的软件现在已经广泛应用，并且出现在面部识别系统中，或例如在Google上搜索图像的系统中。这类软件是基于DL算法的。相反，如果我们使用线性机器学习算法，就无法构建这样的应用，因为这些算法无法处理非线性的图像特征。
- en: Also, using ML approaches, we typically only handle a few hyperparameters. However,
    when neural networks are brought into the mix, things become too complex. In each
    layer, there are millions or even billions of hyperparameters to tune—so many
    that the cost function becomes non-convex. Another reason for this is that the
    activation functions that are used in hidden layers are non-linear, so the cost
    is non-convex. We will discuss this phenomenon in more detail in later chapters,
    but let's take a quick look at ANNs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用机器学习方法时，我们通常只需处理少量的超参数。然而，当神经网络介入时，情况变得非常复杂。每一层中都有成千上万甚至数十亿个超参数需要调整——如此之多，以至于成本函数变得非凸。另一个原因是，隐藏层中使用的激活函数是非线性的，因此成本也是非凸的。我们将在后面的章节中更详细地讨论这一现象，但现在先简要看看人工神经网络（ANNs）。
- en: Artificial neural networks
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: ANNs, which are inspired by how a human brain works, form the core of DL and
    its true realization. Today's revolution around DL would not have been possible
    without ANNs. Thus, to understand DL, we need to understand how neural networks
    work.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: ANN and the human brain
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ANNs represent one aspect of the human nervous system, and how the nervous system
    consists of a number of neurons that communicate with each other using axons.
    The receptors receive the stimuli either internally or from the external world.
    Then, they pass this information to the biological neurons for further processing.
    There are a number of dendrites, in addition to another long extension called
    the axon. Toward the axon's extremities, there are minuscule structures called
    synaptic terminals, which are used to connect one neuron to the dendrites of other
    neurons. Biological neurons receive short electrical impulses called signals from
    other neurons, and, in response, they trigger their own signals.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: We can, therefore, summarize that the neuron comprises a cell body (also known
    as the **soma**), one or more dendrites for receiving signals from other neurons,
    and an axon for carrying out the signals that are generated by the neurons. A
    neuron is in an active state when it is sending signals to other neurons. However,
    when it is receiving signals from other neurons, it is in an inactive state. In
    an idle state, a neuron accumulates all the signals that are received before reaching
    a certain activation threshold. This whole process motivated researchers to test
    out ANNs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: A brief history of ANNs
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inspired by the working principles of biological neurons, Warren McCulloch and
    Walter Pitts proposed the first artificial neuron model, in 1943, in terms of
    a computational model of nervous activity. This simple model of a biological neuron,
    also known as an **artificial neuron** (**AN**), has one or more binary (on/off)
    inputs and one output only. An AN simply activates its output when more than a
    certain number of its inputs are active.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The example sounds too trivial, but even with such a simplified model, it is
    possible to build a network of ANs. Nevertheless, these networks can be combined
    to compute complex logical expressions too. This simplified model inspired John
    von Neumann, Marvin Minsky, Frank Rosenblatt, and many others to come up with
    another model called a **perceptron,** back in 1957\. The perceptron is one of
    the simplest ANN architectures we have seen in the last 60 years. It is based
    on a slightly different AN called a **Linear Threshold Unit** (**LTU**). The only
    difference is that the inputs and outputs are now numbers instead of binary on/off
    values. Each input connection is associated with a weight. The LTU computes a
    weighted sum of its inputs, then applies a step function (which resembles the
    action of an activation function) to that sum, and outputs the result.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: One of the downsides of a perceptron is that its decision boundary is linear.
    Therefore, they are incapable of learning complex patterns. They are also incapable
    of solving some simple problems, such as **Exclusive OR** (**XOR**). However,
    later on, the limitations of perceptrons were somewhat eliminated by stacking
    multiple perceptrons, called **MLP**. So, the most significant progress in ANNs
    and DL can be described in the following timeline. We have already discussed how
    the artificial neurons and perceptrons provided the base in 1943 and 1958, respectively.
    In 1969, Marvin *Minsky* and Seymour *Papert* formulated the XOR as a linearly
    non-separable problem, and later, in 1974, Paul *Werbos* demonstrated the backpropagation
    algorithm for training the perceptron.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the most significant advancement happened in 1982, when John Hopfield
    proposed the Hopfield Network. Then, one of the godfathers of the neural network
    and DL—Hinton and his team—proposed the Boltzmann Machine in 1985\. However, in
    1986 Geoffrey Hinton successfully trained the MLP and Jordan M.I. proposed RNNs.
    In the same year, Paul Smolensky also proposed the improved version of the Boltzmann
    Machine, called the **Restricted Boltzmann Machine** (**RBM**). Then, in 1990,
    Lecun et al. proposed LeNet, which is a deep neural network architecture. For
    a brief glimpse, refer to the following diagram:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb122a6b-b05d-4691-8b20-edad562ebfa2.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
- en: The most significant year of the 90's era was 1997, when Jordan et al. proposed
    a **recurrent neural network** (**RNN**). In the same year, Schuster et al. proposed
    the improved version of **long-short term memory** (**LSTM**) and the improved
    version of the original RNN called bidirectional RNN.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Despite significant advances in computing, from 1997 to 2005, we did not experience
    much advancement. Then, in 2006, Hinton struck again when, he and his team proposed
    a **deep belief network** (**DBN**) by stacking multiple RBMs. Then in 2012, Hinton
    invented the dropout that significantly improved the regularization and overfitting
    in the deep neural network. After that, Ian Goodfellow et al. introduced the GANs—a
    significant milestone in image recognition. In 2017, Hinton proposed CapsNet to
    overcome the limitation of regular CNNs, and this is so far one of the most remarkable
    milestones. We will discuss these architectures later in this chapter.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: How does an ANN learn?
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Based on the concept of biological neurons, the term and idea of ANNs arose.
    Similar to biological neurons, the artificial neuron consists of the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: One or more incoming connections that aggregate signals from neurons
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One or more output connections for carrying the signal to the other neurons
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An activation function, which determines the numerical value of the output signal
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides the state of a neuron, synaptic weight is considered, which influences
    the connection within the network. Each weight has a numerical value indicated
    by *W[ij]*, which is the synaptic weight connecting neuron *i* to neuron *j*.
    Now, for each neuron *i*, an input
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'vector can be defined by *x[i] = (x[1],x[2],...x[n])*, and a weight vector
    can be defined by *w[i] = (w[i1],x[i2],...x[in])*. Now, depending on the position
    of a neuron, the weights and the output function determine the behavior of an
    individual neuron. Then, during forward propagation, each unit in the hidden layer
    gets the following signal:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/239e1275-0719-40b1-9689-eb3ea9bcf6a1.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: 'Nevertheless, among the weights, there is also a special type of weight called
    a bias unit, *b*. Technically, bias units aren''t connected to any previous layer,
    so they don''t have true activity. But still, the bias *b* value allows the neural
    network to shift the activation function to the left or right. By taking the bias
    unit into consideration, the modified network output is formulated as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc603183-bf05-4ad0-b110-7847a8084d82.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: 'The preceding equation signifies that each hidden unit gets the sum of inputs,
    multiplied by the corresponding weight—this is known as the **Summing junction**.
    Then, the resultant output in the **Summing junction** is passed through the activation
    function, which squashes the output, as depicted in the following diagram:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2401dc9f-11f6-42e3-90e0-f31f4f14bfb7.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: 'A practical neural network architecture, however, is composed of input, hidden,
    and output layers that are composed of nodes that make up a network structure.
    It still follows the working principle of an artificial neuron model, as shown
    in the preceding diagram. The input layer only accepts numeric data, such as features
    in real numbers, and images with pixel values. The following diagram shows a neural
    network architecture for solving a multiclass classification (that is, 10 classes)
    problem based on a data having 784 features:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e3fd76b9-b477-4275-8b19-8217f4a4483a.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: A neural network with one input layer, three hidden layers, and an output layer
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the hidden layers perform most of the computation to learn the patterns,
    and the network evaluates how accurate its prediction is compared to the actual
    output using a special mathematical function called the loss function. It could
    be a complex one or a very simple mean squared error, which can be defined as
    follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bea114d3-df9b-4ac8-98b1-41acf87a2dc2.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
- en: In the preceding equation, ![](img/4058e15e-01a0-4db0-9f89-4de3196c76f3.png)
    is the prediction made by the network, while *Y* represents the actual or expected
    output. Finally, when the error is no longer being reduced, the neural network
    converges and makes a prediction through the output layer.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Training a neural network
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The learning process for a neural network is configured as an iterative process
    of the optimization of the weights. The weights are updated in each epoch. Once
    the training starts, the aim is to generate predictions by minimizing the loss
    function. The performance of the network is then evaluated on the test set. We
    already know about the simple concept of an artificial neuron. However, generating
    only some artificial signals is not enough to learn a complex task. As such, a
    commonly used supervised learning algorithm is the backpropagation algorithm,
    which is very often used to train a complex ANN.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, training such a neural network is an optimization problem, too,
    in which we try to minimize the error by adjusting network weights and biases
    iteratively, by using backpropagation through **gradient descent** (**GD**). This
    approach forces the network to backtrack through all its layers to update the
    weights and biases across nodes in the opposite direction of the loss function.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this process using GD does not guarantee that the global minimum is
    reached. The presence of hidden units and the non-linearity of the output function
    means that the behavior of the error is very complex and has many local minima.
    This backpropagation step is typically performed thousands or millions of times,
    using many training batches, until the model parameters converge to values that
    minimize the cost function. The training process ends when the error on the validation
    set begins to increase, because this could mark the beginning of a phase of overfitting:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/964eadcf-5c58-41d9-92a5-2122d399085d.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Searching for the minimum for the error function E, we move in the direction
    in which the gradient G of E is minimal
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The downside of using GD is that it takes too long to converge, which makes
    it impossible to meet the demand of handling large-scale training data. Therefore,
    a faster GD, called **stochastic gradient descent** (**SGD**) was proposed, which
    is also a widely used optimizer in DNN training. In SGD, we use only one training
    sample per iteration from the training set to update the network parameters, which
    is a stochastic approximation of the true cost gradient.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: There are other advanced optimizers nowadays such as Adam, RMSProp, ADAGrad,
    and Momentum. Each of them is either a direct or indirect optimized version of
    SGD.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Weight and bias initialization
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, here''s a tricky question: how do we initialize the weights? Well, if
    we initialize all the weights to the same value (for example, 0 or 1), each hidden
    neuron will get the same signal. Let''s try to break it down:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: If all weights are initialized to 1, then each unit gets a signal equal to the
    sum of the inputs.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If all weights are 0, which is even worse, then every neuron in a hidden layer
    will get zero signal.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For network weight initialization, Xavier initialization is used widely. It
    is similar to random initialization, but often turns out to work much better,
    since it can identify the rate of initialization depending on the total number
    of input and output neurons by default. You may be wondering whether you can get
    rid of random initialization while training a regular DNN.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Well, recently, some researchers have been talking about random orthogonal matrix
    initializations that perform better than just any random initialization for training
    DNNs. When it comes to initializing the biases, we can initialize them to zero.
    But setting the biases to a small constant value, such as 0.01 for all biases,
    ensures that all **rectified linear units** (**ReLU**) can propagate a gradient.
    However, it neither performs well nor shows consistent improvement. Therefore,
    sticking with zero is recommended.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To allow a neural network to learn complex decision boundaries, we apply a
    non-linear activation function to some of its layers. Commonly used functions
    include Tanh, ReLU, softmax, and variants of these. More technically, each neuron
    receives a signal of the weighted sum of the synaptic weights and the activation
    values of the neurons that are connected as input. One of the most widely used
    functions for this purpose is the so-called sigmoid logistic function, which is
    defined as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d18ee45f-3d01-4f2c-9ce3-8ffc88c9d079.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: The domain of this function includes all real numbers, and the co-domain is
    (0, 1). This means that any value obtained as an output from a neuron (as per
    the calculation of its activation state) will always be between zero and one.
    The Sigmoid function, as
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'represented in the following diagram, provides an interpretation of the saturation
    rate of a neuron, from not being active (equal to 0) to complete saturation, which
    occurs at a predetermined maximum value (equal to 1):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09c9bd66-be56-4e39-8322-365a9339cfcc.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Sigmoid versus Tanh activation function
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, a hyperbolic tangent, or **Tanh**, is another form of activation
    function. **Tanh** flattens a real-valued number between **-1** and **1**. The
    preceding graph shows the difference between the **Tanh** and **Sigmoid** activation
    functions. In particular, mathematically,  speaking the *tanh* activation function
    can be expressed as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a31a5802-f491-4761-a390-73b2cbc778c3.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: In general, in the last level of a **feedforward neural network** (**FFNN**),
    the softmax function is applied as the decision boundary. This is a common case,
    especially when solving a classification problem. The softmax function is used
    for the probability distribution over the possible classes in a multiclass classification
    problem. To conclude, choosing proper activation functions and network weight
    initializations are two problems that make a network perform at its best and help
    to obtain good training. Now that we know the brief history of neural networks,
    let's deepdive into different architectures in the next section, which will give
    us an idea of their usage.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Neural network architectures
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up to now, numerous neural network architectures have been proposed and are
    in use. However, more or less all of them are based on a few core neural network
    architectures. We can categorize DL architectures into four groups:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Deep neural networks
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional neural networks
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recurrent neural networks
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emergent architectures
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, DNNs, CNNs, and RNNs have many improved variants. Although most of
    the variants are proposed or developed for solving domain-specific research problems,
    the basic working principles still follow the original DNN, CNN, and RNN architectures.
    The following subsections will give you a brief introduction to these architectures.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Deep neural networks
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DNNs are neural networks that have a complex and deeper architecture with a
    large number of neurons in each layer, and many connections between them. Although
    DNN refers to a very deep network, for simplicity, we consider MLP, **stacked
    autoencoder **(**SAE**), and **deep belief networks** (**DBNs**) as DNN architectures.
    These architectures mostly work as an FFNN, meaning information propagates from
    input to output layers.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple perceptrons are stacked together as MLPs, where layers are connected
    as a directed graph. Fundamentally, an MLP is one of the most simple FFNNs since
    it has three layers: an input layer, a hidden layer, and an output layer. This
    way, the signal propagates one way, from the input layer to the hidden layers
    to the output layer, as shown in the following diagram:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b984dc6-a80d-4037-adc9-dc61d4be1b5a.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: 'Autoencoders and RBMs are the basic building blocks for SAEs and DBNs, respectively.
    Unlike MLP, which is an FFNN that''s trained in a supervised way, both SAEs and
    DBNs are trained in two phases: unsupervised pretraining and supervised fine-tuning.
    In unsupervised pretraining, layers are stacked in order and trained in a layer-wise
    manner with used unlabeled data.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'In supervised fine-tuning, an output classifier layer is stacked and the complete
    neural network is optimized by retraining with labeled data. One problem with
    MLP is that it often overfits the data, so it doesn''t generalize well. To overcome
    this issue, DBN was proposed by Hinton et al. It uses a greedy, layer-by-layer,
    pretraining algorithm. DBNs are composed of a visible layer and multiple hidden
    unit layers. The building blocks of a DBN are RBMs, as shown in the following
    diagram, where several RBMs are stacked one after another:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a7b0c86-7732-461b-93b4-3512d208d1b8.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: The top two layers have undirected, symmetric connections in-between, but the
    lower layers have directed connections from the preceding layer. Despite numerous
    successes, DBNs are now being replaced with AEs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AEs are also special types of neural networks that learn automatically from
    the input data. AEs consist of two components: the encoder and the decoder. The
    encoder compresses the input into a latent-space representation. Then, the decoder
    part tries to reconstruct the original input data from this representation:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoder**: Encodes or compresses the input into a latent-space representation
    using a function known as *h = f(x)*'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoder**: Decodes or reconstructs the input from the latent space representation
    using a function known as *r = g(h)*'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, an AE can be described by a function of* g(f(x)) = 0*, where we want 0
    as close to the original input of *x*. The following diagram shows how an AE typically
    works:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bcbf8bbf-53d7-4d16-9fdc-0bf5612e3e25.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: AEs are very useful for data denoising and dimensionality reduction for data
    visualization because they can learn data projections called representations more
    effectively than PCA.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CNNs have achieved much and have been widely adopted in computer vision (for
    example, image recognition). In CNN networks, the connection schemes are significantly
    different compared to an MLP or DBN. A few of the convolutional layers are connected
    in a cascade style. Each layer is backed up by an ReLU layer, a pooling layer,
    additional convolutional layers (+ReLU), and another pooling layer, which is followed
    by a fully connected layer and a softmax layer. The following diagram is a schematic
    of the architecture of a CNN that''s used for facial recognition, which takes
    facial images as input and predicts emotions such as anger, disgust, fear, happy,
    and sad:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a4a34db-3397-44cb-8825-78eb3053eae0.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: A schematic architecture of a CNN used for facial recognition
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, DNNs have no prior knowledge of how the pixels are organized because
    they do not know that nearby pixels are close. CNNs embed this prior knowledge
    using lower layers by using feature maps in small areas of the image, while the
    higher layers combine lower-level features into larger features.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: This setting works well with most of the natural images, giving CNN a decisive
    head start over DNNs. The output from each convolutional layer is a set of objects,
    called feature maps, that are generated by a single kernel filter. Then, the feature
    maps can be used to define a new input to the next layer. Each neuron in a CNN
    network produces an output, followed by an activation threshold, which is proportional
    to the input and not bound.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent neural networks
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In RNNs, connections between units form a directed cycle. The RNN architecture
    was originally conceived by Hochreiter and Schmidhuber in 1997\. RNN architectures
    have standard MLPs, plus added loops so that they can exploit the powerful nonlinear
    mapping capabilities of the MLP. They also have some form of memory. The following
    diagram shows a very basic RNN that has an input layer, two recurrent layers,
    and an output layer:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77b89365-780e-4461-a58b-6e3c4e492336.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
- en: 'However, this basic RNN suffers from gradient vanishing and the exploding problem,
    and cannot model long-term dependencies. These architectures include LSTM, **gated
    recurrent units** (**GRUs**), bidirectional-LSTM, and other variants. Consequently,
    LSTM and GRU can overcome the drawbacks of regular RNNs: the gradient vanishing/exploding
    problem and long-short term dependency.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Emergent architectures
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many other emergent DL architectures have been suggested, such as **Deep SpatioTemporal
    Neural Networks** (**DST-NNs**), **Multi-Dimensional Recurrent Neural Networks**
    (**MD-RNNs**), and **Convolutional AutoEncoders** (**CAEs**). Nevertheless, there
    are a few more emerging networks, such as **CapsNets** (which is an improved version
    of a CNN, designed to remove the drawbacks of regular CNNs), RNN for image recognition,
    and **Generative Adversarial Networks** (**GANs**) for simple image generation.
    Apart from these, factorization machines for personalization and deep reinforcement
    learning are also being used widely.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Residual neural networks
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since there are sometimes millions and millions of hyperparameters and other
    practical aspects, it's really difficult to train deeper neural networks. To overcome
    this limitation, Kaiming H. et al. ( [https://arxiv.org/abs/1512.03385v1](https://arxiv.org/abs/1512.03385v1))
    proposed a residual learning framework to ease the training of networks that are
    substantially deeper than those used previously.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: They also explicitly reformulated the layers as learning residual functions
    with reference to the layer inputs, instead of learning non-referenced functions.
    This way, these residual networks are easier to optimize and can gain accuracy
    from considerably increased depth. The downside is that building a network by
    simply stacking residual blocks inevitably limits the optimization ability. To
    overcome this limitation, Ke Zhang et al. also proposed using a multilevel residual
    network ([https://arxiv.org/abs/1608.02908](https://arxiv.org/abs/1608.02908)).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'GANs are deep neural net architectures that consist of two networks pitted
    against each other (hence the name *adversarial*). Ian Goodfellow et al. introduced
    GANs in a paper (see more at [https://arxiv.org/abs/1406.2661v1](https://arxiv.org/abs/1406.2661v1)).
    In GANs, the two main components are the **generator and discriminator**:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4920409b-74a3-482e-a9f8-638542cdeab9.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Working principle of generative adversarial networks
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'In a GAN architecture, a generator and a discriminator are pitted against each
    other—hence the name, adversarial:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: The generator tries to generate data samples out of a specific probability distribution
    and is very similar to the actual object.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator will judge whether its input is coming from the original training
    set or from the generator part.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many DL practitioners think that GANs were one of the most important advancements
    because GANs can be used to mimic any distribution of data, and, based on the
    data distribution, they can be taught to create robot artist images, super-resolution
    images, text-to-image synthesis, music, speech, and more. For example, because
    of the concept of adversarial training, Facebook's AI research director, Yann
    LeCun, suggested that GANs are the most interesting idea in the last 10 years
    of ML.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Capsule networks
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In CNNs, each layer understands an image at a much more granular level through
    a slow receptive field or max pooling operations. If the images have rotation,
    tilt, or very different shapes or orientation, CNNs fail to extract such spatial
    information and show very poor performance at image processing tasks. Even the
    pooling operations in CNNs cannot be much help against such positional invariance.
    This issue in CNNs has led us to the recent advancement of CapsNet through the
    paper entitled *Dynamic Routing Between Capsules* (see more at [https://arxiv.org/abs/1710.09829](https://arxiv.org/abs/1710.09829))
    by Geoffrey Hinton et al:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '"A capsule is a group of neurons whose activity vector represents the instantiation
    parameters of a specific type of entity, such as an object or an object part."'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike a regular DNN, where we keep on adding layers, in CapsNet, the idea
    is to add more layers inside a single layer. This way, a CapsNet is a nested set
    of neural layers. In CapsNet, the vector inputs and outputs of a capsule are computed
    using the routing algorithm used in physics, which iteratively transfers information
    and processes the **self-consistent field** (**SCF**) procedure:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/14df1eb2-37d6-4291-b0c9-453194b85145.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows a schematic diagram of a simple three-layer CapsNet.
    The length of the activity vector of each capsule in the DigiCaps layer indicates
    the presence of an instance of each class, which is used to calculate the loss.
    Now that we have learned about the working principles of neural networks and the
    different neural network architectures, implementing something hands-on would
    be great. However, before that, let's take a look at some popular DL libraries
    and frameworks, which come with the implementation of these network architectures.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks for clustering analysis
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several variants of k-means have been proposed to address issues with higher-dimensional
    input spaces. However, they are fundamentally limited to linear embedding. Hence,
    we cannot model non-linear relationships. Nevertheless, fine-tuning in these approaches
    is based on only cluster assignment hardening loss (see later in this section).
    Therefore, a fine-grained clustering accuracy cannot be achieved. Since the quality
    of the clustering results is dependent on the data distribution, deep architecture
    can help the model learn mapping from the data space to a lower-dimensional feature
    space in which it iteratively optimizes a clustering objective. Several approaches
    have been proposed over the last few years, trying to use the representational
    power of deep neural networks for preprocessing clustering inputs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: A few notable approaches include deep embedded clustering, deep clustering networks,
    discriminatively boosted clustering, clustering CNNs, deep embedding networks,
    convolutional deep embedded clustering, and joint unsupervised learning of deep
    representation for images. Other approaches include DL with non-parametric clustering,
    CNN-based joint clustering and representation learning with feature drift compensation,
    learning latent representations in neural networks for clustering, clustering
    using convolutional neural networks, and deep clustering with convolutional autoencoder
    embedding.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of these approaches follow more or less the same principle: that is, representation
    learning using a deep architecture to transform the inputs into a latent representation
    and using these representations as input for a specific clustering method. Such
    deep architectures include MLP, CNN, DBN, GAN, and variational autoencoders. The
    following diagram shows an example of how to improve the clustering performance
    of a DEC network using convolutional autoencoders and optimizing both reconstruction
    and CAH losses jointly. The latent space out of the encoder layer is fed to K-means
    for soft clustering assignment. Blurred genetic variants signify the existence
    of reconstruction errors:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d1aa2d3-1e6d-407c-9349-98e368b48591.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: 'DL based clustering (source: Karim et al., Recurrent Deep Embedding Networks
    for Genotype Clustering and Ethnicity Prediction, arXiv:1805.12218)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: In summary, in these approaches, there are three important steps involved—extracting
    cluster-friendly deep features using deep architectures, combining clustering
    and non-clustering losses, and, finally, network updates to optimize clustering
    and non-clustering losses jointly.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: DL frameworks and cloud platforms for IoT
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several popular DL frameworks. Each of them comes with some pros and
    cons. Some of them are desktop-based, and some of them are cloud-based platforms,
    where you can deploy/run your DL applications. However, most of the libraries
    that are released under an open license help when people are using graphics processors,
    which can ultimately help in speeding up the learning process. Such frameworks
    and libraries include TensorFlow, PyTorch, Keras, Deeplearning4j, H2O, and the
    **Microsoft Cognitive Toolkit** (**CNTK**). Even a few years back, other implementations,
    including Theano, Caffee, and Neon, were used widely. However, these are now obsolete.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '**Deeplearning4j** (**DL4J**) is one of the first commercial-grade, open source,
    distributed DL libraries that was built for Java and Scala. This also provides
    integrated support for Hadoop and Spark. DL4J is built for use in business environments
    on distributed GPUs and CPUs. DL4J aims to be cutting-edge and *Plug and Play*,
    with more convention than configuration, which allows for fast prototyping for
    non-researchers. Its numerous libraries can be integrated with DL4J and will make
    your JVM experience easier, regardless of whether you are developing your ML application
    in Java or Scala. Similar to NumPy for JVM, ND4J comes up with basic operations
    of linear algebra (matrix creation, addition, and multiplication). However, ND4S
    is a scientific computing library for'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'linear algebra and matrix manipulation. It also provides n-dimensional arrays
    for JVM-based languages. The following diagram shows last year''s Google Trends,
    illustrating how popular TensorFlow is:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be613e47-6b26-477a-a6ca-d92333a53d42.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: As well as these frameworks, Chainer is a powerful, flexible, and intuitive
    DL framework, which supports CUDA computation. It only requires a few lines of
    code to leverage a GPU. It also runs on multiple GPUs with little effort. Most
    importantly, Chainer supports various network architectures, including feed-forward
    nets, convnets, recurrent nets, and recursive nets. It also supports per-batch
    architectures. One more interesting feature in Chainer is that it supports forward
    computation, by which any control flow statements of Python can be included without
    lacking the ability of backpropagation. It makes code intuitive and easy to debug.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: The DL framework power scores 2018 also shows that TensorFlow, Keras, and PyTorch
    are far ahead of other frameworks (see [https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a](https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a)).
    Scores were calculated based on usage, popularity, and interest in DL frameworks
    through the following sources. Apart from the preceding libraries, there are some
    recent initiatives for DL in the cloud. The idea is to bring DL capability to
    big data with billions of data points and high-dimensional data. For example,
    **Amazon Web Services** (**AWS**), Microsoft Azure, Google Cloud Platform, and
    **NVIDIA GPU Cloud** (**NGC**) all offer machine and DL services that are native
    to their public clouds.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'In October 2017, AWS released **Deep Learning AMIs** (**DLAMIs**) for **Amazon
    Elastic Compute Cloud** (**Amazon EC2**) P3 instances. These AMIs come preinstalled
    with DL frameworks, such as TensorFlow, Gluon, and Apache MXNet, which are optimized
    for the NVIDIA Volta V100 GPUs within Amazon EC2 P3 instances. The DL service
    currently offers three types of AMIs: Conda AMI, Base AMI, and AMI with source
    code.The CNTK is Azure''s open source DL service. Similar to the AWS offering,
    it focuses on tools that can help developers build and deploy DL applications.
    Azure also provides a model gallery that includes resources, such as code samples,
    to help enterprises get started with the service.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, NGC empowers AI scientists and researchers with GPU-accelerated
    containers (see [https://www. nvidia. com/en-us/data-center/gpu-cloud-computing/](https://www.nvidia.com/en-us/data-center/gpu-cloud-computing/)).
    The NGC features containerized DL frameworks, such as TensorFlow, PyTorch, MXNet,
    and more that are tuned, tested, and certified by NVIDIA to run on the latest
    NVIDIA GPUs on participating cloud-service providers. Nevertheless, there are
    also third-party services available through their respective marketplaces.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '**When it comes to cloud-based IoT system-development markets, currently it
    forks into three obvious routes:** off-the-shelf platforms (for example, AWS IoT
    Core, Azure IoT Suite, and Google Cloud IoT Core), which trade off vendor lock-in
    and higher-end volume pricing against cost-effective scalability and shorter lead
    times; reasonably well-established MQTT configurations over the Linux stack (example:
    Eclipse Mosquitto); and the more exotic emerging protocols and products (for example,
    Nabto''s P2P protocol) that are developing enough uptake, interest, and community
    investment to stake a claim for strong market presence in the future.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: As a DL framework, Chainer Neural Network is a great choice for all devices
    powered by Intel Atom, NVIDIA Jetson TX2, and Raspberry Pi. Therefore, using Chainer,
    we don't need to build and configure the ML framework for our devices from scratch.
    It provides prebuilt packages for three popular ML frameworks, including TensorFlow,
    Apache MXNet, and Chainer. Chainer works in a similar fashion, which depends on
    a library on the Greengrass and a set of model files generated using Amazon SageMaker
    and/or stored directly in an Amazon S3 bucket. From Amazon SageMaker or Amazon
    S3, the ML models can be deployed to AWS Greengrass to be used as a local resource
    for ML inference. Conceptually, AWS IoT Core functions as the managing plane for
    deploying ML inference to the edge.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced a number of fundamental DL themes. We started
    our journey with a basic, but comprehensive, introduction to ML. Then, we gradually
    moved on to DL and different neural architectures. We then had a brief overview
    of the most important DL frameworks that can be utilized to develop DL-based applications
    for IoT-enabled devices.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: IoT applications, such as smart home, smart city, and smart healthcare, heavily
    rely on video or image data processing for decision making. In the next chapter,
    we will cover DL-based image processing for IoT applications, including image
    recognition, classification, and object detection. Additionally, we will cover
    hands-on video data processing in IoT applications.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
