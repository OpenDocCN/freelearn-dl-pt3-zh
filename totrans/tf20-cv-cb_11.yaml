- en: '*Chapter 11*: Streamlining Network Implementation with AutoML'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer vision, particularly when combined with deep learning, is a field that's
    not suitable for the faint of heart! While in traditional computer programming,
    we have a limited set of options for debugging and experimentation, this is not
    the case in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the stochastic nature of machine learning itself plays a role in
    making the process of creating a good enough solution difficult, but so do the
    myriad of parameters, variables, knobs, and settings we need to get right to unlock
    the true power of a neural network for a particular problem.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a proper architecture is just the beginning because we also need to
    consider preprocessing techniques, learning rates, optimizers, loss functions,
    and data splits, among a multiplicity of other factors.
  prefs: []
  type: TYPE_NORMAL
- en: My point is that deep learning is hard! Where do you start? Wouldn't it be great
    if we had a way to ease the burden of searching through such an ample spectrum
    of combinations?
  prefs: []
  type: TYPE_NORMAL
- en: Well, it exists! It's called **Automatic Machine Learning** (**AutoML**), and
    in this chapter, we'll learn how to leverage one of the most promising tools in
    this field, built on top of TensorFlow, known as **AutoKeras**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple image classifier with AutoKeras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a simple image regressor with AutoKeras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exporting and importing a model in AutoKeras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling architecture generation with AutoKeras' AutoModel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting age and gender with AutoKeras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the first things you''ll notice is that **AutoML** is very resource-intensive,
    so accessing a **GPU** is a must if you want to replicate and extend the recipes
    we''ll discuss in this chapter. Also, because we''ll be using **AutoKeras** in
    all the examples provided, install it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The **AutoKeras** version we'll be using in this chapter only works with TensorFlow
    2.3, so ensure you have it installed as well (if you prefer, you can create a
    different environment altogether). In the *Getting ready* section of each recipe,
    you'll find any preparatory information needed. As usual, the code shown in this
    chapter is available at [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch11](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch11).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following link to see the Code in Action video:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/2Na6XRz](https://bit.ly/2Na6XRz).'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple image classifier with AutoKeras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image classification must be the de facto application of neural networks for
    computer vision. However, as we know, depending on the complexity of the dataset,
    the availability of information, and countless other factors, the process of creating
    a proper image classifier can be quite cumbersome at times.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll implement an image classifier effortlessly thanks to the
    magic of **AutoML**. Don't believe me? Let's begin and see for ourselves!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this recipe, you''ll have implemented an image classifier in
    a dozen lines of code or less! Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For the sake of simplicity, we'll use the well-known `Fashion-MNIST` dataset,
    a more challenging version of the famous `MNIST`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load the train and test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Normalize the images to the range [0, 1]:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the number of epochs we''ll allow each possible network (known as a
    trial) to train:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s where the magic happens. Define an instance of `ImageClassifier()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that we are seeding the classifier with 9 and allowing it to find a suitable
    network 10 times. We're doing this so that the **Neural Architecture Search**
    (**NAS**) process terminates in a reasonable amount of time (to learn more about
    **NAS**, please refer to the *See also* section).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fit the classifier on the test data over 10 epochs (per trial):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, evaluate the best classifier on the test set and print out the accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After a while (let's not forget the library is training 10 models with varying
    complexity), we should obtain an accuracy of 93%, give or take. That's not bad,
    considering we didn't even write 10 lines of code!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We'll discuss what we've done a bit more in the *How it works…* section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we created the most effortless image classifier ever! We delegated
    all major decisions to the **AutoML** tool, **AutoKeras**. From selecting an architecture,
    to which optimizer to use, all such decisions were made by the framework.
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that we limited the search space by specifying a maximum
    of 10 trials and 10 epochs per trial. We did this so that the program terminates
    in a reasonable amount of time, but as you might suspect, these parameters can
    also be trusted to **AutoKeras**.
  prefs: []
  type: TYPE_NORMAL
- en: Despite all the autonomy **AutoML** has, we can guide the framework if we wish.
    What **AutoML** offers is, as its name suggests, a way to automate the search
    for a good enough combination for a particular problem. However, this doesn't
    mean that human expertise and prior knowledge is not necessary. In fact, it is
    often the case that a well-crafted network, typically the product of thoroughly
    studying the data, often performs better than one found by **AutoML** with no
    prior information whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, **AutoML** is a tool, and as such, it should be used to enhance
    our mastery of deep learning, not to replace it – because it can't.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can learn more about **NAS** here: [https://en.wikipedia.org/wiki/Neural_architecture_search](https://en.wikipedia.org/wiki/Neural_architecture_search).'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple image regressor with AutoKeras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The power and usefulness of **AutoKeras** is not limited to image classification.
    Although not as popular, image regression is a similar problem where we want to
    predict a continuous quantity based on the spatial information in an image.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll train an image regressor to predict people's ages while
    using **AutoML**.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We'll be using `APPA-REAL` dataset in this recipe, which contains 7,591 images
    labeled with the real and apparent ages for a wide range of subjects. You can
    read more about the dataset and download it from [http://chalearnlap.cvc.uab.es/dataset/26/description/#](http://chalearnlap.cvc.uab.es/dataset/26/description/#).
    Decompress the data in a directory of your preference. For the purposes of this
    recipe, we'll assume the dataset is located within the `~/.keras/datasets/appa-real-release`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some sample images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Sample images from the APPA-REAL dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – Sample images from the APPA-REAL dataset
  prefs: []
  type: TYPE_NORMAL
- en: Let's implement this recipe!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to complete this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the modules we will be using:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Each subset (train, test, and validation) of the dataset is defined in a CSV
    file. There, among many other columns, we have the path to the image and the real
    age of the person depicted in a photo. In this step, we will define the `load_mapping()`
    function, which will create a map from the image paths to the labels that we''ll
    use to load the actual data in memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `get_image_and_labels()` function, which takes the mapping produced
    by the `load_mapping()` function and returns an array of images (normalized to
    the range [-1, 1]) and an array of the corresponding ages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that each image has been resized so that its dimensions are 64x64x3\.
    This is necessary because the images in the dataset don't have homogeneous dimensions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the paths to the CSV files to create the data mappings for each subset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the paths to the directories where the images for each subset live:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the mappings for each subset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the images and labels for each subset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll train each network in a trial for a maximum of 15 epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We instantiate an `ImageRegressor()` object, which encapsulates the `adam`
    as the optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the regressor. Notice that we are passing our own validation set. If we
    don''t do this, **AutoKeras** takes 20% of the training data to validate its experiments
    by default:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we must evaluate the best regressor on the test data and print its
    performance metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After a while, we should obtain a test loss of 241.248, which is not bad if
    we take into account that the bulk of our work consisted of loading the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's move on to the *How it works…* section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we delegated the creation of a model to an **AutoML** framework,
    similar to what we did in the *Creating a simple image classifier with AutoKeras*
    recipe. However, this time, our goal was to solve a regression problem, namely
    predicting the age of a person based on a photo of their face, instead of a classification
    one.
  prefs: []
  type: TYPE_NORMAL
- en: This time, because we used a real-world dataset, we had to implement several
    helper functions to load the data and make it the proper shape for **AutoKeras**
    to use it. However, after doing this, we let the framework take the wheel, leveraging
    its built-in **NAS** algorithm to find the best possible model in a span of 15
    iterations.
  prefs: []
  type: TYPE_NORMAL
- en: We obtained a respectable 241.248 loss on the test set. Predicting the age of
    a person is not an easy task, even though it might appear that it is at first.
    I invite you to take a closer look at the *APPA-REAL* CSV files so that you can
    see the deviation in the human estimates of people's ages!
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can learn more about **NAS** here: [https://en.wikipedia.org/wiki/Neural_architecture_search](https://en.wikipedia.org/wiki/Neural_architecture_search).'
  prefs: []
  type: TYPE_NORMAL
- en: Exporting and importing a model in AutoKeras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One worry we might have when working with **AutoML** is the black-box nature
    of the tools available. Do we have control over the produced models? Can we extend
    them? Understand them? Reuse them?
  prefs: []
  type: TYPE_NORMAL
- en: Of course we can! The good thing about **AutoKeras** is that it is built on
    top of TensorFlow, so despite its sophistication, under the hood, the models being
    trained are just TensorFlow graphs that we can export and tweak and tune later
    if we need to.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll learn how to export a model trained on **AutoKeras**,
    and then import it as a plain old TensorFlow network.
  prefs: []
  type: TYPE_NORMAL
- en: Are you ready? Let's begin.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to complete this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the train and test splits of the `Fashion-MNIST` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Normalize the data to the [0, 1] interval:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the number of epochs we''ll train each network for:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `ImageClassifier()` that''ll try to find to best possible classifier,
    over 20 trials, with each one trained for 10 epochs. We will instruct `adam` as
    the optimizer and seed `ImageClassifier()` for the sake of reproducibility:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the classifier. We''ll allow **AutoKeras** to automatically pick 20% of
    the training data for validation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Export the best model and save it to disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the model back into memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate the training model on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print a text summary of the best model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, generate a graph of the architecture of the best model found by **AutoKeras**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After 20 trials, the best model that was created by **AutoKeras** achieves
    91.5% accuracy on the test set. The following screenshot shows the model''s summary:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.2 – AutoKeras'' best model summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 – AutoKeras' best model summary
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the model''s architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – AutoKeras'' best model architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 – AutoKeras' best model architecture
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 11.2*, we can see the network **AutoKeras** deemed the most suitable
    for **Fashion-MNIST**, at least within the bounds we established. You can take
    a closer look at the full architecture in the companion GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we demonstrated that **AutoML** can work as a great starting
    point when we're tackling a new computer vision problem. How? We can use it to
    produce well-performing models out of the gate, which we can then extend based
    on our domain knowledge of the dataset at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula to do this is straightforward: let **AutoML** do the grunt work
    for a while; then, export the best network and import it into the confines of
    TensorFlow so that you can build your solution on top of it.'
  prefs: []
  type: TYPE_NORMAL
- en: This not only showcases the usability of tools such as **AutoKeras**, but allows
    us to peak behind the curtain, understanding the building blocks of the models
    engendered by **NAS**.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The basis of **AutoKeras** is **NAS**. You can read more about it here (it''s
    pretty interesting!): [https://en.wikipedia.org/wiki/Neural_architecture_search](https://en.wikipedia.org/wiki/Neural_architecture_search).'
  prefs: []
  type: TYPE_NORMAL
- en: Controlling architecture generation with AutoKeras' AutoModel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letting **AutoKeras** automagically figure out what architecture works best
    is great, but it can be time-consuming – unacceptably so at times.
  prefs: []
  type: TYPE_NORMAL
- en: Can we exert more control? Can we hint at which options work best for our particular
    problem? Can we meet **AutoML** halfway by providing a set of guidelines it must
    follow according to our prior knowledge or preference, but still give it enough
    leeway to experiment?
  prefs: []
  type: TYPE_NORMAL
- en: Yes, we can, and in this recipe, you'll learn how by utilizing a special feature
    in **AutoKeras** known as AutoModel!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to learn how to customize the search space of the `AutoModel`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we need to do is import all the necessary dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Because we''ll be training our customized model on `Fashion-MNIST`, we must
    load the train and test splits, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To avoid numerical instability issues, let''s normalize the images of both
    splits so that they''re in the range [0, 1]:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `create_automodel()` function, which defines the custom search space
    of the underlying `Block` is in charge of a defined task, such as image augmentation,
    normalization, image processing, or classification. First, we must define the
    input block, which will be normalized and augmented through the `Normalization()`
    and `ImageAugmentation()` blocks, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that we disabled horizontal and vertical flipping in the `ImageAugmentation()`
    block. This is because these operations alter the class of images in `Fashion-MNIST`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we''ll bifurcate the graph. The left branch searches for vanilla convolutional
    layers, thanks to `ConvBlock()`. On the right branch, we''ll explore more sophisticated
    Xception-like architectures (for more information about the **Xception** architecture,
    refer to the *See also* section):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the previous snippet, we instructed **AutoKeras** to only explore **Xception**
    architectures pre-trained on ImageNet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We''ll merge the left and right branches, flatten them, and pass the result
    through a `DenseBlock()`, which, as its name suggests, searches for fully connected
    combinations of layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this graph will be a `ClassificationHead()`. This is because
    we''re dealing with a classification problem. Notice that we don''t specify the
    number of classes. This is because **AutoKeras** infers this information from
    the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can close `create_automodel()` by building and returning an `AutoModel()`
    instance. We must specify the inputs and outputs, as well as the maximum number
    of trials to perform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s train each trial model for 10 epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `AutoModel` and fit it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s export the best model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Evaluate the model on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the architecture of the best model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final architecture I obtained achieved 90% accuracy on the test set, although
    your results may vary. What''s even more interesting is the structure of the generated
    model:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.4 – AutoKeras'' best model architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.4 – AutoKeras' best model architecture
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram reveals that `AutoModel` produced a network according
    to the blueprint we laid out in `create_automodel()`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's move on to the *How it works…* section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we took advantage of `AutoModel` module to trim down the search
    space. This is a very useful feature when we have an idea of what our final model
    should look like. This leads to huge time gains because we don't allow **AutoKeras**
    to waste time trying out unfruitful, useless combinations. One example of such
    bad combinations can be seen in *Step 4*, where we told **AutoKeras** not to try
    to flip images as part of its image augmentation scheme. This is because, due
    to the characteristics of our problem, this operation changes the classes of the
    numbers in **Fashion-MNIST**.
  prefs: []
  type: TYPE_NORMAL
- en: Proof that we steered `create_automodel()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Impressive, right?
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One thing we didn''t do here is implement our own `Block`, which is possible
    in **AutoKeras**. Why don''t you give it a try? You can start by reading the docs
    here: [https://autokeras.com/tutorial/customized/](https://autokeras.com/tutorial/customized/).
    For a list of all available blocks, go to [https://autokeras.com/block/](https://autokeras.com/block/).
    In this recipe, we used Xception-like layers. To find out more about Xception,
    you can read the original paper: [https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357).'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting age and gender with AutoKeras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we'll study a practical application of AutoML that can be used
    as a template to create prototypes, MVPs, or just to tackle real-world applications
    with the help of AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: 'More concretely, we''ll create an age and gender classification program with
    a twist: the architecture of both the gender and age classifiers will be the responsibility
    of **AutoKeras**. We''ll be in charge of getting and shaping the data, as well
    as creating the framework to test the solution on our own images.'
  prefs: []
  type: TYPE_NORMAL
- en: I hope you're ready because we are about to begin!
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We need a couple of external libraries, such as OpenCV, `scikit-learn`, and
    `imutils`. All these dependencies can be installed at once, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: On the data side, we'll use the **Adience** dataset, which contains 26,580 images
    of 2,284 subjects, along with their gender and age. To download the data, go to
    [https://talhassner.github.io/home/projects/Adience/Adience-data.html](https://talhassner.github.io/home/projects/Adience/Adience-data.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you''ll need to navigate to the **Download** section and enter your name
    and email, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Enter your information to receive the credentials of the FTP
    server where the data is'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.5 – Enter your information to receive the credentials of the FTP server
    where the data is
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you hit the **Submit** button, you''ll get the credentials required for
    the FTP server where the data is located. You can access this here: [http://www.cslab.openu.ac.il/download/](http://www.cslab.openu.ac.il/download/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure that you click on the first link, labeled **Adience OUI Unfiltered
    faces for gender and age classification**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Going to the highlighted link'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.6 – Going to the highlighted link
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the credentials you received previously and access the second link, named
    **AdienceBenchmarkOfUnfilteredFacesForGenderAndAgeClassification**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Clicking the highlighted link'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_007.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.7 – Clicking the highlighted link
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, download `aligned.tar.gz`, `fold_frontal_0_data.txt`, `fold_frontal_1_data.txt`,
    `fold_frontal_2_data.txt`, `fold_frontal_3_data.txt`, `and fold_frontal_4_data.txt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Downloading aligned.tar.gz and all the fold_frontal_*_data.txt
    files'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.8 – Downloading aligned.tar.gz and all the fold_frontal_*_data.txt
    files
  prefs: []
  type: TYPE_NORMAL
- en: Unzip `aligned.tar.gz` into a directory of your preference as `adience`. Inside
    that directory, create a subdirectory named `folds`, and move all the `fold_frontal_*_data.txt`
    files inside it. For the purposes of this recipe, we'll assume the dataset is
    located within `~/.keras/datasets/adience`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some sample images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – Sample images from the Adience dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_11_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.9 – Sample images from the Adience dataset
  prefs: []
  type: TYPE_NORMAL
- en: Let's implement this recipe!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Complete these steps to implement an age and gender classifier using **AutoML**:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we need to do is import all the necessary dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the base path to the `Adience` dataset, as well as the folds (which
    contain the relationships between the images and the ages and genders of their
    subjects, in CSV format):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The ages in `Adience` are expressed as intervals, groups, or brackets. Here,
    we will define an array that we will use to map the reported age in the folds
    to the correct bracket:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `age_to_bin()` function, which takes an input as it appears in a
    fold CSV row and maps it to the corresponding bin. For instance, if the input
    is `(27, 29)`, the output will be `25_32`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will compute the area of a rectangle. We''ll use this
    later to get the largest face detection possible:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''ll also draw a bounding box around the detected face, captioned with the
    recognized age and gender:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `predict()` function, which we''ll use to predict both the age and
    gender (depending on `model`) of a person whose face was passed into the `roi`
    parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the lists where we''ll store all the images, ages, and genders of the
    dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Iterate over each fold file. These will be in CSV format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If the age or gender fields are not well-defined, skip the current line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Map the age to a valid bin. If we get `None` from `age_to_bin()`, this means
    the age doesn''t correspond to any of our defined categories, so we must skip
    this record:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Append the image, age, and gender to the corresponding collections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two copies of the images, one for each problem (age classification and
    gender prediction):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Encode the age and genders:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the number of trials and epochs per trial. These parameters affect both
    models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If there''s a trained version of the age classifier, load it; otherwise, train
    an `ImageClassifier()` from scratch and save it to disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If there''s a trained version of the gender classifier, load it; otherwise,
    train an `ImageClassifier()` from scratch and save it to disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read a test image from disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a **Haar Cascades** face detector. (This is a topic outside the scope
    of this book. If you want to learn more about Haar Cascades, go to the *See also*
    section of this recipe.) Use the following code to do so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Resize the image so that it is 380 pixels wide. Thanks to the `imutils.resize()`
    function, we can rest assured that the result will preserve the aspect ratio.
    This is because the function computes the height automatically to guarantee this
    condition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a copy of the original image so that we can draw the detections on it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the image into grayscale and pass it through the face detector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify whether there are detections and fetch the one with the largest area:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the region of interest (`roi`) corresponding to the detected face and
    extract its age and gender:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice that we use each encoder to revert back to a human-readable label for
    both the predicted age and gender.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot the predicted age and gender on the original image and show the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The first time you execute this script, you'll have to wait a very long time
    – probably more than 24 hours (depending on your hardware). This is because each
    model is trained for a high number of trials and epochs. However, subsequent runs
    should be way faster because the program will load the trained classifiers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can see an example of a successful prediction of both age and gender in
    the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.10 – Our models state the person in the photo is female and is
    between 25 and 32 years of age. Seems about right, doesn''t it?](img/B14768_11_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – Our models state the person in the photo is female and is between
    25 and 32 years of age. Seems about right, doesn't it?
  prefs: []
  type: TYPE_NORMAL
- en: Isn't it truly amazing how the heavy lifting was done by **AutoKeras**? We're
    living in the future!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we implemented a practical solution to a surprisingly challenging
    problem: age and gender prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: Why is this challenging? The apparent age of a person can vary, depending on
    multiple factors, such as ethnicity, gender, health, and other life conditions.
    We humans are not as great as we think we are at estimating the age of a man or
    a woman based solely on their physical features.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, a mostly healthy 25-year-old person will look vastly different
    than another 25-year-old that's a heavy drinker and smoker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Either way, we trusted the power of **AutoML** to find two models: one for
    gender classification and another for age prediction. We must highlight that,
    in this case, we framed age prediction as a classification problem instead of
    a regression one. This is because it makes it a bit easier to select an age range
    instead of producing a precise quantity.'
  prefs: []
  type: TYPE_NORMAL
- en: After a long wait (we trained both models over 100 epochs per trial), we obtained
    two competent networks that we integrated into a framework that automatically
    detects a face in a photo, and using these models, tags them with the predicted
    age and gender.
  prefs: []
  type: TYPE_NORMAL
- en: As you may have noticed, we relied on `ImageClassifier()`, which means we gave
    100% control of the network creation process to `AutoModel` to narrow down the
    search space, therefore arriving at potentially better solutions at a fraction
    of the time. Why don't you give it a try?
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Read the following paper to learn how the authors of the **Adience** dataset
    solve this problem: [https://talhassner.github.io/home/projects/cnn_agegender/CVPR2015_CNN_AgeGenderEstimation.pdf](https://talhassner.github.io/home/projects/cnn_agegender/CVPR2015_CNN_AgeGenderEstimation.pdf).
    To learn more about the Haar Cascade classifier we used previously, read this
    tutorial: [https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html](https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html).'
  prefs: []
  type: TYPE_NORMAL
