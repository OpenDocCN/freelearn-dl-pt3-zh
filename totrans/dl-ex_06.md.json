["```\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist_dataset = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n```", "```\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random as ran\n```", "```\n#Define some helper functions \n# to assign the size of training and test data we will take from MNIST dataset\ndef train_size(size):\n    print ('Total Training Images in Dataset = ' + str(mnist_dataset.train.images.shape))\n    print ('############################################')\n    input_values_train = mnist_dataset.train.images[:size,:]\n    print ('input_values_train Samples Loaded = ' + str(input_values_train.shape))\n    target_values_train = mnist_dataset.train.labels[:size,:]\n    print ('target_values_train Samples Loaded = ' + str(target_values_train.shape))\n    return input_values_train, target_values_train\n\ndef test_size(size):\n    print ('Total Test Samples in MNIST Dataset = ' + str(mnist_dataset.test.images.shape))\n    print ('############################################')\n    input_values_test = mnist_dataset.test.images[:size,:]\n    print ('input_values_test Samples Loaded = ' + str(input_values_test.shape))\n    target_values_test = mnist_dataset.test.labels[:size,:]\n    print ('target_values_test Samples Loaded = ' + str(target_values_test.shape))\n    return input_values_test, target_values_test\n```", "```\n#Define a couple of helper functions for digit images visualization\ndef visualize_digit(ind):\n    print(target_values_train[ind])\n    target = target_values_train[ind].argmax(axis=0)\n    true_image = input_values_train[ind].reshape([28,28])\n    plt.title('Sample: %d Label: %d' % (ind, target))\n    plt.imshow(true_image, cmap=plt.get_cmap('gray_r'))\n    plt.show()\n\ndef visualize_mult_imgs_flat(start, stop):\n    imgs = input_values_train[start].reshape([1,784])\n    for i in range(start+1,stop):\n        imgs = np.concatenate((imgs, input_values_train[i].reshape([1,784])))\n    plt.imshow(imgs, cmap=plt.get_cmap('gray_r'))\n    plt.show()\n```", "```\ninput_values_train, target_values_train = train_size(55000)\n\nOutput:\nTotal Training Images in Dataset = (55000, 784)\n############################################\ninput_values_train Samples Loaded = (55000, 784)\ntarget_values_train Samples Loaded = (55000, 10)\n```", "```\nvisualize_digit(ran.randint(0, input_values_train.shape[0]))\n\nOutput:\n```", "```\nvisualize_mult_imgs_flat(0,400)\n```", "```\nsess = tf.Session()\n```", "```\ninput_values = tf.placeholder(tf.float32, shape=[None, 784]\n```", "```\noutput_values = tf.placeholder(tf.float32, shape=[None, 10])\n```", "```\nweights = tf.Variable(tf.zeros([784,10]))\nbiases = tf.Variable(tf.zeros([10]))\n```", "```\nsoftmax_layer = tf.nn.softmax(tf.matmul(input_values,weights) + biases)\n```", "```\nprint(softmax_layer)\nOutput:\nTensor(\"Softmax:0\", shape=(?, 10), dtype=float32)\n```", "```\ninput_values_train, target_values_train = train_size(3)\nsess.run(tf.global_variables_initializer())\n#If using TensorFlow prior to 0.12 use:\n#sess.run(tf.initialize_all_variables())\nprint(sess.run(softmax_layer, feed_dict={input_values: input_values_train}))\n```", "```\nOutput:\n\n[[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]\n [ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]\n [ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]]\n```", "```\nsess.run(tf.nn.softmax(tf.zeros([4])))\nsess.run(tf.nn.softmax(tf.constant([0.1, 0.005, 2])))\n\nOutput:\narray([0.11634309, 0.10579926, 0.7778576 ], dtype=float32)\n```", "```\nmodel_cross_entropy = tf.reduce_mean(-tf.reduce_sum(output_values * tf.log(softmax_layer), reduction_indices=[1]))\n```", "```\nj = [0.03, 0.03, 0.01, 0.9, 0.01, 0.01, 0.0025,0.0025, 0.0025, 0.0025]\n```", "```\nk = [0,0,0,1,0,0,0,0,0,0]\n```", "```\n-np.log(j)\n-np.multiply(np.log(j),k)\n```", "```\nk = [0,0,1,0,0,0,0,0,0,0]\nnp.sum(-np.multiply(np.log(j),k))\n```", "```\ninput_values_train, target_values_train = train_size(5500)\ninput_values_test, target_values_test = test_size(10000)\nlearning_rate = 0.1\nnum_iterations = 2500\n```", "```\ninit = tf.global_variables_initializer()\n#If using TensorFlow prior to 0.12 use:\n#init = tf.initialize_all_variables()\nsess.run(init)\n```", "```\ntrain = tf.train.GradientDescentOptimizer(learning_rate).minimize(model_cross_entropy)\nmodel_correct_prediction = tf.equal(tf.argmax(softmax_layer,1), tf.argmax(output_values,1))\nmodel_accuracy = tf.reduce_mean(tf.cast(model_correct_prediction, tf.float32))\n```", "```\nfor i in range(num_iterations+1):\n    sess.run(train, feed_dict={input_values: input_values_train, output_values: target_values_train})\n    if i%100 == 0:\n        print('Training Step:' + str(i) + ' Accuracy = ' + str(sess.run(model_accuracy, feed_dict={input_values: input_values_test, output_values: target_values_test})) + ' Loss = ' + str(sess.run(model_cross_entropy, {input_values: input_values_train, output_values: target_values_train})))\n\nOutput:\nTraining Step:0 Accuracy = 0.5988 Loss = 2.1881988\nTraining Step:100 Accuracy = 0.8647 Loss = 0.58029664\nTraining Step:200 Accuracy = 0.879 Loss = 0.45982164\nTraining Step:300 Accuracy = 0.8866 Loss = 0.40857208\nTraining Step:400 Accuracy = 0.8904 Loss = 0.37808096\nTraining Step:500 Accuracy = 0.8943 Loss = 0.35697535\nTraining Step:600 Accuracy = 0.8974 Loss = 0.34104997\nTraining Step:700 Accuracy = 0.8984 Loss = 0.32834956\nTraining Step:800 Accuracy = 0.9 Loss = 0.31782663\nTraining Step:900 Accuracy = 0.9005 Loss = 0.30886236\nTraining Step:1000 Accuracy = 0.9009 Loss = 0.3010645\nTraining Step:1100 Accuracy = 0.9023 Loss = 0.29417014\nTraining Step:1200 Accuracy = 0.9029 Loss = 0.28799513\nTraining Step:1300 Accuracy = 0.9033 Loss = 0.28240603\nTraining Step:1400 Accuracy = 0.9039 Loss = 0.27730304\nTraining Step:1500 Accuracy = 0.9048 Loss = 0.27260992\nTraining Step:1600 Accuracy = 0.9057 Loss = 0.26826677\nTraining Step:1700 Accuracy = 0.9062 Loss = 0.2642261\nTraining Step:1800 Accuracy = 0.9061 Loss = 0.26044932\nTraining Step:1900 Accuracy = 0.9063 Loss = 0.25690478\nTraining Step:2000 Accuracy = 0.9066 Loss = 0.2535662\nTraining Step:2100 Accuracy = 0.9072 Loss = 0.25041154\nTraining Step:2200 Accuracy = 0.9073 Loss = 0.24742197\nTraining Step:2300 Accuracy = 0.9071 Loss = 0.24458146\nTraining Step:2400 Accuracy = 0.9066 Loss = 0.24187621\nTraining Step:2500 Accuracy = 0.9067 Loss = 0.23929419\n```", "```\nfor i in range(10):\n    plt.subplot(2, 5, i+1)\n    weight = sess.run(weights)[:,i]\n    plt.title(i)\n    plt.imshow(weight.reshape([28,28]), cmap=plt.get_cmap('seismic'))\n    frame = plt.gca()\n    frame.axes.get_xaxis().set_visible(False)\n    frame.axes.get_yaxis().set_visible(False)\n```", "```\ninput_values_train, target_values_train = train_size(1)\nvisualize_digit(0)\n\nOutput:\nTotal Training Images in Dataset = (55000, 784)\n############################################\ninput_values_train Samples Loaded = (1, 784)\ntarget_values_train Samples Loaded = (1, 10)\n[0\\. 0\\. 0\\. 0\\. 0\\. 0\\. 0\\. 1\\. 0\\. 0.]\n```", "```\nanswer = sess.run(softmax_layer, feed_dict={input_values: input_values_train})\nprint(answer)\n```", "```\n[[2.1248012e-05 1.1646927e-05 8.9631692e-02 1.9201526e-02 8.2086492e-04\n  1.2516821e-05 3.8538201e-05 8.5374612e-01 6.9188857e-03 2.9596921e-02]]\n```", "```\nanswer.argmax()\n\nOutput:\n7\n```", "```\ndef display_result(ind):\n\n    # Loading a training sample\n    input_values_train = mnist_dataset.train.images[ind,:].reshape(1,784)\n    target_values_train = mnist_dataset.train.labels[ind,:]\n\n    # getting the label as an integer instead of one-hot encoded vector\n    label = target_values_train.argmax()\n\n    # Getting the prediction as an integer\n    prediction = sess.run(softmax_layer, feed_dict={input_values: input_values_train}).argmax()\n    plt.title('Prediction: %d Label: %d' % (prediction, label))\n    plt.imshow(input_values_train.reshape([28,28]), cmap=plt.get_cmap('gray_r'))\n    plt.show()\n```", "```\ndisplay_result(ran.randint(0, 55000))\n\nOutput:\n```"]