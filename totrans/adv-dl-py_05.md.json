["```\nimport tensorflow as tf\n\n# VGG16\nvgg16 = tf.keras.applications.vgg16.VGG16(include_top=True,\n                                          weights='imagenet',\n                                          input_tensor=None,\n                                          input_shape=None,\n                                          pooling=None,\n                                          classes=1000)\n\n# VGG19 \nvgg19 = tf.keras.applications.vgg19.VGG19(include_top=True,\n                                          weights='imagenet',\n                                          input_tensor=None,\n                                          input_shape=None,\n                                          pooling=None,\n                                          classes=1000)\n```", "```\nimport torchvision.models as models\nmodel = models.vgg16(pretrained=True)\n```", "```\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms\n```", "```\nclass PreActivationBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_slices, slices, stride=1):\n        super(PreActivationBlock, self).__init__()\n\n        self.bn_1 = nn.BatchNorm2d(in_slices)\n\n                                out_channels=slices,kernel_size=3, \n                                stride=stride, padding=1,\n                                bias=False)\n\n        self.bn_2 = nn.BatchNorm2d(slices)\n        self.conv_2 = nn.Conv2d(in_channels=slices, \n                                out_channels=slices,kernel_size=3, \n                                stride=1, padding=1,\n                                bias=False)\n\n        # if the input/output dimensions differ use convolution for \n        the shortcut\n        if stride != 1 or in_slices != self.expansion * slices:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels=in_slices,\n                          out_channels=self.expansion * slices,\n                          kernel_size=1,\n                          stride=stride,\n                          bias=False)\n            )\n```", "```\ndef forward(self, x):\n    out = F.relu(self.bn_1(x))\n\n    # reuse bn+relu in downsampling layers\n    shortcut = self.shortcut(out) if hasattr(self, 'shortcut')\n    else x\n\n    out = self.conv_1(out)\n\n    out = F.relu(self.bn_2(out))\n    out = self.conv_2(out)\n\n    out += shortcut\n\n    return out\n```", "```\nclass PreActivationBottleneckBlock(nn.Module):\n    expansion = 4\n    def __init__(self, in_slices, slices, stride=1):\n        super(PreActivationBottleneckBlock, self).__init__()\n\n        self.bn_1 = nn.BatchNorm2d(in_slices)\n        self.conv_1 = nn.Conv2d(in_channels=in_slices, \n                                out_channels=slices, kernel_size=1,\n                                bias=False)\n\n        self.bn_2 = nn.BatchNorm2d(slices)\n        self.conv_2 = nn.Conv2d(in_channels=slices, \n                                out_channels=slices, kernel_size=3, \n                                stride=stride, padding=1,\n                                bias=False)\n\n        self.bn_3 = nn.BatchNorm2d(slices)\n        self.conv_3 = nn.Conv2d(in_channels=slices,\n                                out_channels=self.expansion * \n                                slices,\n                                kernel_size=1,\n                                bias=False)\n\n        # if the input/output dimensions differ use convolution for the shortcut\n        if stride != 1 or in_slices != self.expansion * slices:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels=in_slices,\n                          out_channels=self.expansion * slices,\n                          kernel_size=1, stride=stride,\n                          bias=False)\n            )\n```", "```\ndef forward(self, x):\n    out = F.relu(self.bn_1(x))\n\n    #  reuse bn+relu in downsampling layers\n    shortcut = self.shortcut(out) if hasattr(self, 'shortcut') \n    else x\n\n    out = self.conv_1(out)\n\n    out = F.relu(self.bn_2(out))\n    out = self.conv_2(out)\n\n    out = F.relu(self.bn_3(out))\n    out = self.conv_3(out)\n\n    out += shortcut\n\n    return out\n```", "```\nclass PreActivationResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        \"\"\"\n        :param block: type of residual block (regular or \n        bottleneck)\n        :param num_blocks: a list with 4 integer values.\n            Each value reflects the number of residual blocks in \n            the group\n        :param num_classes: number of output classes\n        \"\"\"\n\n        super(PreActivationResNet, self).__init__()\n\n        self.in_slices = 64\n\n        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64,\n                                kernel_size=3, stride=1, padding=1,\n                                bias=False)\n\n        self.layer_1 = self._make_group(block, 64, num_blocks[0], \n        stride=1)\n        self.layer_2 = self._make_group(block, 128, num_blocks[1], \n        stride=2)\n        self.layer_3 = self._make_group(block, 256, num_blocks[2], \n        stride=2)\n        self.layer_4 = self._make_group(block, 512, num_blocks[3], \n        stride=2)\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n```", "```\ndef _make_group(self, block, slices, num_blocks, stride):\n    \"\"\"Create one residual group\"\"\"\n\n    strides = [stride] + [1] * (num_blocks - 1)\n    layers = []\n    for stride in strides:\n        layers.append(block(self.in_slices, slices, stride))\n        self.in_slices = slices * block.expansion\n\n    return nn.Sequential(*layers)\n```", "```\ndef forward(self, x):\n    out = self.conv_1(x)\n    out = self.layer_1(out)\n    out = self.layer_2(out)\n    out = self.layer_3(out)\n    out = self.layer_4(out)\n    out = F.avg_pool2d(out, 4)\n    out = out.view(out.size(0), -1)\n    out = self.linear(out)\n\n    return out\n```", "```\ndef PreActivationResNet34():\n    return PreActivationResNet(block=PreActivationBlock,\n                               num_blocks=[3, 4, 6, 3])\n```", "```\n# training data transformation\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4821, 0.4465), (0.2470, 0.2435, \n    0.2616))\n])\n\n# training data loader\ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, \n                                        transform=transform_train)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_set, \n                                        batch_size=100,\n                                        shuffle=True, \n                                        num_workers=2)\n\n# test data transformation\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4821, 0.4465), (0.2470, 0.2435, \n    0.2616))\n])\n\n# test data loader\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                        download=True, \n                                        transform=transform_test)\n\ntest_loader = torch.utils.data.DataLoader(dataset=testset, \n                                        batch_size=100,\n                                        shuffle=False,\n                                        num_workers=2)\n```", "```\n# load the pretrained model\nmodel = PreActivationResNet34()\n\n# select gpu 0, if available\n# otherwise fallback to cpu\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# transfer the model to the GPU\nmodel = model.to(device)\n\n# loss function\nloss_function = nn.CrossEntropyLoss()\n\n# We'll optimize all parameters\noptimizer = optim.Adam(model.parameters())\n```", "```\n# train\nEPOCHS = 15\n\ntest_acc = list()  # collect accuracy for plotting\nfor epoch in range(EPOCHS):\n    print('Epoch {}/{}'.format(epoch + 1, EPOCHS))\n\n    train_model(model, loss_function, optimizer, train_loader)\n    _, acc = test_model(model, loss_function, test_loader)\n    test_acc.append(acc)\n\nplot_accuracy(test_acc)\n```"]