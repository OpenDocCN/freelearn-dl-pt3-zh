- en: 1\. Introduction to Machine Learning with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn how to create, utilize, and apply linear transformations
    to the fundamental building blocks of programming with TensorFlow: tensors. You
    will then utilize tensors to understand the complex concepts associated with neural
    networks, including tensor reshaping, transposition, and multiplication.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Machine learning** (**ML**) has permeated various aspects of daily life that
    are unknown to many. From the recommendations of your daily social feeds to the
    results of your online searches, they are all powered by machine learning algorithms.
    These algorithms began in research environments solving niche problems, but as
    their accessibility broadened, so too have their applications for broader use
    cases. Researchers and businesses of all types recognize the value of using models
    to optimize every aspect of their respective operations. Doctors can use machine
    learning to decide diagnosis and treatment options, retailers can use ML to get
    the right products to their stores at the right time, and entertainment companies
    can use ML to provide personalized recommendations to their customers.'
  prefs: []
  type: TYPE_NORMAL
- en: In the age of data, machine learning models have proven to be valuable assets
    to any data-driven company. The large quantities of data available allow powerful
    and accurate models to be created to complete a variety of tasks, from regression
    to classification, recommendations to time series analysis, and even generative
    art, many of which will be covered in this workshop. And all can be built, trained,
    and deployed with TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: The TensorFlow API has a huge amount of functionality that has made it popular
    among all machine learning practitioners building machine learning models or working
    with tensors, which are multidimensional numerical arrays. For researchers, TensorFlow
    is an appropriate choice to create new machine learning applications due to its
    advanced customization and flexibility. For developers, TensorFlow is an excellent
    choice of machine learning library due to its ease in terms of deploying models
    from development to production environments. Combined, TensorFlow's flexibility
    and ease of deployment make the library a smart choice for many practitioners
    looking to build performant machine learning models using a variety of different
    data sources and to replicate the results of that learning in production environments.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provides a practical introduction to TensorFlow's API. You will
    learn how to perform mathematical operations pertinent to machine learning that
    will give you a firm foundation for building performant ML models using TensorFlow.
    You will first learn basic operations such as how to create variables with the
    API. Following that, you will learn how to perform linear transformations such
    as addition before moving on to more advanced tasks, including tensor multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Artificial Neural Networks in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The advanced flexibility that TensorFlow offers lends itself well to creating
    **artificial neural networks** (**ANNs**). ANNs are algorithms that are inspired
    by the connectivity of neurons in the brain and are intended to replicate the
    process in which humans learn. They consist of layers through which information
    propagates from the input to the output.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.1* shows a visual representation of an ANN. An input layer is on
    the left-hand side, which, in this example, has two features (`X`1 and `X`2).
    The input layer is connected to the first hidden layer, which has three units.
    All the data from the previous layer gets passed to each unit in the first hidden
    layer. The data is then passed to the second hidden layer, which also has three
    units. Again, the information from each unit of the prior layer is passed to each
    unit of the second hidden layer. Finally, all the information from the second
    hidden layer is passed to the output layer, which has one unit, representing a
    single number for each set of input features.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1: A visual representation of an ANN with two hidden layers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.1: A visual representation of an ANN with two hidden layers'
  prefs: []
  type: TYPE_NORMAL
- en: ANNs have proven to be successful in learning complex and nonlinear relationships
    with large, unstructured datasets, such as audio, images, and text data. While
    the results can be impressive, there is a lot of variability in how ANNs can be
    configured. For example, the number of layers, the size of each layer, and which
    nonlinear function should be used are some of the factors that determine the configuration
    of ANNs. Not only are the classes and functions that TensorFlow provides well-suited
    to building and training ANNs, but the library also supplies a suite of tools
    to help visualize and debug ANNs during the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Compared with traditional machine learning algorithms, such as linear and logistic
    regression, ANNs can outperform them when provided with large amounts of data.
    ANNs are advantageous since they can be fed unstructured data and feature engineering
    is not necessarily required. Data pre-processing can be a time-intensive process.
    Therefore, many practitioners prefer ANNs if there is a large amount of data.
  prefs: []
  type: TYPE_NORMAL
- en: Many companies from all sectors utilize TensorFlow to build ANNs for their applications.
    Since TensorFlow is backed by Google, the company utilizes the library for much
    of its research, development, and production of machine learning applications.
    However, there are many other companies that also use the library. Companies such
    as Airbnb, Coca-Cola, Uber, and GE Healthcare all utilize the library for a variety
    of tasks. The use of ANNs is particularly appealing since they can achieve remarkable
    accuracy if provided with sufficient data and trained appropriately. For example,
    GE Healthcare uses TensorFlow to build ANNs to identify specific anatomy regardless
    of orientation from magnetic resonance images to improve speed and accuracy. By
    using ANNs, they can achieve over 99% accuracy in identifying anatomy in seconds,
    regardless of head rotation, which would otherwise take a trained professional
    much more time.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the number of companies utilizing ANNs is vast, ANNs may not be the most
    appropriate choice for solving all business problems. In such an environment,
    you must answer the following questions to determine whether ANNs are the most
    appropriate choice:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Does the problem have a numerical solution?** Machine learning algorithms,
    ANNs included, generate predicted numerical results based on input data. For example,
    machine learning algorithms may predict a given number, such as the temperature
    of a city given the location and previous weather conditions, or the stock price
    given previous stock prices, or label images into a given number of categories.
    In each of these examples, a numerical output is generated based on the data provided
    and, given enough labeled data, models can perform well. However, when the desired
    result is more abstract, or creativity is needed, such as creating a new song,
    then machine learning algorithms may not be the most appropriate choice, since
    a well-defined numerical solution may not be available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Is there enough appropriately labeled data to train a model?** For a supervised
    learning task, you must have at least some labeled data to train a model. For
    example, if you want to build a model to predict financial stock data for a given
    company, you will first need historical training data. If the company in question
    has not been public for very long, there may not be adequate training data. ANNs
    can often require a lot of data. When working with images, ANNs often need millions
    of training examples to develop accurate, robust models. This may be a determining
    factor for consideration when deciding which algorithm is appropriate for a given
    task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you are aware of what TensorFlow is, consider the following advantages
    and disadvantages of TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are a few of the main advantages of using TensorFlow that many
    practitioners consider when deciding whether to pursue the library for machine
    learning purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Library Management**: There is a large community of practitioners that maintain
    the TensorFlow library to keep it up to date with frequent new releases to help
    fix bugs, add new functions and classes to reflect current advances in the field,
    and add support for multiple programming languages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pipelining**: TensorFlow supports end-to-end model production, from model
    development in highly parallelizable environments that support GPU processing
    to a suite of model deployment tools. Also, there are lightweight libraries in
    TensorFlow that are used for deploying trained TensorFlow models on mobile and
    embedded devices, such as **Internet of Things** (**IoT**) devices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Community Support**: The community of practitioners that use and support
    the library is vast and they support each other, because of which those practitioners
    who are new to the library achieve the results they are looking for easily.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open Source**: TensorFlow is an open source library, and its code base is
    available for anyone to use and modify for their own applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Works with Multiple Languages**: While the library is natively designed for
    Python, models can now be trained and deployed in JavaScript.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disadvantages of TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are a few of the disadvantages of using TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computational Speed**: Since the primary programming language of TensorFlow
    is Python, the library is not as computationally fast as it could be if it were
    native to other languages, such as C++.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Steep Learning Curve**: Compared to other machine learning libraries, such
    as Keras, the learning curve is steeper, and this can make it challenging for
    new practitioners to create their own models outside of given example code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you have understood what TensorFlow is, the next section will demonstrate
    how to use the TensorFlow library using Python.
  prefs: []
  type: TYPE_NORMAL
- en: The TensorFlow Library in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TensorFlow can be used in Python by importing certain libraries. You can import
    libraries in Python using the `import` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding command, you have imported the TensorFlow library and used
    the shorthand `tf`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, you will learn how to import the TensorFlow library and
    check its version so that you can utilize the classes and functions supplied by
    the library, which is an important and necessary first step when utilizing the
    library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.01: Verifying Your Version of TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will load TensorFlow and check which version is installed
    on your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a Jupyter notebook to implement this exercise by typing `jupyter notebook`
    in the terminal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library by entering the following code in the Jupyter
    cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify the version of TensorFlow using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see from the preceding output, the version of TensorFlow is `2.6.0`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The version may vary on your system if you have not set up the environment using
    the steps provided in *Preface*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this exercise, you successfully imported TensorFlow. You have also checked
    which version of TensorFlow is installed on your system.
  prefs: []
  type: TYPE_NORMAL
- en: This task can be done for any imported library in Python and is useful for debugging
    and referencing documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The potential applications of using TensorFlow are numerous, and it has already
    achieved impressive results, as evidenced by the results from companies such as
    Airbnb, which uses TensorFlow to classify images on their platform, to GE Healthcare,
    which uses TensorFlow to identify anatomy on MRIs of the brain. To learn how to
    create powerful models for your own applications, you first must learn the basic
    mathematical principles and operations that make up the machine learning models
    that can be achieved in TensorFlow. The mathematical operations can be intimidating
    to new users, but a comprehensive understanding of how they operate is key to
    making performant models.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Tensors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tensors can be thought of as the core components of ANNs—the input data, output
    predictions, and weights that are learned throughout the training process are
    all tensors. Information propagates through a series of linear and nonlinear transformations
    to turn the input data into predictions. This section demonstrates how to apply
    linear transformations such as additions, transpositions, and multiplications
    to tensors. Other linear transformations, such as rotations, reflections, and
    shears, also exist. However, their applications as they pertain to ANNs are less common.
  prefs: []
  type: TYPE_NORMAL
- en: Scalars, Vectors, Matrices, and Tensors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Tensors can be represented as multi-dimensional arrays. The number of dimensions
    a tensor spans is known as the tensor''s rank. Tensors with ranks `0`, `1`, and
    `2` are used often and have their own names, which are **scalars**, **vectors**,
    and **matrices**, respectively, although the term *tensors* can be used to describe
    each of them. *Figure 1.2* shows some examples of tensors of various ranks. From
    left to right are a scalar, vector, matrix, and a 3-dimensional tensor, where
    each element represents a different number, and the subscript represents the location
    of the element in the tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2: A visual representation of a scalar, vector, matrix, and tensor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.2: A visual representation of a scalar, vector, matrix, and tensor'
  prefs: []
  type: TYPE_NORMAL
- en: 'The formal definitions of a scalar, vector, matrix, and tensor are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalar**: A scalar consists of a single number, making it a zero-dimensional
    array. It is an example of zero-order tensors. Scalars do not have any axes. For
    instance, the width of an object is a scalar.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vector**: Vectors are one-dimensional arrays and are an example of first-order
    tensors. They can be considered lists of values. Vectors have one axis. The size
    of a given object denoted by the width, height, and depth is an example of a vector field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matrix**: Matrices are two-dimensional arrays with two axes. They are an
    example of second-order tensors. Matrices might be used to store the size of several
    objects. Each dimension of the matrix comprises the size of each object (width,
    height, depth) and the other matrix dimension is used to differentiate between objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`3` or more. A tensor can be used to store the size of many objects and their
    locations over time. The first dimension of the matrix comprises the size of each
    object (width, height, depth), the second dimension is used to differentiate between
    the objects, and the third dimension describes the location of these objects over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tensors can be created using the `Variable` class present in the TensorFlow
    library and passing in a value representing the tensor. A float or integer can
    be passed for scalars, a list of floats or integers can be passed for vectors,
    a nested list of floats or integers for matrices, and so on. The following command
    demonstrates the use of the `Variable` class where a list of the intended values
    for the tensor as well as any other attributes that are required to be explicitly
    defined are passed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The resultant `Variable` object has several attributes that may be commonly
    called, and these are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dtype`: The datatype of the `Variable` object (for the tensor defined above,
    the datatype is `tf.int32`). The default value for this attribute is determined
    from the values passed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`shape`: The number of dimensions and length of each dimension of the `Variable`
    object (for the tensor defined above, the shape is `[3]`). The default value for
    this attribute is also determined from the values passed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: The name of the `Variable` object (for the tensor defined above, the
    name of the tensor is defined as `''my_tensor''`). The default for this attribute
    is `Variable`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trainable`: This attribute indicates whether the `Variable` object can be
    updated during model training (for the tensor defined above, the `trainable` parameter
    is set to `true`). The default for this attribute is `true`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can read more about the attributes of the `Variable` object here: [https://www.tensorflow.org/api_docs/python/tf/Variable](https://www.tensorflow.org/api_docs/python/tf/Variable).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `shape` attribute of the `Variable` object can be called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `shape` attribute gives the shape of the tensor, that is, is it a scalar,
    vector, matrix, and so on. The output of the preceding command will be `[3]` since
    the tensor has a single dimension with three values along that dimension.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rank of a tensor can be determined in TensorFlow using the `rank` function.
    It can be used by passing the tensor as the single argument to the function and
    the result will be an integer value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The output of the following command will be a zero-dimensional integer tensor
    representing the rank of the input. In this case, the rank of `tensor1` will be
    `1` as the tensor has only one dimension.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, you will learn how to create tensors of various ranks
    using TensorFlow's `Variable` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.02: Creating Scalars, Vectors, Matrices, and Tensors in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The votes cast for different candidates of three different political parties
    in districts A and B are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3: Votes cast for different candidates of three different political'
  prefs: []
  type: TYPE_NORMAL
- en: parties in districts A and B](img/B16341_01_03.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.3: Votes cast for different candidates of three different political
    parties in districts A and B'
  prefs: []
  type: TYPE_NORMAL
- en: 'You are required to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a scalar to store the votes cast for `Candidate 1` of political party
    `X` in district `A`, that is, `4113`, and check its shape and rank.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a vector to represent the proportion of votes cast for three different
    candidates of political party `X` in district `A` and check its shape and rank.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a matrix to represent the votes cast for three different candidates of
    political parties `X` and `Y` and check its shape and rank.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a tensor to represent the votes cast for three different candidates in
    two different districts, for three political parties, and check its shape and
    rank.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an integer variable using TensorFlow''s `Variable` class and pass `4113`
    to represent the number of votes cast for a particular candidate. Also, pass `tf.int16`
    as a second argument to ensure that the input number is an integer datatype. Print
    the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you can see the attributes of the variable created, including the name,
    `Variable:0`, the shape, datatype, and the NumPy representation of the tensor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `rank` function to print the rank of the variable created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see that the rank of the integer variable that was created is `0` from
    the NumPy representation of the tensor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Access the integer variable of the rank by calling the `numpy` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The rank of the scalar is `0`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: All attributes of the result of the `rank` function can be called, including
    the `shape` and `dtype` attributes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Call the `shape` attribute of the integer to find the shape of the tensor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding output signifies that the shape of the tensor has no size, which
    is representative of a scalar.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the `shape` of the scalar variable as a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `vector` variable using TensorFlow''s `Variable` class. Pass a list
    for the vector to represent the proportion of votes cast for three different candidates,
    and pass in a second argument for the datatype as `tf.float32` to ensure that
    it is a `float` datatype. Print the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see that the shape and NumPy attributes are different from the scalar
    variable created earlier. The shape is now `(3,)`, indicating that the tensor
    is one-dimensional with three elements along that dimension.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the rank of the `vector` variable using TensorFlow''s `rank` function
    as a NumPy variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you can see that the rank of the vector variable is `1`, confirming that
    this variable is one-dimensional.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the shape of the `vector` variable as a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a matrix variable using TensorFlow''s `Variable` class. Pass a list
    of lists of integers for the matrix to represent the votes cast for three different
    candidates in two different districts. This matrix will have three columns representing
    the candidates, and two rows representing the districts. Pass in a second argument
    for the datatype as `tf.int32` to ensure that it is an integer datatype. Print
    the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.4: The output of the TensorFlow variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.4: The output of the TensorFlow variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the rank of the matrix variable as a NumPy variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you can see that the rank of the matrix variable is `2`, confirming that
    this variable is two-dimensional.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the shape of the matrix variable as a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a tensor variable using TensorFlow''s `Variable` class. Pass in a triple
    nested list of integers for the tensor to represent the votes cast for three different
    candidates in two different districts, for three political parties. Print the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.5: The output of the TensorFlow variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.5: The output of the TensorFlow variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the rank of the tensor variable as a NumPy variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you can see that the rank of the tensor variable is `3`, confirming that
    this variable is three-dimensional.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the shape of the tensor variable as a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The result shows that the shape of the resulting tensor is a list object.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this exercise, you have successfully created tensors of various ranks from
    political voting data using TensorFlow's `Variable` class. First, you created
    scalars, which are tensors that have a rank of `0`. Next, you created vectors,
    which are tensors with a rank of `1`. Matrices were then created, which are tensors
    of rank `2`. Finally, tensors were created that have rank `3` or more. You confirmed
    the rank of the tensors you created by using TensorFlow's `rank` function and
    verified their shape by calling the tensor's `shape` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will combine tensors to create new tensors using tensor addition.
  prefs: []
  type: TYPE_NORMAL
- en: Tensor Addition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tensors can be added together to create new tensors. You will use the example
    of matrices in this chapter, but the concept can be extended to tensors with any
    rank. Matrices may be added to scalars, vectors, and other matrices under certain
    conditions in a process known as broadcasting. Broadcasting refers to the process
    of array arithmetic on tensors of different shapes.
  prefs: []
  type: TYPE_NORMAL
- en: Two matrices may be added (or subtracted) together if they have the same shape.
    For such matrix-matrix addition, the resultant matrix is determined by the element-wise
    addition of the input matrices. The resultant matrix will therefore have the same
    shape as the two input matrices. You can define the matrix `Z = [Z`ij`]` as the
    matrix sum `Z = X + Y`, where `z`ij = `x`ij `+` `y`ij and each element in `Z`
    is the sum of the same element in `X` and `Y`.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix addition is commutative, which means that the order of `X` and `Y` does
    not matter, that is, `X + Y = Y + X`. Matrix addition is also associative, which means
    that the same result is achieved even when the order of additions is different
    or even if the operation is applied more than once, that is, `X + (Y + Z) = (X
    + Y) + Z`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same matrix addition principles apply to scalars, vectors, and tensors.
    An example is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6: A visual example of matrix-matrix addition'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.6: A visual example of matrix-matrix addition'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scalars can also be added to matrices. Here, each element of the matrix is
    added to the scalar individually, as shown in *Figure 1.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7: A visual example of matrix-scalar addition'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.7: A visual example of matrix-scalar addition'
  prefs: []
  type: TYPE_NORMAL
- en: Addition is an important transformation that can be applied to tensors since
    the transformation occurs so frequently. For example, a common transformation
    in developing ANNs is to add a bias to a layer. This is when a constant tensor
    array of the same size of the ANN layer is added to that layer. Therefore, it
    is important to know how and when this seemingly simple transformation can be
    applied to tensors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensor addition can be performed in TensorFlow by using the `add` function
    and passing in the tensors as arguments, or simply by using the `+` operator as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: In the following exercise, you will perform tensor addition on scalars, vectors,
    and matrices in TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.03: Performing Tensor Addition in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The votes cast for different candidates of three different political parties
    in districts A and B are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8: Votes cast for different candidates of three different political'
  prefs: []
  type: TYPE_NORMAL
- en: parties in districts A and B
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.8: Votes cast for different candidates of three different political
    parties in districts A and B'
  prefs: []
  type: TYPE_NORMAL
- en: 'Your requisite tasks are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Store the total number of votes cast for political party X in district A.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store the total number of votes cast for each political party in district A.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store the total number of votes cast for each political party in both districts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three scalar variables using TensorFlow''s `Variable` class to represent
    the votes cast for three candidates of political party X in district A:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new variable to store the total number of votes cast for political
    party X in district A:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the result of the sum of the two variables as a NumPy variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three vectors to represent the number of votes cast for different political
    parties in district A, each with one row and three columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new variable to store the total number of votes for each political
    party in district A:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the result of the sum of the two variables as a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify that the vector addition is as expected by performing the addition of
    each element of the vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see that the `+` operation on three vectors is simply element-wise addition
    of the vectors.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create three matrices to store the votes cast for candidates of each political
    party in each district:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify that the three tensors have the same shape:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new variable to store the total number of votes cast for each political
    party in both districts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the result of the sum of the two variables as a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output representing the total votes for each
    candidate and each party across districts:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.9: The output of the matrix summation as a NumPy variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.9: The output of the matrix summation as a NumPy variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify that the tensor addition is as expected by performing the addition of
    each element of the vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see that the `+` operation is equivalent to the element-wise addition
    of the three matrices created.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this exercise, you successfully performed tensor addition on data representing
    votes cast for political candidates. The transformation can be applied by using
    the `+` operation. You also verified that addition is performed element by element,
    and that one way to ensure that the transformation is valid is for the tensors
    to have the same rank and shape.
  prefs: []
  type: TYPE_NORMAL
- en: In the following activity, you will further practice tensor addition in TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.01: Performing Tensor Addition in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You work in a company that has three locations, each with two salespersons and
    each location sells three products. You are required to sum the tensors to represent
    the total revenue for each product across locations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.10: Number of different products sold by each salesperson at different
    locations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.10: Number of different products sold by each salesperson at different
    locations'
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps you will take are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the TensorFlow library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create two scalars to represent the total revenue for `Product A` by all salespeople
    at `Location X` using TensorFlow's `Variable` class. The first variable will have
    a value of `2706` and the second will have a value of `2386`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new variable as the sum of the scalars and print the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a vector with values `[2706, 2799, 5102]` and a scalar with the value
    `95` using TensorFlow's `Variable` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new variable as the sum of the scalar with the vector to represent
    the sales goal for `Salesperson 1` at `Location X` and print the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.11: The output of the integer-vector summation as a NumPy variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.11: The output of the integer-vector summation as a NumPy variable'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create three tensors with a rank of 2 representing the revenue for each salesperson,
    product, and location using TensorFlow's `Variable` class. The first tensor will
    have the value `[[2706, 2799, 5102], [2386, 4089, 5932]]`, the second will have
    the value `[[5901, 1208, 645], [6235, 1098, 948]]`, and the third will have `[[3908,
    2339, 5520], [4544, 1978, 4729]]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new variable as the sum of the matrices and print the result:![Figure
    1.12: The output of the matrix summation as a NumPy variable'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16341_01_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.12: The output of the matrix summation as a NumPy variable'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor250).
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, you will learn how to change a tensor's shape and
    rank.
  prefs: []
  type: TYPE_NORMAL
- en: Reshaping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some operations, such as addition, can only be applied to tensors if they meet
    certain conditions. Reshaping is one method for modifying the shape of tensors
    so that such operations can be performed. Reshaping takes the elements of a tensor
    and rearranges them into a tensor of a different size. A tensor of any size can
    be reshaped so long as the number of total elements remains the same.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a `(4x3)` matrix can be reshaped into a `(6x2)` matrix since they
    both have a total of `12` elements. The rank, or number, of dimensions, can also
    be changed in the reshaping process. For instance, a `(4x3)` matrix that has a
    rank equal to `2` can be reshaped into a `(3x2x2)` tensor that has a rank equal
    to `3`. The `(4x3)` matrix can also be reshaped into a `(12x1)` vector in which
    the rank has changed from `2` to `1`.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1.13* illustrates tensor reshaping. On the left is a tensor with shape
    `(3x2)`, which can be reshaped to a tensor of shape equal to either `(2x3)`, `(6)`,
    or `(6x1)`. Here, the number of elements, that is, six, has remained constant,
    though the shape and rank of the tensor have changed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.13: Visual representation of reshaping a (3x2) tensor to tensors
    of different shapes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.13: Visual representation of reshaping a (3x2) tensor to tensors of
    different shapes'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensor reshaping can be performed in TensorFlow by using the `reshape` function
    and passing in the tensor and the desired shape of the new tensor as the arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Here, a new tensor is created that has the same elements as the original; however,
    the shape is `[3,2]` instead of `[6]`.
  prefs: []
  type: TYPE_NORMAL
- en: The next section introduces tensor transposition, which is another method for
    modifying the shape of a tensor.
  prefs: []
  type: TYPE_NORMAL
- en: Tensor Transposition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a tensor is transposed, the elements in the tensor are rearranged in a
    specific order. The transpose operation is usually denoted as a `T` superscript
    on the tensor. The new position of each element in the tensor can be determined
    by `(x`12…k`)`T = `x`k…21\. For a matrix or tensor of rank equal to `2`, the rows
    become the columns and vice versa. An example of matrix transposition is shown
    in *Figure 1.14*. Tensors of any rank can be transposed, and often the shape changes
    as a result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.14: A visual representation of tensor transposition on a (3x2) matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.14: A visual representation of tensor transposition on a (3x2) matrix'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the matrix transposition properties of matrices
    `A` and `B`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.15: Tensor transposition properties where X and Y are tensors'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.15: Tensor transposition properties where X and Y are tensors'
  prefs: []
  type: TYPE_NORMAL
- en: A tensor is said to be symmetrical if the transpose of a tensor is equivalent
    to the original tensor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensor transposition can be performed in TensorFlow by using its `transpose`
    function and passing in the tensor as the only argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: When transposing a tensor, there is only one possible result; however, reshaping
    a tensor has multiple possible results depending on the desired shape of the output.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, reshaping and transposition are demonstrated on tensors
    using TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.04: Performing Tensor Reshaping and Transposition in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will learn how to perform tensor reshaping and transposition
    using the TensorFlow library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library and create a matrix with two rows and four columns
    using TensorFlow''s `Variable` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify the shape of the matrix by calling the `shape` attribute of the matrix
    as a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You see that the shape of the matrix is `[2,4]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `reshape` function to change the matrix to a matrix with
    four rows and two columns by passing in the matrix and the desired new shape:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.16: The reshaped matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.16: The reshaped matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify the shape of the reshaped matrix by calling the `shape` attribute as
    a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you can see that the shape of the matrix has changed to your desired shape,
    `[4,2]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `reshape` function to convert the matrix into a matrix with
    one row and eight columns. Pass the matrix and the desired new shape as parameters
    to the `reshape` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify the shape of the reshaped matrix by calling the `shape` attribute as
    a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding output confirms the shape of the reshaped matrix as `[1, 8]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `reshape` function to convert the matrix into a matrix with
    eight rows and one column, passing the matrix and the desired new shape as parameters
    to the `reshape` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.17: Reshaped matrix of shape (8, 1)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.17: Reshaped matrix of shape (8, 1)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify the shape of the reshaped matrix by calling the `shape` attribute as
    a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding output confirms the shape of the reshaped matrix as `[8, 1]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `reshape` function to convert the matrix to a tensor of size
    `2x2x2`. Pass the matrix and the desired new shape as parameters to the reshape
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.18: Reshaped matrix of shape (2, 2, 2)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.18: Reshaped matrix of shape (2, 2, 2)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify the shape of the reshaped matrix by calling the `shape` attribute as
    a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding output confirms the shape of the reshaped matrix as `[2, 2, 2]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify that the rank has changed using TensorFlow''s `rank` function and print
    the result as a NumPy variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use TensorFlow''s `transpose` function to convert the matrix of size `2X4`
    to a matrix of size `4x2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.19: Transposed matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.19: Transposed matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify that the `reshape` function and the `transpose` function create different
    resulting matrices when applied to the given matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 1.20: Verification that transposition and reshaping produce different
    results'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.20: Verification that transposition and reshaping produce different
    results'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `transpose` function to transpose the reshaped matrix in
    *step 9*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.21: The output of the transposition of the reshaped tensor'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.21: The output of the transposition of the reshaped tensor'
  prefs: []
  type: TYPE_NORMAL
- en: This result shows how the resulting tensor appears after reshaping and transposing
    a tensor.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you have successfully modified the shape of a tensor either
    through reshaping or transposition. You studied how the shape and rank of the
    tensor changes following the reshaping and transposition operation.
  prefs: []
  type: TYPE_NORMAL
- en: In the following activity, you will test your knowledge on how to reshape and
    transpose tensors using TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.02: Performing Tensor Reshaping and Transposition in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, you are required to simulate the grouping of 24 school children
    for class projects. The dimensions of each resulting reshaped or transposed tensor
    will represent the size of each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the TensorFlow library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a one-dimensional tensor with 24 monotonically increasing elements using
    the `Variable` class to represent the IDs of the school children. Verify the shape
    of the matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Reshape the matrix so that it has 12 rows and 2 columns using TensorFlow's `reshape`
    function representing 12 pairs of school children. Verify the shape of the new
    matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Reshape the original matrix so that it has a shape of `3x4x2` using TensorFlow's
    `reshape` function representing 3 groups of 4 sets of pairs of school children.
    Verify the shape of the new tensor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Verify that the rank of this new tensor is `3`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transpose the tensor created in *step 3* to represent 2 groups of 12 students
    using TensorFlow's `transpose` function. Verify the shape of the new tensor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor252).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this section, you were introduced to some of the basic components of ANNs—tensors.
    You also learned about some basic manipulation of tensors, such as addition, transposition,
    and reshaping. You implemented these concepts by using functions in the TensorFlow
    library.
  prefs: []
  type: TYPE_NORMAL
- en: In the next topic, you will extend your understanding of linear transformations
    by covering another important transformation related to ANNs—tensor multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: Tensor Multiplication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tensor multiplication is another fundamental operation that is used frequently
    in the process of building and training ANNs since information propagates through
    the network from the inputs to the result via a series of additions and multiplications.
    While the rules for addition are simple and intuitive, the rules for tensors are
    more complex. Tensor multiplication involves more than simple element-wise multiplication
    of the elements. Rather, a more complicated procedure is implemented that involves
    the dot product between the entire rows/columns of each of the tensors to calculate
    each element of the resulting tensor. This section will explain how multiplication
    works for two-dimensional tensors or matrices. However, tensors of higher orders
    can also be multiplied.
  prefs: []
  type: TYPE_NORMAL
- en: Given a matrix, `X = [x`ij`]`m x n, and another matrix, `Y = [y`ij`]`n x p,
    the product of the two matrices is `Z = XY = [z`ij`]`m x p, and each element,
    `z`ij, is defined element-wise as ![Formula](img/B16341_01_21a.png). The shape
    of the resultant matrix is the same as the outer dimensions of the matrix product,
    or the number of rows of the first matrix and the number of columns of the second
    matrix. For the multiplication to work, the inner dimensions of the matrix product
    must match, or the number of columns in the first matrix and the number of columns
    in the second matrix must correspond.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of inner and outer dimensions of matrix multiplication is shown
    in the following diagram, where `X` represents the first matrix and `Y` represents
    the second matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.22: A visual representation of inner and outer dimensions in matrix
    multiplication'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.22: A visual representation of inner and outer dimensions in matrix
    multiplication'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike matrix addition, matrix multiplication is not commutative, which means
    that the order of the matrices in the product matters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.23: Matrix multiplication is non-commutative'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.23: Matrix multiplication is non-commutative'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, say you have the following two matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.24: Two matrices, X and Y'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.24: Two matrices, X and Y'
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to construct the product is to have matrix `X` first, multiplied by
    `Y`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.25: Visual representation of matrix X multiplied by Y, X•Y'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.25: Visual representation of matrix X multiplied by Y, X•Y'
  prefs: []
  type: TYPE_NORMAL
- en: 'This results in a `2x2` matrix. Another way to construct the product is to
    have `Y` first, multiplied by `X`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.26: Visual representation of matrix Y multiplied by X, Y•X'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.26: Visual representation of matrix Y multiplied by X, Y•X'
  prefs: []
  type: TYPE_NORMAL
- en: Here you can see that the matrix formed from the product `YX` is a `3x3` matrix
    and is very different from the matrix formed from the product `XY`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensor multiplication can be performed in TensorFlow by using the `matmul`
    function and passing in the tensors to be multiplied in the order in which they
    are to be multiplied as the arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Tensor multiplication can also be achieved by using the `@` operator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Scalar-tensor multiplication is much more straightforward and is simply the
    product of every element in the tensor multiplied by the scalar so that `λX =
    [λx`ij…k`]`, where `λ` is a scalar and `X` is a tensor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scalar multiplication can be achieved in TensorFlow either by using the `matmul`
    function or by using the `*` operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: In the following exercise, you will perform tensor multiplication using the
    TensorFlow library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.05: Performing Tensor Multiplication in TensorFlow'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will perform tensor multiplication in TensorFlow using
    TensorFlow's `matmul` function and the `@` operator. In this exercise, you will
    use the example of data from a sandwich retailer representing the ingredients
    of various sandwiches and the costs of different ingredients. You will use matrix
    multiplication to determine the costs of each sandwich.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sandwich recipe**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.27: Sandwich recipe'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.27: Sandwich recipe'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ingredient details**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.28: Ingredient details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.28: Ingredient details'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sales projections**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.29: Sales projections'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.29: Sales projections'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a matrix representing the different sandwich recipes, with the rows
    representing the three different sandwich offerings and the columns representing
    the combination and number of the five different ingredients using the `Variable`
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.30: Matrix representing the number of ingredients needed to make
    sandwiches'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.30: Matrix representing the number of ingredients needed to make sandwiches'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Verify the shape of the matrix by calling the `shape` attribute of the matrix
    as a Python list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a second matrix representing the cost and weight of each individual
    ingredient in which the rows represent the five ingredients, and the columns represent
    the cost and weight of the ingredients in grams:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.31: A matrix representing the cost and weight of each ingredient'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.31: A matrix representing the cost and weight of each ingredient'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use TensorFlow''s `matmul` function to perform the matrix multiplication of
    `matrix1` and `matrix2`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.32: The output of the matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.32: The output of the matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a matrix to represent the sales projections of five different stores
    for each of the three sandwiches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Multiply `matrix3` by the result of the matrix multiplication of `matrix1`
    and `matrix2` to give the expected cost and weight for each of the five stores:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will result in the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.33: The output of matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.33: The output of matrix multiplication'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting tensor from the multiplication shows the expected cost of sandwiches
    and the expected weight of the total ingredients for each of the stores.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you have successfully learned how to perform matrix multiplication
    in TensorFlow using several operators. You used TensorFlow's `matmul` function,
    as well as the shorthand `@` operator. Each will perform the multiplication; however,
    the `matmul` function has several different arguments that can be passed into
    the function that make it more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can read more about the `matmul` function here: [https://www.tensorflow.org/api_docs/python/tf/linalg/matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul).'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will explore some other mathematical concepts that
    are related to ANNs. You will explore forward and backpropagation, as well as
    activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will learn about some optimization approaches that are
    fundamental to training machine learning models. Optimization is the process by
    which the weights of the layers of an ANN are updated such that the error between
    the predicted values of the ANN and the true values of the training data is minimized.
  prefs: []
  type: TYPE_NORMAL
- en: Forward Propagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Forward propagation is the process by which information propagates through ANNs.
    Operations such as a series of tensor multiplications and additions occur at each
    layer of the network until the final output. Forward propagation is explained
    in *Figure 1.37*, showing a single hidden layer ANN. The input data has two features,
    while the output layer has a single value for each input record.
  prefs: []
  type: TYPE_NORMAL
- en: The weights and biases for the hidden layer and output are shown as matrices
    and vectors with the appropriate indexes. For the hidden layer, the number of
    rows in the weight matrix is equal to the number of features of the input, and
    the number of columns is equal to the number of units in the hidden layer. Therefore,
    `W1` has two rows and three columns because the input, `X`, has two features.
    Likewise, `W2` has three rows and one column, the hidden layer has three units,
    and the output has the size one. The bias, however, is always a vector with a
    size equal to the number of nodes in that layer and is added to the product of
    the input and weight matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.34: A single-layer artificial neural network'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_34.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.34: A single-layer artificial neural network'
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to perform forward propagation are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`X` is the input to the network and the input to the hidden layer. First, the
    input matrix, `X`, is multiplied by the weight matrix for the hidden layer, `W1`,
    and then the bias, `b1`, is added:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`z1 = X*W1 + b1`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here is an example of what the shape of the resulting tensor will be after the
    operation. If the input is size `nX2`, where `n` is the number of input examples,
    `W1` is of size `2X3`, and `b1` is of size `1X3`, the resulting matrix, `z1`,
    will have a size of `nX3`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`z1` is the output of the hidden layer, which is the `W2`, and the bias, `b2`,
    is added:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Y = z1 * W2 + b2`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To understand the shape of the resulting tensor, consider the following example.
    If the input to the output layer, `z1`, is of size `nX3`, `W2` is of size `3X1`,
    and `b1` is of size `1X1`, the resulting matrix, `Y`, will have a size of `nX1`,
    representing one result for each training example.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The total number of parameters in this model is equal to the sum of the number
    of elements in `W1`, `W2`, `b1`, and `b2`. Therefore, the number of parameters
    can be calculated by summing the elements in each of the parameters in weight
    matrices and biases, which is equal to `6 + 3 + 3 + 1 = 13`. These are the parameters
    that need to be learned in the process of training the ANN.
  prefs: []
  type: TYPE_NORMAL
- en: Following the forward propagation step, you must evaluate your model and compare
    it to the real target values. This is achieved using a loss function. Mean squared
    error, that is, the mean value of the squared difference between true and predicted
    values, is one of the examples of the loss function of the regression task. Once
    the loss is calculated, the weights must be updated to reduce the loss, and the
    amount and direction that the weights should be updated are found using backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`loss` function to the predicted outputs as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`loss = L(y_predicted)`'
  prefs: []
  type: TYPE_NORMAL
- en: The derivative of the loss with respect to the model parameters will inform
    you if increasing or decreasing the model parameter will result in increasing
    or decreasing the loss. The process of backpropagation is achieved by applying
    the chain rule of calculus from the output layer to the input layer of a neural
    network, at each layer computing the derivatives of the `loss` function with respect
    to the model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chain rule of calculus is a technique used to compute the derivative of
    a composite function via intermediate functions. A generalized version of the
    function can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dz/dx = dz/dy * dy/dx`'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `dz/dx` is the composite function and `y` is the intermediate function.
    In the case of ANNs, the composite function is the loss as a function of the model
    parameters and the intermediate functions represent the hidden layers. Therefore,
    the derivative of the loss with respect to the model parameters can be computed
    by multiplying the derivative of the loss with respect to the predicted output
    by the derivative of the predicted output with respect to the model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will learn how the weight parameters are updated given
    the derivatives of the loss function with respect to each of the weights so that
    the loss is minimized.
  prefs: []
  type: TYPE_NORMAL
- en: Learning Optimal Parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will see how optimal weights are iteratively chosen. You
    know that forward propagation transfers information through the network via a
    series of tensor additions and multiplications, and that backpropagation is the
    process of understanding the change in loss with respect to each model weight.
    The next step is to use the results from backpropagation to update the weights
    so that they reduce the error according to the loss function. This process is
    known as learning the parameters and is achieved using an optimization algorithm.
    A common optimization algorithm often utilized is called **gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: In learning the optimal parameters, you apply the optimization algorithm until
    a minimum in the loss function is reached. You usually stop after a given number
    of steps or when there is a negligible change in the loss function. If you plot
    the loss as a function of each model parameter, the shape of the loss function
    resembles a convex shape, having only one minimum, and it is the goal of the optimization
    function to find this minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the loss function of a particular feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.35: A visual representation of the gradient descent algorithm finding'
  prefs: []
  type: TYPE_NORMAL
- en: the optimal parameter to minimize the loss
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.35: A visual representation of the gradient descent algorithm finding
    the optimal parameter to minimize the loss'
  prefs: []
  type: TYPE_NORMAL
- en: This is achieved, first, by randomly setting parameters for each weight, indicated
    by `p`1 in the diagram. The loss is then calculated for that model parameter,
    `l`1\. The backpropagation step determines the derivative of the loss with respect
    to the model parameter and will determine in which direction the model should
    be updated. The next model parameter, `p`2, is equal to the current model parameter
    minus the learning rate (`α`) multiplied by the derivative value. The learning
    rate is a hyperparameter that is set before the model training process. By multiplying
    by the derivative value, larger steps will be taken when the parameter is far
    from the minimum where the absolute value for the derivative is larger. The loss,
    `l`2, is then calculated and the process continues until the minimum loss is reached,
    `l`m, with the optimal parameter, `p`m.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, these are the iterative steps that the optimization algorithm
    performs to find the optimal parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Use forward propagation and current parameters to predict the outputs for the
    entire dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the loss function to compute the loss over all the examples from the predicted
    output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use backpropagation to compute the derivatives of the loss with respect to the
    weights and biases at each layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the weights and biases using the derivative values and the learning rate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimizers in TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are several different optimizers readily available within TensorFlow.
    Each is based on a different optimization algorithm that aims to reach a global
    minimum for the loss function. They are all based on the gradient descent algorithm,
    although they differ slightly in implementation. The available optimizers in TensorFlow
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stochastic Gradient Descent** (**SGD**): The SGD algorithm applies gradient
    descent to small batches of training data. A momentum parameter is also available
    when using the optimizer in TensorFlow that applies exponential smoothing to the
    computed gradient to speed up training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adam**: This optimization is an SGD method that is based on the continuous
    adaptive estimation of first and second-order moments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Root Mean Squared Propagation** (**RMSProp**): This is an unpublished, adaptive
    learning rate optimizer. RMSprop divides the learning rate by an average of the
    squared gradients when finding the loss minimum after each step, which results
    in a learning rate that exponentially decays.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adagrad**: This optimizer has parameter-specific learning rates that are
    updated depending on how frequently the parameter is updated during the training
    process. As the parameter receives more updates, each subsequent update is smaller
    in value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The choice of optimizer will affect training time and model performance. Each optimizer
    also has hyperparameters, such as the initial learning rate, that must be selected
    before training, and tuning of these hyperparameters will also affect training
    time and model performance. While other optimizers available in TensorFlow are
    not explicitly stated here (and can be found here: [https://www.tensorflow.org/api_docs/python/tf/keras/optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)),
    those stated above perform well both in terms of training time and model performance
    and are a safe first choice when selecting an optimizer for your model. The optimizers
    available in TensorFlow are located in the `tf.optimizers` module; for example,
    an Adam optimizer with a learning rate equal to `0.001` can be initialized as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: In this topic, you have seen the steps taken in achieving gradient descent to
    compute the optimal parameters for model training. In gradient descent, every
    single training example is used to learn the parameters. However, when working
    with large volume datasets, such as with images and audio, you will often work
    in batches and make updates after learning from each batch. When using gradient
    descent on batch data, the algorithm is known as SGD. The SGD optimizer, along
    with a suite of other performant optimizers, is readily available in TensorFlow,
    including the Adam, RMSProp, and Adagrad optimizers, and more.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will explore different activation functions, which
    are generally applied to the output of each layer.
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Activation functions are mathematical functions that are generally applied
    to the outputs of ANN layers to limit or bound the values of the layer. The reason
    that values may want to be bounded is that without activation functions, the value
    and corresponding gradients can either explode or vanish, thereby making the results
    unusable. This is because the final value is the cumulative product of the values
    from each subsequent layer. As the number of layers increases, the likelihood
    of values and gradients exploding to infinity or vanishing to zero increases.
    This concept is known as the **exploding and vanishing gradient problem**. Deciding
    whether a node in a layer should be *activated* is another use of activation functions,
    hence their name. Common activation functions and their visual representation
    in *Figure 1.36* are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step** function: The value is non-zero if it is above a certain threshold,
    otherwise it is zero. This is shown in *Figure 1.36a*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linear** function: ![Formula](img/B16341_01_35a.png), which is a scalar multiplication
    of the input value. This is shown in *Figure 1.36b*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid** function: ![Formula](img/B16341_01_35b.png), like a smoothed-out
    step function with smooth gradients. This activation function is useful for classification
    since the values are bound from zero to one. This is shown in *Figure 1.36c*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x=0`. This is shown in *Figure 1.36d*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0`. This is shown in *Figure 1.36e*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ELU** (**Exponential Linear Unit**) function: ![Formula](img/B16341_01_35e.png),
    otherwise ![Formula](img/B16341_01_35f.png), where ![Formula](img/B16341_01_35g.png)
    is a constant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SELU** (**Scaled Exponential Linear Unit**) function: ![Formula](img/B16341_01_35h.png),
    otherwise ![Formula](img/B16341_01_35i.png), where ![Formula](img/B16341_01_35j.png)are
    constants. This is shown in *Figure 1.36f*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swish** function: ![Formula](img/B16341_01_35k.png). This is shown in *Figure
    1.36g*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 1.36: A visual representation of the common activation functions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.36: A visual representation of the common activation functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'An activation function can be applied to any tensor by utilizing the activation
    functions in the `tf.keras.activations` module. For example, a sigmoid activation
    function can be applied to a tensor as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's test the knowledge that you have gained so far in the following activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.03: Applying Activation Functions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, you will recall many of the concepts used throughout the chapter
    as well as apply activation functions to tensors. You will use example data of
    car dealership sales, apply these concepts, show the sales records of various
    salespeople, and highlight those with net positive sales.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sales records**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.37: Sales records'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_37.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.37: Sales records'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vehicle MSRPs**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.38: Vehicle MSRPs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_38.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.38: Vehicle MSRPs'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fixed costs**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.39: Fixed costs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_01_39.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.39: Fixed costs'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the TensorFlow library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `3x4` tensor as an input with the values `[[-0.013, 0.024, 0.06, 0.022],
    [0.001, -0.047, 0.039, 0.016], [0.018, 0.030, -0.021, -0.028]]`. The rows in this
    tensor represent the sales of various sales representatives, the columns represent
    various vehicles available at the dealership, and values represent the average
    percentage difference from MSRP. The values are positive or negative depending
    on whether the salesperson was able to sell for more or less than the MSRP.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `4x1` weights tensor with the shape `4x1` with the values `[[19995.95],
    [24995.50], [36745.50], [29995.95]]` representing the MSRP of the cars.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a bias tensor of size `3x1` with the values `[[-2500.0], [-2500.0], [-2500.0]]`
    representing the fixed costs associated with each salesperson.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Matrix multiply the input by the weight to show the average deviation from the
    MSRP on all cars and add the bias to subtract the fixed costs of the salesperson.
    Print the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.40: The output of the matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_40.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.40: The output of the matrix multiplication'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Apply a ReLU activation function to highlight the net-positive salespeople and
    print the result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.41: The output after applying the activation function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_01_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.41: The output after applying the activation function'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor253).
  prefs: []
  type: TYPE_NORMAL
- en: In subsequent chapters, you will see how to add activation functions to your
    ANNs, either between layers or applied directly after a layer when layers are
    defined. You will learn how to choose which activation functions are most appropriate,
    which is often by hyperparameter optimization techniques. The activation function
    is one example of a hyperparameter, a parameter set before the learning process
    begins, that can be tuned to find the optimal values for model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you were introduced to the TensorFlow library. You learned
    how to use it in the Python programming language. You created the building blocks
    of ANNs (tensors) with various ranks and shapes, performed linear transformations
    on tensors using TensorFlow, and implemented addition, reshaping, transposition,
    and multiplication on tensors—all of which are fundamental for understanding the
    underlying mathematics of ANNs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will improve your understanding of tensors and learn
    how to load data of various types and pre-process it such that it is appropriate
    for training ANNs in TensorFlow. You will work with tabular, visual, and textual
    data, all of which must be pre-processed differently. By working with visual data
    (that is, images), you will also learn how to use training data in which the size
    of the training data cannot fit into memory.
  prefs: []
  type: TYPE_NORMAL
