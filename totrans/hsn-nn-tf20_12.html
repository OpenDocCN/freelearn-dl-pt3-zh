<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Generative Adversarial Networks</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, <strong>Generative Adversarial Networks</strong> (<strong>GANs</strong>) and the adversarial training process will be presented. In the first section, we will go over a theoretical overview of the GAN framework, while highlighting the strengths of the adversarial training process and the flexibility that was introduced by using neural networks as the model of choice for creating GANs. The theoretical part will give you an intuitive idea about which part of the GAN value function is being optimized during the adversarial training process and show you why the non-saturating value function should be used instead of the original one.</p>
<p>We will then go through a step-by-step implementation of GAN models and their training, with a visual explanation of what happens during this process. You will become familiar with the concept of target and learned distributions, which happens by watching the model learn.</p>
<p>The natural extension of the GAN framework to the conditional version is presented in the second part of this chapter, and how to create a conditional image generator will be shown. This chapter, just like the previous ones, will end with an exercise section that you are encouraged not to skip.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Understanding GANs and their applications</li>
<li>Unconditional GANs</li>
<li>Conditional GANs</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding GANs and their applications</h1>
                </header>
            
            <article>
                
<p><span>Introduced in 2014 by <em>Ian Goodfellow et a</em>l. in the paper <em>Generative Adversarial Networks</em>, GANs have revolutionized the field of generative models, opening the road to incredible applications.</span></p>
<p>GANs are frameworks that are used for the estimation of generative models via an adversarial process in which two models, the Generator and the Discriminator, are trained simultaneously.</p>
<p><span>The goal of the generative model (Generator) is to capture the data distribution contained in the training set, while the discriminative model acts as a binary classifier. Its goal is to estimate the probability of a sample to come from the training data rather than from the Generator. In the following diagram, the general architecture of adversarial training is shown:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-934 image-border" src="assets/fba6a37e-b988-4e77-8349-1136b7967d6e.png" style="width:27.33em;height:11.92em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Graphical representation of the adversarial training process. The generator goal is used to fool the Discriminator by learning to generate samples that are more and more similar to the training set. (Image source: <a href="https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/">https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/</a>—by Thalles Silva)</div>
<p>The idea is to train a generative model without explicitly<span> defining a</span> loss function. Instead, we use a signal coming from another network as feedback. The Generator's aim is to fool the Discriminator, while the Discriminator's aim is to correctly classify whether the input samples are real or fake. The power of adversarial training comes from the fact that both the Generator and the Discriminator can be non-linear, parametric models such as neural networks. It is therefore possible to use gradient descent to train them.</p>
<p>To learn about generator distribution over the data, the generator builds a <em>mapping</em> from a <strong>prior noise distribution</strong>, <img class="fm-editor-equation" src="assets/d91fb882-7ced-4adc-8bdb-288dc00f1560.png" style="width:2.33em;height:1.25em;"/>, to a data space <img class="fm-editor-equation" src="assets/3471d5f4-6777-44d6-a144-c7ee3752541a.png" style="width:1.92em;height:1.08em;"/>.</p>
<p>The Discriminator, <img class="fm-editor-equation" src="assets/0928f736-02e1-4807-a547-532c511468a9.png" style="width:1.83em;height:1.00em;"/>, is a function (neural network) that outputs a single scalar representing the probability that <img class="fm-editor-equation" src="assets/84ccb37f-c4bc-4a14-93a7-e97a3c82eb2a.png" style="width:0.75em;height:0.83em;"/> came from the real data distribution rather than <img class="fm-editor-equation" src="assets/334013b8-4a01-4e39-b5ae-946dacf66adf.png" style="width:1.92em;height:1.08em;"/>.</p>
<p>The original GAN framework is expressed by using a game-theory approach to the problem and poses it as a min-max game in which two players, the Generator and the Discriminator, compete against each other.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Value function</h1>
                </header>
            
            <article>
                
<p>The value function is a mathematical way of representing the goals of the players in terms of expected returns. The GAN game is expressed by the following value function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d3613a64-5f05-4433-9fe0-a6c87efcc08e.png" style="width:34.33em;height:1.83em;"/></p>
<p>This value function represents the game that the two players are playing, along with their respective long-term goals.</p>
<p>The Discriminator's goal is to correctly classify the real and fake samples, and this goal is expressed as the <strong>maximization</strong> of both the <img class="fm-editor-equation" src="assets/19a63dae-6136-4f21-ac4c-f4b38a1c29b7.png" style="width:7.92em;height:1.25em;"/> and <img class="fm-editor-equation" src="assets/a1aa6880-eb9b-4525-8622-68a508d897fd.png" style="width:10.17em;height:1.17em;"/> terms. The former represents the correct classification of the samples coming from the real data distribution (therefore, the goal is to get <img class="fm-editor-equation" src="assets/e83ace9e-d8be-4a3f-8c7c-b668fd0dad27.png" style="width:3.17em;height:0.92em;"/>), while the latter is the correct classification of fake samples (and in this case, the goal is to get <img class="fm-editor-equation" src="assets/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png" style="width:5.08em;height:1.08em;"/>).</p>
<p>The generator, on the other hand, is trained to fool the Discriminator, and its goal is to <strong>minimize</strong> <img class="fm-editor-equation" src="assets/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png" style="width:10.08em;height:1.17em;"/>. The way you minimize this term is by producing samples that are more and more similar to the real ones, thereby trying to fool the Discriminator.</p>
<p>A subtlety worth noting is that the min-max game is played only in the second term of the value function since, in the first term, only the Discriminator plays. It does this by learning to correctly classify the data coming from the real data distribution.</p>
<p>Although clear and pretty easy to understand, this formulation has a practical disadvantage. In the early training steps, the Discriminator can easily learn how to correctly classify fake data by maximizing <img class="fm-editor-equation" src="assets/a1aa6880-eb9b-4525-8622-68a508d897fd.png" style="width:8.67em;height:1.00em;"/> because the generated samples are too different from the real ones. Since learning from the quality of the generated samples is poor, the Discriminator can reject samples with high confidence because they are clearly different from the training data. This rejection consists of classing the correct classification of the generated samples as fake (<img class="fm-editor-equation" src="assets/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png" style="width:4.67em;height:1.00em;"/>), making the term <img class="fm-editor-equation" src="assets/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png" style="width:10.08em;height:1.17em;"/> saturate. It follows that the previous equation may not provide a sufficient gradient for <em>G</em> to learn well. The solution to this practical problem is the definition of a new value function that does not saturate.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Non-saturating value function</h1>
                </header>
            
            <article>
                
<p>The proposed solution is to train <em>G</em> to <strong>maximize</strong> <img class="fm-editor-equation" src="assets/ec6f3dc9-5b0c-45ca-ad62-cdeb1404156e.png" style="width:4.75em;height:1.08em;"/> instead of minimizing <img class="fm-editor-equation" src="assets/30b90557-a9fe-474e-a64d-b6908d6af3d4.png" style="width:7.42em;height:1.17em;"/>. Intuitively, we can see the proposed solution as a way of playing the same min-max game in a different manner.</p>
<p>The Discriminator's goal is to maximize the probability of correctly classifying the real and fake samples, with no changes with respect to the previous formulation. The Generator's goal, on the other hand, is to minimize the Discriminator's probability of correctly classifying the generated samples as fake but to explicitly fool the Discriminator by making it classify the fake samples as real.</p>
<p>The value function of the same game, which is played in a different manner by the two players, can be expressed as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/162c9bb9-438c-4a07-bd81-08ffc92c02a4.png" style="width:32.58em;height:2.58em;"/></p>
<p>As we stated previously, the power of the adversarial training frameworks comes from the fact that both <em>G</em> and <em>D</em> can be neural networks and that they can both be trained via gradient descent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model definition and training phase</h1>
                </header>
            
            <article>
                
<p>Defining the Generator and the Discriminator as neural networks allows us to tackle the problem using all the neural network architectures that have been developed over the years, with each one specialized to work with a certain data type.</p>
<p>There are no constraints in the model's definition; in fact, it is possible to define their architecture in a completely arbitrary manner. The only constraints are given by the structure of the data we are working on; the architectures depend on the data type, all of which are as follows:</p>
<ul>
<li><strong>Images</strong>: Convolutional neural networks</li>
<li><strong>Sequences, Text</strong>: Recurrent neural networks</li>
<li><strong>Numerical, Categorical values</strong>: Fully connected networks</li>
</ul>
<p>Once we've defined the model's architecture as a function of the data type, it is possible to use them to play the min-max game.</p>
<p>Adversarial training consists of alternating the execution of training steps. Every training step is a player action, and the Generator and Discriminator compete against each other in turn. The game follows the following rules:</p>
<ul>
<li><strong>Discriminator</strong>: The Discriminator plays first and can repeat the following three steps from 1 to <em>k</em> times, where <em>k</em> is a hyperparameter (often, <em>k</em> equals 1):</li>
</ul>
<ol>
<li style="list-style-type: none">
<ol>
<li>Sample a minibatch of <em>m</em> noise samples, <img class="fm-editor-equation" src="assets/8c7a168d-8b67-487c-a89b-caac740d62f9.png" style="width:6.00em;height:1.42em;"/>, from the noise prior to <img class="fm-editor-equation" src="assets/ab6c44ac-0ebc-4771-9cd5-8bd7ae76b1da.png" style="width:2.25em;height:1.17em;"/></li>
<li>Sample a minibatch of <em>m</em> samples, <img class="fm-editor-equation" src="assets/d26d6ddc-669a-47fd-b298-b7464f068ece.png" style="width:4.75em;height:1.08em;"/>, from the real data distribution, <img class="fm-editor-equation" src="assets/12e80660-9f99-4caf-abe9-f848567808e5.png" style="width:2.92em;height:1.00em;"/></li>
<li>Train the Discriminator via stochastic gradient ascent:<strong><br/>
<img class="fm-editor-equation" src="assets/e43e40a8-c222-4ba9-9f07-0009b1325e5a.png" style="width:36.42em;height:3.92em;"/></strong><strong><br/></strong></li>
</ol>
</li>
</ol>
<p style="padding-left: 120px">Here, <img class="fm-editor-equation" src="assets/5a54844b-6ec5-4e7e-92cd-686cfec824fd.png" style="width:1.25em;height:1.08em;"/> is the Discriminator's parameters</p>
<ul>
<li><strong>Generator</strong>: The Generator always plays after the Discriminator's turn, and it plays only once:</li>
</ul>
<ol>
<li style="list-style-type: none">
<ol>
<li>Sample a minibatch of <em>m</em> noise samples,<span> </span><img class="fm-editor-equation" src="assets/6f6acbf8-4fcc-4154-a9bc-ee1c64d5b85b.png" style="width:4.92em;height:1.17em;"/>,<span> from the noise prior to </span><img class="fm-editor-equation" src="assets/e4c37a82-c37a-46d9-aad3-aed8b32e47b1.png" style="width:2.08em;height:1.08em;"/></li>
<li>Train the Generator via stochastic gradient ascent (this is a maximization problem since the game is targeted the non-saturating value function):<br/>
<img class="fm-editor-equation" src="assets/7042fc2f-3c83-4eab-9725-72b756c3d182.png" style="width:29.83em;height:3.25em;"/></li>
</ol>
</li>
</ol>
<p style="padding-left: 120px">Here, <img class="fm-editor-equation" src="assets/da88d371-aa89-428a-88c7-ccd6fe0b3780.png" style="width:1.25em;height:1.17em;"/><span> is the Generator's parameters</span></p>
<p>Just like any other neural <span>network that's trained via</span> gradient <span>descent, the updates can use any standard optimization algorithm (Adam, SGD, SGD with Momentum, and so on). The game should go on until the Discriminator isn't completely fooled by the Generator, that is, when the Discriminator always</span> predicts a probability of<span> 0.5 for every input sample. The value of 0.5 may sound strange, but intuitively, this means that the Generator is now able to generate samples that are similar to the real ones and the Discriminator can now only make random guesses.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications of GANs</h1>
                </header>
            
            <article>
                
<p>At first glance, Generative models have a limited utility. What is the purpose of having a model that generates something similar to what we already have (the real sample dataset)?</p>
<p>In practice, learning from a data distribution is extremely useful in the anomaly detection domain and in "human-only" fields such as art, painting, and music generation. Moreover, the applications of GANs in their conditional formulation are astonishing and used to create applications with a great market value <span>(see the <em>Conditional GANs</em> section of this chapter for more information).</span></p>
<p>With GANs, it is possible to make a machine generate extremely realistic faces, starting from random noise. The following image shows applying GAN to the face generation problem. These results were obtained in the paper titled <span><em>Progressive Growing of GANs for Improved Quality, Stability, and Variation</em> (T. Karras et al. 2017, NVIDIA):</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-933 image-border" src="assets/59076122-b87b-4fd7-8c15-03c3de5b7f29.jpg" style="width:38.42em;height:19.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">These people do not exist. Every image, although super realistic, is GAN generated. You can try this out for yourself by going to <a href="https://thispersondoesnotexist.com/">https://thispersondoesnotexist.com/</a> (Image source, the paper titled <span><em>Progressive Growing of GANs for Improved Quality, Stability, and Variation</em>).</span></div>
<p>Another astonishing application from before GANs were introduced that was practically impossible to achieve was domain translation, which is where you use a GAN to go from one domain to another, for example, from sketches to a realistic image or from an aerial view to a map.</p>
<p><span>The following image, which was retrieved from the paper <em>Image-to-Image Translation with Conditional Adversarial Networks</em> (Isola et al., </span><span>2017)</span><span> shows how (conditional) GANs are able to solve tasks that were considered impossible only some years ago:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-932 image-border" src="assets/15b3d462-f535-4de8-b74e-8b735b20c47b.jpg" style="width:170.33em;height:62.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">GANs allow you to solve the domain translation problem. Colorizing a black and white image or generating photos only from sketches is now possible. Image source:<em> </em><span><em>Image-to-Image Translation with Conditional Adversarial Networks</em> (Isola et al., </span><span>2017).</span></div>
<p>GAN applications are astonishing and their practical applications are always being discovered. Starting from the next section, we'll learn how to implement some of them in pure TensorFlow 2.0.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unconditional GANs</h1>
                </header>
            
            <article>
                
<p>It isn't common to see GANs mentioned as unconditional since this is the default and original configuration. In this book, however, we decided to stress this characteristic of the original GAN formulation in order to make you aware of the two main GAN classifications:</p>
<ul>
<li>Unconditional GANs</li>
<li>Conditional GANs</li>
</ul>
<p><span>The generative model that we described in the previous section falls under the category of unconditional GANs. The generative model is trained to capture the training data distribution and to generate samples that have been randomly sampled from the captured distribution. </span>The conditional configuration is a slightly modified version of the framework and is presented in the next section.</p>
<p>Thanks to TensorFlow 2.0's eager-by-default style, the implementation of adversarial training is straightforward. In practice, to implement the adversarial training loop as described in the Goodfellow et al. paper (<em>Generative Adversarial Networks<span>)</span></em>, it is required to implement it as it is defined, line by line. Of course, the best way to create a custom training loop that requires the alternate training steps of two different models is not to use Keras, but to implement it manually.</p>
<p>Just like in any other machine learning problem, we have to start with the data. In this section, we will define a generative model, with the goal of learning about the random normal data distribution, centered at 10 and with a small standard deviation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing the data</h1>
                </header>
            
            <article>
                
<p>Since the goal of this section is to learn about data distribution, we will start from the foundations in order to build a strong intuition of the adversarial training process. The most simple and the easiest way to visualize data distribution is by looking at the random normal distribution. We can, therefore, pick a Gaussian (or normal) centered at 10 and with a standard deviation of 0.1 as our target data distribution:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/e95a6682-606a-49cd-b738-469c61356163.png" style="width:8.50em;height:1.25em;"/></p>
<p>Thanks to the eager execution process, we can use TensorFlow 2.0 itself to sample a value from the target distribution. We do this by using the <kbd>tf.random.normal</kbd> function. The following code snippet shows a function that samples (2,000) data points from the target distribution:</p>
<p><kbd>(tf2)</kbd></p>
<pre>import tensorflow as tf<br/><span class="k"><br/>def</span> <span class="nf">sample_dataset</span><span class="p">():</span>
    <span class="n">dataset_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">dataset_shape</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></pre>
<p>To have a better understanding of what a GAN can learn, and of what happens during the adversarial training itself, we use <kbd>matplotlib</kbd> to visualize the data on a histogram:</p>
<p><kbd>(tf2)</kbd></p>
<pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<br/><span class="n">counts</span><span class="p">,</span> <span class="nb">bin</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sample_dataset</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">axes</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">])</span>
<span class="n">axes</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">60</span><span class="p">])<br/>plt.show()</span></pre>
<p>This displays the target distribution that's shown in the following image. As expected, if we have a small standard deviation, the histogram peaks at the mean value:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-931 image-border" src="assets/3addb3b9-567b-43ac-b27a-7a7fc3340faa.png" style="width:23.92em;height:16.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The histogram of the target distribution <span>–</span> 5,000 data points sampled from a Gaussian distribution with a mean of 10 and a stddev of 0.1</div>
<p>Now that we've defined the target data distribution and we have a function that samples from it (<kbd>sample_dataset</kbd>), we are ready to define the Generator and Discriminator networks.</p>
<p><span>As we stated at the beginning of this chapter, the power of the adversarial training process is that both the Generator and the Discriminator can be neural networks, and the models can be trained using gradient descent.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the Generator</h1>
                </header>
            
            <article>
                
<p class="mce-root">The Generator's goal is to behave like the target distribution. For this reason, we have to define it as a network with a single neuron. We can sample one number at a time from the target distribution, and the same should be possible from the Generator.</p>
<p>There is no guideline or constraint for the model architecture definition. <span>The only restrictions are given from the nature of the problem, and these are the input and output dimensions. The output dimension, as we explained previously, depends on the target distribution, while the input dimension is the arbitrary dimension of the noise prior, which is often set to 100.</span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To solve this problem, we are going to define a simple three-layer neural network, with two hidden layers with 64 neurons each:</p>
<p><kbd>(tf2)</kbd></p>
<pre>def generator(input_shape):<br/>    """Defines the generator keras.Model.<br/>    Args:<br/>        input_shape: the desired input shape (e.g.: (latent_space_size))<br/>    Returns:<br/>        G: The generator model<br/>    """<br/>    inputs = tf.keras.layers.Input(input_shape)<br/>    net = tf.keras.layers.Dense(units=64, activation=tf.nn.elu, name="fc1")(inputs)<br/>    net = tf.keras.layers.Dense(units=64, activation=tf.nn.elu, name="fc2")(net)<br/>    net = tf.keras.layers.Dense(units=1, name="G")(net)<br/>    G = tf.keras.Model(inputs=inputs, outputs=net)<br/>    return G</pre>
<p>The <kbd>generator</kbd> function returns a Keras model. The Keras functional API has been used to define the model, although a Sequential was enough.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the Discriminator</h1>
                </header>
            
            <article>
                
<p>Just like the Generator, the Discriminator architecture depends on the target distribution. The goal is to classify samples into two categories. The input layer, therefore, depends on the size of the samples that have been sampled from the target distribution; in our case, it is one. The output layer is a single linear neuron that's used to classify the sample into two categories.</p>
<p>The activation function is linear because the Keras loss function applies the sigmoid:</p>
<p><kbd>(tf2)</kbd></p>
<pre>def disciminator(input_shape):<br/>    """Defines the Discriminator keras.Model.<br/>    Args:<br/>        input_shape: the desired input shape (e.g.: (the generator output shape))<br/>    Returns:<br/>        D: the Discriminator model<br/>    """<br/>    inputs = tf.keras.layers.Input(input_shape)<br/>    net = tf.keras.layers.Dense(units=32, activation=tf.nn.elu, name="fc1")(inputs)<br/>    net = tf.keras.layers.Dense(units=1, name="D")(net)<br/>    D = tf.keras.Model(inputs=inputs, outputs=net)<br/>    return D</pre>
<p>After defining the Generator and Discriminator architecture, we only have to instantiate the Keras models by specifying the correct input shapes:</p>
<p><kbd>(tf2)</kbd></p>
<pre><span class="c1"># Define the real input shape<br/></span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>

<span class="c1"># Define the Discriminator model</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">disciminator</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="c1"># Arbitrary set the shape of the noise prior</span>
<span class="n">latent_space_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,)</span>
<span class="c1"># Define the input noise shape and define the generator</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">latent_space_shape</span><span class="p">)</span></pre>
<p>The models and the target data distribution have been defined; the only thing that's missing is expressing the relationships between them, which is done by defining the loss functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the loss functions</h1>
                </header>
            
            <article>
                
<p>As shown in the previous section, the Discriminator's output is linear because the <kbd>loss</kbd> function we are going to use applies the nonlinearity for us. To implement the adversarial training process by following the original formulation, the <kbd>loss</kbd> function to use is binary cross-entropy:</p>
<p><kbd>(tf2)</kbd></p>
<pre>bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)</pre>
<p>The <kbd>bce</kbd> object is used to compute the binary cross-entropy between two distributions:</p>
<ul>
<li>The learned distribution, which is represented by the Discriminator's output, is squashed into the [0,1] range (by applying it the sigmoid <img class="fm-editor-equation" src="assets/6a8ca1bf-50ed-4882-a26a-b442cf60f361.png" style="width:0.92em;height:0.92em;"/> function, since the <kbd>from_logits</kbd> parameter is set to <kbd>True</kbd>). This produces a value closer to one if the Discriminator classifies the input as coming from the real data distribution.</li>
<li>The conditional empirical distribution over class labels, that is, a discrete probability distribution where the probability of it being a real sample, is labeled as 1 and is 0 otherwise.</li>
</ul>
<p>Mathematically, the binary cross-entropy between the conditional empirical distribution over class labels (<img class="fm-editor-equation" src="assets/7ce7c2cd-5b7a-4df6-9de3-9b7a0b6a1c1f.png" style="width:0.58em;height:0.92em;"/>) and the generator output squashed in [0,1] (<img class="fm-editor-equation" src="assets/47650b3e-1949-4757-99e5-f10970d72bcf.png" style="width:5.58em;height:1.17em;"/>) is expressed as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/74737ade-b438-4b83-bbc1-336c6f8297fb.png" style="width:20.17em;height:1.42em;"/></p>
<p>We want to train the Discriminator to correctly classify real and fake data: correctly classifying the real data can be seen as the maximization of <img class="fm-editor-equation" src="assets/f4a69c26-6d2d-4d9d-acd3-19c9797b2aac.png" style="width:9.00em;height:1.42em;"/>, while the correct classification of the fake data is the maximization of <img class="fm-editor-equation" src="assets/bd7a3ae6-9748-49ae-bee6-0430dc8d0b53.png" style="width:10.83em;height:1.25em;"/>.</p>
<p>By replacing the expected value with the empirical mean over a batch of <em>m</em> samples, it is possible to express the maximization of the log probability of correctly classifying a sample as the sum of two BCEs:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/decb28ca-6b2f-450b-a5a4-6503df00be02.png" style="width:27.58em;height:3.33em;"/></p>
<p>The first term is the BCE between the label <img class="fm-editor-equation" src="assets/538f700e-e62b-4f8a-a414-9eebc0e3b525.png" style="width:2.42em;height:1.08em;"/> and the Discriminator output when given a real sample as input, while the second term is the BCE between the label <img class="fm-editor-equation" src="assets/43bf107b-e712-4374-97ac-33403ff44bc0.png" style="width:2.25em;height:1.00em;"/> and the Discriminator output when given a fake sample as input.</p>
<p>Implementing this loss function in TensorFlow is straightforward:</p>
<p><kbd>(tf2)</kbd></p>
<pre>def d_loss(d_real, d_fake):<br/>    """The disciminator loss function."""<br/>    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)</pre>
<p><span>The same </span><kbd>bce</kbd><span> object we created previously is used inside the </span><kbd>d_loss</kbd><span> function since it is a stateless object that only computes the binary cross-entropy between its inputs.</span></p>
<div class="packt_infobox">Please note that there is no need to add a minus sign in front of the <kbd>bce</kbd> invocations to maximize them; the mathematical formulation of the BCE already contains the minus sign.</div>
<p>The generator loss function follows on from this theory. Implementing the non-saturating value function only consists of the TensorFlow implementation of the following formula:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3c6fa83f-45fe-48eb-a1e1-3121fc5cb745.png" style="width:14.50em;height:3.75em;"/></p>
<p>This formula is the binary cross-entropy between the log probability of the generated images and the distribution of the real images (labeled with 1). In practice, we want to maximize the log probability of the generated samples, updating the Generator parameters in order to make the Discriminator classify them as real (label 1).</p>
<p>The TensorFlow implementation is trivial:</p>
<p><kbd>(tf2)</kbd></p>
<pre>def g_loss(generated_output):<br/>    """The Generator loss function."""<br/>    return bce(tf.ones_like(generated_output), generated_output)</pre>
<p>Everything is set up to implement the adversarial training process.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adversarial training process in unconditional GANs</h1>
                </header>
            
            <article>
                
<p><span>As we explained at the beginning of this chapter, the adversarial training process is where we alternate the execution of the training steps for the Discriminator and Generator. The Generator requires the value that's computed by the Discriminator to perform its parameter update, while the Discriminator requires the generated samples (also known as fake input) and the real samples.</span></p>
<p>TensorFlow allows us to define a custom training loop easily. The <kbd>tf.GradientTape</kbd> object, in particular, is extremely useful for computing the gradient of a specific model, even when there are two models interacting. In fact, thanks to the <kbd>trainable_variables</kbd> property of every Keras model, it is possible to compute the gradient of a certain function, but only with respect to these variables.</p>
<p class="mce-root"/>
<p>The training process is exactly like the one that's described in the GAN paper <span>(</span><em>Generative Adversarial Networks - Ian Goodfellow et a<span>l.)</span></em>, thanks to the eager mode. Moreover, since this training process can be computationally intensive (especially on big datasets where the data distribution that we want to capture is complex), it is worth decorating the training step function with <kbd>@tf.function</kbd> in order to speed up the computation by converting it into a graph:</p>
<p><kbd>(tf2)</kbd></p>
<pre>def train():<br/>    # Define the optimizers and the train operations<br/>    optimizer = tf.keras.optimizers.Adam(1e-5)<br/>    <br/>    @tf.function<br/>    def train_step():<br/>        with tf.GradientTape(persistent=True) as tape:<br/>            real_data = sample_dataset()<br/>            noise_vector = tf.random.normal(<br/>                mean=0, stddev=1,<br/>                shape=(real_data.shape[0], latent_space_shape[0]))<br/>            # Sample from the Generator<br/>            fake_data = G(noise_vector)<br/>            # Compute the D loss<br/>            d_fake_data = D(fake_data)<br/>            d_real_data = D(real_data)<br/>            d_loss_value = d_loss(d_real_data, d_fake_data)<br/>            # Compute the G loss<br/>            g_loss_value = g_loss(d_fake_data)<br/>        # Now that we comptuted the losses we can compute the gradient<br/>        # and optimize the networks<br/>        d_gradients = tape.gradient(d_loss_value, D.trainable_variables)<br/>        g_gradients = tape.gradient(g_loss_value, G.trainable_variables)<br/>        # Deletng the tape, since we defined it as persistent<br/>        # (because we used it twice)<br/>        del tape<br/>        <br/>        optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))<br/>        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))<br/>        return real_data, fake_data, g_loss_value, d_loss_value</pre>
<p><span>In order to visualize what the Generator is learning during the training process, we plot the same graph values that were sampled from the target distribution (in orange), as well as the values that were sampled from the </span>Generator (<span>in blue):</span></p>
<p><kbd>(tf2)</kbd></p>
<pre>    fig, ax = plt.subplots()<br/>    for step in range(40000):<br/>        real_data, fake_data,g_loss_value, d_loss_value = train_step()<br/>        if step % 200 == 0:<br/>            print("G loss: ", g_loss_value.numpy(), " D loss: ", d_loss_value.numpy(), " step: ", step)<br/><br/>            # Sample 5000 values from the Generator and draw the histogram<br/>            ax.hist(fake_data.numpy(), 100)<br/>            ax.hist(real_data.numpy(), 100)<br/>            # these are matplotlib.patch.Patch properties<br/>            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)<br/><br/>            # place a text box in upper left in axes coords<br/>            textstr = f"step={step}"<br/>            ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,<br/>                    verticalalignment='top', bbox=props)<br/><br/>            axes = plt.gca()<br/>            axes.set_xlim([-1,11])<br/>            axes.set_ylim([0, 60])<br/>            display.display(pl.gcf())<br/>            display.clear_output(wait=True)<br/>            plt.gca().clear()</pre>
<p>Now that we've defined the whole training loop as a function, we can execute it by calling <kbd>train()</kbd>.</p>
<p>The <kbd>train_step</kbd> function is the most important of the whole snippet since it contains the implementation of the adversarial training. A peculiarity that is worth highlighting is how, by using <kbd>trainable_variables</kbd>, it has been possible to compute the gradients of the loss function with respect to the model parameters we are interested in, while considering everything else constant.</p>
<p>The second peculiarity has been the usage of a persistent gradient tape object. Using a persistent tape allowed us to keep track of the execution while allocating a single object in memory (the tape) and using it twice. If the tape had been created non-persistently, we couldn't reuse it since it would be automatically destroyed after the first <kbd>.gradient</kbd> invocation.</p>
<p>Instead of visualizing the data using TensorBoard (this is left as an exercise for you), we followed the matplotlib approach we've used so far and sampled 5,000 data points every 200 training steps from both the target and the learned distributions, and then visualized them by plotting the corresponding histograms.</p>
<p>During the initial training steps, the learned distribution is different from the target one, as shown in the following graph:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-930 image-border" src="assets/3c0953dc-73f8-4d9d-bc28-086ed9940865.png" style="width:28.67em;height:19.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Data visualization at the 2,600th training step. The target distribution is a random normal distribution with a mean of 10 and a standard deviation of 0.1. The values that were sampled from the learned distribution are slowly shifting toward the target distribution.</div>
<p>During the training phase, it is possible to appreciate how the Generator is learning to approximate the target distribution:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="aligncenter size-full wp-image-929 image-border" src="assets/44a936c4-6db5-4e5b-981c-c0fe8d062daf.png" style="width:28.25em;height:19.58em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span><span>Data visualization at the 27,800th training step. The learned distribution is approaching the mean value of 10 and is reducing its variance.</span></span></div>
<p>In the late training stages, the two distributions almost completely overlap and the training process can be stopped:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-928 image-border" src="assets/1a6d82a3-cbfb-47a2-91a7-8b77ca46ce64.png" style="width:24.83em;height:16.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Data visualization at the 39,000th training step. The target distribution and the learned distribution overlap.</div>
<p>Thanks to the expressive power of the Keras model and the ease of usage of the TensorFlow eager mode (plus the graph-conversion via <kbd>tf.function</kbd>), defining two models and training them by manually implementing the adversarial training process has been almost trivial.</p>
<p>Although trivial, this is the very same training loop that we use when working with different data types. In fact, the same training loop can be used to train image, text, and even audio generators, except that we use different Generator and Discriminator architectures in those cases.</p>
<p>A slightly modified version of the GAN framework allows you to collect a conditional generation of samples; for example, the Generator is trained to generate specific samples when given a condition.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conditional GANs</h1>
                </header>
            
            <article>
                
<p>Mirza et al. in their paper, <span><em>Conditional Generative Adversarial Nets</em>, introduced a conditional version of the GAN framework. This modification is extremely easy to understand and is the foundation of amazing GAN applications that are widely used in today's world.</span></p>
<p>Some of the most astonishing GAN applications, such as the generation of a street scene from a semantic label to the colorization of an image given a grayscale input, pass through image super-resolution as specialized versions of the conditional GAN idea.</p>
<p>Conditional GANs are based on the idea that GANs can be extended to a conditional model if both G and D are conditioned on some additional information, <em>y</em>. This additional information can be any kind of additional information, from class labels to semantic maps, or data from other modalities. It is possible to perform this conditioning by feeding the additional information into both the Generator and the Discriminator as an additional input layer. The following diagram, which was taken from the <em>Conditional Generative Adversarial Nets</em> paper, clearly shows how the Generator and Discriminator models can be extended to support the conditioning:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-927 image-border" src="assets/c2f44c63-45d8-4591-972b-2f778dcecb59.png" style="width:35.92em;height:30.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Conditional GANs. The Generator and the Discriminator have one additional input, y, which represents the auxiliary information that conditions the models (Image source: <em>Conditional Generative Adversarial Nets</em>, Mirza et al., 2014).</div>
<p>The generator architecture is extended to combine the joint hidden representation of the noise prior to the condition. There are no constraints on how to feed the condition to the Generator network. You can simply concatenate the condition to the noise vector. Alternatively, if the condition is complex, you can encode it using a neural network and concatenate its output to one layer of the Generator. The same reasoning applies to the Discriminator.</p>
<p>Conditioning the models changes the value's function since the data distributions that we sample from are now conditioned:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/398f42ea-5f04-438b-a766-c0ab7da52270.png" style="width:43.08em;height:2.08em;"/></p>
<p class="mce-root">There are no other changes in regards to the adversarial training process, and the same considerations about the non-saturating value function still apply.</p>
<p>In this section, we are going to implement a conditional Fashion-MNIST generator.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting the data for a conditional GAN</h1>
                </header>
            
            <article>
                
<p>By using TensorFlow Datasets, getting the data is straightforward. Since the goal is to create a Fashion-MNIST generator, we will use the class labels as a condition. The data that's returned from the <kbd>tfds.load</kbd> call is in a dictionary format. Therefore, we need to define a function that maps the dictionary to a tuple that contains only the image and the corresponding label. In this phase, we can also prepare the whole data input pipeline:</p>
<p><kbd>(tf2)</kbd></p>
<pre>import tensorflow as tf<br/>import tensorflow_datasets as tfds<br/>import matplotlib.pyplot as plt<br/><br/>dataset = tfds.load("fashion_mnist", split="train")<br/><br/>def convert(row):<br/>  image = tf.image.convert_image_dtype(row["image"], tf.float32)<br/>  label = tf.cast(row["label"], tf.float32)<br/>  return image, label<br/><br/>batch_size = 32<br/>dataset = dataset.map(convert).batch(batch_size).prefetch(1)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the Generator in a conditional GAN</h1>
                </header>
            
            <article>
                
<p>Since we are working with images, the natural choice is to use a convolutional neural network. In particular, using the deconvolution operation we introduced in <a href="51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml">Chapter 8</a>, <em>Semantic Segmentation and Custom Dataset Builder</em>, it is possible to easily define a decoder-like network that generates images, starting from a latent representation and a condition:</p>
<p> </p>
<p><kbd>(tf2)</kbd></p>
<pre>def get_generator(latent_dimension):<br/>  <br/>  # Condition subnetwork: encode the condition in a hidden representation<br/>  condition = tf.keras.layers.Input((1,))<br/>  net = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)<br/>  net = tf.keras.layers.Dense(64, activation=tf.nn.elu)(net)<br/>  <br/>  # Concatenate the hidden condition representation to noise and upsample<br/>  noise = tf.keras.layers.Input(latent_dimension)<br/>  inputs = tf.keras.layers.Concatenate()([noise, net])<br/>  <br/>  # Convert inputs from (batch_size, latent_dimension + 1) <br/>  # To a 4-D tensor, that can be used with convolutions<br/>  inputs = tf.keras.layers.Reshape((1,1, inputs.shape[-1]))(inputs)<br/>  <br/>  depth = 128<br/>  kernel_size= 5<br/>  net = tf.keras.layers.Conv2DTranspose(<br/>      depth, kernel_size,<br/>      padding="valid",<br/>      strides=1,<br/>      activation=tf.nn.relu)(inputs) # 5x5<br/>  net = tf.keras.layers.Conv2DTranspose(<br/>      depth//2, kernel_size,<br/>      padding="valid",<br/>      strides=2,<br/>      activation=tf.nn.relu)(net) #13x13<br/>  net = tf.keras.layers.Conv2DTranspose(<br/>      depth//4, kernel_size,<br/>      padding="valid",<br/>      strides=2,<br/>      activation=tf.nn.relu,<br/>      use_bias=False)(net) # 29x29<br/>  # Standard convolution with a 2x2 kernel to obtain a 28x28x1 out<br/>  # The output is a sigmoid, since the images are in the [0,1] range<br/>  net = tf.keras.layers.Conv2D(<br/>      1, 2,<br/>      padding="valid",<br/>      strides=1,<br/>      activation=tf.nn.sigmoid,<br/>      use_bias=False)(net)<br/>  model = tf.keras.Model(inputs=[noise, condition], outputs=net)<br/>  return model</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining the Discriminator in a conditional GAN</h1>
                </header>
            
            <article>
                
<p>The Discriminator architecture is straightforward. A standard way of conditioning the Discriminator consists of concatenating the encoded representation of the image, with the encoded representation of the condition being placed in a unique vector. Doing this requires the definition of two subnetworks <span>– </span>the first one encodes the image in a feature vector, while the second one encodes the condition in another vector. The following code clarifies this concept:</p>
<p><kbd>(tf2)</kbd></p>
<pre>def get_Discriminator():<br/>  # Encoder subnetwork: feature extactor to get a feature vector<br/>  image = tf.keras.layers.Input((28,28,1))<br/>  depth = 32<br/>  kernel_size=3<br/>  net = tf.keras.layers.Conv2D(<br/>      depth, kernel_size,<br/>      padding="same",<br/>      strides=2,<br/>      activation=tf.nn.relu)(image) #14x14x32<br/>  net = tf.keras.layers.Conv2D(<br/>      depth*2, kernel_size,<br/>      padding="same",<br/>      strides=2,<br/>      activation=tf.nn.relu)(net) #7x7x64<br/>  <br/>  net = tf.keras.layers.Conv2D(<br/>      depth*3, kernel_size,<br/>      padding="same",<br/>      strides=2,<br/>      activation=tf.nn.relu)(net) #4x4x96<br/>  <br/>  feature_vector = tf.keras.layers.Flatten()(net) # 4*4*96</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>After defining the encoder subnetwork that encoded the image into a feature vector, we are ready to create a hidden representation of the condition and concatenate it with the feature vector. After doing it, we can create the Keras model and return it:</p>
<p><kbd>(tf2)</kbd></p>
<pre>  # Create a hidden representation of the condition<br/>  condition = tf.keras.layers.Input((1,))<br/>  hidden = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)<br/>  hidden = tf.keras.layers.Dense(64, activation=tf.nn.elu)(hidden)<br/>  <br/>  # Concatenate the feature vector and the hidden label representation<br/>  out = tf.keras.layers.Concatenate()([feature_vector, hidden])<br/>  <br/>  # Add the final classification layers with a single linear neuron<br/>  out = tf.keras.layers.Dense(128, activation=tf.nn.relu)(out)<br/>  out = tf.keras.layers.Dense(1)(out)<br/>  <br/>  model = tf.keras.Model(inputs=[image, condition], outputs=out)<br/>  return model</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adversarial training process </h1>
                </header>
            
            <article>
                
<p>The adversarial training process is the same as what we presented for the unconditional GAN. The <kbd>loss</kbd> functions are exactly the same:</p>
<p><kbd>(tf2)</kbd></p>
<pre>bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)<br/><br/>def d_loss(d_real, d_fake):<br/>    """The disciminator loss function."""<br/>    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)<br/>  <br/>def g_loss(generated_output):<br/>    """The Generator loss function."""<br/>    return bce(tf.ones_like(generated_output), generated_output)</pre>
<p>The only difference is that our models now accept two input parameters.</p>
<p>After deciding on the noise's prior dimension and instantiated the G and D models, defining the train function requires a slight modification of the previous training loop. As for the unconditional GAN training loop definition, matplotlib has been used to log the images. Improving this script is left as an exercise for you to carry out:</p>
<p><kbd>(tf2)</kbd></p>
<pre>latent_dimension = 100<br/>G = get_generator(latent_dimension)<br/>D = get_Discriminator()<br/><br/><br/>def train():<br/>    # Define the optimizers and the train operations<br/>    optimizer = tf.keras.optimizers.Adam(1e-5)<br/>    <br/>    @tf.function<br/>    def train_step(image, label):<br/>        with tf.GradientTape(persistent=True) as tape:<br/>            noise_vector = tf.random.normal(<br/>            mean=0, stddev=1,<br/>            shape=(image.shape[0], latent_dimension))<br/>            # Sample from the Generator<br/>            fake_data = G([noise_vector, label])<br/>            # Compute the D loss<br/>            d_fake_data = D([fake_data, label])<br/>            d_real_data = D([image, label])<br/>            <br/>            d_loss_value = d_loss(d_real_data, d_fake_data)<br/>            # Compute the G loss<br/>            g_loss_value = g_loss(d_fake_data)<br/>        # Now that we comptuted the losses we can compute the gradient<br/>        # and optimize the networks<br/>        d_gradients = tape.gradient(d_loss_value, D.trainable_variables)<br/>        g_gradients = tape.gradient(g_loss_value, G.trainable_variables)<br/>        # Deletng the tape, since we defined it as persistent<br/>        del tape<br/>        <br/>        optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))<br/>        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))<br/>        return g_loss_value, d_loss_value, fake_data[0], label[0]<br/>    <br/>    epochs = 10<br/>    epochs = 10<br/>    for epoch in range(epochs):<br/>        for image, label in dataset:<br/>            g_loss_value, d_loss_value, generated, condition = train_step(image, label)<br/><br/>        print("epoch ", epoch, "complete")<br/>        print("loss:", g_loss_value, "d_loss: ", d_loss_value)<br/>        print("condition ", info.features['label'].int2str(<br/>                    tf.squeeze(tf.cast(condition, tf.int32)).numpy()))<br/>        plt.imshow(tf.squeeze(generated).numpy(), cmap='gray')<br/>        plt.show()</pre>
<p>The training loop loops over the training set for 10 epochs and displays an image of a generated Fashion-MNIST element, along with its label. After a few epochs, the generated images become more and more realistic and they start matching the label, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-926 image-border" src="assets/3cf10f11-0a41-45fa-938c-710062e95f9a.png" style="width:16.58em;height:16.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">A generated sample feeding in input to the Generator's random noise and the condition T-shirt/top</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we looked at GANs and the adversarial training process. In the first section, a theoretical explanation of the adversarial training process was presented, with a focus on the value function, which is used to formulate the problem as a min-max game. We also showed how the non-saturating value function is, in practice, the solution to making the Generator learn how to solve the saturation problem.</p>
<p>We then looked at implementing the Generator and Discriminator models that are used to create an unconditional GAN in pure TensorFlow 2.0. In this section, the expressive power of TensorFlow 2.0 and the definition of custom training loops was presented. In fact, it has been shown how straightforward it is to create Keras models and write the custom training loop that implements the adversarial training process, just by following the steps described in the GAN paper (<em>Generative Adversarial Networks - Ian Goodfellow et a<span>l.)</span></em><em><span>.</span></em></p>
<p>The Keras functional API has been also extensively used, where a conditional generator of Fashion-MNIST-like images has been implemented. The implementation showed us how, by using the Keras functional API, it is possible to feed a second input (the condition) to both the Generator and Discriminator and define a flexible neural network architecture easily.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The GAN universe is rich in terms of very complex architectures and clever ideas for astonishing applications. This chapter aims to explain the GAN framework without claiming to be complete; there's enough material out there about GANs for me to write more than a whole book.</p>
<p>This chapter ends with an exercise section, which contains a challenge for you (questions 16 and 17): can you create a conditional GAN that generates realistic images, starting from a semantic label?</p>
<p>So far, we've focused on how to train various models, from simple classifiers to generative models, without worrying about the deployment stage.</p>
<p>I<span>n the next chapter, <a href="889170ef-f89d-4485-a111-6cd4e72f0daa.xhtml">Chapter 10</a>, </span><em>Bringing a Model to Production</em>, the final step of every real-life machine learning application will be presented <span>– </span>the deployment of learned models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercises</h1>
                </header>
            
            <article>
                
<p>Try answering and working on the following exercises to expand the knowledge that you've gained from this chapter:</p>
<ol>
<li>What is the adversarial training process?</li>
<li>Write the value function of the min-max game that the Discriminator and Generator are playing.</li>
<li>Explain why the min-max value function formulation can saturate in the early training step of training.</li>
<li>Write and explain the non-saturating value function.</li>
<li>Write the rules of the adversarial training process.</li>
<li>Are there any recommendations on how to feed a condition to a GAN?</li>
<li>What does it mean to create a conditional GAN?</li>
<li>Can only the fully connected neural networks be used to create GANs?</li>
<li>Which neural network architecture works better for the image generation problem?</li>
<li>Update the code of the Unconditional GAN: Log the Generator and Discriminator loss value on TensorBoard, and also log matplotlib plots.</li>
<li>Unconditional GAN: Save the model parameter in a checkpoint at every epoch. Add support for the model's restoration, restarting from the latest checkpoint.</li>
</ol>
<ol start="12">
<li>Extend the code of the unconditional GAN by making it conditional. Given the condition of 0, the Generator must behave like the normal distribution, with a mean of 10 and a standard deviation of 0.1. Given the condition of 1, the Generator must produce a value that has been sampled from a Gaussian distribution with a mean of 100 and a standard deviation of 1.</li>
<li>Log the magnitude of the Gradient that was computed to update the Discriminator and Generator in TensorBoard. Apply gradient clipping if the magnitude is greater than 1 in an absolute value.</li>
<li>Repeat exercises 1 and 2 for the conditional GAN.</li>
<li>Conditional GAN: Do not use matplotlib to plot the images; use <kbd>tf.summary.image</kbd> and TensorBoard.</li>
<li>Using the dataset we created in the previous chapter, <a href="51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml">Chapter 8</a>, <em>Semantic Segmentation and Custom Dataset Builder</em>, create a conditional GAN that performs domain translation, from the semantic label to an image.</li>
<li>Use TensorFlow Hub to download a pre-trained feature extractor and use it as a building block to create the Discriminator for a conditional GAN that generates realistic scenes from semantic labels.</li>
</ol>


            </article>

            
        </section>
    </body></html>