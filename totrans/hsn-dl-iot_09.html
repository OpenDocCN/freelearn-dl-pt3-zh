<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">IoT Security</h1>
                </header>
            
            <article>
                
<p>The use of IoT is growing at a dangerously fast pace, and both researchers and industries have estimated that, the number of active wirelessly connected devices will exceed 20 billion. This exponential growth of IoT devices is increasing the risks to our lives and property, as well as to the entire IT industry. To have more connected devices means more attack vectors, and more opportunities for hackers to exploit. In this context, secure IoT is not only essential for its applications, but also for the rest of the IT industry. </p>
<p>In IoT security solutions, networks and devices can be viewed as either signature-based or  behavior-based. Behavior-based solutions, such as anomaly detection, are preferable in IoT as preparing and maintaining signatures of dynamic and unknown IoT attacks is very difficult.  Similarly to human behavior analysis, <span class="st"><strong>deep learning</strong> (<strong>DL</strong>)</span><span class="st">/<strong>machine learning</strong> (</span><strong>ML</strong>) models can be used in IoT for data exploration, and for learning normal and abnormal behavior (security perspective) of IoT devices and networks, in various IoT application environments. </p>
<p>This chapter presents <span>behavioral data analysis of DL-based networks and devices</span>, and security incident detection techniques for IoT applications in general. In the first part of this chapter, we will briefly describe different IoT security attacks and their potential detection techniques, including DL/ML-based methods. In addition, we will briefly discuss two IoT use cases where security attacks—such as <strong>Denial of Service</strong> (<strong>DoS</strong>) and <strong>Distributed DoS</strong> (<strong>DDoS</strong>) attacks<strong>—</strong>can be detected intelligently and automatically through <span>DL-based anomaly detection</span>. In the second part of the chapter, we will present hands-on DL-based security incident detection implementations. In this chapter, we will cover the following topics:</p>
<ul>
<li>IoT security attacks and potential detection approaches</li>
<li>Use case one—intelligent host intrusion detection in IoT</li>
<li>Implementation of i<span><span>ntelligent host intrusion detection in IoT</span></span></li>
<li>Use case two—intelligent network intrusion detection in IoT</li>
<li>Implementation of i<span>ntelligent network intrusion detection in IoT</span></li>
<li>DL for IoT security incident detection</li>
<li><strong>Deep neural networks</strong> (<strong>DNN</strong>), <strong>autoencoder</strong>, and <span class="st"><strong>long short-term memory</strong></span> (<strong>LSTM</strong>) in IoT security incident detection</li>
<li>Data collection</li>
<li>Data preprocessing</li>
<li>Models training</li>
<li>Evaluation of the models</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security attacks in IoT and detections</h1>
                </header>
            
            <article>
                
<p>According to statistics, there will be more than 26 billion connected IoT devices worldwide. These devices, which include smart TVs, tablets, smartphones, notebooks, wearables, sensors, thermostats, and others, will make our lives more efficient, more energy saving, more comfortable, and less costly. However, these can only be realized when the security of these applications are maintained as, in many cases, these devices are dealing with mission-critical applications.</p>
<p>The reality is that IoT security is currently the number-one challenge faced by IoT industries. Without proper security solutions in place, data traversing the public internet, especially wirelessly connected devices, is vulnerable to hackers. In this context, the entire IoT pipeline or pathway needs to be secure. In other words, IoT needs <strong>end-to-end</strong> (<strong>E2E</strong>) security, where data must be secured from the time it leaves the end device or appliance, throughout its journey to and from the cloud, until it reaches the end user's mobile app or browser-based application. In addition, once it has been processed and a decision has been made on this in the user device/app, it has to follow a secure backward path for actuating or carrying the control instructions to the device. The following diagram presents an E2E (three-layered) view of an IoT solution, and the security requirements of the main three layers:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1087 image-border" src="assets/11c6b11a-5415-4d2e-a124-5f320e994b00.png" style="width:76.08em;height:38.75em;"/></p>
<p>The following diagram presents a summary of the main attacks in IoT in a three-layered perspective:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1081 image-border" src="assets/824f25d1-8d25-46a3-b1a9-c7592ef04b68.png" style="width:162.50em;height:50.75em;"/></p>
<p>Designing and developing IoT security solutions is a very challenging task. For example, such devices are generally termed "embedded" devices; these have a fixed function designed specifically to perform a specialized task. They are resource-constrained, in terms of operating system, processing power, and memory. Traditional and PC security solutions are not suitable, as they will not even run on most embedded devices. Importantly, there are a large number of devices with vulnerabilities to be exploited by attackers. For example, in a smart home, we have more IoT/smart devices than our PC/laptops.</p>
<p class="mce-root"/>
<p>Very soon, our homes will be equipped with ample connected devices that could compete with the number of connections in a mid-sized company. In this context, managing updates, passwords, and settings for these connected devices alone, without the support of an IT security team or any expensive and enterprise level security tools, will be nightmare. Automated approaches based on <strong>artificial intelligence</strong> (<strong>AI</strong>)—especially DL/ML—can reactively and/or proactively find the security issues and help us to manage them. AI-based solutions can take two different forms: </p>
<ul>
<li><strong>Network-based solution</strong>: A network-based solution aims to secure IoT devices of an IoT application by making a protective shield around the network of the application. This approach maintains a whitelist of devices that are allowed to access an IoT application network to prevent intruders from getting into the network. However, the IoT devices need to access to and be accessed from the outside world, such as from the cloud and smartphone applications. A DL/ML engine can monitor incoming and outgoing traffic to the IoT devices, and create a profile that defines the normal behavior of the IoT application. The DL/ML engine will detect any incoming threat by comparing it with established normal behavior. U<span>nlike</span> <span>enterprise networks, AI-based threat detection is easier in IoT as, generally, the functionality of an IoT device is very limited, and it is not easy to disguise the IoT devices in malicious requests. In addition, it is easier to define a finite set of rules to determine normal and anomalous behavior for IoT devices. For example, a smart bulb communicating with the smart fridge in a smart home is not a normal behavior, and it is easy to detect as the bulb is for lighting and does not need to communicate with the fridge to produce light.</span></li>
<li><strong>Device-based solutions</strong>: Generally, IoT devices are resource-constrained in terms of processing power and storage capacity. Hence, signature-based security solutions are not suitable for IoT devices as they require huge databases of threat and malware signature storage. Like network-based solutions, DL/ML-supported automated behavior-based solutions are better alternatives as they are less resource-hungry. In addition, they can run without bogging down small processors.</li>
</ul>
<p>Although, many people prefer network-based solutions over device-based ones, our recommendation would be to opt for both as they will offer stronger protection for your IoT devices as well as for the rest of the world.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Anomaly detection and IoT security</h1>
                </header>
            
            <article>
                
<p>Network- and device-level behavioral anomaly detection is an important means of detecting potential security incidents, including DoS <span>or</span> DDoS, or any general intrusions. Anomaly detection mechanisms can be divided into many subclasses:</p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Statistical methods</strong>: These methods use past behaviors to approximate a model of the correct behavior of a sensor or thing. If the things or networks observe a new behavior, it is compared to the model and, if statistically incompatible, is marked as an anomaly.</li>
<li class="CDPAlignLeft CDPAlign"><strong>Probabilistic methods</strong>: These methods center around the definition of a probabilistic model (parametric or nonparametric). If any the probability of an incident within a device or network falls below a predefined threshold, then it is labelled as an anomalous event.</li>
<li class="CDPAlignLeft CDPAlign"><strong>Proximity-based methods</strong>: These methods are based on the distances between normal and anomalous behavior. Clustering methods also fall into this class.</li>
<li class="CDPAlignLeft CDPAlign"><strong>Prediction-based methods</strong>: These methods use past network/device behavioral data to train a model that can predict the behavior of any incoming or outgoing traffic and identify  anomalies. This is the method we will be using in our two use cases. The first is anomaly detection for host level or device level intrusion detection, and the second is network level intrusion detection.</li>
</ul>
<p>DoS and DDoS intrusion incidents are common in IoT applications. IoT devices could be the target for these attacks and/or IoT devices can be exploited by attackers to generate flooding traffic to initiate and run DDoS attacks. These attacks can be launched in different layers of an IoT protocol stack, including the network, transport, and application layers. Generally, the detection of DDoS attacks launched at the application layer is very challenging, as the request packets look similar to the normal request packets. As a consequence of this attack, we may observe explicit behaviors in terms of resource exhaustion, such as network bandwidth, CPU processing, and memory. For instance, a swarm of IoT devices hijacked by Mirai malware generated about 1 Tbps of DDoS traffic to a French web host in September 2016<sup>[3]</sup>. In this context, it is essential to detect host/IoT device level as well as IoT network level intrusions so that IoT applications become available for their intended use and/or they do not become the means for making a DDoS attack on others. In the following sections, we present one use case on IoT device-level <span>intrusion detection,</span> and another on IoT network level <span>intrusion detection.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case one: intelligent host intrusion detection in IoT</h1>
                </header>
            
            <article>
                
<p>Very often, resource-constrained IoT devices become the target for DoS or DDoS attacks by intruders that can make the IoT application unavailable to the consumers. For example, consider an IoT-based remote patient-monitoring system. If the sensor's reading of the patient at a critical time, such as during a heart attack, are not available to their doctors or hospital, the patient may lose their life. In this context, devices or host level intrusion detection is essential for most IoT applications. In use case one, we will consider IoT device or host level intrusion detection.</p>
<p>It is essential to select a good feature or set of features to determine anomalies in IoT devices and networks (such as DoS and DDoS) using predictive methods, including DL. Often, we need time series data for real-time or online anomaly detection, and if we can exploit any data source that is already in this form, we do not need additional feature engineering. CPU utilization data of IoT devices do not need further engineering for host/device level anomaly detection.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation of use case one</h1>
                </header>
            
            <article>
                
<p>We are considering an IoT-based, remote patient-monitoring application for the implementation of intelligent host-level intrusion detection. Monitoring of physiotherapy is a challenging task. An IoT-based therapy can solve the progress-monitoring issue. The following diagram briefly presents how the IoT-based remote-patient monitoring system and its device-level intrusion detection will work:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ab7c8831-c61e-4176-8a12-d63cc41ff17d.png"/></p>
<p>As shown in the preceding diagram, an IoT-based remote patient-monitoring system consists of three main elements:</p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Sensors and patient-side computing platform</strong>: A patient will be attached to multiple sensors, including an electrocardiograph, blood pressure sensor, accelerometer, and a gyroscope. These sensors will be collecting physiological and activity-related information and sending it to care providers for necessary and real-time feedback. However, the data from these sensors or things can be unavailable because of DoS or DDoS attack. An intruder can launch a DoS attack by flooding these sensors with excessive requests in an attempt to overload it, preventing legitimate requests from being fulfilled. Similarly, the attacker can launch a DDoS attack by flooding these sensors from many different distributed sources. A Raspberry Pi 3 connected with the home network can work as the patient-side computing platform and as the sensor-level intrusion detector.</li>
<li class="CDPAlignLeft CDPAlign"><strong>DL-based intrusion detection</strong>: The <span>R</span>aspberry Pi 3 will be preinstalled with a DL-based anomaly detector that will analyze sensors and its CPU utilization to detect any potential intrusion into the sensors and computing platform. If the sensors come without any MCU, we will consider intrusion detection for the Raspberry Pi 3. The detector will continuously monitor CPU-utilization of the Raspberry Pi 3, and if an anomaly is found it will be reported to the management team for countermeasure.</li>
<li class="CDPAlignLeft CDPAlign"><strong>Healthcloud for model learning</strong>: The healthcloud is a cloud computing platform, mainly designed for healthcare-related services. This will train the selected DL model for anomaly detection using a reference dataset.</li>
</ul>
<p>In the second part of the chapter (that is, the sections starting from <em>DL for IoT security incident detection</em>), we will describe the implementation of DL-based anomaly detection in the preceding use case. <span>All the necessary codes are available in the chapter's code folder.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case two: traffic-based intelligent network intrusion detection in IoT</h1>
                </header>
            
            <article>
                
<p>Generally, host intrusion (including device level intrusion) exploits outside world communications, and most of the time a successful host intrusion comes with the success of a network intrusion. For example, in botnets, remote command-and-control servers communicate with the compromised machines to give instructions on operations to execute. More importantly, a large number of insecure IoT devices has resulted in a surge of IoT botnet attacks in worldwide IT infrastructure. The Dyn <strong>domain name system</strong> (<strong>DNS</strong>) attack in October 2016 is an example of this, wherein the Mirai botnet commanded 100,000 IoT devices to launch the DDoS attack. This incident impacted many popular websites, including GitHub, Amazon, Netflix, Twitter, CNN, and PayPal.  In this context, detection of network-level intrusion in IoT is not only necessary for IoT applications, but also for the rest of the IT industry.</p>
<p>Generally, a network intrusion detector identifies intruders by inspecting traffic that passes between the hosts in the network. Like host intrusion detection, network intrusion detection can be signature-based or anomaly detection-based. In the signature-based approach, all incoming traffic will be compared with a list of known signatures of malicious traffic, and the in the anomaly detection approach, it compares the incoming traffic with previously established normal behavior. Considering the resource-intensive aspect of the former approach, we will consider anomaly detection-based <strong><span class="st">intrusion detection system</span></strong> (<strong>IDS</strong>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementation of use case two</h1>
                </header>
            
            <article>
                
<p>Unlike traditional networks, IDS in IoT needs to be lightweight, distributed to different layers, and long-lasting. The first condition is obvious for resource-constrained IoT devices. The solution needs to be distributed over many layers to optimize the effectiveness of the detection process. Importantly, the solution needs to be usable for long-lasting IoT devices. For example, a smart fridge could be in a house for more than 10 years, and finding a security solution that can withstand that length of time is a difficult task.</p>
<p>The <span><span>following</span></span> diagram presents an IoT infrastructure, including a multilayered network IDS, which can address the first two requirements of the IDS in an IoT. For example, an IoT deployment consists of different components that are distributed and resource constrained. A system-wide holistic IDS may not work well in terms of a real-time response. In this context, each layer in a multilayered IDS will work on identifying the layer-specific anomalies and the corresponding intruders in real time or quasi real time:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/447c4d8b-d209-4b80-91b7-96550945f1cc.png" style="width:36.08em;height:35.58em;"/></p>
<p class="mce-root"/>
<p>The multilayered network IDS of an IoT (especially in a smart home application) consists of the following three main elements:</p>
<ul>
<li><strong>Sensors/things and an edge computing platform</strong>: Smart-home devices, such as smart TVs, smart fridges, thermostats, smart bulbs, and home physical security cameras, are the sensors or 'things' of the use case. These devices are connected to the internet via a home router/gateway. In this use case, we are considering a network-based security solution rather than a device-based solution. We are also assuming that the home router will work as the edge computing device and allow us to install the multilayered IDS.</li>
<li><strong>DL-based intrusion detection</strong>: The home router/gateway will be preinstalled with three (one for each layer) DL-based anomaly detectors that will analyze the traffics/packets coming from the home's connected things. Each of the detectors will analyze and compare with that layer's normal traffic to find any anomaly or intrusion that, if detected, will be reported to the home owner and/or automatically set up countermeasure.</li>
<li><strong>Model learning platform</strong>: A home desktop or cloud platform will be needed to learn and update the DL model for the anomaly detectors. This will train the selected DL model/models for anomaly detection using three reference datasets.</li>
</ul>
<p>All of the following sections will describe the implementation of the DL-based network-level and node-level anomaly detection of the above use cases. All of the necessary code is available in the chapter's code folder.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DL for IoT security incident detection</h1>
                </header>
            
            <article>
                
<p>Traditional security solutions (such as encryption, authentication, access control, and network security) are ineffective for IoT devices. In recent years, DL/ML-based solutions have become very popular alternatives to traditional solutions. DL/ML-based solutions can monitor IoT devices and their networks intelligently and detect various new or zero-day attacks. Importantly, DL/ML can detect and/or predict various devices and network level security incidents through anomaly detection. By gathering, processing, and analyzing data about various normal and abnormal activities of devices/things and their networks, these DL/ML methods can identify various security incidents, including IoT device and network level intrusions. In the following sections, we briefly present a few DL models that are useful in IoT device and network level IDS.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">DNN, autoencoder, and LSTM in IoT security incidents detection</h1>
                </header>
            
            <article>
                
<p>A number of DL models, including simple DNNs, autoencoders, and recurrent neural networks (RNNs)<sup>[6]</sup>, are already being used for IoT security enhancement. These approaches can be supervised or unsupervised. In this chapter, we will use both supervised and unsupervised approaches. For the first use case, we will use the LSTM-based supervised approach for device-level intrusion detection. In use case two, we will use DNNs and autoencoders for supervised and unsupervised network-level intrusion detection, respectively. We are using LSTM for the first use case, as device-level intrusion detection is based on time series CPU utilization data and LSTM works well with temporal data. On the other hand, an autoencoder is a lightweight model and is well suited for resource-constrained IoT devices. We have already presented a brief overview of LSTM in the previous chapter and so, in the following diagram, we briefly present an overview of autoencoders as a review of the model.</p>
<p>As the name suggests, autoencoders encode and decode algorithms. The following diagram presents a simple architecture of an autoencoder model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b3521404-eb04-42d0-b5ab-9f5fc4609717.png" style="width:43.00em;height:30.50em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>As shown in the preceding diagram, autoencoders consist of an input layer and an output layer that are connected through one or more hidden layers [7]. As autoencoders reproduce the inputs, they have the same number of input and output neurons. Generally, an autoencoder consists of two components: an encoder and a decoder. The encoder is connected with the input layer and, once it receives the input (<strong>X</strong>), it transforms it to a new and compressed representation (<strong>Z</strong>). The compressed code is also known as the code or latent variable (<strong>Z</strong>). In the output layer, the decoder receives the generated code or compressed code, and transforms it to a reconstruction of the original input. The aim of the training procedure in autoencoders is to minimize reconstruction errors in the output layer.</p>
<p>Autoencoders are good for diagnosis and fault detection because of their input reconstruction at the output layer. Importantly, this special feature of autoencoders is really useful in IoT, including <strong>industrial IoT</strong> (<strong>IIoT</strong>), for fault diagnosis in hardware devices and machines, and for anomaly detection in operation/data gathering/performance. The anomaly detection capability of autoencoders motivates us to use the model in the network intrusion detection use case. Also, autoencoders are easily transferred between various IoT devices and the network once they are available in the cloud or server. Various types of autoencoders are available, including denoising, contractive, stacked, sparse, and variational autoencoders. In the use case, we will use a simple autoencoder architecture with a standalone DL model for intrusion detection, but autoencoders can be integrated with other DL models, including <strong>convolutional neural networks</strong> (<strong>CNNs</strong>) and LSTMs.  In the following sections, starting with data collection, we will discuss DL-based implementations of the aforementioned use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data collection </h1>
                </header>
            
            <article>
                
<p>For both of the use cases, we can generate our own datasets and train and test the models on them. In the following paragraphs, we briefly present how we can create a dataset for device-level host intrusion detection through a DoS attack.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CPU utilisation data</h1>
                </header>
            
            <article>
                
<p>For the DoS attack, we need an attack machine and a target machine. We are using a Kali Linux machine as the attacker and a Windows machine as the target (which can be home gateway/Raspberry Pi 3/sensors). In Kali Linux, a DoS attack can be achieved in multiple ways. One way is to use the <kbd>hping3</kbd><a href="https://tools.kali.org/information-gathering/hping3">.</a> <kbd>hping3</kbd> command as a network tool to send custom TCP/IP packets, and allowing for the testing of firewalls, port scanning, address spoofing, and more.</p>
<p class="mce-root"/>
<p>This can be used to perform a DoS attack by sending multiple requests in quick succession, taking up an IoT server's/sensor's resources and making it slower or unable to respond. The following screenshot shows CPU utilization of the target Windows server before sending the <kbd>hping3</kbd> command or launching the DoS attack:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e3b59bea-e0e5-4bca-b35d-dbe9950693d3.png"/></p>
<p>The following command is an example of a DoS attack using Kali Linux's <kbd>hping3</kbd> tool.</p>
<pre><span><strong>hping3 -c 10000 -d 120 -S -w 64 -p 21 --flood --rand-source example.com</strong><br/></span></pre>
<p>The following list is the syntax description of the preceding command:</p>
<ul>
<li class="mce-root"><kbd>hping3</kbd>: The name of the binary application</li>
<li class="mce-root"><kbd>-c 100000</kbd>: The amount of packets</li>
<li class="mce-root"><kbd>-d 120</kbd>: The sizing of each packet</li>
<li class="mce-root"><kbd>-S</kbd>: SYN packets only</li>
<li class="mce-root"><kbd>-w 64</kbd>: TCP window size</li>
<li class="mce-root"><kbd>-p 21</kbd>: The destination port</li>
<li class="mce-root"><kbd>--flood</kbd>: Means sending packets as fast as possible, without taking care to show incoming replies</li>
<li class="mce-root"><kbd>--rand-source</kbd>: Using random source IP addresses; you can also use <kbd>-a</kbd> or <kbd>–spoof</kbd> to hide hostnames</li>
<li class="mce-root"><kbd>example.com</kbd>: The website or destination IP address or the target machine's IP address</li>
</ul>
<p class="mce-root"/>
<p>The following screenshot presents CPU utilization of the windows server after the DoS attack. We can clearly see that the CPU utilization of the attacked machine has increased by 30%:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/75b97622-73d3-4e11-a2a7-080f64da71a3.png" style="width:66.67em;height:27.83em;"/></p>
<p> We can run different <kbd>hping3</kbd> sessions to different target machines, and save CPU utilization data. In Windows, a process monitor can be used to save the data. For use case one, we are using CPU utilization data for an LSTM-based intrusion detection algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">KDD cup 1999 IDS dataset</h1>
                </header>
            
            <article>
                
<p>Traffic-based intelligent network intrusion detection in IoT, we can use the Wireshark network monitoring tool to record and save network traffic against different attacks related to network intrusion, and create our own dataset. In addition, we can use an existing open source dataset.  We are using the the KDD cup 1999 IDS dataset.  This dataset is well suited for use case two as it is on the network-level intrusions. In the following paragraphs, we will briefly present an overview of the dataset. Please see reference for further detail.</p>
<p>The KDD cup 1999 datasets were generated by the <strong>Defense Advanced Research Projects Agency</strong> (<strong>DARPA</strong>) on a simulated air force model. The datasets were collected using two different sessions:</p>
<ul>
<li style="text-align: justify">Training data was collected for 7 weeks</li>
<li style="text-align: justify">Testing data was collected for 2 weeks</li>
</ul>
<p>The complete dataset includes 39 network level attack types and 200 instances of background traffic. The network traffic dataset is either classified as one of the attack types or as 'normal'. There are three versions of the KDD cup 1999 IDS datasets—a full KDD dataset, corrected KDD dataset, and 10% KDD dataset. The 10% KDD dataset is the most frequently used of the three datasets, and we are using this for use case two. In use case two, we will use an autoencoder for the clustering of normal and attack or intrusion traffic. Also, we will test a DNN for the classification of normal and attack traffic.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data exploration </h1>
                </header>
            
            <article>
                
<p>In the following paragraphs, we will explore the two datasets used for the two use cases (the CPU utilization dataset for IoT device level, and the KDD cup 1999 IDS dataset for network-level intrusion detection).</p>
<ul>
<li><strong>CPU utilization dataset</strong>: The dataset is a CSV file consisting of dates and times with the corresponding CPU utilization rates (%). The dataset consists of 700 utilization values recorded every minute. The following screenshot presents a snapshot of the dataset:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5a9bd417-c963-429f-8793-92d412f902ac.png" style="width:15.50em;height:29.42em;"/></p>
<p class="mce-root"/>
<ul>
<li><strong><span>KDD cup 1999 IDS dataset</span></strong>: The following screenshot shows a snapshot of the KDD cup 1999 IDS dataset. It is clear from the screenshot that the dataset is not ready to be used in the model. The dataset has protocol types, categorical values, and data values are not normalized. Also, we need to split the data into three sets in order to implement a three-layered, network-level IDS implementation.</li>
</ul>
<p>The following screenshot presents a network traffic pattern of normal communication:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9e4ba990-37c3-49e6-be70-35bfbd2415b4.png" style="width:72.75em;height:13.50em;"/></p>
<p>The following screenshot presents a network traffic pattern of abnormal or attack (such as those by  smurf-it, a network-level distributed DoS attack) communication:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1239b537-0426-4d1a-b244-3fe45f9771ae.png" style="width:76.00em;height:20.08em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data preprocessing </h1>
                </header>
            
            <article>
                
<p>Data preprocessing is an essential step for a DL pipeline. The CPU utilization dataset is ready to be used in the training, but the KDD cup 1999 IDS dataset needs multilevel preprocessing that includes the following three steps:</p>
<ol>
<li style="text-align: justify">Splitting the data into three different protocol sets (application, transport, and network)</li>
<li style="text-align: justify">Duplicate data removal, categorical data conversion, and normalization</li>
<li style="text-align: justify">Feature selection (optional)</li>
</ol>
<p>Using the following lines of code is a potential way of splitting the dataset into three datasets, namely <kbd>Final_App_Layer</kbd>, <kbd>Final_Transport_Layer</kbd>, and <kbd>Final_Network_Layer</kbd>:</p>
<pre>#Importing all the required Libraries<br/>import pandas as pd<br/>IDSdata = pd.read_csv("kddcup.data_10_percent.csv",header = None,engine = 'python',sep=",")<br/><br/># Add column header<br/>IDSdata.columns = ["duration","protocol_type","service","flag","src_bytes","dst_bytes","land","wrong_fragement","urgent",               "hot","num_failed_logins","logged_in","num_compressed","root_shell","su_attempted","num_root","num_file_creations", "num_shells","num_access_files","num_outbound_cmds","is_hot_login","is_guest_login","count","srv_count","serror_rate","srv_serror_rate","rerror_rate","srv_rerror_rate","same_srv_rate","diff_srv_rate","srv_diff_host_rate","dst_host_count","dst_host_srv_count","dst_host_same_srv_rate","dst_host_diff_srv_rate","dst_host_same_src_port_rate","dst_host_srv_diff_host_rate","dst_host_serror_rate","dst_host_srv_serror_rate","dst_host_rerror_rate","dst_host_srv_rerror_rate","labels"]<br/><br/># Explore the Application Layer IDS Data<br/>ApplicationLayer = IDSdata[(IDSdata['labels'].isin(['normal.','smurf.','back.','satan.','pod.','guess_passwd.','buffer_overflow.','warezmaster.','imap.','loadmodule.','ftp_write.','multihop.','perl.']))]<br/>print (ApplicationLayer['labels'].value_counts())<br/><br/># Save a Applayer data only into a text file<br/>ApplicationLayer.to_csv('Final_App_Layer.txt',header = None,index = False)<br/><br/># Explore the Transport Layer IDS Data<br/>TransportLayer = IDSdata[(IDSdata['labels'].isin(['normal.','neptune.','portsweep.','teardrop.','buffer_overflow.','land.','nmap.']))]<br/>print (TransportLayer['labels'].value_counts())<br/>TransportLayer.to_csv('Final_Transport_Layer.txt',header = None,index = False)<br/><br/># Explore the Network Layer IDS Data<br/>NetworkLayer = IDSdata[(IDSdata['labels'].isin(['normal.','smurf.','ipsweep.','pod.','buffer_overflow.']))]<br/>print (NetworkLayer['labels'].value_counts())<br/>NetworkLayer.to_csv('Final_Network_Layer.txt',header = None,index = False)</pre>
<p class="mce-root"/>
<p>Once the datasets are ready, we remove the duplicate data entries and normalize the values of the remaining entries. The following lines of code or function can be used for duplicate removal and normalization:</p>
<pre>def DataPreprocessing(IDSdataframe):<br/> # Duplicate entry removal<br/>    recordcount = len(IDSdataframe)<br/>    print ("Original number of records in the training dataset before removing duplicates is: " , recordcount)<br/>    IDSdataframe.drop_duplicates(subset=None, inplace=True)  # Python command to drop duplicates<br/>    newrecordcount = len(IDSdataframe)<br/>    print ("Number of records in the training dataset after removing the duplicates is :", newrecordcount,"\n")<br/><br/>    #Dropping the labels to a different dataset which is used to train the recurrent neural network classifier<br/>    df_X = IDSdataframe.drop(IDSdataframe.columns[41],axis=1,inplace = False)<br/>    df_Y = IDSdataframe.drop(IDSdataframe.columns[0:41],axis=1, inplace = False)<br/><br/>    # Categorial data to numerical data conversion<br/>    df_X[df_X.columns[1:4]] = df_X[df_X.columns[1:4]].stack().rank(method='dense').unstack()<br/>   <br/>    # Coding the normal as " 1 0" and attack as "0 1"<br/>    df_Y[df_Y[41]!='normal.'] = 0<br/>    df_Y[df_Y[41]=='normal.'] = 1<br/><br/>    #converting input data into float<br/>    df_X = df_X.loc[:,df_X.columns[0:41]].astype(float)<br/><br/>    # Normal is "1 0" and the attack is "0 1"<br/>    df_Y.columns = ["y1"]<br/>    df_Y.loc[:,('y2')] = df_Y['y1'] ==0<br/>    df_Y.loc[:,('y2')] = df_Y['y2'].astype(int)<br/>    return df_X,df_Y</pre>
<p>The final preprocessing of the datasets is the optimal set of features selection for the classifier. This is an optional process, but is useful for resource-constrained IoT devices, as this will minimize the size of the input layer or neurons of the network. The following lines of code or functions exploiting random forest can be used to do this preprocessing:</p>
<pre>def FeatureSelection(myinputX, myinputY):<br/>    labels = np.array(myinputY).astype(int)<br/>    inputX = np.array(myinputX)<br/><br/>    #Random Forest Model<br/>    model = RandomForestClassifier(random_state = 0)<br/>    model.fit(inputX,labels)<br/>    importances = model.feature_importances<br/><br/>    #Plotting the Features agains their importance scores<br/>    indices = np.argsort(importances)[::-1]<br/>    std = np.std([tree.feature_importances_ for tree in model.estimators_],<br/>axis=0)            <br/>    plt.figure(figsize = (10,5))<br/>    plt.title("Feature importances (y-axis) vs Features IDs(x-axis)")<br/>    plt.bar(range(inputX.shape[1]), importances[indices],<br/>       color="g", yerr=std[indices], align="center")<br/>    plt.xticks(range(inputX.shape[1]), indices)<br/>    plt.xlim([-1, inputX.shape[1]])<br/>    plt.show()<br/>   <br/>    # Selecting top featueres which have higher importance values<br/>    newX = myinputX.iloc[:,model.feature_importances_.argsort()[::-1][:10]]<br/><br/>   # Converting the dataframe into tensors<br/>    myX = newX.as_matrix()<br/>    myY = labels<br/>    return myX,myY</pre>
<p class="mce-root"/>
<p>The following two graphs highlight the 41 features of the application-layer and network-layer datasets, respectively. Features are ordered according to their importance, and it is clear from the graphs that different sets of features are important for different layer dataset. We tested the DL models with 8-12 and 41 features:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/93e2b449-e523-4108-a97a-9234a987a43a.png" style="width:40.92em;height:21.42em;"/></p>
<p>The following graphs highlight the 41 features of the network-layer datasets:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1487a535-5731-4952-afe6-24d1a4104318.png" style="width:42.42em;height:22.00em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model training</h1>
                </header>
            
            <article>
                
<p>As we mentioned earlier in the chapter, we are using LSTM for use case one, an autoencoder for the multilayer IDS dataset, and DNN for the overall IDS dataset.  In the following subsections, we will present the DL model-training process for the two use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case one</h1>
                </header>
            
            <article>
                
<p>We considered a three-LSTMs-layered network architecture for the CPU utilization based host/device-level intrusion detection. The following diagram presents the LSTM architecture we used:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/017b7821-457a-4563-9de6-8e53a10ab266.png" style="width:32.50em;height:39.08em;"/></p>
<p class="mce-root"/>
<p>We can train and test the model by running the <kbd>lstm_anomaly_detection.py</kbd> file (available in the chapter's code folder) as follows: </p>
<pre><strong>python lstm_anomaly_detection.py</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case two</h1>
                </header>
            
            <article>
                
<p>We used an autoencoder for the multilayered IDS implementation using the KDD cup 1999 IDS dataset, and we have trained and tested the autoencoder on the three datasets. To train the model on each layer's dataset, we need to run the <kbd>IDS_AutoEncoder_KDD.py</kbd> file (available in the chapter's code folder) on the dataset as follows:</p>
<pre><strong>python IDS_AutoEncoder_KDD.py</strong></pre>
<p>We also trained and tested a DNN model on the overall KDD cup 1999 IDS dataset. To do so, we need to run the <kbd>DNN-KDD-Overall.py</kbd> file (available in the chapter's code folder) as follows:</p>
<pre style="text-align: justify"><strong>python DNN-KDD-Overall.py</strong></pre>
<p>For all of the models, we have saved the best possible model to import and use in IoT devices. Also, we have saved models' logs using TensorBoard to visualize different aspects of the models, including the networks, and their performance graphs. We can generate the performance graphs and networks by running following command:</p>
<pre><strong>tensorboard --logdir logs</strong></pre>
<p>Once TensorBoard is running, navigate your web browser to <kbd>localhost:6006</kbd> to view the TensorBoard and view the network of the corresponding model. The following diagram is the architecture for the autoencoder used in the multilayered IDS for IoT:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f3116f56-5ea6-41d7-bd22-2ee0e0eed884.png" style="width:61.25em;height:43.42em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model evaluation </h1>
                </header>
            
            <article>
                
<p>We can evaluate three different aspects of the models:</p>
<ul>
<li style="text-align: justify">Learning/(re)training time</li>
<li style="text-align: justify">Storage requirement</li>
<li style="text-align: justify">Performance (accuracy)</li>
</ul>
<p>On a desktop (Intel Xenon CPU E5-1650 v3@3.5GHz and 32 GB RAM) with GPU support, the training of LSTM on the CPU-utilization dataset and the autoencoder on the KDD layered wise dataset (reduced dataset) took a few minutes. The DNN model on the overall dataset took a little over an hour, which was expected as it has been trained on a larger dataset (KDD's overall 10% dataset).</p>
<p>The storage requirement of a model is an essential consideration in resource-constrained IoT devices. The following screenshot presents the storage requirements for the three models we tested for the two use cases:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5fc04244-20c1-4be5-b407-4b052d45d4a9.png" style="width:72.17em;height:24.50em;"/></p>
<p>As shown in the screenshot, autoencoders took storage in the range of KB. The final version of a stored autoencoder model took only 85 KB, LSTM took 1.5 MB, and DNN took 16.3 MB. In terms of storage requirements, all the models are fine to be deployed in many resource-constrained IoT devices, including the Raspberry Pi and smartphones. Also, it is clear from the screenshot that an autoencoder is a very lightweight model, because of the optimal feature selection process, among other reasons. </p>
<p>Finally, we have evaluated the performance of the models. In both of the use cases, dataset-wide evaluation or testing has been done during the training phase in the PC platform/server side.  We can also test them on the Raspberry Pi 3 or any IoT edge-computing devices as the models are saved and importable.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model performance (use case one) </h1>
                </header>
            
            <article>
                
<p>The following graph shows the validation result of the LSTM used on the CPU utilization dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/34a51846-ba91-4d78-9cb3-0c9e2b58c2ff.png" style="width:72.83em;height:29.67em;"/></p>
<p>As we can see in the graph, the prediction follows the nonanomalous or 'normal' CPU utilization data series closely, and this is a hint that it is working fine. Importantly, when it finds the anomalous observations, the difference between the observed and predicted CPU utilization values (normalized) are significantly different to the normal behavior. This is an indication that there might be a DoS or DDoS attack to the IoT device. The error differences are plotted as a root mean squared (RMS) value, one of the most popular metrics of this kind.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model performance (use case two) </h1>
                </header>
            
            <article>
                
<p>We have tested the autoencoder model on the three datasets for three different layer's IDS. The following screenshot presents the evaluation result snapshot for the application layer's IDS:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/31375c99-af8d-4c90-9415-d82dd098be3b.png" style="width:67.33em;height:20.08em;"/></p>
<p class="mce-root"/>
<p>As we can see from the screenshot, training accuracy and validation and test accuracy are well above 90% when we used the first 12 most important features for the training. The performance could be different if we used a different feature set.</p>
<p>The following graph presents epoch-wise training accuracy of the preceding model on the application layer IDS dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a8821215-c9ca-47c4-9034-7d09bdc35bc9.png" style="width:67.42em;height:24.50em;"/></p>
<p>We obtained some interesting evaluation results for the network and transport layers IDS model training. If we use the first 12 most important features, the validation accuracy is in the range of 50%, and if we change the feature set to be in between 8 and 10, the accuracy moves into the range of 80–90%. The following two screenshots present a snapshot of the evaluation on the network layer IDS experimentation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/dc7bff50-fee4-4072-a7f2-414fc16399d3.png" style="width:58.00em;height:25.42em;"/></p>
<p><span>Interestingly, as we can see from the second screenshot, the accuracy is in the range of 50% up to 50 epochs, and then it jumps into the range of 90%. The final accuracy, or the accuracy of the saved model, is in the range 91–98%. So, they are sufficient for detecting network and transport layer anomalies.</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/76765bc5-ae6f-4206-8013-8b147c1d7748.png" style="width:58.83em;height:22.50em;"/></p>
<p>The following screenshot shows the training performance of the DNN model on the overall KDD dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/569eaec3-290d-40e1-a793-833fb4c46da1.png" style="width:41.67em;height:26.25em;"/></p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="assets/65470a14-f494-4702-9b01-fe0afe95da56.png" style="width:63.83em;height:25.92em;"/></p>
<p>As we can see from the preceding figures, test accuracy is close to 1 or 100%. We also separately tested the saved model and test accuracy was well above 0.90 or 90%. Hence, the DNN is also good enough to detect network-level intrusions in IoT networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Security is the single most important issue in IoT realization. Traditional PC/desktop security solutions, especially signature-based solutions, are not effective in IoT applications. Behavior-based solutions, such as anomaly detection, are preferable in IoT. DL/ML models are very useful tools in IoT for data analysis and also for security incident detection. In this chapter, we presented DL-based network and device behavioral data analysis, and security incident detection techniques for IoT applications in general. In the first part of this chapter, we briefly described various IoT security attacks and their potential detection techniques, including DL/ML based techniques. We considered two different levels of intrusion detection in IoT applications. The first use case is on device-level or host-level intrusion detection, and the second use case is on network-level intrusion detection. In the second part of the chapter, we presented the DL-based anomaly or incident detection part of the use cases' implementations. As found in the evaluations, the chosen DL models are good enough to detect device- and network-level intrusions in IoT applications.</p>
<p>IoT will be used in various applications, such as infrastructure and industry, to monitor their health conditions. One of the potential applications of health monitoring is predictive maintenance of the monitored subject (such as a motor) to avoid service disruption or any other incidents.</p>
<p class="mce-root"/>
<p>In the next chapter, we will briefly introduce the importance of IoT-based predictive maintenance and its implementation using DL models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References </h1>
                </header>
            
            <article>
                
<ul>
<li class="mce-root CDPAlignLeft CDPAlign"><em>Internet of Things (IoT) connected devices installed base worldwide from 2015 to 2025 (in billions)</em>, at <a href="https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/" target="_blank">https://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/.</a></li>
<li class="mce-root CDPAlignLeft CDPAlign"><em>Real-Time Detection of Application-Layer DDoS Attack Using Time Series Analysis</em>, <span>T. Ni, X. Gu, H. Wang, and Y. Li, </span>Journal of Control Science and Engineering, vol. 2013, pp. 1–6, 2013. </li>
<li class="mce-root CDPAlignLeft CDPAlign"><em>DDoS in the IoT: </em><span><em>Mirai and Other Botnets</em>, C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, IEEE Computer</span><span>, vol. 50, no. 7, pp. 80–84, </span><span>2017.</span></li>
<li class="mce-root CDPAlignLeft CDPAlign">2016 Dyn cyberattack, at <a href="https://en.wikipedia.org/wiki/2016_Dyn_cyberattack" target="_blank">https://en.wikipedia.org/wiki/2016_Dyn_cyberattack.</a></li>
<li class="mce-root CDPAlignLeft CDPAlign"><em>A Big Network Traffic Data Fusion </em><span><em>Approach Based on Fisher and Deep Auto-Encoder</em></span><span>, Tao X., Kong D., Wei Y., and Wang Y. (2016), Information, 7(2), 20.</span></li>
<li class="mce-root CDPAlignLeft CDPAlign"><em>An Effective Intrusion Detection Classifier Using Long Short-Term Memory with Gradient Descent Optimization</em>, K<span>im J., and Kim H. (2017, February), </span>In Platform Technology and Service (PlatCon), 2017 International Conference on (pp. 1-6), IEEE.</li>
<li class="mce-root CDPAlignLeft CDPAlign">Pierre Baldi, <em>Autoencoders, Unsupervised Learning and Deep Architectures</em>, <span>Isabelle Guyon, Gideon Dror, Vincent Lemaire, Graham Taylor, and Daniel Silver (Eds.), </span>In Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning workshop—Volume 27 (UTLW'11), Vol. 27, JMLR.org 37-50, 2011.</li>
<li class="mce-root CDPAlignLeft CDPAlign">KDD Cup 1999 Data, at <a href="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html" target="_blank">http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html.</a></li>
</ul>


            </article>

            
        </section>
    </body></html>