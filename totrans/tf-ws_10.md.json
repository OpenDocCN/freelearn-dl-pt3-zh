["```\nimport tensorflow as tf\n```", "```\ndef custom_loss(y_true, y_pred):\n    custom_loss=tf.math.pow(y_true - y_pred, 4)\n    return custom_loss\n```", "```\nmodel.compile(loss=custom_loss,optimizer=optimizer)\n```", "```\nclass MyCustomLoss(keras.losses.Loss):\n    def __init__(self, threshold=1.0, **kwargs):\n        super().__init__(**kwargs)\n    def call(self, y_true, y_pred):\n        return tf.math.pow(y_true - y_pred, 4)\n```", "```\n    from google.colab import files\n    uploaded = files.upload()\n    ```", "```\n    !unzip \\*.zip\n    ```", "```\n    directory = \"/content/gdrive/My Drive/Datasets/apple-or-tomato/\"\n    ```", "```\n    import pathlib\n    ```", "```\n    path = pathlib.Path(directory)\n    ```", "```\n    train_dir = path / 'training_set'\n    validation_dir = path / 'test_set'\n    ```", "```\n    train_apple_dir = train_dir / 'apple'\n    train_tomato_dir = train_dir /'tomato'\n    validation_apple_dir = validation_dir / 'apple'\n    validation_tomato_dir = validation_dir / 'tomato'\n    ```", "```\n    import os\n    ```", "```\n    total_train = len(os.listdir(train_apple_dir)) + \\\n                  len(os.listdir(train_tomato_dir))\n    total_val = len(os.listdir(validation_apple_dir)) + \\\n                len(os.listdir(validation_tomato_dir))\n    ```", "```\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    ```", "```\n    train_image_generator = ImageDataGenerator(rescale=1./255)\n    validation_image_generator = ImageDataGenerator(rescale=1./255)\n    ```", "```\n    batch_size = 32\n    img_height = 224\n    img_width = 224\n    ```", "```\n    train_data_gen = train_image_generator.flow_from_directory\\\n                     (batch_size=batch_size, directory=train_dir, \\\n                      shuffle=True, \\\n                      target_size=(img_height, img_width), \\\n                      class_mode='binary')\n    ```", "```\n    val_data_gen = validation_image_generator.flow_from_directory\\\n                   (batch_size=batch_size, directory=validation_dir, \\\n                    target_size=(img_height, img_width), \\\n                    class_mode='binary')\n    ```", "```\n    import matplotlib.pyplot as plt\n    for _ in range(5):\n        img, label = train_data_gen.next()\n        plt.imshow(img[0])\n        plt.show()\n    ```", "```\n    import tensorflow as tf\n    ```", "```\n    def custom_loss_function(y_true, y_pred):\n        print(\"y_pred \",y_pred)\n        print(\"y_true \", y_true)\n        squared_difference = tf.square(float(y_true)-float(y_pred))\n        return tf.reduce_mean(squared_difference, axis=-1)\n    ```", "```\n    from tensorflow.keras.applications import NASNetMobile\n    ```", "```\n    base_model = NASNetMobile(include_top=False,\\\n                              input_shape=(100, 100, 3), \\\n                              weights='imagenet')\n    ```", "```\n    base_model.trainable = False\n    ```", "```\n    from tensorflow.keras.layers import Flatten, Dense\n    ```", "```\n    model = tf.keras.Sequential([\n        base_model,\n        layers.Flatten(),\n        layers.Dense(500, activation='relu'),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    ```", "```\n    model.summary()\n    ```", "```\n    model.compile(\n            optimizer='adam',\n            loss=custom_loss_function,\n            metrics=['accuracy'])\n    ```", "```\n    history = model.fit(\n        Train_data_gen,\n        steps_per_epoch=total_train // batch_size,\n        epochs=5,\n        validation_data=val_data_gen,\n        validation_steps=total_val // batch_size)\n    ```", "```\ndef relu_batchnorm_layer(input):\n    return BatchNormalization()(ReLU()(input))\n```", "```\ndef simple_residual_block(input, filters: int, kernel_size: int = 3):\n    int_output = Conv2D(filters=filters, kernel_size=kernel_size, \n                        padding=\"same\")(input)\n    int_output = Conv2D(filters=filters, kernel_size=1, strides=2,\n                        padding=\"same\")(int_output)\n    output = Add()([int_output,input]) \n    output = relu_batchnorm_layer(output)\n    return output\n```", "```\ninputs = Input(shape=(100, 100, 3))\nnum_filters = 32\n\nt = BatchNormalization()(inputs)\nt = Conv2D(kernel_size=3,\n           strides=1,\n           filters=32,\n           padding=\"same\")(t)\nt = relu_batchnorm_layer(t)\nt = residual_block(t, filters=num_filters)\n\nt = AveragePooling2D(4)(t)\nt = Flatten()(t)\noutputs = Dense(1, activation='sigmoid')(t)\n\nmodel = Model(inputs, outputs)\n```", "```\nfrom tensorflow.keras.models import Model \nfrom tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate\n```", "```\nclass MyModel(Model): \n  def __init__(self): \n    super(MyModel, self).__init__()\n    self.dense_1 = Dense(64, activation='relu')\n    self.dense_2 = Dense(10)\n\n  def call(self, inputs):, \n    X = self.dense_1(inputs)\n    return self.dense_2(X)\n```", "```\nmodel = MyModel()\nmodel(tf.random.uniform([1,10]))\nmodel.summary()\n```", "```\nclass MyModel(Model):\n  def __init__(self):\n    super(MyModel, self).__init__()\n    self.dense_1 = Dense(64, activation='relu')\n    self.dense_2 = Dense(10)\n    self.dropout = Dropout(0.4)  \n  def call(self, inputs, training=True):\n    X = self.dense_1(inputs)\n    if training:                             \n      X = self.dropout(X)                    \n    return self.dense_2(X)\n```", "```\nmodel = MyModel()\nmodel(tf.random.uniform([1,10]))\nmodel.summary()\n```", "```\n    from google.colab import files\n    uploaded = files.upload()\n    ```", "```\n    !unzip \\*.zip\n    ```", "```\n    directory = \"/content/gdrive/My Drive/Datasets/pneumonia-or-healthy/\"\n    ```", "```\n    import pathlib     \n    ```", "```\n    path = pathlib.Path(directory)\n    ```", "```\n    train_dir = path / 'training_set'\n    validation_dir = path / 'test_set'\n    ```", "```\n    train_healthy_dir = train_dir / 'healthy'\n    train_pneumonia_dir = train_dir /'pneumonia'\n    validation_healthy_dir = validation_dir / 'healthy'\n    validation_pneumonia_dir = validation_dir / 'pneumonia'\n    ```", "```\n    import os     \n    ```", "```\n    total_train = len(os.listdir(train_healthy_dir)) + \\\n                  len(os.listdir(train_pneumonia_dir))\n    total_val = len(os.listdir(validation_healthy_dir)) + \\\n                len(os.listdir(validation_pneumonia_dir))\n    ```", "```\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    ```", "```\n    train_image_generator = ImageDataGenerator(rescale=1./255)\n    validation_image_generator = ImageDataGenerator(rescale=1./255)\n    ```", "```\n    batch_size = 32\n    img_height = 100\n    img_width = 100     \n    ```", "```\n    train_data_gen = train_image_generator.flow_from_directory\\\n                     (batch_size=batch_size, directory=train_dir, \\\n                      shuffle=True, \\\n                      target_size=(img_height, img_width), \\\n                      class_mode='binary')\n    ```", "```\n    val_data_gen = validation_image_generator.flow_from_directory\\\n                   (batch_size=batch_size, directory=validation_dir, \\\n                    target_size=(img_height, img_width), \\\n                    class_mode='binary')\n    ```", "```\n    import matplotlib.pyplot as plt\n    for _ in range(5):\n        img, label = train_data_gen.next()\n        plt.imshow(img[0])\n        plt.show()\n    ```", "```\n    import tensorflow as tf\n    ```", "```\n    from tensorflow.keras.layers import Input, Conv2D, ReLU, \\\n                                        BatchNormalization, Add, \\\n                                        AveragePooling2D, Flatten, Dense\n    ```", "```\n    def relu_batchnorm_layer(input):\n        return BatchNormalization()(ReLU()(input))\n    ```", "```\n    def residual_block(input, filters: int, kernel_size: int = 3):\n        int_output = Conv2D(filters=filters, kernel_size=kernel_size, \n                            strides=(2), \n                            padding=\"same\")(input)\n        int_output = relu_batchnorm_layer(int_output)\n        int_output = Conv2D(filters=filters, kernel_size=kernel_size, \n                            padding=\"same\")(int_output)\n        int_output2 = Conv2D(filters=filters, kernel_size=1, strides=2,\n                            padding=\"same\")(input)\n        output = Add()([int_output2, int_output]) \n        output = relu_batchnorm_layer(output)\n        return output\n    ```", "```\n    from tensorflow.keras.models import Model\n    ```", "```\n    inputs = Input(shape=(100, 100, 3))\n    ```", "```\n    t = BatchNormalization()(inputs)\n    t = Conv2D(kernel_size=3,\n               strides=1,\n               filters=32,\n               padding=\"same\")(t)\n    t = relu_batchnorm_layer(t)\n    ```", "```\n    t = residual_block(t, filters=32)\n\n    t = AveragePooling2D(4)(t)\n    t = Flatten()(t)\n    outputs = Dense(1, activation='sigmoid')(t)\n    ```", "```\n    model = Model(inputs, outputs)\n    ```", "```\n    model.summary()\n    ```", "```\n    model.compile(\n            optimizer='adam',\n            loss=binary_crossentropy,\n            metrics=['accuracy'])\n    ```", "```\n    history = model.fit(\n        Train_data_gen,\n        steps_per_epoch=total_train // batch_size,\n        epochs=5,\n        validation_data=val_data_gen,\n        validation_steps=total_val // batch_size\n    )\n    ```"]