- en: '*Chapter 4*: Enhancing and Styling Images with DeepDream, Neural Style Transfer,
    and Image Super-Resolution'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although deep neural networks excel in traditional computer vision tasks for
    purely practical applications, they have a fun side too! As we'll discover in
    this chapter, we can unlock the artistic side of deep learning with the help of
    a little bit of cleverness and math, of course!
  prefs: []
  type: TYPE_NORMAL
- en: We'll start this chapter by covering **DeepDream**, an algorithm used to make
    neural networks produce dream-like images. Next, we'll seize the power of transfer
    learning to apply the style of famous paintings to our own images (this is known
    as **Neural Style Transfer**). Finally, we'll close with **Image Super-Resolution**,
    a deep learning approach that's used to improve the quality of an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing DeepDream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating your own dreamy images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Neural Style Transfer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying style transfer to custom images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying style transfer with TFHub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving image resolution with deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The usual advice whenever we are working with deep learning applies here: if
    possible, access a GPU since it greatly improves efficiency and lowers the computing
    time. In each recipe, you''ll find specific preparation instructions in the *Getting
    ready* section, if needed. You can find all the code for this chapter here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following link to see the Code in Action video:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/3bDns2A](https://bit.ly/3bDns2A).'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing DeepDream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DeepDream** is the result of an experiment that aimed to visualize the internal
    patterns that are learned by a neural network. In order to achieve this goal,
    we can pass an image through the network, compute its gradient with respect to
    the activations of a specific layer, and then modify the image to increase the
    magnitude of such activations to, in turn, magnify the patterns. The result? Psychedelic,
    surreal photos!'
  prefs: []
  type: TYPE_NORMAL
- en: Although this recipe is a bit complex due to the nature of **DeepDream**, we
    will take it one step at a time, so don't worry.
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We don''t need to install anything extra for this recipe. However, we won''t
    dive deep into the details of **DeepDream**, but if you''re interested in the
    topic, you can read the original blog post by Google here: [https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html).'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps and you''ll have your own deep dreamer in no time:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the necessary packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `DeepDreamer` class and its constructor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The constructor parameters specify the scale by which we''ll increase the size
    of an image (`octave_scale`), as well as the factor that will applied to the scale
    (`octave_power_factors`). `layers` contains the target layers that will be used
    to generate the dreams. Next, let''s store the parameters as object members:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If some of the inputs are `None`, we use defaults. If not, we use the inputs.
    Finally, create the dreamer model by extracting our `layers` from a pre-trained
    `InceptionV3` network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a private method that will compute the loss:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a private method that will perform gradient ascent (remember, we want
    to magnify the patterns of the image). To increase performance, we can wrap this
    function in `tf.function`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a private method that will convert the image tensor generated by the
    dreamer back into a `NumPy` array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a private method that will generate a dreamy image by performing `_gradient_ascent()`
    for a specific number of steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a public method that will generate dreamy images. The main difference
    between this and `_dream()` (defined in *Step 6* and used internally here) is
    that we''ll use different image sizes (called `self.octave_scale` to each power
    in `self.octave_power_factors`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `DeepDreamer()` class can be reused to produce dream-like versions of any
    image we supply to it. We'll see how this works in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We just implemented a utility class to easily apply **DeepDream**. The algorithm
    works by calculating the gradient with respect to the activations of a set of
    layers, then using such gradients to enhance the patterns seen by the network.
  prefs: []
  type: TYPE_NORMAL
- en: In our `DeepDreamer()` class, the previously described process is implemented
    in the `_gradient_ascent()` method (defined in *Step 4*), where we calculated
    the gradients and added them to the original image over a series of steps. The
    result was an activation map where, in each subsequent step, the **excitement**
    of certain neurons in the target layers was magnified.
  prefs: []
  type: TYPE_NORMAL
- en: Generating a dream consists of applying gradient ascent many times, which we
    basically did in the `_dream()` method (*Step 6*).
  prefs: []
  type: TYPE_NORMAL
- en: One of the problems of applying gradient ascent at the same scale is that the
    result looks noisy, with low resolution. Also, the patterns seem to happen at
    the same granularity level, which produces a uniformity in the result that decreases
    the dream-like effect we want. To resolve all these issues, the main method, `dream()`,
    applies gradient ascent at different scales (called **octaves**), where the dreamy
    output of one octave is the input of the next iteration, at a higher scale.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To see the dream-like results of passing different combinations of parameters
    to `DeepDreamer()`, please see the next recipe, *Generating your own dreamy images*.
  prefs: []
  type: TYPE_NORMAL
- en: Generating your own dreamy images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning has an entertaining side. **DeepDream** is one application that
    aims to understand the inner workings of deep neural networks by exciting certain
    activations on selected layers. However, beyond the investigative intent of the
    experiment, it also produces psychedelic, dream-like fun images.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll experiment with several configurations of **DeepDream**
    on a test image and see how they affect the results.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll use the `DeepDreamer()` implementation from the first recipe of this
    chapter (*Implementing DeepDream*). Although I encourage you to try this out with
    your own images, if you want to follow this recipe as closely as possible, you
    can download the sample image here: https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe2/road.jpg.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the sample image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Sample image'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image86668.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 – Sample image
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to cook up your own dreamy photos:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by importing the required packages. Notice that we are importing
    `DeepDreamer()` from the previous recipe, *Implementing DeepDream*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `load_image()` function that will load images from disk into memory
    as `NumPy` arrays:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will display an image (represented as a `NumPy` array)
    using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the original image and display it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we can see the displayed original image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Original image that we’ll modify shortly'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.2 – Original image that we'll modify shortly
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As we can see, it is just a road that cuts through a forest.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Generate a dreamy version of the image using the default parameters and display
    the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Result of using DeepDream with the default parameters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_003.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.3 – Result of using DeepDream with the default parameters
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The result preserves the overall theme of the original photo but adds lots of
    distortion on top of it in the form of circles, curves, and other basic patterns.
    Cool – and a bit creepy!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use three layers. Layers near the top (for instance, `''mixed7''`) encode higher-level
    patterns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the result of using three layers:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Result of using DeepDream with more, higher-level layers'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_004.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.4 – Result of using DeepDream with more, higher-level layers
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The addition of more layers softened the produced dream. We can see that the
    patterns are smoother than before, which is likely due to the fact that the `'mixed7'`
    layer encodes more abstract information because it is farther down the architecture.
    Let's remember that the first layers in a network learn basic patterns, such as
    lines and shapes, while the layers closer to the output combine these basic patterns
    to learn more complex, abstract information.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, let''s use more **octaves**. The result we expect is an image with
    less noise and more heterogeneous patterns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the resulting image after using more octaves:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Result of using DeepDream with more octaves'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – Result of using DeepDream with more octaves
  prefs: []
  type: TYPE_NORMAL
- en: This generated dream contains a satisfying mixture of both high- and low-level
    patterns, as well as a better color distribution than the one produced in *Step
    4*.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go to the next section to understand what we've just done.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we leveraged the hard work we did in the *Implementing DeepDream*
    recipe in order to produce several dreamy versions of our input image of a road
    in a forest. By combining different parameters, we discovered that the results
    could vary widely. Using higher layers, which encode more abstract information,
    we obtained pictures with less noise and more nuanced patterns.
  prefs: []
  type: TYPE_NORMAL
- en: If we choose to use more octaves, this translates into more images, at different
    scales, being processed by the network. This approach generates less saturated
    images, while keeping the more raw, basic patterns typical of the first few layers
    in a convolutional neural network.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, with just an image and a little creativity, we can obtain pretty
    interesting results!
  prefs: []
  type: TYPE_NORMAL
- en: An even more entertaining application of deep learning is Neural Style Transfer,
    which we will cover in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Neural Style Transfer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creativity and artistic expression are not traits that we tend to associate
    with deep neural networks and AI in general. However, did you know that with the
    right tweaks, we can turn pre-trained networks into impressive artists, capable
    of applying the distinctive style of famous painters such as Monet, Picasso, and
    Van Gogh to our mundane pictures?
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what Neural Style Transfer does. By the end of this recipe,
    we'll have the artistic prowess of any painter at our disposal!
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We don''t need to install any libraries or bring in extra resources to implement
    Neural Style Transfer. However, because this is a hands-on recipe, we won''t detail
    the inner workings of our solution extensively. If you''re interested in the ins
    and outs of Neural Style Transfer, I recommend that you read the original paper
    here: [https://arxiv.org/abs/1508.06576](https://arxiv.org/abs/1508.06576).'
  prefs: []
  type: TYPE_NORMAL
- en: I hope you're ready because we are about to begin!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to implement your own, reusable, neural style transferrer:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary packages (notice that we''re using a pre-trained **VGG19**
    network in our implementation):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `StyleTransferrer()` class and its constructor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The only relevant parameters are two optional lists of layers for the content
    and style generation, respectively. If they are `None`, we''ll use defaults internally
    (as we''ll see shortly). Next, load the pre-trained `VGG19` and freeze it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the weight (importance) of the style and content losses (we''ll use these
    parameters later). Also, store the content and style layers (or use the defaults
    if necessary):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define and store the style transferrer model, which takes the **VGG19** input
    layer as input and outputs all the content and style layers (please take into
    account that we can use any model, but the best results are usually achieved using
    either VGG19 or InceptionV3):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a private method that will calculate the **Gram Matrix**, which is used
    to calculate the style of an image. This is represented by a matrix that contains
    the means and correlations across different feature maps in the input tensor (for
    instance, the weights in a particular layer), known as a **Gram Matrix**. For
    more information on the **Gram Matrix**, please refer to the *See also* section
    of this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, define a private method that will calculate the outputs (content and
    style). What this private method does is pass the inputs to the model and then
    compute the **Gram Matrix** of all the style layers, as well as the identity of
    the content layers, returning dicts that map each layer name to the processed
    values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a static helper private method that will clip values between `0` and
    `1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a static helper private method that will compute the loss between a
    pair of outputs and targets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a private method that will compute the total loss, which is the result
    of computing the style and content loss individually, by multiplying them by their
    respective weight distributed across the corresponding layer and then adding them
    up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, define a private method that will train the model. During a set number
    of epochs, and for a given number of steps per epoch, we''ll calculate the outputs
    (style and content), compute the total loss, and obtain and apply the gradient
    to the generated image while using `Adam` as an optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a static helper private method that will convert a tensor into a `NumPy`
    image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, define a public `transfer()` method that will take a style image and
    a content image and generate a new image. This should preserve the content as
    much as possible while still applying the style of the style image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That was a lot of work! We'll go a bit deeper in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we learned that Neural Style Transfer works by optimizing two
    losses instead of one. On one hand, we want to preserve the content as much as
    possible, but on the other hand, we want to make this content look like it was
    produced using the style of the style image.
  prefs: []
  type: TYPE_NORMAL
- en: Quantifying content is achieved by using the content layers, as we would normally
    do in image classification. How do we quantify style, though? Here's where the
    **Gram Matrix** plays a crucial role, since it computes the correlations across
    the feature maps (more precisely, the outputs) of the style layers.
  prefs: []
  type: TYPE_NORMAL
- en: How do we inform the network that the content is more important than the style?
    By using weights when computing the combined loss. By default, the content weight
    is *10,000*, while the style weight is just *0.01*. This tells the network that
    most of its effort should be on reproducing the content, but also optimizing it
    a bit for style.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, we obtained an image that preserves the coherence of the original
    one, but with the visual appeal of the style reference image, which is the result
    of optimizing the output so that it matches the statistics of both input images.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want to learn more the math behind the `StyleTransferrer()` in action,
    see the next recipe, *Applying style transfer to custom images*.
  prefs: []
  type: TYPE_NORMAL
- en: Applying style transfer to custom images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have you ever wondered how a picture of your puppy Fluffy would look if your
    favorite artist painted it? What if a photo of your car was the product of merging
    it with the magic of your most beloved painting? Well, you don't have to wonder
    anymore! With Neural Style Transfer, we can make our favorite images look like
    wonderful pieces of art effortlessly!
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll use the `StyleTransferrer()` class we implemented in the
    *Implementing Neural Style Transfer* recipe to stylize our own images.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll be using the `StyleTransferrer()` implementation from
    the previous recipe. In order to maximize the fun you''ll get out of this recipe,
    you can find the sample image, along with many different paintings (which you
    can use as the style reference), here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the sample image we''ll be using:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Sample content image'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – Sample content image
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps will teach you how to transfer the style of famous paintings
    to your own images:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Notice we're importing `StyleTransferrer()`, which we implemented in the *Implementing
    Neural Style Transfer* recipe.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Tell TensorFlow that we want to run in eager mode because otherwise, it will
    try to run the `tf.function` decorator functions in `StyleTransferrer()` in graph
    mode, which will prevent it from working properly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will load an image as a TensorFlow tensor. Notice that
    we''re rescaling it to a sensible size. We are doing this because Neural Style
    Transfer is a resource-intensive process, so working on large images can take
    a long time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will display an image using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the content image and display it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the content image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Content image of a car'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_007.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.7 – Content image of a car
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We'll apply the style of a painting to this image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load and display the style image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the style image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Style image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_008.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.8 – Style image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Can you imagine how our car would look if the artist of this painting painted
    it?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use `StyleTransferrer()` to apply the style of the painting to our image of
    a BMW. Then, display the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Result of applying the style of the painting to the content
    image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_009.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.9 – Result of applying the style of the painting to the content image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Impressive, isn't it?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Repeat this process, this time for 100 epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Result of applying the style of the painting to the content
    image for 100 epochs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.10 – Result of applying the style of the painting to the content image
    for 100 epochs
  prefs: []
  type: TYPE_NORMAL
- en: This time, the result is sharper. However, we had to wait a while for the process
    to complete. There's a clear trade-off between time and quality.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we leveraged the hard work we did in the *Implementing Neural
    Style Transfer* recipe. We took an image of a car and applied the style of a cool
    and captivating piece of art to it. The result, as we saw, is fascinating.
  prefs: []
  type: TYPE_NORMAL
- en: However, we must be aware of how taxing this process is since it takes a long
    time to complete on a CPU – even on a GPU. Therefore, there's a trade-off to be
    accounted for between the number of epochs or iterations used to refine the result
    and the overall quality of the output.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I encourage you to try this recipe with your own pictures and styles. As a
    starting point, you can use the images in the following repository to hit the
    ground running: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4).
    There, you''ll find famous artworks from Warhol, Matisse, and Monet, among others.'
  prefs: []
  type: TYPE_NORMAL
- en: Applying style transfer with TFHub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing Neural Style Transfer from scratch is a demanding task. Fortunately,
    we can use out-of-the-box solutions that live in **TensorFlow Hub** (**TFHub**).
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll style our own images in just a few lines of code by harnessing
    the utility and convenience that TFHub provides.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We must install `tensorflow-hub`. We can do this with just a simple `pip` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to access different sample content and style images, please visit
    this link: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the sample image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Content image'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.11 – Content image
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Neural Style Transfer with TFHub is a breeze! Follow these steps to complete
    this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will load an image as a TensorFlow tensor. We need to
    rescale the image in order to save time and resources, given that Neural Style
    Transfer is a taxing process, so working on large images can take a long time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will convert a tensor into an image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will display an image using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the path to the style transfer implementation in TFHub and load the
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the content image. Then, display it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here it is:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Content image of a car'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_012.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.12 – Content image of a car
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We'll apply style transfer to this photo in the next step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load and display the style image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, you can see the style image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.13 – This is our style image of choice'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_013.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.13 – This is our style image of choice
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We'll pass this and the content image to the TFHub module we recently created
    and wait for the result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Apply Neural Style Transfer using the model we downloaded from TFHub and display
    the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the result of applying Neural Style Transfer with TFHub:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Result of applying style transfer using TFHub'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.14 – Result of applying style transfer using TFHub
  prefs: []
  type: TYPE_NORMAL
- en: '*Voilà!* The result looks pretty good, don''t you think? We''ll dive a bit
    deeper in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we learned that using TFHub to stylize images is substantially
    easier than implementing the algorithm from scratch. However, it gives us less
    control since it acts as a black box.
  prefs: []
  type: TYPE_NORMAL
- en: Either way, the result is quite satisfactory because it preserves the coherence
    and meaning of the original scene, while adding the artistic traits of the style
    image on top.
  prefs: []
  type: TYPE_NORMAL
- en: The most important part is downloading the correct module from TFHub, and then
    loading it using the `load()` function.
  prefs: []
  type: TYPE_NORMAL
- en: For the pre-packaged module to work, we must pass both the content and style
    images as `tf.constant` constants.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, because we received a tensor, in order to properly display the result
    on-screen, we used our custom function, `tensor_to_image()`, to turn it into a
    `NumPy` array that can easily be plotted using `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can read more about the TFHub module we used here at https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, why don''t you play around with your own images and other styles? You
    can use the assets here as a starting point: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5).'
  prefs: []
  type: TYPE_NORMAL
- en: Improving image resolution with deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Convolutional Neural Networks (CNNs)** can also be used to improve the resolution
    of low-quality images. Historically, we can achieve this by using interpolation
    techniques, example-based approaches, or low- to high-resolution mappings that
    must be learned.'
  prefs: []
  type: TYPE_NORMAL
- en: As we'll see in this recipe, we can obtain better results faster by using an
    end-to-end deep learning-based approach.
  prefs: []
  type: TYPE_NORMAL
- en: Sound interesting? Let's get to it!
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will need `Pillow` in this recipe, which you can install with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'In this recipe, we are using the `Dog and Cat Detection` dataset, which is
    hosted on Kaggle: [https://www.kaggle.com/andrewmvd/dog-and-cat-detection](https://www.kaggle.com/andrewmvd/dog-and-cat-detection).
    In order to download it, you''ll need to sign in on the website or sign up. Once
    you''re logged in, save it in a place of your preference as `dogscats.zip`. Finally,
    decompress it in a folder named `dogscats`. From now on, we''ll assume the data
    is in `~/.keras/datasets/dogscats`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a sample from the two classes in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Example images'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_015.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.15 – Example images
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to implement a fully convolutional network in order to perform
    image super-resolution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the necessary modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will build the network architecture. Notice that this
    is a fully convolutional network, which means only convolutional layers (besides
    the activations) comprise it, including the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will resize an image based on a scale factor. Take into
    consideration that it receives an image represented as a `NumPy` array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will tightly crop an image. We are doing this because
    we want the image to fit nicely when we apply a sliding window to extract patches
    later. `SCALE` is the factor we want the network to learn how to enlarge images
    by:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will purposely reduce the resolution of an image by
    downsizing it and then upsizing it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will crop patches from input images. `INPUT_DIM` is
    the height and width of the images we will feed into the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will crop patches of output images. `LABEL_SIZE` is
    the height and width of the images outputted by the network. On the other hand,
    `PAD` is the number of pixels that will be used as padding to ensure we are cropping
    the region of interest properly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the random seed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the paths to all the images in the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Because the dataset is huge and we don''t need all the images in it to achieve
    our goal, let''s randomly pick 1,500 of them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the parameters that will be used to create our dataset of low-resolution
    patches as input and high-resolution patches (the labels) as output. All of these
    parameters were defined in previous steps, except for `STRIDE`, which is the number
    of pixels we''ll slide both in the horizontal and vertical axes to extract patches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the dataset. The inputs will be low-resolution patches that have been
    extracted from the images after being downsized and upsized. The labels will be
    patches from the unaltered image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the network, which we''ll train for 12 epochs while using `Adam()`
    as our optimizer with learning rate decay. The loss function is `''mse''`. Why?
    Because our goal is not to achieve great accuracy, but to learn a set of filters
    that correctly map patches from low to high resolution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Train the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, to evaluate our solution, we''ll load a test image, convert it into a
    `NumPy` array, and reduce its resolution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the low-resolution image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s see the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.16 – Low-resolution test image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_04_016.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 4.16 – Low-resolution test image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, we want to create a sharper version of this photo.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a canvas with the same dimensions of the input image. This is where
    we''ll store the high-resolution patches generated by the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract low-resolution patches, pass them through the network to obtain their
    high-resolution counterparts, and place them in their proper location in the output
    canvas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, display the high-resolution result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the super-resolution output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.17 – High-resolution test image'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_04_017.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.17 – High-resolution test image
  prefs: []
  type: TYPE_NORMAL
- en: Compared to the low-resolution image, this photo does a better job of detailing
    the dogs and the overall scene, don't you think?
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: I recommend that you open both the low- and high-resolution images in a PDF
    or photo viewer. This will help you closely examine the differences between them
    and convince yourself that the network did its job well. It can be hard to judge
    the distinction in the print version of this book.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we created a model capable of improving the resolution of a
    blurry or low resolution image. The biggest takeaway of this implementation is
    that it is powered by a **fully convolutional neural network**, meaning that it
    comprises only convolutional layers and their activations.
  prefs: []
  type: TYPE_NORMAL
- en: This is a regression problem, where each pixel in the output is a feature we
    want to learn.
  prefs: []
  type: TYPE_NORMAL
- en: However, our goal is not to optimize for accuracy, but to train the model so
    the feature maps encode the necessary information to produce high-resolution patches
    from low-resolution ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we must ask ourselves: why patches? We don''t want to *learn* what''s
    in the image. Instead, again, we want our network to figure out how to go from
    low to high resolution. Patches are good enough for this purpose as they enclose
    localized patterns that are easier to grasp.'
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that we didn't train for many epochs (only 12). This
    is by design because it's been shown that training for too long can actually hurt
    the network's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it must be noted that because this network was trained on images of
    dogs and cats, its expertise lies in upscaling photos of these animals. Nonetheless,
    by switching the dataset, we can easily create a super-resolution network that
    specializes in other kind of data.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our implementation is based on the great work of Dong et al., whose paper on
    the subject can be read here: [https://arxiv.org/abs/1501.00092](https://arxiv.org/abs/1501.00092).'
  prefs: []
  type: TYPE_NORMAL
