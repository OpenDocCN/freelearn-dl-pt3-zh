<html><head></head><body>
		<div id="_idContainer121">
			<h1 id="_idParaDest-214"><em class="italic"><a id="_idTextAnchor244"/>Chapter 9</em>: Deploying Deep RL Agents on Multiple Platforms</h1>
			<p>This chapter provides recipes to deploy your Deep RL agent models in applications targeting desktop, web, mobile, and beyond. The recipes serve as customizable templates that you can utilize to build and deploy your own Deep RL applications for your use cases. You will also learn how to export RL agent models for serving/deployment in various production-ready formats, such as <strong class="bold">TensorFlow Lite</strong>, <strong class="bold">TensorFlow.js</strong>, and <strong class="bold">ONNX</strong>, and learn how to leverage Nvidia <strong class="bold">Triton</strong> to launch production-ready RL-based AI services.</p>
			<p>Specifically, the following recipes are covered in this chapter:</p>
			<ul>
				<li>Packaging Deep RL agents for mobile and IoT devices using TensorFlow Lite</li>
				<li>Deploying RL agents on mobile devices</li>
				<li>Packaging Deep RL agents for the web and Node.js using TensorFlow.js</li>
				<li>Deploying a Deep RL agent as a service</li>
				<li>Packaging Deep RL agents for cross-platform deployments</li>
			</ul>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor245"/>Technical requirements</h1>
			<p>The code in the book is extensively tested on Ubuntu 18.04 and Ubuntu 20.04 and should work with later versions of Ubuntu if Python 3.6+ is available. With Python 3.6+ installed along with the necessary Python packages, as listed before the start of each of the recipes, the code should run fine on Windows and Mac OSX too. It is advised to create and use a Python virtual environment named <strong class="source-inline">tf2rl-cookbook</strong> to install the packages and run the code in this book. Miniconda or Anaconda installation for Python virtual environment management is recommended.</p>
			<p>The complete code for each recipe in each chapter will be available here: <a href="https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook">https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook</a>.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor246"/>Packaging Deep RL agents for mobile and IoT devices using TensorFlow Lite</h1>
			<p>This <a id="_idIndexMarker961"/>recipe will show how <a id="_idIndexMarker962"/>you can leverage the <a id="_idIndexMarker963"/>open source <strong class="bold">TensorFlow Li<a id="_idTextAnchor247"/>te</strong> (<strong class="bold">TFLite</strong>) framework for serving <a id="_idIndexMarker964"/>your Deep RL agents <a id="_idIndexMarker965"/>on mobile, IoT, and embedded devices. We will implement a complete script to build, train, and export an agent model that you can load into a mobile or embedded device. We will explore two methods to generate the TFLite model for our agent. The first method involves saving and exporting the agent models in TensorFlow's SavedModel file format and then using a command-line converter. The second method leverages the Python API to directly generate the TFLite models.</p>
			<p>Let's get started!</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor248"/>Getting ready</h2>
			<p>To complete this recipe, you will first need to activate the <strong class="source-inline">tf2rl-cookbook</strong> Python/conda virtual environment. Make sure to update the environment to match the latest conda environment specification file (<strong class="source-inline">tfrl-cookbook.yml</strong>) in the cookbook's code repo. If the following imports work without issues, you are ready to get started:</p>
			<p class="source-code">import argparse</p>
			<p class="source-code">import os</p>
			<p class="source-code">import sys</p>
			<p class="source-code">from datetime import datetime</p>
			<p class="source-code">import gym</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import procgen  # Used to register procgen envs with Gym registry</p>
			<p class="source-code">import tensorflow as tf</p>
			<p class="source-code">from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D</p>
			<p>Now, let's begin!</p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor249"/>How to do it...</h2>
			<p>In the following steps, we will save space by focusing on the new and important pieces that are unique to this recipe. We will go through the model saving and export functionality and the different ways you can do that and keep the Actor, Critic, and Agent model definitions out of the following steps to save space. Please refer to the book's code repository for a complete implementation.</p>
			<p>Let's get started:</p>
			<ol>
				<li>First, it is <a id="_idIndexMarker966"/>important to set TensorFlow <a id="_idIndexMarker967"/>Keras's backend to <a id="_idIndexMarker968"/>use <strong class="source-inline">float32</strong> as the default <a id="_idIndexMarker969"/>representation for float values instead of the default <strong class="source-inline">float64</strong>:<p class="source-code">tf.keras.backend.set_floatx("float32")</p></li>
				<li>Next, let's create a handler for arguments passed to the script. We will also define a list of options for the training environments that can be chosen from for the <strong class="source-inline">--env</strong> flag:<p class="source-code">parser = argparse.ArgumentParser(prog="TFRL-Cookbook-Ch9-PPO-trainer-exporter-TFLite")</p><p class="source-code">parser.add_argument(</p><p class="source-code">    "--env", default="procgen:procgen-coinrun-v0",</p><p class="source-code">    choices=["procgen:procgen-bigfish",</p><p class="source-code">        "procgen:procgen-bossfight",</p><p class="source-code">        "procgen:procgen-caveflyer",</p><p class="source-code">        "procgen:procgen-chaser",</p><p class="source-code">        "procgen:procgen-climber",</p><p class="source-code">        "procgen:procgen-coinrun",</p><p class="source-code">        "procgen:procgen-dodgeball",</p><p class="source-code">        "procgen:procgen-fruitbot",</p><p class="source-code">        "procgen:procgen-heist",</p><p class="source-code">        "procgen:procgen-jumper",</p><p class="source-code">        "procgen:procgen-leaper",</p><p class="source-code">        "procgen:procgen-maze",</p><p class="source-code">        "procgen:procgen-miner",</p><p class="source-code">        "procgen:procgen-ninja",</p><p class="source-code">        "procgen:procgen-plunder",</p><p class="source-code">        "procgen:procgen-starpilot",</p><p class="source-code">        "Pong-v4",</p><p class="source-code">    ],</p><p class="source-code">)</p></li>
				<li>We will <a id="_idIndexMarker970"/>add a few other arguments <a id="_idIndexMarker971"/>to ease the training <a id="_idIndexMarker972"/>and logging configuration <a id="_idIndexMarker973"/>of the agent:<p class="source-code">parser.add_argument("--update-freq", type=int, default=16)</p><p class="source-code">parser.add_argument("--epochs", type=int, default=3)</p><p class="source-code">parser.add_argument("--actor-lr", type=float, default=1e-4)</p><p class="source-code">parser.add_argument("--critic-lr", type=float, default=1e-4)</p><p class="source-code">parser.add_argument("--clip-ratio", type=float, default=0.1)</p><p class="source-code">parser.add_argument("--gae-lambda", type=float, default=0.95)</p><p class="source-code">parser.add_argument("--gamma", type=float, default=0.99)</p><p class="source-code">parser.add_argument("--logdir", default="logs")</p><p class="source-code">args = parser.parse_args()</p></li>
				<li>Let's also set up <a id="_idIndexMarker974"/>logging so that we can visualize <a id="_idIndexMarker975"/>the agent's learning <a id="_idIndexMarker976"/>progress using <a id="_idIndexMarker977"/>TensorBoard:<p class="source-code">logdir = os.path.join(</p><p class="source-code">    args.logdir, parser.prog, args.env, \</p><p class="source-code">    datetime.now().strftime("%Y%m%d-%H%M%S")</p><p class="source-code">)</p><p class="source-code">print(f"Saving training logs to:{logdir}")</p><p class="source-code">writer = tf.summary.create_file_writer(logdir)</p></li>
				<li>For the first export approach, we will define save methods for the <strong class="source-inline">Actor</strong>, <strong class="source-inline">Critic</strong>, and <strong class="source-inline">Agent</strong> classes in the following steps. We will start with the implementation of the <strong class="source-inline">save</strong> method in the <strong class="source-inline">Actor</strong> class to export the Actor model to TensorFlow's <strong class="source-inline">SavedModel</strong> format:<p class="source-code">    def save(self, model_dir: str, version: int = 1):</p><p class="source-code">        actor_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), \</p><p class="source-code">            "model.savedmodel"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(actor_model_save_dir, </p><p class="source-code">                        save_format="tf")</p><p class="source-code">        print(f"Actor model saved at:\</p><p class="source-code">                {actor_model_save_dir}")</p></li>
				<li>Similarly, we will <a id="_idIndexMarker978"/>implement a <strong class="source-inline">save</strong> method for the <strong class="source-inline">Critic</strong> class <a id="_idIndexMarker979"/>to export the <a id="_idIndexMarker980"/>Critic model to <a id="_idIndexMarker981"/>TensorFlow's <strong class="source-inline">SavedModel</strong> format:<p class="source-code">    def save(self, model_dir: str, version: int = 1):</p><p class="source-code">        critic_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), \</p><p class="source-code">            "model.savedmodel"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(critic_model_save_dir, </p><p class="source-code">                        save_format="tf")</p><p class="source-code">        print(f"Critic model saved at:{</p><p class="source-code">                                 critic_model_save_dir}")</p></li>
				<li>We can now add a <strong class="source-inline">save</strong> method for the <strong class="source-inline">Agent</strong> class that will utilize the <strong class="source-inline">Actor</strong> and <strong class="source-inline">Critic</strong> <strong class="source-inline">save</strong> method to save both the models needed by the Agent:<p class="source-code">    def save(self, model_dir: str, version: int = 1):</p><p class="source-code">        self.actor.save(model_dir, version)</p><p class="source-code">        self.critic.save(model_dir, version)</p></li>
				<li>Once the <strong class="source-inline">save()</strong> method is executed, it will <a id="_idIndexMarker982"/>generate two models (one <a id="_idIndexMarker983"/>for the Actor <a id="_idIndexMarker984"/>and one for the Critic) and <a id="_idIndexMarker985"/>save them in the specified directory on the filesystem with the directory structure and files similar to the one shown in the following figure:<div id="_idContainer102" class="IMG---Figure"><img src="image/B15074_09_01.jpg" alt="Figure 9.1 – TensorFlow SavedModel directory structure and file contents for the PPO RL agent "/></div><p class="figure-caption">Figure 9.1 – TensorFlow SavedModel directory structure and file contents for the PPO RL agent</p></li>
				<li>Once the <strong class="source-inline">SavedModel</strong> files are generated, we can use the <strong class="source-inline">tflite_convert</strong> command-line tool and specify the location of the Actor model's save directory. Refer to the following <a id="_idTextAnchor250"/>command for an example:<p class="source-code"><strong class="bold">(tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tflite_convert \</strong></p><p class="source-code"><strong class="bold">  --saved_model_dir=trained_models/ppo-procgen-coinrun/1/actor/model.savedmodel \</strong></p><p class="source-code"><strong class="bold">  --output_file=trained_models/ppo-procgen-coinrun/1/actor/model.tflite</strong></p></li>
				<li>Similarly, we can convert the Critic model using the following command:<p class="source-code"><strong class="bold">(tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tflite_convert \</strong></p><p class="source-code"><strong class="bold">  --saved_model_dir=trained_models/ppo-procgen-coinrun/1/critic/model.savedmodel \</strong></p><p class="source-code"><strong class="bold">  --output_file=trained_models/ppo-procgen-coinrun/1/critic/model.tflite</strong></p><p>Hooray! We now have both the Actor and Critic models in  TFLite format, which we can ship with our mobile applications. We will look at another approach that doesn't need us to (manually) switch to the command line to convert the model.</p></li>
				<li>There's <a id="_idIndexMarker986"/>another approach to <a id="_idIndexMarker987"/>export the Agent model <a id="_idIndexMarker988"/>to the TFLite format. We <a id="_idIndexMarker989"/>will be implementing it in the following steps, starting with the <strong class="source-inline">save_tflite</strong> method for the <strong class="source-inline">Actor</strong> class:<p class="source-code">    def save_tflite(self, model_dir: str, version: int =\</p><p class="source-code">     1):</p><p class="source-code">        """Save/Export Actor model in TensorFlow Lite</p><p class="source-code">        format"""</p><p class="source-code">        actor_model_save_dir = os.path.join(model_dir,\</p><p class="source-code">                                   "actor", str(version))</p><p class="source-code">        model_converter = \</p><p class="source-code">            tf.lite.TFLiteConverter.from_keras_model(</p><p class="source-code">                                              self.model)</p><p class="source-code">        # Convert model to TFLite Flatbuffer</p><p class="source-code">        tflite_model = model_converter.convert()</p><p class="source-code">        # Save the model to disk/persistent-storage</p><p class="source-code">        if not os.path.exists(actor_model_save_dir):</p><p class="source-code">            os.makedirs(actor_model_save_dir)</p><p class="source-code">        actor_model_file_name = os.path.join(</p><p class="source-code">                  actor_model_save_dir, "model.tflite")</p><p class="source-code">        with open(actor_model_file_name, "wb") as \</p><p class="source-code">        model_file:</p><p class="source-code">            model_file.write(tflite_model)</p><p class="source-code">        print(f"Actor model saved in TFLite format at:\</p><p class="source-code">               {actor_model_file_name}")</p></li>
				<li>Similarly, we will implement the <strong class="source-inline">save_tflite</strong> method for the <strong class="source-inline">Critic</strong> class:<p class="source-code">    def save_tflite(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Critic model in TensorFlow Lite  </p><p class="source-code">        format"""</p><p class="source-code">        critic_model_save_dir = os.path.join(model_dir, </p><p class="source-code">                                  "critic", str(version))</p><p class="source-code">        model_converter = \</p><p class="source-code">            tf.lite.TFLiteConverter.from_keras_model(</p><p class="source-code">                                              self.model)</p><p class="source-code">        # Convert model to TFLite Flatbuffer</p><p class="source-code">        tflite_model = model_converter.convert()</p><p class="source-code">        # Save the model to disk/persistent-storage</p><p class="source-code">        if not os.path.exists(critic_model_save_dir):</p><p class="source-code">            os.makedirs(critic_model_save_dir)</p><p class="source-code">        critic_model_file_name = os.path.join(</p><p class="source-code">                  critic_model_save_dir, "model.tflite")</p><p class="source-code">        with open(critic_model_file_name, "wb") as \</p><p class="source-code">        model_file:</p><p class="source-code">            model_file.write(tflite_model)</p><p class="source-code">        print(f"Critic model saved in TFLite format at:\</p><p class="source-code">                {critic_model_file_name}")</p></li>
				<li>The Agent's class can then <a id="_idIndexMarker990"/>call the <strong class="source-inline">save_tflite</strong> method on the Actor and Critic using its <a id="_idIndexMarker991"/>own <strong class="source-inline">save_tflite</strong> method, as <a id="_idIndexMarker992"/>shown in the following <a id="_idIndexMarker993"/>code snippet:<p class="source-code">    def save_tflite(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        # Make sure `toco_from_protos binary` is on </p><p class="source-code">        # system's PATH to avoid TFLite ConverterError</p><p class="source-code">        toco_bin_dir = os.path.dirname(sys.executable)</p><p class="source-code">        if not toco_bin_dir in os.environ["PATH"]:</p><p class="source-code">            os.environ["PATH"] += os.pathsep + \</p><p class="source-code">                                  toco_bin_dir</p><p class="source-code">        print(f"Saving Agent model (TFLite) to:{</p><p class="source-code">                                           model_dir}\n")</p><p class="source-code">        self.actor.save_tflite(model_dir, version)</p><p class="source-code">        self.critic.save_tflite(model_dir, version)</p><p>Notice that we added the <strong class="source-inline">bin</strong> directory of the current (<strong class="source-inline">tfrl-cookbook</strong>) Python environment to the system's <strong class="source-inline">PATH</strong> environment variable to make sure the <strong class="source-inline">toco_from_protos</strong> binary is found when the TFLite converter invokes the model conversion.</p></li>
				<li>To <a id="_idIndexMarker994"/>sum up, we <a id="_idIndexMarker995"/>can finalize the <a id="_idIndexMarker996"/><strong class="source-inline">main</strong> function to instantiate <a id="_idIndexMarker997"/>the agent and train and save the model in TFLite model file format:<p class="source-code">if __name__ == "__main__":</p><p class="source-code">    env_name = args.env</p><p class="source-code">    env = gym.make(env_name)</p><p class="source-code">    agent = PPOAgent(env)</p><p class="source-code">    agent.train(max_episodes=1)</p><p class="source-code">    # Model saving</p><p class="source-code">    model_dir = "trained_models"</p><p class="source-code">    agent_name = f"PPO_{env_name}"</p><p class="source-code">    agent_version = 1</p><p class="source-code">    agent_model_path = os.path.join(model_dir, \</p><p class="source-code">                                    agent_name)</p><p class="source-code">    agent.save_tflite(agent_model_path, agent_version)</p></li>
			</ol>
			<p>That completes our recipe. Let's recap with some important details to understand the recipe better.</p>
			<h2 id="_idParaDest-219"><a id="_idTextAnchor251"/>How it works...</h2>
			<p>We first set TensorFlow Keras's backend to use <strong class="source-inline">float32</strong> as the default representation for float values. This is because, otherwise, TensorFlow would use the default <strong class="source-inline">float64</strong> representation, which is not supported by TFLite (for performance reasons) as it is targeted towards running on embedded and mobile devices.</p>
			<p>Then, we <a id="_idIndexMarker998"/>defined a list of choices <a id="_idIndexMarker999"/>for the <strong class="source-inline">--env</strong> argument. This is <a id="_idIndexMarker1000"/>important to make sure <a id="_idIndexMarker1001"/>that the environment's observation and action spaces are compatible with the agent's model. In this recipe, we used a PPO agent with Actor and Critic networks that expect image observations and produce actions in discrete space. You can swap the agent code with the PPO implementations from one of the earlier chapters that use different state/observation spaces and action spaces. You could also replace the agent with a different agent algorithm altogether. You will find a bonus recipe that exports a DDPG agent TFLite model in the book's code repository for this chapter.</p>
			<p>We discussed two approaches to save and convert our Agent models to TFLite format. The first approach allowed us to generate a TensorFlow SavedModel file format first and then convert it to the TFLite model file format using the <strong class="source-inline">tflite_convert</strong> command-line tool. In the second approach, we used TFLite's Python API to directly (in-memory) convert and save the agent's models in TFLite (Flatbuffer) format. We made use of the <strong class="source-inline">TFLiteConverter</strong> module, which ships with the official TensorFlow 2.x Python package. A summary of different ways to export the RL agent's model using the API is provided in the following figure:</p>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/B15074_09_02.jpg" alt="Figure 9.2 – Converting TensorFlow 2.x models to TensorFlow Lite Flatbuffer format "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2 – Converting TensorFlow 2.x models to TensorFlow Lite Flatbuffer format</p>
			<p>You can learn more about the <a id="_idIndexMarker1002"/>TFLite model format here: <a href="https://www.tensorflow.org/lite">https://www.tensorflow.org/lite</a>.</p>
			<p>It's time to hop on to the next recipe!</p>
			<h1 id="_idParaDest-220"><a id="_idTextAnchor252"/>Deploying RL agents on mobile devices</h1>
			<p>Mobile is the <a id="_idIndexMarker1003"/>most-targeted platform due to its high <a id="_idIndexMarker1004"/>customer reach compared to other platforms. The global mobile application market size is projected to reach USD 407.32 <a id="_idIndexMarker1005"/>billion by 2026 according to <a href="https://www.alliedmarketresearch.com/mobile-application-market">https://www.alliedmarketresearch.com/mobile-application-market</a>. Such a huge market opens several opportunities for infusing RL-based Artificial Intelligence. Android and iOS are the two main OS platforms in this space. While IOS is a popular platform, building apps for iOS requires a Mac to develop the apps. We will therefore develop an Android app using the Android SDK, which is more widely accessible. If you are an iOS app developer, you may be able to adapt parts of this recipe to your app.</p>
			<p>This recipe provides ways for you to deploy trained RL agent models on mobile and/or IoT devices using the TensorFLow Lite framework. You will also have access to a sample RL Table Tennis <a id="_idIndexMarker1006"/>Android app that you can use as a testbed to <a id="_idIndexMarker1007"/>deploy your RL agent or develop your own ideas and apps:</p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B15074_09_03.jpg" alt="Figure 9.3 – A screenshot of the RL Table Tennis app running on an Android device "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – A screenshot of the RL Table Tennis app running on an Android device</p>
			<p>Let's get started!</p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor253"/>Getting ready</h2>
			<p>We will be using Android Studio to set up and develop the <a id="_idIndexMarker1008"/>sample RL Android app. Download and install <a id="_idIndexMarker1009"/>Android Studio from the <a id="_idIndexMarker1010"/>official website: <a href="https://developer.android.com/studio">https://developer.android.com/studio</a>. Using the default install location is recommended. Once installed, run Android Studio to start the <strong class="bold">Android Studio Setup Wizard</strong>. Follow through the setup process and make sure the latest Android SDK, Android SDK command-line tools, and the Android SDK build tools are marked for installation.</p>
			<p>To run the application once complete, you have two options: 1. Run it on your Android phone 2. Run it in the Android virtual device emulator. Follow the setup instructions depending on your choice:</p>
			<ul>
				<li>Running it on your Android phone: <p>a) Enable <a id="_idIndexMarker1011"/>developer options and USB debugging in Android settings. Detailed instructions are available here: <a href="https://developer.android.com/studio/debug/dev-options">https://developer.android.com/studio/debug/dev-options</a>.</p><p>b) If you are on Windows, install the Google <a id="_idIndexMarker1012"/>USB driver: <a href="https://developer.android.com/studio/run/win-usb">https://developer.android.com/studio/run/win-usb</a>.</p><p>c) Connect your phone to your computer using a USB cable and, if prompted, allow your computer to access your phone.</p><p>d) Run <strong class="source-inline">adb devices</strong> to make sure your phone is detected. If your phone is not detected, make sure the drivers are installed and ADB debugging is enabled on your phone. You can follow the Android official guide here for detailed instructions: <a href="https://developer.android.com/studio/run/device#setting-up">https://developer.android.com/studio/run/device#setting-up</a>.</p></li>
				<li>Running it in the Android emulator:<p>a) Launch Android Studio, click on the <strong class="bold">AVD Manager</strong> icon and select <strong class="bold">Create Virtual Device</strong>.</p><p>b) Choose a device and select <strong class="bold">Next</strong>.</p><p>c) Choose an x86 or x86_64 image for the Android version you want to emulate and complete the process.</p><p>d) Click <strong class="bold">Run</strong> in the AVD Manager toolbar to launch the emulator.</p></li>
			</ul>
			<p>Once you have the device set up, navigate to the code directory for this recipe under the <strong class="source-inline">src/ch9-cross-platform-deployment</strong> directory. You will find a sample Android application <a id="_idIndexMarker1013"/>with a directory structure and <a id="_idIndexMarker1014"/>contents like the one shown in the following screenshot:</p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/B15074_09_04.jpg" alt="Figure 9.4 – Directory structure and contents of the sample Android app "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Directory structure and contents of the sample Android app</p>
			<p>Once you have the sample code base to work with, move on to the next section to see how to prepare our RL agent model and build the app.</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor254"/>How to do it...</h2>
			<p>We'll start with the RL agent model preparation and then build a simple, two-player Table Tennis app where you can play against the agent. Follow the steps listed here:</p>
			<ol>
				<li value="1">Export your RL agent's (Actor) model to TFLite format using the previous recipe discussed in this chapter. For example, you can run the previous recipe to train a PPO agent for the <strong class="source-inline">Pong-v4</strong> environment and use the generated <strong class="source-inline">model.tflite</strong> file <a id="_idIndexMarker1015"/>in the <strong class="source-inline">trained_models/actor/1/</strong> directory. Place the model in the Android <a id="_idIndexMarker1016"/>app's <strong class="source-inline">app/src/assets/</strong> directory as highlighted in the figure here:<div id="_idContainer106" class="IMG---Figure"><img src="image/B15074_09_05.jpg" alt="Figure 9.5 – RL agent model.tflite location in Android app src "/></div><p class="figure-caption">Figure 9.5 – RL agent model.tflite location in Android app src</p></li>
				<li>Edit the app's <strong class="source-inline">dependencies</strong> section in the <strong class="source-inline">build.gradle</strong> file to include the <strong class="source-inline">tensorflow-lite</strong> dependency:<p class="source-code">dependencies {</p><p class="source-code">    implementation fileTree(dir: 'libs', include: \</p><p class="source-code">                            ['*.jar'])</p><p class="source-code">    implementation 'org.tensorflow:tensorflow-lite:+'</p><p class="source-code">}</p></li>
				<li>Add a member method to load the <strong class="source-inline">agent/model.tflite</strong> from the <strong class="source-inline">assets</strong> folder and return a <strong class="source-inline">MappedByteBuffer</strong>:<p class="source-code">    MappedByteBuffer loadModelFile(AssetManager \</p><p class="source-code">         assetManager) throws IOException {</p><p class="source-code">        AssetFileDescriptor fileDescriptor = \</p><p class="source-code">            assetManager.openFd("agent/model.tflite");</p><p class="source-code">        FileInputStream inputStream = new \</p><p class="source-code">             FileInputStream(</p><p class="source-code">                  fileDescriptor.getFileDescriptor());</p><p class="source-code">        FileChannel fileChannel = \</p><p class="source-code">                    inputStream.getChannel();</p><p class="source-code">        long startOffset = \</p><p class="source-code">             fileDescriptor.getStartOffset();</p><p class="source-code">        long declaredLength = \</p><p class="source-code">             fileDescriptor.getDeclaredLength();</p><p class="source-code">        return fileChannel.map(</p><p class="source-code">            FileChannel.MapMode.READ_ONLY, \</p><p class="source-code">            startOffset, declaredLength);</p><p class="source-code">    }</p></li>
				<li>We <a id="_idIndexMarker1017"/><a id="_idTextAnchor255"/>can now create a <a id="_idIndexMarker1018"/>new TFLite interpreter like so:<p class="source-code">interpreter = new Interpreter(loadModelFile(assetManager),</p><p class="source-code">                              new Interpreter.Options());</p></li>
				<li>The interpreter is ready. Let's prepare the input. First, let's define some constants based on what we know from our agent training:<p class="source-code"> static final int BATCH_SIZE = 1;</p><p class="source-code">  static final int OBS_IMG_WIDTH = 160;</p><p class="source-code"> static final int OBS_IMG_HEIGHT = 210;</p><p class="source-code"> static final int OBS_IMG_CHANNELS = 3;</p><p class="source-code"> // Image observation normalization</p><p class="source-code"> static final int IMAGE_MEAN = 128;</p><p class="source-code"> static final float IMAGE_STD = 128.0f;</p></li>
				<li>Let's now <a id="_idIndexMarker1019"/>implement a method to convert image <a id="_idIndexMarker1020"/>data in <strong class="source-inline">BitMap</strong> format to <strong class="source-inline">ByteArray</strong>:<p class="source-code">ByteBuffer convertBitmapToByteBuffer(Bitmap bitmap) {</p><p class="source-code">        ByteBuffer byteBuffer;</p><p class="source-code">        byteBuffer = ByteBuffer.allocateDirect(4 * \</p><p class="source-code">                      BATCH_SIZE * OBS_IMG_WIDTH * \</p><p class="source-code">                      OBS_IMG_HEIGHT * OBS_IMG_CHANNELS);</p><p class="source-code">        byteBuffer.order(ByteOrder.nativeOrder());</p><p class="source-code">        int[] intValues = new int[OBS_IMG_WIDTH * \</p><p class="source-code">                                  OBS_IMG_HEIGHT];</p><p class="source-code">        bitmap.getPixels(intValues,0, bitmap.getWidth(),\</p><p class="source-code">          0, 0, bitmap.getWidth(), bitmap.getHeight());</p><p class="source-code">        int pixel = 0;</p><p class="source-code">        for (int i = 0; i &lt; OBS_IMG_HEIGHT; ++i) {</p><p class="source-code">            for (int j = 0; j &lt; OBS_IMG_WIDTH; ++j) {</p><p class="source-code">                final int val = intValues[pixel++];</p><p class="source-code">                </p><p class="source-code">                    byteBuffer.putFloat((((val &gt;&gt; 16) &amp;\</p><p class="source-code">                        0xFF)-IMAGE_MEAN)/IMAGE_STD);</p><p class="source-code">                    byteBuffer.putFloat((((val &gt;&gt; 8) &amp; \</p><p class="source-code">                        0xFF)-IMAGE_MEAN)/IMAGE_STD);</p><p class="source-code">                    byteBuffer.putFloat((((val) &amp; 0xFF)-\</p><p class="source-code">                        IMAGE_MEAN)/IMAGE_STD);</p><p class="source-code">            }</p><p class="source-code">        }</p><p class="source-code">        return byteBuffer;</p><p class="source-code">    }</p></li>
				<li>We can now run the <a id="_idIndexMarker1021"/>image observations from the Table Tennis game through the Agent model to get <a id="_idIndexMarker1022"/>the action: <p class="source-code">ByteBuffer byteBuffer = convertBitmapToByteBuffer(bitmap);</p><p class="source-code">int[] action = new int[ACTION_DIM];</p><p class="source-code">interpreter.run(byteBuffer, action);</p><p>Those are all the main ingredients for this recipe! You can run them in a loop to generate actions per observation/game frame or customize them however you like! Let's look at how to run the app on an Android device using Android Studio in the following steps.</p></li>
				<li>Launch Android Studio. You will see a screen like this:<div id="_idContainer107" class="IMG---Figure"><img src="image/B15074_09_06.jpg" alt="Figure 9.6 – Android Studio welcome screen "/></div><p class="figure-caption">Figure 9.6 – Android Studio welcome screen</p><p>Let's proceed to the next step.</p></li>
				<li>Click on <a id="_idIndexMarker1023"/>the <strong class="bold">Open an Existing Project</strong> option <a id="_idIndexMarker1024"/>and you will see a popup asking you to choose the directory on your filesystem. Navigate to the folder where you have cloned the book's code repo or your fork, and browse to this recipe's folder under <a href="#_idTextAnchor244"><em class="italic">Chapter 9</em></a> as shown in the figure here:<div id="_idContainer108" class="IMG---Figure"><img src="image/B15074_09_07.jpg" alt="Figure 9.7 – File/project picker interface to choose the RL Android app "/></div><p class="figure-caption">Figure 9.7 – File/project picker interface to choose the RL Android app</p><p>You will notice <a id="_idIndexMarker1025"/>that Android Studio has already <a id="_idIndexMarker1026"/>identified our app and shows the directory with an Android symbol.</p></li>
				<li>Once you click <strong class="bold">OK</strong>, Android Studio will open with the app's code and will look like the following figure:<div id="_idContainer109" class="IMG---Figure"><img src="image/B15074_09_08.jpg" alt="Figure 9.8 – Android Studio with the TFRL-Cookbook's RL app loaded "/></div><p class="figure-caption">Figure 9.8 – Android Studio with the TFRL-Cookbook's RL app loaded</p><p>So far, so good!</p></li>
				<li>Let's <a id="_idIndexMarker1027"/>build the project <a id="_idIndexMarker1028"/>by clicking on the <strong class="bold">Build</strong> menu and choosing <strong class="bold">Make Project</strong>, as shown in the following figure (or by simply pressing <em class="italic">Ctrl</em> + <em class="italic">F9</em>):<div id="_idContainer110" class="IMG---Figure"><img src="image/B15074_09_09.jpg" alt="Figure 9.9 – Building the RL Android app using the Make Project option "/></div><p class="figure-caption">Figure 9.9 – Building the RL Android app using the Make Project option</p><p>This <a id="_idIndexMarker1029"/>process may take <a id="_idIndexMarker1030"/>some time to complete and you may see useful status messages in the <strong class="bold">Build</strong> information tab.</p></li>
				<li>Once the build process completes, you will see <strong class="bold">BUILD SUCCESSFUL</strong> in the <strong class="bold">Build</strong> console output, as shown in the following figure:<div id="_idContainer111" class="IMG---Figure"><img src="image/B15074_09_010.jpg" alt="Figure 9.10 – RL Android app BUILD SUCCESSFUL message "/></div><p class="figure-caption">Figure 9.10 – RL Android app BUILD SUCCESSFUL message</p><p>The build <a id="_idIndexMarker1031"/>process generates a <strong class="source-inline">.apk</strong> file, which <a id="_idIndexMarker1032"/>can be run on an Android device.</p></li>
				<li>Let's go ahead and run the app by using the <strong class="bold">Run</strong> menu, as shown in the following figure:<div id="_idContainer112" class="IMG---Figure"><img src="image/B15074_09_011.jpg" alt="Figure 9.11 – The Run menu option to run the RL app in Android Studio "/></div><p class="figure-caption">Figure 9.11 – The Run menu option to run the RL app in Android Studio</p><p>At this point, if you have your Android device/phone connected to the machine, you can launch that app on your phone. Otherwise, you can use the AVD to emulate an Android device.</p></li>
				<li>Let's choose <a id="_idIndexMarker1033"/>an AVD device to emulate from the <a id="_idIndexMarker1034"/>device menu, as shown in the following figure:<div id="_idContainer113" class="IMG---Figure"><img src="image/B15074_09_012.jpg" alt="Figure 9.12 – Choose the AVD to emulate an Android device "/></div><p class="figure-caption">Figure 9.12 – Choose the AVD to emulate an Android device</p><p>We are now ready with the device to run the app.</p></li>
				<li>Let's go ahead and launch/run the app! You can use the <strong class="bold">Run 'app'</strong> button from the <strong class="bold">Run</strong> menu, as shown in the following figure:<div id="_idContainer114" class="IMG---Figure"><img src="image/B15074_09_013.jpg" alt="Figure 9.13 – Run 'app' command to launch the app "/></div><p class="figure-caption">Figure 9.13 – Run 'app' command to launch the app</p><p>That should <a id="_idIndexMarker1035"/>launch the app on the AVD <a id="_idIndexMarker1036"/>emulator (or on your phone if you chose it).</p></li>
				<li>The app should launch on the Android device and should look something like the following figure:</li>
			</ol>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B15074_09_014.jpg" alt="Figure 9.14 – The TFRL-Cookbook RL app running on an Android (emulated) device "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.14 – The TFRL-Cookbook RL app running on an Android (emulated) device</p>
			<p>Congratulations! </p>
			<p>That <a id="_idIndexMarker1037"/>completes our <a id="_idIndexMarker1038"/>recipe. Head to the next section to learn more about the recipe.</p>
			<h2 id="_idParaDest-223"><a id="_idTextAnchor256"/>How it works...</h2>
			<p>In the previous recipe, we saw how you can export your Deep RL agent's model to the TFLite format. The previous recipe generated two <strong class="source-inline">model.tflite</strong> files: one for the Actor and another for the Critic. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can train any agent algorithm of your choice following the recipes previously discussed in this book and use the recipe titled <em class="italic">Packaging Deep RL agents for mobile and IoT devices using TensorFlow Lite</em> in this chapter to obtain the Actor <strong class="source-inline">model.tflite</strong> file used in this recipe.</p>
			<p>As you may recall from <a href="B15074_03_ePub_AM.xhtml#_idTextAnchor090"><em class="italic">Chapter 3</em></a>, <em class="italic">Implementing Advanced Deep RL Algorithms on Deep RL Agents</em>, the Actor <a id="_idIndexMarker1039"/>component is responsible for <a id="_idIndexMarker1040"/>generating actions according to the learned policy and the Critic component estimates the state or state-action value. When it comes to deploying RL agents, we are more interested in the action generated by the agent than the predicted state or state-action values. Therefore, we only used the agent's Actor model for deployment purposes in this recipe. </p>
			<p>We first included the TFLite dependency by updating the app's <strong class="source-inline">gradle.build</strong> file. We then added a method named <strong class="source-inline">loadModelFile</strong> to load the agent's model (<strong class="source-inline">model.tflite</strong>). This returns a <strong class="source-inline">MappedByteBuffer</strong> object, which is needed to initialize a TFLite interpreter instance. Once the agent's model is loaded and a TFLite interpreter instance is created, we can run the interpreter with valid inputs to get the agent's actions. In order to make sure the inputs are in a valid format, we converted the image data from <strong class="source-inline">BitMap</strong> format to <strong class="source-inline">ByteBuffer</strong> format. We also defined the image observation width, height, number of channels, and so on based on the observation space of the environment we used to train the RL agent.</p>
			<p>The action returned by the agent's model in <em class="italic">Step 7</em> can be used to actuate/move, say, the red paddle in the Table Tennis game and repeat the preceding steps for each new observation in a loop to make the agent play against itself or a human!</p>
			<p>We then saw how to launch the app using Android Studio and then concluded the recipe. Hope you had fun!</p>
			<p>Let's march on to the next recipe whenever you are ready.</p>
			<h1 id="_idParaDest-224"><a id="_idTextAnchor257"/>Packaging Deep RL agents for the web and Node.js using TensorFlow.js</h1>
			<p>JavaScript is the <a id="_idIndexMarker1041"/>language of choice <a id="_idIndexMarker1042"/>when it comes to <a id="_idIndexMarker1043"/>developing web <a id="_idIndexMarker1044"/>applications due to its versatility both as a frontend as well as a backend programming language that can be executed by a web browser or using Node.js. The ability to run out RL agents on the web will unlock several new pathways for deploying RL agents in web apps. This recipe will show how you can train and export RL agent models into a format that you can then use in your JavaScript applications that can be run directly in the browser or in a Node.js environment. The TensorFlow.js (TF.js) library allows us to use JavaScript to run existing models or even train/retrain new models. We will use the <strong class="source-inline">tensorflowjs</strong> Python module to export our agent's model to a supported format that can be imported into JavaScript-based web or desktop (Node.js/Electron) apps. We will explore two approaches to export the Agent model to the TF.js layers format. </p>
			<p>Let's get started!</p>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor258"/>Getting ready</h2>
			<p>To complete this recipe, you will first need to activate the <strong class="source-inline">tf2rl-cookbook</strong> Python/conda virtual environment. Make sure to update the environment to match the latest conda environment specification file (<strong class="source-inline">tfrl-cookbook.yml</strong>) in the cookbook's code repo. If the following imports work without issues, you are ready to get started:</p>
			<p class="source-code">import argparse</p>
			<p class="source-code">import copy</p>
			<p class="source-code">import os</p>
			<p class="source-code">import random</p>
			<p class="source-code">from collections import deque</p>
			<p class="source-code">from datetime import datetime</p>
			<p class="source-code">import gym</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import tensorflow as tf</p>
			<p class="source-code">import tensorflowjs as tfjs</p>
			<p class="source-code">from tensorflow.keras.layers import (</p>
			<p class="source-code">    Conv2D,</p>
			<p class="source-code">    Dense,</p>
			<p class="source-code">    Dropout,</p>
			<p class="source-code">    Flatten,</p>
			<p class="source-code">    Input,</p>
			<p class="source-code">    Lambda,</p>
			<p class="source-code">    MaxPool2D,</p>
			<p class="source-code">)</p>
			<p class="source-code">import webgym</p>
			<p>Now, let's begin!</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor259"/>How to do it...</h2>
			<p>In the <a id="_idIndexMarker1045"/>following text, we will save <a id="_idIndexMarker1046"/>space by focusing on the <a id="_idIndexMarker1047"/>new and important <a id="_idIndexMarker1048"/>pieces that are unique to this recipe. We will go through the model saving and export functionality and the different ways you can do that and keep the Actor, Critic, and Agent model definitions out of the following steps to save space. Please refer to the book's code repository for a complete implementation, including the training and logging methods.</p>
			<p>Let's get started:</p>
			<ol>
				<li value="1">Let's first set up a command-line argument parser to allow easy customization of the script:<p class="source-code">parser = argparse.ArgumentParser(</p><p class="source-code">    prog="TFRL-Cookbook-Ch9-DDPGAgent-TensorFlow.js-exporter"</p><p class="source-code">)</p><p class="source-code">parser.add_argument("--env", default="MiniWoBSocialMediaMuteUserVisualEnv-v0")</p><p class="source-code">parser.add_argument("--actor_lr", type=float, default=0.0005)</p><p class="source-code">parser.add_argument("--critic_lr", type=float, default=0.001)</p><p class="source-code">parser.add_argument("--batch_size", type=int, default=64)</p><p class="source-code">parser.add_argument("--tau", type=float, default=0.05)</p><p class="source-code">parser.add_argument("--gamma", type=float, default=0.99)</p><p class="source-code">parser.add_argument("--train_start", type=int, </p><p class="source-code">                     default=2000)</p><p class="source-code">parser.add_argument("--logdir", default="logs")</p><p class="source-code">args = parser.parse_args()</p></li>
				<li>Let's also <a id="_idIndexMarker1049"/>set up logging <a id="_idIndexMarker1050"/>so that we <a id="_idIndexMarker1051"/>can visualize the agent's <a id="_idIndexMarker1052"/>learning progress using TensorBoard:<p class="source-code">logdir = os.path.join(</p><p class="source-code">    args.logdir, parser.prog, args.env, \</p><p class="source-code">    datetime.now().strftime("%Y%m%d-%H%M%S")</p><p class="source-code">)</p><p class="source-code">print(f"Saving training logs to:{logdir}")</p><p class="source-code">writer = tf.summary.create_file_writer(logdir)</p></li>
				<li>For the <a id="_idIndexMarker1053"/>first export approach, we will <a id="_idIndexMarker1054"/>define <strong class="source-inline">save_h5</strong> methods <a id="_idIndexMarker1055"/>for the <strong class="source-inline">Actor</strong>, <strong class="source-inline">Critic</strong>, and <strong class="source-inline">Agent</strong> classes in the following <a id="_idIndexMarker1056"/>steps. We will start with the implementation of the <strong class="source-inline">save_h5</strong> method in the <strong class="source-inline">Actor</strong> class to export the Actor model to Keras's <strong class="source-inline">h5</strong> format:<p class="source-code">    def save_h5(self, model_dir: str, version: int = 1):</p><p class="source-code">        actor_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), "model.h5"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(actor_model_save_dir, \</p><p class="source-code">                        save_format="h5")</p><p class="source-code">        print(f"Actor model saved at:\</p><p class="source-code">                {actor_model_save_dir}")</p></li>
				<li>Similarly, we will implement a <strong class="source-inline">save</strong> method for the <strong class="source-inline">Critic</strong> class to export the Critic model to Keras's <strong class="source-inline">h5</strong> format:<p class="source-code">    def save_h5(self, model_dir: str, version: int = 1):</p><p class="source-code">        critic_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), "model.h5"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(critic_model_save_dir, \</p><p class="source-code">                        save_format="h5")</p><p class="source-code">        print(f"Critic model saved at:\</p><p class="source-code">                {critic_model_save_dir}")</p></li>
				<li>We <a id="_idIndexMarker1057"/>can now add a <strong class="source-inline">save</strong> method for <a id="_idIndexMarker1058"/>the <strong class="source-inline">Agent</strong> class that <a id="_idIndexMarker1059"/>will utilize the <a id="_idIndexMarker1060"/>Actor and Critic <strong class="source-inline">save</strong> method to save both the models needed by the agent:<p class="source-code">    def save_h5(self, model_dir: str, version: int = 1):</p><p class="source-code">        self.actor.save_h5(model_dir, version)</p><p class="source-code">        self.critic.save_h5(model_dir, version)</p></li>
				<li>Once the <strong class="source-inline">save_h5()</strong> method is executed, the <strong class="source-inline">save</strong> method will generate two models (one for the Actor and one for the Critic) and save them in the specified directory on the filesystem with a <a id="_idTextAnchor260"/>directory structure and files like the one shown in the following figure:<div id="_idContainer116" class="IMG---Figure"><img src="image/B15074_09_015.jpg" alt="Figure 9.15 – Directory structure and file contents for the DDPG RL agent with the save_h5 model export "/></div><p class="figure-caption">Figure 9.15 – Directory structure and file contents for the DDPG RL agent with the save_h5 model export</p></li>
				<li>Once the <strong class="source-inline">.h5</strong> files are <a id="_idIndexMarker1061"/>generated, we <a id="_idIndexMarker1062"/>can use the <strong class="source-inline">tensorflowjs_converter</strong> command-line tool and specify <a id="_idIndexMarker1063"/>the locat<a id="_idTextAnchor261"/>ion of the Actor <a id="_idIndexMarker1064"/>model's <strong class="source-inline">save</strong> directory. Refer to the following command for an example:<p class="source-code"><strong class="bold">(tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tensorflowjs_converter --input_format keras \</strong></p><p class="source-code"><strong class="bold">                       actor/1/model.h5 \</strong></p><p class="source-code"><strong class="bold">                       actor/t1/model.tfjs</strong></p></li>
				<li>Similarly, we can convert the Critic model using the following command:<p class="source-code"><strong class="bold">(tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tensorflowjs_converter --input_format keras \</strong></p><p class="source-code"><strong class="bold">                       critic/1/model.h5 \</strong></p><p class="source-code"><strong class="bold">                       critic/t1/model.tfjs</strong></p><p>Hooray! We now have both the Actor and Critic models in the TF.js layers format. We will look at another approach that doesn't need us to (manually) switch to the command line to convert the model.</p></li>
				<li>There's another approach to <a id="_idIndexMarker1065"/>export the Agent model to the TF.js layers format. We will <a id="_idIndexMarker1066"/>be implementing it <a id="_idIndexMarker1067"/>in the following steps, starting <a id="_idIndexMarker1068"/>with the <strong class="source-inline">save_tfjs</strong> method for the <strong class="source-inline">Actor</strong> class:<p class="source-code">    def save_tfjs(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Actor model in TensorFlow.js </p><p class="source-code">        supported format"""</p><p class="source-code">        actor_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), \</p><p class="source-code">            "model.tfjs"</p><p class="source-code">        )</p><p class="source-code">        tfjs.converters.save_keras_model(self.model,\</p><p class="source-code">                                   actor_model_save_dir)</p><p class="source-code">        print(f"Actor model saved in TF.js format at:\</p><p class="source-code">                {actor_model_save_dir}")</p></li>
				<li>Similarly, we will implement the <strong class="source-inline">save_tfjs</strong> method for the <strong class="source-inline">Critic</strong> class:<p class="source-code">    def save_tfjs(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Critic model in TensorFlow.js </p><p class="source-code">        supported format"""</p><p class="source-code">        critic_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), \</p><p class="source-code">            "model.tfjs"</p><p class="source-code">        )</p><p class="source-code">        tfjs.converters.save_keras_model(self.model,\</p><p class="source-code">                                 critic_model_save_dir)</p><p class="source-code">        print(f"Critic model saved TF.js format \</p><p class="source-code">                 at:{critic_model_save_dir}")</p></li>
				<li>The <strong class="source-inline">Agent</strong> class <a id="_idIndexMarker1069"/>can then call <a id="_idIndexMarker1070"/>the <strong class="source-inline">save_tfjs</strong> method <a id="_idIndexMarker1071"/>on the Actor and <a id="_idIndexMarker1072"/>Critic using its own <strong class="source-inline">save_tfjs</strong> method, as shown in the following code snippet:<p class="source-code">    def save_tfjs(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        print(f"Saving Agent model to:{model_dir}\n")</p><p class="source-code">        self.actor.save_tfjs(model_dir, version)</p><p class="source-code">        self.critic.save_tfjs(model_dir, version)</p></li>
				<li>When the Agent's <strong class="source-inline">save_tfjs</strong> method gets executed, the Actor and Critic models in the TF.js layers format will be generated and will have a directory structure and file contents like the one shown in the following figure:<div id="_idContainer117" class="IMG---Figure"><img src="image/B15074_09_016.jpg" alt="Figure 9.16 – Directory structure and file contents for the DDPG RL agent with the save_tfjs model export "/></div><p class="figure-caption">Figure 9.16 – Directory structure and file contents for the DDPG RL agent with the save_tfjs model export</p></li>
				<li>To <a id="_idIndexMarker1073"/>sum up, we can <a id="_idIndexMarker1074"/>finalize the <strong class="source-inline">main</strong> function to <a id="_idIndexMarker1075"/>instantiate the agent <a id="_idIndexMarker1076"/>and train and save the model in the TF.js layers format directly using the Python API:<p class="source-code">if __name__ == "__main__":</p><p class="source-code">    env_name = args.env</p><p class="source-code">    env = gym.make(env_name)</p><p class="source-code">    agent = PPOAgent(env)</p><p class="source-code">    agent.train(max_episodes=1)</p><p class="source-code">    # Model saving</p><p class="source-code">    model_dir = "trained_models"</p><p class="source-code">    agent_name = f"PPO_{env_name}"</p><p class="source-code">    agent_version = 1</p><p class="source-code">    agent_model_path = os.path.join(model_dir, \</p><p class="source-code">                                    agent_name)</p><p class="source-code">    # agent.save_h5(agent_model_path, agent_version)</p><p class="source-code">    agent.save_tfjs(agent_model_path, agent_version)</p></li>
				<li>You can now take the TF.js model and deploy it in your web app, Node.js app, Electron app, or any other JavaScript/TypeScript-based applications. Let's recap some of the key items we used in this recipe in the next section.</li>
			</ol>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor262"/>How it works...</h2>
			<p>In <a id="_idIndexMarker1077"/>this recipe, we used a DDPG agent with Actor and Critic <a id="_idIndexMarker1078"/>networks that <a id="_idIndexMarker1079"/>expect image <a id="_idIndexMarker1080"/>observations and produce actions in continuous space. You can swap the agent code with the DDPG implementations from one of the earlier chapters that use different state/observation spaces and action spaces. You could also replace the agent with a different agent algorithm altogether. You will find a bonus recipe that exports a PPO agent TF.js model in the book's code repository for this chapter.</p>
			<p>We discussed two approaches to save and convert our agent models to TF.js format. The first approach allowed us to generate a Keras model in H5 format, which is a short form of HDF5, which is an acronym for Hierarchical Data Format version 5 file format. We then converted it to the TF.js model using the <strong class="source-inline">tensorflowjs_converter</strong> command-line tool. While it is lightweight and easy to handle a single file per model, the Keras HDF5 model has limitations compared to the SavedModel file format. Specifically, the Keras HDF5 models do not contain the computation graphs of custom objects/layers and therefore will require the Python class/function definitions for these custom objects to reconstruct the model during runtime. Moreover, in the cases when we add loss terms and metrics outside the model class definition (using <strong class="source-inline">model.add_loss()</strong> or <strong class="source-inline">model.add_metric()</strong>), these are not exported in the HDF5 model file.</p>
			<p>In the <a id="_idIndexMarker1081"/>second approach, we <a id="_idIndexMarker1082"/>used the <strong class="source-inline">tensorflowjs</strong> Python <a id="_idIndexMarker1083"/>module to directly (in memory) convert <a id="_idIndexMarker1084"/>and save the agent's models in the TF.js layers format.</p>
			<p>You can learn more <a id="_idIndexMarker1085"/>about TF.js here: <a href="https://www.tensorflow.org/js">https://www.tensorflow.org/js</a>.</p>
			<p>It's time for the next recipe!</p>
			<h1 id="_idParaDest-228"><a id="_idTextAnchor263"/>Deploying a Deep RL agent as a service</h1>
			<p>Once you train your RL <a id="_idIndexMarker1086"/>agent to solve a problem or business need, you will want to deploy it as a service – more likely than offering the trained agent model as a product due to several reasons, including scalability and model-staleness limitations. You will want to have a way to update the agent model with new versions and you will not want to maintain or offer support for multiple versions or older versions of your agent if you sell it as a product. You will need a solid and well-tested mechanism to offer your RL agent as an AI service that allows customizable runtimes (different frameworks, and CPU/GPU support), easy model upgrades, logging, performance monitoring, and so on.</p>
			<p>To serve all such needs, we will be using NVIDIA's Triton server as the backend for serving our agent as a service. Triton serves as a unifying inference framework for the deployment of AI models at scale in production. It supports a wide variety of deep learning frameworks including TensorFlow2, PyTorch, ONNX, Caffe2, and others, including custom frameworks, and offers several other production-quality features and optimizations, such as concurrent model execution, dynamic batching, logging, and performance and health monitoring.</p>
			<p>Let's get started with our recipe!</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor264"/>Getting ready</h2>
			<p>To complete this recipe, you will first need to activate the <strong class="source-inline">tf2rl-cookbook</strong> Python/conda virtual environment. Make sure to update the environment to match the latest conda environment specification file (<strong class="source-inline">tfrl-cookbook.yml</strong>) in the cookbook's code repo. You will also need to make sure you have the latest NVIDIA GPU drivers installed on your machine that supports the GPU you have. You will also need Docker set up on your machine. If you haven't installed Docker, you can follow the official instructions here to <a id="_idIndexMarker1087"/>set up Docker for your OS: <a href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a>.</p>
			<p>Now, let's begin!</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor265"/>How to do it...</h2>
			<p>In the following text, we will save space by focusing on the service we will be building. We will keep the contents of the agent training scripts out of the text, but you will find the scripts in the book's code repository under <strong class="source-inline">ch9-cross-platform-deployment</strong>.</p>
			<p>Let's get started:</p>
			<ol>
				<li value="1">First, you will want to train, save, and export the agent that you want to host as a service. You can use the sample <strong class="source-inline">agent_trainer_saver.py</strong> script to train a PPO agent for <a id="_idIndexMarker1088"/>one of the tasks in the Webgym suite of environments using the following command:<p class="source-code"><strong class="bold">$ python agent_trainer_saver.py</strong></p><p>Once the trained agent model is ready, we can move on to the next step.</p><p>Check the NVIDIA framework <a id="_idIndexMarker1089"/>support matrix at <a href="https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html">https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html</a> to find the container image version (in <strong class="source-inline">yy.mm</strong> format) that supports your NVIDIA GPU driver version. For example, if you have installed NVIDIA driver version 450.83 (find out by running <strong class="source-inline">nvidia-smi</strong>), then container versions built with CUDA 11.0.3 or lower, such as container version 20.09 or older, will work.</p></li>
				<li>Once you have identified the suitable container version, say <strong class="source-inline">yy.mm</strong>, you can use Docker to pull the NVIDIA Triton server image using the following command:<p class="source-code"><strong class="bold">praveen@desktop:~$ docker pull nvcr.io/nvidia/tritonserver:yy.mm-py3</strong></p></li>
				<li>Change the <strong class="source-inline">yy.mm</strong> placeholder to the version you have identified. For example, to pull the container version 20.09, you would run the following command:<p class="source-code"><strong class="bold">praveen@desktop:~$ docker pull nvcr.io/nvidia/tritonserver:20.09-py3</strong></p></li>
				<li>When you <a id="_idIndexMarker1090"/>run the <strong class="source-inline">agent_trainer_saver</strong> script, the trained models are stored in the <strong class="source-inline">trained_models</strong> directory with the following directory structure and contents:<div id="_idContainer118" class="IMG---Figure"><img src="image/B15074_09_017.jpg" alt="Figure 9.17 – Directory structure and contents of the exported trained models "/></div><p class="figure-caption">Figure 9.17 – Directory structure and contents of the exported trained models</p><p>The <strong class="source-inline">trained_models/actor</strong> directory will be the root directory for our model repository store when serving with Triton.</p></li>
				<li>We are now ready to serve our agent's actions as a service! To launch the service, run the following command:<p class="source-code"><strong class="bold">$ docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 -v/full/path/to/trained_models/actor:/models nvcr.io/nvidia/tritonserver:yy.mm-py3 tritonserver --model-repository=/models --strict-model-config=false --log-verbose=1</strong></p><p>Remember to update the Docker volume path after the <strong class="source-inline">-v</strong> flag to point to the <strong class="source-inline">trained_models/actor</strong> folder on your serving machine. Also remember to update the <strong class="source-inline">yy.mm</strong> value to reflect your container version (20.3, for example).</p></li>
				<li>If you want to serve the <a id="_idIndexMarker1091"/>agent model from a machine that does not have a GPU (not recommended), you can simply omit the <strong class="source-inline">–gpus=1</strong> flag to instruct the Triton server to serve using CPUs only. The command will look like this: <p class="source-code"><strong class="bold">$ docker run  --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --rm -p8000:8000 -p8001:8001 -p8002:8002 -v/full/path/to/trained_models/actor:/models nvcr.io/nvidia/tritonserver:yy.mm-py3 tritonserver --model-repository=/models --strict-model-config=false --log-verbose=1</strong></p></li>
				<li>If you run into issues serving your agent models, check the <strong class="source-inline">trained_models/actor/config.pbtxt</strong> file, which describes the model configuration. While Triton can automatically generate the <strong class="source-inline">config.pbtxt</strong> file from TensorFlow SavedModels, it may not work well for all, especially a custom policy network implementation. If you are using the <strong class="source-inline">agent_trainer_saver</strong> script to export a trained PPO agent, you can use the following <strong class="source-inline">config.pbtxt</strong>. We will discuss the model config in the next few steps:<p class="source-code">{                                                                                                                     </p><p class="source-code">    "name": "actor",                                                                                                  </p><p class="source-code">    "platform": "tensorflow_savedmodel",                                                                              </p><p class="source-code">    "backend": "tensorflow",                                                                                          </p><p class="source-code">    "version_policy": {                                                                                               </p><p class="source-code">        "latest": {                                                                                                   </p><p class="source-code">            "num_versions": 1                                                                                         </p><p class="source-code">        }                                                                                                             </p><p class="source-code">    },                                                                                                                </p><p class="source-code">    "max_batch_size": 1,  </p></li>
				<li>We will continue <a id="_idIndexMarker1092"/>to specify the input (state/observation) space/dimension configuration:<p class="source-code">    "input": [                                                                                                        </p><p class="source-code">        {                                                                                                             </p><p class="source-code">            "name": "input_1",                                                                                        </p><p class="source-code">            "data_type": "TYPE_FP64",                                                                                 </p><p class="source-code">            "dims": [                                                                                                 </p><p class="source-code">                64,                                                                                                   </p><p class="source-code">                64,                                                                                                   </p><p class="source-code">                3                                                                                                     </p><p class="source-code">            ],</p><p class="source-code">            "format": "FORMAT_NHWC"                                                                                                         </p><p class="source-code">        }                                                                                                             </p><p class="source-code">    ],</p></li>
				<li>Next, we will specify the output (action space):<p class="source-code">    "output": [</p><p class="source-code">        {</p><p class="source-code">            "name": "lambda", </p><p class="source-code">            "data_type": "TYPE_FP64",</p><p class="source-code">            "dims": [</p><p class="source-code">                2</p><p class="source-code">            ]</p><p class="source-code">        },</p><p class="source-code">        {</p><p class="source-code">            "name": "lambda_1",</p><p class="source-code">            "data_type": "TYPE_FP64",</p><p class="source-code">            "dims": [</p><p class="source-code">                2</p><p class="source-code">            ]</p><p class="source-code">        }</p><p class="source-code">    ],                                                                                                                    </p></li>
				<li>Let's also <a id="_idIndexMarker1093"/>specify the instance group, optimization parameters, and so on:<p class="source-code">    "batch_input": [],</p><p class="source-code">    "batch_output": [],</p><p class="source-code">    "optimization": {</p><p class="source-code">        "priority": "PRIORITY_DEFAULT",</p><p class="source-code">        "input_pinned_memory": {</p><p class="source-code">            "enable": true</p><p class="source-code">        },</p><p class="source-code">        "output_pinned_memory": {</p><p class="source-code">            "enable": true</p><p class="source-code">        }</p><p class="source-code">    },</p><p class="source-code">    "instance_group": [</p><p class="source-code">        {</p><p class="source-code">            "name": "actor",</p><p class="source-code">            "kind": "KIND_CPU",</p><p class="source-code">            "count": 1,</p><p class="source-code">            "gpus": [],</p><p class="source-code">            "profile": []</p><p class="source-code">        }</p><p class="source-code">    ],                                                                                                                     </p></li>
				<li>The final set of <a id="_idIndexMarker1094"/>config parameters required for the <strong class="source-inline">config.pbtxt</strong> file is listed here:<p class="source-code">    "default_model_filename": "model.savedmodel",</p><p class="source-code">    "cc_model_filenames": {}, </p><p class="source-code">    "metric_tags": {},</p><p class="source-code">    "parameters": {},</p><p class="source-code">    "model_warmup": []</p><p class="source-code">} </p></li>
				<li>Hooray! Our agent as a service is live. At this point, you can run the same commands we discussed above on a cloud/remote server/VPS if you would like to offer this service on the public web/a network. Let's quickly send a query to the server to make sure everything went as expected:<p class="source-code"><strong class="bold">$curl -v localhost:8000/v2/health/ready</strong></p></li>
				<li>If the agent model is being served without issues, you will see an output similar to the following: <p class="source-code"><strong class="bold">...</strong></p><p class="source-code"><strong class="bold">&lt; HTTP/1.1 200 OK</strong></p><p class="source-code"><strong class="bold">&lt; Content-Length: 0</strong></p><p class="source-code"><strong class="bold">&lt; Content-Type: text/plain</strong></p></li>
				<li>You can also use <a id="_idIndexMarker1095"/>a full-fledged sample client app to query the agent service to get the prescribed action. Let's quickly set up the tools and libraries we need for running a Triton client. You can use Python pip to install the dependencies, as shown in the following command snippet:<p class="source-code"><strong class="bold">$ pip install nvidia-pyindex</strong></p><p class="source-code"><strong class="bold">$ pip install tritonclient[all]</strong></p></li>
				<li>Optionally, to be able to run the performance analyzer (<strong class="source-inline">perf_analyzer</strong>), you will need to install the libb64-dev system package using the following command:<p class="source-code"><strong class="bold">$ sudo apt update &amp;&amp; apt install libb64-dev</strong></p></li>
				<li>You now have all the dependencies to run the sample Triton client app:<p class="source-code"><strong class="bold">$ python sample_client_app.py</strong></p></li>
			</ol>
			<p>That completes our recipe! Let's look into some of the details of what we accomplished in this recipe in the next section.</p>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor266"/>How it works...</h2>
			<p>Our recipe had three sections: </p>
			<ol>
				<li value="1">Train, save, and export; </li>
				<li>Deploy; </li>
				<li>Launch client.</li>
			</ol>
			<p>The first section covered the agent training, saving, and exporting routine. In this section, we first picked the RL environment and agent algorithm we wanted to train. We then utilized one of the many training strategies we discussed earlier in this book to train the agent model. We then used the model saving and export methods we discussed in the previous recipes of this chapter to export the trained agent model in TensorFlow's SavedModel file format. As you may recall, we followed a specific directory structure and file naming convention when we saved and exported our agent model. This convention aligns with the model repository conventions used by the NVIDIA Triton server and thus allows the models we export to be easily served with the production-ready Triton server. Moreover, the organization allows us to manage multiple versions of the agent model concurrently easily. </p>
			<p>In the second section, we saw how we can deploy the exported agent model using NVIDIA's Triton server. You can learn <a id="_idIndexMarker1096"/>more about NVIDIA's Triton here: <a href="https://developer.nvidia.com/nvidia-triton-inference-server">https://developer.nvidia.com/nvidia-triton-inference-server</a>.</p>
			<p>We saw how easy it is to serve our agent using a production-grade serving backend. We can easily run the Docker container on a remote/cloud server or VPS to deploy this service out on the web.</p>
			<p>Finally, once the service <a id="_idIndexMarker1097"/>was launched, we saw how a client can avail of the service by sending action requests with appropriate input/observation data from a test environment. </p>
			<p>That's it for this recipe! Let's move on to the final recipe of this chapter to wrap things up.</p>
			<h1 id="_idParaDest-232"><a id="_idTextAnchor267"/>Packaging Deep RL agents for cross-platform deployment</h1>
			<p>Although the <a id="_idIndexMarker1098"/>grandest success of Deep RL <a id="_idIndexMarker1099"/>has been in the domain of game playing (Atari, Chess, Go, Shogi) and simulated robotics, real-world applications are starting to emerge where Deep RL agents show a lot of promise and value. Deploying Deep RL agents to a variety of physical form factors such as embedded controllers, computers, autonomous cars, drones, and other robots, and so on is expected soon. Differences in hardware processors (CPU, GPU, TPU, FPGA, ASIC), operating systems (Linux, Windows, OSX, Android), architectures (x86, ARM), and form factors (server, desktop, mobile, IoT, embedded systems, and so on) make the deployment process challenging. This recipe includes guidelines around how you can leverage the TensorFlow 2.x framework's ecosystem of libraries, tools, and utilities to package Deep RL agent models suitable for deployments to the web, mobile, IoT, embedded systems, robots, and desktop platforms.</p>
			<p>This recipe provides a complete script to build, train, and package a Deep RL agent in multiple formats that can be used to deploy/serve using TensorFlow Serving, TensorFlow Hub, TensorFlow.js, TensorFlow Lite, NVIDIA Triton, ONNX, ONNX.js, Clipper, and most other serving frameworks built for deep learning models.</p>
			<p>Let's get started!</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor268"/>Getting ready</h2>
			<p>To complete this recipe, you will first need to activate the <strong class="source-inline">tf2rl-cookbook</strong> Python/conda virtual environment. Make sure to update the environment to match the latest conda environment specification file (<strong class="source-inline">tfrl-cookbook.yml</strong>) in the cookbook's code repo. If the <a id="_idIndexMarker1100"/>following imports <a id="_idIndexMarker1101"/>work without issues, you are ready to get started:</p>
			<p class="source-code">import argparse</p>
			<p class="source-code">import os</p>
			<p class="source-code">import sys</p>
			<p class="source-code">from datetime import datetime</p>
			<p class="source-code">import gym</p>
			<p class="source-code">import keras2onnx</p>
			<p class="source-code">import numpy as np</p>
			<p class="source-code">import procgen  # Used to register procgen envs with Gym registry</p>
			<p class="source-code">import tensorflow as tf</p>
			<p class="source-code">import tensorflowjs as tfjs</p>
			<p class="source-code">from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D</p>
			<p>Now, let's begin!</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor269"/>How to do it...</h2>
			<p>In the following text, we will save space by focusing on the new and important pieces that are unique to this recipe. We will focus on the various model saving and export functionalities and keep the Actor, Critic, and Agent model definitions out of the following steps to save space. Please refer to the book's code repository for a complete implementation. We will start implementing the model's save/export methods one after the other for the Actor first and then repeat the steps for the Critic in the subsequent steps, and finally complete the agent implementation.</p>
			<p>Let's get started:</p>
			<ol>
				<li value="1">First, it is <a id="_idIndexMarker1102"/>important to set TensorFlow <a id="_idIndexMarker1103"/>Keras's backend to use <strong class="source-inline">float32</strong> as the default representation for float values instead of the default <strong class="source-inline">float64</strong>:<p class="source-code">tf.keras.backend.set_floatx("float32")</p></li>
				<li>We will begin with the various save/export method implementations for the Actor in the following few steps. Let's implement the <strong class="source-inline">save</strong> method to save and export the Actor model to TensorFlow's <strong class="source-inline">SavedModel</strong> format:<p class="source-code">    def save(self, model_dir: str, version: int = 1):</p><p class="source-code">        actor_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), \</p><p class="source-code">            "model.savedmodel"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(actor_model_save_dir, \</p><p class="source-code">                        save_format="tf")</p><p class="source-code">        print(f"Actor model saved at:\</p><p class="source-code">                {actor_model_save_dir}")</p></li>
				<li>Next, we will <a id="_idIndexMarker1104"/>add the <strong class="source-inline">save_tflite</strong> method <a id="_idIndexMarker1105"/>to the <strong class="source-inline">Actor</strong> class to save and export the Actor model in TFLite format:<p class="source-code">    def save_tflite(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Actor model in TensorFlow Lite </p><p class="source-code">        format"""</p><p class="source-code">        actor_model_save_dir = os.path.join(model_dir,\</p><p class="source-code">                                   "actor", str(version))</p><p class="source-code">        model_converter = \</p><p class="source-code">            tf.lite.TFLiteConverter.from_keras_model(</p><p class="source-code">                                             self.model)</p><p class="source-code">        # Convert model to TFLite Flatbuffer</p><p class="source-code">        tflite_model = model_converter.convert()</p><p class="source-code">        # Save the model to disk/persistent-storage</p><p class="source-code">        if not os.path.exists(actor_model_save_dir):</p><p class="source-code">            os.makedirs(actor_model_save_dir)</p><p class="source-code">        actor_model_file_name = \</p><p class="source-code">            os.path.join(actor_model_save_dir, </p><p class="source-code">                         "model.tflite")</p><p class="source-code">        with open(actor_model_file_name, "wb") as \</p><p class="source-code">        model_file:</p><p class="source-code">            model_file.write(tflite_model)</p><p class="source-code">        print(f"Actor model saved in TFLite format at:\</p><p class="source-code">                {actor_model_file_name}")</p></li>
				<li>Now, let's implement the <strong class="source-inline">save_h5</strong> method and add it to the <strong class="source-inline">Actor</strong> class to save and export the Actor model in HDF5 format:<p class="source-code">    def save_h5(self, model_dir: str, version: int = 1):</p><p class="source-code">        actor_model_save_path = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), "model.h5"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(actor_model_save_path, \</p><p class="source-code">                        save_format="h5")</p><p class="source-code">        print(f"Actor model saved at:\</p><p class="source-code">               {actor_model_save_path}")</p></li>
				<li>Next, we will add the <strong class="source-inline">save_tfjs</strong> method to <a id="_idIndexMarker1106"/>the <strong class="source-inline">Actor</strong> class to save and export the Actor <a id="_idIndexMarker1107"/>model in TF.js format:<p class="source-code">    def save_tfjs(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Actor model in TensorFlow.js</p><p class="source-code">        supported format"""</p><p class="source-code">        actor_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), \</p><p class="source-code">            "model.tfjs"</p><p class="source-code">        )</p><p class="source-code">        tfjs.converters.save_keras_model(self.model, \</p><p class="source-code">                                    actor_model_save_dir)</p><p class="source-code">        print(f"Actor model saved in TF.js format at:\</p><p class="source-code">                {actor_model_save_dir}")</p></li>
				<li>As the final variant, we will add the <strong class="source-inline">save_onnx</strong> method to the <strong class="source-inline">Actor</strong> class to save and export the Actor model in ONNX format:<p class="source-code">    def save_onnx(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Actor model in ONNX format"""</p><p class="source-code">        actor_model_save_path = os.path.join(</p><p class="source-code">            model_dir, "actor", str(version), \</p><p class="source-code">            "model.onnx"</p><p class="source-code">        )</p><p class="source-code">        onnx_model = keras2onnx.convert_keras(</p><p class="source-code">                             self.model, self.model.name)</p><p class="source-code">        keras2onnx.save_model(onnx_model, \</p><p class="source-code">                              actor_model_save_path)</p><p class="source-code">        print(f"Actor model saved in ONNX format at:\</p><p class="source-code">                {actor_model_save_path}")</p></li>
				<li>That completes the save/export methods for the <strong class="source-inline">Actor</strong> class! In a similar way, let's add <a id="_idIndexMarker1108"/>the <strong class="source-inline">save</strong> methods to the <strong class="source-inline">Critic</strong> class for completeness. Starting with the <strong class="source-inline">save</strong> method, and then the <a id="_idIndexMarker1109"/>other methods in the later steps:<p class="source-code">    def save(self, model_dir: str, version: int = 1):</p><p class="source-code">        critic_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), \</p><p class="source-code">            "model.savedmodel"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(critic_model_save_dir, \</p><p class="source-code">                        save_format="tf")</p><p class="source-code">        print(f"Critic model saved at:\</p><p class="source-code">                {critic_model_save_dir}")</p></li>
				<li>The next <a id="_idIndexMarker1110"/>method in the sequence is <a id="_idIndexMarker1111"/>the <strong class="source-inline">save_tflite</strong> method to save and export the Critic model in TFLite format:<p class="source-code">    def save_tflite(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Critic model in TensorFlow Lite </p><p class="source-code">        format"""</p><p class="source-code">        critic_model_save_dir = os.path.join(model_dir,\</p><p class="source-code">                                  "critic", str(version))</p><p class="source-code">        model_converter = \</p><p class="source-code">            tf.lite.TFLiteConverter.from_keras_model(</p><p class="source-code">                                              self.model)</p><p class="source-code">        # Convert model to TFLite Flatbuffer</p><p class="source-code">        tflite_model = model_converter.convert()</p><p class="source-code">        # Save the model to disk/persistent-storage</p><p class="source-code">        if not os.path.exists(critic_model_save_dir):</p><p class="source-code">            os.makedirs(critic_model_save_dir)</p><p class="source-code">        critic_model_file_name = \</p><p class="source-code">            os.path.join(critic_model_save_dir, </p><p class="source-code">                         "model.tflite")</p><p class="source-code">        with open(critic_model_file_name, "wb") as \</p><p class="source-code">        model_file:</p><p class="source-code">            model_file.write(tflite_model)</p><p class="source-code">        print(f"Critic model saved in TFLite format at:\</p><p class="source-code">                {critic_model_file_name}")</p></li>
				<li>Let's <a id="_idIndexMarker1112"/>implement the <strong class="source-inline">save_h5</strong> add <a id="_idIndexMarker1113"/>to the <strong class="source-inline">Critic</strong> class to save and export the Critic model in HDF5 format:<p class="source-code">    def save_h5(self, model_dir: str, version: int = 1):</p><p class="source-code">        critic_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), "model.h5"</p><p class="source-code">        )</p><p class="source-code">        self.model.save(critic_model_save_dir, \</p><p class="source-code">                        save_format="h5")</p><p class="source-code">        print(f"Critic model saved at:\</p><p class="source-code">                {critic_model_save_dir}")</p></li>
				<li>Next, we will add the <strong class="source-inline">save_tfjs</strong> method to the <strong class="source-inline">Critic</strong> class to save and export the Critic model in TF.js format:<p class="source-code">    def save_tfjs(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Critic model in TensorFlow.js </p><p class="source-code">        supported format"""</p><p class="source-code">        critic_model_save_dir = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), \</p><p class="source-code">            "model.tfjs"</p><p class="source-code">        )</p><p class="source-code">        tfjs.converters.save_keras_model(self.model,\</p><p class="source-code">                                   critic_model_save_dir)</p><p class="source-code">        print(f"Critic model saved TF.js format at:\</p><p class="source-code">                {critic_model_save_dir}")</p></li>
				<li>The final variant is the <strong class="source-inline">save_onnx</strong> method, which saves and exports the Critic model in ONNX format:<p class="source-code">    def save_onnx(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        """Save/Export Critic model in ONNX format"""</p><p class="source-code">        critic_model_save_path = os.path.join(</p><p class="source-code">            model_dir, "critic", str(version), \</p><p class="source-code">            "model.onnx"</p><p class="source-code">        )</p><p class="source-code">        onnx_model = keras2onnx.convert_keras(self.model,</p><p class="source-code">                                         self.model.name)</p><p class="source-code">        keras2onnx.save_model(onnx_model, \</p><p class="source-code">                              critic_model_save_path)</p><p class="source-code">        print(f"Critic model saved in ONNX format at:\</p><p class="source-code">                {critic_model_save_path}")</p></li>
				<li>That completes the save/export method additions to our agent's <strong class="source-inline">Critic</strong> class. We now can add the <a id="_idIndexMarker1114"/>corresponding <strong class="source-inline">save</strong> methods to the <strong class="source-inline">Agent</strong> class that will simply <a id="_idIndexMarker1115"/>call the corresponding <strong class="source-inline">save</strong> methods on the Actor and Critic objects. Let's complete the implementation in the following two steps:<p class="source-code">    def save(self, model_dir: str, version: int = 1):</p><p class="source-code">        self.actor.save(model_dir, version)</p><p class="source-code">        self.critic.save(model_dir, version)</p><p class="source-code">    def save_tflite(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        # Make sure `toco_from_protos binary` is on  </p><p class="source-code">        # system's PATH to avoid TFLite ConverterError</p><p class="source-code">        toco_bin_dir = os.path.dirname(sys.executable)</p><p class="source-code">        if not toco_bin_dir in os.environ["PATH"]:</p><p class="source-code">            os.environ["PATH"] += os.pathsep + \</p><p class="source-code">                                  toco_bin_dir</p><p class="source-code">        print(f"Saving Agent model (TFLite) to:\</p><p class="source-code">                {model_dir}\n")</p><p class="source-code">        self.actor.save_tflite(model_dir, version)</p><p class="source-code">        self.critic.save_tflite(model_dir, version)</p></li>
				<li>The <a id="_idIndexMarker1116"/>remaining methods on the <strong class="source-inline">PPOAgent</strong> class <a id="_idIndexMarker1117"/>are straightforward as well:<p class="source-code">    def save_h5(self, model_dir: str, version: int = 1):</p><p class="source-code">        print(f"Saving Agent model (HDF5) to:\</p><p class="source-code">                {model_dir}\n")</p><p class="source-code">        self.actor.save_h5(model_dir, version)</p><p class="source-code">        self.critic.save_h5(model_dir, version)</p><p class="source-code">    def save_tfjs(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        print(f"Saving Agent model (TF.js) to:\</p><p class="source-code">                {model_dir}\n")</p><p class="source-code">        self.actor.save_tfjs(model_dir, version)</p><p class="source-code">        self.critic.save_tfjs(model_dir, version)</p><p class="source-code">    def save_onnx(self, model_dir: str, version: \</p><p class="source-code">    int = 1):</p><p class="source-code">        print(f"Saving Agent model (ONNX) to:\</p><p class="source-code">                {model_dir}\n")</p><p class="source-code">        self.actor.save_onnx(model_dir, version)</p><p class="source-code">        self.critic.save_onnx(model_dir, version)</p></li>
				<li>That <a id="_idIndexMarker1118"/>completes our <a id="_idIndexMarker1119"/>implementation for the <strong class="source-inline">Agent</strong> class! We are now ready to run the script to build, train, and export the Deep RL agent model! Let's implement the <strong class="source-inline">main</strong> function and call all the <strong class="source-inline">save</strong> methods that we have implemented in the previous steps:<p class="source-code">if __name__ == "__main__":</p><p class="source-code">    env_name = args.env</p><p class="source-code">    env = gym.make(env_name)</p><p class="source-code">    agent = PPOAgent(env)</p><p class="source-code">    agent.train(max_episodes=1)</p><p class="source-code">    # Model saving</p><p class="source-code">    model_dir = "trained_models"</p><p class="source-code">    agent_name = f"PPO_{env_name}"</p><p class="source-code">    agent_version = 1</p><p class="source-code">    agent_model_path = os.path.join(model_dir, \</p><p class="source-code">                                    agent_name)</p><p class="source-code">    agent.save_onnx(agent_model_path, agent_version)</p><p class="source-code">    agent.save_h5(agent_model_path, agent_version)</p><p class="source-code">    agent.save_tfjs(agent_model_path, agent_version)</p><p class="source-code">    agent.save_tflite(agent_model_path, agent_version)</p></li>
				<li>It's time to <a id="_idIndexMarker1120"/>execute our script! Please <a id="_idIndexMarker1121"/>pull the latest copy of the recipe from the book's code repository and just run it! By default, the script will train the agent for one episode, save the agent models, and export the model in various formats ready for deployment. Once the script finishes, you will see the exported models with the directory structure and contents similar to the one shown in the following figure:</li>
			</ol>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B15074_09_018.jpg" alt="Figure 9.18 – PPO Deep RL agent model exported to various formats for deployment "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.18 – PPO Deep RL agent model exported to various formats for deployment</p>
			<p>That completes our final recipe for this chapter! Let's quickly revisit some of the key items we covered in this recipe in the following section.</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor270"/>How it works...</h2>
			<p>We first set <a id="_idIndexMarker1122"/>TensorFlow Keras's backend to use <strong class="source-inline">float32</strong> as the <a id="_idIndexMarker1123"/>default representation for float values. This is because, otherwise, TensorFlow would use the default <strong class="source-inline">float64</strong> representation, which is not supported by TensorFlow Lite (for performance reasons) as it is targeted towards running on embedded and mobile devices.</p>
			<p>In this recipe, we used a PPO agent with Actor and Critic networks that expect image observations and produce actions in discrete space, designed for RL environments such as the procedurally generated procgen environment from OpenAI. You can swap the agent code with the PPO implementations from one of the earlier chapters that use different state/observation spaces and action spaces depending on your need/application. You could also replace the agent with a different agent algorithm altogether.</p>
			<p>We discussed several approaches to save and export your agent models, leveraging the whole suite of tools and libraries offered by the TensorFlow 2.x ecosystem. A summary of the various export options that we implemented as part of this recipe is provided in the following figure:</p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/B15074_09_019.jpg" alt="Figure 9.19 – Summary of various RL agent model export options discussed in this recipe "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.19 – Summary of various RL agent model export options discussed in this recipe</p>
			<p>That concludes this recipe, the <a id="_idIndexMarker1124"/>chapter, and – more dramatically – the book! We covered a lot of different <a id="_idIndexMarker1125"/>topics in this cookbook to leverage the TensorFlow 2.x framework and the ecosystem of tools and libraries built around it to build RL building block<a id="_idTextAnchor271"/>s, environments, algorithms, agents, and applications. I hope you had an exciting journey with the book.</p>
			<p>I can't wait to see what you build/cook with the recipes we discussed in the book. I will look forward to hearing about your journey with the book on the discussion page at <a href="https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions">https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions</a>.</p>
			<p>Looking forward to getting in touch with you on the discussion/issues page. All the best for your future endeavors! </p>
		</div>
</body></html>