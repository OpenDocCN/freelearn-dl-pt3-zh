<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Deep Feed-forward Neural Networks - Implementing Digit Classification</h1>
                </header>
            
            <article>
                
<p class="calibre2">A <strong class="calibre13">feed-forward neural network</strong> <span class="calibre10">(<strong class="calibre13">FNN</strong>)</span> is a special type of neural network wherein links/connections between neurons do not form a cycle. As such, it is different from other architectures in a neural network that we will get to study later on in this book (recurrent-type neural networks). The FNN is a widely used architecture and it was the first and simplest type of neural network.</p>
<p class="calibre2">In this chapter, we will go through the architecture of a typical ;FNN, and we will be using the TensorFlow library for this. After covering these concepts, we will give a practical example of digit classification. The question of this example is, <em class="calibre19">Given a set of images that contain handwritten digits, how can you classify these images into 10 different classes (0-9)</em>?</p>
<p class="calibre2">The following topics will be covered in this chapter:</p>
<ul class="calibre7">
<li class="calibre8">Hidden units and architecture design</li>
<li class="calibre8">MNIST dataset analysis</li>
<li class="calibre8">Digit classification - model building and training</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hidden units and architecture design</h1>
                </header>
            
            <article>
                
<p class="calibre2">In the next section, we'll recap artificial neural networks; they can do a good job in classification tasks such as classifying handwritten digits.</p>
<p class="calibre2">Suppose we have the network shown in <em class="calibre19">Figure 1</em>:</p>
<div class="CDPAlignCenter"><img src="assets/fff2d218-3570-4cd7-8ed1-e85114799780.png" class="calibre79"/></div>
<div class="CDPAlignCenter1">Figure 1: Simple FNN with one hidden layer</div>
<p class="calibre2">As mentioned earlier, the leftmost layer in this network is called the <strong class="calibre13">input layer</strong>, and the neurons within the layer are called <strong class="calibre13">input neurons</strong>. The rightmost or output layer contains the output neurons, or, as in this case, a single output neuron. The middle layer is called a <strong class="calibre13">hidden layer</strong>, since the neurons in this layer are neither inputs nor outputs. The term hidden perhaps sounds a little mysterious—the first time I heard the term, I thought it must have some deep philosophical or mathematical significance<span class="calibre10">—</span>but it really means <em class="calibre19">not an input and not an output</em>. It means nothing else. The preceding network has just a single hidden layer, but some networks have multiple hidden layers. For example, the following four-layer network has two hidden layers:</p>
<div class="CDPAlignCenter"><img src="assets/01c99930-1ba8-40ec-ac97-bd50e301540a.png" class="calibre80"/></div>
<div class="CDPAlignCenter1">Figure 2: Artificial neural network with more hidden layers</div>
<div class="title-page-name">
<p class="calibre2">The architecture in which the input, hidden, and output layers are organized is very straightforward. For example, let's go through a practical example to see whether a specific handwritten image has the digit 9 in it or not.</p>
<p class="calibre2">So first, we will feed the pixels of the input image to the input layer; for example, in the MNIST dataset, we have monochrome images. Each one of them is 28 by 28, so we need to have 28 × 28 = 784 neurons in the input layer to receive this input image.</p>
<p class="calibre2">In the output layer, we will need only 1 neuron, which produces a probability (or score) of whether this image has the digit 9 in it or not. For example, an output value of more than 0.5 means that this image has the digit 9, and if it's less than 0.5, then it means that the input image doesn't have the digit 9 in it.</p>
<p class="calibre2">So these types of networks, where the output from one layer is fed as an input to the next layer, are called FNNs. This kind of sequentiality in the layers means that there are no loops in it.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">MNIST dataset analysis</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this section, we are going to get our hands dirty by implementing a classifier for handwritten images. This kind of implementation could be considered as the <em class="calibre19">Hello world!</em> of neural networks.</p>
<p class="calibre2">MNIST is a widely used dataset for benchmarking machine learning techniques. The dataset contains a set of handwritten digits like the ones shown here:</p>
<div class="CDPAlignCenter"><img src="assets/080b85fa-6251-42d9-b069-a96ac276eefe.png" class="calibre81"/></div>
<div class="CDPAlignCenter1">Figure 3: Sample digits from the MNIST dataset</div>
<div class="title-page-name">
<p class="calibre2">So, the dataset includes handwritten images and their corresponding labels as well.</p>
<p class="calibre2">In this section, we are going to train a basic model on these images and the goal will be to tell which digit is handwritten in the input images.</p>
</div>
<div class="title-page-name">
<p class="calibre2">Also, you'll find out that we will be able to accomplish this classification task using very few lines of code, but the idea behind this implementation is to understand the basic bits and pieces for building a neural network solution. Moreover, we are going to cover the main concepts of neural networking in this implementation.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The MNIST data</h1>
                </header>
            
            <article>
                
<p class="calibre2">The MNIST data is hosted on Yann LeCun's website (<a href="http://yann.lecun.com/exdb/mnist/" class="calibre11">http://yann.lecun.com/exdb/mnist/</a>). Fortunately, TensorFlow provides some helper functions to download the dataset, so let's start off by downloading the dataset using the following two lines of code:</p>
<pre class="calibre21"><span>from </span>tensorflow.examples.tutorials.mnist <span>import </span>input_data<br class="title-page-name"/>mnist_dataset = input_data.read_data_sets(<span>"MNIST_data/"</span>, <span>one_hot</span>=<span>True</span>)</pre>
<p class="calibre2">The MNIST data is split into three parts: 55,000 data points of training data (<kbd class="calibre12">mnist.train</kbd>), 10,000 points of test data (<kbd class="calibre12">mnist.test</kbd>), and 5,000 points of validation data (<kbd class="calibre12">mnist.validation</kbd>). This split is very important; it's essential in machine learning that we have separate data that we don't learn from so that we can make sure that what we've learned actually generalizes!</p>
<p class="calibre2">As mentioned earlier, every MNIST sample has two parts: an image of a handwritten digit and its corresponding label. Both the training set and test set contain images and their corresponding labels. For example, the training images are <kbd class="calibre12">mnist.train.images</kbd> and the training labels are <kbd class="calibre12">mnist.train.labels</kbd>.</p>
<p class="calibre2">Each image is 28 pixels by 28 pixels. We can interpret this as a big array of numbers:</p>
<div class="CDPAlignCenter"><img src="assets/67eb24ef-9a39-4345-b9ec-c1e6c2b020a8.png" class="calibre82"/></div>
<div class="CDPAlignCenter1">Figure 4: MNIST digit in matrix representation (intensity values)</div>
<div class="title-page-name">
<p class="calibre2">In order to feed this matrix of pixel values to the input layer of the neural network, we need to flatten this matrix into a vector of 784 values. So, the final shape of the dataset will be a bunch of 784-dimensional vector space.</p>
<p class="calibre2">The result is that <kbd class="calibre12">mnist.train.images</kbd> is a tensor with a shape of <kbd class="calibre12">(55000, 784)</kbd>. The first dimension is an index of the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1 for a particular pixel in a particular image:</p>
</div>
<div class="CDPAlignCenter"><img src="assets/b211b0d9-6625-41f0-b873-a2ddab250156.png" class="calibre83"/></div>
<div class="CDPAlignCenter1">Figure 5: MNIST data analysis</div>
<div class="title-page-name">
<p class="calibre2">As we mentioned previously, each image in the dataset has its corresponding label that ranges from 0 to 9.</p>
<p class="calibre2">For the purposes of this implementation, we're going to encode our labels as one-hot vectors. A one-hot vector is a vector of all zeros except the index of the digit that this vector represents. For example, 3 would be [0,0,0,1,0,0,0,0,0,0]. Consequently, <kbd class="calibre12">mnist.train.labels</kbd> is a <kbd class="calibre12">(55000, 10)</kbd> array of floats:</p>
</div>
<div class="CDPAlignCenter"><img src="assets/5e497ee6-2d08-4004-a666-f1d242eb2060.png" class="calibre84"/></div>
<div class="CDPAlignCenter1">Figure 6: MNIST data analysis</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Digit classification – model building and training</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<p class="calibre2">Now, let's go ahead and build our model. So, we have 10 classes in our dataset 0-9 and the goal is to classify any input image into one of these classes. Instead of giving a hard decision about the input image by saying only which class it could belong to, we are going to produce a vector of 10 possible values (because we have 10 classes). It'll represent the probabilities of each digit from 0-9 being the correct class for the input image.</p>
<p class="calibre2">For example, suppose we feed the model with a specific image. The model might be 70% sure that this image is 9, 10% sure that this image is 8, and so on. So, we are going to use the softmax regression here, which will produce values between 0 and 1.</p>
<p class="calibre2">A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities.</p>
<p class="calibre2">To tally up the evidence that a given image is in a particular class, we do a weighted sum of the pixel intensities. The weight is negative if that pixel having a high intensity is evidence against the image being in that class, and positive if it is evidence in favor.</p>
<p class="calibre2"><em class="calibre19">Figure 7</em> shows the weights one model learned for each of these classes. Red represents negative weights, while blue represents positive weights:</p>
</div>
<div class="CDPAlignCenter"><img src="assets/650f626c-81a7-4e1c-a0c2-a756f5780c21.png" class="calibre85"/></div>
<div class="CDPAlignCenter1">Figure 7: Weights one model learned for each of MNIST classes</div>
<p class="calibre2">We also add some extra evidence called a <strong class="calibre13">bias</strong>. Basically, we want to be able to say that some things are more likely independent of the input. The result is that the evidence for a class <em class="calibre19">i</em>, given an input, <em class="calibre19">x</em>, is:</p>
<div class="CDPAlignCenter"><img class="fm-editor-equation18" src="assets/3a99b106-2fd3-404f-bb8f-b2c894db0e26.png"/></div>
<p class="innercell"><span class="calibre10">Where:</span></p>
<ul class="calibre7">
<li class="calibre8"><em class="calibre25">W<sub class="calibre28">i</sub></em> is the weights</li>
<li class="calibre8"><em class="calibre25">b<sub class="calibre28">i</sub></em> is the bias for class <em class="calibre25">i</em></li>
<li class="calibre8"><em class="calibre25">j</em> is an index for summing over the pixels in our input image <em class="calibre25">x</em>.</li>
</ul>
<p class="calibre2">We then convert the evidence tallies into our predicted probabilities <em class="calibre19">y</em> using the softmax function:</p>
<p class="CDPAlignCenter3"><em class="calibre19">y = softmax(evidence)</em></p>
<p class="calibre2">Here, softmax is serving as an activation or link function, shaping the output of our linear function into the form we want, in this case, a probability distribution over 10 cases (because we have 10 possible classes from 0-9). You can think of it as converting tallies of evidence into probabilities of our input being in each class. It's defined as:</p>
<p class="CDPAlignCenter3"><em class="calibre19">softmax(evidence) = normalize(exp(evidence))</em></p>
<p class="calibre2">If you expand that equation, you get:</p>
<div class="CDPAlignCenter"><img class="fm-editor-equation19" src="assets/0a32b978-b54b-411e-b8fb-cf0132cbd402.png"/></div>
<p class="calibre2">But it's often more helpful to think of softmax the first way: exponentiating its inputs and then normalizing them. Exponentiation means that one more unit of evidence increases the weight given to any hypothesis <span class="calibre10">exponentially</span>. And conversely, having one less unit of evidence means that a hypothesis gets a fraction of its earlier weight. No hypothesis ever has zero or negative weight. Softmax then normalizes these weights so that they add up to one, forming a valid probability distribution.</p>
<p class="calibre2"><br class="calibre20"/>
You can picture our softmax regression as looking something like the following, although with a lot more <em class="calibre19">x</em>'<em class="calibre19"><span class="calibre10">s</span></em>. For each output, we compute a weighted sum of the <em class="calibre19">x</em>'s, add a bias, and then apply softmax:</p>
<div class="CDPAlignCenter"><img src="assets/66464f07-4b6d-4ba2-b7a6-28833847370b.png" class="calibre86"/></div>
<div class="CDPAlignCenter1">Figure 8: Visualization of softmax regression</div>
<div class="title-page-name">
<p class="calibre2">If we write that out as equations, we get:</p>
</div>
<div class="CDPAlignCenter"><img src="assets/88eb5cd6-723b-4cef-807e-c578cc50020c.png" class="calibre87"/></div>
<div class="CDPAlignCenter1">Figure 9: Equation representation of the softmax regression</div>
<div class="title-page-name">
<p class="calibre2">We can use vector notation for this procedure. This means that we'll be turning it into a matrix multiplication and vector addition. This is very helpful for computational efficiency and readability:</p>
</div>
<div class="CDPAlignCenter"><img src="assets/cf06fcbb-5b11-4a96-a7f2-d6cd04e85b5f.png" class="calibre88"/></div>
<div class="CDPAlignCenter1">Figure 10: Vectorized representation of the softmax regression equation</div>
<p class="calibre2">More compactly, we can just write:</p>
<p class="CDPAlignCenter3"><em class="calibre19">y = softmax(W<sub class="calibre28">x</sub> + b)</em></p>
<p class="calibre2">Now, let's turn that into something that TensorFlow can use.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data analysis</h1>
                </header>
            
            <article>
                
<p class="calibre2">So, let's go ahead and start implementing our classifier. Let's start off by importing the required packages for this implementation:</p>
<pre class="calibre21"><span>import </span>tensorflow <span>as </span>tf<br class="title-page-name"/><span>import </span>matplotlib.pyplot <span>as </span>plt<br class="title-page-name"/><span>import </span>numpy <span>as </span>np<br class="title-page-name"/><span>import </span>random <span>as </span>ran</pre>
<p class="calibre2">Next up, we are going to define some helper functions to make us able to subset from the original dataset that we have downloaded:</p>
<pre class="calibre21">#Define some helper functions <br class="title-page-name"/># to assign the size of training and test data we will take from MNIST dataset<br class="title-page-name"/>def train_size(size):<br class="title-page-name"/>    print ('Total Training Images in Dataset = ' + str(mnist_dataset.train.images.shape))<br class="title-page-name"/>    print ('############################################')<br class="title-page-name"/>    input_values_train = mnist_dataset.train.images[:size,:]<br class="title-page-name"/>    print ('input_values_train Samples Loaded = ' + str(input_values_train.shape))<br class="title-page-name"/>    target_values_train = mnist_dataset.train.labels[:size,:]<br class="title-page-name"/>    print ('target_values_train Samples Loaded = ' + str(target_values_train.shape))<br class="title-page-name"/>    return input_values_train, target_values_train<br class="title-page-name"/><br class="title-page-name"/>def test_size(size):<br class="title-page-name"/>    print ('Total Test Samples in MNIST Dataset = ' + str(mnist_dataset.test.images.shape))<br class="title-page-name"/>    print ('############################################')<br class="title-page-name"/>    input_values_test = mnist_dataset.test.images[:size,:]<br class="title-page-name"/>    print ('input_values_test Samples Loaded = ' + str(input_values_test.shape))<br class="title-page-name"/>    target_values_test = mnist_dataset.test.labels[:size,:]<br class="title-page-name"/>    print ('target_values_test Samples Loaded = ' + str(target_values_test.shape))<br class="title-page-name"/>    return input_values_test, target_values_test</pre>
<p class="calibre2">Also, we're going to define two helper functions for displaying specific digits from the dataset or even display a flattened version of a subset of images:</p>
<pre class="calibre21">#Define a couple of helper functions for digit images visualization<br class="title-page-name"/>def visualize_digit(ind):<br class="title-page-name"/>    print(target_values_train[ind])<br class="title-page-name"/>    target = target_values_train[ind].argmax(axis=0)<br class="title-page-name"/>    true_image = input_values_train[ind].reshape([28,28])<br class="title-page-name"/>    plt.title('Sample: %d Label: %d' % (ind, target))<br class="title-page-name"/>    plt.imshow(true_image, cmap=plt.get_cmap('gray_r'))<br class="title-page-name"/>    plt.show()<br class="title-page-name"/><br class="title-page-name"/>def visualize_mult_imgs_flat(start, stop):<br class="title-page-name"/>    imgs = input_values_train[start].reshape([1,784])<br class="title-page-name"/>    for i in range(start+1,stop):<br class="title-page-name"/>        imgs = np.concatenate((imgs, input_values_train[i].reshape([1,784])))<br class="title-page-name"/>    plt.imshow(imgs, cmap=plt.get_cmap('gray_r'))<br class="title-page-name"/>    plt.show()</pre>
<p class="calibre2">Now, let's get down to business and start playing around with the dataset. So we are going to define the training and testing examples that we would like to load from the original dataset.</p>
<p class="calibre2">Now, we'll get down to the business of building and training our model. First, we define variables with how many training and test examples we would like to load. For now, we will load all the data, but we will change this value later on to save resources:</p>
<div class="title-page-name">
<pre class="calibre21">input_values_train, target_values_train = train_size(55000)<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>Total Training Images in Dataset = (55000, 784)
############################################
input_values_train Samples Loaded = (55000, 784)
target_values_train Samples Loaded = (55000, 10)</pre></div>
<p class="calibre2">So now, we have a training set of 55,000 samples of handwritten digits, and each sample is 28 by 28 pixel images flattened to be a 784-dimensional vector. We also have their corresponding labels in a one-hot encoding format.</p>
<p class="calibre2">The <kbd class="calibre12">target_values_train</kbd> data are the associated labels for all the <kbd class="calibre12">input_values_train</kbd> samples. In the following example, the array represents a 7 in one-hot encoding format:</p>
<div class="CDPAlignCenter2"><img src="assets/750c677e-5094-4b5b-b780-f544ae8a31ff.png" class="calibre31"/></div>
<div class="CDPAlignCenter1">Figure 11: One hot encoding for the digit 7</div>
<p class="calibre2">So let's visualize a random image from the dataset and see how it looks like, so we are going to use our preceding helper function to display a random digit from the dataset:</p>
<pre class="calibre21">visualize_digit(ran.randint(0, input_values_train.shape[0]))<br class="title-page-name"/><br class="title-page-name"/>Output:</pre>
<div class="CDPAlignCenter"><img src="assets/6f0caec6-5918-4765-ba6a-f783062558bb.png" class="calibre89"/></div>
<div class="CDPAlignCenter1">Figure 12: Output digit of the display_digit method</div>
<div class="title-page-name">
<p class="calibre2">We can also visualize a bunch of flattened images using the helper function defined before. Each value in the flattened vector represents a pixel intensity, so visualizing the pixels will look like this:</p>
<pre class="calibre21">visualize_mult_imgs_flat(0,400)</pre></div>
<div class="CDPAlignCenter4"><img src="assets/e51ef11a-ea66-4d8c-9e75-ec0806f9085b.png" class="calibre90"/></div>
<div class="CDPAlignCenter1">Figure 13: First 400 training examples</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building the model</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<p class="calibre2">So far, we haven't started to build our computational graph for this classifier. Let's start off by creating the session variable that will be responsible for executing the computational graph we are going to build:</p>
</div>
<pre class="calibre21">sess = tf.Session()</pre>
<p class="calibre2">Next up, we are going to define our model's placeholders, which will be used to feed data into the computational graph:</p>
<pre class="calibre21">input_values = tf.placeholder(tf.float32, shape=[None, 784]</pre>
<p class="calibre2">When we specify <kbd class="calibre12">None</kbd> in our placeholder's first dimension, it means the placeholder can be fed as many examples as we like. In this case, our placeholder can be fed any number of examples, where each example has a <kbd class="calibre12">784</kbd> value.</p>
<p class="calibre2">Now, we need to define another placeholder for feeding the image labels. Also we'll be using this placeholder later on to compare the model predictions with the actual labels of the images:</p>
<pre class="calibre21">output_values = tf.placeholder(tf.float32, shape=[None, 10])</pre>
<p class="calibre2">Next, we will define the <kbd class="calibre12">weights</kbd> and <kbd class="calibre12">biases</kbd>. These two variables will be the trainable parameters of our network and they will be the only two variables needed to make predictions on unseen data:</p>
<pre class="calibre21">weights = tf.Variable(tf.zeros([784,10]))<br class="title-page-name"/>biases = tf.Variable(tf.zeros([10]))</pre>
<p class="calibre2">I like to think of these <kbd class="calibre12">weights</kbd> as 10 cheat sheets for each number. This is similar to how a teacher uses a cheat sheet to grade a multiple choice exam.</p>
<p class="calibre2">We will now define our softmax regression, which is our classifier function. This particular classifier is called <strong class="calibre13">multinomial logistic regression</strong>, and we make the prediction by multiplying the flattened version of the digit by the weight and then adding the bias:</p>
<pre class="calibre21">softmax_layer = tf.nn.softmax(tf.matmul(input_values,weights) + biases)</pre>
<p class="calibre2">First, let's ignore the softmax and look at what's inside the softmax function. <kbd class="calibre12">matmul</kbd> is the TensorFlow function for multiplying matrices. If you know matrix multiplication (<a href="https://en.wikipedia.org/wiki/Matrix_multiplication" target="_blank" class="calibre11">https://en.wikipedia.org/wiki/Matrix_multiplication</a>), you'll understand that this computes properly and that:</p>
<div class="CDPAlignCenter"><img class="fm-editor-equation20" src="assets/872f2c41-24e3-4684-a856-8ec72f4f0aa7.png"/></div>
<p class="calibre2">Will result in a number of training examples fed (<strong class="calibre13">m</strong>) × number of classes (<strong class="calibre13">n</strong>) matrix:</p>
<div class="CDPAlignCenter"><img src="assets/da19af56-1dbd-4cf7-a371-c8af23bc0538.png" class="calibre91"/></div>
<div class="CDPAlignCenter1">Figure 13: Simple matrix multiplication.</div>
<p class="calibre2">You can confirm it by evaluating <kbd class="calibre12">softmax_layer</kbd>:</p>
<pre class="calibre21">print(softmax_layer)<br class="title-page-name"/>Output:<br class="title-page-name"/>Tensor("Softmax:0", shape=(?, 10), dtype=float32)</pre>
<p class="calibre2">Now, let's experiment with the computational graph that we have defined previously with three samples from the training set and see how it works. To execute the computational graph, we need to use the session variable that we defined before. And we need to initialize the variables using <kbd class="calibre12">tf.global_variables_initializer()</kbd>.</p>
<p class="calibre2">Let's go ahead and only feed three samples to the computational graph:</p>
<pre class="calibre21">input_values_train, target_values_train = train_size(3)<br class="title-page-name"/>sess.run(tf.global_variables_initializer())<br class="title-page-name"/>#If using TensorFlow prior to 0.12 use:<br class="title-page-name"/>#sess.run(tf.initialize_all_variables())<br class="title-page-name"/>print(sess.run(softmax_layer, feed_dict={input_values: input_values_train}))</pre>
<pre class="calibre21">Output:<br class="title-page-name"/><br class="title-page-name"/>[[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]<br class="title-page-name"/> [ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]<br class="title-page-name"/> [ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1]]</pre>
<p class="calibre2">Here, you can see the model predictions for the three training samples that fed to it. At the moment, the model has learned nothing about our task because we haven't gone through the training process yet, so it just outputs 10% probability of each digit being the correct class for the input samples.</p>
<p class="calibre2">As we mentioned previously, softmax is an activation function that squashes the output to be between 0 and 1, and the TensorFlow implementation of softmax ensures that all the probabilities of a single input sample sums up to one.</p>
<p class="calibre2">Let's experiment a bit with the softmax function of TensorFlow:</p>
<pre class="calibre21">sess.run(tf.nn.softmax(tf.zeros([4])))<br class="title-page-name"/>sess.run(tf.nn.softmax(tf.constant([0.1, 0.005, 2])))<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>array([0.11634309, 0.10579926, 0.7778576 ], dtype=float32)</pre>
<p class="calibre2">Next up, we need to define our loss function for this model, which will measure how good or bad <span class="calibre10">our classifier </span>is while trying to assign a class for the input images. The accuracy of our model is calculated by making a comparison between the actual values that we have in the dataset and the predictions that we got from the model.</p>
<p class="calibre2">The goal will be to reduce any misclassifications between the actual and predicted values.</p>
<p class="calibre2">Cross-entropy is defined as:</p>
<div class="CDPAlignCenter"><img class="fm-editor-equation21" src="assets/95cbcc07-4d8d-4902-bcdc-0cd64709a406.png"/></div>
<p class="calibre2">Where:</p>
<ul class="calibre7">
<li class="calibre8"><em class="calibre25">y</em> is our predicted probability distribution</li>
<li class="calibre8"><em class="calibre25">y'</em> is the true distribution (the one-hot vector with the digit labels)</li>
</ul>
<p class="calibre2">In some rough sense, cross-entropy measures how inefficient our predictions are for describing the actual input.</p>
<p class="calibre2">We can implement the cross-entropy function:</p>
<pre class="calibre21">model_cross_entropy = tf.reduce_mean(-tf.reduce_sum(output_values * tf.log(softmax_layer), reduction_indices=[1]))</pre>
<p class="calibre2">This function takes the log of all our predictions from <kbd class="calibre12">softmax_layer</kbd> (whose values range from 0 to 1) and multiplies them <span class="calibre10">element-wise</span><span class="calibre10"> </span><span class="calibre10">(<a href="https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29" class="calibre11">https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29</a>) by the example's true value, </span><kbd class="calibre12">output_values</kbd><span class="calibre10">. If the <kbd class="calibre12">log</kbd> function for each value is close to zero, it will make the value a large negative number (</span><kbd class="calibre12">-np.log(0.01) = 4.6</kbd><span class="calibre10">), and if it is close to one, it will make the value a small negative number (</span><kbd class="calibre12">-np.log(0.99) = 0.1</kbd><span class="calibre10">):</span></p>
<div class="CDPAlignCenter"><img src="assets/559d0f5f-c295-4752-b80b-091aa75944ac.png" class="calibre92"/></div>
<div class="CDPAlignCenter1">Figure 15: Visualization for Y = log (x)</div>
<p class="calibre2">We are essentially penalizing the classifier with a very large number if the prediction is confidently incorrect and a very small number if the prediction is confidently correct.</p>
<p class="calibre2">Here is a simple Python example of a softmax prediction that is very confident that the digit is a 3:</p>
<pre class="calibre21">j = [0.03, 0.03, 0.01, 0.9, 0.01, 0.01, 0.0025,0.0025, 0.0025, 0.0025]</pre>
<p class="calibre2">Let's create an array label of 3 as a ground truth to compare to our softmax function:</p>
<pre class="calibre21">k = [0,0,0,1,0,0,0,0,0,0]</pre>
<p class="calibre2">Can you guess what value our loss function gives us? Can you see how the log of <kbd class="calibre12">j</kbd> would penalize a wrong answer with a large negative number? Try this to understand:</p>
<pre class="calibre21">-np.log(j)<br class="title-page-name"/>-np.multiply(np.log(j),k)</pre>
<p class="calibre2">This will return nine zeros and a value of 0.1053; when they all are summed up, we can consider this a good prediction. Notice what happens when we make the same prediction for what is actually a 2:</p>
<pre class="calibre21">k = [0,0,1,0,0,0,0,0,0,0]<br class="title-page-name"/>np.sum(-np.multiply(np.log(j),k))</pre>
<p class="calibre2">Now, our <kbd class="calibre12">cross_entropy</kbd> function gives us 4.6051, which shows a heavily penalized, poorly made prediction. It was heavily penalized due to the fact the classifier was very confident that it was a 3 when it actually was a 2.</p>
<p class="calibre2">Next, we begin to train our classifier. In order to train it, we have to develop appropriate values for W and b that will give us the lowest possible loss.</p>
<p class="calibre2">The following is where we can now assign custom variables for training if we wish. Any value that is in all caps as follows is designed to be changed and messed with. In fact, I encourage it! First, use these values, and then notice what happens when you use too few training examples or too high or low of a learning rate:</p>
<pre class="calibre21">input_values_train, target_values_train = train_size(5500)<br class="title-page-name"/>input_values_test, target_values_test = test_size(10000)<br class="title-page-name"/>learning_rate = 0.1<br class="title-page-name"/>num_iterations = 2500</pre>
<p class="calibre2">We can now initialize all variables so that they can be used by our TensorFlow graph:</p>
<pre class="calibre21">init = tf.global_variables_initializer()<br class="title-page-name"/>#If using TensorFlow prior to 0.12 use:<br class="title-page-name"/>#init = tf.initialize_all_variables()<br class="title-page-name"/>sess.run(init)</pre>
<p class="calibre2">Next, we need to train the classifier using the gradient descent algorithm. So we first define our training method and some variables for measuring the model accuracy. The variable <kbd class="calibre12">train</kbd> will perform the gradient descent optimizer with a chosen learning rate in order to minimize the model loss function <kbd class="calibre12">model_cross_entropy</kbd>:</p>
<pre class="calibre21">train = tf.train.GradientDescentOptimizer(learning_rate).minimize(model_cross_entropy)<br class="title-page-name"/>model_correct_prediction = tf.equal(tf.argmax(softmax_layer,1), tf.argmax(output_values,1))<br class="title-page-name"/>model_accuracy = tf.reduce_mean(tf.cast(model_correct_prediction, tf.float32))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model training</h1>
                </header>
            
            <article>
                
<p class="calibre2">Now, we'll define a loop that iterates <kbd class="calibre12">num_iterations</kbd> times. And for each loop, it runs training, feeding in values from <kbd class="calibre12">input_values_train</kbd> and <kbd class="calibre12">target_values_train</kbd> using <kbd class="calibre12">feed_dict</kbd>.</p>
<p class="calibre2">In order to calculate accuracy, it will test the model against the unseen data in <kbd class="calibre12">input_values_test</kbd> :</p>
<pre class="calibre21">for i in range(num_iterations+1):<br class="title-page-name"/>    sess.run(train, feed_dict={input_values: input_values_train, output_values: target_values_train})<br class="title-page-name"/>    if i%100 == 0:<br class="title-page-name"/>        print('Training Step:' + str(i) + ' Accuracy = ' + str(sess.run(model_accuracy, feed_dict={input_values: input_values_test, output_values: target_values_test})) + ' Loss = ' + str(sess.run(model_cross_entropy, {input_values: input_values_train, output_values: target_values_train})))<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>Training Step:0 Accuracy = 0.5988 Loss = 2.1881988<br class="title-page-name"/>Training Step:100 Accuracy = 0.8647 Loss = 0.58029664<br class="title-page-name"/>Training Step:200 Accuracy = 0.879 Loss = 0.45982164<br class="title-page-name"/>Training Step:300 Accuracy = 0.8866 Loss = 0.40857208<br class="title-page-name"/>Training Step:400 Accuracy = 0.8904 Loss = 0.37808096<br class="title-page-name"/>Training Step:500 Accuracy = 0.8943 Loss = 0.35697535<br class="title-page-name"/>Training Step:600 Accuracy = 0.8974 Loss = 0.34104997<br class="title-page-name"/>Training Step:700 Accuracy = 0.8984 Loss = 0.32834956<br class="title-page-name"/>Training Step:800 Accuracy = 0.9 Loss = 0.31782663<br class="title-page-name"/>Training Step:900 Accuracy = 0.9005 Loss = 0.30886236<br class="title-page-name"/>Training Step:1000 Accuracy = 0.9009 Loss = 0.3010645<br class="title-page-name"/>Training Step:1100 Accuracy = 0.9023 Loss = 0.29417014<br class="title-page-name"/>Training Step:1200 Accuracy = 0.9029 Loss = 0.28799513<br class="title-page-name"/>Training Step:1300 Accuracy = 0.9033 Loss = 0.28240603<br class="title-page-name"/>Training Step:1400 Accuracy = 0.9039 Loss = 0.27730304<br class="title-page-name"/>Training Step:1500 Accuracy = 0.9048 Loss = 0.27260992<br class="title-page-name"/>Training Step:1600 Accuracy = 0.9057 Loss = 0.26826677<br class="title-page-name"/>Training Step:1700 Accuracy = 0.9062 Loss = 0.2642261<br class="title-page-name"/>Training Step:1800 Accuracy = 0.9061 Loss = 0.26044932<br class="title-page-name"/>Training Step:1900 Accuracy = 0.9063 Loss = 0.25690478<br class="title-page-name"/>Training Step:2000 Accuracy = 0.9066 Loss = 0.2535662<br class="title-page-name"/>Training Step:2100 Accuracy = 0.9072 Loss = 0.25041154<br class="title-page-name"/>Training Step:2200 Accuracy = 0.9073 Loss = 0.24742197<br class="title-page-name"/>Training Step:2300 Accuracy = 0.9071 Loss = 0.24458146<br class="title-page-name"/>Training Step:2400 Accuracy = 0.9066 Loss = 0.24187621<br class="title-page-name"/>Training Step:2500 Accuracy = 0.9067 Loss = 0.23929419</pre>
<p class="calibre2"><span class="calibre10">Notice how the loss was still decreasing <span class="calibre10">near the end </span>but our accuracy slightly went down! This shows that we can still minimize our loss and hence maximize the accuracy over our training data, but this may not help us predict the testing data used for measuring accuracy. This is also known as <strong class="calibre13">overfitting</strong> (not generalizing). With the default settings, we got an accuracy of about 91%. If I wanted to cheat to get 94% accuracy, I could've set the test examples to 100. This shows how not having enough test examples can give you a biased sense of accuracy.</span></p>
<div class="title-page-name">
<p class="calibre2">Keep in mind that this is a very inaccurate way to calculate our classifier's performance. However, we did this on purpose for the sake of learning and experimentation. Ideally, when training with large datasets, you train using small batches of training data at a time, not all at once.</p>
<p class="calibre2">This is the interesting part. Now that we have calculated our weight cheat sheet, we can create a graph with the following code:</p>
<pre class="calibre21">for i in range(10):<br class="title-page-name"/>    plt.subplot(2, 5, i+1)<br class="title-page-name"/>    weight = sess.run(weights)[:,i]<br class="title-page-name"/>    plt.title(i)<br class="title-page-name"/>    plt.imshow(weight.reshape([28,28]), cmap=plt.get_cmap('seismic'))<br class="title-page-name"/>    frame = plt.gca()<br class="title-page-name"/>    frame.axes.get_xaxis().set_visible(False)<br class="title-page-name"/>    frame.axes.get_yaxis().set_visible(False)</pre></div>
<div class="CDPAlignCenter"><img src="assets/8ad5bc0f-e6ee-4843-8205-588cde3de594.png" class="calibre93"/></div>
<div class="CDPAlignCenter1">Figure 15: Visualization of our weights from 0-9</div>
<p class="calibre2">The preceding figure shows the model weights from 0-9, which is the most important side of our classifier. All this amount of work of machine learning is done to figure out what the optimal weights are. Once they are calculated based on an optimization criteria, you have the <strong class="calibre13">cheat sheet</strong> and can easily find your answers using the learned weights.</p>
<p class="calibre2">The learned model makes its prediction by comparing how similar or different the input digit sample is to the red and blue weights. The darker the red, the better the hit; white means neutral and blue means misses.</p>
<p class="calibre2">Now, let's use the cheat sheet and see how our model performs on it:</p>
<pre class="calibre21">input_values_train, target_values_train = train_size(1)<br class="title-page-name"/>visualize_digit(0)<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>Total Training Images in Dataset = (55000, 784)<br class="title-page-name"/>############################################<br class="title-page-name"/>input_values_train Samples Loaded = (1, 784)<br class="title-page-name"/>target_values_train Samples Loaded = (1, 10)<br class="title-page-name"/>[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]</pre>
<div class="CDPAlignCenter"><img src="assets/265bc5f7-4cda-47a3-8382-3d3faef8af97.png" class="calibre94"/></div>
<p class="calibre2">Let's look at our softmax predictor:</p>
<pre class="calibre21">answer = sess.run(softmax_layer, feed_dict={input_values: input_values_train})<br class="title-page-name"/>print(answer)</pre>
<p class="calibre2">The preceding code will give us a 10-dimensional vector, with each column containing one probability:</p>
<pre class="calibre21">[[2.1248012e-05 1.1646927e-05 8.9631692e-02 1.9201526e-02 8.2086492e-04<br class="title-page-name"/>  1.2516821e-05 3.8538201e-05 8.5374612e-01 6.9188857e-03 2.9596921e-02]]</pre>
<p class="calibre2">We can use the <kbd class="calibre12">argmax</kbd> function to find out the most probable digit to be the correct classification for our input image:</p>
<pre class="calibre21">answer.argmax()<br class="title-page-name"/><br class="title-page-name"/>Output:<br class="title-page-name"/>7</pre>
<p class="calibre2">Now, we get a correct classification from our network.</p>
<p class="calibre2">Let's use our knowledge to define a helper function that can select a random image from the dataset and test the model against it:</p>
<pre class="calibre21">def display_result(ind):<br class="title-page-name"/>    <br class="title-page-name"/>    # Loading a training sample<br class="title-page-name"/>    input_values_train = mnist_dataset.train.images[ind,:].reshape(1,784)<br class="title-page-name"/>    target_values_train = mnist_dataset.train.labels[ind,:]<br class="title-page-name"/>    <br class="title-page-name"/>    # getting the label as an integer instead of one-hot encoded vector<br class="title-page-name"/>    label = target_values_train.argmax()<br class="title-page-name"/>    <br class="title-page-name"/>    # Getting the prediction as an integer<br class="title-page-name"/>    prediction = sess.run(softmax_layer, feed_dict={input_values: input_values_train}).argmax()<br class="title-page-name"/>    plt.title('Prediction: %d Label: %d' % (prediction, label))<br class="title-page-name"/>    plt.imshow(input_values_train.reshape([28,28]), cmap=plt.get_cmap('gray_r'))<br class="title-page-name"/>    plt.show()</pre>
<p class="calibre2">And now try it out:</p>
<pre class="calibre21">display_result(ran.randint(0, 55000))<br class="title-page-name"/><br class="title-page-name"/>Output:</pre>
<div class="CDPAlignCenter"><img src="assets/fdc05ce6-73ba-4b58-ad42-38c3adad66f9.png" class="calibre95"/></div>
<p class="calibre2">We've got a correct classification again!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this chapter, we went through a basic implementation of a FNN for our digit classification task. We also did a recap of the terminologies used in the neural network context.</p>
<p class="calibre2">Next up, we will build a sophisticated version of the digit classification model using some modern best practices and some tips and tricks to enhance the model's performance.</p>
<p class="calibre2"/>


            </article>

            
        </section>
    </body></html>