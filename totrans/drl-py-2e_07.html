<html><head></head><body>
  <div id="_idContainer978">
    <h1 class="chapterNumber">7</h1>
    <h1 id="_idParaDest-167" class="chapterTitle">Deep Learning Foundations</h1>
    <p class="normal">So far in the previous chapters, we have learned how several reinforcement learning algorithms work and how they find the optimal policy. In the upcoming chapters, we will learn about<strong class="keyword"> Deep Reinforcement Learning</strong> (<strong class="keyword">DRL</strong>), which is a combination of deep learning and reinforcement learning. To understand DRL, we need to have a strong foundation in deep learning. So, in this chapter, we will learn several important deep learning algorithms. </p>
    <p class="normal">Deep learning is a subset of machine learning and it is all about neural networks. Deep learning has been around for a decade, but the reason it is so popular right now is because of the computational advancements and availability of huge volumes of data. With this huge volume of data, deep learning algorithms can outperform classic machine learning algorithms.</p>
    <p class="normal">We will start off the chapter by understanding what biological and artificial neurons are, and then we will learn about <strong class="keyword">Artificial Neural Networks</strong> (<strong class="keyword">ANN</strong>s) and how to implement them. Moving forward, we will learn about several interesting deep learning algorithms such as the <strong class="keyword">Recurrent Neural Network</strong> (<strong class="keyword">RNN</strong>), <strong class="keyword">Long Short-Term Memory</strong> (<strong class="keyword">LSTM</strong>), <strong class="keyword">Convolutional Neural Network</strong> (<strong class="keyword">CNN</strong>), and <strong class="keyword">Generative Adversarial Network</strong> (<strong class="keyword">GAN</strong>).</p>
    <p class="normal">In this chapter, we will learn about the following:</p>
    <ul>
      <li class="bullet">Biological and artificial neurons</li>
      <li class="bullet">ANNs</li>
      <li class="bullet">RNNs</li>
      <li class="bullet">LSTM RNNs</li>
      <li class="bullet">CNNs</li>
      <li class="bullet">GANs</li>
    </ul>
    <p class="normal">Let's begin the chapter by understanding how biological and artificial neurons work. </p>
    <h1 id="_idParaDest-168" class="title">Biological and artificial neurons</h1>
    <p class="normal">Before going <a id="_idIndexMarker617"/>ahead, first, we will explore what neurons are and how neurons <a id="_idIndexMarker618"/>in our brain actually work, and then we will learn about artificial neurons.</p>
    <p class="normal">A <strong class="keyword">neuron</strong> can be <a id="_idIndexMarker619"/>defined as the basic computational unit of the human brain. Neurons are the fundamental units of our brain and nervous system. Our brain encompasses approximately 100 billion neurons. Each and every neuron is connected to one another <a id="_idIndexMarker620"/>through a structure called a <strong class="keyword">synapse</strong>, which is accountable for receiving input from the external environment via sensory organs, for sending motor instructions to our muscles, and for performing other activities.</p>
    <p class="normal">A neuron <a id="_idIndexMarker621"/>can also receive inputs from other neurons through a branchlike structure called a <strong class="keyword">dendrite</strong>. These inputs are strengthened or weakened; that is, they are weighted according to their importance and then they are summed together in the cell body called the <strong class="keyword">soma</strong>. From the cell body, these summed inputs are processed and move through the <strong class="keyword">axons</strong> and are sent to the other neurons.</p>
    <p class="normal"><em class="italic">Figure 7.1</em> shows a basic single biological neuron:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.1: Biological neuron</p>
    <p class="normal">Now, let's see how artificial neurons work. Let's suppose we have three inputs <em class="italic">x</em><sub class="Subscript--PACKT-">1</sub>, <em class="italic">x</em><sub class="Subscript--PACKT-">2</sub>, and <em class="italic">x</em><sub class="Subscript--PACKT-">3</sub>, to predict the output <em class="italic">y</em>. These inputs are multiplied by weights <em class="italic">w</em><sub class="Subscript--PACKT-">1</sub>, <em class="italic">w</em><sub class="Subscript--PACKT-">2</sub>, and <em class="italic">w</em><sub class="Subscript--PACKT-">3</sub> and are summed together as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_001.png" alt="" style="height: 1.02em;"/></figure>
    <p class="normal">But why are we multiplying these inputs by weights? Because all of the inputs are not equally important in calculating the output <em class="italic">y</em>. Let's say that <em class="italic">x</em><sub class="Subscript--PACKT-">2</sub> is more important in calculating the output compared to the other two inputs. Then, we assign a higher value to <em class="italic">w</em><sub class="Subscript--PACKT-">2</sub> than the other two weights. So, upon multiplying weights with inputs, <em class="italic">x</em><sub class="Subscript--PACKT-">2</sub> will have a higher value <a id="_idIndexMarker622"/>than the other two inputs. In simple terms, weights <a id="_idIndexMarker623"/>are used for strengthening the inputs. After multiplying inputs with the weights, we sum them together and we add a value called bias, <em class="italic">b</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_002.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">If you look at the preceding equation closely, it may look familiar. Doesn't <em class="italic">z</em> look like the equation of linear regression? Isn't it just the equation of a straight line? We know that the equation of a straight line is given as:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_003.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Here, <em class="italic">m</em> is the weights (coefficients), <em class="italic">x</em> is the input, and <em class="italic">b</em> is the bias (intercept).</p>
    <p class="normal">Well, yes. Then, what is the difference between neurons and linear regression? In neurons, we <a id="_idIndexMarker624"/>introduce non-linearity to the result, <em class="italic">z</em>, by applying <a id="_idIndexMarker625"/>a function <em class="italic">f</em>(.) called the <strong class="keyword">activation</strong> or <strong class="keyword">transfer function</strong>. Thus, our output becomes:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_004.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal"><em class="italic">Figure 7.2</em> shows a single artificial neuron:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_02.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.2: Artificial neuron</p>
    <p class="normal">So, a neuron <a id="_idIndexMarker626"/>takes the input, <em class="italic">x</em>, multiples it by weights, <em class="italic">w,</em> and adds bias, <em class="italic">b,</em> forms <em class="italic">z</em>, and then <a id="_idIndexMarker627"/>we apply the activation function on <em class="italic">z</em> and get the output, <em class="italic">y</em>.</p>
    <h1 id="_idParaDest-169" class="title">ANN and its layers</h1>
    <p class="normal">While neurons <a id="_idIndexMarker628"/>are really cool, we cannot just use a single neuron to perform complex tasks. This is the reason our brain has billions <a id="_idIndexMarker629"/>of neurons, stacked in layers, forming a network. Similarly, artificial neurons are arranged in layers. Each and every layer will be connected in such a way that information is passed from one layer to another.</p>
    <p class="normal">A typical ANN consists of the following layers:</p>
    <ul>
      <li class="bullet">Input layer</li>
      <li class="bullet">Hidden layer</li>
      <li class="bullet">Output layer</li>
    </ul>
    <p class="normal">Each layer has a collection of neurons, and the neurons in one layer interact with all the neurons in the other layers. However, neurons in the same layer will not interact with one another. This is simply because neurons from the adjacent layers have connections or edges between them; however, neurons in the same layer do not have any connections. We use the term <strong class="keyword">nodes</strong> or <strong class="keyword">units</strong> to represent the neurons in the ANN.</p>
    <p class="normal"><em class="italic">Figure 7.3</em> shows a typical ANN:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_03.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.3: ANN</p>
    <h2 id="_idParaDest-170" class="title">Input layer</h2>
    <p class="normal">The <strong class="keyword">input layer</strong> is where <a id="_idIndexMarker630"/>we feed input to <a id="_idIndexMarker631"/>the network. The number of neurons in the input layer is the number of inputs we feed to the network. Each input will have some influence on predicting the output. However, no computation is performed in the input layer; it is just used for passing information from the outside world to the network.</p>
    <h2 id="_idParaDest-171" class="title">Hidden layer</h2>
    <p class="normal">Any layer <a id="_idIndexMarker632"/>between the input layer and the output layer is called a <strong class="keyword">hidden layer</strong>. It processes the input received from the input layer. The hidden layer is responsible for <a id="_idIndexMarker633"/>deriving complex relationships between input and output. That is, the hidden layer identifies the pattern in the dataset. It is majorly responsible for learning the data representation and for extracting the features.</p>
    <p class="normal">There can be any number of hidden layers; however, we have to choose a number of hidden layers according to our use case. For a very simple problem, we can just use one hidden layer, but while performing complex tasks such as image recognition, we use many <a id="_idIndexMarker634"/>hidden layers, where each layer is responsible for extracting important features. The network is called a <strong class="keyword">deep neural network</strong> when we have many hidden layers.</p>
    <h2 id="_idParaDest-172" class="title">Output layer</h2>
    <p class="normal">After processing <a id="_idIndexMarker635"/>the input, the hidden layer <a id="_idIndexMarker636"/>sends its result to the output layer. As the name suggests, the output layer emits the output. The number of neurons in the output layer is based on the type of problem we want our network to solve.</p>
    <p class="normal">If it is a binary classification, then the number of neurons in the output layer is one, and it tells us which class the input belongs to. If it is a multi-class classification say, with five classes, and if we want to get the probability of each class as an output, then the number of neurons in the output layer is five, each emitting the probability. If it is a regression problem, then we have one neuron in the output layer.</p>
    <h1 id="_idParaDest-173" class="title">Exploring activation functions</h1>
    <p class="normal">An <strong class="keyword">activation function</strong>, also <a id="_idIndexMarker637"/>known as a <strong class="keyword">transfer function</strong>, plays a <a id="_idIndexMarker638"/>vital role in neural networks. It is used to introduce non-linearity in neural networks. As we learned before, we apply the activation function to the input, which is <a id="_idIndexMarker639"/>multiplied by weights and added to the bias, that is, <em class="italic">f</em>(<em class="italic">z</em>), where <em class="italic">z = (input * weights) + bias</em> and <em class="italic">f</em>(.) is the activation function. </p>
    <p class="normal">If we do not apply the activation function, then a neuron simply resembles the linear regression. The aim of the activation function is to introduce a non-linear transformation to learn the complex underlying patterns in the data.</p>
    <p class="normal">Now let's look at some of the interesting commonly used activation functions.</p>
    <h2 id="_idParaDest-174" class="title">The sigmoid function</h2>
    <p class="normal">The <strong class="keyword">sigmoid function</strong> is one <a id="_idIndexMarker640"/>of the most commonly <a id="_idIndexMarker641"/>used activation functions. It scales the value between 0 and 1. The sigmoid function can be defined as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_005.png" alt="" style="height: 2.22em;"/></figure>
    <p class="normal">It is an S-shaped curve shown in <em class="italic">Figure 7.4</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_04.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.4: Sigmoid function</p>
    <p class="normal">It is <a id="_idIndexMarker642"/>differentiable, meaning that we can find the slope of the curve at <a id="_idIndexMarker643"/>any two points. It is <strong class="keyword">monotonic</strong>, which implies it is either entirely non-increasing or non-decreasing. The sigmoid function is <a id="_idIndexMarker644"/>also known as a <strong class="keyword">logistic</strong> function. As we know that probability lies between 0 and 1, and since the sigmoid function squashes the value between 0 and 1, it is used for predicting the probability of output.</p>
    <h2 id="_idParaDest-175" class="title">The tanh function</h2>
    <p class="normal">A <strong class="keyword">hyperbolic tangent</strong> (<strong class="keyword">tanh</strong>) function <a id="_idIndexMarker645"/>outputs the value between -1 to +1 <a id="_idIndexMarker646"/>and is expressed as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_006.png" alt="" style="height: 2.4em;"/></figure>
    <p class="normal">It also <a id="_idIndexMarker647"/>resembles the S-shaped curve. Unlike the sigmoid function, which is centered on 0.5, the tanh function is 0-centered, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_05.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.5: tanh function</p>
    <h2 id="_idParaDest-176" class="title">The Rectified Linear Unit function</h2>
    <p class="normal">The <strong class="keyword">Rectified Linear Unit</strong> (<strong class="keyword">ReLU</strong>) function <a id="_idIndexMarker648"/>is another <a id="_idIndexMarker649"/>one of the most commonly <a id="_idIndexMarker650"/>used activation functions. It outputs a value from zero to infinity. It is basically a <strong class="keyword">piecewise</strong> function and can be expressed as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_007.png" alt="" style="height: 2.31em;"/></figure>
    <p class="normal">That is, <em class="italic">f</em>(<em class="italic">x</em>) returns zero when the value of <em class="italic">x</em> is less than zero and <em class="italic">f</em>(<em class="italic">x</em>) returns <em class="italic">x</em> when the value of <em class="italic">x</em> is greater than or equal to zero. It can also be expressed as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_008.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal"><em class="italic">Figure 7.6</em> shows the ReLU function:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_06.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.6: ReLU function</p>
    <p class="normal">As we <a id="_idIndexMarker651"/>can see in the preceding diagram, when <a id="_idIndexMarker652"/>we feed any negative input to the ReLU function, it converts the negative input to zero.</p>
    <h2 id="_idParaDest-177" class="title">The softmax function</h2>
    <p class="normal">The <strong class="keyword">softmax function</strong> is basically <a id="_idIndexMarker653"/>the generalization of the sigmoid function. It is <a id="_idIndexMarker654"/>usually applied to the final layer of the network and while performing multi-class classification tasks. It gives the probabilities of each class for being output and thus, the sum of softmax values will always equal 1.</p>
    <p class="normal">It can be represented as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_009.png" alt="" style="height: 2.6em;"/></figure>
    <p class="normal">As shown in the <em class="italic">Figure 7.7</em>, the softmax function converts its inputs to probabilities:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_07.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.7: Softmax function</p>
    <p class="normal">Now that <a id="_idIndexMarker655"/>we have learned about different activation <a id="_idIndexMarker656"/>functions, in the next section, we will learn about forward propagation in ANNs.</p>
    <h1 id="_idParaDest-178" class="title">Forward propagation in ANNs</h1>
    <p class="normal">In this section, we will see how an ANN learns where neurons are stacked up in layers. The number <a id="_idIndexMarker657"/>of layers in a network is <a id="_idIndexMarker658"/>equal to the number of hidden layers plus the number of output layers. We don't take the input layer into account when calculating the number of layers in a network. Consider a two-layer neural network with one input layer, <em class="italic">x</em>, one hidden layer, <em class="italic">h</em>, and one output layer, <em class="italic">y</em>, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.8: Forward propagation in ANN</p>
    <p class="normal">Let's consider we have two inputs, <em class="italic">x</em><sub class="Subscript--PACKT-">1</sub> and <em class="italic">x</em><sub class="Subscript--PACKT-">2</sub>, and we have to predict the output, <img src="../Images/B15558_07_010.png" alt="" style="height: 1.11em;"/>. Since we have two inputs, the number of neurons in the input layer is two. We set the number of neurons in the hidden layer to four, and the number of neurons in the output layer to one. Now, the inputs are multiplied by weights, and then we add bias and propagate the resultant value to the hidden layer where the activation function is applied.</p>
    <p class="normal">Before that, we need to initialize the weight matrix. In the real world, we don't know which input is more important than the other so that we can weight them and compute the output. Therefore, we randomly initialize the weights and bias value. The weight and the bias value between the input to the hidden layer are represented by <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub> and <em class="italic">b</em><sub class="" style="font-style: italic;">h</sub>, respectively. What about the dimensions of the weight matrix? The dimensions of the weight matrix must be <em class="italic">the number of neurons in the current layer</em> x <em class="italic">the number of neurons in the next layer</em>. Why is that?</p>
    <p class="normal">Because it <a id="_idIndexMarker659"/>is a basic matrix multiplication rule. To multiply any two matrices, <em class="italic">AB</em>, the number of columns in matrix <em class="italic">A</em> must be <a id="_idIndexMarker660"/>equal to the number of rows in matrix <em class="italic">B</em>. So, the dimension of the weight matrix, <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub>, should be <em class="italic">the number of neurons in the input layer</em> x <em class="italic">the number of neurons in the hidden layer</em>, that is, 2 x 4:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_011.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">The preceding equation represents, <img src="../Images/B15558_07_012.png" alt="" style="height: 1.11em;"/>. Now, this is passed to the hidden layer. In the hidden layer, we apply an activation function to <em class="italic">z</em><sub class="Subscript--PACKT-">1</sub>. Let's use the sigmoid <img src="../Images/B15558_07_013.png" alt="" style="height: 0.84em;"/> activation function. Then, we can write:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_014.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">After applying the activation function, we again multiply result <em class="italic">a</em><sub class="Subscript--PACKT-">1</sub> by a new weight matrix and add a new bias value that is flowing between the hidden layer and the output layer. We can denote this weight matrix and bias as <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub> and <em class="italic">b</em><sub class="" style="font-style: italic;">y</sub>, respectively. The dimension of the weight matrix, <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>, will be <em class="italic">the number of neurons in the hidden layer</em> x <em class="italic">the number of neurons in the output layer</em>. Since we have four neurons in the hidden layer and one neuron in the output layer, the <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub> matrix dimension will be 4 x 1. So, we multiply <em class="italic">a</em><sub class="Subscript--PACKT-">1</sub> by the weight matrix, <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>, and add bias, <em class="italic">b</em><sub class="" style="font-style: italic;">y</sub>, and pass the result <em class="italic">z</em><sub class="Subscript--PACKT-">2</sub> to the next layer, which is the output layer:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_015.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Now, in the output layer, we apply the sigmoid function to <em class="italic">z</em><sub class="Subscript--PACKT-">2</sub>, which will result in an output value:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_016.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">This whole <a id="_idIndexMarker661"/>process from the input <a id="_idIndexMarker662"/>layer to the output layer is known as <strong class="keyword">forward propagation</strong>. Thus, in order to predict the output value, inputs are propagated from the <a id="_idIndexMarker663"/>input layer to the output layer. During this propagation, they are multiplied by their respective weights on each layer and an activation function is applied on top of them. The complete forward propagation steps are given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_011.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_014.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_015.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_016.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">The preceding forward propagation steps can be implemented in Python as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">forward_prop</span><span class="hljs-function">(</span><span class="hljs-params">X</span><span class="hljs-function">):</span>
    z1 = np.dot(X,Wxh) + bh
    a1 = sigmoid(z1)
    z2 = np.dot(a1,Why) + by
    y_hat = sigmoid(z2)
    
    <span class="hljs-keyword">return</span> y_hat
</code></pre>
    <p class="normal">Forward propagation is cool, isn't it? But how do we know whether the output generated <a id="_idIndexMarker664"/>by the neural network is correct? We define a new function called the <strong class="keyword">cost function</strong> (<em class="italic">J</em>), also known as the <strong class="keyword">loss function</strong> (<em class="italic">L</em>), which tells us how well <a id="_idIndexMarker665"/>our neural network is performing. There are many different cost functions. We will use the mean squared error as a cost function, which can be defined as the mean of the squared difference between the actual output and the predicted output:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_021.png" alt="" style="height: 3.24em;"/></figure>
    <p class="normal">Here, <em class="italic">n</em> is the <a id="_idIndexMarker666"/>number of training samples, <em class="italic">y</em> is the actual <a id="_idIndexMarker667"/>output, and <img src="../Images/B15558_07_022.png" alt="" style="height: 1.11em;"/> is the predicted output.</p>
    <p class="normal">Okay, so we learned that a cost function is used for assessing our neural network; that is, it tells us how good our neural network is at predicting the output. But the question is where is our network actually learning? In forward propagation, the network is just trying to predict the output. But how does it learn to predict the correct output? In the next section, we will examine this.</p>
    <h1 id="_idParaDest-179" class="title">How does an ANN learn?</h1>
    <p class="normal">If the cost <a id="_idIndexMarker668"/>or loss is very high, then it means that our network is not predicting the correct output. So, our objective is to minimize the cost function so that our neural network predictions will be better. How can we minimize the cost function? That is, how can we minimize the loss/cost? We learned that the neural network makes predictions using forward propagation. So, if we can change some values in the forward propagation, we can predict the correct output and minimize the loss. But what values can we change in the forward propagation? Obviously, we can't change input and output. We are now left with weights and bias values. Remember that we just initialized weight matrices randomly. Since the weights are random, they are not going to be perfect. Now, we will update these weight matrices (<em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub> and <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>) in such a way that our neural network gives a correct output. How do <a id="_idIndexMarker669"/>we update these weight matrices? Here comes a new technique called <strong class="keyword">gradient descent</strong>.</p>
    <p class="normal">With gradient descent, the neural network learns the optimal values of the randomly initialized weight matrices. With the optimal values of weights, our network can predict the correct output and minimize the loss.</p>
    <p class="normal">Now, we will <a id="_idIndexMarker670"/>explore how the optimal values of weights are learned using gradient descent. Gradient descent is one of the most commonly used optimization algorithms. It is used for minimizing the cost function, which allows us to minimize the error and obtain the lowest possible error value. But how does gradient descent find the optimal weights? Let's begin with an analogy.</p>
    <p class="normal">Imagine we are on top of a hill, as shown in the following diagram, and we want to reach the lowest point on the hill. There could be many regions that look like the lowest points on the hill, but we have to reach the point that is actually the lowest of all.</p>
    <p class="normal">That is, we should not be stuck at a point believing it is the lowest point when the global lowest point exists:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_09.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.9: Analogy of gradient descent </p>
    <p class="normal">Similarly, we can represent our cost function as follows. It is a plot of cost against weights. Our objective is to minimize the cost function. That is, we have to reach the lowest point where the cost is the minimum. The solid dark point in the following diagram shows the randomly initialized weights. If we move this point downward, then we can reach the point where the cost is the minimum:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_10.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.10: Gradient descent</p>
    <p class="normal">But how <a id="_idIndexMarker671"/>can we move this point (initial weight) downward? How can we descend and reach the lowest point? Gradients are used for moving from one point to another. So, we can move this point (initial weight) by calculating a gradient of the cost function with respect to that point (initial weights), which is <img src="../Images/B15558_07_023.png" alt="" style="height: 2.22em;"/>.</p>
    <p class="normal">Gradients are the derivatives that are actually the slope of a tangent line, as illustrated in the following diagram. So, by calculating the gradient, we descend (move downward) and reach the lowest point where the cost is the minimum. Gradient descent is a first-order optimization algorithm, which means we only take into account the first derivative when performing the updates:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_11.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.11: Gradient descent</p>
    <p class="normal">Thus, with <a id="_idIndexMarker672"/>gradient descent, we move our weights to a position where the cost is minimum. But still, how do we update the weights?</p>
    <p class="normal">As a result of forward propagation, we are in the output layer. We will now <strong class="keyword">backpropagate</strong> the network <a id="_idIndexMarker673"/>from the output layer to the input layer and calculate the gradient of the cost function with respect to all the weights between the output and the input layer so that we can minimize the error. After calculating gradients, we update our old weights using the weight update rule:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_024.png" alt="" style="height: 2.22em;"/></figure>
    <p class="normal">This implies <em class="italic">weights = weights -α </em>x<em class="italic"> gradients</em>.</p>
    <p class="normal">What is <img src="../Images/B15558_07_025.png" alt="" style="height: 0.93em;"/>? It is <a id="_idIndexMarker674"/>called the <strong class="keyword">learning rate</strong>. As shown in the following diagram, if the learning rate is small, then we take a small step downward and our gradient descent can be slow.</p>
    <p class="normal">If the learning rate is large, then we take a large step and our gradient descent will be fast, but we might fail to reach the global minimum and become stuck at a local minimum. So, the learning rate should be chosen optimally:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_12.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.12: Effect of learning rate</p>
    <p class="normal">This whole <a id="_idIndexMarker675"/>process of backpropagating the network from the output layer to the input layer and updating the weights of the network using gradient descent to minimize the loss is called <strong class="keyword">backpropagation</strong>. Now that <a id="_idIndexMarker676"/>we have a basic understanding of backpropagation, we will strengthen our understanding by learning about this in detail, step by step. We are going to look at some interesting math, so put on your calculus hats and follow the steps.</p>
    <p class="normal">So, we have two weights, one <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub>, which is the input to hidden layer weights, and the other <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>, which is the hidden to output layer weights. We need to find the optimal values for these two weights that will give us the fewest errors. So, we need to calculate the derivative of the cost function <em class="italic">J</em> with respect to these weights. Since we are backpropagating, that is, going from the output layer to the input layer, our first weight will be <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>. So, now we need to calculate the derivative of <em class="italic">J</em> with respect to <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>. How do we calculate the derivative? First, let's recall our cost function, <em class="italic">J</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_021.png" alt="" style="height: 3.24em;"/></figure>
    <p class="normal">We cannot calculate the derivative directly from the preceding equation since there is no <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub> term. So, instead of calculating the derivative directly, we calculate the partial derivative. Let's recall our forward propagation equation:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_016.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_015.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">First, we will calculate a partial derivative with respect to <img src="../Images/B15558_07_029.png" alt="" style="height: 1.11em;"/>, and then from <img src="../Images/B15558_07_030.png" alt="" style="height: 1.11em;"/> we will calculate the partial derivative with respect to <em class="italic">z</em><sub class="Subscript--PACKT-">2</sub>. From <em class="italic">z</em><sub class="Subscript--PACKT-">2</sub>, we can directly calculate our derivative <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>. It is basically the chain rule. So, the derivative of <em class="italic">J</em> with respect to <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub> becomes as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_031.png" alt="" style="height: 2.6em;"/></figure>
    <p class="normal">Now, we will <a id="_idIndexMarker677"/>compute each of the terms in the preceding equation:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_032.png" alt="" style="height: 2.51em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_033.png" alt="" style="height: 2.51em;"/></figure>
    <p class="normal">Here, <img src="../Images/B15558_07_034.png" alt="" style="height: 1.2em;"/> is the derivative of our sigmoid activation function. We know that the sigmoid function is <img src="../Images/B15558_07_035.png" alt="" style="height: 2.22em;"/>, so the derivative of the sigmoid function would be <img src="../Images/B15558_07_036.png" alt="" style="height: 2.51em;"/>.</p>
    <p class="normal">Next we have:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_037.png" alt="" style="height: 2.6em;"/></figure>
    <p class="normal">Thus, substituting all the preceding terms in equation <em class="italic">(1)</em> we can write:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_038.png" alt="" style="height: 2.6em;"/></figure>
    <p class="normal">Now we need to compute a derivative of <em class="italic">J</em> with respect to our next weight, <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub>.</p>
    <p class="normal">Similarly, we cannot <a id="_idIndexMarker678"/>calculate the derivative of <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub> directly from <em class="italic">J</em> as we don't have any <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub> terms in <em class="italic">J</em>. So, we need to use the chain rule. Let's recall the forward propagation steps again:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_016.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_015.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_014.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_011.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Now, according to the chain rule, the derivative of <em class="italic">J</em> with respect to <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub> is given as:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_043.png" alt="" style="height: 2.51em;"/></figure>
    <p class="normal">We have already seen how to compute the first two terms in the preceding equation; now, we will see how to compute the rest of the terms:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_044.png" alt="" style="height: 2.51em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_045.png" alt="" style="height: 2.51em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_046.png" alt="" style="height: 2.51em;"/></figure>
    <p class="normal">Thus, substituting all the preceding terms in equation <em class="italic">(3)</em>, we can write:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_047.png" alt="" style="height: 2.51em;"/></figure>
    <p class="normal">After we <a id="_idIndexMarker679"/>have computed gradients for both weights, <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub> and <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub>, we will update our initial weights according to the weight update rule:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_048.png" alt="" style="height: 2.6em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_049.png" alt="" style="height: 2.51em;"/></figure>
    <p class="normal">That's it! This is how we update the weights of a network and minimize the loss. Now, let's see how to implement the backpropagation algorithm in Python.</p>
    <p class="normal">In both the equations <em class="italic">(2)</em> and <em class="italic">(4)</em>, we have the term <img src="../Images/B15558_07_050.png" alt="" style="height: 1.2em;"/>, so instead of computing them again and again, we just call them <code class="Code-In-Text--PACKT-">delta2</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">delta2 = np.multiply(-(y-yHat),sigmoidPrime(z2))
</code></pre>
    <p class="normal">Now, we compute the gradient with respect to <em class="italic">W</em><sub class="" style="font-style: italic;">hy</sub>. Refer to equation <em class="italic">(2)</em>:</p>
    <pre class="programlisting code"><code class="hljs-code">dJ_dWhy = np.dot(a1.T,delta2)
</code></pre>
    <p class="normal">We compute the gradient with respect to <em class="italic">W</em><sub class="" style="font-style: italic;">xh</sub>. Refer to equation <em class="italic">(4)</em>:</p>
    <pre class="programlisting code"><code class="hljs-code">delta1 = np.dot(delta2,Why.T)*sigmoidPrime(z1)
dJ_dWxh = np.dot(X.T,delta1)
</code></pre>
    <p class="normal">We will update the weights according to our weight update rule equation <em class="italic">(5)</em> and <em class="italic">(6)</em> as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">Wxh = Wxh - alpha * dJ_dWhy
Why = Why - alpha * dJ_dWxh
</code></pre>
    <p class="normal">The complete <a id="_idIndexMarker680"/>code for the backpropagation is given as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">backword_prop</span><span class="hljs-function">(</span><span class="hljs-params">y_hat, z1, a1, z2</span><span class="hljs-function">):</span>
    delta2 = np.multiply(-(y-y_hat),sigmoid_derivative(z2))
    dJ_dWhy = np.dot(a1.T, delta2)
    delta1 = np.dot(delta2,Why.T)*sigmoid_derivative(z1)
    dJ_dWxh = np.dot(X.T, delta1) 
    Wxh = Wxh - alpha * dJ_dWhy
    Why = Why - alpha * dJ_dWxh
    <span class="hljs-keyword">return</span> Wxh,Why
</code></pre>
    <p class="normal">That's it. Apart from this, there are different variants of gradient descent methods such as stochastic gradient descent, mini-batch gradient descent, Adam, RMSprop, and more.</p>
    <p class="normal">Before moving on, let's familiarize ourselves with some of the frequently used terminology in neural networks:</p>
    <ul>
      <li class="bullet"><strong class="keyword">Forward pass</strong>: Forward <a id="_idIndexMarker681"/>pass implies forward propagating from the input layer to the output layer.</li>
      <li class="bullet"><strong class="keyword">Backward pass</strong>: Backward <a id="_idIndexMarker682"/>pass implies backpropagating from the output layer to the input layer.</li>
      <li class="bullet"><strong class="keyword">Epoch</strong>: The epoch <a id="_idIndexMarker683"/>specifies the number of times the neural network sees our whole training data. So, we can say one epoch is equal to one forward pass and one backward pass for all training samples.</li>
      <li class="bullet"><strong class="keyword">Batch size</strong>: The <a id="_idIndexMarker684"/>batch size specifies the number of training samples we use in one forward pass and one backward pass.</li>
      <li class="bullet"><strong class="keyword">Number of iterations</strong>: The <a id="_idIndexMarker685"/>number of iterations implies the number of passes where <em class="italic">one pass = one forward pass + one backward pass</em>.</li>
    </ul>
    <p class="normal">Say that we have 12,000 training samples and our batch size is 6,000. Then it will take us two iterations to complete one epoch. That is, in the first iteration, we pass the first 6,000 samples <a id="_idIndexMarker686"/>and perform a forward pass and a backward pass; in the second iteration, we pass the next 6,000 samples and perform a forward pass and a backward pass. After two iterations, our neural network will see the whole 12,000 training samples, which makes it one epoch.</p>
    <h1 id="_idParaDest-180" class="title">Putting it all together</h1>
    <p class="normal">Putting all the <a id="_idIndexMarker687"/>concepts we have learned so far together, we will see how to build a neural network from scratch. We will understand how the neural network learns to perform the XOR gate operation. The XOR gate returns 1 only when exactly only one of its inputs is 1, else it returns 0, as shown in <em class="italic">Table 7.1</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_13.png" alt=""/></figure>
    <p class="packt_figref">Table 7.1: XOR operation</p>
    <h2 id="_idParaDest-181" class="title">Building a neural network from scratch</h2>
    <p class="normal">To perform <a id="_idIndexMarker688"/>the XOR gate operation, we build a simple two-layer neural network, as shown in the following diagram. As you can see, we have an input layer with two nodes, a hidden layer with five nodes and an output layer comprising one node:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_14.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.13: ANN</p>
    <p class="normal">We will <a id="_idIndexMarker689"/>understand step-by-step how a neural network learns the XOR logic:</p>
    <ol>
      <li class="numbered">First, import the libraries:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline
</code></pre>
      </li>
      <li class="numbered">Prepare the data as shown in the preceding XOR table:
        <pre class="programlisting code"><code class="hljs-code">X = np.array([ [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>],[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] ])
y = np.array([ [<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>], [<span class="hljs-number">0</span>]])
</code></pre>
      </li>
      <li class="numbered">Define the number of nodes in each layer:
        <pre class="programlisting code"><code class="hljs-code">num_input = <span class="hljs-number">2</span>
num_hidden = <span class="hljs-number">5</span>
num_output = <span class="hljs-number">1</span>
</code></pre>
      </li>
      <li class="numbered">Initialize the weights and bias randomly. First, we initialize the input to hidden layer weights:
        <pre class="programlisting code"><code class="hljs-code">Wxh = np.random.randn(num_input,num_hidden)
bh = np.zeros((<span class="hljs-number">1</span>,num_hidden))
</code></pre>
      </li>
      <li class="numbered">Now, we initialize the hidden to output layer weights:
        <pre class="programlisting code"><code class="hljs-code">Why = np.random.randn (num_hidden,num_output)
by = np.zeros((<span class="hljs-number">1</span>,num_output))
</code></pre>
      </li>
      <li class="numbered">Define the sigmoid activation function:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">sigmoid</span><span class="hljs-function">(</span><span class="hljs-params">z</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span>+np.exp(-z))
</code></pre>
      </li>
      <li class="numbered">Define the derivative of the sigmoid function:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">sigmoid_derivative</span><span class="hljs-function">(</span><span class="hljs-params">z</span><span class="hljs-function">):</span>
     <span class="hljs-keyword">return</span> np.exp(-z)/((<span class="hljs-number">1</span>+np.exp(-z))**<span class="hljs-number">2</span>)
</code></pre>
      </li>
      <li class="numbered">Define <a id="_idIndexMarker690"/>the forward propagation:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">forward_prop</span><span class="hljs-function">(</span><span class="hljs-params">x,Wxh,Why</span><span class="hljs-function">):</span>
    z1 = np.dot(x,Wxh) + bh
    a1 = sigmoid(z1)
    z2 = np.dot(a1,Why) + by
    y_hat = sigmoid(z2)
    
    <span class="hljs-keyword">return</span> z1,a1,z2,y_hat
</code></pre>
      </li>
      <li class="numbered">Define the backward propagation:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">backword_prop</span><span class="hljs-function">(</span><span class="hljs-params">y_hat, z1, a1, z2</span><span class="hljs-function">):</span>
    delta2 = np.multiply(-(y-y_hat),sigmoid_derivative(z2))
    dJ_dWhy = np.dot(a1.T, delta2)
    delta1 = np.dot(delta2,Why.T)*sigmoid_derivative(z1)
    dJ_dWxh = np.dot(x.T, delta1) 
    <span class="hljs-keyword">return</span> dJ_dWxh, dJ_dWhy
</code></pre>
      </li>
      <li class="numbered">Define the cost function:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">cost_function</span><span class="hljs-function">(</span><span class="hljs-params">y, y_hat</span><span class="hljs-function">):</span>
    J = <span class="hljs-number">0.5</span>*sum((y-y_hat)**<span class="hljs-number">2</span>)
    
    <span class="hljs-keyword">return</span> J
</code></pre>
      </li>
      <li class="numbered">Set the learning rate and the number of training iterations:
        <pre class="programlisting code"><code class="hljs-code">alpha = <span class="hljs-number">0.01</span>
num_iterations = <span class="hljs-number">5000</span>
</code></pre>
      </li>
      <li class="numbered">Now, let's <a id="_idIndexMarker691"/>start training the network with the following code:
        <pre class="programlisting code"><code class="hljs-code">cost =[]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_iterations):
    z1,a1,z2,y_hat = forward_prop(X,Wxh,Why)    
    dJ_dWxh, dJ_dWhy = backword_prop(y_hat, z1, a1, z2)
        
    <span class="hljs-comment">#update weights</span>
    Wxh = Wxh -alpha * dJ_dWxh
    Why = Why -alpha * dJ_dWhy
    
    <span class="hljs-comment">#compute cost</span>
    c = cost_function(y, y_hat)
    
    cost.append(c)
</code></pre>
      </li>
      <li class="numbered">Plot the cost function:
        <pre class="programlisting code"><code class="hljs-code">plt.grid()
plt.plot(range(num_iterations),cost)
plt.title(<span class="hljs-string">'Cost Function'</span>)
plt.xlabel(<span class="hljs-string">'Training Iterations'</span>)
plt.ylabel(<span class="hljs-string">'Cost'</span>)
</code></pre>
      </li>
    </ol>
    <p class="normal">As you can observe in the following plot, the loss decreases over the training iterations:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_15.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.14: Cost function</p>
    <p class="normal">Thus, we <a id="_idIndexMarker692"/>have an overall understanding of ANNs and how they learn.</p>
    <h1 id="_idParaDest-182" class="title">Recurrent Neural Networks</h1>
    <p class="normal"><em class="italic">The sun rises in the ____.</em></p>
    <p class="normal">If we were <a id="_idIndexMarker693"/>asked to predict the blank term in the preceding sentence, we would probably say east. Why would we predict that the word east would be the right word here? Because we read the whole sentence, understood the context, and predicted that the word east would be an appropriate word to complete the sentence.</p>
    <p class="normal">If we use a feedforward neural network (the one we learned in the previous section) to predict the blank, it would not predict the right word. This is due to the fact that in feedforward networks, each input is independent of other input and they make predictions based only on the current input, and they don't remember previous input.</p>
    <p class="normal">Thus, the input to the network will just be the word preceding the blank, which is the word <em class="italic">the</em>. With this word alone as an input, our network cannot predict the correct word, because it doesn't know the context of the sentence, which means that it doesn't know the previous set of words to understand the context of the sentence and to predict an appropriate next word.</p>
    <p class="normal">Here is where we use <strong class="keyword">Recurrent Neural Networks</strong> (<strong class="keyword">RNNs</strong>). They predict output not only based on the current input, but also on the previous hidden state. Why do they have to predict the output based on the current input and the previous hidden state? Why can't they just use the current input and the previous input?</p>
    <p class="normal">This is because the previous input will only store information about the previous word, while the previous hidden state will capture the contextual information about all the words in the sentence that the network has seen so far. Basically, the previous hidden state acts <a id="_idIndexMarker694"/>like memory, and it captures the context of the sentence. With this context and the current input, we can predict the relevant word.</p>
    <p class="normal">For instance, let's take the same sentence, <em class="italic">The sun rises in the ____.</em> As shown in the following figure, we first pass the word <em class="italic">the</em> as an input, and then we pass the next word, <em class="italic">sun</em>, as input; but along with this, we also pass the previous hidden state, <em class="italic">h</em><sub class="Subscript--PACKT-">0</sub>. So, every time we pass the input word, we also pass a previous hidden state as an input.</p>
    <p class="normal">In the final step, we pass the word <em class="italic">the</em>, and also the previous hidden state <em class="italic">h</em><sub class="Subscript--PACKT-">3</sub>, which captures the contextual information about the sequence of words that the network has seen so far. Thus, <em class="italic">h</em><sub class="Subscript--PACKT-">3</sub> acts as the memory and stores information about all the previous words that the network has seen. With <em class="italic">h</em><sub class="Subscript--PACKT-">3</sub> and the current input word (<em class="italic">the</em>), we can predict the relevant next word:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_16.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.15: RNN</p>
    <p class="normal">In a nutshell, an RNN uses the previous hidden state as memory, which captures and stores the contextual information (input) that the network has seen so far.</p>
    <p class="normal">RNNs are <a id="_idIndexMarker695"/>widely applied for use cases that involve sequential data, such as time series, text, audio, speech, video, weather, and much more. They have been greatly used in various <strong class="keyword">natural language processing</strong> (<strong class="keyword">NLP</strong>) tasks, such as language translation, sentiment analysis, text generation, and so on.</p>
    <h2 id="_idParaDest-183" class="title">The difference between feedforward networks and RNNs</h2>
    <p class="normal">A <a id="_idIndexMarker696"/>comparison between <a id="_idIndexMarker697"/>an RNN and a feedforward network is shown in the <em class="italic">Figure 7.16</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_17.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.16: Difference between feedforward network and RNN</p>
    <p class="normal">As you can observe in the preceding diagram, the RNN contains a looped connection in the hidden layer, which implies that we use the previous hidden state along with the input to predict the output.</p>
    <p class="normal">Still confused? Let's look at the following unrolled version of an RNN. But wait; what is the unrolled version of an RNN?</p>
    <p class="normal">It means that we roll out the network for a complete sequence. Let's suppose that we have an input sentence with <em class="italic">T</em> words; then, we will have 0 to <em class="italic">T</em>—1 layers, one for each word, as shown in <em class="italic">Figure 7.17</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_18.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.17: Unrolled RNN</p>
    <p class="normal">As you can see in <em class="italic">Figure 7.17</em>, at the time step <em class="italic">t</em> = 1, the output <em class="italic">y</em><sub class="Subscript--PACKT-">1</sub> is predicted based on <a id="_idIndexMarker698"/>the current input <em class="italic">x</em><sub class="Subscript--PACKT-">1</sub> and the previous hidden state <em class="italic">h</em><sub class="Subscript--PACKT-">0</sub>. Similarly, at time step <em class="italic">t</em> = 2, <em class="italic">y</em><sub class="Subscript--PACKT-">2</sub> is predicted <a id="_idIndexMarker699"/>using the current input <em class="italic">x</em><sub class="Subscript--PACKT-">2</sub> and the previous hidden state <em class="italic">h</em><sub class="Subscript--PACKT-">1</sub>. This is how an RNN works; it takes the current input and the previous hidden state to predict the output.</p>
    <h2 id="_idParaDest-184" class="title">Forward propagation in RNNs</h2>
    <p class="normal">Let's look at <a id="_idIndexMarker700"/>how an RNN uses forward propagation to predict the output; but before we jump right in, let's get familiar with the notations:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_19.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.18: Forward propagation in RNN</p>
    <p class="normal">The preceding figure illustrates the following:</p>
    <ul>
      <li class="bullet"><em class="italic">U</em> represents the input to hidden layer weight matrix</li>
      <li class="bullet"><em class="italic">W</em> represents the hidden to hidden layer weight matrix</li>
      <li class="bullet"><em class="italic">V</em> represents the hidden to output layer weight matrix</li>
    </ul>
    <p class="normal">The hidden state <em class="italic">h</em> at a time step <em class="italic">t</em> can be computed as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_051.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">That is, <em class="italic">the</em> <em class="italic">hidden state at a time step, t = tanh([input to hidden layer weight x input]</em> + <em class="italic">[hidden to hidden layer weight x previous hidden state])</em>.</p>
    <p class="normal">The output at a time step <em class="italic">t</em> can be computed as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_052.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">That is, <em class="italic">the</em> <em class="italic">output at a time step, t = softmax (hidden to output layer weight</em> x <em class="italic">hidden state at a time t)</em>.</p>
    <p class="normal">We can also represent RNNs as shown in the following figure. As you can see, the hidden layer is represented by an RNN block, which implies that our network is an RNN, and previous hidden states are used in predicting the output:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_20.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.19: Forward propagation in an RNN</p>
    <p class="normal"><em class="italic">Figure 7.20</em> shows <a id="_idIndexMarker701"/>how forward propagation works in an unrolled version of an RNN:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_21.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.20: Unrolled version – forward propagation in an RNN</p>
    <p class="normal">We initialize the initial hidden state <em class="italic">h</em><sub class="" style="font-style: italic;">init</sub> with random values. As you can see in the preceding figure, the output, <img src="../Images/B15558_07_053.png" alt="" style="height: 1.11em;"/>, is predicted based on the current input, <em class="italic">x</em><sub class="" style="font-style: italic;">0</sub> and the previous hidden state, which is an initial hidden state, <em class="italic">h</em><sub class="" style="font-style: italic;">init</sub>, using the following formula:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_054.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_055.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Similarly, look <a id="_idIndexMarker702"/>at how the output, <img src="../Images/B15558_07_056.png" alt="" style="height: 1.11em;"/>, is computed. It takes the current input, <em class="italic">x</em><sub class="Subscript--PACKT-">1</sub>, and the previous hidden state, <em class="italic">h</em><sub class="Subscript--PACKT-">0</sub>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_057.png" alt="" style="height: 1.11em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_058.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Thus, in forward propagation to predict the output, RNN uses the current input and the previous hidden state.</p>
    <h2 id="_idParaDest-185" class="title">Backpropagating through time</h2>
    <p class="normal">We <a id="_idIndexMarker703"/>just learned how forward propagation works in RNNs and how it predicts the output. Now, we compute the loss, <em class="italic">L</em>, at each time step, <em class="italic">t</em>, to determine how well the RNN has predicted the output. We use the cross-entropy loss as our loss function. The loss <em class="italic">L</em> at a time step <em class="italic">t</em> can be given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_059.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Here, <em class="italic">y</em><sub class="" style="font-style: italic;">t</sub> is the actual output, and <img src="../Images/B15558_07_060.png" alt="" style="height: 1.11em;"/> is the predicted output at a time step <em class="italic">t</em>.</p>
    <p class="normal">The final loss is a sum of the loss at all the time steps. Suppose that we have <em class="italic">T</em> - 1 layers; then, the final loss can be given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_061.png" alt="" style="height: 3.51em;"/></figure>
    <p class="normal"><em class="italic">Figure 7.21</em> shows that the final loss is obtained by the sum of loss at all the time steps:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_22.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.21: Backpropagation in an RNN</p>
    <p class="normal">We computed the loss, now our goal is to minimize the loss. How can we minimize the loss? We <a id="_idIndexMarker704"/>can minimize the loss by finding the optimal weights of the RNN. As we learned, we have three weights in RNNs: input to hidden, <em class="italic">U</em>, hidden to hidden, <em class="italic">W</em>, and hidden to output, <em class="italic">V</em>.</p>
    <p class="normal">We need to find optimal values for all of these three weights to minimize the loss. We can use our favorite gradient descent algorithm to find the optimal weights. We begin by calculating the gradients of the loss function with respect to all the weights; then, we update the weights according to the weight update rule as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_062.png" alt="" style="height: 2.22em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_063.png" alt="" style="height: 2.22em;"/></figure>
    <figure class="mediaobject"><img src="../Images/B15558_07_064.png" alt="" style="height: 2.22em;"/></figure>
    <p class="normal">However, we have a problem with the RNN. The gradient calculation involves calculating the gradient with respect to the activation function. When we calculate the gradient with respect to the sigmoid or tanh function, the gradient will become very small. When we further backpropagate the network over many time steps and multiply the gradients, the gradients will tend to get smaller and smaller. This is called a vanishing gradient problem. </p>
    <p class="normal">Since <a id="_idIndexMarker705"/>the gradient vanishes over time, we cannot learn information about long-term dependencies, that is, RNNs cannot retain information for a long time in the memory. The vanishing gradient problem occurs not only in RNNs but also in other deep networks where we have many hidden layers and when we use sigmoid/tanh functions.</p>
    <p class="normal">One solution to avoid vanishing gradient problem is to use ReLU as an activation function. However, we have a variant of the RNN called <strong class="keyword">Long Short-Term Memory</strong> (<strong class="keyword">LSTM</strong>), which can solve the vanishing gradient problem effectively. We will see how it works in the upcoming section.</p>
    <h1 id="_idParaDest-186" class="title">LSTM to the rescue</h1>
    <p class="normal">While <a id="_idIndexMarker706"/>backpropagating an RNN, we learned about a <a id="_idIndexMarker707"/>problem called <strong class="keyword">vanishing gradients</strong>. Due to the vanishing gradient problem, we cannot train the network properly, and this causes the RNN to not retain long sequences in the memory. To understand what we mean by this, let's consider a small sentence:</p>
    <p class="normal"><em class="italic">The sky is __</em>.</p>
    <p class="normal">An RNN can easily predict the blank as <em class="italic">blue</em> based on the information it has seen, but it cannot cover the long-term dependencies. What does that mean? Let's consider the following sentence to understand the problem better:</p>
    <p class="normal"><em class="italic">Archie lived in China for 13 years. He loves listening to good music. He is a fan of comics. He is fluent in ____.</em></p>
    <p class="normal">Now, if we were asked to predict the missing word in the preceding sentence, we would predict it as <em class="italic">Chinese</em>, but how did we predict that? We simply remembered the previous sentences and understood that Archie lived for 13 years in China. This led us to the conclusion that Archie might be fluent in Chinese. An RNN, on the other hand, cannot retain all of this information in its memory to say that Archie is fluent in Chinese. </p>
    <p class="normal">Due to the vanishing gradient problem, it cannot recollect/remember information for a long time in its memory. That is, when the input sequence is long, the RNN memory (hidden state) cannot hold all the information. To alleviate this, we use an LSTM cell.</p>
    <p class="normal">LSTM is a <a id="_idIndexMarker708"/>variant of an RNN that resolves the vanishing gradient problem and retains information in the memory as long as it is required. Basically, RNN cells are replaced with LSTM cells in the hidden units, as shown in <em class="italic">Figure 7.22</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_23.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.22: LSTM network</p>
    <p class="normal">In the next section, we will understand how the LSTM cells works.</p>
    <h2 id="_idParaDest-187" class="title">Understanding the LSTM cell</h2>
    <p class="normal">What makes <a id="_idIndexMarker709"/>LSTM cells so special? How do LSTM cells achieve long-term dependency? How does it know what information to keep and what information to discard from the memory?</p>
    <p class="normal">This is all <a id="_idIndexMarker710"/>achieved by special structures called <strong class="keyword">gates</strong>. As shown in the following diagram, a typical LSTM cell consists of three special gates called the input gate, output gate, and forget gate:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_24.jpg" alt=""/></figure>
    <p class="packt_figref">Figure 7.23: LSTM gates</p>
    <p class="normal">These three <a id="_idIndexMarker711"/>gates are responsible for deciding what information to add, output, and forget from the memory. With these gates, an LSTM cell effectively keeps information in the memory only as long as required.<em class="italic"> Figure 7.24</em> shows a typical LSTM cell:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_25.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.24: LSTM cell</p>
    <p class="normal">If you look at the LSTM cell, the top horizontal line is called the cell state. It is where the information flows. Information on the cell state will be constantly updated by LSTM gates. Now, we will see the function of these gates:</p>
    <p class="normal"><strong class="keyword">Forget gate</strong>: The forget gate <a id="_idIndexMarker712"/>is responsible for deciding what information should not be in the cell state. Look at the following statement: </p>
    <p class="normal"><em class="italic">Harry is a good singer. He lives in New York. Zayn is also a good singer.</em></p>
    <p class="normal">As soon as we start talking about Zayn, the network will understand that the subject has been <a id="_idIndexMarker713"/>changed from Harry to Zayn and the information about Harry is no longer required. Now, the forget gate will remove/forget information about Harry from the cell state.</p>
    <p class="normal"><strong class="keyword">Input gate</strong>: The input gate <a id="_idIndexMarker714"/>is responsible for deciding what information should be stored in the memory. Let's consider the same example:</p>
    <p class="normal"><em class="italic">Harry is a good singer. He lives in New York. Zayn is also a good singer.</em></p>
    <p class="normal">So, after the forget gate removes information from the cell state, the input gate decides what information <a id="_idIndexMarker715"/>has to be in the memory. Here, since the information about Harry is removed from the cell state by the forget gate, the input gate decides to update the cell state with the information about Zayn.</p>
    <p class="normal"><strong class="keyword">Output gate</strong>: The output <a id="_idIndexMarker716"/>gate is responsible for deciding what information should be shown from the cell state at a time, <em class="italic">t</em>. Now, consider the following sentence:</p>
    <p class="normal"><em class="italic">Zayn's debut album was a huge success. Congrats ____.</em></p>
    <p class="normal">Here, congrats is an adjective which is used to describe a noun. The output layer will predict Zayn (noun), to fill in the blank. </p>
    <p class="normal">Thus, using LSTM, we can overcome the vanishing gradient problem faced in RNN. In the next section, we will learn another interesting algorithm called the <strong class="keyword">Convolutional Neural Network</strong> (<strong class="keyword">CNN</strong>).</p>
    <h1 id="_idParaDest-188" class="title">What are CNNs?</h1>
    <p class="normal">A CNN, also <a id="_idIndexMarker717"/>known as a <strong class="keyword">ConvNet</strong>, is one of the most <a id="_idIndexMarker718"/>widely used deep learning algorithms for computer vision tasks. Let's say we are performing an image-recognition task. Consider the following image. </p>
    <p class="normal">We want our CNN to recognize that it contains a horse:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_26.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.25: Image containing a horse</p>
    <p class="normal">How can we do that? When we feed the image to a computer, it basically converts it into a <a id="_idIndexMarker719"/>matrix of pixel values. The pixel values range from 0 to 255, and the dimensions of this matrix will be of [<em class="italic">image width </em>x<em class="italic"> image height </em>x<em class="italic"> number of channels</em>]. A grayscale image has one channel, and colored images have three channels, <strong class="keyword">red, green, and blue</strong> (<strong class="keyword">RGB</strong>).</p>
    <p class="normal">Let's say we <a id="_idIndexMarker720"/>have a colored input image with a width of 11 and a height of 11, that is 11 x 11, then our matrix dimension would be <em class="italic">[11 </em>x<em class="italic"> 11 </em>x<em class="italic"> 3]</em>. As you can see in <em class="italic">[11 </em>x<em class="italic"> 11 </em>x<em class="italic"> 3]</em>, 11 x 11 represents the image width and height and 3 represents the channel number, as we have a colored image. So, we will have a 3D matrix.</p>
    <p class="normal">But it is hard to visualize a 3D matrix, so, for the sake of understanding, let's consider a grayscale image as our input. Since the grayscale image has only one channel, we will get a 2D matrix.</p>
    <p class="normal">As shown in the following diagram, the input grayscale image will be converted into a matrix of pixel values ranging from 0 to 255, with the pixel values representing the intensity of pixels at that point:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_27.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.26: Input image is converted to matrix of pixel values</p>
    <div class="note">
      <p class="Information-Box--PACKT-">The values given in the input matrix are just arbitrary values for our understanding.</p>
    </div>
    <p class="normal">Okay, now <a id="_idIndexMarker721"/>we have an input matrix of pixel values. What happens next? How does the CNN come to understand that the image contains a horse? CNNs consists of the following three important layers:</p>
    <ul>
      <li class="bullet">The convolutional layer</li>
      <li class="bullet">The pooling layer</li>
      <li class="bullet">The fully connected layer</li>
    </ul>
    <p class="normal">With the help of these three layers, the CNN recognizes that the image contains a horse. Now we will explore each of these layers in detail.</p>
    <h2 id="_idParaDest-189" class="title">Convolutional layers</h2>
    <p class="normal">The convolutional layer is the first and core layer of the CNN. It is one of the building blocks <a id="_idIndexMarker722"/>of a CNN and is used for extracting important features from the image.</p>
    <p class="normal">We have an image of a horse. What do you think are the features that will help us to understand that this is an image of a horse? We can say body structure, face, legs, tail, and so on. But how does the CNN understand these features? This is where we use a convolution operation that will extract all the important features from the image that characterize the horse. So, the convolution operation helps us to understand what the image is all about.</p>
    <p class="normal">Okay, what exactly is this convolution operation? How it is performed? How does it extract the important features? Let's look at this in detail.</p>
    <p class="normal">As we know, every input image is represented by a matrix of pixel values. Apart from the input matrix, we <a id="_idIndexMarker723"/>also have another matrix called the <strong class="keyword">filter matrix</strong>. </p>
    <p class="normal">The filter <a id="_idIndexMarker724"/>matrix is also known as a <strong class="keyword">kernel</strong>, or <a id="_idIndexMarker725"/>simply a <strong class="keyword">filter</strong>, as shown in the <em class="italic">Figure 7.27</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_28.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.27: Input and filter matrix</p>
    <p class="normal">We take <a id="_idIndexMarker726"/>the filter matrix, slide it over the input matrix by one pixel, perform element-wise multiplication, sum the results, and produce a single number. That's pretty confusing, isn't it? Let's understand this better with the aid of the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_29.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.28: Convolution operation</p>
    <p class="normal">As you can see in the previous diagram, we took the filter matrix and placed it on top of the input matrix, performed element-wise multiplication, summed their results, and produced the single number. This is demonstrated as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_065.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Now, we slide the filter over the input matrix by one pixel and perform the same steps, as shown in <em class="italic">Figure 7.29</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_30.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.29: Convolution operation</p>
    <p class="normal">This is demonstrated as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_066.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Again, we slide <a id="_idIndexMarker727"/>the filter matrix by one pixel and perform the same operation, as shown in <em class="italic">Figure 7.30</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_31.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.30: Convolution operation</p>
    <p class="normal">This is demonstrated as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_067.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Now, again, we slide the filter matrix over the input matrix by one pixel and perform the same operation, as shown in <em class="italic">Figure 7.31</em>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_32.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.31: Convolution operation</p>
    <p class="normal">That is:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_068.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Okay. What are <a id="_idIndexMarker728"/>we doing here? We are basically sliding the filter matrix over the entire input matrix by one pixel, performing element-wise multiplication <a id="_idIndexMarker729"/>and summing their results, which creates a new matrix <a id="_idIndexMarker730"/>called a <strong class="keyword">feature map</strong> or <strong class="keyword">activation map</strong>. This is called the <strong class="keyword">convolution operation</strong>.</p>
    <p class="normal">As we've <a id="_idIndexMarker731"/>learned, the convolution operation is used to extract features, and the new matrix, that is, the feature maps, represents the extracted features. If we plot the feature maps, then we can see the features extracted by the convolution operation.</p>
    <p class="normal"><em class="italic">Figure 7.32</em> shows the actual image (the input image) and the convolved image (the feature map). We can see that our filter has detected the edges from the actual image as a feature:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_33.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.32: Conversion of actual image to convolved image</p>
    <p class="normal">Various filters are used for extracting different features from the image. For instance, if we use a sharpen filter, <img src="../Images/B15558_07_069.png" alt="" style="height: 3.16em;"/>, then it will sharpen our image, as shown in the following figure:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_34.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.33: Sharpened image</p>
    <p class="normal">Thus, we have <a id="_idIndexMarker732"/>learned that with filters, we can extract important features from the image using the convolution operation. So, instead of using one filter, we can use multiple filters to extract different features from the image and produce multiple feature maps. So, the depth of the feature map will be the number of filters. If we use seven filters to extract different features from the image, then the depth of our feature map will be seven:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_35.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.34: Feature maps</p>
    <p class="normal">Okay, we have learned that different filters extract different features from the image. But the question is, how can we set the correct values for the filter matrix so that we can extract <a id="_idIndexMarker733"/>the important features from the image? Worry not! We just initialize the filter matrix randomly, and the optimal values of the filter matrix, with which we can extract the important features from the images, will be learned through backpropagation. However, we just need to specify the size of the filter and the number of filters we want to use.</p>
    <h3 id="_idParaDest-190" class="title">Strides</h3>
    <p class="normal">We have <a id="_idIndexMarker734"/>just learned how a convolution operation works. We slide over the input matrix with the filter matrix by one pixel and perform the convolution operation. But we don't have to only slide over the input matrix by one pixel, we can also slide over the input matrix by any number of pixels.</p>
    <p class="normal">The number <a id="_idIndexMarker735"/>of pixels we slide over the input matrix by the filter matrix is called a <strong class="keyword">stride</strong>.</p>
    <p class="normal">If we set the stride to 2, then we slide over the input matrix with the filter matrix by two pixels. <em class="italic">Figure 7.35</em> shows a convolution operation with a stride of 2:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_36.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.35: Stride operation</p>
    <p class="normal">But how do <a id="_idIndexMarker736"/>we choose the stride number? We just learned that a stride is the number of pixels along that we move our filter matrix. So, when the stride <a id="_idIndexMarker737"/>is set to a small number, we can encode a more detailed representation of the image than when the stride is set to a large number. However, a stride with a high value takes less time to compute than one with a low value.</p>
    <h3 id="_idParaDest-191" class="title">Padding</h3>
    <p class="normal">With the <a id="_idIndexMarker738"/>convolution operation, we are sliding over the input matrix with a filter matrix. But in some cases, the filter does not perfectly fit the input <a id="_idIndexMarker739"/>matrix. What do we mean by that? For example, let's say we are performing a convolution operation with a stride of 2. There exists a situation where, when we move our filter matrix by two pixels, it reaches the border and the filter matrix does not fit the input matrix. That is, some part of our filter matrix is outside the input matrix, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_37.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.36: Padding operation</p>
    <p class="normal">In this case, we perform padding. We can simply pad the input matrix with zeros so that the filter <a id="_idIndexMarker740"/>can fit the input matrix, as shown in <em class="italic">Figure 7.37</em>. Padding <a id="_idIndexMarker741"/>with zeros on the input matrix is called <strong class="keyword">same padding</strong> or <strong class="keyword">zero padding</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_38.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.37: Same padding</p>
    <p class="normal">Instead <a id="_idIndexMarker742"/>of padding them with zeros, we can also simply discard the region <a id="_idIndexMarker743"/>of the input matrix where the filter doesn't fit in. This is <a id="_idIndexMarker744"/>called <strong class="keyword">valid padding</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_39.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.38: Valid padding</p>
    <h2 id="_idParaDest-192" class="title">Pooling layers</h2>
    <p class="normal">Okay. Now, we are <a id="_idIndexMarker745"/>done with the convolution operation. As a result of the convolution operation, we have some feature maps. But the feature maps are too large in dimension. In order to reduce the dimensions of feature maps, we perform a pooling operation. This reduces the dimensions of the feature maps and keeps only the necessary details so that the amount of computation can be reduced.</p>
    <p class="normal">For example, to recognize a horse from the image, we need to extract and keep only the features of the horse; we can simply discard unwanted features, such as the background of the image and more. A pooling <a id="_idIndexMarker746"/>operation is also called a <strong class="keyword">downsampling</strong> or <strong class="keyword">subsampling</strong> operation, and it makes the CNN translation invariant. Thus, the <a id="_idIndexMarker747"/>pooling layer reduces spatial dimensions by keeping only the important features.</p>
    <p class="normal">There are different types of pooling operations, including max pooling, average pooling, and sum pooling.</p>
    <p class="normal">In max pooling, we slide over the filter on the input matrix and simply take the maximum value from the filter window, as <em class="italic">Figure 7.39</em> shows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_40.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.39: Max pooling</p>
    <p class="normal">In average pooling, we take the average value of the input matrix within the filter window, and in sum pooling, we sum all the values of the input matrix within the filter window.</p>
    <h2 id="_idParaDest-193" class="title">Fully connected layers</h2>
    <p class="normal">So far, we've <a id="_idIndexMarker748"/>learned how convolutional and pooling layers work. A CNN can have multiple convolutional layers and pooling layers. However, these layers will only extract features from the input image and produce the feature map; that is, they are just the feature extractors.</p>
    <p class="normal">Given any image, convolutional layers extract features from the image and produce a feature map. Now, we need to classify these extracted features. So, we need an algorithm that can classify these extracted features and tell us whether the extracted features are the features of a horse, or something else. In order to make this classification, we use a feedforward neural network. We flatten the feature map and convert it into a vector, and feed it as an input to the feedforward network. </p>
    <p class="normal">The feedforward <a id="_idIndexMarker749"/>network takes this flattened feature map as an input, applies an activation function, such as sigmoid, and returns the output, stating whether the image contains a horse or not; this is called a fully connected layer and is shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_41.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.40: Fully connected layer</p>
    <p class="normal">Let's see how all this fits together.</p>
    <h1 id="_idParaDest-194" class="title">The architecture of CNNs</h1>
    <p class="normal"><em class="italic">Figure 7.41</em> shows the <a id="_idIndexMarker750"/>architecture of a CNN:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_42.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.41: Architecture of CNN</p>
    <p class="normal">As you will notice, first we feed the input image to the convolutional layer, where we apply the <a id="_idIndexMarker751"/>convolution operation to extract important features from the image and create the feature maps. We then pass the feature maps to the pooling layer, where the dimensions of the feature maps will be reduced. </p>
    <p class="normal">As shown in the previous diagram, we can have multiple convolutional and pooling layers, and we should also note that the pooling layer does not necessarily have to be there after every convolutional layer; there can be many convolutional layers followed by a pooling layer.</p>
    <p class="normal">So, after the convolutional and pooling layers, we flatten the resultant feature maps and feed it to a fully connected layer, which is basically a feedforward neural network that classifies the given input image based on the feature maps.</p>
    <p class="normal">Now that we have learned how CNNs work, in the next section, we will learn about another interesting algorithm called the generative adversarial network.</p>
    <h1 id="_idParaDest-195" class="title">Generative adversarial networks</h1>
    <p class="normal"><strong class="keyword">Generative Adversarial Networks</strong> (<strong class="keyword">GANs</strong>) was first introduced by Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio in their paper, <em class="italic">Generative Adversarial Networks</em>, in 2014.</p>
    <p class="normal">GANs <a id="_idIndexMarker752"/>are used extensively for generating new data points. They can be applied to any type of dataset, but they are popularly used for generating images. Some of the applications of GANs include generating realistic human faces, converting grayscale images to colored images, translating text descriptions into realistic images, and many more.</p>
    <p class="normal">GANs have evolved so much in recent years that they can generate a very realistic image. The following figure shows the evolution of GANs in generating images over the course of five years:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_43.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.42: Evolution of GANs over the years</p>
    <p class="normal">Excited about GANs already? Now, we will see how exactly they work. Before going ahead, let's <a id="_idIndexMarker753"/>consider a simple analogy. Let's say you are the police and your task is to find counterfeit money, and the role of the counterfeiter is to create fake money and cheat the police.</p>
    <p class="normal">The counterfeiter constantly tries to create fake money in a way that is so realistic that it cannot be differentiated from the real money. But the police have to identify whether the money is real or fake. So, the counterfeiter and the police essentially play a two-player game where one tries to defeat the other. GANs work something like this. They consist of two important components:</p>
    <ul>
      <li class="bullet">Generator</li>
      <li class="bullet">Discriminator</li>
    </ul>
    <p class="normal">You can perceive the generator as analogous to the counterfeiter, while the discriminator is analogous to the police. That is, the role of the generator is to create fake money, and the role of the discriminator is to identify whether the money is fake or real.</p>
    <p class="normal">Without going into detail, first, we will get a basic understanding of GANs. Let's say we want our GAN to generate handwritten digits. How can we do that? First, we will take a dataset containing a collection of handwritten digits; say, the MNIST dataset. The generator learns the distribution of images in our dataset. Thus, it learns the distribution of handwritten digits in our training set. Once, it learns the distribution of the images in our dataset, and we feed a random noise to the generator, it will convert the random noise into a new handwritten digit similar to the one in our training set based on the learned distribution:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_44.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.43: Generator</p>
    <p class="normal">The goal of the discriminator is to perform a classification task. Given an image, it classifies it as real or fake; that is, whether the image is from the training set or the image is generated by the generator:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_45.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.44: Discriminator</p>
    <p class="normal">The generator <a id="_idIndexMarker754"/>component of GAN is basically a generative model, and the discriminator component is basically a discriminative model. Thus, the generator learns the distribution of the class and the discriminator learns the decision boundary of a class.</p>
    <p class="normal">As <em class="italic">Figure 7.45</em> shows, we feed random noise to the generator, and it then converts this random noise into a new image similar to the one we have in our training set, but not exactly the same as the images in the training set. The image generated by the generator is called a fake image, and the images in our training set are called real images. We feed both the real and fake images to the discriminator, which tells us the probability of them being real. It returns 0 if the image is fake and 1 if the image is real:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_46.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.45: GAN</p>
    <p class="normal">Now that we have a basic understanding of generators and discriminators, we will study each of the components in detail.</p>
    <h2 id="_idParaDest-196" class="title">Breaking down the generator</h2>
    <p class="normal">The <a id="_idIndexMarker755"/>generator component of a GAN is a generative model. When we say the generative model, there are two types of generative models—an <strong class="keyword">implicit</strong> and an <strong class="keyword">explicit</strong> density model. The implicit <a id="_idIndexMarker756"/>density model does not use any <a id="_idIndexMarker757"/>explicit density function to learn the probability distribution, whereas the explicit density model, as the name suggests, uses an explicit density function. GANs falls into the first category. That is, they are an implicit density model. Let's study in detail and understand how GANs are an implicit density model.</p>
    <p class="normal">Let's say we have a generator, <em class="italic">G</em>. It is basically a neural network parametrized by <img src="../Images/B15558_07_070.png" alt="" style="height: 1.11em;"/>. The role of the generator network is to generate new images. How do they do that? What should be the input to the generator?</p>
    <p class="normal">We sample a random noise, <em class="italic">z</em>, from a normal or uniform distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">z</sub>. We feed this random noise, <em class="italic">z</em>, as an input to the generator and then it converts this noise to an image:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_071.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Surprising, isn't it? How does the generator convert random noise to a realistic image?</p>
    <p class="normal">Let's say we have a dataset containing a collection of human faces and we want our generator to generate a new human face. First, the generator learns all the features of the face by learning the probability distribution of the images in our training set. Once the generator learns the correct probability distribution, it can generate totally new human faces.</p>
    <p class="normal">But how does the generator learn the distribution of the training set? That is, how does the generator learn the distribution of images of human faces in the training set?</p>
    <p class="normal">A generator is nothing but a neural network. So, what happens is that the neural network learns the distribution of the images in our training set implicitly; let's call this distribution a generator distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub>. At the first iteration, the generator generates a really noisy image. But over a series of iterations, it learns the exact probability distribution <a id="_idIndexMarker758"/>of our training set and learns to generate a correct image by tuning its <img src="../Images/B15558_07_070.png" alt="" style="height: 1.11em;"/> parameter.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">It is important to note that we are not using the uniform distribution <em class="italic">P</em><sub class="" style="font-style: italic;">z</sub> for learning the distribution of our training set. It is only used for sampling random noise, and we feed this random noise as an input to the generator. The generator network implicitly learns the distribution of our training set and we call this distribution a generator distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub> and that is why we call our generator network an implicit density model.</p>
    </div>
    <p class="normal">Now that we understand the generator, let's move on to the discriminator.</p>
    <h2 id="_idParaDest-197" class="title">Breaking down the discriminator</h2>
    <p class="normal">As the <a id="_idIndexMarker759"/>name suggests, the discriminator is a discriminative model. Let's say we have a discriminator, <em class="italic">D</em>. It is also a neural network and it is parametrized by <img src="../Images/B15558_07_073.png" alt="" style="height: 1.11em;"/>.</p>
    <p class="normal">The goal of the discriminator is to discriminate between two classes. That is, given an image <em class="italic">x</em>, it has to identify whether the image is from a real distribution or a fake distribution (generator distribution). That is, the discriminator has to identify whether the given input image is from the training set or the fake image generated by the generator:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_074.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Let's call the distribution of our training set the real data distribution, which is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>. We know that the generator distribution is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub>.</p>
    <p class="normal">So, the discriminator <em class="italic">D</em> essentially tries to discriminate whether the image <em class="italic">x</em> is from <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub> or <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub>.</p>
    <h2 id="_idParaDest-198" class="title">How do they learn, though?</h2>
    <p class="normal">So far, we <a id="_idIndexMarker760"/>just studied the role of the generator and discriminator, but how do they learn exactly? How does the generator learn to generate new realistic images and how does the discriminator learn to discriminate between images correctly?</p>
    <p class="normal">We know that the goal of the generator is to generate an image in such a way as to fool the discriminator into believing that the generated image is from a real distribution.</p>
    <p class="normal">In the first iteration, the generator generates a noisy image. When we feed this image to the discriminator, it can easily detect that the image is from a generator distribution. The generator takes this as a loss and tries to improve itself, as its goal is to fool the discriminator. That is, if the generator knows that the discriminator is easily detecting the generated image as a fake image, then it means that it is not generating an image similar to those in the training set. This implies that it has not learned the probability distribution of the training set yet.</p>
    <p class="normal">So, the generator tunes its parameters in such a way as to learn the correct probability distribution of the training set. As we know that the generator is a neural network, we simply update the parameters of the network through backpropagation. Once it has learned the probability distribution of the real images, then it can generate images similar to the ones in the training set.</p>
    <p class="normal">Okay, what about the discriminator? How does it learn? As we know, the role of the discriminator is to discriminate between real and fake images.</p>
    <p class="normal">If the discriminator incorrectly classifies the generated image; that is, if the discriminator classifies the fake image as a real image, then it implies that the discriminator has not learned to differentiate between the real and fake image. So, we update the parameter of the discriminator network through backpropagation to make the discriminator learn to classify between real and fake images.</p>
    <p class="normal">So, basically, the generator is trying to fool the discriminator by learning the real data distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>, and the discriminator is trying to find out whether the image is from a real or fake distribution. Now the question is, when do we stop training the network in light of the fact that the generator and discriminator are competing against each other?</p>
    <p class="normal">Basically, the goal of the GAN is to generate images similar to the one in the training set. Say we want to generate a human face—we learn the distribution of images in the training set and generate new faces. So, for a generator, we need to find the optimal discriminator. What do we mean by that?</p>
    <p class="normal">We know that a generator distribution is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub> and the real data distribution is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>. If the generator learns the real data distribution perfectly, then <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub> equals <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>, as <em class="italic">Figure 7.46</em> shows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_47.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.46: Generator and real data distribution</p>
    <p class="normal">When <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub> = <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>, then the discriminator cannot differentiate between whether the input image <a id="_idIndexMarker761"/>is from a real or a fake distribution, so it will just return 0.5 as a probability, as the discriminator will become confused between the two distributions when they are the same.</p>
    <p class="normal">So, for a generator, the optimal discriminator can be given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_075.png" alt="" style="height: 2.6em;"/></figure>
    <p class="normal">So, when the discriminator just returns the probability of 0.5 for all the generator images, then we can say that the generator has learned the distribution of images in our training set and has fooled the discriminator successfully.</p>
    <h2 id="_idParaDest-199" class="title">Architecture of a GAN</h2>
    <p class="normal"><em class="italic">Figure 7.47</em> shows <a id="_idIndexMarker762"/>the architecture of a GAN:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_48.png" alt=""/></figure>
    <p class="packt_figref">Figure 7.47: Architecture of GAN</p>
    <p class="normal">As shown in the preceding diagram, generator <em class="italic">G</em> takes the random noise, <em class="italic">z</em>, as input by sampling from a uniform or normal distribution and generates a fake image by implicitly learning the distribution of the training set.</p>
    <p class="normal">We <a id="_idIndexMarker763"/>sample an image, <em class="italic">x</em>, from the real data distribution, <img src="../Images/B15558_07_076.png" alt="" style="height: 1.11em;"/>, and fake data distribution, <img src="../Images/B15558_07_077.png" alt="" style="height: 1.11em;"/>, and feed it to the discriminator, <em class="italic">D</em>. We feed real and fake images to the discriminator and the discriminator performs a binary classification task. That is, it returns 0 when the image is fake and 1 when the image is real.</p>
    <h2 id="_idParaDest-200" class="title">Demystifying the loss function</h2>
    <p class="normal">Now we <a id="_idIndexMarker764"/>will examine the loss function of the GAN. Before going ahead, let's recap the notation:</p>
    <ul>
      <li class="bullet">A noise that is fed as an input to the generator is represented by <em class="italic">z</em></li>
      <li class="bullet">The uniform or normal distribution from which the noise <em class="italic">z</em> is sampled is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">z</sub></li>
      <li class="bullet">An input image is represented by <em class="italic">x</em></li>
      <li class="bullet">The real data distribution or the distribution of our training set is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub></li>
      <li class="bullet">The fake data distribution or the distribution of the generator is represented by <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub></li>
    </ul>
    <p class="normal">When we write <img src="../Images/B15558_07_078.png" alt="" style="height: 1.11em;"/>, it implies that image <em class="italic">x</em> is sampled from the real distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>. Similarly, <img src="../Images/B15558_07_079.png" alt="" style="height: 1.11em;"/> denotes that image <em class="italic">x</em> is sampled from the generator distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub>, and <img src="../Images/B15558_07_080.png" alt="" style="height: 1.11em;"/> implies that the generator input, <em class="italic">z</em>, is sampled from the uniform distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">z</sub>.</p>
    <p class="normal">We've <a id="_idIndexMarker765"/>learned that both <a id="_idIndexMarker766"/>the generator and discriminator are neural networks and both of them update their parameters through backpropagation. We now need to find the optimal generator parameter, <img src="../Images/B15558_07_081.png" alt="" style="height: 1.11em;"/>, and the discriminator parameter, <img src="../Images/B15558_07_082.png" alt="" style="height: 1.11em;"/>.</p>
    <h3 id="_idParaDest-201" class="title">Discriminator loss</h3>
    <p class="normal">Now we will look at <a id="_idIndexMarker767"/>the loss function of the discriminator. We know that the goal of the discriminator is to classify whether the image is a real or a fake image. Let's denote the discriminator by <em class="italic">D</em>.</p>
    <p class="normal">The loss function of the discriminator is given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_083.png" alt="" style="height: 1.84em;"/></figure>
    <p class="normal">What does this mean, though? Let's understand each of the terms one by one.</p>
    <h4 class="title">First term</h4>
    <p class="normal">Let's <a id="_idIndexMarker768"/>look at the first term:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_084.png" alt="" style="height: 1.2em;"/></figure>
    <p class="normal">Here, <img src="../Images/B15558_07_085.png" alt="" style="height: 1.11em;"/> implies that we are sampling input <em class="italic">x</em> from the real data distribution, <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>, so <em class="italic">x</em> is a real image.</p>
    <p class="normal"><em class="italic">D</em>(<em class="italic">x</em>) implies that we are feeding the input image <em class="italic">x</em> to the discriminator <em class="italic">D</em>, and the discriminator will return the probability of input image <em class="italic">x</em> to be a real image. As <em class="italic">x</em> is sampled from real data distribution <em class="italic">P</em><sub class="" style="font-style: italic;">r</sub>, we know that <em class="italic">x</em> is a real image. So, we need to maximize the probability of <em class="italic">D</em>(<em class="italic">x</em>):</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_086.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">But instead <a id="_idIndexMarker769"/>of maximizing raw probabilities, we maximize log probabilities, so, we can write the following:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_087.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">So, our final equation becomes the following:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_088.png" alt="" style="height: 1.29em;"/></figure>
    <p class="normal"><img src="../Images/B15558_07_089.png" alt="" style="height: 1.29em;"/> represents the expectations of the log-likelihood of input images sampled from the real data distribution being real.</p>
    <h4 class="title">Second term</h4>
    <p class="normal">Now, let's <a id="_idIndexMarker770"/>look at the second term:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_090.png" alt="" style="height: 1.29em;"/></figure>
    <p class="normal">Here, <img src="../Images/B15558_07_091.png" alt="" style="height: 1.2em;"/> shows that we are sampling a random noise <em class="italic">z</em> from the uniform distribution <em class="italic">P</em><sub class="" style="font-style: italic;">z</sub>. <em class="italic">G</em>(<em class="italic">z</em>) implies that the generator <em class="italic">G</em> takes the random noise <em class="italic">z</em> as an input and returns a fake image based on its implicitly learned distribution <em class="italic">P</em><sub class="" style="font-style: italic;">g</sub>.</p>
    <p class="normal"><em class="italic">D</em>(<em class="italic">G</em>(<em class="italic">z</em>)) implies that we are feeding the fake image generated by the generator to the discriminator <em class="italic">D</em> and it will return the probability of the fake input image being a real image.</p>
    <p class="normal">If we subtract <em class="italic">D</em>(<em class="italic">G</em>(<em class="italic">z</em>)) from 1, then it will return the probability of the fake input image being a fake image:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_092.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Since we know <em class="italic">z</em> is not a real image, the discriminator will maximize this probability. That is, the discriminator maximizes the probability of <em class="italic">z</em> being classified as a fake image, so we write:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_093.png" alt="" style="height: 1.11em;"/></figure>
    <p class="normal">Instead of <a id="_idIndexMarker771"/>maximizing raw probabilities, we maximize the log probability:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_094.png" alt="" style="height: 1.76em;"/></figure>
    <p class="normal"><img src="../Images/B15558_07_095.png" alt="" style="height: 1.96em;"/> implies the expectations of the log likelihood of the input images generated by the generator being fake.</p>
    <h4 class="title">Final term</h4>
    <p class="normal">So, combining <a id="_idIndexMarker772"/>these two terms, the loss function of the discriminator is given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_083.png" alt="" style="height: 1.84em;"/></figure>
    <p class="normal">Here, <img src="../Images/B15558_07_097.png" alt="" style="height: 1.2em;"/> and <img src="../Images/B15558_07_098.png" alt="" style="height: 1.11em;"/> are the parameters of the generator and discriminator network respectively. So, the <a id="_idIndexMarker773"/>discriminator's goal is to find the right <img src="../Images/B15558_07_099.png" alt="" style="height: 1.11em;"/> so that it can classify the image correctly.</p>
    <h3 id="_idParaDest-202" class="title">Generator loss</h3>
    <p class="normal">The loss function of the generator is given as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_100.png" alt="" style="height: 1.96em;"/></figure>
    <p class="normal">We know <a id="_idIndexMarker774"/>that the goal of the generator is to fool the discriminator to classify the fake image as a real image.</p>
    <p class="normal">In the <em class="italic">Discriminator loss</em> section, we saw that <img src="../Images/B15558_07_101.png" alt="" style="height: 1.96em;"/> implies the probability of classifying the fake input image as a fake image, and the discriminator maximizes the probabilities for correctly classifying the fake image as fake.</p>
    <p class="normal">But the generator wants to minimize this probability. As the generator wants to fool the discriminator, it minimizes this probability of a fake input image being classified as fake by the discriminator. Thus, the loss function of the generator can be expressed as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_100.png" alt="" style="height: 1.96em;"/></figure>
    <h1 id="_idParaDest-203" class="title">Total loss</h1>
    <p class="normal">We just <a id="_idIndexMarker775"/>learned the loss function of the generator and the discriminator combining these two losses, and we write our final loss function as follows:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_103.png" alt="" style="height: 1.84em;"/></figure>
    <p class="normal">So, our objective function is basically a min-max objective function, that is, a maximization for the discriminator and a minimization for the generator, and we find the optimal generator parameter, <img src="../Images/B15558_07_104.png" alt="" style="height: 1.2em;"/>, and discriminator parameter, <img src="../Images/B15558_07_105.png" alt="" style="height: 1.11em;"/>, through backpropagating the respective networks.</p>
    <p class="normal">So, we perform <a id="_idIndexMarker776"/>gradient ascent; that is, maximization on the discriminator:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_106.png" alt="" style="height: 3.24em;"/></figure>
    <p class="normal">And, we perform gradient descent; that is, minimization on the generator:</p>
    <figure class="mediaobject"><img src="../Images/B15558_07_107.png" alt="" style="height: 3.24em;"/></figure>
    <h1 id="_idParaDest-204" class="title">Summary</h1>
    <p class="normal">We started off the chapter by understanding biological and artificial neurons. Then we learned about ANNs and their layers. We learned different types of activation functions and how they are used to introduce nonlinearity in the network.</p>
    <p class="normal">Later, we learned about the forward and backward propagation in the neural network. Next, we learned how to implement an ANN. Moving on, we learned about RNNs and how they differ from feedforward networks. Next, we learned about the variant of the RNN called LSTM. Going forward, we learned about CNNs, how they use different types of layers, and the architecture of CNNs in detail.</p>
    <p class="normal">At the end of the chapter, we learned about an interesting algorithm called GAN. We understood the generator and discriminator component of GAN and we also explored the architecture of GAN in detail. Followed by that, we examined the loss function of GAN in detail.</p>
    <p class="normal">In the next chapter, we will learn about one of the most popularly used deep learning frameworks, called TensorFlow.</p>
    <h1 id="_idParaDest-205" class="title">Questions</h1>
    <p class="normal">Let's assess our understanding of deep learning algorithms by answering the following questions:</p>
    <ol>
      <li class="numbered" value="1">What is the activation function?</li>
      <li class="numbered">Define the softmax function.</li>
      <li class="numbered">What is an epoch?</li>
      <li class="numbered">What are some of the applications of RNNs?</li>
      <li class="numbered">Explain the vanishing gradient problem.</li>
      <li class="numbered">What are the different types of pooling operations?</li>
      <li class="numbered">Explain the generator and discriminator components of GANs.</li>
    </ol>
    <h1 id="_idParaDest-206" class="title">Further reading</h1>
    <ul>
      <li class="bullet">To learn more about deep learning algorithms, you can check out my book<strong class="keyword"> Hands-on Deep Learning Algorithms with Python</strong>, also published by Packt, at <a href="https://www.packtpub.com/in/big-data-and-business-intelligence/hands-deep-learning-algorithms-python"><span class="url">https://www.packtpub.com/in/big-data-and-business-intelligence/hands-deep-learning-algorithms-python</span></a>.</li>
    </ul>
  </div>
</body></html>