["```\ndef preprocess_data(data):\ndata = data.drop(['Time'], axis=1)\ndata['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\nreturn\n data\n```", "```\ndef get_train_and_test_data(processed_data):\nX_train, X_test = train_test_split(processed_data, test_size=0.25, random_state=RANDOM_SEED)\nX_train = X_train[X_train.Class == 0]\nX_train = X_train.drop(['Class'], axis=1)\ny_test = X_test['Class']\nX_test = X_test.drop(['Class'], axis=1)\nX_train = X_train.values\nX_test = X_test.values\nreturn X_train, X_test,y_test\n```", "```\ndef define_model(self):\ndim_input = self.train_data.shape[1]\nlayer_input = Input(shape=(dim_input,))\nlayer_encoder = Dense(DIM_ENCODER, activation=\"tanh\",\nactivity_regularizer=regularizers.l1(10e-5))(layer_input)\nlayer_encoder = Dense(int(DIM_ENCODER / 2), activation=\"relu\")(layer_encoder)\nlayer_decoder = Dense(int(DIM_ENCODER / 2), activation='tanh')(layer_encoder)\nlayer_decoder = Dense(dim_input, activation='relu')(layer_decoder)\nautoencoder = Model(inputs=layer_input, outputs=layer_decoder)\nreturn autoencoder\n```", "```\ndef train_model(self):\nself.model.compile(optimizer=OPTIMIZER,\nloss=LOSS,\nmetrics=[EVAL_METRIC])\ncheckpoint = ModelCheckpoint(filepath=os.path.join(MODEL_SAVE_DIR, \"trained_model.h5\"),\nverbose=0,\nsave_best_only=True)\nlog_tensorboard = TensorBoard(log_dir='./logs',\nhistogram_freq=0,\nwrite_graph=True,\nwrite_images=True)\nhistory = self.model.fit(self.train_data, self.train_data,\nepochs=EPOCHS,\nbatch_size=BATCH_SIZE,\nshuffle=True,\nvalidation_data=(self.test_data, self.test_data),\nverbose=1,\ncallbacks=[checkpoint, log_tensorboard]).history\nself.history = history\nprint(\"Training Done. Plotting Loss Curves\")\nself.plot_loss_curves()\n```", "```\ndef plot_loss_curves(self):\nfig = plt.figure(num=\"Loss Curves\")\nfig.set_size_inches(12, 6)\nplt.plot(self.history['loss'])\nplt.plot(self.history['val_loss'])\nplt.title('Loss By Epoch')\nplt.ylabel('Loss')\nplt.xlabel('Epoch Num')\nplt.legend(['Train_Data', 'Test_Data'], loc='upper right');\nplt.grid(True, alpha=.25)\nplt.tight_layout()\nimage_name = 'Loss_Curves.png'\nfig.savefig(os.path.join(PLOTS_DIR,image_name), dpi=fig.dpi)\nplt.clf()\n```", "```\ndef plot_reconstruction_error_by_class(self):\nself.get_test_predictions()\nmse = np.mean(np.power(self.test_data - self.test_predictions, 2), axis=1)\nself.recon_error = pd.DataFrame({'recon_error': mse,\n'true_class': self.y_test})\n## Plotting the errors by class\n# Normal Transactions\nfig = plt.figure(num = \"Recon Error with Normal Transactions\")\nfig.set_size_inches(12, 6)\nax = fig.add_subplot(111)\nnormal_error_df = self.recon_error[(self.recon_error['true_class'] == 0) & (self.recon_error['recon_error'] < 50)]\n_ = ax.hist(normal_error_df.recon_error.values, bins=20)\nplt.xlabel(\"Recon Error Bins\")\nplt.ylabel(\"Num Samples\")\nplt.title(\"Recon Error with Normal Transactions\")\nplt.tight_layout()\nimage_name = \"Recon_Error_with_Normal_Transactions.png\"\nfig.savefig(os.path.join(PLOTS_DIR, image_name), dpi=fig.dpi)\nplt.clf()\n```", "```\ndef get_precision_recall_curves(self):\nprecision, recall, threshold = precision_recall_curve(self.recon_error.true_class, self.recon_error.recon_error)\n# Plotting the precision curve\nfig = plt.figure(num =\"Precision Curve\")\nfig.set_size_inches(12, 6)\nplt.plot(threshold, precision[1:], 'g', label='Precision curve')\nplt.title('Precision By Recon Error Threshold Values')\nplt.xlabel('Threshold')\nplt.ylabel('Precision')\nplt.tight_layout()\nimage_name = 'Precision_Threshold_Curve.png'\nfig.savefig(os.path.join(PLOTS_DIR, image_name), dpi=fig.dpi)\nplt.clf()\nplt.plot(threshold, recall[1:], 'g', label='Recall curve')\nplt.title('Recall By Recon Error Threshold Values')\nplt.xlabel('Threshold')\nplt.ylabel('Recall')\nplt.tight_layout()\nimage_name = 'Recall_Threshold_Curve.png'\nfig.savefig(os.path.join(PLOTS_DIR, image_name), dpi=fig.dpi)\nplt.clf()\n```", "```\ndef get_confusion_matrix(self, min_recall = 0.8):\n# Get the confusion matrix with min desired recall on the testing dataset used.\nprecision, recall, threshold = precision_recall_curve(self.recon_error.true_class, self.recon_error.recon_error)\nidx = filter(lambda x: x[1] > min_recall, enumerate(recall[1:]))[-1][0]\nth = threshold[idx]\nprint (\"Min recall is : %f, Threshold for recon error is: %f \" %(recall[idx+1], th))\n# Get the confusion matrix\npredicted_class = [1 if e > th else 0 for e in self.recon_error.recon_error.values]\ncnf_matrix = confusion_matrix(self.recon_error.true_class, predicted_class)\nclasses = ['Normal','Fraud']\nfig = plt.figure(figsize=(12, 12))\nplt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title(\"Confusion Matrix\")\nplt.colorbar()\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\nfmt = 'd'\nthresh = cnf_matrix.max() / 2.\nfor i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\nplt.text(j, i, format(cnf_matrix[i, j], fmt),\nhorizontalalignment=\"center\",\ncolor=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.tight_layout()\nimage_name = 'Confusion_Matrix_with_threshold_{}.png'.format(th)\nfig.savefig(os.path.join(PLOTS_DIR, image_name), dpi=fig.dpi)\nplt.clf()\n```"]