- en: Deploying TensorFlow Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will discuss the TensorFlow framework. Initially. We will
    begin by describing how the various approaches for building the algorithms differ.
    We will also cover deep learning and how to train neural networks but, more importantly,
    you will learn how to use pre-trained neural networks in the application and where
    you can find them.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Approaches for building algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why neural networks?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repositories for pre-trained TensorFlow models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of image captioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS subscription
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverless framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find all the codes at [https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda](https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaches for building algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The various approaches for building algorithms are :'
  prefs: []
  type: TYPE_NORMAL
- en: First of all, there are deterministic algorithms that are very transparent and
    predictable, but it may be very difficult to build a custom algorithm for complex
    tasks, which will work in all cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, there's the machine learning technique, where we train the model based
    on features we get from data. We don't need a lot of data to train models in a
    reliable way, but we need to make a separate process for training validation and
    testing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, there's the deep learning approach, where we train our own neural networks.
    The main advantage of this is that we can use raw data without predefined features.
    The downside is that we need a lot of data and a lot of computing resources for
    training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The machine learning approach varies greatly from the classic approach. The
    classic approach uses rules and data as input and answers as output. In the machine
    learning approach, we use data and answers as input and we produce rules as output,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a39a3c2-c246-4aea-8d6d-3d1c0c931b82.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's look into why neural networks have become so popular in recent years.
  prefs: []
  type: TYPE_NORMAL
- en: Why neural networks?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The reasons why neural networks have become popular in recent years are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Computing resources have become a lot cheaper now compared to the prices in
    the past. With the introduction of a public cloud, it became extremely easy and
    affordable to use these resources at scale.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The machine learning approach requires a lot of data and, right now, there's
    a lot of public and private data that can be used for training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced algorithms were allowed to make and train more complex neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's discuss why we actually don't need to train neural networks to successfully
    use them.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although training neural networks may require large processing power and a lot
    of data, deploying them can be done using a simple CPU. In this way, we can say
    that deploying a deep learning model is close to using an external library in
    your code. Secondly, there's a large community of people and companies that open
    source their pre-trained neural networks, which means that you can freely use
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two instances where using pre-trained neural networks can be extremely
    convenient:'
  prefs: []
  type: TYPE_NORMAL
- en: The first case is when your task has already been solved. For example, if you
    want to conduct image captioning with *X* classification, then you can use already
    existing neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second case is when your task is fairly different from what has been done
    but it's close. Then, you can use pre-trained models to generate features that
    you can use later with deterministic or simple machine learning models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Majority of the pre-trained models use TensorFlow and therefore it currently
    is the most popular framework for deep learning. It has a very large community
    of people and a lot of people share the models they've trained. Most companies
    that are using neural networks in their production environment are using the TensorFlow
    framework. We will, therefore, learn the use of TensorFlow for the pre-trained
    models through an example in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Simple TensorFlow example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the great use cases for showing the power of deep learning is the **MNIST**
    (short for **Modified National Institute of Standards and Technology**) dataset.
    It consists of black and white pictures with handwritten digits, as shown in the
    following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95d0fd34-71dd-42a5-bfd9-792414a009ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Each image is labeled based on the digit that's written on the image. The task,
    in this case, is to predict the label based on the image. This kind of task is
    very difficult to implement using deterministic methods; as you can see in the
    preceding image, there are a lot of different ways of writing the same number.
    Therefore, you can't use a single template for prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Training for MNIST
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll discuss model training for MNIST:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we start with importing the `tensorflow` library. For this example, we'll
    use the Keras deep learning framework, which makes it easy to set up layers for
    the neural network. In simple terms, Keras acts as a wrapper on top of TensorFlow,
    so everything is still based on TensorFlow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we need to load data and present it in a binary format since the original
    image pixel values are 0 and 255\. We''ll also divide the dataset into training
    and test sets. This will allow us to measure the performance of the neural network.
    A good practice for the machine learning approach is to train the model on the
    training dataset and measure the final score on the test dataset. It enables us
    to be sure that the model doesn''t see data points on which it''ll be measured
    after training. We''ll see the explanation as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, we need to set up the layers for our neural network. Basically, each layer
    consists of a number of neurons and an activation function. In this case, the
    first layer tries to get more useful data out of the raw data. The second layer
    tries to use this data to assign the probability of the image being one of 10
    digits.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As part of the  model, you need to choose three parameters for the training
    process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First is the `loss` function, which the network will use to optimize its performance.
    The training process basically consists of decreasing the value of the `loss`
    function and trying to find weights for the neural network, so the `loss` function
    will be minimal.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next is the `optimizer`, which handles how the neural network will iterate towards
    the most optimal solution, and how it'll change weights after each iteration.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, `metrics` allows us to measure neural network performance over the
    dataset. For example, `accuracy` allows us to understand which part of the dataset
    was correctly classified. This metric doesn''t participate in the training process
    directly and mainly allows us to understand whether network performance has improved
    or not. We can  understand the preceding explanation from the following code:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once everything is set up, we can just run training on the training part of
    our dataset. It may take several minutes, depending on the configurations of your
    computer. After that, we can evaluate model performance and the test set. Our
    model will produce something around 97% accuracy/test set, which is very impressive,
    and as demonstrated, it can be achieved with even a simple neural network as shown
    in the code below:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, once the neural network has been trained, we can save it so that we
    can use it later. As you can see, it''s a pretty simple process. The model file
    will contain the model architecture, a key composition of layers, the layer''s
    weights and training configuration, and the optimizer state, which allows us to
    continue training on the already trained model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Let's discuss the available files. There's only one Python file, the `testMNIST.py`
    file, which we're about to run. In this file, we can see the parts that we've
    discussed, which include data transformation, model installation, model training,
    model evaluation, model export, and model import.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s run the `testMNIST.py` file in the command line to see the results. By
    running the code, we can see the process of training, which happens in epochs.
    This kind of neural network doesn''t require a GPU to train and we can achieve
    very good results, even on the CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the following screenshot, we achieved 97% accuracy with just
    two epochs and were able to successfully export and import the model. We can see
    the exported retrained model, which can now be used in different code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/01018366-1582-48f2-9652-a36763e05cc8.png)'
  prefs: []
  type: TYPE_IMG
- en: .In the next section, we talk about the repositories for pre-trained TensorFlow
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Repositories for pre-trained TensorFlow models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pre-trained models are pretty skilled when it comes to import and export.
    In a nutshell, declaring deployment consists of importing the trained model and
    transforming input data into the format that''s acceptable by the neural network.
    There are certain things that you need to keep in mind during deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: The model can be pretty large, for example, hundreds of megabytes, which makes
    deployment more difficult.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to keep versions of the model and track their performance. If you train
    the model by yourself, you might need to update the model based on changes in
    incoming data or if you find better architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some models require additional files that translate predicted numbers or values
    into meaningful information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow has five main repositories with a number of selected models. They're
    a bit established and it's very easy to use them with the TensorFlow framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information on the most popular models that are trained using TensorFlow,
    visit this site: [https://github.com/tensorflow/models](https://github.com/tensorflow/models).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The different examples for the repositories are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Image to text models, which allow what's happening on the image to be described
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image captioning, which classifies the image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep speech, which allows speech to be recognized
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text summarization, which allows you to make a summary of the text article
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vid2depth, which produces a depth map based on the video stream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow Hub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's the TensorFlow Hub hosting platform, which was specifically designed
    for neural networks. TensorFlow Hub has a lot of great models that are free to
    use and are mainly trained by Google. They're good and are of state-of-the-art
    quality. The advantage of TensorFlow Hub is that the models are checked before
    they're added and the disadvantage is that it has a high barrier for entry submissions.
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow Hub for different models can be viewed at the following link: [https://tfhub.dev/](https://tfhub.dev/).'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GitHub is considered the largest repository of open source code. There are countless
    models that are published there but, since there's no entry filter, you'll need
    to be more cautious about using these models in production. The advantage of GitHub
    is that it has a low barrier for entry and the disadvantages are that it may be
    difficult to find a relevant model and the user needs to check how the model works
    before deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In this next section, we learn about Image captioning through an example.
  prefs: []
  type: TYPE_NORMAL
- en: Image captioning example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image captioning is a task where we need to recognize an object on the image.
    Although it sounds simple, it was considered one of the most difficult problems
    in computer vision since it was close to impossible to make a separate detector
    for each type of object. The main way to test the image captioning algorithm is
    to run it on the ImageNet dataset. The ImageNet dataset consists of 14 million
    images with over 20,000 labels. It was introduced in 2010\. Every year, there's
    a competition of different models, and accuracy has significantly improved in
    recent years due to the introduction of complex neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of different models with different architectures that successfully
    work with ImageNet. We'll see that errors significantly decreased over the years.
     The following diagram shows a change in the error rate of winner models in the ImageNet dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a33ec83-dd5a-4b2c-9c9f-0649c94e1cae.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll now discuss Inception v3, which we'll use in the code sample later.
  prefs: []
  type: TYPE_NORMAL
- en: Inception v3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inception v3 was introduced by Google and achieved an error rate of 3.46%. You'll
    see that Inception v3 is significantly more complex. It also takes more resources
    to train this model, but the upside here is that we don't have to train it to
    use it.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look into what we'll need to start using Inception v3 in our code. The
    model consists of layers and weight values present in `classify_image_graph_def.pb`.
  prefs: []
  type: TYPE_NORMAL
- en: We also have a list of labels, which the model can predict in  `imagenet_2012_challenge_label_map_proto.pbtxt`file
    and a document that allows the mapping of results of the neural network to the
    labels in`imagenet_synset_to_human_label_map``.txt`file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of the Panda image. First, we receive the IDs that score.
    The highest score means that the model has high confidence in the image having
    this label. After mapping IDs to label names, we can see that the model correctly
    detected Panda. The following screenshot explains this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/579bdbe1-1e38-4c17-9929-b7c3ca5ffd7b.png)'
  prefs: []
  type: TYPE_IMG
- en: TensorFlow code for Inception v3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s see how the code for any Inception v3 model will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to set up a TensorFlow session. A session is an environment in
    which tensors are evaluated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need to read and set up our neural network by loading it from the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we need to ask for our image in the format that'll be readable by the
    neural network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will need to run a power model and receive a list of row predictions, and
    transform these predictions into actual label values, as shown in the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Running the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's look at the available files, `inputimage.png` and `testinception.py`,
    which we're about to run. In this example, we'll be using the Panda image (`inputimage.png`).
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following code, there''s the `NodeLookup` class, which will
    help us to translate responses from the model to the label name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows how we can read the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, this is the code that tells how we import the pre-trained model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we exchange the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we translate the results of the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can run the code and see the response. As you can see from the following
    output, the model successfully detected a panda on the image. The code will run
    fast since there''s no training involved. You can try the code on different images
    and get a sense of the possibilities of this model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ab937d37-75f1-4fa0-8744-75b06c873bd5.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we studied different approaches for building algorithms. We
    discussed how to train TensorFlow models and repositories for pre-trained Tenserflow
    models. We also learned about image captioning using an Inception v3 TensorFlow
    example.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll learn how to work with TensorFlow AWS Lambda, where
    we'll learn more about using TensorFlow models with AWS Lambda.
  prefs: []
  type: TYPE_NORMAL
