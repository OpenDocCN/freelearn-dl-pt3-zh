["```\ndataset = tf.data.Dataset.list_files(\"/path/to/dataset/*.png\")\n```", "```\ndef parse_fn(filename):\n    img_bytes = tf.io.read_file(filename)\n    img = tf.io.decode_png(img_bytes, channels=3)\n    img = tf.image.resize(img, [64, 64])\n    return img  # or for instance, `{'image': img}` if we want to name this input\ndataset = dataset.map(map_func=parse_fn)\n```", "```\nprint(dataset.output_types)  # > \"tf.uint8\"\nprint(dataset.output_shapes) # > \"(64, 64, 3)\"\nfor image in dataset:\n     # do something with the image\n```", "```\nkeras_model.fit(dataset, ...)     # to train a Keras model on the data\ndef input_fn():\n    # ... build dataset\n    return dataset\ntf_estimator.train(input_fn, ...) # ... or to train a TF estimator\n```", "```\nx, y = np.array([1, 2, 3, 4]), np.array([5, 6, 7, 8])\nd = tf.data.Dataset.from_tensors((x,y))\nprint(d.output_shapes) # > (TensorShape([4]), TensorShape([4]))\nd_sliced = tf.data.Dataset.from_tensor_slices((x,y))\nprint(d_sliced.output_shapes) # > (TensorShape([]), TensorShape([]))\n```", "```\ndataset = tf.data.experimental.SqlDataset(\n    \"sqlite\", \"/path/to/my_db.sqlite3\",\n    \"SELECT img_filename, label FROM images\", (tf.string, tf.int32))\n```", "```\ndef parse_fn(line):\n    img_filename, img_label = tf.strings.split(line, sep=',')\n    img = tf.io.decode_image(tf.io.read_file(img_filename))[0]\n    return {'image': img, 'label': tf.strings.to_number(img_label)}\ndataset = tf.data.TextLineDataset('/path/to/file.txt').map(parse_fn)\n```", "```\ndataset = tf.data.TFRecordDataset(['file1.tfrecords','file2.tfrecords'])\n# Dictionary describing the features/tf.trainExample structure:\nfeat_dic = {'img': tf.io.FixedLenFeature([], tf.string), # image's bytes\n            'label': tf.io.FixedLenFeature([1], tf.int64)} # class label\ndef parse_fn(example_proto): # Parse a serialized tf.train.Example\n    sample = tf.parse_single_example(example_proto, feat_dic)\n    return tf.io.decode_image(sample['img])[0], sample['label']\ndataset = dataset.map(parse_fn)\n```", "```\nurl_regex = \"(?i)([a-z][a-z0-9]*)://([^ /]+)(/[^ ]*)?|([^ @]+)@([^ @]+)\"\ndef is_not_url(filename): #NB: the regex isn't 100% sure/covering all cases\n    return ~(tf.strings.regex_full_match(filename, url_regex))\ndataset = dataset.filter(is_not_url)\n```", "```\nnum_training_samples, num_epochs = 10000, 100\ndataset_train = dataset.take(num_training_samples)\ndataset_train = dataset_train.repeat(num_epochs)\ndataset_val   = dataset.skip(num_training_samples)\n```", "```\nd1 = tf.data.Dataset.range(3)\nd2 = tf.data.Dataset.from_tensor_slices([[4, 5], [6, 7], [8, 9]])\nd = tf.data.Dataset.zip((d1, d2))\n# d will return [0, [4, 5]], [1, [6, 7]], and [2, [8, 9]]\n```", "```\nfilenames = ['/path/to/file1.txt', '/path/to/file2.txt', ...]\nd = tf.data.Dataset.from_tensor_slices(filenames)\nd = d.interleave(lambda f: tf.data.TextLineDataset(f).map(parse_fn), \n                 cycle_length=2, block_length=5)\n```", "```\ndataset = tf.data.TextLineDataset('/path/to/file.txt')\ndataset = dataset.map(parse_fn, num_threads).batch(batch_size).prefetch(1)\n```", "```\noptions = tf.data.Options()\noptions.experimental_optimization.map_and_batch_fusion = True\ndataset = dataset.with_options(options)\n```", "```\n# Use utility function to tell TF to gather latency stats for this dataset:\ndataset = dataset.apply(tf.data.experimental.latency_stats(\"data_latency\"))\n# Link stats aggregator to dataset through the global options:\nstats_aggregator = tf.data.experimental.StatsAggregator()\noptions = tf.data.Options()\noptions.experimental_stats.aggregator = stats_aggregator\ndataset = dataset.with_options(options)\n# Later, aggregated stats can be obtained as summary, for instance, to log them:\nsummary_writer = tf.summary.create_file_writer('/path/to/summaries/folder')\nwith summary_writer.as_default():\n    stats_summary = stats_aggregator.get_summary()\n    # ... log summary with `summary_writer` for Tensorboard (TF2 support coming soon)\n```", "```\ndataset = tf.data.TextLineDataset('/path/to/file.txt')\ndataset_v1 = dataset.cache('cached_textlines.temp').map(parse_fn)\ndataset_v2 = dataset.map(parse_fn).cache('cached_images.temp')\n```", "```\nimg_dim, img_ch = tf.shape(img)[-3:-1], tf.shape(img)[-1]\n# Stack/concatenate the image pairs along the channel axis:\nstacked_imgs = tf.concat([img, tf.cast(gt_img, img.dtype)], -1)\n# Apply the random operations, for instance, horizontal flipping:\nstacked_imgs = tf.image.random_flip_left_right(stacked_imgs)\n# ... or random cropping (for instance, keeping from 80 to 100% of the images):\nrand_factor = tf.random.uniform([], minval=0.8, maxval=1.)\ncrop_shape = tf.cast(tf.cast(img_dim, tf.float32) * rand_factor, tf.int32)\ncrop_shape = tf.concat([crop_shape, tf.shape(stacked_imgs)[-1]], axis=0)\nstacked_imgs = tf.image.random_crop(stacked_imgs, crop_shape)\n# [...] (apply additional geometrical transformations)\n# Unstack to recover the 2 augmented tensors:\nimg = stacked_imgs[..., :img_ch]\ngt_img = tf.cast(stacked_imgs[..., img_ch:], gt_img.dtype)\n# Apply other transformations in the pixel domain, for instance:\nimg = tf.image.random_brightness(image, max_delta=0.15)\n```", "```\n# This decorator specifies the method has a custom gradient. Along with its normal output, the method should return the function to compute its gradient:\n@tf.custom_gradient \ndef reverse_gradient(x): # Flip the gradient's sign.\n    y = tf.identity(x) # the value of the tensor itself isn't changed\n    return y, lambda dy: tf.math.negative(dy) # output + gradient method\n```"]