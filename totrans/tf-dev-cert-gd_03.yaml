- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear Regression with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will cover the concept of linear regression and how we can
    implement it using TensorFlow. We will start by discussing what linear regression
    is, how it works, its underlying assumptions, and the type of problems that can
    be solved using it. Next, we will examine the various evaluation metrics used
    in regression modeling, such as mean squared error, mean absolute error, root
    mean squared error, and R-squared, and strive to understand how to interpret the
    results from these metrics.
  prefs: []
  type: TYPE_NORMAL
- en: To get hands-on, we will implement linear regression by building a real-world
    use case where we predict employees’ salaries using various attributes. Here,
    we will learn in a hands-on fashion how to load and pre-process data, covering
    important ideas such as handling missing values, encoding categorical variables,
    and normalizing the data for modeling. Then, we will explore the process of building,
    compiling, and fitting a linear regression model with TensorFlow, as well as examine
    concepts such as underfitting and overfitting and their impact on our model’s
    performance. Before we close this chapter, you will also learn how to save and
    load a trained model to make predictions on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression with TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating regression models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salary prediction with TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving and loading models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use a `python >= 3.8.0`, along with the following packages, which can
    be installed using the `pip` `install` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tensorflow>=2.7.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tensorflow-datasets==4.4.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pillow==8.4.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas==1.3.4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy==1.21.4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scipy==1.7.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear regression with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Linear regression** is a supervised machine learning technique that models
    the linear relationship between the predicted output variable (dependent variable)
    and one or more independent variables. When one independent variable can be used
    to effectively predict the output variable, we have a case of *simple linear regression*,
    which can be represented by the equation *y = wX + b*, where *y* is the target
    variable, *X* is the input variable, *w* is the weight of the feature(s), and
    *b* is the bias.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – A plot showing simple linear regression](img/B18118_03_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – A plot showing simple linear regression
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3**.1*, the straight line, referred to as the regression line (the
    line of best fit), is the line that optimally models the relationship between
    *X* and *y*. Hence, we can use it to determine the dependent variable based on
    the current value of the independent variable at a certain point on the plot.
    The objective of linear regression is to find the best values of *w* and *b*,
    which model the underlying relationship between *X* and *y*. The closer the predicted
    value is to the ground truth, the smaller the error.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, when we have more than one input variable used to predict the output
    value, then we have a case of *multiple linear regression*, and we can represent
    it by the equation *y = b0 + b1X1 + b2X2 + .... + bnXn*, where *y* is the target
    variable, *X1*, *X2*, ... *Xn* are input variables, *b0* is the bias, and *b1*,
    *b2*, ... *bn* are the feature weights.
  prefs: []
  type: TYPE_NORMAL
- en: Simple linear and multiple linear regression have lots of real-world applications,
    as they are simple to implement and computationally cheap. Hence, they can be
    easily applied to large datasets. However, linear regression may fail when we
    try to model nonlinear relationships between *X* and *y*, or when there are many
    irrelevant features in our input data.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression is widely used to solve a wide range of real-world problems
    across different domains. For example, we can apply linear regression to predict
    the price of a house using factors such as the size, number of bedrooms, location,
    and proximity to social amenities. Similarly, in the field of **human resource**
    (**HR**), we can use linear regression to predict the salary of new hires, based
    on factors such as years of experience of the candidate and their level of education.
    These are a few examples of what is possible using linear regression. Next, let
    us see how we can evaluate linear regression models.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating regression models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our *hello world* example from [*Chapter 2*](B18118_02.xhtml#_idTextAnchor045),
    *Introduction to TensorFlow*, we tried to predict a student’s test score when
    the student spent 38 hours studying during the term. Our study model arrived at
    81.07 marks, while the true value was 81\. So, we were close but not completely
    correct. When we subtract the difference between our model’s prediction and the
    ground truth, we get a residual of 0.07\. The residual value could be either positive
    or negative, depending on whether our model overestimates or underestimates the
    predicted result. When we take the absolute value of the residual, we eliminate
    any negative signs; hence, the absolute error will always be a positive value,
    irrespective of whether the residual is positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for absolute error is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Absolute error = |Y pred − Y true|
  prefs: []
  type: TYPE_NORMAL
- en: where Y pred = the predicted value and Y true = the ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **mean absolute error** (**MAE**) of a model is the average of all absolute
    errors of the data points under consideration. MAE measures the average of the
    residuals and can be represented using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: MAE =  1 _ n  ∑ i=1 n  |Y pred − Y true|
  prefs: []
  type: TYPE_NORMAL
- en: 'where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*n* = the number of data points under consideration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ∑ = summation of the absolute errors of all the observations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|Y pred − Y true| = Absolute value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the MAE = 0, it means that Y pred = Y true. This means the model is 100 percent
    accurate; although this is an ideal scenario, it is highly unlikely. On the flip
    side, if MAE= ∞, this means the model is completely off, as it fails to capture
    any relationship between the input and output variables. The larger the error,
    the larger the value of the MAE. For performance evaluation, we aim for low values
    of MAE, but because MAE is a relative metric whose value depends on the scale
    of the data you work with, it is difficult to compare MAE results across different
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important evaluation metric is the **mean squared error** (**MSE**).
    MSE, in contrast to MAE, squares the residuals, thus removing any negative values
    in the residuals. MSE is represented using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: MSE =  1 _ N  ∑ i=1 N ( Y pred − Y true) 2
  prefs: []
  type: TYPE_NORMAL
- en: Like MAE, when there are no residuals, we have a perfect model. So, the lower
    the MSE value, the better the performance of the model. Unlike MAE, where large
    or small errors have a proportional impact, MSE penalizes larger errors in comparison
    to smaller errors, and it has a higher order of units, since we square the residual
    in this instant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful metric in regression modeling is the **root mean square error**
    (**RMSE**). As the name suggests, it is the square root of MSE, as shown in the
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: MSE =  1 _ N  ∑ i=1 N ( Y pred − Y true) 2
  prefs: []
  type: TYPE_NORMAL
- en: RMSE = √ _ MSE  = √ ________________   1 _ N  ∑ i=1 N ( Y pred − Y true) 2
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, let us look at the **coefficient of determination** (**R squared**).
    R2 measures how well the dependent variable is explained by the independent variables
    in a regression modeling task. We can calculate R2 with this equation:'
  prefs: []
  type: TYPE_NORMAL
- en: R 2 = 1 −  R res _ R tot
  prefs: []
  type: TYPE_NORMAL
- en: where Rres is the sum of the square of residuals and Rtot is the total sum of
    squares. The closer the value of R2 is to 1, the more accurate the model is, and
    the closer the R2 value of a model is to 0, the worse the model is. Also, it is
    possible for R² to take on a negative value. This happens when the model does
    not follow the trend of the data – in this instance, Rres is greater than Rtot.
    A negative R2 is a sign that our model requires significant improvement due to
    its poor performance.
  prefs: []
  type: TYPE_NORMAL
- en: We have looked at some regression evaluation metrics. The good news is that
    we will not work them out by hand; we will leverage the `tf.keras.metrics` module
    from TensorFlow to help us do the heavy lifting. We have breezed quickly through
    the theory at a high level. Now, let us examine a multiple linear regression case
    study to enable us to understand all the moving parts required to build a model
    with TensorFlow, as well as understand how to evaluate, save, load, and use our
    trained model to make predictions on new data. Let’s proceed to our case study.
  prefs: []
  type: TYPE_NORMAL
- en: Salary prediction with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this case study, you will assume the role of a new machine learning engineer
    at Tensor Limited, a rapidly growing start-up with over 200 employees. Now, the
    company wants to hire seven new employees, and the HR department is having a hard
    time coming up with the ideal salary based on varying qualifications, years of
    experience, the roles applied for, and the level of training of each of the potential
    new hires. Your job is to work with the HR unit to determine the optimal salary
    for each of these potential hires.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, we went through the machine learning life cycle in [*Chapter 1*](B18118_01.xhtml#_idTextAnchor014),
    *Introduction to Machine Learning,* built our hello world case study in [*Chapter
    2*](B18118_02.xhtml#_idTextAnchor045), *Introduction to TensorFlow,* and have
    already covered some key evaluation metrics required for regression modeling in
    this chapter. So, you are well equipped theoretically to carry out the task. You
    have had a productive discussion with the HR manager, and now you have a better
    understanding of the task and the requirements. You defined your task as a supervised
    learning task (regression). Also, the HR unit allowed you to download employee
    records and their corresponding salaries for this task. Now that you have the
    dataset, let us proceed to load the data into our notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to load the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the notebook called `Linear_Regression_with_TensorFlow.ipynb`. We will
    start by importing all the necessary libraries for this project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will run this code block. If everything goes well, we will get to see the
    version of TensorFlow we are using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will import some additional libraries that will help us simplify our
    workflow:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will run this cell, and everything should work perfectly. NumPy is a scientific
    computing library in Python that is used to perform mathematical operations on
    arrays, while pandas is a built-in Python library for data analysis and manipulation.
    Matplotlib and Seaborn are used to visualize data, and we will use sklearn for
    data preprocessing and splitting our data. We will apply these libraries in this
    case study, and you will get to understand what they do and also be able to apply
    them in your exam and beyond.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will proceed to load the dataset, which we got from the HR team for
    this project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will use pandas to generate a DataFrame that holds the record in a tabular
    format, and we will use `df.head()` to print the first five entries in the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – A DataFrame showing a snapshot of our dataset](img/B18118_03_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – A DataFrame showing a snapshot of our dataset
  prefs: []
  type: TYPE_NORMAL
- en: We now have a sense of what data was collected, based on the details captured
    in each column. We will proceed to explore the data to see what we can learn and
    how we can effectively develop a solution to meet the business objective. Let
    us proceed by looking at data pre-processing.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To be able to model our data, we need to ensure it is in the right form (i.e.,
    numerical values). Also, we will need to deal with missing values and remove irrelevant
    features. In the real world, data preprocessing takes a long time. You will hear
    this repeatedly, and it is true. Without correctly shaping the data, we cannot
    model it. Let’s jump in and see how we can do this for our current task. From
    the DataFrame, we can immediately see that there are some irrelevant columns,
    and they hold personally identifiable information about employees. So, we will
    remove and also inform HR about this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `drop` function in pandas to drop the name, phone number, and
    date of birth columns. We will now display the DataFrame again using `df.head()`
    to show the first five rows of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – The first five rows of the DataFrame after dropping the columns](img/B18118_03_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – The first five rows of the DataFrame after dropping the columns
  prefs: []
  type: TYPE_NORMAL
- en: 'We have successfully removed the irrelevant columns, so we can now proceed
    and check for missing values in our dataset using the `isnull()` function in pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run this code block, we can see that there are no missing values in
    the `University` and `Salary` columns. However, we have missing values for the
    `Role`, `Cert`, `Qualification`, and `Experience` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a number of ways to handle missing values – from simply asking HR
    to fix the omissions to simple imputations or replacements using mean, median,
    or mode. In this case study, we will drop the rows with missing values, since
    it’s a small subset of our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We use the `dropna` function to drop all the missing values in the dataset,
    and then we save the new dataset in `df`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to learn more about how to handle missing values, check out this
    playlist by Data Scholar: [https://www.youtube.com/playlist?list=PLB9iiBW-oO9eMF45oEMB5pvC7fsqgQv7u](https://www.youtube.com/playlist?list=PLB9iiBW-oO9eMF45oEMB5pvC7fsqgQv7u).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to check to ensure that there are no more missing values using
    the `isnull()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the code, and let’s see whether there are any missing values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that there are no missing values in our dataset anymore. Our model
    requires us to pass in numerical values for it to be able to model our data and
    predict the target variable, so let us look at the data types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the code, we get an output showing the different columns and their
    data types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'From the output, we can see that experience and salary are numeric values,
    since they are `float` and `int`, respectively, while `Qualification`, `University`,
    `Role`, and `Cert` are categorical values. This means we cannot train our model
    yet; we have to find a way to convert our categorical values to numerical values.
    Luckily, this is possible via a process called one-hot encoding. `get_dummies`
    function in pandas to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: When we run the code, we will get a DataFrame like the one displayed in *Figure
    3**.4*. We use the `drop_first` argument to drop the first category.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – A DataFrame showing numerical values](img/B18118_03_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – A DataFrame showing numerical values
  prefs: []
  type: TYPE_NORMAL
- en: If you are confused as to why we dropped one of the categorical columns, let’s
    look at the `Cert` column, which was made up of yes or no. values If we performed
    one hot encoding, without dropping any columns, we would have two `Cert` columns,
    as displayed in *Figure 3**.5*. In the `Cert_No` column, if the employee has a
    relevant certification, the column gets a value of `0`, and when the employee
    does not have a relevant certification, the column gets a value of `1`. Looking
    at the `Cert_Yes` column, we can see that when an employee has a certificate,
    the column gets a value of `1`; otherwise, it gets `0`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – The dummy variables from the Cert column](img/B18118_03_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – The dummy variables from the Cert column
  prefs: []
  type: TYPE_NORMAL
- en: From *Figure 3**.5*, we can see that both columns can be used to show whether
    an employee has a certificate or not. Using both dummy columns generated from
    our certificate column will lead to the *dummy variable trap*. This occurs when
    our one-hot encoded columns are strongly related or correlated, where one column
    can effectively explain the other column. Hence, we say both columns are multicollinear,
    and *multicollinearity* can lead to the overfitting of our model. We will talk
    more about overfitting in [*Chapter 5*](B18118_05.xhtml#_idTextAnchor105)*, Image
    Classification with* *Neural Networks*.
  prefs: []
  type: TYPE_NORMAL
- en: For now, it is good enough to know that overfitting is a situation where our
    model performs very well on training data but poorly on test data. To avoid the
    dummy variable trap, we will drop one of the columns in *Figure 3**.5*. If there
    are three categories, we only need two columns to capture all three categories;
    if we have four categories, we will only need three columns to capture four categories,
    and so on. Hence, we can drop the extra columns for all the other categorical
    columns as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will use the `corr()` function to get the correlation of our refined
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We can see that there is a strong correlation between salary and years of experience.
    Also, there is a strong correlation between `Role_Senior` and `Salary`, as shown
    in *Figure 3**.6*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – The correlation values for our data](img/B18118_03_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – The correlation values for our data
  prefs: []
  type: TYPE_NORMAL
- en: We have completed the preprocessing phase of our task, or at least for now.
    We have removed all irrelevant columns; we also removed the missing values by
    dropping rows with missing values and, finally, used one-hot encoding to convert
    our categorical values to numeric values. It is important to note that we are
    skipping some **exploratory data analysis** (**EDA**) steps here, such as visualizing
    the data; although that’s an essential step, our core focus for the exam is building
    models with TensorFlow. In our Colab notebook, you will find some additional EDA
    steps; although they are not directly relevant to the exams, they will give you
    a better understanding of your data and help you detect anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us move on to the modeling phase.
  prefs: []
  type: TYPE_NORMAL
- en: Model building
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To build a model, we will have to sort our data into features (*X*) and the
    target (*y*). To do this, we will run this code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We will use the `drop()` function to drop the `Salary` column from the `X` variable,
    and we will make the `y` variable the `Salary` column alone, since this is our
    target.
  prefs: []
  type: TYPE_NORMAL
- en: 'With our features and target variable well defined, we can proceed to split
    our data into training and test sets. This step is important, as it enables our
    model to learn patterns from our data to effectively predict employees’ salaries.
    To achieve this, we train our model using the training set and then evaluate the
    model’s efficacy on the hold-out test set. We discussed this at a high level in
    [*Chapter 1*](B18118_01.xhtml#_idTextAnchor014)*, Introduction to Machine Learning,*
    when we talked about the ML life cycle. It is a very important process, as we
    will use the test set to evaluate our model’s generalization capability before
    we deploy it for real-world use. To split our data into training and testing sets,
    we will use the `sklearn` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Using the `train_test_split` function from the `sklearn` library, we split our
    data into training and testing datasets, with a test size of `0.2`. We set the
    `random_state =10` to ensure reproducibility so that every time you use the same
    `random_state` value, you’ll get the same split, even if you run the code multiple
    times. For instance, in our code, we set `random_state` to `10`, which means every
    time we run the code, we will get the same split. If we change this value from
    `10` to, say, `50`, we will get a different shuffled split for our training and
    test set. Setting the `random_state` argument when splitting our data into training
    and test sets is very useful, as it allows us to effectively compare different
    models, since our training set and test sets are the same across all the models
    we experiment with.
  prefs: []
  type: TYPE_NORMAL
- en: When modeling our data in machine learning, we usually use 80 percent of the
    data to train the model and 20 percent of the data to test the model’s generalization
    capability. That’s why we set `test_size` to `0.2` for our dataset. Now that we
    have everything in place, we will start the modeling process in earnest. When
    it comes to building models with TensorFlow, there are three essential steps,
    as illustrated in *Figure 3**.7* – building the model, compiling the model, and
    fitting it to our data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – The three-step modeling process](img/B18118_03_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – The three-step modeling process
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us see how we can use this three-step approach to build our salary prediction
    model. We will begin by building our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In *Figure 3**.8*, we can see the first line of code for our model. Here, we
    generated a single layer using the `Sequential` class as an array. The `Sequential`
    class is used for layer definition. The `Dense` function is used to generate a
    layer of fully connected neuron. In this case, we have just one unit. For our
    activation function here, we employ a linear activation function. Activation functions
    are used to determine the output of a neuron based on a given input or set of
    inputs. Here, the linear activation function simply outputs whatever the input
    is – that is, a direct relationship between the input and the output. Next, we
    pass in the input shape of our data, which in this case is 8, representing the
    features in data (columns) in `X_train`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – Building a model in TensorFlow](img/B18118_03_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – Building a model in TensorFlow
  prefs: []
  type: TYPE_NORMAL
- en: In the first step of our three-step process, we designed the model structure.
    Now, we will move on to the model compilation step. This step is equally important
    as it determines how the model will learn. Here, we specify parameters such as
    the loss function, the optimizer, and the metrics we want to use to evaluate our
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The optimizer determines how our model will update its internal parameters,
    based on the information it gathers from the loss function and the data. The job
    of the loss function is to measure how well our model does on our training data.
    We then use our metrics to monitor the model’s performance on the training step
    and test steps. Here, we use **stochastic gradient descent** (**SGD**) as our
    optimizer and MAE for our loss and evaluation metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Now, all we have to do is feed our model with training data and the corresponding
    labels, with which our model can learn to intelligently predict the target numerical
    values, which in our case is the expected salary. Every time the model makes a
    prediction, the loss function compares the difference between the model’s prediction
    and the ground truth. This information is passed to the optimizer, which uses
    the information to make an improved prediction until the model can fashion the
    right mathematical equation to accurately predict our employee’s salary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s fit our training model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We use `model_1.fit` to fit our training data and labels and set the number
    of tries (epochs) to `50`. In just a few lines of code, we have generated a mini-brain
    that we can train over time to make sensible predictions. Let’s run the code and
    see what the output looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We have displayed the last five tries (epochs `46`–`50`). The error drops gradually;
    however, we end up with a very large error after `50` epochs. Perhaps we can train
    our model for more epochs, as we did in [*Chapter 2*](B18118_02.xhtml#_idTextAnchor045)*,
    Introduction to TensorFlow*. Why not?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we simply change the number of epochs to `500` using our single-layer
    model. The activation function, the loss, and optimizers are the same as our initial
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'From the last five lines of our output, we can see that the loss is still quite
    high after `500` epochs. You may wish to experiment with the model for longer
    epochs to see how it will fare. It is also a good idea to visualize your model’s
    loss curve to see how it performs. A lower loss indicates a better-performing
    model. With this in mind, let us explore the loss curve for `model_2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We will generate a utility plotting function, `visualize_model`, which we will
    use in our experiments to plot the model’s loss over time as it trains. In this
    code, we generate a figure to plot the loss values stored in the `history` object.
    The `history` object is the output of the `fit` function in our three-step modeling
    process, and it holds the loss and metrics values at the end of each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: 'To plot `model_2`, we simply call the function to visualize the plot and pass
    in `history_2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the code, we get the plot shown in *Figure 3**.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Model losses at 500](img/B18118_03_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – Model losses at 500
  prefs: []
  type: TYPE_NORMAL
- en: From *Figure 3**.9*, we can see the loss falling, and the rate at which it falls
    is too slow, as it takes **500** epochs to fall from around **97400** to **97000**.
    In your spare time, you can try to train the model for 2,000 or more epochs. It
    will not be able to generalize well, as the model is too simple to handle the
    complexity of our data. In machine learning lingo, we say the model is *underfitting*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'There are primarily two ways to build models with TensorFlow – the sequential
    API and the functional API. The sequential API is a simple way of building models
    by using a stack of layers, where data flows in a single direction, from the input
    layer to the output layer. Conversely, the functional API in TensorFlow allows
    us to build more complex models – this includes models with multiple inputs or
    outputs and models with shared layers. Here, we use the Sequential API. For more
    information about building models with the sequential API, check out the documentation:
    [https://www.tensorflow.org/guide/keras/sequential_model](https://www.tensorflow.org/guide/keras/sequential_model).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, let us try to build a more complex model and see whether we can push
    the loss lower and quicker than our initial model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have generated a new model. We stack a 64-neuron layer on top of our
    single-unit layer. We also use a **Rectified Linear Unit** (**ReLU**) activation
    function for this layer; its job is to help our model learn more complex patterns
    in our data and improve computational efficiency. The second layer is our output
    layer, made up of a single neuron because we have a regression task (predicting
    a continuous value). Let’s run it for 500 epochs and see whether this will make
    any difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: From the last five lines of our output, we can see that there is a significant
    drop in our loss to around `3686`. Let’s also plot the loss curve to get a visual
    understanding as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – Model losses after 500 epochs](img/B18118_03_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – Model losses after 500 epochs
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3**.10*, we can see that our model’s loss has fallen below our lowest
    recorded loss. This is a massive improvement in comparison to our previous model.
    However, this is not a desired result, nor does it look like the type of result
    we would like to present to the HR team. This is because, with this model, if
    an employee earns $50,000, the model could predict either around $46,300 as the
    employee’s salary, which would make them unhappy, or $53,700 as the employee’s
    salary, in which case the HR team will not be happy. So, we need to figure out
    how to improve our result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s zoom into the plot to have a better understanding of what is happening
    with our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: When we run the code, it returns the plot shown in *Figure 3**.11*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Model losses after 500 epochs when we zoom into the plot](img/B18118_03_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – Model losses after 500 epochs when we zoom into the plot
  prefs: []
  type: TYPE_NORMAL
- en: From the plot in *Figure 3**.11*, we can see that the loss falls sharply and
    settles at around the 100th epoch, and nothing significant seems to happen afterward.
    Hence, training the model for longer just as we did in our previous model may
    not be the optimal solution. What can we do to improve our model?
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps we can add another layer? Let’s do that and see what our results look
    like. As we initially pointed out, our job requires a lot of experimentation;
    only then can we learn how to do things better and faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we added another dense layer of `64` neurons. Note that we also use ReLU
    as the activation function here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We display only the last five epochs, and we can see the loss is around `97384`,
    which is worse than the results achieved in `model_3`. So, how do we know how
    many layers to use in our modeling process? The answer is by experimenting. We
    use trial and error, backed by our understanding of what the results look like.
    We can decide whether we need to add more layers, as we did initially when the
    model was underfitting. And should the model get so complex that it masters the
    training data well but does not generalize well on our test (hold-out) data, it
    is said to be *overfitting* in machine learning lingo.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have tried smaller and larger models, we cannot yet say we have
    achieved a suitable result, and the HR manager has checked in on us to find out
    how we are doing in terms of the prediction modeling task. So far, we did some
    research, as all ML engineers do, and we discovered a very important step that
    we can try out. What step? Let’s see.
  prefs: []
  type: TYPE_NORMAL
- en: Normalization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Normalization** is a technique applied to input features to ensure they are
    of a consistent scale, usually between 0 and 1\. This process helps our model
    to converge faster and more accurately. It is worth noting that we should apply
    normalization after completing other data preprocessing steps, such as handling
    missing values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s good practice to know that improving your model output can also rely strongly
    on your data preparation process. Hence, let us apply this here. We will take
    a step back from model building and look at our features after we converted all
    the columns to numerical values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the `describe` function to get vital statistics of our data. This
    information shows us that most of the columns have a minimum value of 0 and a
    maximum value of 1, but the experience column is of a different scale, as shown
    in *Figure 3**.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – A statistical summary of the dataset (before normalization)](img/B18118_03_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 – A statistical summary of the dataset (before normalization)
  prefs: []
  type: TYPE_NORMAL
- en: Why does this matter, you may ask? When the scale of our data is different,
    our model will arbitrarily attach more importance to columns with higher values,
    which could affect the model’s ability to predict our target correctly. To resolve
    this issue, we will use normalization to scale the data between 0 and 1 to bring
    all our features to the same scale, thereby giving every feature an equal chance
    when our model begins to learn how they relate to our target (*y*).
  prefs: []
  type: TYPE_NORMAL
- en: 'To normalize our data, we will use the following equation to scale it:'
  prefs: []
  type: TYPE_NORMAL
- en: X norm =  X − X min _ X max − X min
  prefs: []
  type: TYPE_NORMAL
- en: 'where *X* is our data, X min is the minimum value of *X*, and X max is the
    maximum value of *X*. In our case study, the minimum value of *X* in the `Experience`
    column is 1, and the maximum value of *X* in the `Experience` column is 7\. The
    good news is that we can easily implement this step using the `MinMaxScaler` function
    from the `sklearn` library. Let’s see how to scale our data next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Let’s use the `describe()` function to view the key statistics again, as shown
    in *Figure 3**.13*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13 – A statistical summary of the dataset (after normalization)](img/B18118_03_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 – A statistical summary of the dataset (after normalization)
  prefs: []
  type: TYPE_NORMAL
- en: Now, all our data is of the same scale. So, we have successfully implemented
    normalization of our data in just a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we split our data into training and testing sets, but this time, we use
    our normalized *X* (`X_norm`) in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we use our best-performing model (`model_3`) from the initial experiments
    we have done so far. Let’s see how our model performs after normalization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: From the results, we can see that MAE has reduced by more than half in comparison
    to the results we got without applying normalization.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14 – The zoomed-in loss curve for model_5](img/B18118_03_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 – The zoomed-in loss curve for model_5
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, if you look at the loss plot for `model_5` in *Figure 3**.14*, you can
    see the loss fails to drop significantly after around the 100th epoch. Instead
    of guessing how many epochs are ideal to train the model, how about we set a rule
    to stop training when the model fails to improve its performance? Also, we can
    see that `model_5` doesn’t give us the result we want; perhaps now is a good time
    to try out a bigger model, in which we train it for longer and set a rule to stop
    training once it fails to improve its performance on the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we use a three-layer model; the first two layers are made up of 64 neurons
    and the output layer has a single neuron. To set the rule to stop training, we
    use *early stopping*; this additional parameter is applied when we fit our model
    on the data to stop training when the model loss fails to improve after 10 epochs.
    This is achieved by specifying the metric to monitor loss and setting `patience`
    to `10`. Early stopping is also a great technique to prevent overfitting, as it
    stops training when the model fails to improve; we will discuss this further in
    [*Chapter 6*](B18118_06.xhtml#_idTextAnchor129)*, Improving the Model*. Let’s
    look at the result now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Although we set our training for `1000` epochs, our `Earlystopping` callback
    halted the training process on the 29th epoch because it observed no meaningful
    drop in the loss. Although the result here isn’t great, we have used `EarlyStopping`
    to save a considerable amount of computational resources and time. Perhaps now
    is a good time to try out a different optimizer. For this next experiment, let’s
    use the Adam optimizer. Adam is another popular optimizer that is used in deep
    learning, due to its ability to adaptively control the learning rate for each
    parameter in a model, which accelerates the model’s convergence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Note we only changed the optimizer to Adam in our compile step. Let’s see the
    result of this change in the optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'By just changing the optimizer, we have recorded an incredible drop in loss.
    Also, note that we did not need the entire `1000` epochs, as training ended on
    `901` epochs. Let us add another layer; perhaps we will see an improved performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we added an extra layer with `64` neurons, with ReLU as the activation
    function. Everything else is the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Training stops at 270 epochs; although our model is more complex, it doesn’t
    perform better than `model_7` on training. We have tried out different ideas while
    experimenting; now, let us try out all eight models on the test set and evaluate
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To evaluate our models, we will write a function to apply the `evaluate` metrics
    to all eight models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We will generate an `eval_testing(model)` function that takes a model as an
    argument and uses the `evaluate` method to evaluate the performance of the model
    on our test dataset. Looping through the list of models, the code returns the
    loss and MAE values for all eight models for our test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: After we evaluate the models, we can that see `model_7` has the lowest loss.
    Let’s see how it does on our test set by using it to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we are done with experimenting and have evaluated the models, let’s
    use `model_7` to predict our test set salaries and see how they compare with the
    ground truth. To do this, we will use the `predict()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'After we run this code block, we get the output in an array, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'For clarity, let’s build a DataFrame with the model’s prediction and ground
    truth. This should be fun and somewhat magical when you see how good our model
    has become:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Here, we generate two columns and convert the model’s prediction from `float`
    to `int`, just to keep it in scope with the ground truth. Ready for the result?
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `head` function to print out the first 10 values of the test
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'We then see our results, as shown in *Figure 3**.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.15 – A DataFrame showing the actual values, predictions made by
    the model, and the resulting residuals](img/B18118_03_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 – A DataFrame showing the actual values, predictions made by the
    model, and the resulting residuals
  prefs: []
  type: TYPE_NORMAL
- en: Our model has achieved something impressive; it is really close to the initial
    salaries in our test data. Now, you can show the HR manager your amazing result.
    We must save the model so that we can load it and make predictions anytime we
    want. Let’s learn how to do this next.
  prefs: []
  type: TYPE_NORMAL
- en: Saving and loading models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The beauty of TensorFlow is the ease with which we can do complex stuff. To
    save a model, we just need one line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: You can save it as `your_model.h5` or `your_model`; either way works. TensorFlow
    recommends the `SavedModel` approach because it is language-agnostic, which makes
    it easy to deploy on various platforms. In this format, we can save the model
    and its individual components, such as the weights and variables. Conversely,
    the HDF5 format saves the complete model structure, its weights, and the training
    configurations as a single file. This approach gives us greater flexibility to
    share and distribute models; however, for deployment purposes, it’s not the preferred
    method. When we run the code, we can see the saved model on the left-hand panel
    in our Colab notebook, as shown in *Figure 3**.16*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16 – A snapshot of our saved model](img/B18118_03_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 – A snapshot of our saved model
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have saved the model, it is wise to test it out by reloading it
    and testing it. Let’s do that. Also, it’s just one line of code to load the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s try out our `saved_model` and see whether it will work as well as `model_7`.
    We will generate `y_pred` again and generate a DataFrame, using `y_test` and `y_pred`
    as we did earlier checking first the 10 random samples from our test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.17 – A DataFrame showing the actual values and predictions made
    by the saved model](img/B18118_03_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 – A DataFrame showing the actual values and predictions made by
    the saved model
  prefs: []
  type: TYPE_NORMAL
- en: 'From the results in *Figure 3**.17*, we can see that our saved model performs
    at a high level. Now, you can deliver your result to the HR manager, and they
    should be excited about your results. Let’s imagine that the HR manager wants
    you to use your model to predict the salary of the new hires. Let’s do that next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We generate a function using our saved model. We simply wrap all the steps
    we’ve covered so far into the function, and we return a DataFrame. Now, let’s
    read in the data of our new hires:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: When we run the code block, we can see their data in a DataFrame, as shown in
    *Figure 3**.18*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.18 – A DataFrame showing the new hires](img/B18118_03_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.18 – A DataFrame showing the new hires
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we pass the data into the function we generated to get the predicted salaries
    for our new hires:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We pass `df_new` into the salary prediction function, and we get a new DataFrame,
    as shown in *Figure 3**.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.19 – A DataFrame showing the new hires with their predicted salaries](img/B18118_03_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.19 – A DataFrame showing the new hires with their predicted salaries
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have achieved our goal. HR is happy, the new hires are happy, and
    everyone in the company thinks you are a magician. Perhaps a pay raise could be
    on the table, but while you bask in the euphoria around your first success, your
    manager returns with another task. This time, it is a classification task, which
    we will look at this in the next chapter. For now, good job!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we took a deeper dive into supervised learning, with a focus
    on regression modeling. Here, we discussed the difference between simple and multiple
    linear regression and looked at some important evaluation metrics for regression
    modeling. Then, we rolled up our sleeves on our case study, helping our company
    build a working regression model to predict the salaries of new employees. We
    carried out some data preprocessing steps and saw the importance of normalization
    in our modeling process.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the case study, we successfully built a salary prediction model,
    evaluated the model on our test set, and mastered how to save and load models
    for use at a later stage. Now, you can confidently build a regression model with
    TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll take a look at classification modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s test what we learned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: What is linear regression?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between simple and multiple linear regression?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What evaluation metric penalizes large errors in regression modeling?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the salary dataset to forecast salaries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more, you can check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amr, T., 2020\. *Hands-On Machine Learning with scikit-learn and Scientific
    Python Toolkits*. [S.l.]: Packt Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raschka, S. and Mirjalili, V., 2019\. *Python Machine Learning*. 3rd ed. Packt
    Publishing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TensorFlow* *documen**t**ation*: [https://www.TensorFlow.org/guide](https://www.TensorFlow.org/guide).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
