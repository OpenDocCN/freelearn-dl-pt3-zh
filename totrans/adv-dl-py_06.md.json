["```\nimport os.path\n\nimport cv2  # opencv import\nimport numpy as np\nimport requests\n```", "```\n# Download YOLO net config file\n# We'll it from the YOLO author's github repo\nyolo_config = 'yolov3.cfg'\nif not os.path.isfile(yolo_config):\n   url = 'https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg'\n    r = requests.get(url)\n    with open(yolo_config, 'wb') as f:\n        f.write(r.content)\n\n# Download YOLO net weights\n# We'll it from the YOLO author's website\nyolo_weights = 'yolov3.weights'\nif not os.path.isfile(yolo_weights):\n    url = 'https://pjreddie.com/media/files/yolov3.weights'\n    r = requests.get(url)\n    with open(yolo_weights, 'wb') as f:\n        f.write(r.content)\n\n# load the network\nnet = cv2.dnn.readNet(yolo_weights, yolo_config)\n```", "```\n# Download class names file\n# Contains the names of the classes the network can detect\nclasses_file = 'coco.names'\nif not os.path.isfile(classes_file):\n    url = 'https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names'\n    r = requests.get(url)\n    with open(classes_file, 'wb') as f:\n        f.write(r.content)\n\n# load class names\nwith open(classes_file, 'r') as f:\n    classes = [line.strip() for line in f.readlines()]\n```", "```\n# Download object detection image\nimage_file = 'source_1.png'\nif not os.path.isfile(image_file):\n    url = \"https://github.com/ivan-vasilev/advanced-deep-learning-with-python/blob/master/chapter04-detection-segmentation/source_1.png\"\n    r = requests.get(url)\n    with open(image_file, 'wb') as f:\n        f.write(r.content)\n\n# read and normalize image\nimage = cv2.imread(image_file)\nblob = cv2.dnn.blobFromImage(image, 1 / 255, (416, 416), (0, 0, 0), True, crop=False)\n```", "```\n# set as input to the net\nnet.setInput(blob)\n\n# get network output layers\nlayer_names = net.getLayerNames()\noutput_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n\n# inference\n# the network outputs multiple lists of anchor boxes,\n# one for each detected class\nouts = net.forward(output_layers)\n```", "```\n# extract bounding boxes\nclass_ids = list()\nconfidences = list()\nboxes = list()\n\n# iterate over all classes\nfor out in outs:\n    # iterate over the anchor boxes for each class\n    for detection in out:\n        # bounding box\n        center_x = int(detection[0] * image.shape[1])\n        center_y = int(detection[1] * image.shape[0])\n        w, h = int(detection[2] * image.shape[1]), int(detection[3] * image.shape[0])\n        x, y = center_x - w // 2, center_y - h // 2\n        boxes.append([x, y, w, h])\n\n        # confidence\n        confidences.append(float(detection[4]))\n\n        # class\n        class_ids.append(np.argmax(detection[5:]))\n```", "```\n# non-max suppression\nids = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.75, nms_threshold=0.5)\n```", "```\nfor i in ids:\n    i = i[0]\n    x, y, w, h = boxes[i]\n    class_id = class_ids[i]\n\n    color = colors[class_id]\n\n    cv2.rectangle(img=image,\n                  pt1=(round(x), round(y)),\n                  pt2=(round(x + w), round(y + h)),\n                  color=color,\n                  thickness=3)\n\n    cv2.putText(img=image,\n                text=f\"{classes[class_id]}: {confidences[i]:.2f}\",\n                org=(x - 10, y - 10),\n                fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n                fontScale=0.8,\n                color=color,\n                thickness=2)\n```", "```\ncv2.imshow(\"Object detection\", image)\ncv2.waitKey()\n```", "```\nimport os.path\n\nimport cv2\nimport numpy as np\nimport requests\nimport torchvision\nimport torchvision.transforms as transforms\n```", "```\n# load the pytorch model\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\n# set the model in evaluation mode\nmodel.eval()\n```", "```\nimg = cv2.imread(image_file)\n```", "```\ntransform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\nnn_input = transform(img)\noutput = model([nn_input])\n```", "```\ncolors = np.random.uniform(0, 255, size=(len(classes), 3))\n```", "```\n# iterate over the network output for all boxes\nfor box, box_class, score in zip(output[0]['boxes'].detach().numpy(),\n                                 output[0]['labels'].detach().numpy(),\n                                 output[0]['scores'].detach().numpy()):\n\n    # filter the boxes by score\n    if score > 0.5:\n        # transform bounding box format\n        box = [(box[0], box[1]), (box[2], box[3])]\n\n        # select class color\n        color = colors[box_class]\n\n        # extract class name\n        class_name = classes[box_class]\n\n        # draw the bounding box\n        cv2.rectangle(img=img, pt1=box[0], pt2=box[1], color=color, thickness=2)\n\n        # display the box class label\n        cv2.putText(img=img, text=class_name, org=box[0], \n                    fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=color, thickness=2)\n```", "```\ncv2.imshow(\"Object detection\", image)\ncv2.waitKey()\n```", "```\nmodel = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()\n```", "```\n# read the image file\nimg = cv2.imread(image_file)\n\n# transform the input to tensor\ntransform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\nnn_input = transform(img)\noutput = model([nn_input])\n```", "```\n# iterate over the network output for all boxes\nfor mask, box, score in zip(output[0]['masks'].detach().numpy(),\n                            output[0]['boxes'].detach().numpy(),\n                            output[0]['scores'].detach().numpy()):\n\n    # filter the boxes by score\n    if score > 0.5:\n        # transform bounding box format\n        box = [(box[0], box[1]), (box[2], box[3])]\n\n        # overlay the segmentation mask on the image with random color\n        img[(mask > 0.5).squeeze(), :] = np.random.uniform(0, 255, size=3)\n\n        # draw the bounding box\n        cv2.rectangle(img=img,\n                      pt1=box[0],\n                      pt2=box[1],\n                      color=(255, 255, 255),\n                      thickness=2)\n```", "```\ncv2.imshow(\"Object detection\", img)\ncv2.waitKey()\n```", "```\nimg[(mask > 0.5).squeeze(), :] = np.random.uniform(0, 255, size=3)\n```"]