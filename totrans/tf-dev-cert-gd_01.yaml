- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction to Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There has never been a more exciting time to be a deep learning expert. With
    the advent of super-fast computers, open source algorithms, well-curated datasets,
    and affordable cloud services, deep learning experts are armed with the requisite
    skills to build amazing and impactful applications across all domains. Computer
    vision, natural language processing, and time series analysis are just a few of
    the areas where deep learning experts can make a real impact. Anyone with the
    right skills can build a groundbreaking application and perhaps become the next
    Elon Musk. For this to happen, adequate knowledge of deep learning frameworks
    such as TensorFlow is required.
  prefs: []
  type: TYPE_NORMAL
- en: The TensorFlow Developer Certificate aims to build a new generation of deep
    learning experts who are already in high demand across all fields. Hence, joining
    this club equips you with the required expertise to start your journey as a deep
    learning expert and also presents you with a certificate to show for your weeks,
    months, or years of hard work.
  prefs: []
  type: TYPE_NORMAL
- en: We will begin this chapter with a high-level introduction to **machine learning**
    (**ML**), after which we will examine the different types of ML approaches. Next,
    we will drill down into the ML life cycle and use cases (we will cover a few hands-on
    implementations in subsequent chapters). We conclude this chapter by introducing
    the TensorFlow Developer Certificate and examining the anatomy of the core components
    needed to ace the exam. By the end of this chapter, you should be able to clearly
    explain what ML is and have gained a foundational understanding of the ML life
    cycle. Also, after this chapter, you will be able to differentiate between different
    types of ML approaches and clearly understand what the TensorFlow Developer Certificate
    exam is all about.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is ML?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of ML algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ML life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring ML use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the learning journey
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is ML?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML is a subfield of **artificial intelligence** (**AI**) in which computer systems
    learn patterns from data to perform specific tasks or make predictions on unseen
    data without being explicitly programmed. In 1959, Arthur Samuel defined ML as
    a “*field of study that gives computers the ability to learn without being explicitly
    programmed to do so*.” To give clarity to the definition given to us by Arthur
    Samuel, let us unpack it using a well-known use case of ML in the banking industry.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we work in the ML team of a Fortune 500 bank in the heart of London.
    We are saddled with the responsibility of automating the fraud detection process
    as the current manual process is too slow and costs the bank millions of pounds
    sterling, due to delays in the transaction processing time. Based on the preceding
    definition, we request historical data of previous transactions, containing both
    fraudulent and non-fraudulent transactions, after which we go through the ML life
    cycle (which we will cover shortly) and deploy our solution to prevent fraudulent
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we used historical data that provides us with the features
    (independent variables) needed to determine the outcome of the model, which is
    generally referred to as the target (dependent variable). In this scenario, the
    target is a fraudulent or non-fraudulent transaction, as shown in *Figure 1**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – A flowchart showing the features and the target in our data](img/B18118_01_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – A flowchart showing the features and the target in our data
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding scenario, we were able to train a model with historical data
    made up of features and the target to generate rules that are used to make predictions
    on unseen data. This is an example of what ML is all about – the ability to empower
    computers to make decisions without explicit programming. In classic programming,
    as shown in *Figure 1**.2*, we feed in the data and some hardcoded rules – for
    example, the volume of a daily transaction to determine whether it is fraudulent
    or not. If a customer goes above this daily limit, the customer’s account gets
    flagged, and a human moderator will intervene to decide whether the transaction
    was fraudulent or not.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2 – A traditional programming approach](img/B18118_01_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 – A traditional programming approach
  prefs: []
  type: TYPE_NORMAL
- en: This approach will soon leave the bank overwhelmed with unhappy customers constantly
    complaining about delayed transactions, while fraudsters and money launderers
    will evade the system by simply limiting their transactions within the daily permissible
    limits defined by the bank. With every new attribute, we would need to update
    the rules. This approach quickly becomes impractical, as there will always be
    something new to update to make the system tick. Like a house of cards, the system
    will eventually fall apart, as such a complex problem with continuously varying
    attributes across millions of daily transactions may be near impossible to explicitly
    program.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, we do not need to hardcode anything. We can use ML to build a model
    that can learn to identify patterns of fraudulent transactions from historical
    data, based on a set of input features in it. We train our model using labeled
    historical data of past transactions that contain both fraudulent and non-fraudulent
    transactions. This allows our model to develop rules based on the data, as shown
    in *Figure 1**.3*, which can be applied in the future to detect fraudulent transactions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – An ML approach](img/B18118_01_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 – An ML approach
  prefs: []
  type: TYPE_NORMAL
- en: 'The rules generated by examining the data are used by the model to make new
    predictions to curb fraudulent transactions. This paradigm shift differs from
    traditional programming where applications are built using well-defined rules.
    In ML-powered applications, such as our fraud detection system, the model learns
    to recognize patterns and create rules from the training data; it then uses these
    rules to make predictions on new data to efficiently flag fraudulent transactions,
    as shown in *Figure 1**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – An ML model uses rules to make predictions on unseen data](img/B18118_01_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 – An ML model uses rules to make predictions on unseen data
  prefs: []
  type: TYPE_NORMAL
- en: In the example we just examined, we can see from *Figure 1**.1* that our training
    data is usually structured in a tabular form, made up of numerical values such
    as transaction amount and frequency of transactions, as well as categorical variables
    such as location and payment type. In this type of data representation, we can
    easily identify both the features and the target. However, what about textual
    data from social media, images from our smartphones, video from streaming movies,
    and so on, as illustrated in *Figure 1**.5*? How do we approach these types of
    problems where the data is unstructured? Thankfully, we have a solution, which
    is called **deep learning**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – An illustration of structured and unstructured data types ](img/B18118_01_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 – An illustration of structured and unstructured data types
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning is a subset of ML that mimics the human brain by using complex
    hierarchical models that are composed of multiple processing layers. The buzz
    around deep learning lies around the state-of-the-art performance recorded by
    deep learning algorithms over the years across many real-world applications, such
    as object detection, image classification, and speech recognition, as deep learning
    algorithms can model complex relationships in data. In *Sections 2* and *3*, we
    will discuss deep learning in greater detail and see it in action for image and
    text applications, respectively. For now, let us probe further into the world
    of ML by looking at the types of ML algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Types of ML algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last section, we looked at what ML is, and we examined a use case where
    we had labeled data. In this section, we will look at the four main types of ML
    approaches to give us a base understanding of what each type does, and where and
    how they can be applied. The four types of ML algorithms are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s examine the four types of ML methods, which will serve as a building block
    for later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In **supervised learning**, an ML model is trained using data made of features
    and a target. This enables the model to learn the underlying relationship in the
    data. After training, the model can use its newfound knowledge to make predictions
    on unseen data. For example, say you want to buy a house. You would consider factors
    such as the location of the house, the number of rooms, the number of bathrooms,
    whether it has a garden, and the type of property; these factors you would consider
    as the features, while the price of the house is the target. Perhaps after the
    TensorFlow exam, you can roll up your sleeves, scrape some housing data, and train
    a model to predict house prices based on these features. You can use your house
    prediction model to compare prices on real estate websites to close a good deal
    for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of supervised learning – regression and classification.
    In a regression task, the label is a numeric value, just like the example we gave
    previously in which the target is the predicted price of the house. Conversely,
    in a classification task, the label is a category, just like the fraud example
    we discussed previously, in which the goal was to detect whether a transaction
    was fraudulent or not fraudulent. In a classification task, the model will learn
    to categorize the target as classes.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with a classification task made up of two classes (for example,
    fraudulent and non-fraudulent transactions), it is referred to as binary classification.
    When there are more than two categories (for example, the classification of different
    car brands), it is referred to as multi-class classification.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6: An example of multi-label classification, where the model identifies
    multiple subjects within an image](img/B18118_01_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: An example of multi-label classification, where the model identifies
    multiple subjects within an image'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-label classification is another type of classification, and it is used
    for image tagging in social media applications such as Facebook and Instagram.
    Unlike binary and multi-class classification tasks in which we have one target
    per instance, in multi-label classification our model identifies multiple targets
    for each instance, as shown in *Figure 1**.6*, where our model identifies a girl,
    a dog, a boy, and a cat in the given photo.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Unsupervised learning** is the opposite of supervised learning. In this case,
    there is no labeled data. The model will have to figure things out by itself.
    Here, an unsupervised learning algorithm is provided with data, and we expect
    it to extract meaningful insights from the unlabeled data, by identifying patterns
    within the data without relying on predefined targets – for example, an image
    you work on for a large retail store that aims to segment its customers for marketing
    purposes. You are given data containing the demographics and spending habits of
    the store’s customers. By employing an unsupervised ML model, you successfully
    cluster customers with similar characteristics into distinct customer segments.
    The marketing team can now create a tailored campaign targeted at each of the
    customer segments identified by the model, potentially leading to a higher conversion
    rate from the campaign.'
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Semi-supervised learning** is a combination of supervised and unsupervised
    learning. In this case, there is some data with labels (i.e., it has both features
    and a target) and the rest is without labels. In such scenarios, the unlabeled
    data is usually the dominant group. In this case, we can apply a combination of
    unsupervised and supervised learning methods to generate optimal results, especially
    when the cost implication and time required to manually label the data may not
    be practical. Here, the model takes advantage of the available label data to learn
    the underlying relationships, which it then applies to the unlabeled data.'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you work for a big corporation that collects a large volume of documents
    that we need to classify and send to the appropriate department (i.e, finance,
    marketing, and sales) for effective document management, and only a small number
    of the documents are labeled. Here, we apply semi-supervised learning, train the
    model on the labeled document, and apply the learned patterns to classify the
    remaining unlabeled documents.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In **reinforcement learning**, unlike supervised learning, the model does not
    learn from training data. Instead, it learns from its interactions within an environment;
    it gets rewarded for making the right decisions and punished for making wrong
    choices. It is a trial-and-error learning approach in which the model learns from
    its past experience to make better decisions in the future. The model aims to
    maximize reward. Reinforcement learning is applied in self-driving cars, robotics,
    trading and finance, question answering, and text summarization, among other exciting
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we can clearly differentiate between the different types of ML approaches,
    we can look into what the core components of an ML life cycle are and what steps
    we should take, from the birth of a project to its application by end users. Let
    us take a look at the ML life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: ML life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before embarking on any ML project, we must take into account some key components
    that can determine whether our project will be successful or not. And this is
    important because as data professionals who want to build and implement successful
    ML projects, we need to understand how the ML life cycle works. The ML life cycle
    is a sensible framework to implement an ML project, as shown in *Figure 1**.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7 – The ML life cycle](img/B18118_01_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.7 – The ML life cycle
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at each of these in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The business case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before unleashing state-of-the-art models on any problem, it is imperative you
    take time to sit with stakeholders to clearly understand the business objectives
    or the pain points to be resolved, as without clarity, the entire process will
    almost definitely fail. It is always important to keep in mind that the goal of
    the entire process is not to test a new breakthrough model you have been itching
    to try out but to solve a pain point, or create value for your company.
  prefs: []
  type: TYPE_NORMAL
- en: Once we understand the problem, we can categorize the problem as either a supervised
    or unsupervised learning task. This phase of an ML life cycle is all about asking
    the right questions. We need to sit with the concerned team to determine what
    the key metrics that would define the project as a success are. What resources
    are required in terms of budget, manpower, compute, and the project timeline?
    Do we have the domain understanding or do we need an expert’s input into defining
    and understanding the underlying factors and goals that will define the project’s
    success? These are some of the questions we should ask as data professionals before
    we embark on a project.
  prefs: []
  type: TYPE_NORMAL
- en: For the exam, we will need to understand the requirements of each question before
    we tackle them. We will discuss a lot more about the exam before we conclude this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Data gathering and understanding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When all the requirements are detailed, the next step is to collect the data
    required for the project. In this phase, we would first determine what type of
    data we will collect and where we will collect it from. Before we embark on anything,
    we need to ask ourselves whether the data is relevant – for example, if we collect
    historical car data from 1980, would we be able to predict the price of a car
    in 2022? Would data be made available by stakeholders, or would we be collecting
    it from a database, **Internet of Things** (**IoT**) devices, or via web scraping?
    Would there be any need for the collection of secondary data for the task at hand?
    Also, we would need to establish whether the data will be collected all at once
    or whether it will be a continuous process of data collection. Once we have collected
    the data needed for the project, we would then examine the data to get an understanding
    of it.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we would examine the data to see whether the data collected is in the
    right format. For example, if you collect car sales data from multiple sources,
    one source may calculate a car’s mileage in kilometers per hour and another source
    could use miles per hour. Also, there could be missing values in some of the features,
    and we might also encounter duplicates, outliers, and irrelevant features in the
    data we collected. During this phase, we would carry out data exploration to gain
    insights into the data, and data preprocessing to handle various issues such as
    formatting problems, missing values, duplicates, removal of irrelevant features,
    and handling outliers, imbalanced data, and categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a good understanding of the business needs, we have decided
    on the type of ML problem that we will address, and we also have good-quality
    data after completing our preprocessing step. We will split our data into a training
    split and keep a small subset of the test to evaluate the model’s performance.
    We will train our model to understand the relationship between the features and
    the target variable using our training set. For example, we could train our fraud
    detection model on historical data provided by the bank and test it out with our
    hold out (test set) to evaluate our model’s performance before deploying it for
    use. We go through an iterative process of fine-tuning our model hyperparameters
    until we arrive at our optimal model.
  prefs: []
  type: TYPE_NORMAL
- en: Defining whether the modeling process is a success or not is tied to the business
    objective, since achieving a high accuracy of 90 percent would still leave room
    for a 10 percent error, which could be decisive in high-stake domains such as
    healthcare. Imagine you deploy a model for early-stage cancer detection with an
    accuracy of 90 percent, which means the model would likely fail once for every
    10 people; in 100 tries, it could fail about 10 times, and it could misclassify
    someone with cancer as healthy. This could lead to the individual not only failing
    to seek medical advice but also to an untimely demise. Your company could get
    sued and the blame would fall in your lap. To avoid situations like this, we need
    to understand what metrics are important for our project and what we should be
    less strict with. It is also important to address factors such as class imbalance,
    model interpretability, and ethical implications.
  prefs: []
  type: TYPE_NORMAL
- en: There are various metrics that are used to evaluate a model, and the type of
    evaluation depends on the type of problem we will handle. We will discuss regression
    metrics in [*Chapter 3*](B18118_03.xhtml#_idTextAnchor065)*, Linear Regression
    with TensorFlow,* and classification metrics in [*Chapter 4*](B18118_04.xhtml#_idTextAnchor085)*,
    Classification* *with TensorFlow,*.
  prefs: []
  type: TYPE_NORMAL
- en: Error analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are not ready for deployment yet. Remember the 10 percent data that could
    tank our project? We will address that here. We perform an error analysis to identify
    the misclassified labels to identify why the model missed them. Do we have enough
    representative samples of these misclassified labels in our training data? We
    would have to determine whether we need to collect more data to capture these
    cases where the model failed. Can we generate synthetic data to capture the misclassified
    labels? Or was the misclassified data down to the wrong labeling?
  prefs: []
  type: TYPE_NORMAL
- en: Wrongly labeled data can hamper the performance of a model, as it will learn
    incorrect relationships between the features and target, resulting in poor performance
    on unseen data, making the model unreliable and the entire process a waste of
    resources and time. Once we resolve these questions and ensure accurate labels,
    we need to retrain and reevaluate our model. These steps are continuous until
    the business objective is achieved, and then we can proceed to deploy our model.
  prefs: []
  type: TYPE_NORMAL
- en: Model deployment and monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After resolving the issues identified in the error analysis step, we can now
    deploy our model to production. There are various methods of deployment available.
    We could deploy our model as a web service, on the cloud, or on edge devices.
    Model deployment can be challenging as well as exciting because the entire point
    of building and training a model is to allow end users to apply it to solve a
    pain point. Once we deploy our model, we also monitor the model to ensure that
    the overall objectives of the business are continually achieved, and even the
    best-performing models can begin to underperform over time due to concept drift
    and data drift. Hence, after deploying our model, we cannot retire to some island.
    We need to continuously monitor our model and retrain the model when needed in
    order to ensure it continues to perform optimally.
  prefs: []
  type: TYPE_NORMAL
- en: We have now gone through the full length of the ML life cycle at a high level.
    Of course, there is a lot more that we can talk about in greater depth, but this
    is out of the scope of this exam. Hence, we will now switch our focus to looking
    at a number of exciting use cases where ML can be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring ML use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beyond the car price prediction and fraud detection use cases, let’s look at
    some exciting applications of ML here. Perhaps it will get you fired up for both
    the exams and inspire you to build something spectacular in your ML journey.
  prefs: []
  type: TYPE_NORMAL
- en: Healthcare
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: HearAngel uses AI to automatically prevent hearing loss for headphone users
    by tracking users’ exposure to unhealthy levels of sounds from the headphones.
    Insitro uses knowledge of ML and biology for drug discovery and development. Other
    use cases of ML in healthcare include smart record keeping, data collection, disease
    outbreak forecasting, personalized medicine, and disease identification.
  prefs: []
  type: TYPE_NORMAL
- en: The retail industry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ML engineers are revolutionizing the retail industry by deploying models to
    enhance customer experience and improve profitability. This is achieved by optimizing
    assortment planning, predicting customer behavior, the provision of virtual assistants,
    inventory optimization, tracking customers’ sentiments, price optimization, product
    recommendation, and customer segmentation, among other use cases. In the retail
    industry, ML engineers provide value by automating cumbersome manual processes.
  prefs: []
  type: TYPE_NORMAL
- en: The entertainment industry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The entertainment industry currently applies ML/AI in automatic script and lyric
    generation. Yes, currently there are movie script-writing ML models. One such
    movie is a short science fiction movie called *Sunspring* ([https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/](https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/)).
    Also, ML/AI is used for automatic caption generation, augmented reality, game
    development, target marketing, sentiment analysis, movie recommendation, and sales
    forecasting, among others. So, if you plan to carve a niche in this industry as
    an ML engineer, there is a lot you can do, and surely you can also come up with
    some new ideas.
  prefs: []
  type: TYPE_NORMAL
- en: Education
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Readrly utilizes deep learning techniques to create personalized children’s
    stories, enhancing the learning experience for young readers. By tailoring stories
    to each child’s interests and skill level, Readrly supports children’s reading
    development in a fun and engaging way.
  prefs: []
  type: TYPE_NORMAL
- en: Agriculture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are numerous use cases of ML in agriculture. ML/AI can be used for price
    forecasting, disease detection, weather prediction, yield mapping, soil and crop
    health monitoring, and precision farming, among others.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we covered some use cases of ML. However, the exciting part is that, as
    an ML/DL engineer, you will be able to apply your knowledge to any industry as
    long as data is available. And that is the awesomeness of being an ML engineer
    – there are no restrictions. We have covered a lot already in this chapter; however,
    we have one more section to go, and it is a very important one, as it centers
    on the exam itself. Let’s jump in.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the learning journey
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TensorFlow Developer Certificate exam was designed and developed by Google
    to assess data professionals’ expertise in model building and training deep learning
    models with TensorFlow. The exams enable data professionals to showcase their
    skills in solving real-world problems with ML/DL, as shown in *Figure 1**.8*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.8 – The goal of the exam](img/B18118_01_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.8 – The goal of the exam
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dig deeper into why you should take this exam.
  prefs: []
  type: TYPE_NORMAL
- en: Why take the exam?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most compelling reasons why you should take the TensorFlow Developer
    Certificate is that it can help you get a job. The global AI market is expected
    to grow exponentially, reaching $2 trillion by 2030 according to a report by Statista
    ([https://www.statista.com/statistics/1365145/artificial-intelligence-market-size/#:~:text=The%20market%20for%20artificial%20intelligence,nearly%20two%20trillion%20U.S.%20dollars](https://www.statista.com/statistics/1365145/artificial-intelligence-market-size/#:~:text=The%20market%20for%20artificial%20intelligence,nearly%20two%20trillion%20U.S.%20dollars)).
  prefs: []
  type: TYPE_NORMAL
- en: This rapid growth is being driven by continued advancements in areas such as
    autonomous vehicles, image recognition, and natural language processing, powering
    a new wave of applications across a wide range of industries. This growth is expected
    to create an increased demand for deep learning specialists who can build cutting-edge
    ML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In light of this development, recruiters and hiring managers are on the lookout
    for skilled candidates who can build deep learning models with TensorFlow, and
    this certificate can help you stand out from the crowd. To further accelerate
    your job-hunting, Google has put together *TensorFlow Certificate Network*, which
    is an online database of certified TensorFlow developers across the globe, as
    shown in *Figure 1**.9*. Hiring managers can easily find suitable candidates to
    build their machine learning and deep learning solutions using a range of filters,
    such as location and years of experience, as well as verifying a candidate based
    on their name.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.9 – A map display of TensorFlow-certified developers](img/B18118_01_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.9 – A map display of TensorFlow-certified developers
  prefs: []
  type: TYPE_NORMAL
- en: In addition to helping you get a first job, the TensorFlow Developer Certificate
    can also help you advance your career. If you’re already working with TensorFlow,
    the certificate can help you demonstrate your expertise to your employer. This
    can lead to promotions and raises.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have looked at some of the reasons why you should take the exam,
    the next logical step is to look at what the exam is all about. Let us do that.
  prefs: []
  type: TYPE_NORMAL
- en: What is the exam all about?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you’re planning on becoming a certified TensorFlow developer, there are
    a few things you’ll need to know. Here’s a quick rundown of what you need to know
    to ace the TensorFlow Developer Certificate exam:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow developer skills
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and training neural network models using TensorFlow 2.x
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Natural language** **processing** (**NLP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series, sequences, and predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the complete exam details here: [https://www.tensorflow.org/static/extras/cert/TF_Certificate_Candidate_Handbook.pdf](https://www.tensorflow.org/static/extras/cert/TF_Certificate_Candidate_Handbook.pdf).
    However, this book covers each section of the exam in detail to help ensure success.
    The exam costs $100, but there is an option to apply for a stipend that, if approved,
    will allow you to only pay half the exam fee. The stipend must be used within
    90 days of receiving it and is only valid for one attempt. To apply for the stipend,
    you must provide information about yourself, why you need the stipend, and your
    portfolio projects with TensorFlow if you have any. You can find more information
    about how to access the TensorFlow Education Stipend using this link: [https://www.tensorflow.org/static/extras/cert/TF_Education_Stipend.pdf](https://www.tensorflow.org/static/extras/cert/TF_Education_Stipend.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: We have now covered what and why. Now, let us look at how you can ace the exam.
  prefs: []
  type: TYPE_NORMAL
- en: How to ace the exam
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you’re looking to become a certified TensorFlow developer, there are a few
    things you should know. First, you should be proficient in Python. Second, you’ll
    need to have a strong understanding of ML concepts and be able to use TensorFlow
    to build and train deep learning models with TensorFlow. If you’re not already
    familiar with Python programming, then *Modern Python Cookbook – Second Edition*
    by Steven F Lott is a good place to start.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some tips to help you ace the TensorFlow Developer Certificate exam:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Review the course material**: Before taking the exam, be sure to review the
    materials for every topic in the TensorFlow candidate handbook in detail. Pay
    special attention to building and training models, since the exam is hands-on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model building**: In addition to reviewing the course material, it’s also
    important to get some hands-on experience with TensorFlow. Experiment with building
    models, covering each section of the exam requirement. This book will get you
    started with the core fundamentals of ML and walk you through each section of
    the exam in a hands-on manner, ensuring that you can comfortably build and train
    all sorts of models with TensorFlow – from simple linear models to complex neural
    networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understand the exam format**: The exam is unlike many other exams. It is
    a five-hour coding exam with questions covering each section of the exam that
    we outlined. You will be given a task and asked to write code to solve it in PyCharm.
    So, you will need to spend some time mastering how to build, train, and save models
    in PyCharm before the exams. The exam is an open-book one, so you are allowed
    to use any resource you want during the exam.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Practice, practice, practice**: One of the best ways to prepare for the exam
    is to practice solving questions. You will find lots of hands-on practice questions
    in every chapter of this book, along with code files in the book’s GitHub repository.
    Additionally, you will find lots of datasets on the TensorFlow website and Kaggle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you’ve completed this book, you should be ready to take the TensorFlow
    Developer Certificate exam.
  prefs: []
  type: TYPE_NORMAL
- en: When to take the exam
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on your experience, you may need more or less time to prepare for
    the exam. If you are familiar with TensorFlow already, with hands-on model-building
    skills, you may take between three weeks to two months to prepare for the exam.
    However, if you are completely new to TensorFlow, it is advisable to look at around
    six months to thoroughly prepare for this exam, as stipulated on the exam website.
    However, these rules are not cast in stone. Everyone is different, so go at your
    own pace.
  prefs: []
  type: TYPE_NORMAL
- en: Exam tips
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After you sign up for the exam, you can take it within a six-month period.
    It is okay to set a target day for your exams early enough. The exam takes place
    in PyCharm, so you will need to take a few days or weeks to get used to PyCharm
    (if you’re not familiar with it) before the exam day. Here is an excellent video
    tutorial by Jeff Henton to help you set up your PyCharm environment: [https://www.youtube.com/watch?v=zRY5lx-So-c](https://www.youtube.com/watch?v=zRY5lx-So-c).
    Ensure you install the stipulated version of PyCharm. You can also learn more
    about setting up the exam environment using this link: [https://www.tensorflow.org/static/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf](https://www.tensorflow.org/static/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Before the exam, it helps to have a clearly planned study routine in which you
    can cover the outlined syllabus for the exam. This book will help you on this
    journey, so you should pay attention to the next chapters, as we will start coding
    and tackling the core components, which make up the exam henceforth. On exam day,
    I would advise you to find a quiet, comfortable space to take this exam. Ensure
    you are well rested and not going in exhausted, as the exam is five hours long.
    Also, try out your PyCharm and internet connectivity. Don’t panic, and read the
    questions thoroughly to have a clear understanding of what is required of you.
    Start from questions 1 to 5\. Since the questions get more difficult, it is better
    to get the easy ones out of the way quickly and tackle the more difficult ones
    afterward.
  prefs: []
  type: TYPE_NORMAL
- en: However, you should pace yourself correctly. Your saved model will be graded
    each time you submit it, and you are allowed to submit as many times as you want
    within the stipulated 5-hour time frame until you achieve an optimal result. You
    can also run your model in Colab if this enables you to work faster, especially
    if you have a model running in PyCharm. Colab provides you with free GPU access
    to train your model. The exam will be graded only in PyCharm, so bear this in
    mind. Ensure you save the model you train in Colab, and move it to the directory
    where you are stipulated to save the model for the exam.
  prefs: []
  type: TYPE_NORMAL
- en: If you need help, you can use Stack Overflow. You can also look through the
    code we use in this book, or any other material you use to prepare for your exam.
    However, if a question proves too difficult, move on to other questions. When
    you are done, you can return to the difficult one and work your way through it
    to avoid losing all your time on a difficult question. Also, you are allowed to
    submit multiple times, so work on improving your models until you attain optimal
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: What to expect after the exam
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The exam ends after five hours exactly, but you can submit it before that. After
    which, you will receive a congratulatory email if you have passed. After passing
    this exam, you will now be a member of the Google TensorFlow Developer community,
    opening more doors of opportunity for yourself. Assuming you pass (and I hope
    you do), you will get your certificate in about a week, which will look like *Figure
    1**.10*, and you will be added to the Google TensorFlow community in about two
    weeks. The certificate is valid for a period of three years.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.10 – TensorFlow Developer Certificate](img/B18118_01_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.10 – TensorFlow Developer Certificate
  prefs: []
  type: TYPE_NORMAL
- en: Now, you know the topics, the time frame, the cost, how to prepare, what to
    do on exam day, and what to expect after the exam. With this, we have come to
    the end of this chapter. We have covered a lot of theory in this chapter, which
    will serve as the basis for the work we will do together in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided an overview of ML, deep learning, and the types of ML
    approaches. It also covered the ML life cycle and various ML use cases across
    different domains. We looked at a high-level overview of the TensorFlow Developer
    Certificate, along with information on the components of the exam and how to prepare
    for it. At the end of this chapter, you should have a good foundational understanding
    of what ML is and its types. You should now be able to determine which problems
    are ML-based problems and those that require classic programming. You should also
    be able to unpack ML problems into different types and be familiar with what it
    takes to prepare for the TensorFlow Developer Certificate exam by Google.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at what TensorFlow is, set up our environment,
    and start coding our way to the end of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s test what we learned in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is ML?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is deep learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the types of ML?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the steps in the ML life cycle?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the TensorFlow Developer Certificate about?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the core areas of the exam?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more, you can check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*TensorFlow Developer Certificate* *overview*: [https://www.tensorflow.org/certificate](https://www.tensorflow.org/certificate)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hands-On Machine Learning with scikit-learn and Scientific Python: Toolkits*
    by Amr, T., Packt Publishing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deep Learning: Methods and Applications* by Li Deng, and Dong Yu: [https://doi.org/10.1561/2000000039](https://doi.org/10.1561/2000000039)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Movie written by algorithm turns out to be hilarious and* *intense*: [https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/](https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Python Machine Learning – Third Edition* by Sebastian Raschka and Vahid Mirjalili'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
