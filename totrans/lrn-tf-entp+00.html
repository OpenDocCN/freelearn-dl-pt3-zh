<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer004">&#13;
			<h1 id="_idParaDest-5"><a id="_idTextAnchor004"/>Preface</h1>&#13;
			<p>TensorFlow as a <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) library has matured into a production-ready ecosystem. This beginner's book uses practical examples to enable you to build and deploy TensorFlow models using optimal settings that ensure long-term support without having to worry about library deprecation or being left behind when it comes to bug fixes or workarounds.</p>&#13;
			<p>The book begins by showing you how to refine your TensorFlow project and set it up for enterprise-level deployment. You'll then learn to choose the version of TensorFlow. As you advance, you'll find out how to build and deploy models in a robust and stable environment by following recommended practices made available in TensorFlow Enterprise. This book also teaches you how to manage your services better and enhance the performance and reliability of your <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) applications. You'll discover how to use various enterprise-ready services to accelerate your ML and AI workflows on Google Cloud. Finally, you'll scale your ML models and handle heavy workloads across CPUs, GPUs, and cloud TPUs.</p>&#13;
			<p>By the end of this TensorFlow book, you'll have learned the patterns needed for TensorFlow Enterprise model development, data pipelines, training, and deployment.</p>&#13;
			<h1 id="_idParaDest-6"><a id="_idTextAnchor005"/>Who this book is for</h1>&#13;
			<p>This book is for data scientists, ML developers or engineers, and cloud practitioners who want to learn and implement various services and features offered by TensorFlow Enterprise from scratch. Basic knowledge of the ML development process will be useful.</p>&#13;
			<h1 id="_idParaDest-7"><a id="_idTextAnchor006"/>What this book covers</h1>&#13;
			<p><a href="B16070_01_Final_JM_ePub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a>, <em class="italic">Overview of TensorFlow Enterprise</em>, illustrates how to set up and run TensorFlow Enterprise in a <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) environment. This will give you initial hands-on experience in seeing how TensorFlow Enterprise integrates with other data services in GCP.</p>&#13;
			<p><a href="B16070_02_Final_JM_ePub.xhtml#_idTextAnchor061"><em class="italic">Chapter 2</em></a>, <em class="italic">Running TensorFlow Enterprise in Google AI Platform</em>, describes how to use GCP to set up and run TensorFlow Enterprise. As a differentiated TensorFlow distribution, TensorFlow Enterprise can be found on several (but not all) GCP platforms. It is important to use these platforms in order to ensure that the correct distribution is provisioned.Â </p>&#13;
			<p><a href="B16070_03_Final_JM_ePub.xhtml#_idTextAnchor081"><em class="italic">Chapter 3</em></a>, <em class="italic">Data Preparation and Manipulation Techniques</em>, illustrates how to deal with raw data and format it to uniquely suit consumption by a TensorFlow model training process. We will look at a number of essential TensorFlow Enterprise APIs that convert raw data into Protobuf format for efficient streaming, which is a recommended workflow for feeding data into a training process.</p>&#13;
			<p><a href="B16070_04_Final_JM_ePub.xhtml#_idTextAnchor101"><em class="italic">Chapter 4</em></a>, <em class="italic">Reusable Models and Scalable Data Pipelines</em>, describes the different ways in which a TensorFlow Enterprise model may be built or reused. These options provide the flexibility to suit different situational requirements for building, training, and deploying TensorFlow models. Equipped with this knowledge, you will be able to make informed choices and understand the trade-offs among different model development strategies.</p>&#13;
			<p><a href="B16070_05_Final_JM_ePub.xhtml#_idTextAnchor145"><em class="italic">Chapter 5</em></a>, <em class="italic">Training at Scale</em>, illustrates the use of TensorFlow Enterprise distributed training strategies to scale your model training to a cluster (either GPU or TPU). This will enable you to build a model development and training process that is robust and take advantage of all the hardware at your disposal.</p>&#13;
			<p><a href="B16070_06_Final_JM_ePub.xhtml#_idTextAnchor177"><em class="italic">Chapter 6</em></a>, <em class="italic">Hyperparameter Tuning</em>, focuses on hyperparameter tuning as this is a necessary part of model training, especially when building your own model. TensorFlow Enterprise now provides high-level APIs for advanced hyperparameter space search algorithms. Through this chapter, you will learn how to leverage the distributed computing power at your disposal to reduce the training time required for hyperparameter tuning.</p>&#13;
			<p><a href="B16070_07_Final_JM_ePub.xhtml#_idTextAnchor200"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Optimization</em>, explores the concept of how lean and mean your model is. Does your model run as efficiently as possible? If your use case requires the model to run with limited resources (memory, model size, or data type), such as in the case of edge or mobile devices, then it's time to consider model runtime optimization. This chapter discusses the latest means of model optimization through the TensorFlow Lite framework. After this chapter, you will be able to optimize a trained TensorFlow Enterprise model to be as lightweight as possible for inferencing.</p>&#13;
			<p><a href="B16070_08_Final_JM_ePub.xhtml#_idTextAnchor235"><em class="italic">Chapter 8</em></a>, <em class="italic">Best Practices for Model Training and Performance</em>, focuses on two aspects of model training that are universal: data ingestion and overfitting. First, it is necessary to build a data ingestion pipeline that works regardless of the size and complexity of the training data. In this chapter, best practices and recommendations for using TensorFlow Enterprise data preprocessing pipelines are explained and demonstrated. Second, in dealing with overfitting, standard practices of regularization as well as some recently released regularizations by the TensorFlow team are discussed.</p>&#13;
			<p><a href="B16070_09_Final_JM_ePub.xhtml#_idTextAnchor249"><em class="italic">Chapter 9</em></a>, <em class="italic">Serving a TensorFlow Model</em>, describes the fundamentals of model inferencing as a web service. You will learn how to serve a TensorFlow model using TensorFlow Serving by building a Docker image of the model. In this chapter, you will begin by learning how to make use of saved models in your local environment first. Then you will build a Docker image of the model using TensorFlow Serving as the base image. Finally, you will serve this model as a web service through the RESTful API exposed by your Docker container. </p>&#13;
			<h1 id="_idParaDest-8"><a id="_idTextAnchor007"/>To get the most out of this book</h1>&#13;
			<p>It would be very helpful to have a fundamental understanding of, and experience with, the Keras API, as this book pivots on a TensorFlow version beyond 2.x, in which the Keras API is officially supported and adopted as the <strong class="source-inline">tf.keras</strong> API. In addition, having a basic understanding of image classification techniques (convolution, and multiclass classification) would be helpful, as this book reuses the image classification problem as a vehicle to introduce and explain new features in TensorFlow Enterprise 2. Another helpful tool is GitHub. Basic experience with cloning GitHub repositories and navigating file structures would be very helpful for downloading the source code in this book. </p>&#13;
			<p>From the ML perspective, having a basic understanding of model architectures, feature engineering processes, and hyperparameter optimization would be helpful. It is also assumed that you are familiar with fundamental Python data structures, including NumPy arrays, tuples, and dictionaries.</p>&#13;
			<p><strong class="bold">If you are using the digital version of this book, we advise you to type the code in yourself or access the code via the GitHub repository (link available in the next section). Doing so will help you avoid any potential errors related to the copying/pasting of code.</strong></p>&#13;
			<h1 id="_idParaDest-9"><a id="_idTextAnchor008"/>Download the example code files</h1>&#13;
			<p>You can download the example code files for this book from GitHub at <a href="https://github.com/PacktPublishing/learn-tensorflow-enterprise/">https://github.com/PacktPublishing/learn-tensorflow-enterprise/</a>. In case there's an update to the code, it will be updated on the existing GitHub repository. </p>&#13;
			<p>We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</p>&#13;
			<h1 id="_idParaDest-10"><a id="_idTextAnchor009"/>Download the color images</h1>&#13;
			<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="_ColorImages.pdf">https://static.packt-cdn.com/downloads/9781800209145_ColorImages.pdf</a></p>&#13;
			<h1 id="_idParaDest-11"><a id="_idTextAnchor010"/>Conventions used</h1>&#13;
			<p>There are a number of text conventions used throughout this book.</p>&#13;
			<p><strong class="source-inline">Code in text</strong>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: 'Just like <strong class="source-inline">lxterminal</strong>, we can run Linux commands from here too.'</p>&#13;
			<p>A block of code is set as follows:</p>&#13;
			<p class="source-code">p2 = Person()</p>&#13;
			<p class="source-code">p2.name = 'Jane'</p>&#13;
			<p class="source-code">p2.age = 20</p>&#13;
			<p class="source-code">print(p2.name)</p>&#13;
			<p class="source-code">print(p2.age)</p>&#13;
			<p>Any command-line input or output is written as follows:</p>&#13;
			<p class="source-code">sudo apt-get install xrdp -y</p>&#13;
			<p><strong class="bold">Bold</strong>: Indicates a new term, an important word, or words that you see on screen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: 'Open the <strong class="bold">Remote Desktop Connection</strong> application on your Windows PC.'</p>&#13;
			<p class="callout-heading">Tips or important notes	</p>&#13;
			<p class="callout">Appear like this.</p>&#13;
			<h1 id="_idParaDest-12"><a id="_idTextAnchor011"/>Get in touch</h1>&#13;
			<p>Feedback from our readers is always welcome.</p>&#13;
			<p><strong class="bold">General feedback</strong>: If you have questions about any aspect of this book, mention the book title in the subject of your message and email us at <strong class="source-inline">customercare@packtpub.com</strong>.</p>&#13;
			<p><strong class="bold">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>&#13;
			<p><strong class="bold">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <strong class="source-inline">copyright@packt.com</strong> with a link to the material.</p>&#13;
			<p><strong class="bold">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in, and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com">authors.packtpub.com</a>.</p>&#13;
			<p>Reviews</p>&#13;
			<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>&#13;
			<p>For more information about Packt, please visit <a href="http://packt.com">packt.com</a>.</p>&#13;
		</div>&#13;
	</div></body></html>