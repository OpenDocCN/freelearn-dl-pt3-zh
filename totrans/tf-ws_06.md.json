["```\nfrom tensorflow.keras.regularizers import l1\nl1_reg = l1(l=0.01)\n```", "```\nfrom tensorflow.keras.layers import Dense\nDense(10, kernel_regularizer=l1_reg)\n```", "```\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Dense\nl2_reg = l2(l=0.01)\nDense(20, kernel_regularizer=l2_reg)\n```", "```\nfrom tensorflow.keras.regularizers \nimport l1_l2\nl1_l2_reg = l1_l2(l1=0.01, l2=0.001)\n```", "```\n    import pandas as pd\n    ```", "```\n    file_url = 'https://raw.githubusercontent.com/PacktWorkshops'\\\n              '/The-TensorFlow-Workshop/master/Chapter06/dataset'\\\n              '/connect-4.csv'\n    ```", "```\n    data = pd.read_csv(file_url)\n    data.head()\n    ```", "```\n    target = data.pop('class')\n    ```", "```\n    import tensorflow as tf\n    from tensorflow.keras.layers import Dense\n    ```", "```\n    tf.random.set_seed(8)\n    ```", "```\n    model = tf.keras.Sequential()\n    ```", "```\n    fc1 = Dense(512, input_shape=(42,), activation='relu')\n    ```", "```\n    fc2 = Dense(512, activation='relu')\n    fc3 = Dense(128, activation='relu')\n    fc4 = Dense(128, activation='relu')\n    ```", "```\n    fc5 = Dense(3, activation='softmax')\n    ```", "```\n    model.add(fc1)\n    model.add(fc2)\n    model.add(fc3)\n    model.add(fc4)\n    model.add(fc5)\n    ```", "```\n    model.summary()\n    ```", "```\n    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n    ```", "```\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```\n    model.compile(optimizer=optimizer, loss=loss, \\\n                  metrics=['accuracy'])\n    ```", "```\n    model.fit(data, target, epochs=5, validation_split=0.2)\n    ```", "```\n    reg_fc1 = Dense(512, input_shape=(42,), activation='relu', \\\n                    kernel_regularizer=tf.keras.regularizers\\\n                                         .l2(l=0.1))\n    reg_fc2 = Dense(512, activation='relu', \\\n                    kernel_regularizer=tf.keras.regularizers\\\n                                         .l2(l=0.1))\n    reg_fc3 = Dense(128, activation='relu', \\\n                    kernel_regularizer=tf.keras.regularizers\\\n                                         .l2(l=0.1))\n    reg_fc4 = Dense(128, activation='relu', \\\n                    kernel_regularizer=tf.keras.regularizers\\\n                                         .l2(l=0.1))\n    reg_fc5 = Dense(3, activation='softmax')\n    ```", "```\n    model2 = tf.keras.Sequential()\n    model2.add(reg_fc1)\n    model2.add(reg_fc2)\n    model2.add(reg_fc3)\n    model2.add(reg_fc4)\n    model2.add(reg_fc5)\n    ```", "```\n    model2.summary()\n    ```", "```\n    model2.compile(optimizer=optimizer, loss=loss, \\\n                   metrics=['accuracy'])\n    ```", "```\n    model2.fit(data, target, epochs=5, validation_split=0.2)\n    ```", "```\nfrom tensorflow.keras.layers import Dropout\ndo = Dropout(0.5)\n```", "```\n    import pandas as pd\n    ```", "```\n    file_url = 'https://raw.githubusercontent.com/PacktWorkshops'\\\n               '/The-TensorFlow-Workshop/master/Chapter06/dataset'\\\n               '/connect-4.csv'\n    ```", "```\n    data = pd.read_csv(file_url)\n    data.head()\n    ```", "```\n    target = data.pop('class')\n    ```", "```\n    import tensorflow as tf\n    from tensorflow.keras.layers import Dense\n    ```", "```\n    tf.random.set_seed(8)\n    ```", "```\n    model = tf.keras.Sequential()\n    ```", "```\n    fc1 = Dense(512, input_shape=(42,), activation='relu')\n    ```", "```\n    fc2 = Dense(512, activation='relu')\n    fc3 = Dense(128, activation='relu')\n    fc4 = Dense(128, activation='relu')\n    ```", "```\n    fc5 = Dense(3, activation='softmax')\n    ```", "```\n    model.add(fc1)\n    model.add(Dropout(0.75))\n    model.add(fc2)\n    model.add(Dropout(0.75))\n    model.add(fc3)\n    model.add(Dropout(0.75))\n    model.add(fc4)\n    model.add(Dropout(0.75))\n    model.add(fc5)\n    ```", "```\n    model.summary()\n    ```", "```\n    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n    ```", "```\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```\n    model.compile(optimizer=optimizer, loss=loss, \\\n                  metrics=['accuracy'])\n    ```", "```\n    model.fit(data, target, epochs=5, validation_split=0.2)\n    ```", "```\nfrom tensorflow.keras.callbacks import EarlyStopping\nEarlyStopping(monitor='val_accuracy', patience=5)\n```", "```\npip install keras-tuner\n```", "```\nhp.Choice('learning_rate', values = [0.1, 0.01, 0.001, 0.0001])\n```", "```\ntuner.search(X_train, y_train, validation_data=(X_test, y_test))\n```", "```\nbest_hps = tuner.get_best_hyperparameters()[0]\nbest_hps.get('learning_rate')\n```", "```\nmodel = tuner.hypermodel.build(best_hps)\n```", "```\ndef model_builder(hp):\n    model = tf.keras.Sequential()\n    hp_lr = hp.Choice('learning_rate', \\\n                      values = [0.1, 0.01, 0.001, 0.0001])\n    model.add(Dense(512, input_shape=(100,), activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n    optimizer = tf.keras.optimizers.Adam(hp_lr)\n    model.compile(optimizer=optimizer, loss=loss, \\\n                  metrics=['accuracy'])\n    return model\n```", "```\nimport kerastuner as kt\ntuner = kt.RandomSearch(model_builder, objective='val_accuracy', \\\n                        max_trials=10)\n```", "```\n    import pandas as pd\n    ```", "```\n    file_url = 'https://raw.githubusercontent.com/PacktWorkshops'\\\n              '/The-TensorFlow-Workshop/master/Chapter06/dataset'\\\n              '/connect-4.csv'\n    ```", "```\n    data = pd.read_csv(file_url)\n    data.head()\n    ```", "```\n    target = data.pop('class')\n    ```", "```\n    from sklearn.model_selection import train_test_split\n    ```", "```\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (data, target, \\\n                                        test_size=0.2, \\\n                                        random_state=42)\n    ```", "```\n    !pip install keras-tuner\n    import kerastuner as kt\n    ```", "```\n    import tensorflow as tf\n    from tensorflow.keras.layers import Dense\n    ```", "```\n    tf.random.set_seed(8)\n    ```", "```\n    def model_builder(hp):\n        model = tf.keras.Sequential()\n        p_l2 = hp.Choice('l2', values = [0.1, 0.01, 0.001, 0.0001])\n        reg_fc1 = Dense(512, input_shape=(42,), activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=hp_l2))\n        reg_fc2 = Dense(512, activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=hp_l2))\n        reg_fc3 = Dense(128, activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=hp_l2))\n        reg_fc4 = Dense(128, activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=hp_l2))\n        reg_fc5 = Dense(3, activation='softmax')\n\n        model.add(reg_fc1)\n        model.add(reg_fc2)\n        model.add(reg_fc3)\n        model.add(reg_fc4)\n        model.add(reg_fc5)\n        loss = tf.keras.losses.SparseCategoricalCrossentropy()\n        optimizer = tf.keras.optimizers.Adam(0.001)\n        model.compile(optimizer = optimizer, loss = loss, \\\n                      metrics = ['accuracy'])\n        return model\n    ```", "```\n    tuner = kt.RandomSearch(model_builder, objective='val_accuracy', \\\n                            max_trials=10)\n    ```", "```\n    tuner.search(X_train, y_train, validation_data=(X_test, y_test))\n    ```", "```\n    best_hps = tuner.get_best_hyperparameters()[0]\n    ```", "```\n    best_l2 = best_hps.get('l2')\n    best_l2\n    ```", "```\n    0.0001\n    ```", "```\n    model = tuner.hypermodel.build(best_hps)\n    model.fit(X_train, y_train, epochs=5, \\\n              validation_data=(X_test, y_test))\n    ```", "```\ntuner = kt.Hyperband(model_builder, objective='val_accuracy', \\\n                     max_epochs=5)\n```", "```\n    import pandas as pd\n    ```", "```\n    file_url = 'https://raw.githubusercontent.com/PacktWorkshops'\\\n               '/The-TensorFlow-Workshop/master/Chapter06/dataset'\\\n               '/connect-4.csv'\n    ```", "```\n    data = pd.read_csv(file_url)\n    data.head()\n    ```", "```\n    target = data.pop('class')\n    ```", "```\n    from sklearn.model_selection import train_test_split\n    ```", "```\n    X_train, X_test, y_train, y_test = train_test_split\\\n                                       (data, target, \\\n                                        test_size=0.2, \\\n                                        random_state=42)\n    ```", "```\n    !pip install keras-tuner\n    import kerastuner as kt\n    ```", "```\n    import tensorflow as tf\n    from tensorflow.keras.layers import Dense\n    ```", "```\n    tf.random.set_seed(8)\n    ```", "```\n    def model_builder(hp):\n        model = tf.keras.Sequential()\n        hp_units = hp.Int('units', min_value=128, max_value=512, \\\n                          step=64)\n        reg_fc1 = Dense(hp_units, input_shape=(42,), \\\n                        activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=0.0001))\n        reg_fc2 = Dense(512, activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=0.0001))\n        reg_fc3 = Dense(128, activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=0.0001))\n        reg_fc4 = Dense(128, activation='relu', \\\n                        kernel_regularizer=tf.keras.regularizers\\\n                                             .l2(l=0.0001))\n        reg_fc5 = Dense(3, activation='softmax')\n        model.add(reg_fc1)\n        model.add(reg_fc2)\n        model.add(reg_fc3)\n        model.add(reg_fc4)\n        model.add(reg_fc5)\n        loss = tf.keras.losses.SparseCategoricalCrossentropy()\n        hp_learning_rate = hp.Choice('learning_rate', \\\n                                     values = [0.01, 0.001, 0.0001])\n        optimizer = tf.keras.optimizers.Adam(hp_learning_rate)\n        model.compile(optimizer = optimizer, loss = loss, \\\n                      metrics = ['accuracy'])\n        return model\n    ```", "```\n    tuner = kt.Hyperband(model_builder, objective='val_accuracy', \\\n                         max_epochs=5)\n    ```", "```\n    tuner.search(X_train, y_train, validation_data=(X_test, y_test))\n    ```", "```\n    best_hps = tuner.get_best_hyperparameters()[0]\n    ```", "```\n    best_units = best_hps.get('units')\n    best_units\n    ```", "```\n    192\n    ```", "```\n    best_lr = best_hps.get('learning_rate')\n    best_lr\n    ```", "```\n    0.001\n    ```", "```\n    model.fit(X_train, y_train, epochs=5, \\\n              validation_data=(X_test, y_test))\n    ```", "```\ntuner = kt.BayesianOptimization(model_builder, \\\n                                objective='val_accuracy', \\\n                                max_trials=10)\n```"]