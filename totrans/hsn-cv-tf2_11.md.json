["```\ninception_v3 = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n```", "```\nx = inception_v3.output\npooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n\nfeature_extraction_model = tf.keras.Model(inception_v3.input, pooling_output)\n```", "```\ndataset = tf.data.Dataset.from_generator(frame_generator,\n             output_types=(tf.float32, tf.string),\n             output_shapes=((299, 299, 3), ())\n```", "```\ndef frame_generator():\n    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\n    for video_path in video_paths:\n        capture = cv2.VideoCapture(video_path)\n        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n        current_frame = 0\n\n        label = os.path.basename(os.path.dirname(video_path))\n        while True:\n            success, frame = capture.read()\n            if not success:\n                break\n\n            if current_frame % sample_every_frame == 0:\n                img = preprocess_frame(frame)\n                yield img, video_path\n\n            current_frame += 1\n```", "```\ndataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\ncurrent_path = None\nall_features = []\n\nfor img, batch_paths in tqdm.tqdm(dataset):\n    batch_features = feature_extraction_model(img)\n\n    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n        if path != current_path and current_path is not None:\n            output_path = current_path.decode().replace('.avi', '')\n            np.save(output_path, all_features)\n            all_features = []\n\n        current_path = path\n        all_features.append(features)\n```", "```\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Masking(mask_value=0.),\n    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(len(LABELS), activation='softmax')\n])\n```", "```\ndef make_generator(file_list):\n    def generator():\n        np.random.shuffle(file_list)\n        for path in file_list:\n            full_path = os.path.join(BASE_PATH, path)\n            full_path = full_path.replace('.avi', '.npy')\n\n            label = os.path.basename(os.path.dirname(path))\n            features = np.load(full_path)\n\n            padded_sequence = np.zeros((SEQUENCE_LENGTH, 2048))\n            padded_sequence[0:len(features)] = np.array(features)\n\n            transformed_label = encoder.transform([label])\n            yield padded_sequence, transformed_label[0]\n    return generator\n```", "```\ntrain_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\n                 output_types=(tf.float32, tf.int16),\n                 output_shapes=((SEQUENCE_LENGTH, 2048), (len(LABELS))))\ntrain_dataset = train_dataset.batch(16)\ntrain_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\nvalid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\n                 output_types=(tf.float32, tf.int16),\n                 output_shapes=((SEQUENCE_LENGTH, 2048), (len(LABELS))))\nvalid_dataset = valid_dataset.batch(16)\nvalid_dataset = valid_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n```"]