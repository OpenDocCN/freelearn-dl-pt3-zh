["```\n$> pip install opencv-contrib-python Pillow imutils\n```", "```\n    import cv2\n    import imutils\n    import numpy as np\n    from tensorflow.keras.applications import imagenet_utils\n    from tensorflow.keras.applications.inception_resnet_v2 \\\n        import *\n    from tensorflow.keras.preprocessing.image import img_to_array\n    ```", "```\n    class ObjectDetector(object):\n        def __init__(self, \n                     classifier,\n                     preprocess_fn=lambda x: x,\n                     input_size=(299, 299),\n                     confidence=0.98,\n                     window_step_size=16,\n                     pyramid_scale=1.5,\n                     roi_size=(200, 150),\n                     nms_threshold=0.3):\n            self.classifier = classifier\n            self.preprocess_fn = preprocess_fn\n            self.input_size = input_size\n            self.confidence = confidence\n            self.window_step_size = window_step_size\n            self.pyramid_scale = pyramid_scale\n            self.roi_size = roi_size\n            self.nms_threshold = nms_threshold\n    ```", "```\n        def sliding_window(self, image):\n            for y in range(0,\n                           image.shape[0],\n                           self.window_step_size):\n                for x in range(0,\n                               image.shape[1],\n                               self.window_step_size):\n                  y_slice = slice(y, y + self.roi_size[1], 1)\n                  x_slice = slice(x, x + self.roi_size[0], 1)\n                    yield x, y, image[y_slice, x_slice]\n    ```", "```\n        def pyramid(self, image):\n            yield image\n            while True:\n                width = int(image.shape[1] / \n                         self.pyramid_scale)\n                image = imutils.resize(image, width=width)\n                if (image.shape[0] < self.roi_size[1] or\n                        image.shape[1] < \n                      self.roi_size[0]):\n                    break\n                yield image\n    ```", "```\n        def non_max_suppression(self, boxes, probabilities):\n            if len(boxes) == 0:\n                return []\n            if boxes.dtype.kind == 'i':\n                boxes = boxes.astype(np.float)\n            pick = []\n            x_1 = boxes[:, 0]\n            y_1 = boxes[:, 1]\n            x_2 = boxes[:, 2]\n            y_2 = boxes[:, 3]\n            area = (x_2 - x_1 + 1) * (y_2 - y_1 + 1)\n            indexes = np.argsort(probabilities)\n    ```", "```\n            while len(indexes) > 0:\n                last = len(indexes) - 1\n                i = indexes[last]\n                pick.append(i)\n    ```", "```\n                xx_1 = np.maximum(x_1[i],x_1[indexes[:last]])\n                yy_1 = np.maximum(y_1[i],y_1[indexes[:last]])\n                xx_2 = np.maximum(x_2[i],x_2[indexes[:last]])\n                yy_2 = np.maximum(y_2[i],y_2[indexes[:last]])\n                width = np.maximum(0, xx_2 - xx_1 + 1)\n                height = np.maximum(0, yy_2 - yy_1 + 1)\n                overlap = (width * height) / \n                          area[indexes[:last]]\n                redundant_boxes = \\\n                    np.where(overlap > \n                            self.nms_threshold)[0]\n                to_delete = np.concatenate(\n                    ([last], redundant_boxes))\n                indexes = np.delete(indexes, to_delete)\n    ```", "```\n            return boxes[pick].astype(np.int)\n    ```", "```\n        def detect(self, image):\n            rois = []\n            locations = []\n    ```", "```\n            for img in self.pyramid(image):\n                scale = image.shape[1] / \n                        float(img.shape[1])\n                for x, y, roi_original in \\\n                        self.sliding_window(img):\n                    x = int(x * scale)\n                    y = int(y * scale)\n                    w = int(self.roi_size[0] * scale)\n                    h = int(self.roi_size[1] * scale)\n                    roi = cv2.resize(roi_original, \n                                     self.input_size)\n                    roi = img_to_array(roi)\n                    roi = self.preprocess_fn(roi)\n                    rois.append(roi)\n                    locations.append((x, y, x + w, y + h))\n            rois = np.array(rois, dtype=np.float32)\n    ```", "```\n            predictions = self.classifier.predict(rois)\n            predictions = \\\n           imagenet_utils.decode_predictions(predictions, \n                                                  top=1)\n    ```", "```\n            labels = {}\n            for i, pred in enumerate(predictions):\n                _, label, proba = pred[0]\n                if proba >= self.confidence:\n                    box = locations[i]\n                    label_detections = labels.get(label, [])\n                    label_detections.append({'box': box,\n                                             'proba': \n                                              proba})\n                    labels[label] = label_detections\n            return labels\n    ```", "```\n    model = InceptionResNetV2(weights='imagenet',\n                              include_top=True)\n    object_detector = ObjectDetector(model, preprocess_input)\n    ```", "```\n    image = cv2.imread('dog.jpg')\n    image = imutils.resize(image, width=600)\n    labels = object_detector.detect(image)\n    ```", "```\n    GREEN = (0, 255, 0)\n    for i, label in enumerate(labels.keys()):\n        clone = image.copy()\n        for detection in labels[label]:\n            box = detection['box']\n            probability = detection['proba']\n            x_start, y_start, x_end, y_end = box\n            cv2.rectangle(clone, (x_start, y_start),\n                          (x_end, y_end), (0, 255, 0), 2)\n        cv2.imwrite(f'Before_{i}.jpg', clone)\n    ```", "```\n        clone = image.copy()\n        boxes = np.array([d['box'] for d in \n                       labels[label]])\n        probas = np.array([d['proba'] for d in \n                        labels[label]])\n        boxes = object_detector.non_max_suppression(boxes,\n                                                  probas)\n        for x_start, y_start, x_end, y_end in boxes:\n            cv2.rectangle(clone, (x_start, y_start),\n                          (x_end, y_end), GREEN, 2)\n\n            if y_start - 10 > 10:\n                y = y_start - 10\n            else:\n                y = y_start + 10\n\n            cv2.putText(clone, label, (x_start, y),\n                        cv2.FONT_HERSHEY_SIMPLEX, .45,\n                        GREEN, 2)\n        cv2.imwrite(f'After_{i}.jpg', clone)\n    ```", "```\n$> pip install tqdm\n```", "```\n    import glob\n    import json\n    import struct\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tqdm\n    from matplotlib.patches import Rectangle\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.models import *\n    from tensorflow.keras.preprocessing.image import *\n    ```", "```\n    class WeightReader:\n        def __init__(self, weight_file):\n            with open(weight_file, 'rb') as w_f:\n                major, = struct.unpack('i', w_f.read(4))\n                minor, = struct.unpack('i', w_f.read(4))\n                revision, = struct.unpack('i', w_f.read(4))\n                if (major * 10 + minor) >= 2 and \\\n                        major < 1000 and \\\n                        minor < 1000:\n                    w_f.read(8)\n                else:\n                    w_f.read(4)\n                binary = w_f.read()\n            self.offset = 0\n            self.all_weights = np.frombuffer(binary,\n                                         dtype='float32')\n    ```", "```\n        def read_bytes(self, size):\n            self.offset = self.offset + size\n            return self.all_weights[self.offset-\n                                   size:self.offset]\n    ```", "```\n        def load_weights(self, model):\n            for i in tqdm.tqdm(range(106)):\n                try:\n                    conv_layer = model.get_layer(f'conv_{i}')\n                    if i not in [81, 93, 105]:\n                        norm_layer = \n                 model.get_layer(f'bnorm_{i}')\n                        size = np.prod(norm_layer.\n\n                                  get_weights()[0].shape)\n                        bias = self.read_bytes(size)\n                        scale = self.read_bytes(size)\n                        mean = self.read_bytes(size)\n                        var = self.read_bytes(size)\n                        norm_layer.set_weights([scale, \n                                                bias, mean, \n                                                var])\n    ```", "```\n                    if len(conv_layer.get_weights()) > 1:\n                        bias = self.read_bytes(np.prod(\n                       conv_layer.get_weights()[1].shape))\n                        kernel = self.read_bytes(np.prod(\n                       conv_layer.get_weights()[0].shape))\n                        kernel = \n                      kernel.reshape(list(reversed(\n                    conv_layer.get_weights()[0].shape)))\n                        kernel = kernel.transpose([2, 3, \n                                                   1, 0])\n                        conv_layer.set_weights([kernel, \n                                                bias])\n                    else:\n                        kernel = self.read_bytes(np.prod(\n                      conv_layer.get_weights()[0].shape))\n                        kernel = \n                   kernel.reshape(list(reversed(\n\n                conv_layer.get_weights()[0].shape)))\n                      kernel = kernel.transpose([2, 3, 1, 0])\n                        conv_layer.set_weights([kernel])\n                except ValueError:\n                    pass\n    ```", "```\n        def reset(self):\n            self.offset = 0\n    ```", "```\n    class BoundBox(object):\n        def __init__(self, x_min, y_min, x_max, y_max,\n                     objness=None,\n                     classes=None):\n            self.xmin = x_min\n            self.ymin = y_min\n            self.xmax = x_max\n            self.ymax = y_max\n            self.objness = objness\n            self.classes = classes\n            self.label = -1\n            self.score = -1\n        def get_label(self):\n            if self.label == -1:\n                self.label = np.argmax(self.classes)\n            return self.label\n        def get_score(self):\n            if self.score == -1:\n                self.score = self.classes[self.get_label()]\n            return self.score\n    ```", "```\n    class YOLO(object):\n        def __init__(self, weights_path,\n                     anchors_path='resources/anchors.json',\n                     labels_path='resources/coco_labels.txt',\n                     class_threshold=0.65):\n            self.weights_path = weights_path\n            self.model = self._load_yolo()\n            self.labels = []\n            with open(labels_path, 'r') as f:\n                for l in f:\n                    self.labels.append(l.strip())\n            with open(anchors_path, 'r') as f:\n                self.anchors = json.load(f)\n            self.class_threshold = class_threshold\n    ```", "```\n        def _conv_block(self, input, convolutions, \n                       skip=True):\n            x = input\n            count = 0\n            for conv in convolutions:\n                if count == (len(convolutions) - 2) and \n                    skip:\n                    skip_connection = x\n                count += 1\n                if conv['stride'] > 1:\n                    x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n                x = Conv2D(conv['filter'],\n                           conv['kernel'],\n                           strides=conv['stride'],\n                           padding=('valid' if \n                           conv['stride'] > 1\n                                    else 'same'),\n\n                 name=f'conv_{conv[\"layer_idx\"]}',\n                           use_bias=(False if \n                               conv['bnorm']\n                                     else True))(x)\n    ```", "```\n                if conv['bnorm']:\n                    name = f'bnorm_{conv[\"layer_idx\"]}'\n                    x = BatchNormalization(epsilon=1e-3,\n                                           name=name)(x)\n                if conv['leaky']:\n                    name = f'leaky_{conv[\"layer_idx\"]}'\n                    x = LeakyReLU(alpha=0.1, name=name)(x)\n            return Add()([skip_connection, x]) if skip else x\n    ```", "```\n        def _make_yolov3_architecture(self):\n            input_image = Input(shape=(None, None, 3))\n            # Layer  0 => 4\n            x = self._conv_block(input_image, [\n                {'filter': 32, 'kernel': 3, 'stride': 1,\n                 'bnorm': True,\n                 'leaky': True, 'layer_idx': 0},\n                {'filter': 64, 'kernel': 3, 'stride': 2,\n                 'bnorm': True,\n                 'leaky': True, 'layer_idx': 1},\n                {'filter': 32, 'kernel': 1, 'stride': 1,\n                 'bnorm': True,\n                 'leaky': True, 'layer_idx': 2},\n                {'filter': 64, 'kernel': 3, 'stride': 1,\n                 'bnorm': True,\n                 'leaky': True, 'layer_idx': 3}])\n    ...\n    ```", "```\n        def _load_yolo(self):\n            model = self._make_yolov3_architecture()\n            weight_reader = WeightReader(self.weights_path)\n            weight_reader.load_weights(model)\n            model.save('model.h5')\n            model = load_model('model.h5')\n            return model\n    ```", "```\n        @staticmethod\n        def _sigmoid(x):\n            return 1.0 / (1.0 + np.exp(-x))\n    ```", "```\n        def _decode_net_output(self, \n                               network_output,\n                               anchors,\n                               obj_thresh,\n                               network_height,\n                               network_width):\n          grid_height, grid_width = network_output.shape[:2]\n            nb_box = 3\n            network_output = network_output.reshape(\n                (grid_height, grid_width, nb_box, -1))\n            boxes = []\n            network_output[..., :2] = \\\n                self._sigmoid(network_output[..., :2])\n            network_output[..., 4:] = \\\n                self._sigmoid(network_output[..., 4:])\n            network_output[..., 5:] = \\\n                (network_output[..., 4][..., np.newaxis] *\n                 network_output[..., 5:])\n            network_output[..., 5:] *= \\\n                network_output[..., 5:] > obj_thresh\n            for i in range(grid_height * grid_width):\n                r = i / grid_width\n                c = i % grid_width\n    ```", "```\n                for b in range(nb_box):\n                    objectness = \\\n                        network_output[int(r)][int(c)][b][4]\n                    if objectness.all() <= obj_thresh:\n                        continue\n    ```", "```\n                    x, y, w, h = \\\n                        network_output[int(r)][int(c)][b][:4]\n                    x = (c + x) / grid_width\n                    y = (r + y) / grid_height\n                    w = (anchors[2 * b] * np.exp(w) /\n                         network_width)\n                    h = (anchors[2 * b + 1] * np.exp(h) /\n                         network_height)\n                   classes = network_output[int(r)][c][b][5:]\n                    box = BoundBox(x_min=x - w / 2,\n                                   y_min=y - h / 2,\n                                   x_max=x + w / 2,\n                                   y_max=y + h / 2,\n                                   objness=objectness,\n                                   classes=classes)\n                    boxes.append(box)\n            return boxes\n    ```", "```\n        @staticmethod\n        def _correct_yolo_boxes(boxes,\n                                image_height,\n                                image_width,\n                                network_height,\n                                network_width):\n            new_w, new_h = network_width, network_height\n            for i in range(len(boxes)):\n                x_offset = (network_width - new_w) / 2.0\n                x_offset /= network_width\n                x_scale = float(new_w) / network_width\n                y_offset = (network_height - new_h) / 2.0\n                y_offset /= network_height\n                y_scale = float(new_h) / network_height\n                boxes[i].xmin = int((boxes[i].xmin - x_     \n                                        offset) /\n                                    x_scale * image_width)\n                boxes[i].xmax = int((boxes[i].xmax - x_\n                                 offset) /x_scale * image_\n                                            width)\n                boxes[i].ymin = int((boxes[i].ymin - y_\n                                    offset) /\n                                    y_scale * image_height)\n                boxes[i].ymax = int((boxes[i].ymax - y_\n                                     offset) /\n                                    y_scale * image_height)\n    ```", "```\n        @staticmethod\n        def _interval_overlap(interval_a, interval_b):\n            x1, x2 = interval_a\n            x3, x4 = interval_b\n            if x3 < x1:\n                if x4 < x1:\n                    return 0\n                else:\n                    return min(x2, x4) - x1\n            else:\n                if x2 < x3:\n                    return 0\n                else:\n                    return min(x2, x4) - x3\n    ```", "```\n        def _bbox_iou(self, box1, box2):\n            intersect_w = self._interval_overlap(\n                [box1.xmin, box1.xmax],\n                [box2.xmin, box2.xmax])\n            intersect_h = self._interval_overlap(\n                [box1.ymin, box1.ymax],\n                [box2.ymin, box2.ymax])\n            intersect = intersect_w * intersect_h\n            w1, h1 = box1.xmax - box1.xmin, box1.ymax - box1.ymin\n            w2, h2 = box2.xmax - box2.xmin, box2.ymax - box2.ymin\n            union = w1 * h1 + w2 * h2 - intersect\n            return float(intersect) / union\n    ```", "```\n        def _non_max_suppression(self, boxes, nms_thresh):\n            if len(boxes) > 0:\n                nb_class = len(boxes[0].classes)\n            else:\n                return\n            for c in range(nb_class):\n                sorted_indices = np.argsort(\n                    [-box.classes[c] for box in boxes])\n                for i in range(len(sorted_indices)):\n                    index_i = sorted_indices[i]\n                    if boxes[index_i].classes[c] == 0:\n                        continue\n                    for j in range(i + 1, \n                    len(sorted_indices)):\n                        index_j = sorted_indices[j]\n                        iou = self._bbox_iou(boxes[index_i],\n\n                        boxes[index_j])\n                        if iou >= nms_thresh:\n                            boxes[index_j].classes[c] = 0\n    ```", "```\n        def _get_boxes(self, boxes):\n            v_boxes, v_labels, v_scores = [], [], []\n            for box in boxes:\n                for i in range(len(self.labels)):\n                    if box.classes[i] > \n                   self.class_threshold:\n                        v_boxes.append(box)\n                        v_labels.append(self.labels[i])\n                        v_scores.append(box.classes[i] * \n                                          100)\n            return v_boxes, v_labels, v_scores\n    ```", "```\n        @staticmethod\n        def _draw_boxes(filename, v_boxes, v_labels, \n                        v_scores):\n            data = plt.imread(filename)\n            plt.imshow(data)\n            ax = plt.gca()\n            for i in range(len(v_boxes)):\n                box = v_boxes[i]\n                y1, x1, y2, x2 = \\\n                    box.ymin, box.xmin, box.ymax, box.xmax\n                width = x2 - x1\n                height = y2 - y1\n                rectangle = Rectangle((x1, y1), width, \n                                     height,\n                                      fill=False, \n                                   color='white')\n                ax.add_patch(rectangle)\n                label = f'{v_labels[i]} ({v_scores[i]:.3f})'\n                plt.text(x1, y1, label, color='green')\n            plt.show()\n    ```", "```\n        def detect(self, image, width, height):\n            image = np.expand_dims(image, axis=0)\n            preds = self.model.predict(image)\n            boxes = []\n    ```", "```\n            for i in range(len(preds)):\n                boxes.extend(\n                    self._decode_net_output(preds[i][0],\n                                        self.anchors[i],\n                                    self.class_threshold,\n                                            416,\n                                            416))\n    ```", "```\n            self._correct_yolo_boxes(boxes, height, width, \n                                     416,\n                                     416)\n            self._non_max_suppression(boxes, .5)\n    ```", "```\n            valid_boxes, valid_labels, valid_scores = \\\n                self._get_boxes(boxes)\n            for i in range(len(valid_boxes)):\n                print(valid_labels[i], valid_scores[i])\n            self._draw_boxes(image_path,\n                             valid_boxes,\n                             valid_labels,\n                             valid_scores)\n    ```", "```\n    model = YOLO(weights_path='resources/yolov3.weights')\n    ```", "```\n    for image_path in glob.glob('test_images/*.jpg'):\n        image = load_img(image_path, target_size=(416, \n                                                  416))\n        image = img_to_array(image)\n        image = image.astype('float32') / 255.0\n        original_image = load_img(image_path)\n        width, height = original_image.size\n        model.detect(image, width, height)\n    ```", "```\n$> git clone –-depth 1 https://github.com/tensorflow/models\n```", "```\n$> sudo apt install -y protobuf-compiler\n$> cd models/research\n$> protoc object_detection/protos/*.proto –-python_out=.\n$> cp object_detection/packages/tf2/setup.py .\n$> python -m pip install -q . \n```", "```\n$> pip install pandas Pillow\n```", "```\n    import glob\n    import io\n    import os\n    from collections import namedtuple\n    from xml.etree import ElementTree as tree\n    import pandas as pd\n    import tensorflow.compat.v1 as tf\n    from PIL import Image\n    from object_detection.utils import dataset_util\n    ```", "```\n    def encode_class(row_label):\n        class_mapping = {'apple': 1, 'orange': 2, \n                         'banana': 3}\n        return class_mapping.get(row_label, None)\n    ```", "```\n    def split(df, group):\n        Data = namedtuple('data', ['filename', 'object'])\n        groups = df.groupby(group)\n        return [Data(filename, groups.get_group(x))\n                for filename, x\n                in zip(groups.groups.keys(), \n              groups.groups)]\n    ```", "```\n    def create_tf_example(group, path):\n        groups_path = os.path.join(path, f'{group.filename}')\n        with tf.gfile.GFile(groups_path, 'rb') as f:\n            encoded_jpg = f.read()\n        image = Image.open(io.BytesIO(encoded_jpg))\n        width, height = image.size\n        filename = group.filename.encode('utf8')\n        image_format = b'jpg'\n    ```", "```\n        xmins = []\n        xmaxs = []\n        ymins = []\n        ymaxs = []\n        classes_text = []\n        classes = []\n        for index, row in group.object.iterrows():\n            xmins.append(row['xmin'] / width)\n            xmaxs.append(row['xmax'] / width)\n            ymins.append(row['ymin'] / height)\n            ymaxs.append(row['ymax'] / height)\n            classes_text.append(row['class'].encode('utf8'))\n            classes.append(encode_class(row['class']))\n    ```", "```\n        features = tf.train.Features(feature={\n            'image/height':\n                dataset_util.int64_feature(height),\n            'image/width':\n                dataset_util.int64_feature(width),\n            'image/filename':\n                dataset_util.bytes_feature(filename),\n            'image/source_id':\n                dataset_util.bytes_feature(filename),\n            'image/encoded':\n                dataset_util.bytes_feature(encoded_jpg),\n            'image/format':\n                dataset_util.bytes_feature(image_format),\n            'image/object/bbox/xmin':\n                dataset_util.float_list_feature(xmins),\n            'image/object/bbox/xmax':\n                dataset_util.float_list_feature(xmaxs),\n            'image/object/bbox/ymin':\n                dataset_util.float_list_feature(ymins),\n            'image/object/bbox/ymax':\n                dataset_util.float_list_feature(ymaxs),\n            'image/object/class/text':\n               dataset_util.bytes_list_feature(classes_text),\n            'image/object/class/label':\n                dataset_util.int64_list_feature(classes)\n        })\n    ```", "```\n        return tf.train.Example(features=features)\n    ```", "```\n    def bboxes_to_csv(path):\n        xml_list = []\n        bboxes_pattern = os.path.sep.join([path, '*.xml'])\n        for xml_file in glob.glob(bboxes_pattern):\n            t = tree.parse(xml_file)\n            root = t.getroot()\n            for member in root.findall('object'):\n                value = (root.find('filename').text,\n                         int(root.find('size')[0].text),\n                         int(root.find('size')[1].text),\n                         member[0].text,\n                         int(member[4][0].text),\n                         int(member[4][1].text),\n                         int(member[4][2].text),\n                         int(member[4][3].text))\n                xml_list.append(value)\n        column_names = ['filename', 'width', 'height', \n                'class','xmin', 'ymin', 'xmax', 'ymax']\n        df = pd.DataFrame(xml_list, columns=column_names)\n        return df\n    ```", "```\n    base = 'fruits'\n    for subset in ['test', 'train']:\n        folder = os.path.sep.join([base, f'{subset}_zip', \n                                   subset])\n        labels_path = os.path.sep.join([base,f'{subset}_\n                                           labels.           \n                                           csv'])\n        bboxes_df = bboxes_to_csv(folder)\n        bboxes_df.to_csv(labels_path, index=None)\n    ```", "```\n        writer = (tf.python_io.\n                TFRecordWriter(f'resources/{subset}.record'))\n        examples = pd.read_csv(f'fruits/{subset}_labels.csv')\n        grouped = split(examples, 'filename')\n        path = os.path.join(f'fruits/{subset}_zip/{subset}')\n        for group in grouped:\n            tf_example = create_tf_example(group, path)\n            writer.write(tf_example.SerializeToString())\n        writer.close()\n    ```", "```\n    item {\n        id: 1\n        name: 'apple'\n    }\n    item {\n        id: 2\n        name: 'orange'\n    }\n    item {\n        id: 3\n        name: 'banana'\n    }\n    ```", "```\n    num_classes: 3\n    ```", "```\n    fine_tune_checkpoint: \"/home/jesus/Desktop/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n    ```", "```\n    fine_tune_checkpoint_type: \"detection\"\n    ```", "```\n    label_map_path: \"/home/jesus/Desktop/tensorflow-computer-vision/ch9/recipe3/resources/label_map.txt\"\n    ```", "```\n    input_path: \"/home/jesus/Desktop/tensorflow-computer-vision/ch9/recipe3/resources/train.record\"\n    ```", "```\n    label_map_path: \"/home/jesus/Desktop/tensorflow-computer-vision/ch9/recipe3/resources/label_map.txt\"\n    ```", "```\n    input_path: \"/home/jesus/Desktop/tensorflow-computer-vision/ch9/recipe3/resources/test.record\"\n    ```", "```\n    $> cd models/research/object_detection\n    ```", "```\n    $> python model_main_tf2.py --pipeline_config_path=../../../ch9/recipe3/resources/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir=../../../ch9/recipe3/training --num_train_steps=10000\n    ```", "```\n    $> cd models/research/object_detection\n    ```", "```\n    $> python exporter_main_v2.py --trained_checkpoint_dir=../../../ch9/recipe3/training/ --pipeline_config_path=../../../ch9/recipe3/resources/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --output_directory=../../../ch9/recipe3/resources/inference_graph\n    ```", "```\n    import glob\n    import random\n    from io import BytesIO\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    from PIL import Image\n    from object_detection.utils import ops\n    from object_detection.utils import visualization_utils as viz\n    from object_detection.utils.label_map_util import \\\n        create_category_index_from_labelmap\n    ```", "```\n    def load_image(path):\n        image_data = tf.io.gfile.GFile(path, 'rb').read()\n        image = Image.open(BytesIO(image_data))\n        width, height = image.size\n        shape = (height, width, 3)\n        image = np.array(image.getdata())\n        image = image.reshape(shape).astype('uint8')\n        return image\n    ```", "```\n    def infer_image(net, image):\n        image = np.asarray(image)\n        input_tensor = tf.convert_to_tensor(image)\n        input_tensor = input_tensor[tf.newaxis, ...]\n    ```", "```\n        num_detections = int(result.pop('num_detections'))\n        result = {key: value[0, :num_detections].numpy()\n                  for key, value in result.items()}\n        result['num_detections'] = num_detections\n        result['detection_classes'] = \\\n            result['detection_classes'].astype('int64')\n    ```", "```\n        if 'detection_masks' in result:\n            detection_masks_reframed = \\\n                ops.reframe_box_masks_to_image_masks(\n                    result['detection_masks'],\n                    result['detection_boxes'],\n                    image.shape[0],\n                    image.shape[1])\n            detection_masks_reframed = \\\n                tf.cast(detection_masks_reframed > 0.5, \n                        tf.uint8)\n            result['detection_masks_reframed'] = \\\n                detection_masks_reframed.numpy()\n        return result\n    ```", "```\n    labels_path = 'resources/label_map.txt'\n    CATEGORY_IDX = \\\n        create_category_index_from_labelmap(labels_path,\n                                      use_display_name=True)\n    model_path = 'resources/inference_graph/saved_model'\n    model = tf.saved_model.load(model_path)\n    ```", "```\n    test_images = list(glob.glob('fruits/test_zip/test/*.jpg'))\n    random.shuffle(test_images)\n    test_images = test_images[:3]\n    ```", "```\n    for image_path in test_images:\n        image = load_image(image_path)\n        result = infer_image(model, image)\n        masks = result.get('detection_masks_reframed', \n                            None)\n        viz.visualize_boxes_and_labels_on_image_array(\n            image,\n            result['detection_boxes'],\n            result['detection_classes'],\n            result['detection_scores'],\n            CATEGORY_IDX,\n            instance_masks=masks,\n            use_normalized_coordinates=True,\n            line_thickness=5)\n        plt.figure(figsize=(24, 32))\n        plt.imshow(image)\n        plt.savefig(f'detections_{image_path.split(\"/\")[-1]}')\n    ```", "```\n$> pip install Pillow tensorflow-hub\n```", "```\n$> git clone –-depth 1 https://github.com/tensorflow/models\n```", "```\n$> sudo apt install -y protobuf-compiler\n$> cd models/research\n$> protoc object_detection/protos/*.proto –-python_out=.\n$> cp object_detection/packages/tf2/setup.py .\n$> python -m pip install -q . \n```", "```\n    import glob\n    from io import BytesIO\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    import tensorflow_hub as hub\n    from PIL import Image\n    from object_detection.utils import visualization_utils as viz\n    from object_detection.utils.label_map_util import \\\n        create_category_index_from_labelmap\n    ```", "```\n    def load_image(path):\n        image_data = tf.io.gfile.GFile(path, 'rb').read()\n        image = Image.open(BytesIO(image_data))\n        width, height = image.size\n        shape = (1, height, width, 3)\n        image = np.array(image.getdata())\n        image = image.reshape(shape).astype('uint8')\n        return image\n    ```", "```\n    def get_and_save_predictions(model, image_path):\n        image = load_image(image_path)\n        results = model(image)\n    ```", "```\n    model_output = {k: v.numpy() for k, v in results.items()}\n    ```", "```\n        boxes = model_output['detection_boxes'][0]\n        classes = \\\n           model_output['detection_classes'][0].astype('int')\n        scores = model_output['detection_scores'][0]\n\n        clone = image.copy()\n        viz.visualize_boxes_and_labels_on_image_array(\n            image=clone[0],\n            boxes=boxes,\n            classes=classes,\n            scores=scores,\n            category_index=CATEGORY_IDX,\n            use_normalized_coordinates=True,\n            max_boxes_to_draw=200,\n            min_score_thresh=0.30,\n            agnostic_mode=False,\n            line_thickness=5\n        )\n    ```", "```\n        plt.figure(figsize=(24, 32))\n        plt.imshow(image_with_mask[0])\n        plt.savefig(f'output/{image_path.split(\"/\")[-1]}')\n    ```", "```\n    labels_path = 'resources/mscoco_label_map.pbtxt'\n    CATEGORY_IDX =create_category_index_from_labelmap(labels_path)\n    ```", "```\n    MODEL_PATH = ('https://tfhub.dev/tensorflow/faster_rcnn/'\n                  'inception_resnet_v2_1024x1024/1')\n    model = hub.load(MODEL_PATH)\n    ```", "```\n    test_images_paths = glob.glob('test_images/*')\n    for image_path in test_images_paths:\n        get_and_save_predictions(model, image_path)\n    ```"]