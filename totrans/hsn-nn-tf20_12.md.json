["```\nimport tensorflow as tf\n\ndef sample_dataset():\n    dataset_shape = (2000, 1)\n    return tf.random.normal(mean=10., shape=dataset_shape, stddev=0.1, dtype=tf.float32)\n```", "```\nimport matplotlib.pyplot as plt\n\ncounts, bin, ignored = plt.hist(sample_dataset().numpy(), 100)\naxes = plt.gca()\naxes.set_xlim([-1,11])\naxes.set_ylim([0, 60])\nplt.show()\n```", "```\ndef generator(input_shape):\n    \"\"\"Defines the generator keras.Model.\n    Args:\n        input_shape: the desired input shape (e.g.: (latent_space_size))\n    Returns:\n        G: The generator model\n    \"\"\"\n    inputs = tf.keras.layers.Input(input_shape)\n    net = tf.keras.layers.Dense(units=64, activation=tf.nn.elu, name=\"fc1\")(inputs)\n    net = tf.keras.layers.Dense(units=64, activation=tf.nn.elu, name=\"fc2\")(net)\n    net = tf.keras.layers.Dense(units=1, name=\"G\")(net)\n    G = tf.keras.Model(inputs=inputs, outputs=net)\n    return G\n```", "```\ndef disciminator(input_shape):\n    \"\"\"Defines the Discriminator keras.Model.\n    Args:\n        input_shape: the desired input shape (e.g.: (the generator output shape))\n    Returns:\n        D: the Discriminator model\n    \"\"\"\n    inputs = tf.keras.layers.Input(input_shape)\n    net = tf.keras.layers.Dense(units=32, activation=tf.nn.elu, name=\"fc1\")(inputs)\n    net = tf.keras.layers.Dense(units=1, name=\"D\")(net)\n    D = tf.keras.Model(inputs=inputs, outputs=net)\n    return D\n```", "```\n# Define the real input shape\ninput_shape = (1,)\n\n# Define the Discriminator model\nD = disciminator(input_shape)\n\n# Arbitrary set the shape of the noise prior\nlatent_space_shape = (100,)\n# Define the input noise shape and define the generator\nG = generator(latent_space_shape)\n```", "```\nbce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n```", "```\ndef d_loss(d_real, d_fake):\n    \"\"\"The disciminator loss function.\"\"\"\n    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)\n```", "```\ndef g_loss(generated_output):\n    \"\"\"The Generator loss function.\"\"\"\n    return bce(tf.ones_like(generated_output), generated_output)\n```", "```\ndef train():\n    # Define the optimizers and the train operations\n    optimizer = tf.keras.optimizers.Adam(1e-5)\n\n    @tf.function\n    def train_step():\n        with tf.GradientTape(persistent=True) as tape:\n            real_data = sample_dataset()\n            noise_vector = tf.random.normal(\n                mean=0, stddev=1,\n                shape=(real_data.shape[0], latent_space_shape[0]))\n            # Sample from the Generator\n            fake_data = G(noise_vector)\n            # Compute the D loss\n            d_fake_data = D(fake_data)\n            d_real_data = D(real_data)\n            d_loss_value = d_loss(d_real_data, d_fake_data)\n            # Compute the G loss\n            g_loss_value = g_loss(d_fake_data)\n        # Now that we comptuted the losses we can compute the gradient\n        # and optimize the networks\n        d_gradients = tape.gradient(d_loss_value, D.trainable_variables)\n        g_gradients = tape.gradient(g_loss_value, G.trainable_variables)\n        # Deletng the tape, since we defined it as persistent\n        # (because we used it twice)\n        del tape\n\n        optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))\n        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n        return real_data, fake_data, g_loss_value, d_loss_value\n```", "```\n    fig, ax = plt.subplots()\n    for step in range(40000):\n        real_data, fake_data,g_loss_value, d_loss_value = train_step()\n        if step % 200 == 0:\n            print(\"G loss: \", g_loss_value.numpy(), \" D loss: \", d_loss_value.numpy(), \" step: \", step)\n\n            # Sample 5000 values from the Generator and draw the histogram\n            ax.hist(fake_data.numpy(), 100)\n            ax.hist(real_data.numpy(), 100)\n            # these are matplotlib.patch.Patch properties\n            props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n\n            # place a text box in upper left in axes coords\n            textstr = f\"step={step}\"\n            ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n                    verticalalignment='top', bbox=props)\n\n            axes = plt.gca()\n            axes.set_xlim([-1,11])\n            axes.set_ylim([0, 60])\n            display.display(pl.gcf())\n            display.clear_output(wait=True)\n            plt.gca().clear()\n```", "```\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\n\ndataset = tfds.load(\"fashion_mnist\", split=\"train\")\n\ndef convert(row):\n  image = tf.image.convert_image_dtype(row[\"image\"], tf.float32)\n  label = tf.cast(row[\"label\"], tf.float32)\n  return image, label\n\nbatch_size = 32\ndataset = dataset.map(convert).batch(batch_size).prefetch(1)\n```", "```\ndef get_generator(latent_dimension):\n\n  # Condition subnetwork: encode the condition in a hidden representation\n  condition = tf.keras.layers.Input((1,))\n  net = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n  net = tf.keras.layers.Dense(64, activation=tf.nn.elu)(net)\n\n  # Concatenate the hidden condition representation to noise and upsample\n  noise = tf.keras.layers.Input(latent_dimension)\n  inputs = tf.keras.layers.Concatenate()([noise, net])\n\n  # Convert inputs from (batch_size, latent_dimension + 1) \n  # To a 4-D tensor, that can be used with convolutions\n  inputs = tf.keras.layers.Reshape((1,1, inputs.shape[-1]))(inputs)\n\n  depth = 128\n  kernel_size= 5\n  net = tf.keras.layers.Conv2DTranspose(\n      depth, kernel_size,\n      padding=\"valid\",\n      strides=1,\n      activation=tf.nn.relu)(inputs) # 5x5\n  net = tf.keras.layers.Conv2DTranspose(\n      depth//2, kernel_size,\n      padding=\"valid\",\n      strides=2,\n      activation=tf.nn.relu)(net) #13x13\n  net = tf.keras.layers.Conv2DTranspose(\n      depth//4, kernel_size,\n      padding=\"valid\",\n      strides=2,\n      activation=tf.nn.relu,\n      use_bias=False)(net) # 29x29\n  # Standard convolution with a 2x2 kernel to obtain a 28x28x1 out\n  # The output is a sigmoid, since the images are in the [0,1] range\n  net = tf.keras.layers.Conv2D(\n      1, 2,\n      padding=\"valid\",\n      strides=1,\n      activation=tf.nn.sigmoid,\n      use_bias=False)(net)\n  model = tf.keras.Model(inputs=[noise, condition], outputs=net)\n  return model\n```", "```\ndef get_Discriminator():\n  # Encoder subnetwork: feature extactor to get a feature vector\n  image = tf.keras.layers.Input((28,28,1))\n  depth = 32\n  kernel_size=3\n  net = tf.keras.layers.Conv2D(\n      depth, kernel_size,\n      padding=\"same\",\n      strides=2,\n      activation=tf.nn.relu)(image) #14x14x32\n  net = tf.keras.layers.Conv2D(\n      depth*2, kernel_size,\n      padding=\"same\",\n      strides=2,\n      activation=tf.nn.relu)(net) #7x7x64\n\n  net = tf.keras.layers.Conv2D(\n      depth*3, kernel_size,\n      padding=\"same\",\n      strides=2,\n      activation=tf.nn.relu)(net) #4x4x96\n\n  feature_vector = tf.keras.layers.Flatten()(net) # 4*4*96\n```", "```\n  # Create a hidden representation of the condition\n  condition = tf.keras.layers.Input((1,))\n  hidden = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n  hidden = tf.keras.layers.Dense(64, activation=tf.nn.elu)(hidden)\n\n  # Concatenate the feature vector and the hidden label representation\n  out = tf.keras.layers.Concatenate()([feature_vector, hidden])\n\n  # Add the final classification layers with a single linear neuron\n  out = tf.keras.layers.Dense(128, activation=tf.nn.relu)(out)\n  out = tf.keras.layers.Dense(1)(out)\n\n  model = tf.keras.Model(inputs=[image, condition], outputs=out)\n  return model\n```", "```\nbce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef d_loss(d_real, d_fake):\n    \"\"\"The disciminator loss function.\"\"\"\n    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)\n\ndef g_loss(generated_output):\n    \"\"\"The Generator loss function.\"\"\"\n    return bce(tf.ones_like(generated_output), generated_output)\n```", "```\nlatent_dimension = 100\nG = get_generator(latent_dimension)\nD = get_Discriminator()\n\ndef train():\n    # Define the optimizers and the train operations\n    optimizer = tf.keras.optimizers.Adam(1e-5)\n\n    @tf.function\n    def train_step(image, label):\n        with tf.GradientTape(persistent=True) as tape:\n            noise_vector = tf.random.normal(\n            mean=0, stddev=1,\n            shape=(image.shape[0], latent_dimension))\n            # Sample from the Generator\n            fake_data = G([noise_vector, label])\n            # Compute the D loss\n            d_fake_data = D([fake_data, label])\n            d_real_data = D([image, label])\n\n            d_loss_value = d_loss(d_real_data, d_fake_data)\n            # Compute the G loss\n            g_loss_value = g_loss(d_fake_data)\n        # Now that we comptuted the losses we can compute the gradient\n        # and optimize the networks\n        d_gradients = tape.gradient(d_loss_value, D.trainable_variables)\n        g_gradients = tape.gradient(g_loss_value, G.trainable_variables)\n        # Deletng the tape, since we defined it as persistent\n        del tape\n\n        optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))\n        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n        return g_loss_value, d_loss_value, fake_data[0], label[0]\n\n    epochs = 10\n    epochs = 10\n    for epoch in range(epochs):\n        for image, label in dataset:\n            g_loss_value, d_loss_value, generated, condition = train_step(image, label)\n\n        print(\"epoch \", epoch, \"complete\")\n        print(\"loss:\", g_loss_value, \"d_loss: \", d_loss_value)\n        print(\"condition \", info.features['label'].int2str(\n                    tf.squeeze(tf.cast(condition, tf.int32)).numpy()))\n        plt.imshow(tf.squeeze(generated).numpy(), cmap='gray')\n        plt.show()\n```"]