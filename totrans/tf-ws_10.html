<html><head></head><body>
		<div>
			<div id="_idContainer353" class="Content">
			</div>
		</div>
		<div id="_idContainer354" class="Content">
			<h1 id="_idParaDest-184"><a id="_idTextAnchor208"/>10. Custom TensorFlow Components</h1>
		</div>
		<div id="_idContainer370" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">In this chapter, you will dive a level deeper into the TensorFlow framework and build custom modules. By the end of it, you will know how to create custom TensorFlow components to use within your models, such as loss functions and layers.</p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor209"/>Introduction</h1>
			<p>In the previous chapters, you learned how to build CNN or RNN models from predefined TensorFlow modules. You have been using one of the APIs offered by TensorFlow called the sequential API. This API is a great way to start building "simple" deep learning architecture with few lines of code. But if you want to achieve higher performance, you may want to build your own custom architecture. In this case, you will need to use another API called the functional API. Researchers use functional APIs while defining their model architecture. By learning how to use it, you will be able to create custom loss functions or modules, such as a residual block from the ResNet architecture.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor210"/>TensorFlow APIs</h1>
			<p>When using TensorFlow, you can choose from the sequential, functional, or subclassing APIs to define your models. For most, the sequential API will be the go-to option. However, as time goes by and you are exposed to more complexity, your needs will expand as well.</p>
			<p>The <strong class="bold">sequential API</strong> is the simplest API used for creating TensorFlow models. It works by stacking different layers one after the other. For example, you will create a sequential model with a first layer that's a convolution layer, followed by a dropout layer, and then a fully connected layer. This model is sequential as the input data will be passed to each defined layer sequentially.</p>
			<p>The <strong class="bold">functional API</strong> provides more flexibility. You can define models with different layers that interact with each other not in a sequential manner. For instance, you can create two different layers both of which will feed into a third one. This can be easily achieved with the functional API.</p>
			<p><strong class="bold">Model subclassing</strong> allows the user a very low level of control over the entire model. It works by inheriting attributes and methods from TensorFlow classes such as <strong class="source-inline">Layer</strong> or <strong class="source-inline">Model</strong>. You can define your own custom layers or models, but this means you will need to comply with all the requirements of the inherited TensorFlow classes, such as coding mandatory methods.</p>
			<p>The following diagram provides a quick overview of the three different APIs offered by TensorFlow:</p>
			<div>
				<div id="_idContainer355" class="IMG---Figure">
					<img src="image/B16341_10_01.jpg" alt="Figure 10.1: Diagram showing a comparison of all three APIs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1: Diagram showing a comparison of all three APIs</p>
			<p>In the section ahead, you will learn how to define a custom loss function.</p>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor211"/>Implementing Custom Loss Functions</h1>
			<p>There are several types of loss functions that are commonly used for machine learning. In <em class="italic">Chapter 5</em>, <em class="italic">Classification</em>, you studied different types of loss functions and used them with different classification models. TensorFlow has quite a few built-in loss functions to choose from. The following are just a few of the more common loss functions:</p>
			<ul>
				<li>Mean Absolute Error (MAE)</li>
				<li>Mean Squared Error (MSE)</li>
				<li>Binary cross-entropy</li>
				<li>Categorical cross-entropy</li>
				<li>Hinge</li>
				<li>Huber</li>
				<li>Mean Squared Logarithmic Error (MSLE)</li>
			</ul>
			<p>As a quick reminder, you can think of loss functions as a kind of compass that allows you to clearly see what is working in an algorithm and what isn't. The higher the loss, the less accurate the model, and so on.</p>
			<p>Although TensorFlow has several loss functions available, at some point, you will most likely need to create your own loss function for your specific needs. For instance, if you are building a model that is predicting stock prices, you want to define a loss function that will penalize substantially incorrect values. </p>
			<p>The following section will show you how to build a custom loss function.</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor212"/>Building a Custom Loss Function with the Functional API</h2>
			<p>You saw in the previous chapters how to use predefined loss functions from TensorFlow. But if you want to build your own custom functions, you can use either the functional API or model subclassing. Let's say you want to build a loss function that will raise the difference between the predictions and the actual values to the power of 4:</p>
			<div>
				<div id="_idContainer356" class="IMG---Figure">
					<img src="image/B16341_10_02.jpg" alt="Figure 10.2: Formula for custom loss&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2: Formula for custom loss</p>
			<p>While creating a custom loss function, you will always need two arguments: <strong class="source-inline">y_true</strong> (actual values) and <strong class="source-inline">y_pred</strong> (predictions). A loss function will calculate the difference between these two values and return an error value that represents how far the predictions of your model are from the actual values. In the case of MAE, this loss function will return the absolute value of this error. On the other hand, MSE will square the difference between the actual value and the predicted value. But in the preceding example, the error should be raised to the power of <strong class="source-inline">4</strong>.</p>
			<p>Let's see how you can implement this using the functional API. Firstly, you will need to import the TensorFlow library using the following command:</p>
			<p class="source-code">import tensorflow as tf</p>
			<p>Then, you will have to create a function called <strong class="source-inline">custom_loss</strong> that takes as input the <strong class="source-inline">y_true</strong> and <strong class="source-inline">y_pred</strong> arguments. You will then use the <strong class="source-inline">pow</strong> function to raise the calculated error to the power of <strong class="source-inline">4</strong>. Finally, you will return the calculated error:</p>
			<p class="source-code">def custom_loss(y_true, y_pred):</p>
			<p class="source-code">    custom_loss=tf.math.pow(y_true - y_pred, 4)</p>
			<p class="source-code">    return custom_loss</p>
			<p>You have created your own custom loss function using the functional API. You can now pass it to the <strong class="source-inline">compile</strong> method, instead of the predefined loss functions, before training your model:</p>
			<p class="source-code">model.compile(loss=custom_loss,optimizer=optimizer)</p>
			<p>After this, you can train your model exactly the same way as you did in previous chapters. TensorFlow will use your custom loss function to optimize the learning process of your model.</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor213"/>Building a Custom Loss Function with the Subclassing API</h2>
			<p>There is another way to define a custom loss function: using the subclassing API. In this case, rather than building a function, you will define a custom class for it. This is quite useful if you want to extend it with additional custom attributes or methods. With subclassing, you can create a custom class that will inherit attributes and methods from the <strong class="source-inline">Loss</strong> class of the <strong class="source-inline">keras.losses</strong> module. You will then need to define the <strong class="source-inline">__init__()</strong> and <strong class="source-inline">call()</strong> methods, which are required in the <strong class="source-inline">Loss</strong> class. The <strong class="source-inline">__init__</strong> method is where you will define all the attributes of your custom class, and the <strong class="source-inline">call()</strong> method is where you will specify the logic for calculating the loss.</p>
			<p>The following is a brief example of how you can implement your custom loss, using the subclassing API, where the error should be raised to the power of <strong class="source-inline">4</strong>:</p>
			<p class="source-code">class MyCustomLoss(keras.losses.Loss):</p>
			<p class="source-code">    def __init__(self, threshold=1.0, **kwargs):</p>
			<p class="source-code">        super().__init__(**kwargs)</p>
			<p class="source-code">    def call(self, y_true, y_pred):</p>
			<p class="source-code">        return tf.math.pow(y_true - y_pred, 4)</p>
			<p>In the preceding example, you have reimplemented the same loss function as previously (power of 4) but used subclassing from <strong class="source-inline">keras.losses.Loss</strong>. You started by initializing the attributes of your class in the <strong class="source-inline">__init__()</strong> method using the <strong class="source-inline">self</strong> parameter, which refers to the object itself.</p>
			<p>Then, in the <strong class="source-inline">call()</strong> method, you defined the logic of your loss function, which calculated the error and raised it to the power of 4.</p>
			<p>Now that you're up to speed with loss functions, it's time for you to build one in the next exercise.</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor214"/>Exercise 10.01: Building a Custom Loss Function</h2>
			<p>In this exercise, you will create your own custom loss function to train a CNN model to distinguish between images of apples and tomatoes.</p>
			<p>You will use the <strong class="source-inline">Apple-or-Tomato</strong> dataset for this exercise. The dataset is a subset of the <strong class="source-inline">Fruits 360</strong> dataset on GitHub. The <strong class="source-inline">Fruits 360</strong> dataset consists of 1,948 total color images with dimensions of 100 by 100 pixels. The <strong class="source-inline">Apple-or-Tomato</strong> dataset has 992 apple images with 662 in the training set and 330 in the test dataset. There are a total of 956 tomato images, with 638 in the training dataset and 318 in the test dataset.</p>
			<p class="callout-heading"><strong class="bold">Note</strong></p>
			<p class="callout">You can get the <strong class="source-inline">Apple-or-Tomato</strong> dataset at the following link: <a href="https://packt.link/28kZY">https://packt.link/28kZY</a>.</p>
			<p class="callout">You can find the <strong class="source-inline">Fruits 360</strong> dataset here: <a href="https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip">https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip</a>.</p>
			<p>To get started, open a new Colab or Jupyter Notebook. If you are using Google Colab, you will need to download the dataset into your Google Drive first:</p>
			<ol>
				<li>Open a new Jupyter notebook or Google Colab notebook.</li>
				<li>If you are using Google Colab, upload your dataset locally with the following code. Otherwise, go to <em class="italic">step 4</em>. Click on <strong class="source-inline">Choose Files</strong> to navigate to the CSV file and click <strong class="source-inline">Open</strong>. Save the file as <strong class="source-inline">uploaded</strong>. Then, go to the folder where you have saved the dataset:<p class="source-code">from google.colab import files</p><p class="source-code">uploaded = files.upload()</p></li>
				<li>Unzip the dataset in the current folder:<p class="source-code">!unzip \*.zip</p></li>
				<li>Create a variable, <strong class="source-inline">directory</strong>, that contains the path to the dataset:<p class="source-code">directory = "/content/gdrive/My Drive/Datasets/apple-or-tomato/"</p></li>
				<li>Import the <strong class="source-inline">pathlib</strong> library:<p class="source-code">import pathlib</p></li>
				<li>Create a variable, <strong class="source-inline">path</strong>, that contains the full path to the dataset using <strong class="source-inline">pathlib.Path</strong>:<p class="source-code">path = pathlib.Path(directory)</p></li>
				<li>Create two variables, <strong class="source-inline">train_dir</strong> and <strong class="source-inline">validation_dir</strong>, that take the full paths to the train and validation folders, respectively:<p class="source-code">train_dir = path / 'training_set'</p><p class="source-code">validation_dir = path / 'test_set'</p></li>
				<li>Create four variables, <strong class="source-inline">train_apple_dir</strong>, <strong class="source-inline">train_tomato_dir</strong>, <strong class="source-inline">validation_apple_dir</strong>, and <strong class="source-inline">validation_tomato_dir</strong>, that take the full paths to the <strong class="source-inline">apple</strong> and <strong class="source-inline">tomato</strong> folders for the train and validation sets, respectively:<p class="source-code">train_apple_dir = train_dir / 'apple'</p><p class="source-code">train_tomato_dir = train_dir /'tomato'</p><p class="source-code">validation_apple_dir = validation_dir / 'apple'</p><p class="source-code">validation_tomato_dir = validation_dir / 'tomato'</p></li>
				<li>Import the <strong class="source-inline">os</strong> package:<p class="source-code">import os</p></li>
				<li>Create two variables, called <strong class="source-inline">total_train</strong> and <strong class="source-inline">total_val</strong>, that will get the number of images for the training and validation sets, respectively:<p class="source-code">total_train = len(os.listdir(train_apple_dir)) + \</p><p class="source-code">              len(os.listdir(train_tomato_dir))</p><p class="source-code">total_val = len(os.listdir(validation_apple_dir)) + \</p><p class="source-code">            len(os.listdir(validation_tomato_dir))</p></li>
				<li>Import <strong class="source-inline">ImageDataGenerator</strong> from the <strong class="source-inline">tensorflow.keras.preprocessing</strong> module:<p class="source-code">from tensorflow.keras.preprocessing.image import ImageDataGenerator</p></li>
				<li>Instantiate two <strong class="source-inline">ImageDataGenerator</strong> classes, <strong class="source-inline">train_image_generator</strong> and <strong class="source-inline">validation_image_generator</strong>, that will rescale the images by dividing by 255:<p class="source-code">train_image_generator = ImageDataGenerator(rescale=1./255)</p><p class="source-code">validation_image_generator = ImageDataGenerator(rescale=1./255)</p></li>
				<li>Create three variables, called <strong class="source-inline">batch_size</strong>, <strong class="source-inline">img_height</strong>, and <strong class="source-inline">img_width</strong>, that take the values <strong class="source-inline">32</strong>, <strong class="source-inline">224</strong>, and <strong class="source-inline">224</strong>, respectively:<p class="source-code">batch_size = 32</p><p class="source-code">img_height = 224</p><p class="source-code">img_width = 224</p></li>
				<li>Create a data generator called <strong class="source-inline">train_data_gen</strong>, using <strong class="source-inline"> flow_from_directory()</strong>, and specify the batch size, the path to the training folder, the value of the <strong class="source-inline">shuffle</strong> parameter, the size of the target, and the class mode:<p class="source-code">train_data_gen = train_image_generator.flow_from_directory\</p><p class="source-code">                 (batch_size=batch_size, directory=train_dir, \</p><p class="source-code">                  shuffle=True, \</p><p class="source-code">                  target_size=(img_height, img_width), \</p><p class="source-code">                  class_mode='binary')</p></li>
				<li>Create a data generator called <strong class="source-inline">val_data_gen</strong> using <strong class="source-inline"> flow_from_directory()</strong> and specify the batch size, the path to the validation folder, the size of the target, and the class mode: <p class="source-code">val_data_gen = validation_image_generator.flow_from_directory\</p><p class="source-code">               (batch_size=batch_size, directory=validation_dir, \</p><p class="source-code">                target_size=(img_height, img_width), \</p><p class="source-code">                class_mode='binary')</p></li>
				<li>Import <strong class="source-inline">matplotlib</strong> and create a <strong class="source-inline">for</strong> loop that will iterate through five images from <strong class="source-inline">train_data_gen</strong> and plot them:<p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">for _ in range(5):</p><p class="source-code">    img, label = train_data_gen.next()</p><p class="source-code">    plt.imshow(img[0])</p><p class="source-code">    plt.show()</p><p>You should get the following output:</p><div id="_idContainer357" class="IMG---Figure"><img src="image/B16341_10_03a.jpg" alt="Figure 10.3: Sample of images from the dataset&#13;&#10;"/></div><div id="_idContainer358" class="IMG---Figure"><img src="image/B16341_10_03b.jpg" alt="10.3 b"/></div><div id="_idContainer359" class="IMG---Figure"><img src="image/B16341_10_03c.jpg" alt="Figure 10.3: Sample of images from the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 10.3: Sample of images from the dataset</p><p>The preceding results show some examples of the images contained in this dataset.</p></li>
				<li>Import the TensorFlow library:<p class="source-code">import tensorflow as tf</p></li>
				<li>Create your custom loss function that will square the calculated error: <p class="source-code">def custom_loss_function(y_true, y_pred):</p><p class="source-code">    print("y_pred ",y_pred)</p><p class="source-code">    print("y_true ", y_true)</p><p class="source-code">    squared_difference = tf.square(float(y_true)-float(y_pred))</p><p class="source-code">    return tf.reduce_mean(squared_difference, axis=-1)</p></li>
				<li>Import the <strong class="source-inline">NASNetMobile</strong> model from the <strong class="source-inline">tensorflow.keras.applications</strong> module:<p class="source-code">from tensorflow.keras.applications import NASNetMobile</p></li>
				<li>Instantiate this model with the ImageNet weights, remove the top layer, and specify the right input dimensions:<p class="source-code">base_model = NASNetMobile(include_top=False,\</p><p class="source-code">                          input_shape=(100, 100, 3), \</p><p class="source-code">                          weights='imagenet')</p></li>
				<li>Freeze all the layers of this model so that you are not going to update the model weights of <strong class="source-inline">NASNetMobile</strong>:<p class="source-code">base_model.trainable = False</p></li>
				<li>Import the <strong class="source-inline">Flatten</strong> and <strong class="source-inline">Dense</strong> layers from the <strong class="source-inline">tensorflow.keras.layers</strong> module:<p class="source-code">from tensorflow.keras.layers import Flatten, Dense</p></li>
				<li>Create a new model that combines the <strong class="source-inline">NASNetMobile</strong> model with two new top layers (with 500 and 1 units, respectively) and ReLu and sigmoid as activation functions:<p class="source-code">model = tf.keras.Sequential([</p><p class="source-code">    base_model,</p><p class="source-code">    layers.Flatten(),</p><p class="source-code">    layers.Dense(500, activation='relu'),</p><p class="source-code">    layers.Dense(1, activation='sigmoid')</p><p class="source-code">])</p></li>
				<li>Print the summary of your model:<p class="source-code">model.summary()</p><p>You will get the following output:</p><div id="_idContainer360" class="IMG---Figure"><img src="image/B16341_10_04.jpg" alt="Figure 10.4: Model summary&#13;&#10;"/></div><p class="figure-caption">Figure 10.4: Model summary</p><p>Here, you can see the layers on the left-hand side. You have <strong class="source-inline">Output Shape</strong> shown—for example, <strong class="source-inline">(None, 224, 224, 3)</strong>. Then, the number of parameters is shown under <strong class="source-inline">Param #</strong>. At the bottom, you will find the summary, including trainable and non-trainable parameters.</p></li>
				<li>Compile this model by providing your custom loss function, with Adam as the optimizer and accuracy as the metric to be displayed:<p class="source-code">model.compile(</p><p class="source-code">        optimizer='adam',</p><p class="source-code">        loss=custom_loss_function,</p><p class="source-code">        metrics=['accuracy'])</p></li>
				<li>Fit the model and provide the train and validation data generators, the number of steps per epoch, and the number of validation steps:<p class="source-code">history = model.fit(</p><p class="source-code">    Train_data_gen,</p><p class="source-code">    steps_per_epoch=total_train // batch_size,</p><p class="source-code">    epochs=5,</p><p class="source-code">    validation_data=val_data_gen,</p><p class="source-code">    validation_steps=total_val // batch_size)</p><p>You should get the following output:</p><div id="_idContainer361" class="IMG---Figure"><img src="image/B16341_10_05.jpg" alt="Figure 10.5: Screenshot of training progress&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 10.5: Screenshot of training progress</p>
			<p>The preceding screenshot shows the information displayed by TensorFlow during the training of your model. You can see the accuracy achieved on the training and validation sets for each epoch. On the fifth epoch, the model is <strong class="source-inline">96%</strong> accurate on both the training set and the validation set.</p>
			<p>In this exercise, you have successfully built your own loss function and trained a binary classifier with it to recognize images of apples or tomatoes. In the following section, you will take it a step further and build your own custom layers.</p>
			<h1 id="_idParaDest-191"><a id="_idTextAnchor215"/>Implementing Custom Layers</h1>
			<p>Previously, you looked at implementing your own custom loss function with either the TensorFlow functional API or the subclassing approach. These concepts can also be applied to creating custom layers for a deep learning model. In this section, you will build a ResNet module from scratch.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor216"/>Introduction to ResNet Blocks</h2>
			<p><strong class="bold">Residual neural network</strong>, or <strong class="bold">ResNet</strong>, was first proposed by <em class="italic">Kaiming He</em> in his paper <em class="italic">Deep Residual Learning for Image Recognition</em> in 2015. He introduced a new concept called a residual block that tackles the problem of vanishing gradients, which limits the ability of training very deep networks (with a lot of layers).</p>
			<p>A residual block is composed of multiple layers. But instead of having a single path where each layer is stacked and executed sequentially, a residual block contains two different paths. The first path has two different convolution layers. The second path, called the <strong class="bold">skip connection</strong>, takes the input and forwards it to the last layer of the first path. So, the input of a residual block will go through the first path with the sequence of convolution layers, and its result will be combined with the original input coming from the second path (skip connection), as shown in <em class="italic">Figure 10.6</em>. Without going too much into the mathematical details, this extra path allows the architecture to pass through the gradients in a deeper layer without impacting the overall performance.</p>
			<div>
				<div id="_idContainer362" class="IMG---Figure">
					<img src="image/B16341_10_06.jpg" alt="Figure 10.6: Skip connection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6: Skip connection</p>
			<p>As you can see, if you want to build an architecture for the preceding residual block, it will be quite hard with the TensorFlow sequential API. Here, you need to build a very customized layer. This is the reason why you need to use either the functional API or model subclassing instead.</p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor217"/>Building Custom Layers with the Functional API</h2>
			<p>In this section, you will see how to use the TensorFlow functional API to build a custom layer.</p>
			<p>To start, you will build a function that takes your input as a tensor and adds ReLU and batch normalization to it. For example, in the following code snippet, the <strong class="source-inline">relu_batchnorm_layer</strong> function takes input and then returns a tensor. This makes a composite layer with ReLU activation and batch normalization in succession:</p>
			<p class="source-code">def relu_batchnorm_layer(input):</p>
			<p class="source-code">    return BatchNormalization()(ReLU()(input))</p>
			<p>Now, create a function for your residual block. You'll need to take a tensor as input and pass it to two Conv2D layers. Then, you will add the output of the second Conv2D layer to the original input, which represents the skip connection. The output of this addition will then be passed to the <strong class="source-inline">relu_batchnorm_layer()</strong> function that you defined in the preceding code snippet. The output will be given to another Conv2D layer:</p>
			<p class="source-code">def simple_residual_block(input, filters: int, kernel_size: int = 3):</p>
			<p class="source-code">    int_output = Conv2D(filters=filters, kernel_size=kernel_size, </p>
			<p class="source-code">                        padding="same")(input)</p>
			<p class="source-code">    int_output = Conv2D(filters=filters, kernel_size=1, strides=2,</p>
			<p class="source-code">                        padding="same")(int_output)</p>
			<p class="source-code">    output = Add()([int_output,input]) </p>
			<p class="source-code">    output = relu_batchnorm_layer(output)</p>
			<p class="source-code">    return output</p>
			<p>Now, you can use this custom layer in your model. In the following code snippet, you will define a simple model with a Conv2D layer followed by a residual block:</p>
			<p class="source-code">inputs = Input(shape=(100, 100, 3))</p>
			<p class="source-code">num_filters = 32</p>
			<p class="source-code">    </p>
			<p class="source-code">t = BatchNormalization()(inputs)</p>
			<p class="source-code">t = Conv2D(kernel_size=3,</p>
			<p class="source-code">           strides=1,</p>
			<p class="source-code">           filters=32,</p>
			<p class="source-code">           padding="same")(t)</p>
			<p class="source-code">t = relu_batchnorm_layer(t)</p>
			<p class="source-code">t = residual_block(t, filters=num_filters)</p>
			<p class="source-code">    </p>
			<p class="source-code">t = AveragePooling2D(4)(t)</p>
			<p class="source-code">t = Flatten()(t)</p>
			<p class="source-code">outputs = Dense(1, activation='sigmoid')(t)</p>
			<p class="source-code">    </p>
			<p class="source-code">model = Model(inputs, outputs)</p>
			<p>Let's now build custom layers using subclassing in the following section.</p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor218"/>Building Custom Layers with Subclassing</h2>
			<p>Previously, you looked at how to create a simplified version of a residual block using the functional API. Now, you will see how to use model subclassing to create a custom layer.</p>
			<p>To begin, you need to import the <strong class="source-inline">Model</strong> class together with a few layers:</p>
			<p class="source-code">from tensorflow.keras.models import Model </p>
			<p class="source-code">from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate</p>
			<p>Then, you use model subclassing to create a model with two dense layers. Firstly, define a model subclass denoted as <strong class="source-inline">MyModel</strong>. The objects that you will generate from this class are models with two dense layers. </p>
			<p>Define the two dense layers within the <strong class="source-inline">init</strong> method. For instance, the first one can have <strong class="source-inline">64</strong> units and the ReLU activation function, while the second one can have <strong class="source-inline">10</strong> units without an activation function (in this case, the default activation function used is the linear one). After this, in the <strong class="source-inline">call</strong> method, you set up the forward pass by calling the previously defined dense layers. Firstly, you can place the <strong class="source-inline">dense_1</strong> layer to take the inputs and after it, the <strong class="source-inline">dense_2</strong> layer that returns the outputs of the layer:</p>
			<p class="source-code">class MyModel(Model): </p>
			<p class="source-code">  def __init__(self): </p>
			<p class="source-code">    super(MyModel, self).__init__()</p>
			<p class="source-code">    self.dense_1 = Dense(64, activation='relu')</p>
			<p class="source-code">    self.dense_2 = Dense(10)</p>
			<p class="source-code">    </p>
			<p class="source-code">  def call(self, inputs):, </p>
			<p class="source-code">    X = self.dense_1(inputs)</p>
			<p class="source-code">    return self.dense_2(X)</p>
			<p>The next step is to instantiate the model. For this, just call the class with no argument inside the brackets. Next, call the model on a random input to create the weights. For the input, this example uses a one-dimensional vector with <strong class="source-inline">10</strong> elements, but feel free to use a different input. You can then print the summary of the model where you can see the dense layers that you defined before.</p>
			<p>Consider the following model summary:</p>
			<p class="source-code">model = MyModel()</p>
			<p class="source-code">model(tf.random.uniform([1,10]))</p>
			<p class="source-code">model.summary()</p>
			<p>The resulting output should be like the following:</p>
			<div>
				<div id="_idContainer363" class="IMG---Figure">
					<img src="image/B16341_10_07.jpg" alt="Figure 10.7: Model summary&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7: Model summary</p>
			<p>Now, you can modify the <strong class="source-inline">call</strong> method by including a keyword argument called <strong class="source-inline">training</strong>. This is useful if you want to have different behaviors in training and inference. For example, you can create a dropout layer that will be activated only if <strong class="source-inline">training</strong> is <strong class="source-inline">true</strong>. Firstly, you need to define a dropout layer within the <strong class="source-inline">init</strong> method, given your learning rate of <strong class="source-inline">0.4</strong>. Then, in the <strong class="source-inline">call</strong> method, write an <strong class="source-inline">if</strong> clause with the <strong class="source-inline">training</strong> keyword is set to <strong class="source-inline">true</strong> by default. Inside it, just call the dropout layer:</p>
			<p class="source-code">class MyModel(Model):</p>
			<p class="source-code">  def __init__(self):</p>
			<p class="source-code">    super(MyModel, self).__init__()</p>
			<p class="source-code">    self.dense_1 = Dense(64, activation='relu')</p>
			<p class="source-code">    self.dense_2 = Dense(10)</p>
			<p class="source-code">    self.dropout = Dropout(0.4)  </p>
			<p class="source-code">  def call(self, inputs, training=True):</p>
			<p class="source-code">    X = self.dense_1(inputs)</p>
			<p class="source-code">    if training:                             </p>
			<p class="source-code">      X = self.dropout(X)                    </p>
			<p class="source-code">    return self.dense_2(X)</p>
			<p>Now, consider the model summary:</p>
			<p class="source-code">model = MyModel()</p>
			<p class="source-code">model(tf.random.uniform([1,10]))</p>
			<p class="source-code">model.summary()</p>
			<p>The summary is displayed as follows, upon running the preceding command:</p>
			<div>
				<div id="_idContainer364" class="IMG---Figure">
					<img src="image/B16341_10_08.jpg" alt="Figure 10.8: Model summary&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.8: Model summary</p>
			<p>In the following exercise, you will build a custom layer.</p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor219"/>Exercise 10.02: Building a Custom Layer</h2>
			<p>The <strong class="source-inline">Healthy-Pneumonia</strong> dataset is a subset of the <strong class="source-inline">National Institute for Health NIH</strong> dataset. The dataset consists of 9,930 total color images with dimensions of 100 by 100 pixels. The <strong class="source-inline">pneumonia-or-healthy</strong> dataset has 1,965 total healthy images with 1,375 images in the training dataset and 590 images in the test dataset.</p>
			<p>You will create a custom ResNet block that consists of a Conv2D layer, a batch normalization layer, and a ReLU activation function. You will perform binary classification on the images to distinguish between healthy and pneumonic images.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can get the <strong class="source-inline">pneumonia-or-healthy</strong> dataset here: <a href="https://packt.link/IOpUX">https://packt.link/IOpUX</a>.</p>
			<p>To get started, open a new Colab or Jupyter Notebook. If you are using Google Colab, you will need to download the dataset into your Google Drive first:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook or Google Colab.</li>
				<li>If you are using Google Colab, you can upload your dataset locally with the following code. Otherwise, go to <em class="italic">step 4</em>. Click on <strong class="source-inline">Choose Files</strong> to navigate to the CSV file and click <strong class="source-inline">Open</strong>. Save the file as <strong class="source-inline">uploaded</strong>. Then, go to the folder where you saved the dataset:<p class="source-code">from google.colab import files</p><p class="source-code">uploaded = files.upload()</p></li>
				<li>Unzip the dataset in the current folder:<p class="source-code">!unzip \*.zip</p></li>
				<li>Create a variable, <strong class="source-inline">directory</strong>, that contains the path to the dataset:<p class="source-code">directory = "/content/gdrive/My Drive/Datasets/pneumonia-or-healthy/"</p></li>
				<li>Import the <strong class="source-inline">pathlib</strong> library:<p class="source-code">import pathlib     </p></li>
				<li>Create a variable, <strong class="source-inline">path</strong>, that contains the full path to the data using <strong class="source-inline">pathlib.Path</strong>:<p class="source-code">path = pathlib.Path(directory)</p></li>
				<li>Create two variables, called <strong class="source-inline">train_dir</strong> and <strong class="source-inline">validation_dir</strong>, that take the full paths to the train and validation folders, respectively:<p class="source-code">train_dir = path / 'training_set'</p><p class="source-code">validation_dir = path / 'test_set'</p></li>
				<li>Create four variables, called <strong class="source-inline">train_healthy_dir</strong>, <strong class="source-inline">train_pneumonia_dir</strong>, <strong class="source-inline">validation_healthy_dir</strong>, and <strong class="source-inline">validation_pneumonia_dir</strong>, that take the full paths to the healthy and pneumonia folders for the train and validation sets, respectively:<p class="source-code">train_healthy_dir = train_dir / 'healthy'</p><p class="source-code">train_pneumonia_dir = train_dir /'pneumonia'</p><p class="source-code">validation_healthy_dir = validation_dir / 'healthy'</p><p class="source-code">validation_pneumonia_dir = validation_dir / 'pneumonia'</p></li>
				<li>Import the <strong class="source-inline">os</strong> package:<p class="source-code">import os     </p></li>
				<li>Create two variables, called <strong class="source-inline">total_train</strong> and <strong class="source-inline">total_val</strong>, to get the number of images for the training and validation sets, respectively:<p class="source-code">total_train = len(os.listdir(train_healthy_dir)) + \</p><p class="source-code">              len(os.listdir(train_pneumonia_dir))</p><p class="source-code">total_val = len(os.listdir(validation_healthy_dir)) + \</p><p class="source-code">            len(os.listdir(validation_pneumonia_dir))</p></li>
				<li>Import <strong class="source-inline">ImageDataGenerator</strong> from <strong class="source-inline">tensorflow.keras.preprocessing</strong>:<p class="source-code">from tensorflow.keras.preprocessing.image import ImageDataGenerator</p></li>
				<li>Instantiate two <strong class="source-inline">ImageDataGenerator</strong> classes and call them <strong class="source-inline">train_image_generator</strong> and <strong class="source-inline">validation_image_generator</strong>, which will rescale the images by dividing by 255:<p class="source-code">train_image_generator = ImageDataGenerator(rescale=1./255)</p><p class="source-code">validation_image_generator = ImageDataGenerator(rescale=1./255)</p></li>
				<li>Create three variables, called <strong class="source-inline">batch_size</strong>, <strong class="source-inline">img_height</strong>, and <strong class="source-inline">img_width</strong>, that take the values <strong class="source-inline">32</strong>, <strong class="source-inline">100</strong>, and <strong class="source-inline">100</strong>, respectively:<p class="source-code">batch_size = 32</p><p class="source-code">img_height = 100</p><p class="source-code">img_width = 100     </p></li>
				<li>Create a data generator called <strong class="source-inline">train_data_gen</strong> using <strong class="source-inline"> flow_from_directory()</strong> and specify the batch size, the path to the training folder, the value of the <strong class="source-inline">shuffle</strong> parameter, the size of the target, and the class mode:<p class="source-code">train_data_gen = train_image_generator.flow_from_directory\</p><p class="source-code">                 (batch_size=batch_size, directory=train_dir, \</p><p class="source-code">                  shuffle=True, \</p><p class="source-code">                  target_size=(img_height, img_width), \</p><p class="source-code">                  class_mode='binary')</p></li>
				<li>Create a data generator called <strong class="source-inline">val_data_gen</strong> using <strong class="source-inline"> flow_from_directory()</strong> and specify the batch size, the path to the validation folder, the size of the target, and the class mode: <p class="source-code">val_data_gen = validation_image_generator.flow_from_directory\</p><p class="source-code">               (batch_size=batch_size, directory=validation_dir, \</p><p class="source-code">                target_size=(img_height, img_width), \</p><p class="source-code">                class_mode='binary')</p></li>
				<li>Import <strong class="source-inline">matplotlib</strong> and create a <strong class="source-inline">for</strong> loop that will iterate through five images from <strong class="source-inline">train_data_gen</strong> and plot them:<p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">for _ in range(5):</p><p class="source-code">    img, label = train_data_gen.next()</p><p class="source-code">    plt.imshow(img[0])</p><p class="source-code">    plt.show()</p><p>You should see the following output:</p><div id="_idContainer365" class="IMG---Figure"><img src="image/B16341_10_09a.jpg" alt="Figure 10.9: Sample of images from the dataset&#13;&#10;"/></div><div id="_idContainer366" class="IMG---Figure"><img src="image/B16341_10_09b.jpg" alt="10.9 b"/></div><div id="_idContainer367" class="IMG---Figure"><img src="image/B16341_10_09c.jpg" alt="10.9 c"/></div><p class="figure-caption">Figure 10.9: Sample of images from the dataset </p><p>The preceding results show some examples of the images contained in this dataset.</p></li>
				<li>Import the TensorFlow library:<p class="source-code">import tensorflow as tf</p></li>
				<li>Import <strong class="source-inline">Input</strong>, <strong class="source-inline">Conv2D</strong>, <strong class="source-inline">ReLU</strong>, <strong class="source-inline">BatchNormalization</strong>, <strong class="source-inline">Add</strong>, <strong class="source-inline">AveragePooling2D</strong>, <strong class="source-inline">Flatten</strong>, and <strong class="source-inline">Dense</strong>:<p class="source-code">from tensorflow.keras.layers import Input, Conv2D, ReLU, \</p><p class="source-code">                                    BatchNormalization, Add, \</p><p class="source-code">                                    AveragePooling2D, Flatten, Dense</p></li>
				<li>Build a function that takes your input as a tensor and adds ReLU and batch normalization to it:<p class="source-code">def relu_batchnorm_layer(input):</p><p class="source-code">    return BatchNormalization()(ReLU()(input))</p></li>
				<li>Create a function to build your residual block. You will need to take a tensor (<strong class="source-inline">input</strong>) as your input and pass it to two Conv2D layers with a stride of <strong class="source-inline">2</strong>. Next, add the input to the output, followed by ReLU and batch normalization, returning a tensor. Add another Conv2D layer with <strong class="source-inline">kernel_size=1</strong>. Add its result to the output of the previous Conv2D layer. Finally, apply <strong class="source-inline">relu_batchnorm_layer()</strong> and return its value. You will apply the exact same filters (numbers and dimensions are defined by two input parameters of the construction function) to all Conv2D layers:<p class="source-code">def residual_block(input, filters: int, kernel_size: int = 3):</p><p class="source-code">    int_output = Conv2D(filters=filters, kernel_size=kernel_size, </p><p class="source-code">                        strides=(2), </p><p class="source-code">                        padding="same")(input)</p><p class="source-code">    int_output = relu_batchnorm_layer(int_output)</p><p class="source-code">    int_output = Conv2D(filters=filters, kernel_size=kernel_size, </p><p class="source-code">                        padding="same")(int_output)</p><p class="source-code">    int_output2 = Conv2D(filters=filters, kernel_size=1, strides=2,</p><p class="source-code">                        padding="same")(input)</p><p class="source-code">    output = Add()([int_output2, int_output]) </p><p class="source-code">    output = relu_batchnorm_layer(output)</p><p class="source-code">    return output</p></li>
				<li>Import the <strong class="source-inline">Model</strong> module:<p class="source-code">from tensorflow.keras.models import Model</p></li>
				<li>Use <strong class="source-inline">keras.layers.Input()</strong> to define the input layer to the model. Here, your shape is 100 pixels by 100 pixels and has three colors (RGB):<p class="source-code">inputs = Input(shape=(100, 100, 3))</p></li>
				<li>Apply batch normalization to the input, followed by a Conv2D layer with <strong class="source-inline">32</strong> filters of size <strong class="source-inline">3*3</strong>, stride <strong class="source-inline">1</strong>, and <strong class="source-inline">same</strong> padding. Finally, apply the <strong class="source-inline">relu_batchnorm_layer()</strong> function to its output:<p class="source-code">t = BatchNormalization()(inputs)</p><p class="source-code">t = Conv2D(kernel_size=3,</p><p class="source-code">           strides=1,</p><p class="source-code">           filters=32,</p><p class="source-code">           padding="same")(t)</p><p class="source-code">t = relu_batchnorm_layer(t)</p></li>
				<li>Provide the output of the previous layer to the <strong class="source-inline">residual_block()</strong> function with <strong class="source-inline">32</strong> filters. Then, pass its output an average pooling layer with four units and then flatten its results before feeding it to a fully connected layer of <strong class="source-inline">1</strong> unit with sigmoid as the activation function:<p class="source-code">t = residual_block(t, filters=32)</p><p class="source-code">    </p><p class="source-code">t = AveragePooling2D(4)(t)</p><p class="source-code">t = Flatten()(t)</p><p class="source-code">outputs = Dense(1, activation='sigmoid')(t)</p></li>
				<li>Instantiate a <strong class="source-inline">Model()</strong> class with the original input and the output of the fully connected layer:<p class="source-code">model = Model(inputs, outputs)</p></li>
				<li>Get the summary of your model:<p class="source-code">model.summary()</p><p>You will see a summary, including trainable and non-trainable parameters, as follows:</p><div id="_idContainer368" class="IMG---Figure"><img src="image/B16341_10_10.jpg" alt="Figure 10.10: Model summary&#13;&#10;"/></div><p class="figure-caption">Figure 10.10: Model summary</p></li>
				<li>Compile the model by providing binary cross-entropy as the loss function, Adam as the optimizer, and accuracy as the metric to be displayed:<p class="source-code">model.compile(</p><p class="source-code">        optimizer='adam',</p><p class="source-code">        loss=binary_crossentropy,</p><p class="source-code">        metrics=['accuracy'])</p></li>
				<li>Fit the model and provide the train and validation data generators, the number of epochs, the steps per epoch, and the validation steps:<p class="source-code">history = model.fit(</p><p class="source-code">    Train_data_gen,</p><p class="source-code">    steps_per_epoch=total_train // batch_size,</p><p class="source-code">    epochs=5,</p><p class="source-code">    validation_data=val_data_gen,</p><p class="source-code">    validation_steps=total_val // batch_size</p><p class="source-code">)</p><p>You should get output like the following:</p><div id="_idContainer369" class="IMG---Figure"><img src="image/B16341_10_11.jpg" alt="Figure 10.11: Screenshot of training progress&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 10.11: Screenshot of training progress</p>
			<p>The preceding screenshot shows the information displayed by TensorFlow during the training of your model. You can see the accuracy achieved on the training and validation sets for each epoch. </p>
			<p>In this exercise, you created your own custom layer for the network. Now, let's test the knowledge you have gained so far in the following activity.</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor220"/>Activity 10.01: Building a Model with Custom Layers and a Custom Loss Function</h2>
			<p>The <strong class="source-inline">table-or-glass</strong> dataset is a subset of images taken from the <strong class="source-inline">Open Images V6</strong> dataset. The <strong class="source-inline">Open Images V6</strong> dataset has around 9 million images. The <strong class="source-inline">table-or-glass</strong> dataset consists of 7,484 total color images with dimensions of 100 by 100 pixels. The <strong class="source-inline">table-or-glass</strong> dataset has 3,741 total glass images with 2,618 in the training and 1,123 in the test dataset. There are a total of 3,743 table images with 2,618 in the training and 1,125 in the test dataset. You are required to train a more complex model that can distinguish images of glasses and tables using custom ResNet blocks and a custom loss function.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can find the dataset here: <a href="https://packt.link/bE5F6">https://packt.link/bE5F6</a>.</p>
			<p>The following steps will help you to complete this activity:</p>
			<ol>
				<li value="1">Import the dataset and unzip the file into a local folder.</li>
				<li>Create the list of images for both the training and testing sets.</li>
				<li>Analyze the distribution of the target variable.</li>
				<li>Preprocess the images (standardization and reshaping).</li>
				<li>Create a custom loss function that will calculate the average squared error.</li>
				<li>Create a custom residual block constructor function.</li>
				<li>Train your model.</li>
				<li>Print the learning curves for accuracy and loss.<p class="callout-heading">Note</p><p class="callout">The solution to this activity can be found via <a href="B16341_Solution_ePub.xhtml#_idTextAnchor283">this link</a>.</p></li>
			</ol>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor221"/>Summary</h1>
			<p>This chapter demonstrated how to build and utilize custom TensorFlow components. You learned how to design and implement custom loss functions, layers, and residual blocks. Using the TensorFlow functional API or model subclassing allows you to build more complex deep learning models that may be a better fit for your projects.</p>
			<p>In the next and final chapter, you will explore and build generative models that can learn patterns and relationships within data, and use those relationships to generate new, unique data.</p>
		</div>
	</body></html>