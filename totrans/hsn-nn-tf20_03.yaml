- en: Neural Networks and Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks are the main machine learning models that we will be looking
    at in this book. Their applications are countless, as are their application fields.
    These range from computer vision applications (where an object should be localized
    in an image), to finance (where neural networks are applied to detect frauds),
    passing trough trading, to reaching even the art field, where neural networks
    are used together with the adversarial training process to create models that
    are able to generate new and unseen kinds of art with astonishing results.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter, which is perhaps the richest in terms of theory in this whole
    book, shows you how to define neural networks and how to make them learn. To begin,
    the mathematical formula for artificial neurons will be presented, and we will
    highlight why a neuron must have certain features to be able to learn. After that,
    fully connected and convolutional neuronal topologies will be explained in detail
    since these are the building blocks of almost every neural network architecture.
    At the same time, the concept of deep learning and deep architectures will be
    introduced. Introducing this concept is a must since it is because of deep architectures
    that, nowadays, neural networks are used to solve challenging problems with super-human
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, the optimization process that's required to train a parametric
    model, together with some regularization techniques that are used to improve the
    model's performance, will be shown. Gradient descent, the chain rule, and the
    graphical representation of the computations all have their own dedicated sections
    since it is extremely important for any machine learning practitioner to know
    what happens when a framework is used to train a model.
  prefs: []
  type: TYPE_NORMAL
- en: If you are already familiar with the concepts presented in this chapter, you
    can jump directly to the next chapter, [Chapter 3](f62be9d4-c8e0-4590-8299-2fdad139830f.xhtml), *TensorFlow
    Graph Architecture*, which is dedicated to the TensorFlow graph architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The definition of a neural network, as provided by the inventor of one of the
    first neurocomputers, *Dr. Robert Hecht-Nielson,* in *Neural Network Primer—Part
    I*, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '"A computing system made up of a number of simple, highly interconnected processing
    elements, which process information by their dynamic state response to external
    inputs."'
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we can think of artificial neural networks as a computational model
    that is based on how the brain is believed to work. Hence, the mathematical model
    is inspired by biological neurons.
  prefs: []
  type: TYPE_NORMAL
- en: Biological neurons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main computational units of the brain are known as neurons; in the human
    nervous system, approximately 86 billion neurons can be found, all of which are
    connected by synapses. The following diagram shows a biological neuron and the
    mathematical model that draws inspiration from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a05f5586-0ad6-4a20-8935-4c44a2176e6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Representation of the biological neuron, (a), on the left and its mathematical
    model, (b), on the right. Source: Stanford cs231n'
  prefs: []
  type: TYPE_NORMAL
- en: 'Biological neurons are made up of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dendrites**: Minor fibers that carry information, in the form of an electric
    signal, from the outside to the nucleus.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synapses**: These are the connection points among neurons. Neurons receive
    input signals on the synapses that are connected to the dendrites.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nucleus**: This receives the signals from the dendrites, elaborates on them,
    and produces a response (output signal) that it sends to the axon.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Axon**: The output channel of the neuron. It can be connected to other neuron synapses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each neuron receives input signals from its dendrites and transports them to
    the nucleus where they are processed; dendrites process the signals, thereby integrating
    (adding up or combining) excitation and inhibition from every input synapse. The
    nucleus receives the integrated signals and adds them. If the final sum is above
    a certain threshold, the neuron fires and the resulting information is carried
    down through the axon and thus to any other connected neuron.
  prefs: []
  type: TYPE_NORMAL
- en: The amount of signal that's transmitted among neurons depends on the strength
    of the connections. It is the arrangement of the neurons and the strength of these
    synapses that establish the function of the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: The learning phase of biological neurons is based on the modification of the
    output signal generated by the nucleus over time, as a function of certain types
    of input signals. Neurons specialize themselves in recognizing certain stimuli
    during their lifetime.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neurons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Artificial neurons are based on the structure of the biological neuron and
    use mathematical functions with real values to simulate their behavior. Such artificial
    neurons are called **perceptrons**, a concept that was developed in the 50s and
    60s by the scientist Frank Rosenblatt. Taking this mathematical analogy into account,
    we can talk about the biological neurons as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dendrites**: The number of inputs the neuron accepts. It can also be seen
    as the number of dimensions, *D*, of the input data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synapses**:  ![](img/c63ff61c-545a-41e4-b0ec-57332f0d83b3.png)  weights associated
    with the dendrites. These are the values that change during the training phase.
    At the end of the training phase, we say the neuron is specialized (it learned
    to extract particular features from the input).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If ![](img/747cd994-4daa-4673-940e-a76a4d293266.png) is a D-dimensional input
    vector, the operation that's executed by the synapses is ![](img/e7a6566e-2a4d-4bb1-892c-93e979c5ef86.png)
  prefs: []
  type: TYPE_NORMAL
- en: '**Nucleus** (body cell): This is a function that bonds the values coming from
    the synapses, thereby defining the behavior of the neuron. To simulate the action
    of the biological neuron, that is, firing (activating) only when there are certain
    stimuli in the input, the nucleus is modeled with **non-linear** functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If ![](img/e49a8892-74d1-462d-b219-ead61cd07dd1.png) is a non-linear function,
    the output of the neuron, which takes into account all input stimuli, is given
    by the following equation:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/c5c1b918-f08f-4320-9f07-991087923360.png).'
  prefs: []
  type: TYPE_NORMAL
- en: Here, ![](img/5b69a829-f2ab-4c5a-a836-2c82601b0cf4.png) is the **bias term**,
    which is of fundamental importance. It allows you to learn about a decision boundary
    that's not centered on the origin of the D-dimensional space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we remove the non-linear (also called **activation**) function for a moment,
    we can easily see that the synapses define a hyper-plane with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/7a2788a7-db86-43dc-8480-78a4609c1c88.png)].'
  prefs: []
  type: TYPE_NORMAL
- en: A single neuron is able to perform *only* binary classification because the
    D-dimensional vector, ![](img/a99782dc-877b-4629-b277-f9ee1ba29535.png), can just
    be over or under the hyperplane it defines.
  prefs: []
  type: TYPE_NORMAL
- en: A perceptron can correctly classify samples in a D-dimensional space if—and
    only if—those samples are linearly separable.
  prefs: []
  type: TYPE_NORMAL
- en: The nucleus, with its non-linearity, maps the hyperplane defined by the dendrites in
    a more general hypersurface, which is the learned decision boundary. Non-linearity,
    in the best-case scenario, transforms the hyperplane into a hypersurface that's
    able to correctly classify points in a D-dimensional space. However, it only does
    this if those points are separable in two regions by a single hypersurface.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the main reason we need multi-layer neural networks: if the input data
    is not separable by a single hypersurface, adding another layer on top that works
    by transforming the learned hypersurface into a new hypersurface with an additional
    classification region allows it to learn complex classification boundaries that
    are capable of separating the regions correctly.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, it is worth noting that feed-forward neural networks, such as neural
    networks with connections among neurons that do not form a cycle, are universal
    function approximators. This means that, if a way to separate regions exists,
    a well-trained neural network with enough capacity will learn to approximate that
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Axon**: This is the output value of the neuron. It can be used as input by
    other neurons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s important to stress that this model of a biological neuron is very coarse:
    for example, there are many different types of neuron, each with different properties.
    The dendrites in biological neurons perform complex nonlinear computations. The
    synapses are not just a single weight; they are a complex non-linear dynamical
    system. There are many other simplifications in the model because the reality
    is way more complicated and tougher to model than this. Hence, this biological
    inspiration is just a nice way to think about neural networks, but don''t be fooled
    by all of these similarities: artificial neural networks are only loosely inspired
    by biological neurons.'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Why we should use neural networks and not other machine learning models?"*'
  prefs: []
  type: TYPE_NORMAL
- en: Traditional machine learning models are powerful but usually not as flexible as
    neural networks. Neural networks can be arranged in different topologies, and
    the geometry changes what the neural networks see (the input stimuli). Moreover,
    it's straightforward to create layers upon layers of neural networks with different
    topologies, creating deep models.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the greatest strengths of neural networks is their ability to become
    feature extractors: other machine learning models need the input data to be processed,
    have their meaningful features extracted, and only on those features (manually
    defined!) can the model be applied.'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks, on the other hand, can extract meaningful features from any
    input data by themselves (depending on the topology of the layers that are used).
  prefs: []
  type: TYPE_NORMAL
- en: The single perceptron illustrates how it is possible to weigh and add different
    types of input to make a simple decision; a complex network of perceptrons could
    make a quite subtle decision. A **neural network architecture**, therefore, is
    made up of neurons, all of which are connected through synapses (biologically)
    where the information flows through them. During training, the neurons fire when
    they learn specific patterns from the data.
  prefs: []
  type: TYPE_NORMAL
- en: This fire rate is modeled using an activation function. More precisely, the
    neurons are connected in an acyclic graph; c
  prefs: []
  type: TYPE_NORMAL
- en: ycles are not allowed since that would imply an infinite loop in the forward
    pass of the network (these types of networks are called **feed-forward neural
    networks**). Instead of amorphous blobs of connected neurons, neural network models
    are often organized into distinct layers of neurons. The most common layer type
    is the fully connected layer.
  prefs: []
  type: TYPE_NORMAL
- en: Fully connected layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fully connected configuration is a particular network topology in which
    neurons between two adjacent layers are fully pairwise-connected, but neurons
    within a single layer share no connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'Organizing networks into layers allows us to create stacks of fully connected
    layers, with a different number of neurons per layer. We can think about a multi-layer
    neural network as a model with visible and hidden layers. The visible layers are
    just the input and output layers; the hidden layers are the ones that aren''t
    connected to the outside:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef4794f3-77ae-4d57-a534-cc05481441aa.png)'
  prefs: []
  type: TYPE_IMG
- en: A typical representation of a fully connected neural network, with two hidden
    layers. Every layer reduces the dimensionality of its input with the aim of producing
    two different outputs given the ten input features.
  prefs: []
  type: TYPE_NORMAL
- en: The number of neurons in the hidden layers is entirely arbitrary, and it changes
    the learning capacity of the network. The input and output layers, instead, have
    a fixed dimension due to the task we are going to solve (for example, if we want
    to solve an *n*-classes classification on D-dimensional inputs, then we need an
    input layer with D inputs and an output layer with n outputs).
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, it is possible to define the output of a fully connected layer
    as the result of a matrix product. Let''s say we have the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2192c7e-2156-49c3-a22d-842fd589f073.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output, *O*, is given by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f1acf9a-a09f-43f9-ad9e-293314aab109.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, M is the arbitrary number of neurons in the layer.
  prefs: []
  type: TYPE_NORMAL
- en: While the design of the input and output layers of a neural network is straightforward,
    the design of the hidden layers is not so simple. There are no rules; neural networks
    researchers have developed many design heuristics for hidden layers which help
    to get the correct behavior (for example, when there's a trade-off between the
    number of hidden layers and the time to train the network).
  prefs: []
  type: TYPE_NORMAL
- en: In general, increasing the number of neurons per layer and/or the number of
    layers in a neural network means having to increase the network capacity. This
    means that the neural network can express more complicated functions and that
    the space of representable functions grows; however, this is good and bad at the
    same time. It's good because we can learn more complicated functions, but it's
    bad because having more trainable parameters increases the risk of overfitting
    the training data.
  prefs: []
  type: TYPE_NORMAL
- en: In general, smaller neural networks should be preferred if the data is not complex
    or we are working with small datasets. Fortunately, there are different techniques
    that allow you to prevent overfitting the data when you're using high-capacity
    models. These techniques are called regularization techniques (L2 penalties on
    the parameters, dropout, batch normalization, data augmentation, and so on). We
    will dig into them in upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The activation function is another important part of the design of every neural
    network. It is applied to every single neuron: nobody forces us to use the same
    non-linear function on every neuron, but it is a convention to pick a form of
    nonlinearity and use it for every neuron in the same layer.'
  prefs: []
  type: TYPE_NORMAL
- en: If we are building a classifier, we are interested in evaluating the output
    layer of the network and being able to interpret the output values to understand
    what the network predicted. Let's say we have a linear activation function that's
    been applied to every single neuron of the output layer, where every neuron is
    associated with a particular class (looking at the preceding image, we have a
    3-dimensional input and two output neurons, one for each class) – how can we interpret
    those values, since their codomain is the whole set of real numbers? It's hard
    to interpret values that are expressed in this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most natural way is to constrain the sum of the output values to the [0,1]
    range so that we can consider the output values as sampled from the probability
    distribution over the predicted classes and we can consider the neuron with the
    highest value as the predicted class. Alternatively, we could choose to apply
    a thresholding operation on the values in order to simulate the biological neurons
    firing: if the output of a neuron is greater then a certain threshold value, we
    can output a value of 1, or 0 otherwise.'
  prefs: []
  type: TYPE_NORMAL
- en: Another thing we can do is squash every single neuron's output in the [0,1]
    range if, for instance, we are solving a multi-class classification task where
    the classes are not mutually exclusive.
  prefs: []
  type: TYPE_NORMAL
- en: It's easy to understand why a certain non-linearity in the output layer is important
    – it can change the behavior of the network since the way we interpret the network's
    output depends on it. However, understanding why non-linearity is important in
    every single layer is mandatory for a complete understanding of neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we already know, the output value of the *i*-th neuron in a layer is computed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The activation function, ![](img/cc9f57ec-e305-4b23-a956-360d0bf40fe8.png),
    is important for several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: As stated in the previous section, depending on the layer we are applying the
    non-linearity to, it allows us to interpret the result of the neural network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the input data is not linearly separable, it's non-linearity allows you to
    approximate a non-linear function that's capable of separating data in a non-linear
    way (just think about the transformation of a hyperplane into a generic hypersurface).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Without non-linearities among adjacent layers, multi-layer neural networks
    are equivalent to a single neural network with a single hidden layer, and so they
    are able to separate only two regions of the input data. In fact, given:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/840f8ae1-cb55-4dee-a6f9-afb63507b410.png)]'
  prefs: []
  type: TYPE_NORMAL
- en: 'And two perceptrons stacked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/89dacb54-3f48-42e0-97a3-038597d46210.png)],'
  prefs: []
  type: TYPE_NORMAL
- en: 'We know that the output of the second perceptron is equivalent to the output
    of a single perceptron:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](img/ba89ea59-dade-46b2-bd23-18f3ce03eda9.png)],'
  prefs: []
  type: TYPE_NORMAL
- en: Where [![](img/025f29e7-7378-415e-a1f1-470c0576b486.png)] and [![](img/3dff90d5-1a3e-4cbf-9e5e-b3c69ce83826.png)] are
    the matrix of weights and the bias vector is equivalent to the product of the
    single weight matrices and bias vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that, when [![](img/cc9f57ec-e305-4b23-a956-360d0bf40fe8.png)] is linear, a
    multi-layer neural network is always equal to a single layer neural network (hence,
    it has the same learning capacity). If not, the last equation doesn't hold.
  prefs: []
  type: TYPE_NORMAL
- en: 'Non-linearities make the network robust to noisy input. If the input data contains
    noise (the training set contains values that are not perfect – it happens, and
    it happens often), the non-lineary avoids its propagation to the output. This
    can be demonstrated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/60b167dc-c66d-4b10-9223-20e985ab5cb5.png)].'
  prefs: []
  type: TYPE_NORMAL
- en: Two of the most frequently used activation functions are the sigmoid (![](img/098ad987-518d-4116-88e6-0046e571c631.png))and
    the hyperbolic tangent (![](img/995ab973-a9e9-4291-827b-987f67f5a715.png)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The first is used as the activation function of the output layer in almost
    every classification problem since it squashes the output in the [0,1] range and
    allows you to interpret the prediction as a probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c0d2c3a-c044-4063-b46e-3845f2c0e6f9.png)'
  prefs: []
  type: TYPE_IMG
- en: The hyperbolic tangent, instead, is used as the activation function of the output
    layer of almost every generative model that's trained to generate images. Even
    in this case, the reason we use it is to correctly interpret the output and to
    create a meaningful bond among the input images and the generated images. We are
    used to scaling the input values from [0,255] to [-1,1], which is the range of
    the ![](img/7e4d457c-5fc1-4a06-8529-8210d777dcc1.png) function.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, using functions such as ![](img/6be6bd2c-1dad-4e1f-8349-0a473db8694d.png)
    and ![](img/6b3d6095-8a78-4677-803e-481b6e8ae40c.png) as activations in the hidden
    layer isn''t the best choice for reasons related to training via backpropagation
    (as we will see in the following sections, saturating nonlinearities can be a
    problem). Many other activation functions have been developed in order to overcome
    the problems that have been introduced by saturating nonlinearities. A short visual
    overview of the most common nonlinearities that have been developed is shown in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fefa202a-4a07-4467-821d-2f0c8716a113.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A list of the most common activation functions. Source: Stanford cs231n.'
  prefs: []
  type: TYPE_NORMAL
- en: Once the network structure has been defined, as well as the activation functions
    to use in the hidden and the output layers, it's time to define the relation among
    the training data and the network's output in order to be able to train the network and
    make it solve the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming sections, we will talk about a discrete classification problem
    that follows on from [Chapter 1](0dff1bba-f231-45fa-9a89-b4f127309579.xhtml), *What
    is Machine Learning? *We're talking about the fact that everything that holds
    for a classification problem also holds for continuous variables since we are
    using neural networks as a tool to solve a supervised learning problem. Since
    a neural network is a parametric model, training it means that we need to update
    the parameters,
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d054cd5a-5fb8-4652-83d5-1e63d2b345ce.png), to find the configuration
    that solves the problem in the best possible way.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Training a neural network is mandatory if we wish to define a relationship
    among the input data and the desired output: an objective function—or loss function,
    since we want to minimize the loss as our objective.'
  prefs: []
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After defining the network architecture, the model must be trained. It's now
    time to define the relationship between the model's output and the real data.
    To do so, a loss function must be defined.
  prefs: []
  type: TYPE_NORMAL
- en: The loss function is used to assesses the goodness-of-fit of a model.
  prefs: []
  type: TYPE_NORMAL
- en: There are several loss functions, each one expressing a relationship among the
    network output and the real data, and their form completely influences the quality
    of the model's prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a discrete classification problem over ![](img/df395d74-ce33-4d18-bf37-ae6953cd08fa.png)
    classes, we can model the defined neural network that accepts a D-dimensional
    input vector, ![](img/4226cdb4-79cd-473b-b532-e842f7ee12c8.png), and produces
    an ![](img/cf076cfb-87a0-49bd-a1ee-b1b1f7ebbacf.png)-dimensional vector of predictions
    as a function of its parameters,![](img/50596d95-1217-443a-884b-c017f8359979.png), like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c25c25e7-a0eb-47ac-a593-e2a2de349c83.png)'
  prefs: []
  type: TYPE_IMG
- en: The model produces an M-dimensional output vector that contains the probabilities
    the model assigns to the input, ![](img/fb3cf79f-e92c-4dd7-8c10-1204ce356b49.png), for
    every possible class (if we applied the sigmoid activation to the output layer,
    we can interpret the output in this way).
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s easy to extract the position of the neuron in the output layer that produced
    the highest value. The equation for the predicted class is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85b9814f-fc1e-4196-8202-a64e6ab3f9bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'By using this, we can find the index of the neuron that produced the highest
    classification score. Since we know the label associated with the input, ![](img/25a9a721-29f9-4e85-8410-f1fc7554e79e.png),
    we are almost ready to define the relationship between the prediction and the
    label. The last problem we will face is the label format: the label is a scalar
    value, whereas the network output is an M-dimensional vector. Although we can
    find the position of the neuron with the highest probability value, we are interested
    in the whole output layer, since we want to increase the probability of the correct
    class and penalize the incorrect ones.'
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the label must be converted into an M-dimensional representation
    so that we can create a bond between every output neuron and the label.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most natural conversion from a scalar value to an M-dimensional representation
    is called **one-hot** encoding. This encoding consists of the creation of an M-dimensional
    vector that has a value of 1 in the position of the label and 0 in every other
    position. Therefore, we can consider the one-hot encoded-label as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b47d8b8-13b3-455e-8991-b107a617fb45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It''s now possible to define the general formulation of the loss-function for
    the *i*-th training set instance as a real-valued function that creates a bond
    between the ground truth (the label that''s been correctly encoded) and the predicted
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fd197327-5b89-4c4b-9687-4892f9fd2c9f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The general formulation of a loss function that''s applied to the complete
    training set of cardinality, *k*, can be expressed as the mean of the loss that''s
    computed on the single instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06ef012e-6bec-4994-a209-11a815a73b75.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The loss must be chosen (or defined) based on the problem at hand. The simplest
    and most intuitive loss function for a classification problem (of mutually exclusive
    classes) is the L2 distance among the one-hot encoded representation of the label
    and the network output. The aim is to minimize the distance between the network
    output and the one-hot encoded label, thereby making the network predict an M-dimensional
    vector that looks like the correct label:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b3e944a-47a2-4d41-ab21-32e54add72da.png)'
  prefs: []
  type: TYPE_IMG
- en: The minimization of the loss function occurs through small iterative adjustments
    of the model's parameter values.
  prefs: []
  type: TYPE_NORMAL
- en: Parameter initialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The initial model parameter values are the solution to the problem the training
    phase iteratively refines: there''s no unique way of initializing the network
    parameters, and perhaps the only working suggestions regarding the parameter''s
    initialization are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Do not initialize the network parameters to zero**: It is impossible to find
    a new solution using gradient descent (as we will see in the next section) since
    the whole gradient is 0 and therefore there''s no indication of the update direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Break symmetry between different units**: If two hidden units with the same
    activation function are connected to the same input, then these two inputs must
    have a different initial parameter value. This is required because almost every
    solution requires a set of different parameters to be assigned to each neuron
    to find a meaningful solution. If we start with all the parameters with the same
    value instead, every update step will update all the network parameters by the
    same amount since the updated value depends on the error, which is equal for every
    neuron in the network. Due to this, we will be unable to find a meaningful solution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, the initial solution to the problem is sampled by a random normal distribution
    with zero mean and unary variance. This distribution ensures that network parameters
    are small and equally distributed around the zero value while being different
    among them, therefore breaking the symmetry.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have defined the network architecture, correctly formatted the input
    labels, and defined the input-output relation with the loss function, how can
    we minimize the loss? How can we iteratively adjust the model parameters to minimize
    the loss and thus solve the problem?
  prefs: []
  type: TYPE_NORMAL
- en: It's all a matter of optimization and optimization algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operation research gives us efficient algorithms that we can use to solve optimization
    problems by finding the global optimum (the global minimum point) if the problems
    are expressed as a function with well-defined characteristics (for instance, convex
    optimization requires the function to be a convex).
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neural networks are universal function approximators; therefore, it
    is not possible to make assumptions about the shape of the function the neural
    network is approximating. Moreover, the most common optimization methods exploit
    geometric considerations, but we know from [Chapter 1](0dff1bba-f231-45fa-9a89-b4f127309579.xhtml), *What
    is Machine Learning?**,* that geometry works in an unusual way when dimensionality
    is high due to the curse of dimensionality.
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, it is not possible to use operation research methods that
    are capable of finding the global optimum of an optimization (minimization) problem.
    Instead, we have to use an iterative refinement method that, starting from an
    initial solution tries, to refine it (by updating the model parameters that represent
    the solution) with the aim of finding a good, local optimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can think about the model parameters, ![](img/58b62beb-2225-4afb-9f44-73127d592942.png), as
    the initial solution to a minimization problem. Therefore, we can start evaluating
    the loss function at the training step, 0 ![](img/1432f8ae-a8cc-4427-ba37-04412b6a62db.png),
    so that we have an idea about the value it assumes with the actual initial configuration
    of parameters, ![](img/c14904a6-26e2-4c70-8cd8-265c03f0efa3.png). Now, we have
    to decide on how to update the model parameters. To do this, we need to perform
    the first update step, which we do by following the information that the loss
    gives us. We can proceed in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Random perturbations**: We can apply a random perturbation, ![](img/6b4079db-023b-4ab2-a317-528be4f62854.png), to
    the current set of parameters and compute the loss value on the obtained new set
    of parameters, ![](img/d7c875ab-85c7-45d7-bc2a-64f076174514.png).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the loss value at the training step, ![](img/36c33b0c-8754-4502-95f6-12fd0e510b73.png), is
    less than the value at the previous one, we can accept the found solution and
    move on with a new random perturbation that's applied to the new set of parameters.
    Otherwise, we have to repeat the random perturbation until a better solution is
    found.
  prefs: []
  type: TYPE_NORMAL
- en: '**Estimation of the update direction**: Instead of generating a new set of
    parameters randomly, is it possible to guide the local optimum research process
    toward the direction of the maximum descent of the function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second approach is the de facto standard for training parametric machine
    learning models that are expressed as differentiable functions.
  prefs: []
  type: TYPE_NORMAL
- en: To properly understand this gradient descent method, we have to think about
    the loss function as a way of defining a surface in the parameter space—our objective,
    that is, minimizing the loss, means that we need to find the lowest point on this
    surface.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Gradient descent is a method that''s used to calculate the best direction to
    move in when we''re searching for the solution to a minimization/maximization
    problem. This method suggests the direction to follow when we''re updating the
    model parameters: the direction that''s found, depending on the input data that''s
    used, is the direction of the steepest descent of the loss surface. The data that''s
    used is of extreme importance since it follows the evaluation of the loss function
    and therefore the surface that''s used to evaluate the update direction.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The update direction is given by the gradient of the loss function. It''s known
    from calculus that the derivative operation for a single variable differentiable
    function, ![](img/b2f0595a-05ea-4981-b131-dd0467a0a09f.png), in point ![](img/f07ae0c3-7f9d-4a9d-90e8-77fa60aa7f42.png) is
    given by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4b9aced6-e6f2-4851-9807-f9acae93e082.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This operation gives us a description of the behavior of the function in ![](img/4ba59bc9-d41e-4b45-8758-2e5f68c35f5b.png):
    it shows us how much the function varies with respect to the ![](img/2fa106b7-259a-4b3c-9f1f-19004dda9d59.png) variable
    in an infinitely small region centered in ![](img/ad1c59c0-9c33-4535-a361-51106af7897f.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The generalization of the derivative operation for an n-variables function
    is given by the gradient, that is, the vector of the partial derivatives (the
    vector of the derivatives of the function with respect to a single variable considering
    constants any other variable). In the case of our loss function, it is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f89ad48-7a5d-4489-b34f-9d6b627052be.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/d29ed3ba-8018-45d0-b3dc-28b5c014d4ff.png) indicates the direction along
    which the function is growing. Hence, since our objective is to find the minimum,
    we have to move along the direction indicated by the anti-gradient, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d10a5132-7220-453a-b128-126bd8af5117.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, the anti-gradient represents the direction to follow when performing
    the parameter update. The parameter update step now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de3e35e9-2313-406e-8607-058f113a430e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The ![](img/b39bcd22-c232-4adb-aff2-c3b55ed3d1d2.png) parameter is the learning
    rate and is a hyperparameter of the training phase with gradient descent. Choosing
    the correct value for the learning rate is more of an art than a science, and
    the only thing we can do is use our intuition to choose a value that works well
    for our model and dataset. We have to keep in mind that the anti-gradient only
    tells us the direction to follow; it doesn''t give us any information about the
    distance from the current solution to the minimum point. The distance, or the
    strength of the update, is regulated by the learning rate:'
  prefs: []
  type: TYPE_NORMAL
- en: A learning rate that's too high could make the training phase unstable due to
    jumps around the local minima. This causes oscillations of the loss function's
    value. To remember this, we can just think about a U shaped surface. If the learning
    rate is too high, we jump from the left to the right of the U, and vice versa
    in the next update step, without ever descending the valley (because the distance
    from the two peaks of the U is greater than ![](img/b39bcd22-c232-4adb-aff2-c3b55ed3d1d2.png)).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A learning rate that's too small could make the training phase suboptimal since
    we never jump out of a valley that is not the point of the global minimum. Hence,
    there's a risk of being stuck in a local minimum. Moreover, another risk with
    a learning rate that's too small is never finding a good solution – not because
    we are stuck in a local minimum, but because we are moving too slowly toward the
    direction at hand. Since this is an iterative process, the research could take
    too long.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to face the challenge of choosing the learning rate value, various
    strategies have been developed that change its value during the training phase,
    usually reducing it in order to find a trade-off between the exploration of the
    landscape using a big learning rate and the refinement of the found solution (descending
    the valley) using a smaller learning rate value.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've looked at updating parameters by considering a loss function that's
    computed using the complete dataset, all at once. This method is called **batch
    gradient descent**. This method, in practice, can never be applied to a real scenario
    since modern applications of neural networks deal with huge amounts of data that
    rarely fit inside the computer's memory.
  prefs: []
  type: TYPE_NORMAL
- en: Several variants of batch gradient descent have been developed to overcome its
    limitations, together with different strategies for updating the model parameters,
    that will help us solve face some challenges related to the gradient methods themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Stochastic gradient descent updates the model parameter for every element of
    the training dataset—one example, one update step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf9fde1e-c705-4e1e-8dc5-b3ecac1f28c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the dataset has high variance, stochastic gradient descent causes huge fluctuations
    of the loss value during the training phase. This can be both an advantage and
    a disadvantage:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be an advantage because, due to the fluctuations of the loss, we jump
    into unexplored zones of the solution space that could contain a better minimum.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a method suited for online training. This means training with new data
    during the whole lifetime of the model (which means we can continue to train the
    model with new data, usually coming from a sensor).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The convergence is slower and finding a good minimum is more difficult since
    the updates have high variance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The de facto method for training neural networks that try to keep the advantages
    of both batch and stochastic gradient descent is known as mini-batch gradient
    descent.
  prefs: []
  type: TYPE_NORMAL
- en: Mini-batch gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Mini-batch gradient descent keeps the best parts of the batch and stochastic
    gradient descent methods. It updates the model parameters using a subset of cardinality, ![](img/9e376903-315b-45f3-9d66-ab20fde2b198.png),
    of the training set, which is a mini-batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3923a990-cd69-4524-910a-1e4a0d1f6093.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is the most widely used approach due to the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Using mini-batches reduces the parameter's update variance, and so it causes
    faster convergence in the training process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a mini-batch of cardinality allows you to reuse the same method for online
    training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s possible to write down a generic formula for gradient descent at the
    update step, *s*, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ccb450d2-31b0-4728-a205-a43e450ad77e.png)'
  prefs: []
  type: TYPE_IMG
- en: For ![](img/213bad97-a25e-469a-8e6b-328f9f15ea2a.png), the method is stochastic
    gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For ![](img/4fba78fd-d5ec-4b11-b2f2-8a010fd4ead7.png), the method is batch gradient
    descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For ![](img/7776fe65-4456-4dcd-a3f2-14f4cdad03bb.png), the method is mini-batch
    gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The three methods that have been shown here update the model parameters in a
    so-called **vanilla** way that only considers the current parameter's value and
    the anti-gradient that's computed by applying the definition. They all use a fixed
    value for the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other parameter optimization algorithms exist, and all of them have been developed
    with the aim of finding better solutions, exploring the parameter space in a better
    way, and overcoming all the problems that a vanilla approach can face when searching
    for a good minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choose the learning rate**: The learning rate is probably the most important
    hyperparameter of the whole training phase. These reasons were explained at the
    end of the *Gradient descent* section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Constant learning rate**: The vanilla update strategy doesn''t change the
    learning rate value during the training phase. Moreover, it uses the same learning
    rate to update every parameter. Is this always desirable? Probably not, since
    treating parameters associated with input features with a different frequency
    of appearance in the same manner is not reasonable. Intuitively, we want to update
    the parameters associated with low appearance frequency features and the others
    with smaller steps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Saddle points and plateau**: The loss functions that are used to train neural
    networks are a function of a huge number of parameters and thus are non-convex
    functions. During the optimization process, it is possible to run into saddle
    points (points in which the value of the function increases along one dimension,
    but decreases along other dimensions) or plateaus (locally constant regions of
    the loss surface).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In these cases, the gradient is almost zero along every dimension, and so the
    direction that's pointed to by the anti-gradient is nearly 0\. This means we are
    stuck, and the optimization process can't go on. We have been fooled by the constant
    value that was assumed by the loss function during several training steps; we
    think we have found a good minimum, but in reality, we are stuck inside a meaningless
    region of the solution space.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent optimization algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Several optimization algorithms have been developed to improve the efficiency
    of vanilla optimization. In the upcoming sections, we will recap on vanilla optimization
    and show the two most common optimization algorithms: momentum and ADAM. The former
    will be discussed because it shows how a physical interpretation of the loss surface
    can lead to successful results, while the latter will be discussed because it
    is the most widely adaptive optimization method that''s used.'
  prefs: []
  type: TYPE_NORMAL
- en: Vanilla
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we saw previously, the update formula only requires an estimation of the
    direction, which it gets by using the anti-gradient and the learning rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3109de1-4053-4766-8911-7b7452387ed1.png)'
  prefs: []
  type: TYPE_IMG
- en: Momentum
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The momentum optimization algorithm is based on a physical interpretation of
    the loss surface. Let's think about the loss surface as a messy landscape where
    a particle is moving around, with the aim of finding the global minimum.
  prefs: []
  type: TYPE_NORMAL
- en: The vanilla algorithm updates the position of the particle as a function of
    the direction that was found by calculating the anti-gradient, making the particle
    jump from one position to another without any physical meaning. This can be seen
    as an unstable system rich in energy.
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea that was introduced in the momentum algorithm is to update the
    model parameters by considering the interaction between the surface and the particle,
    just like you would in a physical system.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, a system that teleports a particle from one point to a new
    point in zero time and without loss of energy does not exist. The initial energy
    of the system is lost due to external forces and because the velocity changes
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, we can use the analogy of an object (the particle) that slides
    over a surface (the loss surface) and is subject to a kinetic friction force that
    reduces its energy and speed over time. In machine learning, we call friction
    coefficient momentum, but in practice, we can reason exactly like we do in physics.
    Hence, given a friction coefficient, ![](img/a2851ec3-fff2-4c9b-aaeb-46744da7521c.png) (a
    hyperparameter with values in the [0,1] range but usually in the [0.9, 0.999]
    range), the update rule of the Momentum algorithm is given by the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a433d5f6-3b77-4117-9181-d718dec9110a.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/0a3a3069-a338-4782-9c96-d2f1aa775173.png) is the vectorial velocity
    of the particle (every component if the vector is the velocity in a particular
    dimension). The analogy of velocity is natural since, in one dimension, the derivative
    of the position with respect to time is the velocity.
  prefs: []
  type: TYPE_NORMAL
- en: This method takes into account the vectorial velocity that's reached by the
    particle at the previous step and reduces it for those components that go in a
    different direction, while increasing it for points that go in the same direction
    for subsequent updates.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this way, the overall energy of the system is reduced, which in turn reduces
    the oscillations and gets faster convergence, as we can see from the following
    diagram, which shows the difference between the vanilla (on the left) and the
    momentum (on the right) optimization algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/614fe9e7-0b9c-4e74-88a8-dcd0d3d0f74d.png)'
  prefs: []
  type: TYPE_IMG
- en: Visual representation of the vanilla (left) and momentum (right) optimization
    algorithms. Momentum causes fewer loss oscillations and reaches the minimum faster.
  prefs: []
  type: TYPE_NORMAL
- en: ADAM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The vanilla and the momentum optimization algorithms consider the ![](img/c7fc9572-6b26-4936-9b82-1a12bd1643d8.png) parameter
    as being constant: the strength of the update (the step size) is the same for
    every parameter in the network; there''s no distinction among parameters associated
    with high or low occurrence features. To face this problem and increase the efficiency
    of the optimization algorithms, a whole set of new algorithms has been developed,
    known as **adaptive learning rate optimization methods**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea behind these algorithms is to associate a different learning rate
    to every parameter of the network and thus update them using a learning rate that
    adapts itself to the type of feature the neuron is specialized to extract (or
    in general, to adapt itself to the different features the neuron sees as input):
    small updates associated with a high frequency of occurrence features, bigger
    otherwise. **Adaptive Moment Estimation** (**ADAM**) wasn''t the first adaptive
    method to be developed, but it is the most commonly used because it outperforms
    almost every other adaptive and non-adaptive algorithm on many different tasks:
    it increases the model''s generalization capabilities while speeding up its convergence.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Being an adaptive method, it creates a learning rate for every parameter in
    the model, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e71fd61d-2aec-4659-8daa-4c1657fb8141.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The algorithm''s authors decided to take into account how the (square of the)
    gradients changes, as well as their variance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dfdb2e60-2894-4f3d-9bf5-5773ed6086ef.png)'
  prefs: []
  type: TYPE_IMG
- en: The first term is the exponential moving average of the gradients (estimation
    of the first-order momentum), while the second term is the exponential moving
    average of the square of the gradients (estimation of the second-order momentum).
    Both ![](img/04814af9-ae83-463b-acdf-2a56da1b6dc7.png) and ![](img/3cd62c43-3e77-4bc8-8204-7c0c7cec70e7.png) are
    vectors with ![](img/ee8135dc-044d-436e-a90d-af3333d49492.png) components, and
    both have been initialized to 0.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e2512472-c9ac-4f41-9914-54c65afce56a.png) and ![](img/3f4b443e-eab4-4386-8620-403ff099e5c0.png) are
    the decaying factors of the exponential moving average and are hyperparameters
    of the algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: The zero initializations of the ![](img/056848f6-156e-44ac-b37e-4fb49ae57c72.png) and ![](img/a6e47090-46d4-4fc5-83bf-e028c5e1a316.png) vectors
    make their value close to 0, especially if the decaying factors are close to 1
    (hence a low decay rate).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a problem since we are estimating values close to zero, and without
    any influence from any possible update rule. To solve this, the authors suggested
    to correct the first and second-order momentums by computing them in the following
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b927b51-ccdf-40de-899c-476d3f6ce1ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, they suggested an update rule that was inspired by other adaptive
    algorithms (Adadelta and RMSProp, which are not explained in this book):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1662318-f34e-4fd1-8095-4fd508488548.png)'
  prefs: []
  type: TYPE_IMG
- en: They suggested that we use decaying rates close to 1 and a very small value
    for the epsilon parameter (it's only there to avoid divisions by zero).
  prefs: []
  type: TYPE_NORMAL
- en: Why should using the first and second-order moment estimation and this update
    rule to update every single parameter of the network improve the model's speed
    convergence and improve the generalization capabilities of the model?
  prefs: []
  type: TYPE_NORMAL
- en: The effective learning rate, ![](img/e55675c7-89ab-4d5a-842b-4e7ac2d62027.png),
    adapts itself during training for every single parameter and takes the frequency
    of occurrence of the input features for every neuron into account. The denominator
    will increase if the computed partial derivatives associated with the current
    parameter are different from zero, such as if the input feature associated with
    that neuron occurs frequently. The higher the occurrence frequency, the smaller
    the update steps becomes during training.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, the partial derivatives are almost zero every time, the update
    steps are almost constant and never change their size during training.
  prefs: []
  type: TYPE_NORMAL
- en: Every gradient descent optimization algorithm that we've presented thus far
    requires that we compute the gradient of the loss function. Since neural networks
    can approximate any function and their topology can be very complex, how can we
    compute the gradient of a complex function efficiently? Representing the computation
    using data flow graphs and the backpropagation algorithm is the solution.
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation and automatic differentiation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computing partial derivatives is a process that's repeated thousands upon thousands
    of times while training a neural network and for this reason, this process must
    be as efficient as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous sections, we showed you how, by using a loss function, is it
    possible to create a bond between the model''s output, the input, and the label.
    If we represent the whole neural network architecture using a graph, it''s easy
    to see how, given an input instance, we are just performing a mathematical operation
    (input multiplied by a parameter, adding those multiplication results, and applying
    the non-linearity function to the sum) in an ordinate manner. At the input of
    this graph, we have the input samples from the dataset. The output nodes of the
    graph are the predictions; the graph can be seen as a set of compound functions
    of the type:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/40ed459e-d6d6-4ce6-bba4-33cb8dfdaa1d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The output of a neuron with two inputs, ![](img/d1f9677a-f85f-4ae5-9c01-479169f35aa4.png) and
    ![](img/f2207421-d662-4328-8211-5c93b6445f3c.png), that uses the ReLU activation
    function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c8e664a-cc1b-4ee8-8406-d27969c1f4c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The functions that are used in the previous equations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/545dc695-bfba-4e29-9f85-173a3109fdc3.png) is the product function of
    an input for a parameter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/6ccab198-d7d3-4f7c-9529-8d994a2993c2.png) is the sum function of two
    values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3ee445bc-073b-4e55-9224-32842ad10fd8.png) is the rectified linear unit
    activation function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hence, we can represent the output neuron as a composition of these functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/173342e1-c695-4e41-8625-3cccac226f70.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Keep in mind that the variables are not the input values of the functions,
    but the model parameters ![](img/69090582-e723-4b1f-9841-d2f4c95c7484.png). We
    are interested in computing the partial derivatives of the loss function in order
    to train the network. We do this using the gradient descent algorithm. As a simple
    example, we can just consider a simple loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/974b9d87-bb4b-4144-95f0-27453fa5d2ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To compute the loss gradient with respect to the variables (![](img/7afc4997-4f59-4c23-92dd-825d86f6975c.png)),
    it is possible to apply the chain rule (the rule of the derivatives of compound
    functions):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b903714-fdfe-4978-bf9e-ed2e70f79be2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the Leibniz notation, it is easier to see how the chain rule can be applied
    to compute the partial derivatives of any differentiable function, which is represented
    as a graph (and thus represented as a set of compound functions):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28203b41-9d23-4285-9d9e-99163c6301ec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the end, it is just a matter of expressing the operations as compound functions,
    and using a graph is a natural way to do this. We can associate a graph node with
    a function: its inputs are the function inputs; the node performs the function
    computation and outputs the result. Moreover, a node can have attributes, such
    as a formula to apply when calculating the partial derivative with respect to
    its inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, a graph can be traversed in both directions. We can traverse it in
    the forward direction (forward pass of the backpropagation algorithm), and thus
    compute the loss value. We can also traverse it in the backward direction, applying
    the formula of the derivative of the output with respect to the input associated
    with every node and multiplying the value coming from the previous node with the
    current to compute the partial derivative. This is the application of the chain
    rule.
  prefs: []
  type: TYPE_NORMAL
- en: Representing computations as graphs allow us to perform automatic differentiation
    by computing the gradient of complex functions. We only consider operations singularly,
    and just look at the node's inputs and outputs.
  prefs: []
  type: TYPE_NORMAL
- en: There are two different ways of applying the chain rule on a graph – forward
    and backward mode. A detailed explanation of the automatic differentiation in
    both forward and backward mode is beyond the scope of this book; however, in upcoming
    chapters, we will see how TensorFlow implements automatic differentiation in backward
    mode and how it applies the chain rule to compute the loss value and then traverse
    the graph in a backward fashion ![](img/da51f7dc-33d2-4d02-9bbf-e4d33d34bfd9.png) times.
    Automatic differentiation in backward mode depends on the input cardinality and
    not on the number of parameters of the network, compared to implementing it in
    forwarding mode (it's now easy to imagine why TensorFlow implements automatic
    differentiation in backward mode; neural networks can have millions of parameters).
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we''ve described optimization algorithms and strategies that can be
    applied to compute the loss function so that it fits the training data. We do
    this by using a generic function that''s been approximated by our neural network.
    In practice, we only introduced one neural network architecture: the fully connected
    architecture. However, there are several different neural network architectures
    that can be applied to solve different problems, depending on the dataset type.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the strengths of neural networks is their ability to be able to perform
    different tasks, depending on the neuron topology that's used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fully connected configuration is a global view on the input—every neuron
    sees everything. However, there are certain types of data that do not require
    a complete view to be correctly used by a neural network, or that are computationally
    intractable with a fully connected configuration. Think about a high-resolution
    image with millions of pixels; we have to connect every neuron to every single
    pixel, creating a network with a number of parameters equal to the number of pixels
    times the number of neurons: a network with only two neurons will lead to [![](img/5a2a2927-7a40-46f2-ac81-728913b0e5ba.png)] parameters—that
    is completely intractable!'
  prefs: []
  type: TYPE_NORMAL
- en: The architecture that's been developed to work with images, and maybe the most
    important neuronal layer that's been developed in the past years, is the convolutional
    neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Convolutional Neural Networks** (**CNNs**) are the fundamental building blocks
    of modern computer vision, speech recognition, and even natural language processing
    applications. In this section, we are going to describe the convolution operator,
    how it is used in the signal analysis domain, and how convolution is used in machine
    learning.'
  prefs: []
  type: TYPE_NORMAL
- en: The convolution operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Signal theory gives us all the tools we need to properly understand the convolution
    operation: why it is so widely used in many different domains and why CNNs are
    so powerful. The convolution operation is used to study the response of certain
    physical systems when a signal is applied to their input. Different input stimuli
    can make a system, *S*, produce a different output, and the behavior of a system
    can be modeled using the convolution operation.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's start from the one-dimensional case by introducing the concept of the **Linear
    Time-Invariant** (**LTI**) system.
  prefs: []
  type: TYPE_NORMAL
- en: 'A system, *S*, that accepts an input signal and produces an output signal, ![](img/fddf2624-e066-4e73-99ea-5cac2ac7559a.png),
    is an LTI system if the following properties hold:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linearity**: ![](img/9aad29ea-c241-4282-a0a8-5fa019acfc75.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time invariance**:** ![](img/cb68d1a7-4a82-4132-90f9-88cfd0bd2d59.png)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Is it possible to analyze the behavior of an LTI system by analyzing its response
    to the Dirac Delta function, δ(t). δ(t) is a function with a value of zero in
    every point of its domain, except in ![](img/a7944924-1073-48ec-8c6b-c738690a2b37.png).
    In ![](img/8509f617-d95d-429c-b9fa-00b13a3a2cda.png), it assumes a value that
    makes its definition true:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f04b13a9-d157-4643-90d0-a1917bbd6961.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Intuitively, applying δ(t) to a function, φ(t), means sample the φ(t) in 0\.
    Hence, if we put δ(t) as the input of a system, *S*, we get its response to a
    unitary impulse centered on zero. The system output when the input is the Dirac
    Delta function is called the system impulse response, and is noted with the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d22c5c09-6adc-4339-8e02-08a6ceac1d0d.png)'
  prefs: []
  type: TYPE_IMG
- en: The system impulse response is of fundamental importance since it allows us
    to compute the response of an LTI system to any input.
  prefs: []
  type: TYPE_NORMAL
- en: 'A generic signal, *x(t)*, can be seen as the sum of the value it assumes on
    every instant, *t*. This can be modeled as the application of δ(t) that''s translated
    in every point of the *x* domain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c557149-3270-4106-ac6e-779476a177a7.png)'
  prefs: []
  type: TYPE_IMG
- en: This formula is the definition of convolution among two signals.
  prefs: []
  type: TYPE_NORMAL
- en: So, why is the convolution operation important for the study of LTI systems?
  prefs: []
  type: TYPE_NORMAL
- en: 'Given *x(t)* as a generic input signal and *h(t)* as the impulse response of
    an LTI system, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86a0aff0-a8b6-4c20-b30f-d304290e08af.png)'
  prefs: []
  type: TYPE_IMG
- en: The result of the convolution represents the behavior of the LTI system that's
    modeled by its impulse response, *h(t)*, when *x(t)* is its input. This is an
    important result since it shows us how the impulse response completely characterizes
    the system and how the convolution operation can be used to analyze the output
    of an LTI system when given any input signal.
  prefs: []
  type: TYPE_NORMAL
- en: The convolution operation is commutative and the result of the operation is
    a function (a signal).
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we''ve only considered the continuous case, but there''s a natural
    generalization on the discrete domain. If ![](img/b4bdd466-10c1-410d-bed3-9878b3d6eed8.png)
    and ![](img/79ef65c0-fdd6-4c59-915c-aaa424f1c1e3.png) are defined on ![](img/f25a2724-cd2b-46c9-98fe-31b0ba0d6db3.png),
    the convolution is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a67c9c0-107b-4ef7-ba03-8a5846dd779d.png)'
  prefs: []
  type: TYPE_IMG
- en: 2D convolution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The generalization of the 1D convolution we''ve introduced in terms of the
    2D case is natural. Images, in particular, can be seen as 2D discrete signals.
    In the 2D case, the counterpart of the Dirac Delta function is the Kronecker Delta
    function, and it can be expressed independently from the dimensionality of the
    space it is used in. It''s seen as a tensor, δ, with components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d7511bf-bc0d-4aad-af0e-9f18c591c32c.png)'
  prefs: []
  type: TYPE_IMG
- en: Images can be thought as 2D versions of LTI systems. In this case, we are talking
    about **Linear Space-Invariant** (**LSI**) systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the bi-dimensional discrete case, the convolution operation is defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b018f87c-2eed-4f71-b9e1-296ddccd3d9e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Images are finite dimension signals with a well-defined spatial extent. This
    means that the previously introduced formula becomes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/61bcc68e-9af0-4468-94a9-e919c41fb19a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db207dad-9299-4a07-8d20-8fbe4dff1c48.png) is the input image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3e983129-600b-4904-a5aa-9c3f107ea69e.png) is the convolutional filter
    (also called the kernel) itself and ![](img/60df3516-8d34-4750-9402-3dc8fa95cf63.png) is
    its side'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/63514cb4-bf69-4077-9c2f-65eefa156bc9.png)is the output pixel, in the ![](img/a4367dd5-d676-43a4-bd56-ac5183ac20b3.png) position'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The operation that we''ve described is performed for every *(i,j)* position
    of the input image that has a complete overlap with the convolutional filter,
    as it slides over the input image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b73289d2-6c28-4abf-a4d9-80f5b6aacce0.png)'
  prefs: []
  type: TYPE_IMG
- en: The convolution operation between the input image (on the left) and the convolution
    kernel produces the feature map on the right
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding diagram, different convolutional filters extract different
    features from the input image. In fact, in the preceding diagram, we can see how
    that rectangular filter (Sobel filter) is able to extract the edges of the input
    image. Convolving an image with a different convolutional filter means having
    to extract different input features that the kernel can capture. Before the introduction
    of convolutional neural networks, as we will see in the next section, we would
    had to manually design convolutional kernels that were able to extract the features
    needed that were to solve the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: There are two additional parameters that aren't shown in the preceding formula
    that control how the convolution operation is performed. These parameters are
    the horizontal and vertical stride; they tell the operation how many pixels to
    skip when we move the kernel over the input image over the horizontal and vertical
    directions. Usually, the horizontal and vertical strides are equal, and they are
    noted with the letter S.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the input image has side ![](img/80e97c32-8975-4de7-81ac-fafe3b917468.png),
    then the resolution of the output signal resulting from the convolution with a
    kernel of size *k* can be computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8371c927-70bc-4fd4-ab37-073cbad71ede.png)'
  prefs: []
  type: TYPE_IMG
- en: 2D convolutions among volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've only considered the case of a grayscale image, that is, an image
    with a single channel. The images we are used to seeing in real life are all RGB
    images, which are images with three color channels. The convolution operation
    also works well when the input image has more than one channel; in fact, its definition
    has been slightly changed in order to make the convolution operation span every
    channel.
  prefs: []
  type: TYPE_NORMAL
- en: This extended version requires the convolution filter to have the same number
    of channels as the input image; in short, if the input image has three channels,
    the convolutional kernel must have three channels too. This way, we are treating
    images as stacks of 2D signals; we call these volumes.
  prefs: []
  type: TYPE_NORMAL
- en: As a volume, every image (or convolutional kernel) is identified by the triple
    (W, H, D), where W, H, and D are the width, height, and depth, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'By considering images and kernels as volumes, we can treat them as unordered
    sets. In fact, the order (RGB, BGR) of the channels only changes how the software
    interprets the data, while the content remains the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9634856-f0df-4107-a316-d797f326060e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This reasoning allows us to extend the previous formula, thereby making it
    take the input depth into account:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8dc9046b-f480-4014-8808-36a8d9ba40e9.png)'
  prefs: []
  type: TYPE_IMG
- en: The result of this convolution operation is called a feature map. Even though
    the convolution is performed among volumes, the output is a feature map with unitary
    depth since the convolution operation sums the feature maps that have been produced
    to take into account all the information of the pixels that share the same spatial
    (x,y) location. In fact, summing the resulting D feature maps is a way to treat a
    set of 2D convolutions as a single 2D convolution.
  prefs: []
  type: TYPE_NORMAL
- en: This means that every single position of the resulting activation map, *O*,
    contains the information that was captured from the same input location through
    its complete depth. This is the intuitive idea behind the convolution operation.
  prefs: []
  type: TYPE_NORMAL
- en: Alright; we now have a grasp of the convolution operation in 1 and two spatial
    dimensions; we also introduced the concept of convolutional kernel highlighting
    whereby defining the kernel value is a manual operation where different kernels
    can extract different features from the input image/volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of kernel definition is pure engineering, and defining them is
    not easy: different tasks can require different kernels; some of them have never
    been defined, and most of them can be simply impossible to design since certain
    features can only be extracted by processing a processed signal, which means we
    would have to apply the convolution operation on the result of another convolution
    operation (a cascade of convolution operations).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Convolutional neural networks solve this problem: instead of manually defining
    the convolutional kernels, we can just define convolutional kernels made of neurons.'
  prefs: []
  type: TYPE_NORMAL
- en: We can extract features from the input volume by convolving it with multiple
    volumes of filters and combining them while considering the feature maps that
    extract new input for a new convolutional layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deeper the network becomes, the more abstract the extracted feature becomes.
    One of the greatest strengths of CNNs is their ability to combine features that
    have been extracted, ranging from raw, basic features that were extracted by the
    first convolutional layers to high-level abstract features that were extracted
    by the last layers and learned as a combination of the low-level features that
    were extracted by the other layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15c9bc11-2a4e-426e-a274-c813b1901dcd.png)'
  prefs: []
  type: TYPE_IMG
- en: CNNs learn to extract low-level features in the first layers; as the networks
    become deeper, the abstraction level of the extracted features increases. Image
    from Zeiler and Fergus, 2013.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of convolutional layers with respect to fully connected layers
    is their local-view nature.
  prefs: []
  type: TYPE_NORMAL
- en: To process an image, a fully connected layer has to linearize the input image
    and create a connection from every pixel value to every neuron of the layer. The
    memory requirements are huge, and making every neuron see the whole input isn't
    the ideal way to extract meaningful features.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are certain features that, due to their nature, are not global like the
    ones that are captured by a fully connected layer. Instead, they are local. For
    example, the edges of an object are local features to a certain input region,
    not the whole image. Therefore, CNNs can learn to extract only local features
    and combine them in the following layers. Another advantage of convolutional architectures
    is their low number of parameters: they don''t need to see (and thus create connections)
    the whole input; they only need to have a view of their local receptive field.
    Convolution operations requires fewer parameters to extract meaningful feature
    maps, all of which capture the local features of the input volume.'
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are usually used with another layer, known as the pooling layer. Without
    digging too much into the details of this operation (it tends to be avoided in
    today's architectures), we can just think about it as an operation with the same
    structure as the convolution operation (hence a window that moves in the horizontal
    and vertical direction of the input) but without a learnable kernel. In every
    region of the input, a non-learnable function is applied. The aim of this operation
    is to reduce the size of the feature maps that are produced by a convolution operation
    in order to reduce the number of parameters of the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'So that we have an idea of what the common convolutional neural network architecture
    looks like, the following diagram presents the LeNet 5 architecture that uses
    a convolutional layer, max-pooling (a pooling operation where the non-learnable
    function is the max operation over the window), and fully connected layers with
    the aim of classifying images of handwritten digits in 10 classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c66bb426-c824-4e25-bd3a-f95e53bb6147.png)'
  prefs: []
  type: TYPE_IMG
- en: 'LeNet 5 architecture – each plane is a feature map. Source: Gradient-Based
    Learning Applied to Document Recognition, Yann LeCun at al—1998'
  prefs: []
  type: TYPE_NORMAL
- en: Defining network architectures such as LeNet 5 is an art – there are no precise
    rules on the number of layers you can use, the number of convolutional filters
    to learn, or the number of neurons in the fully connected layers. Moreover, even
    picking the right activation function for the hidden layer is another hyperparameter
    to search for. Complex models are not only rich in terms of learnable parameters,
    but also rich in terms of hyperparameters to tune, making the definition of deep
    architectures non-trivial and challenging.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutions among volumes allow us to do fancy things such as replace every
    fully connected layer with a 1 x 1 x D convolutional layer and use a 1 x 1 x D
    convolution inside the network to reduce the dimensionality of the input.
  prefs: []
  type: TYPE_NORMAL
- en: 1 x 1 x D convolutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](img/a17c5c54-a4e3-4ba9-ba02-982cc9de6279.png) convolutions are important
    building blocks of state-of-the-art models because they can be used for different
    goals.'
  prefs: []
  type: TYPE_NORMAL
- en: One goal is the use them as a dimensionality reduction technique. Let's understand
    this by going through an example.
  prefs: []
  type: TYPE_NORMAL
- en: If the convolution operation is applied to an input volume of ![](img/f4d95ccf-5747-4e0b-8f50-8fc3ca4eb3ef.png)
    and it is convolved with a set of ![](img/a8512514-2b3d-43f7-8829-10aed76735cc.png)
    filters, each one being ![](img/2696cd65-26ca-4860-bc34-741a5e6a5cf9.png) in size,
    the number of features is reduced from 512 to ![](img/741dd8e9-80e5-4610-a8a6-7769d32a5ea7.png).
    The output volume now has a shape of ![](img/62854add-6e95-40c1-a316-a9ba6e08a489.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'A ![](img/a17c5c54-a4e3-4ba9-ba02-982cc9de6279.png) convolution is also equivalent
    to a fully connected layer. The main difference lies in the nature of the convolution
    operator and the architectural structure of the fully connected layer: while the
    latter requires the input to have a fixed size, the former accepts every volume
    with a spatial extent greater than or equal to![](img/fb51544f-def0-408d-90f3-c2f30f12a92c.png) as
    input. A ![](img/583a75a4-89fe-4dee-933c-49a54a4111b7.png) convolution can therefore
    substitute any fully connected layer because of this equivalence.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the ![](img/09084700-e4d3-441f-ada9-d1696ab3e2e4.png) convolutions
    not only reduce the features in the input to the next layer but also introduce
    new parameters and new non-linearity into the network that could help increase
    the model's accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: When a ![](img/6a28df78-051d-47f5-80d7-98940333115d.png) convolution is placed
    at the end of a classification network, it acts exactly like a fully connected
    layer, but instead of thinking about it as a dimensionality reduction technique,
    it's more intuitive to think about it as a layer that will output a tensor with
    a shape of ![](img/139f5c3a-ae49-4e6e-b7a6-826f91453690.png). The spatial extent
    of the output tensor (identified by W and H) is dynamic and is determined by the
    locations of the input image that the network analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: If the network has been defined with an input of 200 x 200 x 3 and we give it
    an image with this size as input, the output will be a map with ![](img/b5135bd2-7d73-4628-a087-69cc2ce2241b.png)
    and ![](img/b2f3fa0e-99ca-4682-8263-47b7d2e77e70.png). However, if the input image
    has a spatial extent greater than ![](img/68dd81b4-620a-4db0-a698-8cf7be4d6ff0.png),
    then the convolutional network will analyze different locations of the input image
    (just like a standard convolution does, since it's not possible to consider the
    whole convolutional architecture as a convolution operation with its own kernel
    side and stride parameters) and will produce a tensor with ![](img/b431996f-3149-42b6-83d2-e24390645ef7.png)
    and ![](img/50c37809-537b-4428-bbd0-d6739caf3158.png). This is not possible with
    a fully connected layer that constrains the network to accept a fixed-size input
    and produce a fixed-size output.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/441b5a58-8d8a-4a9e-a518-d4b64f64ccad.png) convolutions are also the
    fundamental building blocks of semantic segmentation networks, as we will see
    in the upcoming chapters.'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional, pooling, and fully connected layers are the building blocks of
    almost every neural network architecture that's used nowadays to solve computer
    vision tasks such as image classification, object detection, semantic segmentation,
    image generation, and many others!
  prefs: []
  type: TYPE_NORMAL
- en: We will implement all of these neural network architectures using TensorFlow
    2.0 in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Although CNNs have a reduced number of parameters, even this model can suffer
    from the problem of overfitting when used in a deep configuration (a stack of
    convolutional layers).
  prefs: []
  type: TYPE_NORMAL
- en: Hence, another fundamental topic any ML practitioner should be aware of is regularization.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regularization is a way to deal with the problem of overfitting: the goal of
    regularization is to modify the learning algorithm, or the model itself, to make
    the model perform well—not just on the training data, but also on new inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most widely used solutions to the overfitting problem—and probably
    one of the most simple to understand and analyze—is known as **dropout**.
  prefs: []
  type: TYPE_NORMAL
- en: Dropout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The idea of dropout is to train an ensemble of neural networks and average the
    results instead of training only a single standard network. Dropout builds new
    neural networks, starting from a standard neural network, by dropping out neurons
    with ![](img/6e9b401e-2a38-422f-b6b8-4c4d06475673.png) probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a neuron is dropped out, its output is set to zero. This is shown in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5a3e4ba-804f-4bb5-aa91-1769ceb28f2b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On the left, a standard fully connected architecture. On the right, a possible
    network architecture that''s been obtained by dropping out neurons, which means
    it used dropout during the training phase. Source: Dropout: A simple way to Prevent
    Neural Networks from Overfitting - N. Srivastava—2014'
  prefs: []
  type: TYPE_NORMAL
- en: The dropped neurons do not contribute to the training phase. Since neurons are
    dropped randomly at each new training iteration, using dropout makes the training
    phase different every time. In fact, using dropout means that every training step
    is performed on a new network—and even better, a network with a different topology.
  prefs: []
  type: TYPE_NORMAL
- en: 'N. Srivastava et al. in *Dropout: A simple way to Prevent Neural Networks from
    Overfitting (the *paper that introduced this regularization technique) explained
    this concept very well:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>"In a standard neural network, the derivative that's received by each parameter
    tells it how it should change, so the final loss function is reduced, given what
    all the other units are doing. Therefore, units may change in a way that they
    fix the mistakes of the other units.</q> This may lead to complex co-adaptations.
    This, in turn, leads to overfitting because these co-adaptations do not generalize
    to unseen data. We hypothesize that, for each hidden unit, dropout prevents co-adaptation
    by making the presence of other hidden units unreliable.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, a hidden unit cannot rely on other specific units to correct its
    mistakes."
  prefs: []
  type: TYPE_NORMAL
- en: Dropout works well in practice because it prevents the co-adaption of neurons
    during the training phase. In the upcoming sections, we will analyze how dropout
    works and how it is implemented.
  prefs: []
  type: TYPE_NORMAL
- en: How dropout works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can analyze how dropout works by looking at its application on a single
    neuron. Let''s say we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c58e518-fe94-4e6a-84d1-2f6a7c08b864.png) as a linear neuron'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/fbbd7bb5-e61d-42bb-a8eb-5805dd1050b4.png) as an activation function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By using these, it is possible to model the application of dropout – in the
    training phase only – as a modification of the activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a39aef6-94c0-4700-a6e8-4c5dbdbe0c41.png)'
  prefs: []
  type: TYPE_IMG
- en: Here,
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/708655cb-6a8c-4fa3-be9b-8dafaa1e374d.png)'
  prefs: []
  type: TYPE_IMG
- en: Is a ![](img/1eb41971-a3f1-4a84-b7a0-9adad3a37fd1.png)-dimensional vector of
    Bernoulli random variables, ![](img/cab4fb0c-9771-43f5-9c00-c146c6d1b89c.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'A Bernoulli random variable has the following probability mass distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae9d177b-578f-4440-b6c8-3ad4776e6568.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/5e33fffd-7b0c-461f-8cbf-feb02b635fe5.png) is the possible outcomes.
    The Bernoulli random variable correctly models the dropout application on a neuron
    since the neuron is turned off with the probability of ![](img/b8b68122-db98-4ed8-a819-97393c50ea2a.png) and
    kept on otherwise. It can be useful to see the application of dropout on the generic
    *i*-th neuron of a fully-connected layer (but the same holds for the application
    on a single neuron of a convolutional layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46bc5ccb-a72c-42ae-b8a2-105927df6069.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/f7f094f4-5367-4d05-9ebc-a0db16b34ad1.png).
  prefs: []
  type: TYPE_NORMAL
- en: During training, a neuron is kept on with probability ![](img/28839481-ee56-4492-9416-b00020fdda79.png).
    Therefore, during the test phase, we have to emulate the behavior of the ensemble
    of networks that were used in the training phase. To do this, we need to scale
    the neuron's output by a factor of ![](img/5cc47d91-61c6-4c8b-b790-b78ccdcb4bdd.png)
    d.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3d37f89-abe1-4b0d-9aea-ecb48f55661f.png)'
  prefs: []
  type: TYPE_IMG
- en: Inverted dropout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A slightly different approach—and the one that's used in practice in almost
    every deep learning framework – is to use inverted dropout. This approach consists
    of scaling the activations during the training phase, with the obvious advantage
    of not having to change the network architecture during the test phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scale factor is the inverse of the keep probability,![](img/0e09929f-15bb-4375-9347-a236fcc47928.png),
    and so we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![](img/f300107d-65f3-4b9c-8596-814671b1644d.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: Inverted dropout is how dropout is implemented in practice because it helps
    us define the model and just change a parameter (the keep/drop probability) to
    train and test on the same model.
  prefs: []
  type: TYPE_NORMAL
- en: Direct dropout, which is the version that was presented in the previous section,
    forces you to modify the network during the test phase because, if you don't multiply
    by ![](img/7831c757-0f28-4927-8ee2-c8d3114b6cbd.png), the neuron will produce
    values that are higher with respect to the one expected by the successive neurons
    (thus the following neurons can saturate or explode). This is why inverted dropout
    is the more common implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Dropout and L2 regularization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dropout is often used with L2 normalization and other parameter constraint techniques,
    but this is not always the case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Normalization helps keep model parameter values low. In this way, a parameter
    can''t grow too much. In brief, the L2 normalization is an additional term to
    the loss, where ![](img/c7924e24-0afd-429a-be70-96b6044340c5.png) is a hyperparameter
    called regularization strength, ![](img/178b99c3-c3e5-4a59-90b3-ee4614ce70ab.png) is
    the model, and ![](img/67310229-1d29-4969-8e5e-c61e2a05b3b7.png) is the error
    function between the real ![](img/9f579730-4561-4fcb-8f58-63013856e698.png) and
    the predicted ![](img/11375194-8a2b-43b3-85bc-f999060f0900.png) value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f15888b1-63ed-4ab7-9fa1-be92c76fefe6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It''s easy to understand that this additional term, when we''re doing back-propagation
    via gradient descent, reduces the update amount. If ![](img/2a9e1749-082f-4022-9843-3626a2515e02.png)
    is the learning rate, the update amount of the parameter ![](img/a69ccf6f-1f31-4683-ac2e-37595c5e3715.png)
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee04dc3e-0b77-4110-b2e5-28d38c70d816.png)'
  prefs: []
  type: TYPE_IMG
- en: Dropout alone does not have any way of preventing parameter values from becoming
    too large during this update phase.
  prefs: []
  type: TYPE_NORMAL
- en: There are two other solutions that are extremely easy to implement that do not
    even require the model to be changed or for the loss to have additional terms.
    These are known as data augmentation and early stopping.
  prefs: []
  type: TYPE_NORMAL
- en: Data augmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data augmentation is a simple way to increase the dataset's size. This is done
    by applying a set of transformations on the train data. Its aim is to make the
    model aware that certain input variations are possible and thus make it perform
    better on a variety of input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The set of transformations highly depends on the dataset itself. Usually, when
    working with an image dataset, the transformations to apply are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Random flip left/right
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random flip up/down
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding random noise to the input image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random brightness variation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random saturation variation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, before applying any of these transformations to our training set,
    we have to ask: *is this transformation meaningful for this data type, for my
    dataset, and for the task at hand?*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just think about the random flip left/right of the input image: if our dataset
    is a dataset of drawn arrows, each labeled with its direction, and we are training
    a model to predict the arrow''s direction, mirroring the image will just break
    our training set.'
  prefs: []
  type: TYPE_NORMAL
- en: Early stopping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we introduced in [Chapter 1](0dff1bba-f231-45fa-9a89-b4f127309579.xhtml), *What
    is Machine Learning?**, *measuring the performance of the model during the training
    phase on both the validation and training sets is a good habit.
  prefs: []
  type: TYPE_NORMAL
- en: This good habit can help us prevent overfitting and save us a lot of training
    time since the measured metrics tell us whether the model is starting to overfit
    the training data and thus if it is time to stop the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Let's think about a classifier—we measure the validation accuracy, the training
    accuracy, and the loss value.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the loss value, we can see that, as the training process goes on,
    the loss decreases. Of course, this is true only for healthy training. Training
    is healthy when the loss trend decreases. It is possible to just observe the fluctuation
    that was introduced by mini-batch gradient descent or the usage of the stochastic
    regularization process (dropout).
  prefs: []
  type: TYPE_NORMAL
- en: If the training process is healthy and the loss trend decreases, the training
    accuracy will increase. Training accuracy measures how well the model learns the
    training set—it does not capture its generalization capabilities. Validation accuracy,
    on the other hand, is the measure of how good the predictions of your model are
    on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: If the model is learning, the validation accuracy increases. If the model is
    overfitting, the validation accuracy stops increasing and can even start to decrease,
    while the accuracy measured on the training set reaches the maximum value.
  prefs: []
  type: TYPE_NORMAL
- en: If you stop training the model as soon as the validation accuracy (or whatever
    the monitored metric is) stops increasing, then you are facing the overfitting
    problem easily and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Data augmentation and early stopping are two ways of reducing overfitting without
    changing the model's architecture.
  prefs: []
  type: TYPE_NORMAL
- en: However, similar to dropout, there is another common regularization technique,
    known as batch normalization, that requires that we change the model architecture
    that we use. This helps speed up the training process and lets us achieve better
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Batch normalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Batch normalization is not only a regularization technique—it is also a good
    way to speed up the training process. To increase the stability of the learning
    process, and thus reduce the oscillation of the loss function, batch normalization
    normalizes the output of a layer by subtracting the batch mean and dividing it
    by the batch standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: 'After this normalization, which is not a learned process, batch normalization
    adds two trainable parameters: the standard deviation parameter (gamma) and the
    mean parameter (beta).'
  prefs: []
  type: TYPE_NORMAL
- en: Batch normalization not only helps speed up convergence by reducing the training
    oscillations, it also helps in reducing overfitting since it introduces stochasticity
    in the training process in a way that's similar to dropout. The difference is
    that, while dropout adds noise in an explicit manner, batch normalization introduces
    stochasticity by computing the mean and the variance over the batch.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image, which was taken from the original paper, *Batch Normalization
    – Accelerating Deep Network Training*, by Reducing Internal Covariate Shift (Ioffe
    et al. 2015), shows the algorithm that''s applied during the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/42174206-4adb-457d-9c54-396c7322aeca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The batch normalization algorithm. Source: *Batch Normalization – Accelerating
    Deep Network Training by Reducing Internal Covariate Shift*, Ioffe et al. 2015'
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the training process, it is required that you apply the same affine
    transformation that was learned during the training process. However, instead
    of computing the mean and the variance over the input batch, the mean and the
    variance that accumulated during the training process are used. In fact, batch
    normalization, just like dropout, has a different behavior during the training
    and inference phases. During the training phase, it computes the mean and variance
    over the current input batch, while it accumulates the moving mean and variance
    use during the inference phase.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, since this is a very common operation, TensorFlow has a BatchNormalization
    layer ready to use, so we don't have to worry about the accumulation of statistics
    during the training and having to change the layer's behavior during the inference
    phase.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is probably the most theory intensive of this whole book; however,
    it is required that you have at least an intuitive idea of the building blocks
    of neural networks and of the various algorithms that are used in machine learning
    so that you can start developing a meaningful understanding of what's going on.
  prefs: []
  type: TYPE_NORMAL
- en: We have looked at what a neural network is, what it means to train it, and how
    to perform a parameter update with some of the most common update strategies.
    You should now have a basic understanding of how the chain rule can be applied
    in order to compute the gradient of a function efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: We haven't explicitly talked about deep learning, but in practice, that is what
    we did; keep in mind that stacking layers of neural networks is like stacking
    different classifiers that combine their expressive power. We indicated this with
    the term deep learning. In practice, we can say that deep neural networks (a deep
    learning model) are just neural networks with more than one hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, we introduced a lot of important concepts about parametric
    model training, the origin of neural networks, as well as their mathematical formulation.
    It is of extreme importance to have at least an intuitive idea of what happens
    when we define a fully connected (among others) layer when we define the loss
    and use a certain optimization strategy to train a model using a machine learning
    framework such as TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow hides the complexity of everything we've described in this chapter,
    but having an understanding of what happens under the hood will allow you to debug
    a model just by looking at its behavior. You will also have an idea of why certain
    things happen during the training phase and how to solve certain problems. For
    instance, knowledge of optimization strategies will help you understand why your
    loss function value follows a certain trend and assumes certain values during
    the training phase, and will give you an idea of how to choose the right hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [Chapter 3](f62be9d4-c8e0-4590-8299-2fdad139830f.xhtml), *TensorFlow
    Graph Architecture*, we will see how all the theoretical concepts presented in
    this chapter, using the graph representation of the computation, can be effectively
    implemented in TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter was filled with various theoretical concepts to understand so,
    just like the previous chapter, don''t skip the exercises:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the similarities between artificial and biological neurons?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does the neuron's topology change the neural network's behavior?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do neurons require a non-linear activation function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the activation function is linear, a multi-layer neural network is the same
    as a single layer neural network. Why?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is an error in input data treated by a neural network?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the mathematical formulation of a generic neuron.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the mathematical formulation of a fully connected layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can a multi-layer configuration solve problems with non-linearly separable
    solutions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the graph of the sigmoid, tanh, and ReLu activation functions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it always required to format training set labels into a one-hot encoded representation?
    What if the task is regression?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The loss function creates a bond between the desired outcome and the model
    output: why is this required for the loss function to be differentiable?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the gradient of the loss function indicate? What about the anti-gradient?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a parameter update rule? Explain the vanilla update rule.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the mini-batch gradient descent algorithm and explain the three possible
    scenarios.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is random perturbation a good update strategy? Explain the pros and cons of
    this approach.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the difference between a non-adaptive and adaptive optimization algorithm?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the relationship between the concept of velocity and momentum update?
    Describe the momentum update algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an LTI system? How is it related to the convolution operation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a feature vector?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are CNNs feature extractors? If yes, can a fully connected layer be used to
    classify the output of a convolutional layer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the guidelines for model parameter initialization? Is assigning a constant
    value of 10 to every parameter of the network a good initialization strategy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the differences between direct and inverted dropout? Why does TensorFlow
    implement the inverted version?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is the L2 normalization of network parameters useful when using dropout?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Write the formula of convolution among volumes: show how it behaves in the
    case of a 1 x 1 x D convolutional kernel. Why is there an equivalence between
    the fully connected layer and a 1 x 1 x D convolution?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If, while training a classifier, the validation accuracy stops increasing, what
    does this mean? Can adding dropout or increasing the drop probability if dropout layers
    are already present make the network improve the validation accuracy again? Why
    or why not?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
