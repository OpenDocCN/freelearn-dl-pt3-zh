["```\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nimport PIL.Image as Image\nclassifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\" #@param {type:\"string\"}\nIMAGE_SHAPE = (224, 224)\n# wrap the hub to work with tf.keras\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n])\ngrace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\ngrace_hopper = Image.open(grace_hopper).resize(IMAGE_SHAPE)\ngrace_hopper = np.array(grace_hopper)/255.0\nresult = classifier.predict(grace_hopper[np.newaxis, ...])\npredicted_class = np.argmax(result[0], axis=-1)\nprint (predicted_class) \n```", "```\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n# IMAGE\n#\n# Define CNN for visual processing\ncnn_model = models.Sequential()\ncnn_model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', \n        input_shape=(224, 224, 3)))\ncnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D(2, 2))\ncnn_model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D(2, 2))\ncnn_model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\ncnn_model.add(layers.Conv2D(256, (3, 3), activation='relu'))\ncnn_model.add(layers.Conv2D(256, (3, 3), activation='relu'))\ncnn_model.add(layers.MaxPooling2D(2, 2))\ncnn_model.add(layers.Flatten())\ncnn_model.summary()\n#define the visual_model with proper input\nimage_input = layers.Input(shape=(224, 224, 3))\nvisual_model = cnn_model(image_input) \n```", "```\n# TEXT\n#\n#define the RNN model for text processing\nquestion_input = layers.Input(shape=(100,), dtype='int32')\nemdedding = layers.Embedding(input_dim=10000, output_dim=256, \n    input_length=100)(question_input)\nencoded_question = layers.LSTM(256)(emdedding) \n```", "```\n# combine the encoded question and visual model\nmerged = layers.concatenate([encoded_question, visual_model])\n#attach a dense network at the end\noutput = layers.Dense(1000, activation='softmax')(merged)\n#get the combined model\nvqa_model = models.Model(inputs=[image_input, question_input], outputs=output)\nvqa_model.summary() \n```", "```\n# Download an image and read it into a NumPy array, \ndef download(url):\n  name = url.split(\"/\")[-1]\n  image_path = tf.keras.utils.get_file(name, origin=url)\n  img = image.load_img(image_path)\n  return image.img_to_array(img)\n# Scale pixels to between (-1.0 and 1.0)\ndef preprocess(img):\n  return (img / 127.5) - 1\n\n# Undo the preprocessing above\ndef deprocess(img):\n  img = img.copy()\n  img /= 2.\n  img += 0.5\n  img *= 255.\n  return np.clip(img, 0, 255).astype('uint8')\n# Display an image\ndef show(img):\n  plt.figure(figsize=(12,12))\n  plt.grid(False)\n  plt.axis('off')\n  plt.imshow(img)\n# https://commons.wikimedia.org/wiki/File:Flickr_-_Nicholas_T_-_Big_Sky_(1).jpg\nurl = 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Flickr_-_Nicholas_T_-_Big_Sky_%281%29.jpg/747px-Flickr_-_Nicholas_T_-_Big_Sky_%281%29.jpg'\nimg = preprocess(download(url))\nshow(deprocess(img)) \n```", "```\n# We'll maximize the activations of these layers\nnames = ['mixed2', 'mixed3', 'mixed4', 'mixed5']\nlayers = [inception_v3.get_layer(name).output for name in names]\n# Create our feature extraction model\nfeat_extraction_model = tf.keras.Model(inputs=inception_v3.input, outputs=layers)\ndef forward(img):\n\n  # Create a batch\n  img_batch = tf.expand_dims(img, axis=0)\n\n  # Forward the image through Inception, extract activations\n  # for the layers we selected above\n  return feat_extraction_model(img_batch) \n```", "```\ndef calc_loss(layer_activations):\n\n  total_loss = 0\n\n  for act in layer_activations:\n\n    # In gradient ascent, we'll want to maximize this value\n    # so our image increasingly \"excites\" the layer\n    loss = tf.math.reduce_mean(act)\n    # Normalize by the number of units in the layer\n    loss /= np.prod(act.shape)\n    total_loss += loss\n  return total_loss \n```", "```\nimg = tf.Variable(img)\nsteps = 400\nfor step in range(steps):\n\n  with tf.GradientTape() as tape:\n    activations = forward(img)\n    loss = calc_loss(activations)\n\n  gradients = tape.gradient(loss, img)\n  # Normalize the gradients\n  gradients /= gradients.numpy().std() + 1e-8 \n\n  # Update our image by directly adding the gradients\n  img.assign_add(gradients)\n\n  if step % 50 == 0:\n    clear_output()\n    print (\"Step %d, loss %f\" % (step, loss))\n    show(deprocess(img.numpy()))\n    plt.show()\n# Let's see the result\nclear_output()\nshow(deprocess(img.numpy())) \n```", "```\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models, preprocessing\nimport tensorflow_datasets as tfds\nmax_len = 200\nn_words = 10000\ndim_embedding = 256\nEPOCHS = 20\nBATCH_SIZE =500\ndef load_data():\n    #load data\n    (X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n    # Pad sequences with max_len\n    X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n    X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n    return (X_train, y_train), (X_test, y_test) \n```", "```\ndef build_model():\n    model = models.Sequential()\n    #Input - Embedding Layer\n    # the model will take as input an integer matrix of size (batch, input_length)\n    # the model will output dimension (input_length, dim_embedding)\n    # the largest integer in the input should be no larger\n    # than n_words (vocabulary size).\n    model.add(layers.Embedding(n_words,\n        dim_embedding, input_length=max_len))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv1D(256, 3, padding='valid', \n        activation='relu'))\n    #takes the maximum value of either feature vector from each of the n_words features\n    model.add(layers.GlobalMaxPooling1D())\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    return model\n(X_train, y_train), (X_test, y_test) = load_data()\nmodel=build_model()\nmodel.summary() \n```", "```\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 256)          2560000   \n\n dropout (Dropout)           (None, 200, 256)          0         \n\n conv1d (Conv1D)             (None, 198, 256)          196864    \n\n global_max_pooling1d (Globa  (None, 256)              0         \n lMaxPooling1D)                                                  \n\n dense (Dense)               (None, 128)               32896     \n\n dropout_1 (Dropout)         (None, 128)               0         \n\n dense_1 (Dense)             (None, 1)                 129       \n\n=================================================================\nTotal params: 2,789,889\nTrainable params: 2,789,889\nNon-trainable params: 0 \n```", "```\nmodel.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n  metrics = [\"accuracy\"]\n)\nscore = model.fit(X_train, y_train,\n  epochs= EPOCHS,\n  batch_size = BATCH_SIZE,\n  validation_data = (X_test, y_test)\n)\nscore = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\nprint(\"\\nTest score:\", score[0])\nprint('Test accuracy:', score[1]) \n```", "```\nEpoch 19/20\n25000/25000 [==============================] - 135s 5ms/sample - loss: 7.5276e-04 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.8818\nEpoch 20/20\n25000/25000 [==============================] - 129s 5ms/sample - loss: 6.7755e-04 - accuracy: 0.9999 - val_loss: 0.5802 - val_accuracy: 0.8821\n25000/25000 [==============================] - 23s 916us/sample - loss: 0.5802 - accuracy: 0.8821\nTest score: 0.5801781857013703\nTest accuracy: 0.88212 \n```"]