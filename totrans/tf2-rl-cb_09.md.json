["```\nimport argparse\nimport os\nimport sys\nfrom datetime import datetime\nimport gym\nimport numpy as np\nimport procgen  # Used to register procgen envs with Gym registry\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n```", "```\n    tf.keras.backend.set_floatx(\"float32\")\n    ```", "```\n    parser = argparse.ArgumentParser(prog=\"TFRL-Cookbook-Ch9-PPO-trainer-exporter-TFLite\")\n    parser.add_argument(\n        \"--env\", default=\"procgen:procgen-coinrun-v0\",\n        choices=[\"procgen:procgen-bigfish\",\n            \"procgen:procgen-bossfight\",\n            \"procgen:procgen-caveflyer\",\n            \"procgen:procgen-chaser\",\n            \"procgen:procgen-climber\",\n            \"procgen:procgen-coinrun\",\n            \"procgen:procgen-dodgeball\",\n            \"procgen:procgen-fruitbot\",\n            \"procgen:procgen-heist\",\n            \"procgen:procgen-jumper\",\n            \"procgen:procgen-leaper\",\n            \"procgen:procgen-maze\",\n            \"procgen:procgen-miner\",\n            \"procgen:procgen-ninja\",\n            \"procgen:procgen-plunder\",\n            \"procgen:procgen-starpilot\",\n            \"Pong-v4\",\n        ],\n    )\n    ```", "```\n    parser.add_argument(\"--update-freq\", type=int, default=16)\n    parser.add_argument(\"--epochs\", type=int, default=3)\n    parser.add_argument(\"--actor-lr\", type=float, default=1e-4)\n    parser.add_argument(\"--critic-lr\", type=float, default=1e-4)\n    parser.add_argument(\"--clip-ratio\", type=float, default=0.1)\n    parser.add_argument(\"--gae-lambda\", type=float, default=0.95)\n    parser.add_argument(\"--gamma\", type=float, default=0.99)\n    parser.add_argument(\"--logdir\", default=\"logs\")\n    args = parser.parse_args()\n    ```", "```\n    logdir = os.path.join(\n        args.logdir, parser.prog, args.env, \\\n        datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    )\n    print(f\"Saving training logs to:{logdir}\")\n    writer = tf.summary.create_file_writer(logdir)\n    ```", "```\n        def save(self, model_dir: str, version: int = 1):\n            actor_model_save_dir = os.path.join(\n                model_dir, \"actor\", str(version), \\\n                \"model.savedmodel\"\n            )\n            self.model.save(actor_model_save_dir, \n                            save_format=\"tf\")\n            print(f\"Actor model saved at:\\\n                    {actor_model_save_dir}\")\n    ```", "```\n        def save(self, model_dir: str, version: int = 1):\n            critic_model_save_dir = os.path.join(\n                model_dir, \"critic\", str(version), \\\n                \"model.savedmodel\"\n            )\n            self.model.save(critic_model_save_dir, \n                            save_format=\"tf\")\n            print(f\"Critic model saved at:{\n                                     critic_model_save_dir}\")\n    ```", "```\n        def save(self, model_dir: str, version: int = 1):\n            self.actor.save(model_dir, version)\n            self.critic.save(model_dir, version)\n    ```", "```\n    (tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tflite_convert \\\n      --saved_model_dir=trained_models/ppo-procgen-coinrun/1/actor/model.savedmodel \\\n      --output_file=trained_models/ppo-procgen-coinrun/1/actor/model.tflite\n    ```", "```\n    (tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tflite_convert \\\n      --saved_model_dir=trained_models/ppo-procgen-coinrun/1/critic/model.savedmodel \\\n      --output_file=trained_models/ppo-procgen-coinrun/1/critic/model.tflite\n    ```", "```\n        def save_tflite(self, model_dir: str, version: int =\\\n         1):\n            \"\"\"Save/Export Actor model in TensorFlow Lite\n            format\"\"\"\n            actor_model_save_dir = os.path.join(model_dir,\\\n                                       \"actor\", str(version))\n            model_converter = \\\n                tf.lite.TFLiteConverter.from_keras_model(\n                                                  self.model)\n            # Convert model to TFLite Flatbuffer\n            tflite_model = model_converter.convert()\n            # Save the model to disk/persistent-storage\n            if not os.path.exists(actor_model_save_dir):\n                os.makedirs(actor_model_save_dir)\n            actor_model_file_name = os.path.join(\n                      actor_model_save_dir, \"model.tflite\")\n            with open(actor_model_file_name, \"wb\") as \\\n            model_file:\n                model_file.write(tflite_model)\n            print(f\"Actor model saved in TFLite format at:\\\n                   {actor_model_file_name}\")\n    ```", "```\n        def save_tflite(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Critic model in TensorFlow Lite  \n            format\"\"\"\n            critic_model_save_dir = os.path.join(model_dir, \n                                      \"critic\", str(version))\n            model_converter = \\\n                tf.lite.TFLiteConverter.from_keras_model(\n                                                  self.model)\n            # Convert model to TFLite Flatbuffer\n            tflite_model = model_converter.convert()\n            # Save the model to disk/persistent-storage\n            if not os.path.exists(critic_model_save_dir):\n                os.makedirs(critic_model_save_dir)\n            critic_model_file_name = os.path.join(\n                      critic_model_save_dir, \"model.tflite\")\n            with open(critic_model_file_name, \"wb\") as \\\n            model_file:\n                model_file.write(tflite_model)\n            print(f\"Critic model saved in TFLite format at:\\\n                    {critic_model_file_name}\")\n    ```", "```\n        def save_tflite(self, model_dir: str, version: \\\n        int = 1):\n            # Make sure `toco_from_protos binary` is on \n            # system's PATH to avoid TFLite ConverterError\n            toco_bin_dir = os.path.dirname(sys.executable)\n            if not toco_bin_dir in os.environ[\"PATH\"]:\n                os.environ[\"PATH\"] += os.pathsep + \\\n                                      toco_bin_dir\n            print(f\"Saving Agent model (TFLite) to:{\n                                               model_dir}\\n\")\n            self.actor.save_tflite(model_dir, version)\n            self.critic.save_tflite(model_dir, version)\n    ```", "```\n    if __name__ == \"__main__\":\n        env_name = args.env\n        env = gym.make(env_name)\n        agent = PPOAgent(env)\n        agent.train(max_episodes=1)\n        # Model saving\n        model_dir = \"trained_models\"\n        agent_name = f\"PPO_{env_name}\"\n        agent_version = 1\n        agent_model_path = os.path.join(model_dir, \\\n                                        agent_name)\n        agent.save_tflite(agent_model_path, agent_version)\n    ```", "```\n    dependencies {\n        implementation fileTree(dir: 'libs', include: \\\n                                ['*.jar'])\n        implementation 'org.tensorflow:tensorflow-lite:+'\n    }\n    ```", "```\n        MappedByteBuffer loadModelFile(AssetManager \\\n             assetManager) throws IOException {\n            AssetFileDescriptor fileDescriptor = \\\n                assetManager.openFd(\"agent/model.tflite\");\n            FileInputStream inputStream = new \\\n                 FileInputStream(\n                      fileDescriptor.getFileDescriptor());\n            FileChannel fileChannel = \\\n                        inputStream.getChannel();\n            long startOffset = \\\n                 fileDescriptor.getStartOffset();\n            long declaredLength = \\\n                 fileDescriptor.getDeclaredLength();\n            return fileChannel.map(\n                FileChannel.MapMode.READ_ONLY, \\\n                startOffset, declaredLength);\n        }\n    ```", "```\n    interpreter = new Interpreter(loadModelFile(assetManager),\n                                  new Interpreter.Options());\n    ```", "```\n     static final int BATCH_SIZE = 1;\n      static final int OBS_IMG_WIDTH = 160;\n     static final int OBS_IMG_HEIGHT = 210;\n     static final int OBS_IMG_CHANNELS = 3;\n     // Image observation normalization\n     static final int IMAGE_MEAN = 128;\n     static final float IMAGE_STD = 128.0f;\n    ```", "```\n    ByteBuffer convertBitmapToByteBuffer(Bitmap bitmap) {\n            ByteBuffer byteBuffer;\n            byteBuffer = ByteBuffer.allocateDirect(4 * \\\n                          BATCH_SIZE * OBS_IMG_WIDTH * \\\n                          OBS_IMG_HEIGHT * OBS_IMG_CHANNELS);\n            byteBuffer.order(ByteOrder.nativeOrder());\n            int[] intValues = new int[OBS_IMG_WIDTH * \\\n                                      OBS_IMG_HEIGHT];\n            bitmap.getPixels(intValues,0, bitmap.getWidth(),\\\n              0, 0, bitmap.getWidth(), bitmap.getHeight());\n            int pixel = 0;\n            for (int i = 0; i < OBS_IMG_HEIGHT; ++i) {\n                for (int j = 0; j < OBS_IMG_WIDTH; ++j) {\n                    final int val = intValues[pixel++];\n\n                        byteBuffer.putFloat((((val >> 16) &\\\n                            0xFF)-IMAGE_MEAN)/IMAGE_STD);\n                        byteBuffer.putFloat((((val >> 8) & \\\n                            0xFF)-IMAGE_MEAN)/IMAGE_STD);\n                        byteBuffer.putFloat((((val) & 0xFF)-\\\n                            IMAGE_MEAN)/IMAGE_STD);\n                }\n            }\n            return byteBuffer;\n        }\n    ```", "```\n    ByteBuffer byteBuffer = convertBitmapToByteBuffer(bitmap);\n    int[] action = new int[ACTION_DIM];\n    interpreter.run(byteBuffer, action);\n    ```", "```\nimport argparse\nimport copy\nimport os\nimport random\nfrom collections import deque\nfrom datetime import datetime\nimport gym\nimport numpy as np\nimport tensorflow as tf\nimport tensorflowjs as tfjs\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    Dense,\n    Dropout,\n    Flatten,\n    Input,\n    Lambda,\n    MaxPool2D,\n)\nimport webgym\n```", "```\n    parser = argparse.ArgumentParser(\n        prog=\"TFRL-Cookbook-Ch9-DDPGAgent-TensorFlow.js-exporter\"\n    )\n    parser.add_argument(\"--env\", default=\"MiniWoBSocialMediaMuteUserVisualEnv-v0\")\n    parser.add_argument(\"--actor_lr\", type=float, default=0.0005)\n    parser.add_argument(\"--critic_lr\", type=float, default=0.001)\n    parser.add_argument(\"--batch_size\", type=int, default=64)\n    parser.add_argument(\"--tau\", type=float, default=0.05)\n    parser.add_argument(\"--gamma\", type=float, default=0.99)\n    parser.add_argument(\"--train_start\", type=int, \n                         default=2000)\n    parser.add_argument(\"--logdir\", default=\"logs\")\n    args = parser.parse_args()\n    ```", "```\n    logdir = os.path.join(\n        args.logdir, parser.prog, args.env, \\\n        datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n    )\n    print(f\"Saving training logs to:{logdir}\")\n    writer = tf.summary.create_file_writer(logdir)\n    ```", "```\n        def save_h5(self, model_dir: str, version: int = 1):\n            actor_model_save_dir = os.path.join(\n                model_dir, \"actor\", str(version), \"model.h5\"\n            )\n            self.model.save(actor_model_save_dir, \\\n                            save_format=\"h5\")\n            print(f\"Actor model saved at:\\\n                    {actor_model_save_dir}\")\n    ```", "```\n        def save_h5(self, model_dir: str, version: int = 1):\n            critic_model_save_dir = os.path.join(\n                model_dir, \"critic\", str(version), \"model.h5\"\n            )\n            self.model.save(critic_model_save_dir, \\\n                            save_format=\"h5\")\n            print(f\"Critic model saved at:\\\n                    {critic_model_save_dir}\")\n    ```", "```\n        def save_h5(self, model_dir: str, version: int = 1):\n            self.actor.save_h5(model_dir, version)\n            self.critic.save_h5(model_dir, version)\n    ```", "```\n    (tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tensorflowjs_converter --input_format keras \\\n                           actor/1/model.h5 \\\n                           actor/t1/model.tfjs\n    ```", "```\n    (tfrl-cookbook)praveen@desktop:~/tfrl-cookbook/ch9$tensorflowjs_converter --input_format keras \\\n                           critic/1/model.h5 \\\n                           critic/t1/model.tfjs\n    ```", "```\n        def save_tfjs(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Actor model in TensorFlow.js \n            supported format\"\"\"\n            actor_model_save_dir = os.path.join(\n                model_dir, \"actor\", str(version), \\\n                \"model.tfjs\"\n            )\n            tfjs.converters.save_keras_model(self.model,\\\n                                       actor_model_save_dir)\n            print(f\"Actor model saved in TF.js format at:\\\n                    {actor_model_save_dir}\")\n    ```", "```\n        def save_tfjs(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Critic model in TensorFlow.js \n            supported format\"\"\"\n            critic_model_save_dir = os.path.join(\n                model_dir, \"critic\", str(version), \\\n                \"model.tfjs\"\n            )\n            tfjs.converters.save_keras_model(self.model,\\\n                                     critic_model_save_dir)\n            print(f\"Critic model saved TF.js format \\\n                     at:{critic_model_save_dir}\")\n    ```", "```\n        def save_tfjs(self, model_dir: str, version: \\\n        int = 1):\n            print(f\"Saving Agent model to:{model_dir}\\n\")\n            self.actor.save_tfjs(model_dir, version)\n            self.critic.save_tfjs(model_dir, version)\n    ```", "```\n    if __name__ == \"__main__\":\n        env_name = args.env\n        env = gym.make(env_name)\n        agent = PPOAgent(env)\n        agent.train(max_episodes=1)\n        # Model saving\n        model_dir = \"trained_models\"\n        agent_name = f\"PPO_{env_name}\"\n        agent_version = 1\n        agent_model_path = os.path.join(model_dir, \\\n                                        agent_name)\n        # agent.save_h5(agent_model_path, agent_version)\n        agent.save_tfjs(agent_model_path, agent_version)\n    ```", "```\n    yy.mm format) that supports your NVIDIA GPU driver version. For example, if you have installed NVIDIA driver version 450.83 (find out by running nvidia-smi), then container versions built with CUDA 11.0.3 or lower, such as container version 20.09 or older, will work.\n    ```", "```\n    praveen@desktop:~$ docker pull nvcr.io/nvidia/tritonserver:yy.mm-py3\n    ```", "```\n    praveen@desktop:~$ docker pull nvcr.io/nvidia/tritonserver:20.09-py3\n    ```", "```\n    -v flag to point to the trained_models/actor folder on your serving machine. Also remember to update the yy.mm value to reflect your container version (20.3, for example).\n    ```", "```\n    $ docker run  --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --rm -p8000:8000 -p8001:8001 -p8002:8002 -v/full/path/to/trained_models/actor:/models nvcr.io/nvidia/tritonserver:yy.mm-py3 tritonserver --model-repository=/models --strict-model-config=false --log-verbose=1\n    ```", "```\n    {                                                                                                                     \n        \"name\": \"actor\",                                                                                                  \n        \"platform\": \"tensorflow_savedmodel\",                                                                              \n        \"backend\": \"tensorflow\",                                                                                          \n        \"version_policy\": {                                                                                               \n            \"latest\": {                                                                                                   \n                \"num_versions\": 1                                                                                         \n            }                                                                                                             \n        },                                                                                                                \n        \"max_batch_size\": 1,  \n    ```", "```\n        \"input\": [                                                                                                        \n            {                                                                                                             \n                \"name\": \"input_1\",                                                                                        \n                \"data_type\": \"TYPE_FP64\",                                                                                 \n                \"dims\": [                                                                                                 \n                    64,                                                                                                   \n                    64,                                                                                                   \n                    3                                                                                                     \n                ],\n                \"format\": \"FORMAT_NHWC\"                                                                                                         \n            }                                                                                                             \n        ],\n    ```", "```\n        \"output\": [\n            {\n                \"name\": \"lambda\", \n                \"data_type\": \"TYPE_FP64\",\n                \"dims\": [\n                    2\n                ]\n            },\n            {\n                \"name\": \"lambda_1\",\n                \"data_type\": \"TYPE_FP64\",\n                \"dims\": [\n                    2\n                ]\n            }\n        ],                                                                                                                    \n    ```", "```\n        \"batch_input\": [],\n        \"batch_output\": [],\n        \"optimization\": {\n            \"priority\": \"PRIORITY_DEFAULT\",\n            \"input_pinned_memory\": {\n                \"enable\": true\n            },\n            \"output_pinned_memory\": {\n                \"enable\": true\n            }\n        },\n        \"instance_group\": [\n            {\n                \"name\": \"actor\",\n                \"kind\": \"KIND_CPU\",\n                \"count\": 1,\n                \"gpus\": [],\n                \"profile\": []\n            }\n        ],                                                                                                                     \n    ```", "```\n        \"default_model_filename\": \"model.savedmodel\",\n        \"cc_model_filenames\": {}, \n        \"metric_tags\": {},\n        \"parameters\": {},\n        \"model_warmup\": []\n    } \n    ```", "```\n    $curl -v localhost:8000/v2/health/ready\n    ```", "```\n    ...\n    < HTTP/1.1 200 OK\n    < Content-Length: 0\n    < Content-Type: text/plain\n    ```", "```\n    $ pip install nvidia-pyindex\n    $ pip install tritonclient[all]\n    ```", "```\n    $ sudo apt update && apt install libb64-dev\n    ```", "```\n    $ python sample_client_app.py\n    ```", "```\nimport argparse\nimport os\nimport sys\nfrom datetime import datetime\nimport gym\nimport keras2onnx\nimport numpy as np\nimport procgen  # Used to register procgen envs with Gym registry\nimport tensorflow as tf\nimport tensorflowjs as tfjs\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n```", "```\n    tf.keras.backend.set_floatx(\"float32\")\n    ```", "```\n        def save(self, model_dir: str, version: int = 1):\n            actor_model_save_dir = os.path.join(\n                model_dir, \"actor\", str(version), \\\n                \"model.savedmodel\"\n            )\n            self.model.save(actor_model_save_dir, \\\n                            save_format=\"tf\")\n            print(f\"Actor model saved at:\\\n                    {actor_model_save_dir}\")\n    ```", "```\n        def save_tflite(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Actor model in TensorFlow Lite \n            format\"\"\"\n            actor_model_save_dir = os.path.join(model_dir,\\\n                                       \"actor\", str(version))\n            model_converter = \\\n                tf.lite.TFLiteConverter.from_keras_model(\n                                                 self.model)\n            # Convert model to TFLite Flatbuffer\n            tflite_model = model_converter.convert()\n            # Save the model to disk/persistent-storage\n            if not os.path.exists(actor_model_save_dir):\n                os.makedirs(actor_model_save_dir)\n            actor_model_file_name = \\\n                os.path.join(actor_model_save_dir, \n                             \"model.tflite\")\n            with open(actor_model_file_name, \"wb\") as \\\n            model_file:\n                model_file.write(tflite_model)\n            print(f\"Actor model saved in TFLite format at:\\\n                    {actor_model_file_name}\")\n    ```", "```\n        def save_h5(self, model_dir: str, version: int = 1):\n            actor_model_save_path = os.path.join(\n                model_dir, \"actor\", str(version), \"model.h5\"\n            )\n            self.model.save(actor_model_save_path, \\\n                            save_format=\"h5\")\n            print(f\"Actor model saved at:\\\n                   {actor_model_save_path}\")\n    ```", "```\n        def save_tfjs(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Actor model in TensorFlow.js\n            supported format\"\"\"\n            actor_model_save_dir = os.path.join(\n                model_dir, \"actor\", str(version), \\\n                \"model.tfjs\"\n            )\n            tfjs.converters.save_keras_model(self.model, \\\n                                        actor_model_save_dir)\n            print(f\"Actor model saved in TF.js format at:\\\n                    {actor_model_save_dir}\")\n    ```", "```\n        def save_onnx(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Actor model in ONNX format\"\"\"\n            actor_model_save_path = os.path.join(\n                model_dir, \"actor\", str(version), \\\n                \"model.onnx\"\n            )\n            onnx_model = keras2onnx.convert_keras(\n                                 self.model, self.model.name)\n            keras2onnx.save_model(onnx_model, \\\n                                  actor_model_save_path)\n            print(f\"Actor model saved in ONNX format at:\\\n                    {actor_model_save_path}\")\n    ```", "```\n        def save(self, model_dir: str, version: int = 1):\n            critic_model_save_dir = os.path.join(\n                model_dir, \"critic\", str(version), \\\n                \"model.savedmodel\"\n            )\n            self.model.save(critic_model_save_dir, \\\n                            save_format=\"tf\")\n            print(f\"Critic model saved at:\\\n                    {critic_model_save_dir}\")\n    ```", "```\n        def save_tflite(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Critic model in TensorFlow Lite \n            format\"\"\"\n            critic_model_save_dir = os.path.join(model_dir,\\\n                                      \"critic\", str(version))\n            model_converter = \\\n                tf.lite.TFLiteConverter.from_keras_model(\n                                                  self.model)\n            # Convert model to TFLite Flatbuffer\n            tflite_model = model_converter.convert()\n            # Save the model to disk/persistent-storage\n            if not os.path.exists(critic_model_save_dir):\n                os.makedirs(critic_model_save_dir)\n            critic_model_file_name = \\\n                os.path.join(critic_model_save_dir, \n                             \"model.tflite\")\n            with open(critic_model_file_name, \"wb\") as \\\n            model_file:\n                model_file.write(tflite_model)\n            print(f\"Critic model saved in TFLite format at:\\\n                    {critic_model_file_name}\")\n    ```", "```\n        def save_h5(self, model_dir: str, version: int = 1):\n            critic_model_save_dir = os.path.join(\n                model_dir, \"critic\", str(version), \"model.h5\"\n            )\n            self.model.save(critic_model_save_dir, \\\n                            save_format=\"h5\")\n            print(f\"Critic model saved at:\\\n                    {critic_model_save_dir}\")\n    ```", "```\n        def save_tfjs(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Critic model in TensorFlow.js \n            supported format\"\"\"\n            critic_model_save_dir = os.path.join(\n                model_dir, \"critic\", str(version), \\\n                \"model.tfjs\"\n            )\n            tfjs.converters.save_keras_model(self.model,\\\n                                       critic_model_save_dir)\n            print(f\"Critic model saved TF.js format at:\\\n                    {critic_model_save_dir}\")\n    ```", "```\n        def save_onnx(self, model_dir: str, version: \\\n        int = 1):\n            \"\"\"Save/Export Critic model in ONNX format\"\"\"\n            critic_model_save_path = os.path.join(\n                model_dir, \"critic\", str(version), \\\n                \"model.onnx\"\n            )\n            onnx_model = keras2onnx.convert_keras(self.model,\n                                             self.model.name)\n            keras2onnx.save_model(onnx_model, \\\n                                  critic_model_save_path)\n            print(f\"Critic model saved in ONNX format at:\\\n                    {critic_model_save_path}\")\n    ```", "```\n        def save(self, model_dir: str, version: int = 1):\n            self.actor.save(model_dir, version)\n            self.critic.save(model_dir, version)\n        def save_tflite(self, model_dir: str, version: \\\n        int = 1):\n            # Make sure `toco_from_protos binary` is on  \n            # system's PATH to avoid TFLite ConverterError\n            toco_bin_dir = os.path.dirname(sys.executable)\n            if not toco_bin_dir in os.environ[\"PATH\"]:\n                os.environ[\"PATH\"] += os.pathsep + \\\n                                      toco_bin_dir\n            print(f\"Saving Agent model (TFLite) to:\\\n                    {model_dir}\\n\")\n            self.actor.save_tflite(model_dir, version)\n            self.critic.save_tflite(model_dir, version)\n    ```", "```\n        def save_h5(self, model_dir: str, version: int = 1):\n            print(f\"Saving Agent model (HDF5) to:\\\n                    {model_dir}\\n\")\n            self.actor.save_h5(model_dir, version)\n            self.critic.save_h5(model_dir, version)\n        def save_tfjs(self, model_dir: str, version: \\\n        int = 1):\n            print(f\"Saving Agent model (TF.js) to:\\\n                    {model_dir}\\n\")\n            self.actor.save_tfjs(model_dir, version)\n            self.critic.save_tfjs(model_dir, version)\n        def save_onnx(self, model_dir: str, version: \\\n        int = 1):\n            print(f\"Saving Agent model (ONNX) to:\\\n                    {model_dir}\\n\")\n            self.actor.save_onnx(model_dir, version)\n            self.critic.save_onnx(model_dir, version)\n    ```", "```\n    if __name__ == \"__main__\":\n        env_name = args.env\n        env = gym.make(env_name)\n        agent = PPOAgent(env)\n        agent.train(max_episodes=1)\n        # Model saving\n        model_dir = \"trained_models\"\n        agent_name = f\"PPO_{env_name}\"\n        agent_version = 1\n        agent_model_path = os.path.join(model_dir, \\\n                                        agent_name)\n        agent.save_onnx(agent_model_path, agent_version)\n        agent.save_h5(agent_model_path, agent_version)\n        agent.save_tfjs(agent_model_path, agent_version)\n        agent.save_tflite(agent_model_path, agent_version)\n    ```"]