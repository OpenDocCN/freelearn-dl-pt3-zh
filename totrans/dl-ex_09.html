<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Object Detection – Transfer Learning with CNNs</h1>
                </header>
            
            <article>
                
<div class="packtquote">"How individuals transfer in one context to another context that share similar characteristics"</div>
<div class="CDPAlignRight">– <em class="calibre25">E. L. Thorndike</em>, <em class="calibre25">R. S. Woodworth (1991)</em></div>
<p class="calibre2"><strong class="calibre13">Transfer learning</strong> (<strong class="calibre13">TL</strong>) is a research problem in data science that is mainly concerned with persisting knowledge acquired during solving a specific task and using this acquired knowledge to solve another different but similar task. In this chapter, we will demonstrate one of the modern practices and common themes used in the field of data science with TL. The idea here is how to get the help from domains with very large datasets to domains that have less dataset size. Finally, we will revisit our object detection example of CIFAR-10 and try to reduce both the training time and performance error via TL.</p>
<p class="calibre2">The following topics will be covered in this chapter:</p>
<ul class="calibre7">
<li class="calibre8">Transfer learning</li>
<li class="calibre8">CIFAR-10 object detection revisited</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transfer learning</h1>
                </header>
            
            <article>
                
<p class="calibre2">Deep learning architectures are data greedy and having a few samples in a training set will not get us the best out of them. TL solves this problem by transferring learned or gained knowledge/representations from solving a task with a large dataset to another different but similar one with a smaller dataset.</p>
<p class="calibre2">TL is not only useful for the case of small training sets, but also we can use it to make the training process faster. Training large deep learning architectures from scratch <span class="calibre10">can </span>sometimes be very slow because we have millions of weights in these architectures that need to be learned. Instead, someone can make use of TL by just fine-tuning a learned weight on a similar<span class="calibre10"> </span>problem to the one that he/she's trying to solve.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The intuition behind TL</h1>
                </header>
            
            <article>
                
<p class="calibre2">Let's build up the intuition behind TL by using the following teacher-student analogy. A teacher has many years of experience in the modules that he'she's teaching. On the other side, the students get a compact overview of the topic from the lectures that this teacher gives. So you can say that the teacher is transferring their knowledge in a concise and compact way to the students.</p>
<p class="calibre2">The same analogy of the teacher and students can be applied to our case of transferring knowledge in deep learning, or in neural networks in general. So our model learns some representations from the data, which is represented by the <em class="calibre19">weights</em> of the network. These learned representations/features (weights) can be transferred to another different but similar task. This process of transferring the learned weights to another task will reduce the need for huge datasets for deep learning architectures to converge, and it will also reduce the time needed to adapt the model to the new dataset compared to training the model from scratch.</p>
<p class="calibre2">Deep learning is widely used nowadays, but usually most people are using TL while training deep learning architectures; few of them train deep learning architectures from scratch, because most of the time it's rare to have a dataset of sufficient size for deep learning to converge. So it's very common to use a pre-trained model on a large dataset such as <kbd class="calibre12">ImageNet</kbd>, which has about 1.2 million images, and apply it to your new task. We can use the weights of that pre-trained model as a feature extractor, or we can just initialize our architecture with it and then fine-tune them to your new task. There are three major scenarios for using TL:</p>
<ul class="calibre7">
<li class="calibre8">
<p class="calibre9"><strong class="calibre13">Use a convolution network as a fixed feature extractor</strong>:<strong class="calibre13"> </strong>In this scenario, you use a pre-trained convolution model on a large dataset such as ImageNet and adapt it to work on your problem. For instance, a pre-trained convolution model on ImageNet will have a fully connected layer with output scores for the 1,000 categories that ImageNet has. So you need to remove this layer because you are not interested anymore in the classes of ImageNet. Then, you treat all other layers as a feature extractor. Once you have extracted the features using the pre-trained model, you can feed these features to any linear classifier, such as the softmax classifier, or even linear SVM.</p>
</li>
<li class="calibre8">
<p class="calibre9"><strong class="calibre13">Fine-tune the convolution neural network</strong>: The second scenario involves the first one but with an extra effort to fine-tune the pre-trained weights on your new task using backpropagation. Usually, people keep most of the layers fixed and only fine-tune the top end of the network. Trying to fine-tune the whole network or even most of the layers may result in overfitting. So, you might be interested in fine-tuning <span class="calibre10">only </span>those layers that are concerned with the semantic-level features of the images. The intuition behind leaving the earlier layers fixed is that they contain generic or low-level features that are common across most imaging tasks, such as corners, edges, and so on. Fine-tuning the higher level or the top end layers of the network will be useful if you're introducing new classes that are not present in the original dataset that the model was pre-trained on.</p>
<div class="CDPAlignCenter"><img src="assets/7b634245-e286-449f-8f6a-5b7fee31ffef.png" class="calibre112"/></div>
</li>
</ul>
<div class="CDPAlignCenter1">Figure 10.1: Fine-tuning the pre-trained CNN for a new task</div>
<ul class="calibre7">
<li class="calibre8">
<p class="calibre9"><strong class="calibre13">Pre-trained models</strong>: The third widely used scenario is to download checkpoints that people have made available on the internet. You may go for this scenario if you don't have big computational power to train the model from scratch, so you just initialize the model with the released checkpoints and then do a little fine-tuning. </p>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Differences between traditional machine learning and TL</h1>
                </header>
            
            <article>
                
<p class="calibre2">As you've noticed from the previous section, there's a clear difference between the traditional way we apply machine learning and machine learning that involves TL (as shown in the following diagram<em class="calibre19">)</em>. In traditional machine learning, you don't transfer any knowledge or representations to any other task, which is not the case in TL. Sometimes, people use TL in a wrong way, so we are going to mention a few conditions under which you can only use TL to maximize the gains.</p>
<p class="calibre2">The following are the conditions for applying TL:</p>
<ul class="calibre7">
<li class="calibre8">Unlike traditional machine learning, the source and target task or domains don't have to come from the same distribution, but they have to be similar</li>
<li class="calibre8">You can also use TL in case of less training samples or if you don't have the necessary computational power</li>
</ul>
<div class="CDPAlignCenter"><img src="assets/ba7e27f6-a962-4f30-8c43-f6798ad21fe0.png" class="calibre113"/></div>
<div class="CDPAlignCenter1">Figure 10.2: Traditional machine learning versus machine learning with TL</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CIFAR-10 object detection – revisited</h1>
                </header>
            
            <article>
                
<p class="calibre2">In the previous chapter, we trained a simple <strong class="calibre13">convolution neural network</strong> (<strong class="calibre13">CNN</strong>) model on the CIFAR-10 dataset. Here, we are going to demonstrate the case of using a pre-trained model as a feature extractor while removing the fully connected layer of the pre-trained model, and then we'll feed these extracted features or transferred values to a softmax layer.</p>
<p class="calibre2">The pre-trained model in this implementation will be the inception model, which will be pre-trained on ImageNet. But bear in mind that this implementation builds on the previous two chapters that introduced CNN.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solution outline</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignCenter">
<p class="calibre2">Again, we are going to replace the final fully connected layer of the pre-trained inception model and then use the rest of the inception model as a feature extractor. So, we first feed our raw images in the inception model, which will extract the features from them and then output our so-called transfer values.</p>
<p class="calibre2">After getting the transfer values of the extracted features from the inception model, you might need to save them to your desk because it will take some time if you did it on the fly, so it's useful to persist them to your desk to save you time. In TensorFlow tutorials, they use the term bottleneck values instead of transfer values, but it's just a different name for the exact same thing.</p>
</div>
<p class="calibre2">After getting the transfer values or loading them from the desk, we can feed them to any linear classifier that's customized to our new task. Here, we will feed the extracted transfer values to another neural network and then train for the new classes of CIFAR-10.</p>
<p class="innercell">The following diagram, shows the general solution outline that we will be following:</p>
</div>
</div>
<div class="CDPAlignCenter"><img src="assets/389af43d-d01c-4193-b267-df995b4124a1.png" class="calibre114"/></div>
<div class="CDPAlignCenter1">Figure 10.3: The solution outline for an object detection task using the CIFAR-10 dataset with TL</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loading and exploring CIFAR-10</h1>
                </header>
            
            <article>
                
<div class="CDPAlignLeft">
<p class="calibre2">Let's start off by importing the required packages for this implementation:</p>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>%matplotlib inline<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>import tensorflow as tf<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>import time<br class="title-page-name"/>from datetime import timedelta<br class="title-page-name"/>import os<br class="title-page-name"/><br class="title-page-name"/># Importing a helper module for the functions of the Inception model.<br class="title-page-name"/>import inception</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we need to load another helper script that we can use to download the processing CIFAR-10 dataset:</p>
<pre class="calibre21"><span>import</span> <span>cifar10<br class="title-page-name"/></span>#importing number of classes of CIFAR-10<br class="title-page-name"/>from<span> </span><span>cifar10</span><span> </span><span>import</span><span> </span><span>num_classes</span></pre>
<p class="calibre2">If you haven't done this already, you need to set the path for CIFAR-10. This path will be used by the <kbd class="calibre12">cifar-10.py</kbd> script to persist the dataset:</p>
<pre class="calibre21"><span>cifar10.data_path = "data/CIFAR-10/"<br class="title-page-name"/><br class="title-page-name"/></span>The CIFAR-10 dataset is about 170 MB, the next line checks if the dataset is already downloaded if not it downloads the dataset and store in the previous <kbd class="calibre115">data_path</kbd><span>:<br class="title-page-name"/><br class="title-page-name"/></span>cifar10<span>.</span><span>maybe_download_and_extract&lt;/span&gt;<span>()<br class="title-page-name"/><br class="title-page-name"/></span></span>Output:<br class="title-page-name"/><br class="title-page-name"/>- Download progress: 100.0%<br class="title-page-name"/>Download finished. Extracting files.<br class="title-page-name"/>Done.</pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Let's see the categories that we have in the CIFAR-10 dataset:</p>
</div>
</div>
</div>
<pre class="calibre21"><span>#Loading the class names of CIFAR-10 dataset<br class="title-page-name"/>class_names</span> <span>=</span> <span>cifar10</span><span>.</span><span>load_class_names</span><span>()</span>
<span>class_names</span></pre>
<p class="calibre2">Output:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta<br class="title-page-name"/>['airplane',<br class="title-page-name"/> 'automobile',<br class="title-page-name"/> 'bird',<br class="title-page-name"/> 'cat',<br class="title-page-name"/> 'deer',<br class="title-page-name"/> 'dog',<br class="title-page-name"/> 'frog',<br class="title-page-name"/> 'horse', <br class="title-page-name"/> 'ship',<br class="title-page-name"/> 'truck']<br class="title-page-name"/>Load the training-set. </pre></div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">This returns <kbd class="calibre12">images</kbd>, the class-numbers as <kbd class="calibre12">integers</kbd>, and the class-numbers as one-hot encoded arrays called <kbd class="calibre12">labels</kbd>:</p>
<pre class="calibre21">training_images, training_cls_integers, trainig_one_hot_labels = cifar10.load_training_data()</pre>
<p class="calibre2">Output:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1
Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2
Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3
Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4
Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5
Load the test-set.</pre></div>
<p class="calibre2">Now, let's do the same for the testing set by loading the images and their corresponding integer representation of the target classes with their one-hot encoding:</p>
<pre class="calibre21"><span>#Loading the test images, their class integer, and their corresponding one-hot encoding<br class="title-page-name"/>testing_images, testing_cls_integers, testing_one_hot_labels = cifar10.load_test_data()<br class="title-page-name"/></span><br class="title-page-name"/>Output:<br class="title-page-name"/><br class="title-page-name"/>Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Let's have a look at the distribution of the training and testing sets in CIFAR-10:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>print("-Number of images in the training set:\t\t{}".format(len(training_images)))<br class="title-page-name"/>print("-Number of images in the testing set:\t\t{}".format(len(testing_images)))</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Output:</p>
<div class="title-page-name">
<pre class="calibre21">-Number of images in the training set:          50000
-Number of images in the testing set:           10000</pre></div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Let's define some helper functions that will enable us to explore the dataset. The following helper function plots a set of nine images in a grid:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>def plot_imgs(imgs, true_class, predicted_class=None):<br class="title-page-name"/><br class="title-page-name"/>    assert len(imgs) == len(true_class)<br class="title-page-name"/><br class="title-page-name"/>    # Creating a placeholders for 9 subplots<br class="title-page-name"/>    fig, axes = plt.subplots(3, 3)<br class="title-page-name"/><br class="title-page-name"/>    # Adjustting spacing.<br class="title-page-name"/>    if predicted_class is None:<br class="title-page-name"/>        hspace = 0.3<br class="title-page-name"/>    else:<br class="title-page-name"/>        hspace = 0.6<br class="title-page-name"/>    fig.subplots_adjust(hspace=hspace, wspace=0.3)<br class="title-page-name"/><br class="title-page-name"/><br class="title-page-name"/>    for i, ax in enumerate(axes.flat):<br class="title-page-name"/>        # There may be less than 9 images, ensure it doesn't crash.<br class="title-page-name"/>        if i &lt; len(imgs):<br class="title-page-name"/>            # Plot image.<br class="title-page-name"/>            ax.imshow(imgs[i],<br class="title-page-name"/>                      interpolation='nearest')<br class="title-page-name"/><br class="title-page-name"/>            # Get the actual name of the true class from the class_names array<br class="title-page-name"/>            true_class_name = class_names[true_class[i]]<br class="title-page-name"/><br class="title-page-name"/>            # Showing labels for the predicted and true classes<br class="title-page-name"/>            if predicted_class is None:<br class="title-page-name"/>                xlabel = "True: {0}".format(true_class_name)<br class="title-page-name"/>            else:<br class="title-page-name"/>                # Name of the predicted class.<br class="title-page-name"/>                predicted_class_name = class_names[predicted_class[i]]<br class="title-page-name"/><br class="title-page-name"/>                xlabel = "True: {0}\nPred: {1}".format(true_class_name, predicted_class_name)<br class="title-page-name"/><br class="title-page-name"/>        <br class="title-page-name"/>            ax.set_xlabel(xlabel)<br class="title-page-name"/>        <br class="title-page-name"/>        # Remove ticks from the plot.<br class="title-page-name"/>        ax.set_xticks([])<br class="title-page-name"/>        ax.set_yticks([])<br class="title-page-name"/>    <br class="title-page-name"/>    plt.show()</span></pre>
<div class="title-page-name">
<p class="calibre2">Let's go ahead and visualize some images from the test set along with their corresponding actual class:</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span># get the first 9 images in the test set<br class="title-page-name"/>imgs = testing_images[0:9]<br class="title-page-name"/><br class="title-page-name"/># Get the integer representation of the true class.<br class="title-page-name"/>true_class = testing_cls_integers[0:9]<br class="title-page-name"/><br class="title-page-name"/># Plotting the images<br class="title-page-name"/>plot_imgs(imgs=imgs, true_class=true_class)</span></pre>
<p class="innercell">Output:</p>
<div class="CDPAlignCenter"><img src="assets/94ffc181-5c5d-4376-b599-6ecef7f9cf86.png" class="calibre116"/></div>
<div class="CDPAlignCenter1">Figure 10.4: The first nine images of the test set</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Inception model transfer values</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">As we mentioned earlier, we will be using the pre-trained inception model on the ImageNet dataset. So, we need to download this pre-trained model from the internet.</p>
<p class="calibre2">Let's start off by defining <kbd class="calibre12">data_dir</kbd> for the inception model:</p>
<pre class="calibre21"><span>inception.data_dir = 'inception/'</span></pre></div>
</div>
<p class="calibre2">The weights of the pre-trained inception model are about 85 MB. The following line of code will download it if it doesn't exist in the <kbd class="calibre12">data_dir</kbd> defined previously:</p>
<pre class="calibre21"><span>inception</span><span>.</span><span>maybe_download</span><span>()<br class="title-page-name"/><br class="title-page-name"/></span>Downloading Inception v3 Model ...<br class="title-page-name"/>- Download progress: 100%</pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">We will load the inception model so that we can use it as a feature extractor for our CIFAR-10 images:</p>
<pre class="calibre21"><span># Loading the inception model so that we can inialized it with the pre-trained weights and customize for our model<br class="title-page-name"/>inception_model = inception.Inception()</span></pre></div>
</div>
<div class="title-page-name">
<p class="calibre2">As we mentioned previously, calculating the transfer values for the CIFAR-10 dataset will take some time, so we need to cache them for future use. Thankfully, there's a helper function in the <kbd class="calibre12">inception</kbd> module that can help us do that:</p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>from</span> <span>inception</span> <span>import</span> <span>transfer_values_cache</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we need to set the file paths for the cached training and testing files:</p>
<pre class="calibre21"><span>file_path_train = os.path.join(cifar10.data_path, 'inception_cifar10_train.pkl')<br class="title-page-name"/>file_path_test = os.path.join(cifar10.data_path, 'inception_cifar10_test.pkl')<br class="title-page-name"/></span>print("Processing Inception transfer-values for the training images of Cifar-10 ...")<br class="title-page-name"/><span># First we need to scale the imgs to fit the Inception model requirements as it requires all pixels to be from 0 to 255,<br class="title-page-name"/># while our training examples of the CIFAR-10 pixels are between 0.0 and 1.0<br class="title-page-name"/>imgs_scaled = training_images * 255.0<br class="title-page-name"/><br class="title-page-name"/># Checking if the transfer-values for our training images are already calculated and loading them, if not calculate and save them.<br class="title-page-name"/>transfer_values_training = transfer_values_cache(cache_path=file_path_train,<br class="title-page-name"/>                                              images=imgs_scaled,<br class="title-page-name"/>                                              model=inception_model)<br class="title-page-name"/></span>print("Processing Inception transfer-values for the testing images of Cifar-10 ...")<br class="title-page-name"/># First we need to scale the imgs to fit the Inception model requirements as it requires all pixels to be from 0 to 255,<br class="title-page-name"/># while our training examples of the CIFAR-10 pixels are between 0.0 and 1.0<br class="title-page-name"/>imgs_scaled = testing_images * 255.0<br class="title-page-name"/># Checking if the transfer-values for our training images are already calculated and loading them, if not calcaulate and save them.<br class="title-page-name"/>transfer_values_testing = transfer_values_cache(cache_path=file_path_test,<br class="title-page-name"/>                                     images=imgs_scaled,<br class="title-page-name"/><span>                                     model=inception_model)<br class="title-page-name"/></span></pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">As mentioned before, we have 50,000 images in the training set of the CIFAR-10 dataset. So let's check the shapes of the transfer values of these images. It should be 2,048 for each image in this training set:</p>
<pre class="calibre21">transfer_values_training.shape</pre>
<p class="calibre2">Output:</p>
<pre class="calibre21">(50000, 2048)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">We need to do the same for the test set:</p>
<pre class="calibre21">transfer_values_testing.shape</pre>
<p class="calibre2">Output:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignLeft">
<pre class="calibre21">(10000, 2048)</pre></div>
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignLeft">
<p class="calibre2">To intuitively understand how the transfer values look, we are going to define a helper function to enable us to use the plot the transfer values of a specific image from the training or the testing sets:</p>
<pre class="calibre21"><span>def plot_transferValues(ind):<br class="title-page-name"/>    print("Original input image:")<br class="title-page-name"/>    <br class="title-page-name"/>    # Plot the image at index ind of the test set.<br class="title-page-name"/>    plt.imshow(testing_images[ind], interpolation='nearest')<br class="title-page-name"/>    plt.show()<br class="title-page-name"/><br class="title-page-name"/>    print("Transfer values using Inception model:")<br class="title-page-name"/>    <br class="title-page-name"/>    # Visualize the transfer values as an image.<br class="title-page-name"/>    transferValues_img = transfer_values_testing[ind]<br class="title-page-name"/>    transferValues_img = transferValues_img.reshape((32, 64))<br class="title-page-name"/><br class="title-page-name"/>    # Plotting the transfer values image.<br class="title-page-name"/>    plt.imshow(transferValues_img, interpolation='nearest', cmap='Reds')<br class="title-page-name"/>    plt.show()<br class="title-page-name"/></span><span>plot_transferValues(</span><span>i</span><span>=</span><span>16</span><span>)<br class="title-page-name"/><br class="title-page-name"/></span>Input image:</pre></div>
</div>
<div class="CDPAlignCenter"><img src="assets/b7e00c35-26ef-40ae-95aa-8aed2b82d9ea.png" class="calibre117"/></div>
<div class="CDPAlignCenter1"><br class="title-page-name"/>
Figure 10.5: Input image</div>
<div class="CDPAlignCenter">
<p class="calibre2">Transfer values for the image using the inception model:</p>
<img src="assets/77a148f8-97e1-4f21-9498-5968fdbdbfce.png" class="calibre118"/></div>
<div class="CDPAlignCenter1">Figure 10.6: Transfer values for the input image in Figure 10.3</div>
</div>
<div class="title-page-name">
<pre class="calibre21"><span>plot_transferValues</span><span>(</span><span>i</span><span>=</span><span>17</span><span>)</span></pre></div>
<div class="CDPAlignCenter"><span><br class="title-page-name"/>
<img src="assets/a7e0afb5-7e8e-4566-bfd8-1e8259915cff.png" class="calibre119"/><br class="title-page-name"/></span></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="CDPAlignCenter1">Figure 10.7: Input image</div>
</div>
</div>
</div>
</div>
<p class="calibre2"><span class="calibre10">Transfer values for the image using the inception model:</span></p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignCenter"><br class="title-page-name"/>
<img src="assets/190cc356-b9bd-40b0-b453-b2edde09a99c.png" class="calibre120"/></div>
<div class="CDPAlignCenter1">Figure 10.8: Transfer values for the input image in Figure 10.5</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Analysis of transfer values</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">In this section, we will do some analysis of the transferred values that we just got for the training images. The purpose of this analysis is to see whether these transfer values will be enough for classifying the images that we have in CIFAR-10 or not.</p>
<p class="calibre2">We have 2,048 transfer values for each input image. In order to plot these transfer values and do further analysis on them, we can use dimensionality reduction techniques such as <strong class="calibre13">Principal Component Analysis</strong> (<strong class="calibre13">PCA</strong>) from scikit-learn. We'll reduce the transfer values from 2,048 to 2  to be able to visualize it and see if they will be good features for discriminating between different categories of CIFAR-10:</p>
<pre class="calibre21"><span>from</span> <span>sklearn.decomposition</span> <span>import</span> <span>PCA</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we need to create a PCA object wherein the number of components is only <kbd class="calibre12">2</kbd>:</p>
<pre class="calibre21">pca_obj = PCA(n_components=2)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">It takes a lot of time to reduce the transfer values from 2,048 to 2, so we are going to subset only 3,000 out of the 5,000 images that we have transfer values for:</p>
<pre class="calibre21"><span>subset_transferValues = transfer_values_training[</span><span>0</span><span>:</span><span>3000</span><span>]</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">We need to get the class numbers of these images as well:</p>
</div>
</div>
<pre class="calibre21"><span>cls_integers = testing_cls_integers[</span><span>0</span><span>:</span><span>3000</span><span>]</span></pre>
<div class="title-page-name">
<p class="calibre2">We can double-check our subsetting by printing the shape of the transfer values:</p>
<pre class="calibre21">subset_transferValues.shape</pre>
<p class="calibre2">Output:</p>
<div class="title-page-name">
<pre class="calibre21">(3000, 2048)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we use our PCA object to reduce the transfer values from 2,048 to just 2:</p>
<pre class="calibre21">reduced_transferValues = pca_obj.fit_transform(subset_transferValues)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Now, let's see the output of the PCA reduction process:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">reduced_transferValues.shape</pre>
Output:</div>
</div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">(3000, 2)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">After reducing the dimensionality of the transfer values to only 2, let's plot these values:</p>
<pre class="calibre21"><span>#Importing the color map for plotting each class with different color.<br class="title-page-name"/>import matplotlib.cm as color_map<br class="title-page-name"/><br class="title-page-name"/>def plot_reduced_transferValues(transferValues, cls_integers):<br class="title-page-name"/>    <br class="title-page-name"/>    # Create a color-map with a different color for each class.<br class="title-page-name"/>    c_map = color_map.rainbow(np.linspace(0.0, 1.0, num_classes))<br class="title-page-name"/><br class="title-page-name"/>    # Getting the color for each sample.<br class="title-page-name"/>    colors = c_map[cls_integers]<br class="title-page-name"/><br class="title-page-name"/>    # Getting the x and y values.<br class="title-page-name"/>    x_val = transferValues[:, 0]<br class="title-page-name"/>    y_val = transferValues[:, 1]<br class="title-page-name"/><br class="title-page-name"/>    # Plot the transfer values in a scatter plot<br class="title-page-name"/>    plt.scatter(x_val, y_val, color=colors)<br class="title-page-name"/>    plt.show()<br class="title-page-name"/><br class="title-page-name"/></span></pre>
<p class="calibre2">Here, we are plotting the reduced transfer values of the subset from the training set. We have 10 classes in CIFAR-10, so we are going to plot their corresponding transfer values with different colors. As you can see from the following graph, the transfer values are grouped according to the corresponding class. The overlap between groups is because the reduction process of PCA can't properly separate the transfer values:</p>
</div>
</div>
</div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">plot_reduced_transferValues(reduced_transferValues, cls_integers)</pre>
<div class="title-page-name">
<div class="CDPAlignCenter1">
<p class="calibre121"><img src="assets/665d1102-3dcb-4584-9292-f80f1af46526.png" class="calibre122"/></p>
Figure 10.9: Transfer values reduced using PCA</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">We can do a further analysis on our transfer values using a different dimensionality reduction method called <strong class="calibre13">t-SNE</strong>:</p>
<pre class="calibre21"><span>from</span> <span>sklearn.manifold</span> <span>import</span> <span>TSNE<br class="title-page-name"/></span></pre></div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Again, we'll be reduce our dimensionality of the transfer values, which is 2,048, but this time to 50 values and not 2:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>pca_obj = PCA(n_components=50)<br class="title-page-name"/>transferValues_50d = pca_obj.fit_transform(subset_transferValues)</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we stack the second dimensionality reduction technique and feed the output of the PCA process to it:</p>
<pre class="calibre21">tsne_obj = TSNE(n_components=2)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Finally, we use the reduced values from the PCA method and apply the t-SNE method to it:</p>
</div>
<pre class="calibre21">reduced_transferValues = tsne_obj.fit_transform(transferValues_50d) </pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">And double-check if it has the correct shape:</p>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">reduced_transferValues.shape</pre>
<p class="calibre2">Output:</p>
</div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">(3000, 2)</pre>
<p class="calibre2">Let's plot the reduced transfer values by the t-SNE method. As you can see in the next image, the t-SNE has been able to do better separation of grouped transfer values than the PCA one.</p>
<p class="calibre2">The takeaway from this analysis is that the extracted transfer values we got by feeding our input images to the pre-trained inception model can be used to separate training images into the 10 classes. This separation won't be 100% <span class="calibre10">accurate</span> because of the small overlap in the following graph, but we can get rid of this overlap by doing some fine-tuning on our pre-trained model:</p>
<pre class="calibre21">plot_reduced_transferValues(reduced_transferValues, cls_integers)</pre>
<div class="CDPAlignCenter"><img src="assets/35bdf697-4c8f-4a3d-a228-586343632d6c.png" class="calibre123"/></div>
<div class="CDPAlignCenter1">Figure 10.10: Transfer values reduced using t-SNE</div>
<p class="calibre2">Now we have transfer values extracted from our training images and we know that these values will be able to, to some extent, distinguish between the different classes that CIFAR-10 has. Next, we need to build a linear classifier and feed these transfer values to it to do the actual classification.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model building and training</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignLeft">
<p class="calibre2"><span class="calibre10">So, let's start off by specifying the input placeholder variables that will be fed to our neural network model. The shape of the first input variable (which will contain the extracted transfer values) will be <kbd class="calibre12">[None, transfer_len]</kbd>. The second placeholder variable will hold the actual class labels of the training set in a one-hot vector format:</span></p>
<pre class="calibre21">transferValues_arrLength = inception_model.transfer_len<br class="title-page-name"/>input_values = tf.placeholder(tf.float32, shape=[None, transferValues_arrLength], name='input_values')<br class="title-page-name"/>y_actual = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_actual')</pre></div>
</div>
</div>
<p class="calibre2">We can also get the corresponding integer value of each class from 1 to 10 by defining another placeholder variable:</p>
<pre class="calibre21">y_actual_cls = tf.argmax(y_actual, axis=1)</pre>
<p class="calibre2">Next up, we need to build the actual classification neural network that will take these input placeholders and produce the predicted classes:</p>
<pre class="calibre21"><span>def new_weights(shape):<br class="title-page-name"/>    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))<br class="title-page-name"/><br class="title-page-name"/>def new_biases(length):<br class="title-page-name"/>    return tf.Variable(tf.constant(0.05, shape=[length]))<br class="title-page-name"/><br class="title-page-name"/>def new_fc_layer(input,          # The previous layer.<br class="title-page-name"/>                 num_inputs,     # Num. inputs from prev. layer.<br class="title-page-name"/>                 num_outputs,    # Num. outputs.<br class="title-page-name"/>                 use_relu=True): # Use Rectified Linear Unit (ReLU)?<br class="title-page-name"/><br class="title-page-name"/>    # Create new weights and biases.<br class="title-page-name"/>    weights = new_weights(shape=[num_inputs, num_outputs])<br class="title-page-name"/>    biases = new_biases(length=num_outputs)<br class="title-page-name"/><br class="title-page-name"/>    # Calculate the layer as the matrix multiplication of<br class="title-page-name"/>    # the input and weights, and then add the bias-values.<br class="title-page-name"/>    layer = tf.matmul(input, weights) + biases<br class="title-page-name"/><br class="title-page-name"/>    # Use ReLU?<br class="title-page-name"/>    if use_relu:<br class="title-page-name"/>        layer = tf.nn.relu(layer)<br class="title-page-name"/><br class="title-page-name"/>    return layer<br class="title-page-name"/><br class="title-page-name"/># First fully-connected layer.<br class="title-page-name"/>layer_fc1 = new_fc_layer(input=input_values,<br class="title-page-name"/>                             num_inputs=2048,<br class="title-page-name"/>                             num_outputs=1024,<br class="title-page-name"/>                             use_relu=True)<br class="title-page-name"/><br class="title-page-name"/># Second fully-connected layer.<br class="title-page-name"/>layer_fc2 = new_fc_layer(input=layer_fc1,<br class="title-page-name"/>                             num_inputs=1024,<br class="title-page-name"/>                             num_outputs=num_classes,<br class="title-page-name"/>                             use_relu=False)<br class="title-page-name"/><br class="title-page-name"/># Predicted class-label.<br class="title-page-name"/>y_predicted = tf.nn.softmax(layer_fc2)<br class="title-page-name"/><br class="title-page-name"/># Cross-entropy for the classification of each image.<br class="title-page-name"/>cross_entropy = \<br class="title-page-name"/>    tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,<br class="title-page-name"/>                                                labels=y_actual)<br class="title-page-name"/><br class="title-page-name"/># Loss aka. cost-measure.<br class="title-page-name"/># This is the scalar value that must be minimized.<br class="title-page-name"/>loss = tf.reduce_mean(cross_entropy)<br class="title-page-name"/></span></pre>
<div class="title-page-name">
<p class="calibre2">Then, we need to define an optimization criteria that will be used during the training of the classifier. In this implementation, we will use <kbd class="calibre12">AdamOptimizer</kbd>. The output of this classifier will be an array of 10 probability scores, corresponding to the number of classes that we have in the CIFAR-10 dataset. Then, we are going to apply the <kbd class="calibre12">argmax</kbd> operation over this array to assign the class of the largest score to this input sample:</p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>step = tf.Variable(initial_value=0,<br class="title-page-name"/>                          name='step', trainable=False)<br class="title-page-name"/></span>optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, step)<br class="title-page-name"/>y_predicted_cls = tf.argmax(y_predicted, axis=1)<br class="title-page-name"/>#compare the predicted and true classes<br class="title-page-name"/>correct_prediction = tf.equal(y_predicted_cls, y_actual_cls)<br class="title-page-name"/>#cast the boolean values to fload<br class="title-page-name"/>model_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we need to define a TensorFlow session that will actually execute the graph and then initialize the variables that we defined earlier in this implementation:</p>
<pre class="calibre21"><span>session</span> <span>=</span> <span>tf</span><span>.</span><span>Session</span><span>()<br class="title-page-name"/>session.run(tf.global_variables_initializer())<br class="title-page-name"/></span></pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">In this implementation, we will be using <strong class="calibre13">Stochastic Gradient Descent</strong> (<strong class="calibre13">SGD</strong>), so we need to define a function to randomly generate batches of a particular size from our training set of 50,000 images.</p>
<p class="calibre2">Thus, we are going to define a helper function for generating a random batch from the input training set of the transfer values:</p>
</div>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>#defining the size of the train batch<br class="title-page-name"/>train_batch_size = 64<br class="title-page-name"/><br class="title-page-name"/>#defining a function for randomly selecting a batch of images from the dataset<br class="title-page-name"/>def select_random_batch():<br class="title-page-name"/>    # Number of images (transfer-values) in the training-set.<br class="title-page-name"/>    num_imgs = len(transfer_values_training)<br class="title-page-name"/><br class="title-page-name"/>    # Create a random index.<br class="title-page-name"/>    ind = np.random.choice(num_imgs,<br class="title-page-name"/>                           size=training_batch_size,<br class="title-page-name"/>                           replace=False)<br class="title-page-name"/><br class="title-page-name"/>    # Use the random index to select random x and y-values.<br class="title-page-name"/>    # We use the transfer-values instead of images as x-values.<br class="title-page-name"/>    x_batch = transfer_values_training[ind]<br class="title-page-name"/>    y_batch = trainig_one_hot_labels[ind]<br class="title-page-name"/><br class="title-page-name"/>    return x_batch, y_batch</span></pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Next up, we need to define a helper function to do the actual optimization process, which will refine the weights of the network. It will generate a batch at each iteration and optimize the network based on that batch:</p>
</div>
<pre class="calibre21"><span>def optimize(num_iterations):<br class="title-page-name"/><br class="title-page-name"/>    for i in range(num_iterations):<br class="title-page-name"/>        # Selectin a random batch of images for training<br class="title-page-name"/>        # where the transfer values of the images will be stored in input_batch<br class="title-page-name"/>        # and the actual labels of those batch of images will be stored in y_actual_batch<br class="title-page-name"/>        input_batch, y_actual_batch = select_random_batch()<br class="title-page-name"/><br class="title-page-name"/>        # storing the batch in a dict with the proper names<br class="title-page-name"/>        # such as the input placeholder variables that we define above.<br class="title-page-name"/>        feed_dict = {input_values: input_batch,<br class="title-page-name"/>                           y_actual: y_actual_batch}<br class="title-page-name"/><br class="title-page-name"/>        # Now we call the optimizer of this batch of images<br class="title-page-name"/>        # TensorFlow will automatically feed the values of the dict we created above<br class="title-page-name"/>        # to the model input placeholder variables that we defined above.<br class="title-page-name"/>        i_global, _ = session.run([step, optimizer],<br class="title-page-name"/>                                  feed_dict=feed_dict)<br class="title-page-name"/><br class="title-page-name"/>        # print the accuracy every 100 steps.<br class="title-page-name"/>        if (i_global % 100 == 0) or (i == num_iterations - 1):<br class="title-page-name"/>            # Calculate the accuracy on the training-batch.<br class="title-page-name"/>            batch_accuracy = session.run(model_accuracy,<br class="title-page-name"/>                                    feed_dict=feed_dict)<br class="title-page-name"/><br class="title-page-name"/>            <br class="title-page-name"/>            msg = "Step: {0:&gt;6}, Training Accuracy: {1:&gt;6.1%}"<br class="title-page-name"/>            print(msg.format(i_global, batch_accuracy))</span></pre>
<div class="title-page-name">
<p class="calibre2">We are going to define some helper functions to show the results of the previous neural network and show the confusion matrix of the predicted results as well:</p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>def plot_errors(cls_predicted, cls_correct):<br class="title-page-name"/>    <br class="title-page-name"/>    # cls_predicted is an array of the predicted class-number for<br class="title-page-name"/>    # all images in the test-set.<br class="title-page-name"/><br class="title-page-name"/>    # cls_correct is an array with boolean values to indicate<br class="title-page-name"/>    # whether is the model predicted the correct class or not.<br class="title-page-name"/><br class="title-page-name"/>    # Negate the boolean array.<br class="title-page-name"/>    incorrect = (cls_correct == False)<br class="title-page-name"/>    <br class="title-page-name"/>    # Get the images from the test-set that have been<br class="title-page-name"/>    # incorrectly classified. <br class="title-page-name"/>    incorrectly_classified_images = testing_images[incorrect]<br class="title-page-name"/>    <br class="title-page-name"/>    # Get the predicted classes for those images.<br class="title-page-name"/>    cls_predicted = cls_predicted[incorrect]<br class="title-page-name"/><br class="title-page-name"/>    # Get the true classes for those images.<br class="title-page-name"/>    true_class = testing_cls_integers[incorrect]<br class="title-page-name"/><br class="title-page-name"/>    n = min(9, len(incorrectly_classified_images))<br class="title-page-name"/>    <br class="title-page-name"/>    <br class="title-page-name"/>    # Plot the first n images.<br class="title-page-name"/>    plot_imgs(imgs=incorrectly_classified_images[0:n],<br class="title-page-name"/>                true_class=true_class[0:n],<br class="title-page-name"/>                predicted_class=cls_predicted[0:n])</span></pre>
<p class="calibre2">Next, we need to define the helper function for plotting the confusion matrix:</p>
<pre class="calibre21"><span>from sklearn.metrics import confusion_matrix<br class="title-page-name"/><br class="title-page-name"/>def plot_confusionMatrix(cls_predicted):<br class="title-page-name"/><br class="title-page-name"/>    # cls_predicted array of all the predicted <br class="title-page-name"/>    # classes numbers in the test.<br class="title-page-name"/><br class="title-page-name"/>    # Call the confucion matrix of sklearn<br class="title-page-name"/>    cm = confusion_matrix(y_true=testing_cls_integers,<br class="title-page-name"/>                          y_pred=cls_predicted)<br class="title-page-name"/><br class="title-page-name"/>    # Printing the confusion matrix<br class="title-page-name"/>    for i in range(num_classes):<br class="title-page-name"/>        # Append the class-name to each line.<br class="title-page-name"/>        class_name = "({}) {}".format(i, class_names[i])<br class="title-page-name"/>        print(cm[i, :], class_name)<br class="title-page-name"/><br class="title-page-name"/>    # labeling each column of the confusion matrix with the class number<br class="title-page-name"/>    cls_numbers = [" ({0})".format(i) for i in range(num_classes)]<br class="title-page-name"/>    print("".join(cls_numbers))</span></pre>
<p class="calibre2">Also, we are going to define another helper function to run the trained classifier over the test set and measure the accuracy of the trained model over the test set:</p>
<pre class="calibre21"><span># Split the data-set in batches of this size to limit RAM usage.<br class="title-page-name"/>batch_size = 128<br class="title-page-name"/><br class="title-page-name"/>def predict_class(transferValues, labels, cls_true):<br class="title-page-name"/>    <br class="title-page-name"/>    # Number of images.<br class="title-page-name"/>    num_imgs = len(transferValues)<br class="title-page-name"/><br class="title-page-name"/>    # Allocate an array for the predicted classes which<br class="title-page-name"/>    # will be calculated in batches and filled into this array.<br class="title-page-name"/>    cls_predicted = np.zeros(shape=num_imgs, dtype=np.int)<br class="title-page-name"/><br class="title-page-name"/>    # Now calculate the predicted classes for the batches.<br class="title-page-name"/>    # We will just iterate through all the batches.<br class="title-page-name"/>    # There might be a more clever and Pythonic way of doing this.<br class="title-page-name"/><br class="title-page-name"/>    # The starting index for the next batch is denoted i.<br class="title-page-name"/>    i = 0<br class="title-page-name"/><br class="title-page-name"/>    while i &lt; num_imgs:<br class="title-page-name"/>        # The ending index for the next batch is denoted j.<br class="title-page-name"/>        j = min(i + batch_size, num_imgs)<br class="title-page-name"/><br class="title-page-name"/>        # Create a feed-dict with the images and labels<br class="title-page-name"/>        # between index i and j.<br class="title-page-name"/>        feed_dict = {input_values: transferValues[i:j],<br class="title-page-name"/>                     y_actual: labels[i:j]}<br class="title-page-name"/><br class="title-page-name"/>        # Calculate the predicted class using TensorFlow.<br class="title-page-name"/>        cls_predicted[i:j] = session.run(y_predicted_cls, feed_dict=feed_dict)<br class="title-page-name"/><br class="title-page-name"/>        # Set the start-index for the next batch to the<br class="title-page-name"/>        # end-index of the current batch.<br class="title-page-name"/>        i = j<br class="title-page-name"/>        <br class="title-page-name"/>    # Create a boolean array whether each image is correctly classified.<br class="title-page-name"/>    correct = [a == p for a, p in zip(cls_true, cls_predicted)]<br class="title-page-name"/><br class="title-page-name"/>    return correct, cls_predicted<br class="title-page-name"/><br class="title-page-name"/></span>#Calling the above function making the predictions for the test<br class="title-page-name"/><br class="title-page-name"/>def<span> </span><span>predict_cls_test</span><span>():<br class="title-page-name"/></span>    <span>return</span><span> </span><span>predict_class</span><span>(</span><span>transferValues</span><span> </span><span>=</span><span> </span><span>transfer_values_test</span><span>,<br class="title-page-name"/></span>                       <span>labels</span><span> </span><span>=</span><span> </span><span>labels_test</span><span>,<br class="title-page-name"/></span>                       <span>cls_true</span><span> </span><span>=</span><span> </span><span>cls_test</span><span>)<br class="title-page-name"/><br class="title-page-name"/></span>def classification_accuracy(correct):<br class="title-page-name"/>    # When averaging a boolean array, False means 0 and True means 1.<br class="title-page-name"/>    # So we are calculating: number of True / len(correct) which is<br class="title-page-name"/>    # the same as the classification accuracy.<br class="title-page-name"/><br class="title-page-name"/>    # Return the classification accuracy<br class="title-page-name"/>    # and the number of correct classifications.<br class="title-page-name"/>    return np.mean(correct), np.sum(correct)<br class="title-page-name"/><br class="title-page-name"/>def test_accuracy(show_example_errors=False,<br class="title-page-name"/>                        show_confusion_matrix=False):<br class="title-page-name"/><br class="title-page-name"/>    # For all the images in the test-set,<br class="title-page-name"/>    # calculate the predicted classes and whether they are correct.<br class="title-page-name"/>    correct, cls_pred = predict_class_test()<br class="title-page-name"/>    <br class="title-page-name"/>    # Classification accuracypredict_class_test and the number of correct classifications.<br class="title-page-name"/>    accuracy, num_correct = classification_accuracy(correct)<br class="title-page-name"/>    <br class="title-page-name"/>    # Number of images being classified.<br class="title-page-name"/>    num_images = len(correct)<br class="title-page-name"/><br class="title-page-name"/>    # Print the accuracy.<br class="title-page-name"/>    msg = "Test set accuracy: {0:.1%} ({1} / {2})"<br class="title-page-name"/>    print(msg.format(accuracy, num_correct, num_images))<br class="title-page-name"/><br class="title-page-name"/>    # Plot some examples of mis-classifications, if desired.<br class="title-page-name"/>    if show_example_errors:<br class="title-page-name"/>        print("Example errors:")<br class="title-page-name"/>        plot_errors(cls_predicted=cls_pred, cls_correct=correct)<br class="title-page-name"/><br class="title-page-name"/>    # Plot the confusion matrix, if desired.<br class="title-page-name"/>    if show_confusion_matrix:<br class="title-page-name"/>        print("Confusion Matrix:")<br class="title-page-name"/>        plot_confusionMatrix(cls_predicted=cls_pred)</pre>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">Let's see the performance of the previous neural network model before doing any optimization:</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>test_accuracy(show_example_errors=True,<br class="title-page-name"/>                    show_confusion_matrix=True)<br class="title-page-name"/><br class="title-page-name"/></span>Accuracy on Test-Set: 9.4% (939 / 10000)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2">As you can see, the performance of the network is very low, but it will get better after doing some optimization based on the optimization criteria that we already defined. So we are going to run the optimizer for 10,000 iterations and test the model accuracy after that:</p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>optimize</span><span>(</span><span>num_iterations</span><span>=</span><span>10000</span><span>)<br class="title-page-name"/></span>test_accuracy(show_example_errors=True,<br class="title-page-name"/>                           show_confusion_matrix=True)<br class="title-page-name"/>Accuracy on Test-Set: 90.7% (9069 / 10000)<br class="title-page-name"/>Example errors:</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignCenter"><img src="assets/125c29c9-437c-4a01-be7d-f3769cc2940e.png" class="calibre124"/></div>
<div class="CDPAlignCenter1">Figure 10.11: Some misclassified images from the test set</div>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="CDPAlignLeft">
<pre class="calibre21">Confusion Matrix:
[926   6  13   2   3   0   1   1  29  19] (0) airplane
[  9 921   2   5   0   1   1   1   2  58] (1) automobile
[ 18   1 883  31  32   4  22   5   1   3] (2) bird
[  7   2  19 855  23  57  24   9   2   2] (3) cat
[  5   0  21  25 896   4  24  22   2   1] (4) deer
[  2   0  12  97  18 843  10  15   1   2] (5) dog
[  2   1  16  17  17   4 940   1   2   0] (6) frog
[  8   0  10  19  28  14   1 914   2   4] (7) horse
[ 42   6   1   4   1   0   2   0 932  12] (8) ship
[  6  19   2   2   1   0   1   1   9 959] (9) truck
 (0) (1) (2) (3) (4) (5) (6) (7) (8) (9)</pre>
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2"><span class="calibre10">To wrap this up, we are going to close the opened sessions:</span></p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span>model.close()</span>
<span>session.close()</span></pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this chapter, we introduced one of the most widely used best practices of deep learning. TL is a very exciting tool that you can use to get deep learning architectures to learn from your small dataset, but make sure you use it in the right way.</p>
<p class="calibre2">Next up, we are going to introduce a widely used deep learning architecture for natural language processing. These recurrent-type architectures have achieved a breakthrough in most NLP domains: machine translation, speech recognition, language modeling, and sentiment analysis.</p>


            </article>

            
        </section>
    </body></html>