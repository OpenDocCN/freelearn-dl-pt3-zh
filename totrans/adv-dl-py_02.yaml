- en: The Nuts and Bolts of Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll discuss some of the intricacies of neural networks (**NNs**)—the
    cornerstone of **deep learning** (**DL**). We'll talk about their mathematical
    apparatus, structure, and training. Our main goal is to provide you with a systematic understanding
    of NNs. Often, we approach them from a computer science perspective—as a machine
    learning (**ML**) algorithm (or even a special entity) composed of a number of
    different steps/components. We gain our intuition by thinking in terms of neurons,
    layers, and so on (at least I did this when I first learned about this field).
    This is a perfectly valid way to do things and we can still do impressive things
    at this level of understanding. Perhaps this is not the correct approach, though.
  prefs: []
  type: TYPE_NORMAL
- en: NNs have solid mathematical foundations and if we approach them from this point
    of view, we'll be able to define and understand them in a more fundamental and
    elegant way. Therefore, in this chapter, we'll try to underscore the analogy between
    NNs from mathematical and computer science points of view. If you are already
    familiar with these topics, you can skip this chapter. Still, I hope that you'll
    find some interesting bits you didn't know about already (we'll do our best to
    keep this chapter interesting!).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The mathematical apparatus of NNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A short introduction to NNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training NNs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mathematical apparatus of NNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the next few sections, we'll discuss the mathematical branches related to
    NNs. Once we've done this, we'll connect them to NNs themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Linear algebra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algebra deals with linear equations such as [![](img/6f58b451-029b-4567-901b-7d8cee5287f8.png) ]and
    linear transformations (or linear functions) and their representations, such as
    matrices and vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear algebra identifies the following mathematical objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalars**: A single number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vectors**: A one-dimensional array of numbers (or components). Each component
    of the array has an index. In literature, we will see vectors denoted either with
    a superscript arrow ([![](img/12778eab-f899-4ef1-86a4-963419135aae.png)]) or in
    bold (**x**). The following is an example of a vector:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/6081dcdb-46c7-42cc-96ac-9ca33280b3ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Throughout this book, we'll mostly use the bold (**x**) graph notations. But
    in some instances, we'll use formulas from different sources and we'll try to
    retain their original notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can visually represent an *n*-dimensional vector as the coordinates of a
    point in an *n*-dimensional Euclidean space, [![](img/d51dca7b-23f1-4beb-8870-7c33c790cae0.png)] (equivalent
    to a coordinate system). In this case, the vector is referred to as Euclidean
    and each vector component represents the coordinate along the corresponding axis,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b7d4b80-53be-48f8-94b6-734fc3067210.png)'
  prefs: []
  type: TYPE_IMG
- en: Vector representation in [![](img/0d21b02f-f4ac-400c-9389-ec8cf53ab570.png)] space
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the Euclidean vector is more than just a point and we can also represent
    it with the following two properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Magnitude** (or **length**) is a generalization of the Pythagorean theorem
    for an *n*-dimensional space:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/7858b8a3-ac6c-4d81-84f7-bea53f11c884.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Direction** is the angle of the vector along each axis of the vector space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matrices**: This is a two-dimensional array of numbers. Each element is identified
    by two indices (row and column). A matrix is usually denoted with a bold capital
    letter; for example, **A**. Each matrix element is denoted with the small matrix
    letter and a subscript index; for example, *a[ij]*. Let''s look at an example
    of the matrix notation in the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/95cc7e76-7279-4ffd-840e-7c01ea75404b.png)'
  prefs: []
  type: TYPE_IMG
- en: We can represent a vector as a single-column *n×1* matrix (referred to as a
    column matrix) or a single -ow *1×n* matrix (referred to as a row matrix).
  prefs: []
  type: TYPE_NORMAL
- en: '**Tensors**: Before we explain them, we have to start with a disclaimer. Tensors
    originally come from mathematics and physics, where they have existed long before
    we started using them in ML. The tensor definition in these fields differs from
    the ML one. For the purposes of this book, we''ll only consider tensors in the
    ML context. Here, a tensor is a multi-dimensional array with the following properties:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rank**: Indicates the number of array dimensions. For example, a tensor of
    rank 2 is a matrix, a tensor of rank 1 is a vector, and a tensor of rank 0 is
    a scalar. However, the tensor has no limit on the number of dimensions. Indeed,
    some types of NNs use tensors of rank 4.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shape**: The size of each dimension.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The data type** of the tensor elements. These can vary between libraries,
    but typically include 16-, 32-, and 64-bit float and 8-, 16-, 32-, and 64-bit
    integers.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Contemporary DL libraries such as TensorFlow and PyTorch use tensors as their
    main data structure.
  prefs: []
  type: TYPE_NORMAL
- en: You can find a thorough discussion on the nature of tensors here: [https://stats.stackexchange.com/questions/198061/why-the-sudden-fascination-with-tensors](https://stats.stackexchange.com/questions/198061/why-the-sudden-fascination-with-tensors).
    You can also check the TensorFlow ([https://www.tensorflow.org/guide/tensors](https://www.tensorflow.org/guide/tensors))
    and PyTorch ([https://pytorch.org/docs/stable/tensors.html](https://pytorch.org/docs/stable/tensors.html))
    tensor definitions.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've introduced the types of objects in linear algebra, in the next
    section, we'll discuss some operations that can be applied to them.
  prefs: []
  type: TYPE_NORMAL
- en: Vector and matrix operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll discuss the vector and matrix operations that are relevant
    to NNs. Let''s start:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Vector addition** is the operation of adding two or more vectors together
    into an output vector sum. The output is another vector and is computed with the
    following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/0f5341c5-fb2c-45f4-b0e0-75306d43a081.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The **dot** (**or scalar**) **product** takes two vectors and outputs a scalar
    value. We can compute the dot product with the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/dcfaa2c5-6467-44b6-87b0-69669e7d4f4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, |*a*| and |*b*| are the vector magnitudes and θ is the angle between
    the two vectors. Let''s assume that the two vectors are *n*-dimensional and that
    their components are *a[1]*, *b[1]*, *a[2]*, *b[2]*, and so on. Here, the preceding
    formula is equivalent to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46537fc8-349f-4046-9417-0543b0524012.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The dot product of two two-dimensional vectors, **a** and **b**, is illustrated
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0922a3d2-af6c-4c3b-bcbe-df8ca2fbbdd4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The dot product of vectors. Top: vector components; Bottom: dot product of
    the two vectors'
  prefs: []
  type: TYPE_NORMAL
- en: The dot product acts as a kind of similarity measure between the two vectors—if
    the angle θ between the two vectors is small (the vectors have similar directions),
    then their dot product will be higher because of [![](img/2020afd0-3989-43cc-a5d2-d7bdcfb9f1db.png)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Following this idea, we can define a **cosine similarity** between two vectors
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f82ad3d3-1446-4ef6-af18-997490b7eca9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The **cross** (**or vector**)** product** takes two vectors and outputs another
    vector, which is perpendicular to both initial vectors. We can compute the magnitude
    of the cross product output vector with the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/22fef02f-a59c-4443-ba72-a4ee23e950d3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following diagram shows an example of a cross product between two two-dimensional
    vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/78e303b7-c5ed-4a04-b205-36d8a4dbb1cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Cross product of two two-dimensional vectors
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, the output vector is perpendicular to the input
    vectors, which also means that the vector is normal to the plane containing them.
    The magnitude of the output vector is equal to the area of the parallelogram with
    the vectors **a** and **b** for sides (denoted in the preceding diagram).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also define a vector through **vector space**, which is a collection
    of objects (in our case, vectors) that can be added together and multiplied by
    a scalar value. The vector space will allow us to define a **linear transformation**
    as a function, *f*, which can transform each vector (point) of vector space, ***V***,
    into a vector (point) of another vector space, ***W*** : [![](img/5c14d1cd-c51d-4987-9a10-9b12d667bf94.png)].
    *f* has to satisfy the following requirements for any two vectors, [![](img/e192b6b7-1389-41ae-a87e-3b72678b2572.png)]:'
  prefs: []
  type: TYPE_NORMAL
- en: Additivity: [![](img/7244c5ff-977f-4d71-aa10-073bfcb5bdef.png)]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Homogeneity: [![](img/64244355-8911-4913-9b28-54a739f130b8.png)], where *c* is
    a scalar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matrix transpose**: Here, we flip the matrix along its main diagonal (the
    main diagonal is the collection of matrix elements, *a[ij]*, where *i = j*). The
    transpose operation is denoted with superscript, ^(![](img/197f61f9-0945-4ea1-bb90-ce72f751af65.png)).
    To clarify, the cell [![](img/7c130bda-b7e7-4a0d-a965-0cc338c6cb57.png)] of ![](img/57dd28ea-d409-49c2-8032-9fad6261d4c7.png) is
    equal to the cell [![](img/d40013ee-5d21-4cee-83f0-781b154ed773.png)] of [![](img/6c02e597-82aa-4af4-8811-f17e6164c93a.png)]:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/47f10040-ad04-4cf0-bd8e-eb26768f9d0b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The transpose of an *m×n* matrix is an *n×m* matrix. The following are a few
    transpose examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f70469ff-c9d5-4f61-b017-8bebbc0e8abc.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Matrix-scalar multiplication** is the multiplication of a matrix by a scalar
    value. In the following example, [![](img/4931bab7-9012-44c1-a6a0-5708f01cc23a.png)] is
    a scalar:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/ece33a00-58a4-462e-89f6-5249e8f3e5f9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Matrix-matrix addition** is the element-wise addition of one matrix with
    another. For this operation, both matrices must have the same size. The following
    is an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/8790d323-7f9e-4c7b-bf79-bedba3f4a110.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Matrix-vector multiplication** is the multiplication of a matrix by a vector.
    For this operation to be valid, the number of matrix columns must be equal to
    the vector length. The result of multiplying the *m×n* matrix and an *n*-dimensional
    vector is an *m*-dimensional vector. The following is an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/335d2d08-a422-4d14-84fc-2ccb407decf5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can think of each row of the matrix as a separate *n*-dimensional vector. Here,
    each element of the output vector is the dot product between the corresponding
    matrix row and **x**. The following is a numerical example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a390abf7-9e62-4fb5-a511-ca25849b9306.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Matrix multiplication** is the multiplication of one matrix with another.
    To be valid, the number of columns of the first matrix has to be equal to the
    number of rows of the second (this is a non-commutative operation). We can think
    of this operation as multiple matrix-vector multiplications, where each column
    of the second matrix is one vector. The result of an *m×n* matrix multiplied by
    an *n×p* matrix is an *m×p* matrix. The following is an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/59628c27-e81f-4945-b00a-b3555d20046e.png)'
  prefs: []
  type: TYPE_IMG
- en: If we consider two vectors as row matrices, we can represent a vector dot product
    as matrix multiplication, that is, ![](img/b94c318e-0c3f-4c68-be0a-bec4d81fc96b.png).
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our introduction to linear algebra. In the next section, we'll
    introduce the probability theory.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll discuss some of the aspects of probability and statistics
    that are relevant to NNs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by introducing the concept of a **statistical experiment**, which
    has the following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: Consists of multiple independent trials.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The outcome of each trial is non-deterministic; that is, it's determined by
    chance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has more than one possible outcome. These outcomes are known as **events**
    (we'll also discuss events in the context of sets in the following section).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the possible outcomes of the experiment are known in advance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One example of a statistical experiment is a coin toss, which has two possible
    outcomes—heads or tails. Another example is a dice throw with six possible outcomes:
    1, 2, 3, 4, 5, and 6.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll define **probability** as the likelihood that some event, **e**, would
    occur and we'll denote it with **P(e)**. The probability is a number in the range
    of [0, 1], where 0 indicates that the event cannot occur and 1 indicates that
    it will always occur. If *P(e) = 0.5*, there is a 50-50 chance the event would
    occur, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways we can approach probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Theoretical**: The event we''re interested in compared to the total number
    of possible events. All the events are equally as likely:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/49b6defa-690f-4e59-a266-fd4d9f6b2c1f.png)'
  prefs: []
  type: TYPE_IMG
- en: To understand this, let's use the coin toss example with two possible outcomes.
    The theoretical probability of each possible outcome is P(heads) = P(tails) =
    1/2\. The theoretical probability for each of the sides of a dice throw would
    be 1/6.
  prefs: []
  type: TYPE_NORMAL
- en: '**Empirical**: This is the number of times an event we''re interested in occurs
    compared to the total number of trials:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f0d0450e-9cfc-4b25-b874-eef2ccc77de7.png)'
  prefs: []
  type: TYPE_IMG
- en: The result of the experiment may show that the events aren't equally likely.
    For example, let's say that we toss a coin 100 times and that we observe heads
    56 times. Here, the empirical probability for heads is P(heads) = 56 / 100 = 0.56\.
    The higher the number of trials, the more accurate the calculated probability
    is (this is known as the law of large numbers).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss probability in the context of sets.
  prefs: []
  type: TYPE_NORMAL
- en: Probability and sets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The collection of all possible outcomes (events) of an experiment is called, **sample
    space**. We can think of the sample space as a mathematical **set. **It is usually
    denoted with a capital letter and we can list all the set outcomes with {} (the
    same as Python sets). For example, the sample space of coin toss events is S[c] =
    {heads, tails}, while for dice rows it's S[d] = {1, 2, 3, 4, 5, 6}. A single outcome
    of the set (for example, heads) is called a **sample point**. An **e****vent** is
    an outcome (sample point) or a combination of outcomes (subset) of the sample
    space. An example of a combined event is for the dice to land on an even number,
    that is, {2, 4, 6}.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume that we have a sample space S = {1, 2, 3, 4, 5} and two subsets
    (events) A = {1, 2, 3} and B = {3, 4, 5}. Here, we can do the following operations
    with them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intersection**: The result is a new set that contains only the elements found
    in both sets:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9750f3fa-904e-4d19-8929-29b91192e4f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Sets whose intersections are empty sets {} are **disjoint**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Complement**: The result is a new set that contains all the elements of the
    sample space that aren''t included in a given set:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9faf6393-251d-4453-9452-2a4a88467b1b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Union:** The result is a new set that contains the elements that can be found
    in either set:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/a0d19f6d-0d13-44f8-99e9-4b63f679d7b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following Venn diagrams illustrate these different set relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fa553edf-4bc6-447f-970b-1fb73643b7cd.png)'
  prefs: []
  type: TYPE_IMG
- en: Venn diagrams of the possible set relationships
  prefs: []
  type: TYPE_NORMAL
- en: 'We can transfer the set properties to events and their probabilities. We''ll
    assume that the events are **independent**—the occurrence of one event doesn''t
    affect the probability of the occurrence of another. For example, the outcomes
    of the different coin tosses are independent of one another. That being said,
    let''s learn how to translate the set operations in the events domain:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The intersection of two events is a subset of the outcomes, contained in both
    events. The probability of the intersection is called **joint probability** and
    is computed via the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/4de15857-c77b-4a52-84e0-53c12fdc63d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's say that we want to compute the probability of a card being red (either
    hearts or diamonds) and a Jack. The probability for red is *P(red) = 26/52 = 1/2*.
    The probability for getting a Jack is *P(Jack) = 4/52 = 1/13*. Therefore, the
    joint probability is *P(red, Jack) = (1/2) * (1/13) = 1/26*. In this example,
    we assumed that the two events are independent. However, the two events occur
    at the same time (we draw a single card). Had they occurred successively, for
    example, two card draws, where one is a Jack and the other is red, we would enter
    the realm of conditional probability. This joint probability is also denoted as
    P(A, B) or P(AB).
  prefs: []
  type: TYPE_NORMAL
- en: The probability of the occurrence of a single event P(A) is also known as **marginal
    probability **(as opposed to joint probability).
  prefs: []
  type: TYPE_NORMAL
- en: 'Two events are disjoint (or **mutually exclusive**) if they don''t share any
    outcomes. That is, their respective sample space subsets are disjoint. For example,
    the events of odd or even dice rows are disjoint. The following is true for the
    probability of disjoint events:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The joint probability of disjoint events (the probability for these events to
    occur simultaneously) is P(A∩B) = 0.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sum of the probabilities of disjoint events is [![](img/82424ff7-15fe-4381-a40a-034f8c46b5d0.png)].
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the subsets of multiple events contain the whole sample space between themselves,
    they are **jointly exhaustive**. Events A and B from the preceding example are
    jointly exhaustive because, together, they fill up the whole sample space (1 through
    5). The following is true for the probability of jointly exhaustive events:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f27611cd-f808-40d6-a0c4-cc09f3d0f911.png)'
  prefs: []
  type: TYPE_IMG
- en: If we only have two events that are disjoint and jointly exhaustive at the same
    time, the events are **complement**. For example, odd and even dice throw events
    are complement.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll refer to outcomes coming from either A or B (not necessarily in both)
    as the union of A and B. The probability of this union is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/a7739b11-08b3-46e4-80a9-bc940ada1c1c.png)'
  prefs: []
  type: TYPE_IMG
- en: So far, we've discussed independent events. In the next section, we'll focus
    on dependent ones.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional probability and the Bayes rule
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the occurrence of event A changes the probability of the occurrence of event
    B, where A occurs before B, then the two are dependent. To illustrate this concept,
    let's imagine that we draw multiple cards sequentially from the deck. When the
    deck is full, the probability to draw hearts is *P(hearts) = 13/52 = 0.25*. But
    once we've drawn the first card, the probability to pick hearts on the second
    turn changes. Now, we only have 51 cards and one less heart. We'll call the probability
    of the second draw conditional probability and we'll denote it with P(B|A). This
    is the probability of event B (second draw), given that event A has occurred (first
    draw). To continue with our example, the probability of picking hearts on the
    second draw becomes *P(hearts[2]|hearts[1]) = 12/51 = 0.235*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can extend the joint probability formula (introduced in the preceding
    section) in terms of dependent events. The formula is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ccab1c9-ab2d-4913-a6a3-72e19662ec07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, the preceding equation is just a special case for two events. We can
    extend this further for multiple events, A[1], A[2], ..., A[n]. This new generic
    formula is known as the chain rule of probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e7799cb-67c2-454f-adc4-d50a7d9ef1dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, the chain rule for three events is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e68d065f-658a-4e69-af1d-e453133b3156.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also derive the formula for the conditional probability itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d06c169-d129-491f-93ba-dbaefbd62344.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This formula makes sense for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**P(A ∩ B)** states that we''re interested in the occurrences of B, given that
    A has already occurred. In other words, we''re interested in the joint occurrence
    of the events, hence the joint probability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**P(A)** states that we''re interested only in the subset of outcomes when
    event A has occurred. We already know that A has occurred and therefore we restrict
    our observations to these outcomes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following holds true for dependent events:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ca82fc58-9f78-4a59-b73c-00851157a8c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using this equation, we can replace the value of P(A∩B) in the conditional
    probability formula to come up with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97ce1d41-4f63-4420-ba47-2c307235e44d.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding formula gives us the ability to compute the conditional probability,
    P(B|A), if we know the opposite conditional probability, P(B|A). This equation
    is known as the **Bayes rule** and is frequently used in ML. In the context of
    Bayesian statistics, P(A) and P(B|A) are known as prior and posterior probability,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Bayes rule can be illustrated in the realm of medical testing. Let''s say
    that we want to determine whether a patient has a particular disease or not. We
    conduct a medical test, which comes out positive. But this doesn''t necessarily
    mean that the patient has the disease. Most tests have a reliability value, which
    is the percentage chance of the test being positive when administered on people
    with a particular disease. Using this information, we''ll apply the Bayes rule
    to compute the actual probability of the patient having the disease, given that
    the test is positive. We get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f66a8ac-fd8c-4842-8d7a-664b37690ab0.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *P(has disease)* is the general probability of the disease without any
    prior conditions. Think of this as the probability of the disease in the general
    population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s make some assumptions about the disease and the test''s accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The test is 98% reliable, that is, if the test is positive, it will also be
    positive in 98% of cases: *P(test=positive|has disease)* = 0.98.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Only 2% of the people under 50 have this kind of disease: *P(has disease)*
    = 0.02.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The test that''s administered on people under 50 is positive only for 3.9%
    of the population: *P(test=positive)* = 0.039.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can ask the following question: if a test is 98% accurate for cancer and
    if a 45-year-old person took the test, which turned out to be positive, what is
    the probability that they may have the disease? Using the preceding formula, we
    can calculate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ba37462-d1ef-4608-bea0-3f1ab81484c8.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next section, we'll go beyond probabilities and we'll discuss random
    variables and probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Random variables and probability distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In statistics, we define a variable as an attribute that describes a given entity.
    The value of the attribute can vary between entities. For example, we can describe
    the height of a person with a variable, which would differ for different people.
    But let's say that we take the height measurement of the same person multiple
    times. We can expect to obtain slightly different values each time due to some
    random factors, such as the person's pose or inaccuracy in our own measurements.
    Therefore, the value of the variable height would differ, despite the fact that
    we are measuring the same thing. To account for these changes, we'll introduce
    random variables. These are variables whose values are determined by some random
    event. Unlike regular variables, a random variable can take multiple values and
    each of these values is associated with some probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of random variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Discrete**, which can take distinct separate values. For example, the number
    of goals in a football match is a discrete variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous**, which can take any value within a given interval. For example,
    a height measurement is a continuous variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Random variables are denoted with capital letters and the probability of a
    certain value *x* for random variable *X* is denoted with either *P(X = x)* or
    *p(x)*. The collection of probabilities for each possible value of a random variable
    is called the **probability distribution**. Depending on the variable type, we
    have two types of probability distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Probability mass function** (**PMF**) for discrete variables. The following
    is an example of a PMF. The *x *axis shows the possible values and the *y *axis shows
    the probability for each value:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/b624542d-ad4c-4de3-b8cd-705432da3571.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a PMF
  prefs: []
  type: TYPE_NORMAL
- en: The PMF is only defined for the possible values of the random variable. All
    the values of a PMF are non-negative and their sum is 1\. That is, the events
    of the PMF are mutually exclusive and jointly exhaustive. We'll denote PMF with
    P(X), where X is the random variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Probability density function** (**PDF**) for continuous variables. Unlike
    PMF, the PDF is uninterrupted (defined for every possible value) in the interval
    between two values, thereby reflecting the nature of the continuous variable.
    The following is an example of a PDF:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9af07727-a3be-4e97-becd-2e28cf781e10.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a PDF
  prefs: []
  type: TYPE_NORMAL
- en: In the PDF, the probability is computed for a value interval and is given by
    the surface area under the curve, enclosed by that interval (this is the marked
    area in the preceding diagram). The total area under the curve is 1. We'll denote
    PDF with *f[X]*, where X is the random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s focus on some of the properties of random variables:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **mean** (or **expected value**) is the expected outcome of an experiment
    over many observations. We''ll denote it with μ or [![](img/0e27cda7-f298-4638-bb45-baf9d20f900d.png)].
    For a discrete variable, the mean is the weighted sum of all possible values,
    multiplied by their probabilities:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/c0657eab-a8d9-4164-a902-80831922cf56.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's use the preceding discrete variable example as an example, where we defined
    a random variable with six possible values (0, 1, 2, 3, 4, 5) and their respective
    probabilities (0.1, 0.2, 0.3, 0.2, 0.1, 0.1). Here, the mean is *μ = 0*0.1 + 1*0.2
    + 2*0.3 + 3*0.2 + 4*0.1 + 5*0.1 = 2.3.*
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean for a continuous variable is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/795d34b0-3db0-4bb7-b329-ba6fb5340ce0.png)'
  prefs: []
  type: TYPE_IMG
- en: While with a discrete variable we can think of the PMF as a lookup table, the
    PDF may be more complex (an actual function or equation), which is why there's
    different notation between the two. We won't go into further details about the
    mean of continuous variables.
  prefs: []
  type: TYPE_NORMAL
- en: '**Variance** is defined as the expected value of the squared deviation from
    the mean, μ, of a random variable:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f8904fe0-0265-47a6-a282-560d4650cef1.png)'
  prefs: []
  type: TYPE_IMG
- en: In other words, the variance measures how the values of a random variable differ
    from its mean value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The variance of a discrete random variable is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5af276dd-d6ad-45d1-9d18-6e96bde7e162.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's use the preceding example, where we calculated the mean value to be 2.3\.
    The new variance would be *Var(X)* = *(0 - 2.3)² * 0 + (1 - 2.3)² *** 1 + ...
    + (5- 2.3)² * 5 = 2.01*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The variance of a continuous variable is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab614d73-6d72-434e-bb88-e4aaca8c203c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The **standard deviation** measures the degree to which the values of the random
    variable differ from the expected value. If this definition sounds similar to
    variance, it''s because it is. In fact, the formula for standard deviation is
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/aa212f96-53f9-4902-b157-a7794dae687a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also define the variance in terms of standard deviation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95089bd7-c563-4642-9f9e-9ffd955b814c.png)'
  prefs: []
  type: TYPE_IMG
- en: The difference between standard deviation and variance is that the standard
    deviation is expressed in the same units as the mean value, while the variance
    uses squared units.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we defined what a probability distribution is. Next, let's
    discuss different types of probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Probability distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll start with the **binomial distribution** for discrete variables in binomial
    experiments. A binomial experiment has only two possible outcomes: success or
    failure. It also satisfies the following requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: Each trial is independent of the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability of success is always the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of a binomial experiment is the coin toss experiment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s assume that the experiment consists of *n* trials. *x* of them
    are successful, while the probability of success at each trial is *p*. The formula
    for a binomial PMF of variable X (not to be confused with *x*) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ecbfa31a-d56f-4dcb-9901-471b1326841d.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, [![](img/54708b4a-3bf1-4a19-9f3b-5c06c5cd6035.png)] is the binomial coefficient.
    This is the number of combinations of *x* successful trials, which we can select
    from the *n* total trials. If *n=1*, then we have a special case of binomial distribution
    called **Bernoulli distribution**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s discuss the normal (or Gaussian) distribution for continuous variables, which
    closely approximates many natural processes. The normal distribution is defined
    with the following exponential PDF formula, known as normal equation (one of the
    most popular notations):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27332c0a-c327-44ac-a6de-6fc4308703ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *x* is the value of the random variable, *μ* is the mean, *σ* is the
    standard deviation, and *σ²* is the variance. The preceding equation produces
    a bell-shaped curve, which is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/299a86be-c077-4a2e-8565-9e5bd48b9636.png)'
  prefs: []
  type: TYPE_IMG
- en: Normal distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss some of the properties of the normal distribution, in no particular
    order:'
  prefs: []
  type: TYPE_NORMAL
- en: The curve is symmetric along its center, which is also the maximum value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The shape and location of the curve are fully described by the mean and standard
    deviation, where we have the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The center of the curve (and its maximum value) is equal to the mean. That is,
    the mean determines the location of the curve along the *x* axis.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The width of the curve is determined by the standard deviation.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following diagram, we can see examples of normal distributions with
    different *μ* and *σ* values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/966244d3-6838-4232-8d95-efcc2db6718b.png)'
  prefs: []
  type: TYPE_IMG
- en: Examples of normal distributions with different *μ* and *σ* values
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution approaches 0 toward +/- infinity, but it never becomes
    0\. Therefore, a random variable under normal distribution can have any value
    (albeit some values with a tiny probability).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The surface area under the curve is equal to 1, which is ensured by the constant, [![](img/02c31240-b7e4-4022-86be-883f26fb9ced.png)],
    being before the exponent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[![](img/6c9b2a78-408e-49a3-a1bc-d1462d3c6964.png)] (located in the exponent) is
    called the standard score (or z-score). A standardized normal variable has a mean
    of 0 and a standard deviation of 1\. Once transformed, the random variable participates
    in the equation in its standardized form.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we'll introduce the multidisciplinary field of information
    theory, which will help us use probability theory in the context of NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Information theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Information theory attempts to determine the amount of information an event
    has. The amount of information is guided by the following principles:'
  prefs: []
  type: TYPE_NORMAL
- en: The higher the probability of an event, the less informative the event is considered.
    Conversely, if the probability is lower, the event carries more informational
    content. For example, the outcome of a coin flip (with a probability of 1/2) provides
    less information than the outcome of a dice throw (with a probability of 1/6).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The information that's carried by independent events is the sum of their individual
    information contents. For example, two dice rows that come up on the same side
    of the dice (let's say, 4) are twice as informative as the individual rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We''ll define the amount of information (or self-information) of event *x*
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc0a3a5c-f8c5-416c-860a-9ff406d5bddc.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *log* is the natural logarithm. For example, if the probability of event
    is *P(x) = 0.8*, then *I(x) = 0.22*. Alternatively, if *P(x)** = 0.2*, then *I(x)
    = 1.61*. We can see that the event information content is opposite to the event
    probability. The amount of self-information I(x) is measured in natural units
    of information (**nat**). We can also compute I(x) with a base 2 logarithm [![](img/c6e7e6d6-823e-41fd-b98b-53f85660ed0b.png)],
    in which case we measure it in bits. There is no principal difference between
    the two versions. For the purposes of this book, we'll stick with the natural
    logarithm version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss why we use logarithm in the preceding formula, even though a
    negative probability would also satisfy the reciprocity between self-information
    and probability. The main reason is the product and division rules of logarithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df24a7c6-d531-45f0-8349-f55b4cc9fe81.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x[1]* and *x[2]* are scalar values. Without going into too much detail,
    note that these properties allow us to easily minimize the error function during
    network training.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've defined the information content of a single outcome. But what
    about other outcomes? To measure them, we have to measure the amount of information
    over the probability distribution of the random variable. Let's denote it with I(*X*),
    where *X* is a random discrete variable (we'll focus on discrete variables here)*.* Recall
    that, in the *Random variables and probability distributions* section, we defined
    the mean (or expected value) of a discrete random variable as the weighted sum
    of all possible values, multiplied by their probabilities. We'll do something
    similar here, but we'll multiply the information content of each event by the
    probability of that event.
  prefs: []
  type: TYPE_NORMAL
- en: 'This measure is called Shannon entropy (or just entropy) and is defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b5be33a0-5072-4c44-a32f-f4afe5eb8a38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *x[i]* represents the discrete variable values. Events with higher probabilities
    will carry more weight compared to low-probability ones. We can think of entropy
    as the expected (mean) amount of information about the events (outcomes) of the
    probability distribution. To understand this, let''s try to compute the entropy
    of the familiar coin toss experiment. We''ll calculate two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s assume that *P(heads) = P(tails) = 0.5*. In this case, the entropy
    is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/ea728c03-e98b-46d7-a382-4c5a4721f411.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, let''s assume that, for some reason, the outcomes are not equally likely
    and that the probability distribution is *P(heads) = 0.2 and P(tails) = 0.8*.
    The entropy is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/8f2e8145-8134-4095-9957-dab1e32d88d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that the entropy is highest when the outcomes are equally likely
    and decreases when one outcome becomes prevalent. In a sense, we can think of
    entropy as a measurement of uncertainty or chaos. The following diagram shows
    a graph of the entropy **H(X)** over a binary event (such as the coin toss), depending
    on the probability distribution of the two outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3048ac36-93c3-4e88-8c6b-5465ce9619c7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Left: entropy with natural logarithm; right: entropy with base 2 logarithm'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s imagine that we have a discrete random variable, *X*, and two
    different probability distributions over it. This is usually the scenario where
    a NN produces some output probability distribution *Q*(*X*) and we compare it
    to a target distribution, *P*(*X*), during training. We can measure the difference
    between these two distributions with **cross-entropy**, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/286a0d80-e65e-4094-9d51-5ed9a35d3c5a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, let''s calculate the cross entropy between the two probability
    distributions of the preceding coin toss scenario. We have predicted distribution
    *Q(heads) = 0.2, Q(tails) = 0.8* and the target (or true) distribution *P(heads)
    = 0.5, P(tails) = 0.5*. The cross entropy is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f2d9c169-6917-4baa-a640-e127e574dd99.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Another measure of the difference between two probability distributions is
    the **Kullback–Leibler divergence** (**KL divergence**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cd443f93-4762-4798-97b1-2fad942ff6a8.png)'
  prefs: []
  type: TYPE_IMG
- en: The product rule of logarithms helped us to transform the first-row formula
    into a more intuitive form on the second row. It is easier to see that the KL
    divergence measures the difference between the target and predicted log probabilities.
    If we derive the equation further, we can also see the relationship between the
    entropy, cross-entropy, and KL divergence.
  prefs: []
  type: TYPE_NORMAL
- en: 'The KL divergence of the coin toss example scenario is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb7873f1-4967-4cc2-aa2b-9847a61eafeb.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next section, we'll discuss the field of differential calculus, which
    will help us with training NNs.
  prefs: []
  type: TYPE_NORMAL
- en: Differential calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ML, we are often interested in how to approximate some target function by
    adjusting the parameters of ML algorithms. If we think of the ML algorithm itself
    as a mathematical function (which is the case for NNs), we would like to know
    how the output of that function changes when we change some of its parameters
    (weights). Thankfully, differential calculus deals with the rate of change of
    a function with respect to a variable that the function depends on. The following
    is a (very) short introduction to derivatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that we have a function, *f(x)*, with a single parameter, *x*, which
    has the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6af6853f-95e6-4295-9928-8072b8b3cc4e.png)'
  prefs: []
  type: TYPE_IMG
- en: The graph of *f(x)* and the slope (red dot-dashed line)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get a relative idea of how *f(x)* changes with respect to *x* at any
    value of *x* by calculating the slope of the function at that point. If the slope
    is positive, the function increases. Conversely, if it''s negative, it decreases.
    We can calculate the slope with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4747290f-0134-4f25-9a76-8cc959826bc4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The idea here is simple—we calculate the difference between two values of *f*
    at *x* and *x+Δx: Δy = f(x + Δx) - f(x)*. Then, we calculate the ratio between *Δy* and *Δx*
    to get the slope. But if *Δx* is too big, the measurement won''t be very accurate,
    because the part of the function graph enclosed between *x* and *x+Δx* may change
    drastically. We can use a smaller *Δx* to minimize this error; here, we can focus
    on a smaller part of the graph. If *Δx* approaches 0, we can assume that the slope
    reflects a single point of the graph. In this case, we call the slope the **first
    derivative** of *f(x)*. We can express this in mathematical terms via the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1346b5cc-2850-455b-b2c2-d08ac1436d63.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *f''(x)* and *dy*/*dx* are Lagrange''s and Leibniz''s notations for derivatives,
    respectively. [![](img/daf6028e-6f96-422b-85ad-2958c188a7de.png)] is the mathematical
    concept of the limit—we can think of it as *Δx* approaches 0\. The process of
    finding the derivative of *f* is called **differentiation**. The following diagram
    shows slopes at different values of *x*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9be91093-11dc-41c7-934a-35a65f6c27c3.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that the slopes at the **local minimum** and **local maximum** of
    *f* are 0—at these points (known as saddle points), *f* neither increases nor
    decreases as we change *x*.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's assume that we have a function of multiple parameters, [![](img/12ed27f9-3790-42db-8686-9074a9898e0a.png)].
    The derivative of *f* with respect to any of the parameters, *x[i]*, is called
    a partial derivative and is denoted by [![](img/727e193f-e698-4224-a40f-e4f2df518a13.png)].
    When computing the partial derivative, we assume that all the other parameters, [![](img/97873945-7233-4a21-b250-4dd3f2ce4a5f.png)],
    are constants. We'll denote the partial derivatives of the components of a vector
    with [![](img/cf689fe9-76b8-4538-b626-f1a2716c9281.png)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s mention some useful rules for differentiation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Chain rule**: Let''s say that *f* and *g* are some functions and *h(x)= f(g(x)).* Here, the
    derivative of *f* with respect to *x* for any *x* is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/657a48ea-67e9-4c27-8ae3-1ca8c386e28c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Sum rule**: Let''s say that *f* and *g* are some functions and *h(x) = f(x)
    + g(x)*. The sum rule states the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/e856188c-d37a-44e0-919c-99764acc1029.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Common functions**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x'' = 1*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*(ax)'' = a*, where *a* is scalar'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*a'' = 0*, where *a* is scalar'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x² = 2x*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*(e^x)'' = e^x*'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The mathematical apparatus of NNs and NNs themselves form a sort of knowledge
    hierarchy. If we think of implementing a NN as building a house, then the mathematical
    apparatus is like mixing concrete. We can learn how to mix the concrete independently
    of how to build a house. In fact, we can mix concrete for a variety of purposes
    other than the specific goal of building a house. However, we need to know how
    to mix concrete before building the house. To continue with our analogy, now that
    we know how to mix concrete (mathematical apparatus), we'll focus on actually
    building the house (NNs).
  prefs: []
  type: TYPE_NORMAL
- en: A short introduction to NNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A NN is a function (let''s denote it with *f*) that tries to approximate another
    target function, *g*. We can describe this relationship with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0d8ad81-d35d-4aca-938c-a995ad09c5cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x* is the input data and *θ* are the NN parameters (weights). The goal
    is to find such *θ* parameters with the best approximate, *g*. This generic definition
    applies for both regression (approximating the exact value of *g*) and classification
    (assigning the input to one of multiple possible classes) tasks. Alternatively,
    the NN function can be denoted as ![](img/04acee79-fa2e-435c-b648-1ae896c2e1d0.png).
  prefs: []
  type: TYPE_NORMAL
- en: We'll start our discussion from the smallest building block of the NN—the neuron.
  prefs: []
  type: TYPE_NORMAL
- en: Neurons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The preceding definition is a bird''s-eye view of a NN. Now, let''s discuss
    the basic building blocks of a NN, namely the neurons (or **units**). Units are
    mathematical functions that can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f16f17a0-7360-485c-a4ca-463feb633388.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*y* is the unit output (single value).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*f* is the non-linear differentiable activation function. The activation function
    is the source of non-linearity in a NN—if the NN was entirely linear, it would
    only be able to approximate other linear functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The argument of the activation function is the weighted sum (with weights *w[i]*)
    of all the unit inputs *x[i]* (*n* total inputs) and the bias weight *b*. The
    inputs *x[i]* can be either the data input values or outputs of other units.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alternatively, we can substitute *x[i]* and *w[i]* with their vector representations,
    where [![](img/70c30cb5-49ed-4523-915a-7ad17f211850.png)] and [![](img/5463e3ea-224a-4be3-9db7-87f4172b806d.png)].
    Here, the formula will use the dot product of the two vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d9748d38-e79a-4d30-9a70-0558d40a3a9a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following diagram (left) shows a unit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/082ab20e-1d14-4d08-9d03-cf22b368c695.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Left: A unit and its equivalent formula; right: A geometric representation
    of a perceptron.'
  prefs: []
  type: TYPE_NORMAL
- en: The input vector **x** will be perpendicular to the weight vector **w** if **x•
    w = 0**. Therefore, all vectors **x** where **x• w = 0** define a hyperplane in
    the vector space [![](img/4c44a65f-c096-4021-a553-a0ce228357cb.png)], where *n* is
    the dimension of *x*. In the case of two-dimensional input *(x[1], x[2])*, we
    can represent the hyperplane as a line. This could be illustrated with the perceptron (or
    binary classifier)—a unit with a **threshold** activation function ![](img/1ece5653-1f1a-458a-87b4-0d9c75eff95e.png) that
    classifies its input in one of the two classes. The geometric representation of
    the perceptron with two inputs *(x[1], x[2])* is a line (or decision boundary)
    separating the two classes (to the right in the preceding diagram). This imposes
    a serious limitation on the neuron because it cannot classify linearly inseparable
    problems—even simple ones such as XOR.
  prefs: []
  type: TYPE_NORMAL
- en: A unit with an identity activation function (*f(x) = x*) is equivalent to multiple
    linear regression, while a unit with a sigmoid activation function is equivalent
    to logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's learn how to organize the neurons in layers.
  prefs: []
  type: TYPE_NORMAL
- en: Layers as operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next level in the NN organizational structure is the layers of units, where
    we combine the scalar outputs of multiple units in a single output vector. The
    units in a layer are not connected to each other. This organizational structure
    makes sense for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: We can generalize multivariate regression to a layer, as opposed to only linear
    or logistic regression for a single unit. In other words, we can approximate multiple
    values with a layer as opposed to a single value with a unit. This happens in
    the case of classification output, where each output unit represents the probability
    the input belongs to a certain class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A unit can convey limited information because its output is a scalar. By combining
    the unit outputs, instead of a single activation, we can now consider the vector
    in its entirety. In this way, we can convey a lot more information, not only because
    the vector has multiple values, but also because the relative ratios between them
    carry additional meaning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the units in a layer have no connections to each other, we can parallelize
    the computation of their outputs (thereby increasing the computational speed).
    This ability is one of the major reasons for the success of DL in recent years.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In classical NNs (that is, NNs before DL, when they were just one of many ML
    algorithms), the primary type of layer is the **fully connected** (**FC**) layer.
    In this layer, every unit receives weighted input from all the components of the
    input vector, **x**. Let''s assume that the size of the input vector is *m* and
    that the FC layer has *n* units and an activation function *f*, which is the same
    for all the units. Each of the *n* units will have *m* weights: one for each of
    the *m* inputs. The following is a formula we can use for the output of a single
    unit *j* of an FC layer. It''s the same as the formula we defined in the *Neurons*
    section, but we''ll include the unit index here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d58e01e-f4a0-4d06-85ec-4bab1f5954c5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *w[ij]* is the weight between the *j*-th layer unit and the *i*-th input
    component. We can represent the weights connecting the input vector to the units
    as an *m×n* matrix **W**. Each matrix column represents the weight vector of all
    the inputs to one layer unit. In this case, the output vector of the layer is
    the result of matrix-vector multiplication. However, we can also combine multiple
    input samples, **x***[i]*, in an input matrix (or **batch**) **X**, which will
    be passed through the layer simultaneously. In this case, we have matrix-matrix
    multiplication and the layer output is also a matrix. The following diagram shows
    an example of an FC layer, as well as its equivalent formulas in the batch and
    single sample scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9eca7a6e-1de6-4761-827d-8ad3056d0cd2.png)'
  prefs: []
  type: TYPE_IMG
- en: An FC layer with vector/matrix inputs and outputs and its equivalent formulas
  prefs: []
  type: TYPE_NORMAL
- en: We have explicitly separated the bias and input weight matrices, but in practice,
    the underlying implementation may use a shared weight matrix and append an additional
    row of 1s to the input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Contemporary DL is not limited to FC layers. We have many other types, such
    as convolutional, pooling, and so on. Some of the layers have trainable weights
    (FC, convolutional), while others don''t (pooling). We can also use the terms
    functions or operations interchangeably with the layer. For example, in TensorFlow
    and PyTorch, the FC layer we just described is a combination of two sequential
    operations. First, we perform the weighted sum of the weights and inputs and then
    we feed the result as an input to the activation function operation. In practice
    (that is, when working with DL libraries), the basic building block of a NN is
    not the unit but an operation that takes one or more tensors as input and outputs
    one or more tensors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c10ceb6-f86f-412b-b227-6761c88280d4.png)'
  prefs: []
  type: TYPE_IMG
- en: A function with input and output tensors
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's discuss how to combine the layer operations in a NN.
  prefs: []
  type: TYPE_NORMAL
- en: NNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Neurons* section, we demonstrated that a neuron (also valid for a layer)
    can only classify linearly separable classes. To overcome this limitation, we
    have to combine multiple layers in a NN. We'll define the NN as a directed graph
    of operations (or layers). The graph nodes are the operations, and the edges between
    them determine the data flow. If two operations are connected, then the output
    tensor of the first will serve as input to the second, which is determined by
    the edge direction. A NN can have multiple inputs and outputs—the input nodes
    only have outgoing edges, while the outputs only have incoming edges.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this definition, we can identify two main types of NNs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feed-forward**, which are represented by **acyclic** graphs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent** (**RNN**), which are represented by **cyclic** graphs. The recurrence
    is temporal; the loop connection in the graph propagates the output of an operation
    at moment *t-1* and feeds it back into the network at the next moment, *t*. The
    RNN maintains an internal state, which represents a kind of summary of all the
    previous network inputs. This summary, along with the latest input, is fed to
    the RNN. The network produces some output but also updates its internal state
    and waits for the next input value. In this way, the RNN can take inputs with
    variable lengths, such as text sequences or time series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is an example of the two types of networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5659f4a0-a7f8-4824-8f4f-06316abc9594.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Left: Feed-forward network; Right: Recurrent network'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume that, when an operation receives input from more than one operation,
    we use the element-wise sum to combine the multiple input tensors. Then, we can
    represent the NN as a series of nested functions/operations. We''ll denote a NN
    operation with [![](img/02ac42df-f4ea-4c94-baa7-4f4784483f3e.png)], where *i* is
    some index that helps us differentiate between multiple operations. For example,
    the equivalent formula for the feed-forward network on the left is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1efd317b-048c-4ad8-b062-7b8f76925308.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The formula for the RNN on the right is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7dea3971-d074-4813-8c6e-813f7564454a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We''ll also denote the parameters (weights) of an operation with the same index
    as the operation itself. Let''s take an FC network layer with index *l*, which
    takes its input from a previous layer with index *l-1*. The following are the
    layer formulas for a single unit and vector/matrix layer representations with
    layer indexes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fbb5a8e3-b244-48ce-b989-38f6dae8e12b.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we're familiar with the full NN architecture, let's discuss the different
    types of activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s discuss the different types of activation functions, starting with the
    classics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sigmoid**: Its output is bounded between 0 and 1 and can be interpreted stochastically
    as the probability of the neuron activating. Because of these properties, the
    sigmoid was the most popular activation function for a long time. However, it
    also has some less desirable properties (more on that later), which led to its
    decline in popularity. The following diagram shows the sigmoid formula, its derivative,
    and their graphs (the derivative will be useful when we discuss backpropagation):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/4e410206-7352-455d-80de-cf5fcf8ffcb4.png)'
  prefs: []
  type: TYPE_IMG
- en: Sigmoid activation function
  prefs: []
  type: TYPE_NORMAL
- en: '**Hyperbolic tangent** (**tanh**): The name speaks for itself. The principal
    difference with the sigmoid is that the tanh is in the (-1, 1) range. The following
    diagram shows the tanh formula, its derivative, and their graphs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/a197e86d-c3e1-4e94-9430-061a91ecc65c.png)'
  prefs: []
  type: TYPE_IMG
- en: The hyperbolic tangent activation function
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s focus on the new kids on the block—the *LU (**LU** stands for
    **linear unit**) family of functions. We''ll start with the rectified linear unit
    (**ReLU**), which was first successfully used in 2011 (*Deep Sparse Rectifier
    Neural Networks*, [http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf](http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf)).
    The following diagram shows the ReLU formula, its derivative, and their graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/727a2c5f-91fc-45ce-8943-7d095f3cf119.png)'
  prefs: []
  type: TYPE_IMG
- en: ReLU activation function
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, the ReLU repeats its input when **x > 0** and stays at 0 otherwise.
    This activation has several important advantages over sigmoid and tanh:'
  prefs: []
  type: TYPE_NORMAL
- en: Its derivative helps prevent vanishing gradients (more on that in the *Weights
    initialization* section). Strictly speaking, the derivative ReLU at value 0 is
    undefined, which makes the ReLU only semi-differentiable (more information about
    this can be found at [https://en.wikipedia.org/wiki/Semi-differentiability](https://en.wikipedia.org/wiki/Semi-differentiability)).
    But in practice, it works well enough.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s idempotent—if we pass a value through an arbitrary number of ReLU activations,
    it will not change; for example, *ReLU(2) = 2*, *ReLU(ReLU(2)) = 2*, and so on.
    This is not the case for a sigmoid, where the value is *squashed* on each pass:
    *σ(**σ(2)) = 0.707*. The following is an example of the activation of three consecutive
    sigmoid activations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9b449d44-5940-42ea-888a-5500e5cc386d.png)'
  prefs: []
  type: TYPE_IMG
- en: Consecutive sigmoid activations "squash" the data
  prefs: []
  type: TYPE_NORMAL
- en: The idempotence of ReLU makes it theoretically possible to create networks with
    more layers compared to the sigmoid.
  prefs: []
  type: TYPE_NORMAL
- en: It creates sparse activations—let's assume that the weights of the network are
    initialized randomly through normal distribution. Here, there is a 0.5 chance
    that the input for each ReLU unit is < 0\. Therefore, the output of about half
    of all activations will also be 0\. The sparse activations have a number of advantages,
    which we can roughly summarize as the Occam's razor in the context of NNs—it's
    better to achieve the same result with a simpler data representation than a complex
    one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's faster to compute in both the forward and backward passes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, during training, the network weights can be updated in such a way
    that some of the ReLU units in a layer will always receive inputs smaller than
    0, which in turn will cause them to permanently output 0 as well. This phenomenon
    is known as **dying** ReLUs. To solve this, a number of ReLU modifications have
    been proposed. The following is a non-exhaustive list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Leaky ReLU**: When the input is larger than 0, leaky ReLU repeats its input
    in the same way as the regular ReLU does. However, when **x < 0**, the leaky ReLU
    outputs *x* multiplied by some constant *α (0 < α < 1)*, instead of 0\. The following
    diagram shows the leaky ReLU formula, its derivative, and their graphs for α=0.2:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/1a2ece75-3d35-421d-b429-0a00a302ff39.png)'
  prefs: []
  type: TYPE_IMG
- en: Leaky ReLU activation function
  prefs: []
  type: TYPE_NORMAL
- en: '**Parametric ReLU** (**PReLU**, *Delving Deep into Rectifiers: Surpassing Human-Level
    Performance on ImageNet Classification*, [https://arxiv.org/abs/1502.01852](https://arxiv.org/abs/1502.01852)):
    This activation is the same as the leaky ReLU, but the parameter α is tunable
    and is adjusted during training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exponential linear units** (**ELU**, *Fast and Accurate Deep Network Learning
    by Exponential Linear Units (ELUs)*, [https://arxiv.org/abs/1511.07289](https://arxiv.org/abs/1511.07289)): When
    the input is larger than 0, ELU repeats its input in the same way as ReLU does.
    However, when *x < 0*, the ELU output becomes [![](img/7facdd5f-4b7c-496b-9faa-7325f05759f9.png)],
    where α is a tunable parameter. The following diagram shows the ELU formula, its
    derivative, and their graphs for α=0.2:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/4dec517e-6475-4ca9-acc6-f6beecdbcdd2.png)'
  prefs: []
  type: TYPE_IMG
- en: ELU activation function
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaled exponential linear units** (**SELU**, *Self-Normalizing Neural Networks*, [https://arxiv.org/abs/1706.02515](https://arxiv.org/abs/1706.02515)):
    This activation is similar to ELU, except that the output (both smaller and larger
    than 0) is scaled with an additional training parameter, λ. The SELU is part of
    a larger concept called self-normalizing NNs (SNNs), which is described in the
    source paper. The following is the SELU formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/dde66d94-9f7d-42ba-892c-7985c308e100.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we''ll mention the **softmax**, which is the activation function of
    the output layer in classification problems. Let''s assume that the output of
    the final network layer is a vector, [![](img/1d8758ff-5740-4a18-9ced-3c25f706c7e2.png)],
    where each of the *n* components represents the probability that the input data
    belongs to one of *n* possible classes. Here, the softmax output for each of the
    vector components is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9f9f8dd8-dcbe-4f3f-96fd-54a569fe8803.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The denominator in this formula acts as a normalizer. The softmax output has
    some important properties:'
  prefs: []
  type: TYPE_NORMAL
- en: Every value *f(z[i])* is in the [0, 1] range.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The total sum of values of **z** is equal to 1: [![](img/8c9d0b4e-4c25-4547-b7b5-16f7f149ef92.png).]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An added bonus (in fact, obligatory) is that the function is differentiable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other words, we can interpret the softmax output as a probability distribution
    of a discrete random variable. However, it also has one more subtle property.
    Before we normalize the data, we transform each vector component exponentially
    with [![](img/2ddaa9ce-bb9f-4662-b18b-864359b51d72.png)]. Let's imagine that two
    of the vector components are *z[1] = 1* and *z[2] = 2*. Here, we would have *exp(1) =
    2.7* and *exp(2) = 7.39*. As we can see, the ratios between the components before
    and after the transformation are very different—0.5 and 0.36\. In effect, the
    softmax increases the probability of the higher scores compared to lower ones.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll shift our attention from the building blocks of the
    NN and focus on its entirety instead. More specifically, we'll demonstrate how
    NNs can approximate any function.
  prefs: []
  type: TYPE_NORMAL
- en: The universal approximation theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The universal approximation theorem was first proved in 1989 for a NN with sigmoid
    activation functions and then in 1991 for NNs with arbitrary non-linear activation
    functions. It states that any continuous function on compact subsets of [![](img/95737d8a-6d84-4a7a-89d1-ec9b27ea62b0.png)] can
    be approximated to an arbitrary degree of accuracy by a feedforward NN with at
    least one hidden layer with a finite number of units and a non-linear activation.
    Although a NN with a single hidden layer won't perform well in many tasks, the
    theorem still tells us that there are no theoretical insurmountable limitations
    in terms of NNs. The formal proof of the theorem is too complex to be explained
    here, but we'll attempt to provide an intuitive explanation using some basic mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: The idea for the following example was inspired by Michael A. Nielsen's book *Neural
    Networks and **Deep Learning *([http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll implement a NN that approximates the boxcar function (shown on the right
    in the following diagram), which is a simple type of step function. Since a series
    of step functions can approximate any continuous function on a compact subset
    of *R*, this will give us an idea of why the universal approximation theorem holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6e00a40-0299-4a5d-b3f6-62404071d039.png)'
  prefs: []
  type: TYPE_IMG
- en: The diagram on the left depicts continuous function approximation with a series
    of step functions, while the diagram on the right illustrates a single boxcar
    step function.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how this approximation works, we''ll start with a single unit
    with a single scalar input *x* and sigmoid activation. The following is a visualization
    of the unit and its equivalent formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ba8fa8c-d68c-46bf-babc-7b4593d951fd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the following diagrams, we can see the graph of the formula for different
    values of *b* and *w* for inputs in the range of [-10: 10]:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79c3e582-7a3f-40ae-b2bd-b65568584257.png)'
  prefs: []
  type: TYPE_IMG
- en: The neuron output based on different values of *w* and *b*. The network input
    *x* is represented on the x axis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Upon closer inspection of the formula and the graph, we can see that the steepness
    of the sigmoid function is determined by the weight, *w*. Also, the translation
    of the function along the *x* axis is determined by the formula *t = -b/w*. Let''s
    discuss the different scenarios in the preceding diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: The top-left graph shows the regular sigmoid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The top-right graph demonstrates that a large weight *w* amplifies the input
    *x* to a point, where the unit output resembles threshold activation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bottom-left graph shows how the bias *b* translates the unit activation
    along the *x *axis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bottom-right graph shows that we can simultaneously reverse the activation
    with negative weight *w* and translate the activation along the *x *axis with
    the bias *b*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can intuitively see that the preceding graphs contain all the ingredients
    of the box function. We can combine the different scenarios with the help of a
    NN with one hidden layer, which contains two of the aforementioned units. The
    following diagram shows the network architecture, along with the weights and biases
    of the units, as well as the box function that''s produced by the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/617c2e78-f676-443e-af6d-f35cb87771f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: First, the top unit activates for the upper step of the function and stays active.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bottom unit activates afterward for the bottom step of the function and
    stays active. The outputs of the hidden units cancel each other out because of
    the weights in the output layer, which are the same but with opposite signs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The weights of the output layer determine the height of the boxcar rectangle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output of this network isn't 0, but only in the (-5, 5) interval. Therefore,
    we can approximate additional boxes by adding more units to the hidden layer in
    a similar manner.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we're familiar with the structure of a NN, let's focus on the training
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Training NNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll define training a NN as the process of adjusting its
    parameters (weights) *θ* in a way that minimizes the cost function *J(θ)*. The
    cost function is some performance measurement over a training set that consists
    of multiple samples, represented as vectors. Each vector has an associated label
    (supervised learning). Most commonly, the cost function measures the difference
    between the network output and the label.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start this section with a short recap of the gradient descent optimization
    algorithm. If you're already familiar with it, you can skip this.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the purposes of this section, we''ll use a NN with a single regression
    output and **mean square error** (**MSE**) cost function, which is defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e50aabbd-24c7-4044-8422-09de5c713e04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*f[θ]*(**x**^((*i*))) is the output of the NN.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*n* is the total number of samples in the training set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**x**^((*i*)) are the vectors for the training samples, where the superscript
    *i* indicates the *i*-th sample of the dataset. We use superscript because **x**^((*i*)) is
    a vector and the subscript is reserved for each of the vector components. For
    example, [![](img/6a45d5e7-f486-48b8-b2aa-69e1c8f94188.png)] is the *j*-th component
    of the *i*-th training sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*t*^((*i*)) is the label associated with sample **x**^((*i*)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We shouldn't confuse the *(i)* superscript index of the *i*-th training sample
    with the *(l)* superscript, which represents the layer index of the NN. We'll
    only use the (*i*) sample index notation in the *Gradient descent* and *Cost functions*
    sections, and elsewhere we'll use the *(l)* notation for the layer index*.*
  prefs: []
  type: TYPE_NORMAL
- en: 'First, gradient descent computes the derivative (gradient) of *J(θ)* with respect
    to all the network weights. The gradient gives us an indication of how *J(θ)* changes
    with respect to every weight. Then, the algorithm uses this information to update
    the weights in a way that will minimize *J(θ)* in future occurrences of the same
    input/target pairs. The goal is to gradually reach the global minimum of the cost
    function. The following is a visualization of gradient descent for MSE and a NN
    with a single weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7a7fada6-aac8-4594-b4da-9e415a4cf357.png)'
  prefs: []
  type: TYPE_IMG
- en: A visualization of gradient descent for MSE
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go over the step-by-step execution of gradient descent:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the network weights *θ* with random values*.*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Repeat until the cost function falls below a certain threshold:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Forward pass: compute the MSE *J(θ)* cost function for all the samples of the
    training set using the preceding formula.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Backward pass: compute the derivative of *J(θ)* with respect to all the network
    weights using the chain rule:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d391519c-5add-4895-b0ed-536e1ced832c.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's analyze the derivative [![](img/cdaeaebd-a07c-4e59-96a0-d899abe8f63a.png)]. *J* is
    a function of *θ[j]* by being a function of the network output. Therefore, it
    is also a function of the NN function itself, that is, [![](img/fa690c9c-f79a-4e9f-977d-d708662e3522.png)].
    Then, by following the chain rule, we get [![](img/d806c39d-4564-477f-9d35-55fd146e442f.png)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Use these derivatives to update each of the network weights:'
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0f30d60f-7e45-4be6-9a2c-53cd1d36156f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, η is the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gradient descent updates the weights by accumulating the error across all the
    training samples. In practice, we would use two of its modifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stochastic** (**or online**) **gradient descent**(**SGD**) updates the weights
    after every training sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mini-batch gradient descent **accumulates the error for every *n* samples
    (one mini-batch)and performs one weight update.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let's discuss the different cost functions we can use with SGD.
  prefs: []
  type: TYPE_NORMAL
- en: Cost functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Besides MSE, there are also a few other loss functions that are commonly used
    in regression problems. The following is a non-exhaustive list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean absolute error** (**MAE**) is the mean of the absolute differences (not
    squared) between the network output and the target. The following is the MAE graph
    and formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/32429f23-4286-46c2-8d93-85eb26c7c50d.png)'
  prefs: []
  type: TYPE_IMG
- en: One advantage of MAE over MSE is that it deals with outlier samples better.
    With MSE, if the difference of a sample is [![](img/7e8d1ad7-eed6-4166-a47f-686c534cd901.png)],
    it increases exponentially (because of the square). We'll get an outsized weight
    of this sample compared to the others, which may skew the results. With MAE, the
    difference is not exponential and this issue is less pronounced.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the MAE gradient will have the same value until we reach
    the minimum, where it will become 0 immediately. This makes it harder for the
    algorithm to anticipate how close the cost function minimum is. Compare this to
    MSE, where the slope gradually decreases as we get close to the cost minimum.
    This makes MSE easier to optimize. In conclusion, unless the training data is
    corrupted with outliers, it is usually recommended to use MSE over MAE.
  prefs: []
  type: TYPE_NORMAL
- en: '**Huber loss** attempts to fix the problems of both MAE and MSE by combining
    their properties. In short, when the absolute difference between the output and
    the target data falls below the value of a fixed parameter, δ, the Huber loss
    behaves like MSE. Conversely, when the difference is greater than δ, it resembles
    MAE. In this way, it is less sensitive to outliers (when the difference is big)
    and at the same time, the minimum of the function is properly differentiable.
    The following is the Huber loss graph for three values of δ and its formula for
    a single training sample, which reflects its dualistic nature:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9e3e7435-9aaa-40b2-a4c7-503bfa747d7a.png)'
  prefs: []
  type: TYPE_IMG
- en: Huber loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s focus on cost functions for classification problems. The following
    is a non-exhaustive list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cross-entropy** loss: We have our work cut out for us here as we already
    defined cross-entropy in the *Information theory* section. This loss is usually
    applied over the output of a softmax function. The two work very well together.
    First, the softmax converts the network output into a probability distribution.
    Then, cross-entropy measures the difference between the network output (Q) and
    the true distribution (P), which is provided as a training label. Another nice
    property is that the derivative of *H(P, Q[softmax])* is quite straightforward
    (although the computation isn''t):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/d38c6fac-8614-4e00-92a4-b5ca8514070f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x^((i))/t^((i))* is the *i*-th input/label training pair.
  prefs: []
  type: TYPE_NORMAL
- en: '**KL Divergence** loss: Like cross-entropy loss, we already did the grunt work
    in the *Information theory* section, where we derived the relationship between
    KL divergence and cross-entropy loss. From their relationship, we can state that
    if we use either of the two as a loss function, we implicitly use the other one
    as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes, we may encounter the terms loss function and cost function being
    used interchangeably. It is usually accepted that they differ slightly. We'll
    refer to the loss function as the difference between the network output and target
    data for a **single** sample of the training set. The cost function is the same
    thing but is averaged (or summed) over multiple samples (batch) of the training
    set.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have looked at different cost functions, let's focus on propagating
    the error gradient through the network with backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll discuss how to update the network weights in order
    to minimize the cost function. As we demonstrated in the *Gradient descent* section,
    this means finding the derivative of the cost function *J(θ)* with respect to
    each network weight*. *We already took a step in this direction with the help
    of the chain rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2e6ef655-6bb5-4a77-92ab-f54faf307fae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *f(θ)* is the network output and *θ[j]* is the *j*-th network weight*.*
    In this section, we''ll push the envelope further and we''ll learn how to derive
    the NN function itself for all the network weights (hint: chain rule). We''ll
    do this by propagating the error gradient backward through the network (hence
    the name). Let''s start with a few assumptions:'
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of simplicity, we'll work with a sequential feed-forward NN. Sequential
    means that each layer takes input from the preceding layer and sends its output
    to the following layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll define *w[ij]* as the weight between the *i*-th neuron of layer *l* and
    the *j-*th neuron of layer *l+1. *In other words, we use subscripts *i* and *j*,
    where the element with subscript *i* belongs to the preceding layer, which is
    the layer containing the element with subscript *j*. In a multi-layer network, *l* and *l+1* can
    be any two consecutive layers, including input, hidden, and output layers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll denote the output of the *i*-th unit of layer l with [![](img/47df128a-d1f0-403d-9aa3-b8d5351f475b.png)]and the
    output of the *j*-th unit of layer l+1 with [![](img/af8df4bf-f929-49c3-94e8-738416ee0df6.png)].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll denote the input to the activation function (that is, the weighted sum
    of the inputs before activation) of unit *j* of layer *l* with *a[j]^((l))*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows all the notations we introduced:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ad7c70ac-37b4-4ce6-b1e5-7cc5923cebc0.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, layer l represents the input, layer l+1 represents the output, and *w[ij]* connects
    the *y[i]^([(l)])* activation in layer l to the inputs of the j-th neuron of layer
    l+1
  prefs: []
  type: TYPE_NORMAL
- en: 'Armed with this great knowledge, let''s get down to business:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll assume that *l* and *l+1* are the second-to-last and the last
    (output) network layers, respectively. Knowing this, the derivative of J with
    respect to *w[ij]* is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2b12510e-19c8-4740-82c3-45b27e4270a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s focus on [![](img/3c0fe6b4-4c70-4de4-9a24-c723eafaaea8.png)]. Here,
    we compute the partial derivative of the weighted sum of the output of layer *l* with
    respect to one of the weights, *w[ij]*. As we discussed in the *Differential calculus* section,
    in partial derivatives, we''ll consider all the function parameters except *w[ij]* constants.
    When we derive *a[j]^([(l+1)])*, they all become 0 and we''re only left with [![](img/638298cb-bba0-48fe-923d-28fd64be27e3.png)].
    Therefore, we get the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/687176f6-b628-434b-9438-8f8617082829.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The formula from point 1 holds for any two consecutive hidden layers, *l* and
    *l+1*, of the network. We know that [![](img/0faa558f-675d-4698-9454-12d5360204f9.png)], and
    we also know that [![](img/6f4c364f-79c1-45fe-99c9-bc175617827e.png)] is the derivative
    of the activation function, which we can calculate (see the *Activation functions*
    section). All we need to do is calculate the derivative [![](img/bd64bfc9-cd1a-479d-98b5-9b5a61f76faf.png)] (recall
    that, here, *l+1* is some hidden layer). Let''s note that this is the derivative
    of the error with respect to the activation function in layer *l+1*. We can now
    calculate all the derivatives, starting from the last layer and moving backward,
    because the following apply:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can calculate this derivative for the last layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a formula that allows us to calculate the derivative for one layer,
    assuming that we can calculate the derivative for the next.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With these points in mind, we get the following equation by applying the chain
    rule:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9fa73368-1629-499f-aacf-6e8f707914b8.png)'
  prefs: []
  type: TYPE_IMG
- en: The sum over *j* reflects the fact that, in the feedforward part of the network,
    the output* ![](img/178b40b8-5edb-4888-aea4-61ab1d0bdf82.png) *is fed to all the
    neurons in layer *l+1*. Therefore, they all contribute to *y[i]^([(l)])*when the
    error is propagated backward.
  prefs: []
  type: TYPE_NORMAL
- en: Once again, we can calculate [![](img/3e0a68a5-2579-4d38-8687-6634162d3520.png)].
    Following the same logic that we followed in *step 3*, we can compute that [![](img/bc64c3d6-ee8a-4c98-b0a3-28c92ea47bde.png)].
    Therefore, once we know that [![](img/a35b6e03-6a0e-4b88-abeb-f5a509057bd0.png)] , we
    can calculate [![](img/61ecb327-6a60-4342-bb49-e1bdb135e3d5.png)]. Since we can
    calculate ![](img/85b5edb6-75f7-467d-80fb-a18b93c3df98.png) for the last layer,
    we can move backward and calculate [![](img/3c0ace54-6609-4270-9270-3fa338a59359.png)] for
    any layer, and therefore [![](img/944cd03c-040e-45c8-9bb1-1547d1008bd7.png)] for
    any layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, let''s say we have a sequence of layers where the following applies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fe64b72a-110b-4725-9b1e-36259211544c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, we have the following fundamental equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/12977aa0-3f9f-4e34-80ec-35760bb18f06.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/9fa73368-1629-499f-aacf-6e8f707914b8.png)'
  prefs: []
  type: TYPE_IMG
- en: By using these two equations, we can calculate the derivatives for the cost
    with respect to each layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we set ![](img/cdeb3c79-172c-4362-bd0d-0a524fb30cbe.png) , then δ*[j]^([(l+1)])* represents
    the variation in cost with respect to the activation value, and we can think of
    δ*[j]^([(l+1)])* as the error at neuron *y[j]^([(l+1)])*. We can rewrite these
    equations as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a622a08e-7657-4b31-8480-de8e99875315.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Following this, we can write the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/19ad376c-3380-41ba-8234-1c7ba5b8bdbe.png)'
  prefs: []
  type: TYPE_IMG
- en: These two equations provide us with an alternative view of backpropagation since
    there is a variation in cost with respect to the activation value. They provide
    us with a way to calculate the variation for any layer *l* once we know the variation
    for the following layer, *l+1*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can combine these equations to show the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6e2b1ad1-9a70-419e-acb7-ad1b25411f4b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The updated rule for the weights of each layer is given by the following equation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b266473d-8d0e-4086-9f57-69b057f810d5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we''re familiar with backpropagation, let''s discuss another component
    of the training process: weight initialization.'
  prefs: []
  type: TYPE_NORMAL
- en: Weight initialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One key component of training deep networks is the random weight initialization.
    This matters because some activation functions, such as sigmoid and ReLU, produce
    meaningful outputs and gradients if their inputs are within a certain range.
  prefs: []
  type: TYPE_NORMAL
- en: A famous example is the vanishing gradient problem. To understand it, let's
    take an FC layer with sigmoid activation (this example is also valid for tanh).
    We saw the sigmoid's graph (blue) and its derivative (green) in the *Activation
    functions* section. If the weighted sum of the inputs falls roughly outside the (-5,
    5) range, the sigmoid activation will be effectively 0 or 1\. In essence, it saturates.
    This is visible during the backward pass where we derive the sigmoid (the formula
    is *σ' = **σ(1 - σ)*). We can see that the derivative is larger than 0 within
    the same (-5, 5) range of the input. Therefore, whatever error we try to propagate
    back to the previous layers, it will vanish if the activation doesn't fall within
    this range (hence the name).
  prefs: []
  type: TYPE_NORMAL
- en: Besides the tight meaningful range of the sigmoid derivative, let's note that,
    even under the best conditions, its maximum value is 0.25\. When we propagate
    the gradient through the sigmoid derivative, it will be four times smaller at
    best once it passes through. Because of this, the gradient may vanish in just
    a few layers, even if we don't fall outside the desired range. This is one of
    the major disadvantages of sigmoid over the *LU family of functions, where the
    gradient is 1 in most cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to solve this problem is to use *LU activations. But even so, it still
    makes sense to use better weight initialization since it can speed up the training
    process. One popular technique is the Xavier/Glorot initializer (often found under
    either of the two names: [http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)).
    In short, this technique takes the number of input and output connections of the
    unit into account. There are two variations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Xavier uniform initializer**, which draws samples from a uniform distribution
    in the range [-a, a]. The parameter, a, is defined as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/1d4472a0-1575-4512-9897-6b8d20a85b7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *n[in]* and *n[out]* are the number of inputs and outputs, respectively
    (that is, the number of units that send their output to the current unit and the
    number of units the current unit sends its output to).
  prefs: []
  type: TYPE_NORMAL
- en: '**Xavier normal initializer**, which draws samples from a normal distribution
    (see the *Probability distributions* section) with a mean of 0 and variance as
    follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3391fd8c-4eb8-4a03-a3f3-a554a21786e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Xavier/Glorot initialization is recommended for sigmoid or tanh activations
    functions. The paper *Delving Deep into Rectifiers: Surpassing Human-Level Performance
    on ImageNet Classification* ([https://arxiv.org/abs/1502.01852](https://arxiv.org/abs/1502.01852))
    proposes a similar technique that''s better suited for ReLU activations. Again,
    there are two variations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**He uniform initializer**, which draws samples from a uniform distribution
    in the range [-a, a]. The parameter, a, is defined as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/f7816ef0-6745-4756-b693-71c54dc13181.png)'
  prefs: []
  type: TYPE_IMG
- en: '**He normal initializer**, which draws samples from a normal distribution with
    a mean of 0 and variance as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/798e9c12-982e-491f-b9e7-16d7a31ea90c.png)'
  prefs: []
  type: TYPE_IMG
- en: The ReLU output is always 0 when the input is negative. If we assume that the
    initial inputs of the ReLU units are centered around 0, half of them will produce
    0 outputs. The He initializer compensates this by increasing the variance twice,
    compared to the Xavier initialization.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss some improvements in the weight update rule
    over the standard SGD.
  prefs: []
  type: TYPE_NORMAL
- en: SGD improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll start with **momentum**, which extends vanilla SGD by adjusting the current
    weight update with the values of the previous weight updates. That is, if the
    weight update at step *t-1* was big, it will also increase the weight update of
    step *t*. We can explain momentum with an analogy. Think of the loss function
    surface as the surface of a hill. Now, imagine that we are holding a ball at the
    top of the hill (maximum). If we drop the ball, thanks to the Earth's gravity,
    it will start rolling toward the bottom of the hill (minimum). The more distance
    it travels, the more its speed will increase. In other words, it will gain momentum
    (hence the name of the optimization).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s look at how to implement momentum in the weight update rule. Recall
    the update rule that we introduced in the *Gradient descent* section, that is, [![](img/2547d3e8-4eab-46b2-be9f-56163d2f81b2.png)].
    Let''s assume that we are at step *t* of the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll calculate the current weight update value *v[t]* by also including
    the **velocity** of the previous update *v[t-1]*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ce482d72-124d-4535-93d0-de41f1f1c0c6.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, μ is a hyperparameter in the [0:1] range called the momentum rate. *v[t]*
    is initialized as 0 during the first iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we perform the actual weight update:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1716068c-45f5-4605-b5c7-3c9b42665c54.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An improvement over the basic momentum is the **Nesterov momentum**. It relies
    on the observation that the momentum from step *t-1* may not reflect the conditions
    at step *t*. For example, let''s say that the gradient at *t-1* is steep and therefore
    the momentum is high. However, after the *t-1* weight update, we actually reach
    the cost function minimum and require only a minor weight update at *t*. Despite
    that, we''ll still get the large momentum from *t-1*, which may lead the adjusted
    weight to jump over the minimum. Nesterov momentum proposes a change in the way
    we compute the velocity of the weight update. We''ll calculate *v[t]* based on
    the gradient of the cost function that''s computed by the potential future value
    of the weight *θ[j]*. The following is the updated velocity formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03baa9fb-5d82-45f6-8740-095ed92c6f88.png)'
  prefs: []
  type: TYPE_IMG
- en: If the momentum at *t-1* is incorrect with respect to *t*, the modified gradient
    will compensate for this error in the same update step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s discuss the Adam adaptive learning rate algorithm (*Adam: A Method
    for Stochastic Optimization*, [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)).
    It calculates individual and adaptive learning rates for every weight based on
    previous weight updates (momentum). Let''s see how that works:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to compute the first moment (or mean) and the second moment
    (or variance) of the gradient:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/274ca96c-8518-4c6e-b03e-b1a12f9d7993.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, β[1] and β[2] are hyperparameters with default values of 0.9 and 0.999,
    respectively. *m[t]* and *v[t]* act as moving-average values of the gradient,
    somewhat similar to momentum. They are initialized with 0 during the first iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since *m[t]* and *v[t]* start as 0, they will have a bias toward 0 in the initial
    phase of the training. For example, let''s say that, at *t=1, β1 = 0.9* and ![](img/3d8d6c89-32c0-4cb3-b1f4-92cd4aec489a.png) =
    10\. Here, *m1 = 0.9 * 0 + (1 - 0.9) * 10 = 1*, which is a lot less than the actual
    gradient of 10\. To compensate for this bias, we''ll compute the bias-corrected
    versions of *m[t]* and *v[t]*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8f26742b-e907-4cd6-8414-31dd3745e614.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we need to perform the weight update using the following formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f47df8a1-7ac4-49a8-8a56-a0337c443779.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, η is the learning rate and ε is some small value to prevent division by
    0.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started this chapter with a tutorial on the mathematical apparatus that forms
    the foundation of NNs. Then, we recapped on NNs and their architecture. Along
    the way, we tried to explicitly connect the mathematical concepts with the various
    components of the NNs. We paid special attention to the various types of activation
    functions. Finally, we took a comprehensive look at the NN training process. We
    discussed gradient descent, cost functions, backpropagation, weights initialization,
    and SGD optimization techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll discuss the intricacies of convolutional networks
    and their applications in the computer vision domain.
  prefs: []
  type: TYPE_NORMAL
