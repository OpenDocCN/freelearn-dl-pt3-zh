["```\nimport math\nimport os\nimport hashlib\nfrom urllib.request import urlretrieve\nimport zipfile\nimport gzip\nimport shutil\n\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport utils\n\nimport tensorflow as tf\n```", "```\n#Downloading celebA dataset\ncelebA_data_dir = 'input'\nutils.download_extract('celeba', celebA_data_dir)\n```", "```\nOutput:\n\nDownloading celeba: 1.44GB [00:21, 66.6MB/s] \nExtracting celeba...\n```", "```\n#number of images to display\nnum_images_to_show = 25\n\ncelebA_images = utils.get_batch(glob(os.path.join(celebA_data_dir, 'img_align_celeba/*.jpg'))[:num_images_to_show], 28,\n                                28, 'RGB')\npyplot.imshow(utils.images_square_grid(celebA_images, 'RGB'))\n```", "```\nOutput:\n```", "```\n# defining the model inputs\ndef inputs(img_width, img_height, img_channels, latent_space_z_dim):\n    true_inputs = tf.placeholder(tf.float32, (None, img_width, img_height, img_channels),\n                                 'true_inputs')\n    l_space_inputs = tf.placeholder(tf.float32, (None, latent_space_z_dim), 'l_space_inputs')\n    model_learning_rate = tf.placeholder(tf.float32, name='model_learning_rate')\n\n    return true_inputs, l_space_inputs, model_learning_rate\n```", "```\n# Defining the discriminator function\ndef discriminator(input_imgs, reuse=False):\n    # using variable_scope to reuse variables\n    with tf.variable_scope('discriminator', reuse=reuse):\n        # leaky relu parameter\n        leaky_param_alpha = 0.2\n\n        # defining the layers\n        conv_layer_1 = tf.layers.conv2d(input_imgs, 64, 5, 2, 'same')\n        leaky_relu_output = tf.maximum(leaky_param_alpha * conv_layer_1, conv_layer_1)\n\n        conv_layer_2 = tf.layers.conv2d(leaky_relu_output, 128, 5, 2, 'same')\n        normalized_output = tf.layers.batch_normalization(conv_layer_2, training=True)\n        leay_relu_output = tf.maximum(leaky_param_alpha * normalized_output, normalized_output)\n\n        conv_layer_3 = tf.layers.conv2d(leay_relu_output, 256, 5, 2, 'same')\n        normalized_output = tf.layers.batch_normalization(conv_layer_3, training=True)\n        leaky_relu_output = tf.maximum(leaky_param_alpha * normalized_output, normalized_output)\n\n        # reshaping the output for the logits to be 2D tensor\n        flattened_output = tf.reshape(leaky_relu_output, (-1, 4 * 4 * 256))\n        logits_layer = tf.layers.dense(flattened_output, 1)\n        output = tf.sigmoid(logits_layer)\n\n    return output, logits_layer\n```", "```\ndef generator(z_latent_space, output_channel_dim, is_train=True):\n\n    with tf.variable_scope('generator', reuse=not is_train):\n\n        #leaky relu parameter\n        leaky_param_alpha = 0.2\n\n        fully_connected_layer = tf.layers.dense(z_latent_space, 2*2*512)\n\n        #reshaping the output back to 4D tensor to match the accepted format for convolution layer\n        reshaped_output = tf.reshape(fully_connected_layer, (-1, 2, 2, 512))\n        normalized_output = tf.layers.batch_normalization(reshaped_output, training=is_train)\n        leaky_relu_output = tf.maximum(leaky_param_alpha * normalized_output, normalized_output)\n\n        conv_layer_1 = tf.layers.conv2d_transpose(leaky_relu_output, 256, 5, 2, 'valid')\n        normalized_output = tf.layers.batch_normalization(conv_layer_1, training=is_train)\n        leaky_relu_output = tf.maximum(leaky_param_alpha * normalized_output, normalized_output)\n\n        conv_layer_2 = tf.layers.conv2d_transpose(leaky_relu_output, 128, 5, 2, 'same')\n        normalized_output = tf.layers.batch_normalization(conv_layer_2, training=is_train)\n        leaky_relu_output = tf.maximum(leaky_param_alpha * normalized_output, normalized_output)\n\n        logits_layer = tf.layers.conv2d_transpose(leaky_relu_output, output_channel_dim, 5, 2, 'same')\n        output = tf.tanh(logits_layer)\n\n        return output\n```", "```\n# Define the error for the discriminator and generator\ndef model_losses(input_actual, input_latent_z, out_channel_dim):\n    # building the generator part\n    gen_model = generator(input_latent_z, out_channel_dim)\n    disc_model_true, disc_logits_true = discriminator(input_actual)\n    disc_model_fake, disc_logits_fake = discriminator(gen_model, reuse=True)\n\n    disc_loss_true = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_logits_true, labels=tf.ones_like(disc_model_true)))\n\n    disc_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n        logits=disc_logits_fake, labels=tf.zeros_like(disc_model_fake)))\n\n    gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n        logits=disc_logits_fake, labels=tf.ones_like(disc_model_fake)))\n\n    disc_loss = disc_loss_true + disc_loss_fake\n\n    return disc_loss, gen_loss\n```", "```\n# specifying the optimization criteria\ndef model_optimizer(disc_loss, gen_loss, learning_rate, beta1):\n    trainable_vars = tf.trainable_variables()\n    disc_vars = [var for var in trainable_vars if var.name.startswith('discriminator')]\n    gen_vars = [var for var in trainable_vars if var.name.startswith('generator')]\n\n    disc_train_opt = tf.train.AdamOptimizer(\n        learning_rate, beta1=beta1).minimize(disc_loss, var_list=disc_vars)\n\n    update_operations = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n    gen_updates = [opt for opt in update_operations if opt.name.startswith('generator')]\n\n    with tf.control_dependencies(gen_updates):\n        gen_train_opt = tf.train.AdamOptimizer(\n            learning_rate, beta1).minimize(gen_loss, var_list=gen_vars)\n\n    return disc_train_opt, gen_train_opt\n```", "```\n# define a function to visualize some generated images from the generator\ndef show_generator_output(sess, num_images, input_latent_z, output_channel_dim, img_mode):\n    cmap = None if img_mode == 'RGB' else 'gray'\n    latent_space_z_dim = input_latent_z.get_shape().as_list()[-1]\n    examples_z = np.random.uniform(-1, 1, size=[num_images, latent_space_z_dim])\n\n    examples = sess.run(\n        generator(input_latent_z, output_channel_dim, False),\n        feed_dict={input_latent_z: examples_z})\n\n    images_grid = utils.images_square_grid(examples, img_mode)\n    pyplot.imshow(images_grid, cmap=cmap)\n    pyplot.show()\n```", "```\ndef model_train(num_epocs, train_batch_size, z_dim, learning_rate, beta1, get_batches, input_data_shape, data_img_mode):\n    _, image_width, image_height, image_channels = input_data_shape\n\n    actual_input, z_input, leaningRate = inputs(\n        image_width, image_height, image_channels, z_dim)\n\n    disc_loss, gen_loss = model_losses(actual_input, z_input, image_channels)\n\n    disc_opt, gen_opt = model_optimizer(disc_loss, gen_loss, learning_rate, beta1)\n\n    steps = 0\n    print_every = 50\n    show_every = 100\n    model_loss = []\n    num_images = 25\n\n    with tf.Session() as sess:\n\n        # initializing all the variables\n        sess.run(tf.global_variables_initializer())\n\n        for epoch_i in range(num_epocs):\n            for batch_images in get_batches(train_batch_size):\n\n                steps += 1\n                batch_images *= 2.0\n                z_sample = np.random.uniform(-1, 1, (train_batch_size, z_dim))\n\n                _ = sess.run(disc_opt, feed_dict={\n                    actual_input: batch_images, z_input: z_sample, leaningRate: learning_rate})\n                _ = sess.run(gen_opt, feed_dict={\n                    z_input: z_sample, leaningRate: learning_rate})\n\n                if steps % print_every == 0:\n                    train_loss_disc = disc_loss.eval({z_input: z_sample, actual_input: batch_images})\n                    train_loss_gen = gen_loss.eval({z_input: z_sample})\n\n                    print(\"Epoch {}/{}...\".format(epoch_i + 1, num_epocs),\n                          \"Discriminator Loss: {:.4f}...\".format(train_loss_disc),\n                          \"Generator Loss: {:.4f}\".format(train_loss_gen))\n                    model_loss.append((train_loss_disc, train_loss_gen))\n\n                if steps % show_every == 0:\n                    show_generator_output(sess, num_images, z_input, image_channels, data_img_mode)\n```", "```\n# Training the model on CelebA dataset\ntrain_batch_size = 64\nz_dim = 100\nlearning_rate = 0.002\nbeta1 = 0.5\n\nnum_epochs = 1\n\nceleba_dataset = utils.Dataset('celeba', glob(os.path.join(data_dir, 'img_align_celeba/*.jpg')))\nwith tf.Graph().as_default():\n    model_train(num_epochs, train_batch_size, z_dim, learning_rate, beta1, celeba_dataset.get_batches,\n                celeba_dataset.shape, celeba_dataset.image_mode)\n```", "```\n\n Epoch 1/1... Discriminator Loss: 0.9118... Generator Loss: 12.2238\n Epoch 1/1... Discriminator Loss: 0.6119... Generator Loss: 3.2168\n Epoch 1/1... Discriminator Loss: 0.5383... Generator Loss: 2.8054\n Epoch 1/1... Discriminator Loss: 1.4381... Generator Loss: 0.4672\n Epoch 1/1... Discriminator Loss: 0.7815... Generator Loss: 14.8220\n Epoch 1/1... Discriminator Loss: 0.6435... Generator Loss: 9.2591\n Epoch 1/1... Discriminator Loss: 1.5661... Generator Loss: 10.4747\n Epoch 1/1... Discriminator Loss: 1.5407... Generator Loss: 0.5811\n Epoch 1/1... Discriminator Loss: 0.6470... Generator Loss: 2.9002\n Epoch 1/1... Discriminator Loss: 0.5671... Generator Loss: 2.0700\n```", "```\nEpoch 1/1... Discriminator Loss: 0.7950... Generator Loss: 1.5818\nEpoch 1/1... Discriminator Loss: 1.2417... Generator Loss: 0.7094\nEpoch 1/1... Discriminator Loss: 1.1786... Generator Loss: 1.0948\nEpoch 1/1... Discriminator Loss: 1.0427... Generator Loss: 2.8878\nEpoch 1/1... Discriminator Loss: 0.8409... Generator Loss: 2.6785\nEpoch 1/1... Discriminator Loss: 0.8557... Generator Loss: 1.7706\nEpoch 1/1... Discriminator Loss: 0.8241... Generator Loss: 1.2898\nEpoch 1/1... Discriminator Loss: 0.8590... Generator Loss: 1.8217\nEpoch 1/1... Discriminator Loss: 1.1694... Generator Loss: 0.8490\nEpoch 1/1... Discriminator Loss: 0.9984... Generator Loss: 1.0042\n```", "```\n# Lets start by loading the necessary libraries\n%matplotlib inline\n\nimport pickle as pkl\nimport time\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.io import loadmat\nimport tensorflow as tf\nimport os\n\n```", "```\nfrom urllib.request import urlretrieve\nfrom os.path import isfile, isdir\nfrom tqdm import tqdm\ninput_data_dir = 'input/'\n\ninput_data_dir = 'input/'\n\nif not isdir(input_data_dir):\n    raise Exception(\"Data directory doesn't exist!\")\n\nclass DLProgress(tqdm):\n    last_block = 0\n\n    def hook(self, block_num=1, block_size=1, total_size=None):\n        self.total = total_size\n        self.update((block_num - self.last_block) * block_size)\n        self.last_block = block_num\n\nif not isfile(input_data_dir + \"train_32x32.mat\"):\n    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Training Set') as pbar:\n        urlretrieve(\n            'http://ufldl.stanford.edu/housenumbers/train_32x32.mat',\n            input_data_dir + 'train_32x32.mat',\n            pbar.hook)\n\nif not isfile(input_data_dir + \"test_32x32.mat\"):\n    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Training Set') as pbar:\n        urlretrieve(\n            'http://ufldl.stanford.edu/housenumbers/test_32x32.mat',\n            input_data_dir + 'test_32x32.mat',\n            pbar.hook)\n\ntrain_data = loadmat(input_data_dir + 'train_32x32.mat')\ntest_data = loadmat(input_data_dir + 'test_32x32.mat')\n```", "```\nOutput:\n```", "```\ntrainset shape: (32, 32, 3, 73257)\ntestset shape: (32, 32, 3, 26032)\n```", "```\nindices = np.random.randint(0, train_data['X'].shape[3], size=36)\nfig, axes = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(5,5),)\nfor ii, ax in zip(indices, axes.flatten()):\n    ax.imshow(train_data['X'][:,:,:,ii], aspect='equal')\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\nplt.subplots_adjust(wspace=0, hspace=0)\n```", "```\nOutput:\n```", "```\n# Scaling the input images\ndef scale_images(image, feature_range=(-1, 1)):\n    # scale image to (0, 1)\n    image = ((image - image.min()) / (255 - image.min()))\n\n    # scale the image to feature range\n    min, max = feature_range\n    image = image * (max - min) + min\n    return image\n```", "```\nclass Dataset:\n    def __init__(self, train_set, test_set, validation_frac=0.5, shuffle_data=True, scale_func=None):\n        split_ind = int(len(test_set['y']) * (1 - validation_frac))\n        self.test_input, self.valid_input = test_set['X'][:, :, :, :split_ind], test_set['X'][:, :, :, split_ind:]\n        self.test_target, self.valid_target = test_set['y'][:split_ind], test_set['y'][split_ind:]\n        self.train_input, self.train_target = train_set['X'], train_set['y']\n\n        # The street house number dataset comes with lots of labels,\n        # but because we are going to do semi-supervised learning we are going to assume that we don't have all labels\n        # like, assume that we have only 1000\n        self.label_mask = np.zeros_like(self.train_target)\n        self.label_mask[0:1000] = 1\n\n        self.train_input = np.rollaxis(self.train_input, 3)\n        self.valid_input = np.rollaxis(self.valid_input, 3)\n        self.test_input = np.rollaxis(self.test_input, 3)\n\n        if scale_func is None:\n            self.scaler = scale_images\n        else:\n            self.scaler = scale_func\n        self.train_input = self.scaler(self.train_input)\n        self.valid_input = self.scaler(self.valid_input)\n        self.test_input = self.scaler(self.test_input)\n        self.shuffle = shuffle_data\n\n    def batches(self, batch_size, which_set=\"train\"):\n        input_name = which_set + \"_input\"\n        target_name = which_set + \"_target\"\n\n        num_samples = len(getattr(dataset, target_name))\n        if self.shuffle:\n            indices = np.arange(num_samples)\n            np.random.shuffle(indices)\n            setattr(dataset, input_name, getattr(dataset, input_name)[indices])\n            setattr(dataset, target_name, getattr(dataset, target_name)[indices])\n            if which_set == \"train\":\n                dataset.label_mask = dataset.label_mask[indices]\n\n        dataset_input = getattr(dataset, input_name)\n        dataset_target = getattr(dataset, target_name)\n\n        for jj in range(0, num_samples, batch_size):\n            input_vals = dataset_input[jj:jj + batch_size]\n            target_vals = dataset_target[jj:jj + batch_size]\n\n            if which_set == \"train\":\n                # including the label mask in case of training\n                # to pretend that we don't have all the labels\n                yield input_vals, target_vals, self.label_mask[jj:jj + batch_size]\n            else:\n                yield input_vals, target_vals\n```", "```\n# defining the model inputs\ndef inputs(actual_dim, z_dim):\n    inputs_actual = tf.placeholder(tf.float32, (None, *actual_dim), name='input_actual')\n    inputs_latent_z = tf.placeholder(tf.float32, (None, z_dim), name='input_latent_z')\n\n    target = tf.placeholder(tf.int32, (None), name='target')\n    label_mask = tf.placeholder(tf.int32, (None), name='label_mask')\n\n    return inputs_actual, inputs_latent_z, target, label_mask\n```", "```\ndef generator(latent_z, output_image_dim, reuse_vars=False, leaky_alpha=0.2, is_training=True, size_mult=128):\n    with tf.variable_scope('generator', reuse=reuse_vars):\n        # define a fully connected layer\n        fully_conntected_1 = tf.layers.dense(latent_z, 4 * 4 * size_mult * 4)\n\n        # Reshape it from 2D tensor to 4D tensor to be fed to the convolution neural network\n        reshaped_out_1 = tf.reshape(fully_conntected_1, (-1, 4, 4, size_mult * 4))\n        batch_normalization_1 = tf.layers.batch_normalization(reshaped_out_1, training=is_training)\n        leaky_output_1 = tf.maximum(leaky_alpha * batch_normalization_1, batch_normalization_1)\n\n        conv_layer_1 = tf.layers.conv2d_transpose(leaky_output_1, size_mult * 2, 5, strides=2, padding='same')\n        batch_normalization_2 = tf.layers.batch_normalization(conv_layer_1, training=is_training)\n        leaky_output_2 = tf.maximum(leaky_alpha * batch_normalization_2, batch_normalization_2)\n\n        conv_layer_2 = tf.layers.conv2d_transpose(leaky_output_2, size_mult, 5, strides=2, padding='same')\n        batch_normalization_3 = tf.layers.batch_normalization(conv_layer_2, training=is_training)\n        leaky_output_3 = tf.maximum(leaky_alpha * batch_normalization_3, batch_normalization_3)\n\n        # defining the output layer\n        logits_layer = tf.layers.conv2d_transpose(leaky_output_3, output_image_dim, 5, strides=2, padding='same')\n\n        output = tf.tanh(logits_layer)\n\n        return output\n```", "```\n# Defining the discriminator part of the network\ndef discriminator(input_x, reuse_vars=False, leaky_alpha=0.2, drop_out_rate=0., num_classes=10, size_mult=64):\n    with tf.variable_scope('discriminator', reuse=reuse_vars):\n\n        # defining a dropout layer\n        drop_out_output = tf.layers.dropout(input_x, rate=drop_out_rate / 2.5)\n\n        # Defining the input layer for the discriminator which is 32x32x3\n        conv_layer_3 = tf.layers.conv2d(input_x, size_mult, 3, strides=2, padding='same')\n        leaky_output_4 = tf.maximum(leaky_alpha * conv_layer_3, conv_layer_3)\n        leaky_output_4 = tf.layers.dropout(leaky_output_4, rate=drop_out_rate)\n\n        conv_layer_4 = tf.layers.conv2d(leaky_output_4, size_mult, 3, strides=2, padding='same')\n        batch_normalization_4 = tf.layers.batch_normalization(conv_layer_4, training=True)\n        leaky_output_5 = tf.maximum(leaky_alpha * batch_normalization_4, batch_normalization_4)\n\n        conv_layer_5 = tf.layers.conv2d(leaky_output_5, size_mult, 3, strides=2, padding='same')\n        batch_normalization_5 = tf.layers.batch_normalization(conv_layer_5, training=True)\n        leaky_output_6 = tf.maximum(leaky_alpha * batch_normalization_5, batch_normalization_5)\n        leaky_output_6 = tf.layers.dropout(leaky_output_6, rate=drop_out_rate)\n\n        conv_layer_6 = tf.layers.conv2d(leaky_output_6, 2 * size_mult, 3, strides=1, padding='same')\n        batch_normalization_6 = tf.layers.batch_normalization(conv_layer_6, training=True)\n        leaky_output_7 = tf.maximum(leaky_alpha * batch_normalization_6, batch_normalization_6)\n\n        conv_layer_7 = tf.layers.conv2d(leaky_output_7, 2 * size_mult, 3, strides=1, padding='same')\n        batch_normalization_7 = tf.layers.batch_normalization(conv_layer_7, training=True)\n        leaky_output_8 = tf.maximum(leaky_alpha * batch_normalization_7, batch_normalization_7)\n\n        conv_layer_8 = tf.layers.conv2d(leaky_output_8, 2 * size_mult, 3, strides=2, padding='same')\n        batch_normalization_8 = tf.layers.batch_normalization(conv_layer_8, training=True)\n        leaky_output_9 = tf.maximum(leaky_alpha * batch_normalization_8, batch_normalization_8)\n        leaky_output_9 = tf.layers.dropout(leaky_output_9, rate=drop_out_rate)\n\n        conv_layer_9 = tf.layers.conv2d(leaky_output_9, 2 * size_mult, 3, strides=1, padding='valid')\n\n        leaky_output_10 = tf.maximum(leaky_alpha * conv_layer_9, conv_layer_9)\n```", "```\n...\n```", "```\n...\n```", "```\n# Flatten it by global average pooling\nleaky_output_features = tf.reduce_mean(leaky_output_10, (1, 2))\n```", "```\n...\n```", "```\n[BATCH_SIZE, 8, 8, NUM_CHANNELS] \n```", "```\n [BATCH_SIZE, 1, 1, NUM_CHANNELS] \n```", "```\n[BATCH_SIZE, NUM_CHANNELS].\n```", "```\n...\n# Get the probability that the input is real rather than fake\nsoftmax_output = tf.nn.softmax(classes_logits)s\n...\n```", "```\n# Defining the discriminator part of the network\ndef discriminator(input_x, reuse_vars=False, leaky_alpha=0.2, drop_out_rate=0., num_classes=10, size_mult=64):\n    with tf.variable_scope('discriminator', reuse=reuse_vars):\n\n        # defining a dropout layer\n        drop_out_output = tf.layers.dropout(input_x, rate=drop_out_rate / 2.5)\n\n        # Defining the input layer for the discrminator which is 32x32x3\n        conv_layer_3 = tf.layers.conv2d(input_x, size_mult, 3, strides=2, padding='same')\n        leaky_output_4 = tf.maximum(leaky_alpha * conv_layer_3, conv_layer_3)\n        leaky_output_4 = tf.layers.dropout(leaky_output_4, rate=drop_out_rate)\n\n        conv_layer_4 = tf.layers.conv2d(leaky_output_4, size_mult, 3, strides=2, padding='same')\n        batch_normalization_4 = tf.layers.batch_normalization(conv_layer_4, training=True)\n        leaky_output_5 = tf.maximum(leaky_alpha * batch_normalization_4, batch_normalization_4)\n\n        conv_layer_5 = tf.layers.conv2d(leaky_output_5, size_mult, 3, strides=2, padding='same')\n        batch_normalization_5 = tf.layers.batch_normalization(conv_layer_5, training=True)\n        leaky_output_6 = tf.maximum(leaky_alpha * batch_normalization_5, batch_normalization_5)\n        leaky_output_6 = tf.layers.dropout(leaky_output_6, rate=drop_out_rate)\n\n        conv_layer_6 = tf.layers.conv2d(leaky_output_6, 2 * size_mult, 3, strides=1, padding='same')\n        batch_normalization_6 = tf.layers.batch_normalization(conv_layer_6, training=True)\n        leaky_output_7 = tf.maximum(leaky_alpha * batch_normalization_6, batch_normalization_6)\n\n        conv_layer_7 = tf.layers.conv2d(leaky_output_7, 2 * size_mult, 3, strides=1, padding='same')\n        batch_normalization_7 = tf.layers.batch_normalization(conv_layer_7, training=True)\n        leaky_output_8 = tf.maximum(leaky_alpha * batch_normalization_7, batch_normalization_7)\n\n        conv_layer_8 = tf.layers.conv2d(leaky_output_8, 2 * size_mult, 3, strides=2, padding='same')\n        batch_normalization_8 = tf.layers.batch_normalization(conv_layer_8, training=True)\n        leaky_output_9 = tf.maximum(leaky_alpha * batch_normalization_8, batch_normalization_8)\n        leaky_output_9 = tf.layers.dropout(leaky_output_9, rate=drop_out_rate)\n\n        conv_layer_9 = tf.layers.conv2d(leaky_output_9, 2 * size_mult, 3, strides=1, padding='valid')\n\n        leaky_output_10 = tf.maximum(leaky_alpha * conv_layer_9, conv_layer_9)\n\n        # Flatten it by global average pooling\n        leaky_output_features = tf.reduce_mean(leaky_output_10, (1, 2))\n\n        # Set class_logits to be the inputs to a softmax distribution over the different classes\n        classes_logits = tf.layers.dense(leaky_output_features, num_classes + extra_class)\n\n        if extra_class:\n            actual_class_logits, fake_class_logits = tf.split(classes_logits, [num_classes, 1], 1)\n            assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n            fake_class_logits = tf.squeeze(fake_class_logits)\n        else:\n            actual_class_logits = classes_logits\n            fake_class_logits = 0.\n\n        max_reduced = tf.reduce_max(actual_class_logits, 1, keep_dims=True)\n        stable_actual_class_logits = actual_class_logits - max_reduced\n\n        gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_actual_class_logits), 1)) + tf.squeeze(\n            max_reduced) - fake_class_logits\n\n        softmax_output = tf.nn.softmax(classes_logits)\n\n        return softmax_output, classes_logits, gan_logits, leaky_output_features\n```", "```\ndef model_losses(input_actual, input_latent_z, output_dim, target, num_classes, label_mask, leaky_alpha=0.2,\n                     drop_out_rate=0.):\n\n        # These numbers multiply the size of each layer of the generator and the discriminator,\n        # respectively. You can reduce them to run your code faster for debugging purposes.\n        gen_size_mult = 32\n        disc_size_mult = 64\n\n        # Here we run the generator and the discriminator\n        gen_model = generator(input_latent_z, output_dim, leaky_alpha=leaky_alpha, size_mult=gen_size_mult)\n        disc_on_data = discriminator(input_actual, leaky_alpha=leaky_alpha, drop_out_rate=drop_out_rate,\n                                     size_mult=disc_size_mult)\n        disc_model_real, class_logits_on_data, gan_logits_on_data, data_features = disc_on_data\n        disc_on_samples = discriminator(gen_model, reuse_vars=True, leaky_alpha=leaky_alpha,\n                                        drop_out_rate=drop_out_rate, size_mult=disc_size_mult)\n        disc_model_fake, class_logits_on_samples, gan_logits_on_samples, sample_features = disc_on_samples\n\n        # Here we compute `disc_loss`, the loss for the discriminator.\n        disc_loss_actual = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits_on_data,\n                                                    labels=tf.ones_like(gan_logits_on_data)))\n        disc_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits_on_samples,\n                                                    labels=tf.zeros_like(gan_logits_on_samples)))\n        target = tf.squeeze(target)\n        classes_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=class_logits_on_data,\n                                                                        labels=tf.one_hot(target,\n                                                                                          num_classes + extra_class,\n                                                                                          dtype=tf.float32))\n        classes_cross_entropy = tf.squeeze(classes_cross_entropy)\n        label_m = tf.squeeze(tf.to_float(label_mask))\n        disc_loss_class = tf.reduce_sum(label_m * classes_cross_entropy) / tf.maximum(1., tf.reduce_sum(label_m))\n        disc_loss = disc_loss_class + disc_loss_actual + disc_loss_fake\n\n        # Here we set `gen_loss` to the \"feature matching\" loss invented by Tim Salimans.\n        sampleMoments = tf.reduce_mean(sample_features, axis=0)\n        dataMoments = tf.reduce_mean(data_features, axis=0)\n\n        gen_loss = tf.reduce_mean(tf.abs(dataMoments - sampleMoments))\n\n        prediction_class = tf.cast(tf.argmax(class_logits_on_data, 1), tf.int32)\n        check_prediction = tf.equal(tf.squeeze(target), prediction_class)\n        correct = tf.reduce_sum(tf.to_float(check_prediction))\n        masked_correct = tf.reduce_sum(label_m * tf.to_float(check_prediction))\n\n        return disc_loss, gen_loss, correct, masked_correct, gen_model\n```", "```\ndef model_optimizer(disc_loss, gen_loss, learning_rate, beta1):\n\n        # Get weights and biases to update. Get them separately for the discriminator and the generator\n        trainable_vars = tf.trainable_variables()\n        disc_vars = [var for var in trainable_vars if var.name.startswith('discriminator')]\n        gen_vars = [var for var in trainable_vars if var.name.startswith('generator')]\n        for t in trainable_vars:\n            assert t in disc_vars or t in gen_vars\n\n        # Minimize both gen and disc costs simultaneously\n        disc_train_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(disc_loss,\n                                                                                           var_list=disc_vars)\n        gen_train_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)\n        shrink_learning_rate = tf.assign(learning_rate, learning_rate * 0.9)\n\n        return disc_train_optimizer, gen_train_optimizer, shrink_learning_rate\n```", "```\nclass GAN:\n        def __init__(self, real_size, z_size, learning_rate, num_classes=10, alpha=0.2, beta1=0.5):\n            tf.reset_default_graph()\n\n            self.learning_rate = tf.Variable(learning_rate, trainable=False)\n            model_inputs = inputs(real_size, z_size)\n            self.input_actual, self.input_latent_z, self.target, self.label_mask = model_inputs\n            self.drop_out_rate = tf.placeholder_with_default(.5, (), \"drop_out_rate\")\n\n            losses_results = model_losses(self.input_actual, self.input_latent_z,\n                                          real_size[2], self.target, num_classes,\n                                          label_mask=self.label_mask,\n                                          leaky_alpha=0.2,\n                                          drop_out_rate=self.drop_out_rate)\n            self.disc_loss, self.gen_loss, self.correct, self.masked_correct, self.samples = losses_results\n\n            self.disc_opt, self.gen_opt, self.shrink_learning_rate = model_optimizer(self.disc_loss, self.gen_loss,\n                                                                                     self.learning_rate, beta1)\n```", "```\ndef view_generated_samples(epoch, samples, nrows, ncols, figsize=(5, 5)):\n        fig, axes = plt.subplots(figsize=figsize, nrows=nrows, ncols=ncols,\n                                 sharey=True, sharex=True)\n        for ax, img in zip(axes.flatten(), samples[epoch]):\n            ax.axis('off')\n            img = ((img - img.min()) * 255 / (img.max() - img.min())).astype(np.uint8)\n            ax.set_adjustable('box-forced')\n            im = ax.imshow(img)\n\n        plt.subplots_adjust(wspace=0, hspace=0)\n        return fig, axes\n```", "```\ndef train(net, dataset, epochs, batch_size, figsize=(5, 5)):\n\n        saver = tf.train.Saver()\n        sample_z = np.random.normal(0, 1, size=(50, latent_space_z_size))\n\n        samples, train_accuracies, test_accuracies = [], [], []\n        steps = 0\n\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n            for e in range(epochs):\n                print(\"Epoch\", e)\n\n                num_samples = 0\n                num_correct_samples = 0\n                for x, y, label_mask in dataset.batches(batch_size):\n                    assert 'int' in str(y.dtype)\n                    steps += 1\n                    num_samples += label_mask.sum()\n\n                    # Sample random noise for G\n                    batch_z = np.random.normal(0, 1, size=(batch_size, latent_space_z_size))\n\n                    _, _, correct = sess.run([net.disc_opt, net.gen_opt, net.masked_correct],\n                                             feed_dict={net.input_actual: x, net.input_latent_z: batch_z,\n                                                        net.target: y, net.label_mask: label_mask})\n                    num_correct_samples += correct\n\n                sess.run([net.shrink_learning_rate])\n\n                training_accuracy = num_correct_samples / float(num_samples)\n\n                print(\"\\t\\tClassifier train accuracy: \", training_accuracy)\n\n                num_samples = 0\n                num_correct_samples = 0\n\n                for x, y in dataset.batches(batch_size, which_set=\"test\"):\n                    assert 'int' in str(y.dtype)\n                    num_samples += x.shape[0]\n\n                    correct, = sess.run([net.correct], feed_dict={net.input_real: x,\n                                                                  net.y: y,\n                                                                  net.drop_rate: 0.})\n                    num_correct_samples += correct\n\n                testing_accuracy = num_correct_samples / float(num_samples)\n                print(\"\\t\\tClassifier test accuracy\", testing_accuracy)\n\n                gen_samples = sess.run(\n                    net.samples,\n                    feed_dict={net.input_latent_z: sample_z})\n                samples.append(gen_samples)\n                _ = view_generated_samples(-1, samples, 5, 10, figsize=figsize)\n                plt.show()\n\n                # Save history of accuracies to view after training\n                train_accuracies.append(training_accuracy)\n                test_accuracies.append(testing_accuracy)\n\n            saver.save(sess, './checkpoints/generator.ckpt')\n\n        with open('samples.pkl', 'wb') as f:\n            pkl.dump(samples, f)\n\n        return train_accuracies, test_accuracies, samples\n```", "```\nreal_size = (32,32,3)\nlatent_space_z_size = 100\nlearning_rate = 0.0003\n\nnet = GAN(real_size, latent_space_z_size, learning_rate)\n```", "```\ndataset = Dataset(train_data, test_data)\n\ntrain_batch_size = 128\nnum_epochs = 25\ntrain_accuracies, test_accuracies, samples = train(net,\n                                                   dataset,\n                                                   num_epochs,\n                                                   train_batch_size,\n                                                   figsize=(10,5))\n```", "```\nEpoch 24\n                Classifier train accuracy:  0.937\n                Classifier test accuracy 0.67401659496\n                Step time:  0.03694915771484375\n                Epoch time:  26.15842580795288\n```", "```\nfig, ax = plt.subplots()\nplt.plot(train_accuracies, label='Train', alpha=0.5)\nplt.plot(test_accuracies, label='Test', alpha=0.5)\nplt.title(\"Accuracy\")\nplt.legend()\n```"]