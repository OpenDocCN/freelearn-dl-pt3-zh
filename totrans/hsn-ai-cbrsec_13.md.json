["```\nfrom sklearn import preprocessing\n import numpy as np\n raw_data = np.array([\n [ 2., -3., 4.],\n [ 5., 0., 1.],\n [ 4., 0., -2.]])\n min_max_scaler = preprocessing.MinMaxScaler()\n scaled_data = min_max_scaler.fit_transform(raw_data)\n```", "```\nfrom sklearn import preprocessing\nimport numpy as np\nraw_data = np.array([\n[ 2., -3., 4.],\n[ 5., 0., 1.],\n[ 4., 0., -2.]])\nstd_scaler = preprocessing.StandardScaler().fit(raw_data)\nstd_scaler.transform(raw_data)\ntest_data = [[-3., 1., 2.]]\nstd_scaler.transform(test_data)\n```", "```\nfrom sklearn import preprocessing\nimport numpy as np\npt = preprocessing.PowerTransformer(method='box-cox', standardize=False) \nX_lognormal = np.random.RandomState(616).lognormal(size=(3, 3))\npt.fit_transform(X_lognormal)\n```", "```\nfrom sklearn import preprocessing\nord_enc = preprocessing.OrdinalEncoder()\ncat_data = [['Developer', 'Remote Working', 'Windows'], ['Sysadmin', 'Onsite Working', 'Linux']]\nord_enc.fit(cat_data)\nord_enc.transform([['Developer', 'Onsite Working', 'Linux']])\n```", "```\nfrom sklearn import preprocessing\none_hot_enc = preprocessing.OneHotEncoder()\ncat_data = [['Developer', 'Remote Working', 'Windows'], ['Sysadmin', 'Onsite Working', 'Linux']]\none_hot_enc.fit(cat_data)\none_hot_enc.transform([['Developer', 'Onsite Working', 'Linux']])\n```", "```\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\ny_true = np.array([0, 1, 1, 1])\ny_pred = np.array([0.2, 0.7, 0.65, 0.9])\nprec, rec, thres = precision_recall_curve(y_true, y_pred)\naverage_precision_score(y_true, y_pred)\nmetrics.precision_score(y_true, y_pred)\nmetrics.recall_score(y_true, y_pred)\nmetrics.f1_score(y_true, y_pred)\n```", "```\nimport numpy as np\nfrom sklearn.metrics import roc_curve\ny_true = np.array([0, 1, 1, 1])\ny_pred = np.array([0.2, 0.7, 0.65, 0.9])\nFPR, TPR, THR = roc_curve(y_true, y_pred)\n```", "```\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\ny_true = np.array([0, 1, 1, 1])\ny_pred = np.array([0.2, 0.7, 0.65, 0.9])\nroc_auc_score(y_true, y_pred)\n```", "```\n import numpy as np\n from sklearn.metrics import brier_score_loss\n y_true = np.array([0, 1, 1, 1])\n y_cats = np.array([\"fraud\", \"legit\", \"legit\", \"legit\"])\n y_prob = np.array([0.2, 0.7, 0.9, 0.3])\n y_pred = np.array([1, 1, 1, 0])\n brier_score_loss(y_true, y_prob)\n brier_score_loss(y_cats, y_prob, pos_label=\"legit\")\n brier_score_loss(y_true, y_prob > 0.5)\n```", "```\nfrom sklearn.model_selection import train_test_split\n# Create training and testing subsets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n```", "```\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.svm import SVC\n_sizes = [ 60, 80, 100]\ntrain_sizes, train_scores, valid_scores = learning_curve(SVC(), X, y, train_sizes=_sizes)\n```", "```\nimport numpy as np\nfrom sklearn.model_selection import KFold\nX = np.array([[1., 0.], [2., 1.], [-2., -1.], [3., 2.]])\ny = np.array([0, 1, 0, 1])\nk_folds = KFold(n_splits=2)\nfor train, test in k_folds.split(X):\nprint(\"%s %s\" % (train, test))\n[2 0] [3 1]\n[3 1] [2 0]\nX_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n```"]