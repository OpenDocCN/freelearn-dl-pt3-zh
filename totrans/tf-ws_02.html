<html><head></head><body>
		<div>
			<div id="_idContainer105" class="Content">
			</div>
		</div>
		<div id="_idContainer106" class="Content">
			<h1 id="_idParaDest-44"><a id="_idTextAnchor044"/>2. Loading and Processing Data</h1>
		</div>
		<div id="_idContainer126" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">In this chapter, you will learn how to load and process a variety of data types for modeling in TensorFlow. You will implement methods to input data into TensorFlow models so that model training can be optimized. </p>
			<p class="callout">By the end of this chapter, you will know how to input tabular data, images, text, and audio data and preprocess them so that they are suitable for training TensorFlow models.</p>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor045"/>Introduction</h1>
			<p>In the previous chapter, you learned how to create, utilize, and apply linear transformations to tensors using TensorFlow. The chapter started with the definition of tensors and how they can be created using the <strong class="source-inline">Variable</strong> class in the TensorFlow library. You then created tensors of various ranks and learned how to apply tensor addition, reshaping, transposition, and multiplication using the library. These are all examples of linear transformations. You concluded that chapter by covering optimization methods and activation functions and how they can be accessed in the TensorFlow library.</p>
			<p>When training machine learning models in TensorFlow, you must supply the model with training data. The raw data that is available may come in a variety of formats—for example, tabular CSV files, images, audio, or text files. Different data sources are loaded and preprocessed in different ways in order to provide numerical tensors for TensorFlow models. For example, virtual assistants use voice queries as input interaction and then apply machine learning models to decipher input speech and perform specific actions as output. To create the models for this task, the audio data of the speech input must be loaded into memory. A preprocessing step also needs to be involved that converts the audio input into text. Following this, the text is converted into numerical tensors for model training. This is one example that demonstrates the complexity of creating models from non-tabular, non-numerical data such as audio data.</p>
			<p>This chapter will explore a few of the common data types that are utilized for building machine learning models. You will load raw data into memory in an efficient manner, and then perform some preprocessing steps to convert the raw data into numerical tensors that are appropriate for training machine learning models. Luckily, machine learning libraries have advanced significantly, which means that training models with data types such as images, text, and audio is extremely accessible to practitioners.</p>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor046"/>Exploring Data Types</h1>
			<p>Depending on the source, raw data can be of different forms. Common forms of data include tabular data, images, video, audio, and text. For example, the output from a temperature logger (used to record the temperature at a given location over time) is tabular. Tabular data is structured with rows and columns, and, in the example of a temperature logger, each column may represent a characteristic for each record, such as the time, location, and temperature, while each row may represent the values of each record. The following table shows an example of numerical tabular data:</p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B16341_02_01.jpg" alt="Figure 2.1: An example of 10 rows of tabular data that consists of numerical values&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1: An example of 10 rows of tabular data that consists of numerical values</p>
			<p>Image data represents another common form of raw data that is popular for building machine learning models. These models are popular due to the large volume of data that's available. With smartphones and security cameras recording all of life's moments, they have generated an enormous amount of data that can be used to train models.</p>
			<p>The dimensions of image data for training are different than they are for tabular data. Each image has a height and width dimension, as well as a color channel adding a third dimension, and the quantity of images adding a fourth. As such, the input tensors for image data models are four-dimensional tensors, whereas the input tensors for tabular data are two-dimensional. The following figure shows an example of labeled training examples of boats and airplanes taken from the <strong class="source-inline">Open Images</strong> dataset (<a href="https://storage.googleapis.com/openimages/web/index.html">https://storage.googleapis.com/openimages/web/index.html</a>); the images have been preprocessed so that they all have the same height and width. This data could be used, for example, to train a binary classification model to classify images as boats or airplanes:</p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B16341_02_02.jpg" alt="Figure 2.2: A sample of image data that can be used for training machine learning models"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2: A sample of image data that can be used for training machine learning models</p>
			<p>Other types of raw data that can be used to build machine learning models include text and audio. Like images, their popularity in the machine learning community is derived from the large amount of data that's available. Both audio and text have the challenge of having indeterminate sizes. You will explore how this challenge can be overcome later in this chapter. The following figure shows an audio sample with a sample rate of 44.1 kHz, which means the audio data is sampled 44,100 times per second. This is an example of the type of raw data that is input into virtual assistants, from which they decipher the request and act accordingly:</p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B16341_02_03.jpg" alt="Figure 2.3: A visual representation of audio data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3: A visual representation of audio data</p>
			<p>Now that you know about some of the types of data you may encounter when building machine learning models, in the next section, you will uncover ways to preprocess different types of data.</p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor047"/>Data Preprocessing</h1>
			<p>Data preprocessing refers to the process in which raw data is converted into a form that is appropriate for machine learning models to use as input. Each different data type will require different preprocessing steps, with the minimum requirement that the resulting tensor is composed solely of numerical elements, such as integers or decimal numbers. Numerical tensors are required since models rely on linear transformations such as addition and multiplication, which can only be performed on numerical tensors. </p>
			<p>While many datasets exist with solely numerical fields, many do not. They may have fields that are of the string, Boolean, categorical, or date data types that must all be converted into numerical fields. Some may be trivial; a Boolean field can be mapped so that <strong class="source-inline">true</strong> values are equal to <strong class="source-inline">1</strong> and <strong class="source-inline">false</strong> values are equal to <strong class="source-inline">0</strong>. Therefore, mapping a Boolean field to a numerical field is simple and all the necessary information is preserved. However, when converting other data types, such as date fields, you may lose information when converting into numerical fields unless it's explicitly stated otherwise.</p>
			<p>One example of a possible loss of information occurs when converting a date field into a numerical field by using Unix time. Unix time represents the number of seconds that have elapsed since the Unix epoch; that is, 00:00:00 UTC on January 1, 1970, and leap seconds are ignored. Using Unix time removes the explicit indication of the month, day of the week, hour of the day, and so on, which may act as important features when training a model.</p>
			<p>When converting fields into numerical data types, it is important to preserve as much informational context as possible as it will aid any model that is trained to understand the relationship between the features and the target. The following diagram demonstrates how a date field can be converted into a series of numerical fields:</p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B16341_02_04.jpg" alt="Figure 2.4: A numerical encoding of a date column&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4: A numerical encoding of a date column</p>
			<p>As shown in the preceding diagram, on the left, the date field represents a given date, while on the right, there is a method providing numerical information:</p>
			<ul>
				<li>The year is extracted from the date, which is an integer.</li>
				<li>The month is one-hot encoded. There is a column for each month of the year and the month is binary encoded, if the date's month corresponds with the column's name.</li>
				<li>A column is created indicating whether the date occurs on a weekend.</li>
			</ul>
			<p>This is just a method to encode the <strong class="source-inline">date</strong> column here; not all the preceding methods are necessary and there are many more that can be used. Encoding all the fields into numerical fields appropriately is important to create performant machine learning models that can learn the relationships between the features and the target.</p>
			<p>Data normalization is another preprocessing technique used to speed up the training process. The normalization process rescales the fields so that they are all of the same scale. This will also help ensure that the weights of the model are of the same scale.</p>
			<p>In the preceding diagram, the <strong class="source-inline">year</strong> column has the order of magnitude <strong class="source-inline">10</strong><span class="superscript">3</span>, and the other columns have the order <strong class="source-inline">10</strong><span class="superscript">0</span>. This implies there are three orders of magnitude between the columns. Fields with values that are very different in scale will result in a less accurate model as the optimal weights to minimize the error function may not be discovered. This may be due to the tolerance limits or the learning rate that are defined as hyperparameters prior to training not being optimal for both scales when the weights are updated. In the preceding example, it may be beneficial to rescale the <strong class="source-inline">year</strong> column so that it has the same order of magnitude as the other columns.</p>
			<p>Throughout this chapter, you will explore a variety of methods that can be used to preprocess tabular data, image data, text data, and audio data so that it can be used to train machine learning models.</p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor048"/>Processing Tabular Data</h1>
			<p>In this section, you will learn how to load tabular data into a Python development environment so that it can be used for TensorFlow modeling. You will use pandas and scikit-learn to utilize the classes and functions that are useful for processing data. You will also explore methods that can be used to preprocess this data.</p>
			<p>Tabular data can be loaded into memory by using the pandas <strong class="source-inline">read_csv</strong> function and passing the path into the dataset. The function is well suited and easy to use for loading in tabular data and can be used as follows:</p>
			<p class="source-code">df = pd.read_csv('path/to/dataset')</p>
			<p>In order to normalize the data, you can use a scaler that is available in scikit-learn. There are multiple scalers that can be applied; <strong class="source-inline">StandardScaler</strong> will normalize the data so that the fields of the dataset have a mean of <strong class="source-inline">0</strong> and a standard deviation of <strong class="source-inline">1</strong>. Another common scaler that is used is <strong class="source-inline">MinMaxScaler</strong>, which will rescale the dataset so that the fields have a minimum value of <strong class="source-inline">0</strong> and a maximum value of <strong class="source-inline">1</strong>. </p>
			<p>To use a scaler, it must be initialized and fit to the dataset. By doing this, the dataset can be transformed by the scaler. In fact, the fitting and transformation processes can be performed in one step by using the <strong class="source-inline">fit_transform</strong> method, as follows:</p>
			<p class="source-code">scaler = StandardScaler()</p>
			<p class="source-code">transformed_df = scaler.fit_transform(df)</p>
			<p>In the first exercise, you will learn how to use pandas and scikit-learn to load a dataset and preprocess it so that it is suitable for modeling.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor049"/>Exercise 2.01: Loading Tabular Data and Rescaling Numerical Fields</h2>
			<p>The dataset, <strong class="source-inline">Bias_correction_ucl.csv</strong>, contains information for bias correction of the next-day maximum and minimum air temperature forecast for Seoul, South Korea. The fields represent temperature measurements of the given date, the weather station at which the metrics were measured, model forecasts of weather-related metrics such as humidity, and projections for the temperature of the following day. You are required to preprocess the data to make all the columns normally distributed with a mean of <strong class="source-inline">0</strong> and a standard deviation of <strong class="source-inline">1</strong>. You will demonstrate the effects with the <strong class="source-inline">Present_Tmax</strong> column, which represents the maximum temperature on the given date at a given weather station.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset can be found here: <a href="https://packt.link/l83pR">https://packt.link/l83pR</a>.</p>
			<p>Perform the following steps to complete this exercise:</p>
			<ol>
				<li>Open a new Jupyter notebook to implement this exercise. Save the file as <strong class="source-inline">Exercise2-01.ipnyb</strong>. </li>
				<li>In a new Jupyter Notebook cell, import the pandas library, as follows:<p class="source-code">import pandas as pd</p><p class="callout-heading">Note</p><p class="callout">You can find the documentation for pandas at the following link: <a href="https://pandas.pydata.org/docs/">https://pandas.pydata.org/docs/</a>.</p></li>
				<li>Create a new pandas DataFrame named <strong class="source-inline">df</strong> and read the <strong class="source-inline">Bias_correction_ucl.csv</strong> file into it. Examine whether your data is properly loaded by printing the resultant DataFrame:<p class="source-code">df = pd.read_csv(<strong class="bold">'Bias_correction_ucl.csv'</strong>)</p><p class="source-code">df</p><p class="callout-heading">Note </p><p class="callout">Make sure you change the path (highlighted) to the CSV file based on its location on your system. If you're running the Jupyter notebook from the same directory where the CSV file is stored, you can run the preceding code without any modification. </p><p>The output will be as follows:</p><div id="_idContainer111" class="IMG---Figure"><img src="image/B16341_02_05.jpg" alt="Figure 2.5: The output from printing the DataFrame&#13;&#10;"/></div><p class="figure-caption">Figure 2.5: The output from printing the DataFrame</p></li>
				<li>Drop the <strong class="source-inline">date</strong> column using the <strong class="source-inline">drop</strong> method of the DataFrame and pass in the name of the column. The <strong class="source-inline">date</strong> column will be dropped as it is a non-numerical field and rescaling will not be possible when non-numerical fields exist. Since you are dropping a column, both the <strong class="source-inline">axis=1</strong> argument and the <strong class="source-inline">inplace=True</strong> argument should be passed:<p class="source-code">df.drop('Date', inplace=True, axis=1)</p></li>
				<li>Plot a histogram of the <strong class="source-inline">Present_Tmax</strong> column that represents the maximum temperature across dates and weather stations within the dataset:<p class="source-code">ax = df['Present_Tmax'].hist(color='gray')</p><p class="source-code">ax.set_xlabel("Temperature")</p><p class="source-code">ax.set_ylabel("Frequency")</p><p>The output will be as follows:</p><div id="_idContainer112" class="IMG---Figure"><img src="image/B16341_02_06.jpg" alt="Figure 2.6: A Temperature versus Frequency histogram of the Present_Tmax column&#13;&#10;"/></div><p class="figure-caption">Figure 2.6: A Temperature versus Frequency histogram of the Present_Tmax column</p><p>The resultant histogram shows the distribution of values for the <strong class="source-inline">Present_Tmax</strong> column. You can see that the temperature values vary from 20 to 38 degrees Celsius. Plotting a histogram of the feature values is a good way to view the distribution of values to understand whether scaling is required as a preprocessing step.</p></li>
				<li>Import the <strong class="source-inline">StandardScaler</strong> class from scikit-learn's preprocessing package. Initialize the scaler, fit the scaler, and transform the DataFrame using the scaler's <strong class="source-inline">fit_transform</strong> method. Create a new DataFrame, <strong class="source-inline">df2</strong>, using the transformed DataFrame since the result of the <strong class="source-inline">fit_transform</strong> method is a NumPy array. The standard scaler will transform the numerical fields so that the mean of the field is <strong class="source-inline">0</strong> and the standard deviation is <strong class="source-inline">1</strong>:<p class="source-code">from sklearn.preprocessing import StandardScaler</p><p class="source-code">scaler = StandardScaler()</p><p class="source-code">df2 = scaler.fit_transform(df)</p><p class="source-code">df2 = pd.DataFrame(df2, columns=df.columns)</p><p class="callout-heading">Note</p><p class="callout">The values for the mean and standard deviation of the resulting transformed data can be input into the scaler.</p></li>
				<li>Plot a histogram of the transformed <strong class="source-inline">Present_Tmax</strong> column:<p class="source-code">ax = df2['Present_Tmax'].hist(color='gray')</p><p class="source-code">ax.set_xlabel("Normalized Temperature")</p><p class="source-code">ax.set_ylabel("Frequency")</p><p>The output will be as follows:</p><div id="_idContainer113" class="IMG---Figure"><img src="image/B16341_02_07.jpg" alt="Figure 2.7: A histogram of the rescaled Present_Tmax column&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.7: A histogram of the rescaled Present_Tmax column</p>
			<p>The resulting histogram shows that the temperature values range from around <strong class="source-inline">-3</strong> to <strong class="source-inline">3</strong> degrees Celsius, as evidenced by the range on the <em class="italic">x</em> axis of the histogram. By using the standard scaler, the values will always have a mean of <strong class="source-inline">0</strong> and a standard deviation of <strong class="source-inline">1</strong>. Having the features normalized can speed up the model training process.</p>
			<p>In this exercise, you successfully imported tabular data using the pandas library and performed some preprocessing using the scikit-learn library. The preprocessing of data included dropping the <strong class="source-inline">date</strong> column and scaling the numerical fields so that they have a mean value of <strong class="source-inline">0</strong> and a standard deviation of <strong class="source-inline">1</strong>.</p>
			<p>In the following activity, you will load in tabular data using the pandas library and scale that data using the <strong class="source-inline">MinMax</strong> scaler present in scikit-learn. You will do so on the same dataset that you used in the prior exercise, which describes the bias correction of air temperature forecasts for Seoul, South Korea.</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor050"/>Activity 2.01: Loading Tabular Data and Rescaling Numerical Fields with a MinMax Scaler</h2>
			<p>In this activity, you are required to load tabular data and rescale the data using a <strong class="source-inline">MinMax</strong> scaler. The dataset, <strong class="source-inline">Bias_correction_ucl.csv</strong>, contains information for bias correction of the next-day maximum and minimum air temperature forecast for Seoul, South Korea. The fields represent temperature measurements of the given date, the weather station at which the metrics were measured, model forecasts of weather-related metrics such as humidity, and projections for the temperature the following day. You are required to scale the columns so that the minimum value of each column is <strong class="source-inline">0</strong> and the maximum value is <strong class="source-inline">1</strong>.</p>
			<p>Perform the following steps to complete this activity:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this activity.</li>
				<li>Import pandas and the <strong class="source-inline">Bias_correction_ucl.csv</strong> dataset.</li>
				<li>Read the dataset using the pandas <strong class="source-inline">read_csv</strong> function.</li>
				<li>Drop the <strong class="source-inline">date</strong> column of the DataFrame.</li>
				<li>Plot a histogram of the <strong class="source-inline">Present_Tmax</strong> column.</li>
				<li>Import <strong class="source-inline">MinMaxScaler</strong> and fit it to and transform the feature DataFrame.</li>
				<li>Plot a histogram of the transformed <strong class="source-inline">Present_Tmax</strong> column.<p>You should get an output similar to the following:</p><div id="_idContainer114" class="IMG---Figure"><img src="image/B16341_02_08.jpg" alt="Figure 2.8: Expected output of Activity 2.01&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.8: Expected output of Activity 2.01</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution to this activity can be found via <a href="B16341_Solution_ePub.xhtml#_idTextAnchor255">this link</a>.</p>
			<p>One method of converting non-numerical fields such as categorical or date fields is to one-hot encode them. The <strong class="bold">one-hot encoding process</strong> creates a new column for each unique value in the provided column, while each row has a value of <strong class="source-inline">0</strong> except for the one that corresponds to the correct column. The column headers of the newly created dummy columns correspond to the unique values. One-hot encoding can be achieved by using the <strong class="source-inline">get_dummies</strong> function of the pandas library and passing in the column to be encoded. An optional argument is to provide a prefix feature that adds a prefix to the column headers. This can be useful for referencing the columns:</p>
			<p class="source-code">dummies = pd.get_dummies(df['feature1'], prefix='feature1')</p>
			<p class="callout-heading">Note</p>
			<p class="callout">When using the <strong class="source-inline">get_dummies</strong> function, <strong class="source-inline">NaN</strong> values are converted into all zeros.</p>
			<p>In the following exercise, you'll learn how to preprocess non-numerical fields. You will utilize the same dataset that you used in the previous exercise and activity, which describes the bias correction of air temperature forecasts for Seoul, South Korea.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor051"/>Exercise 2.02: Preprocessing Non-Numerical Data</h2>
			<p>In this exercise, you will preprocess the <strong class="source-inline">date</strong> column by one-hot encoding the year and the month from the <strong class="source-inline">date</strong> column using the <strong class="source-inline">get_dummies</strong> function. You will join the one-hot-encoded columns with the original DataFrame and ensure that all the fields in the resultant DataFrame are numerical.</p>
			<p>Perform the following steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this exercise. Save the file as <strong class="source-inline">Exercise2-02.ipnyb</strong>.</li>
				<li>In a new Jupyter Notebook cell, import the pandas library, as follows:<p class="source-code">import pandas as pd</p></li>
				<li>Create a new pandas DataFrame named <strong class="source-inline">df</strong> and read the <strong class="source-inline">Bias_correction_ucl.csv</strong> file into it. Examine whether your data is properly loaded by printing the resultant DataFrame:<p class="source-code">df = pd.read_csv(<strong class="bold">'Bias_correction_ucl.csv'</strong>)</p><p class="callout-heading">Note </p><p class="callout">Make sure you change the path (highlighted) to the CSV file based on its location on your system. If you're running the Jupyter notebook from the same directory where the CSV file is stored, you can run the preceding code without any modification. </p></li>
				<li>Change the data type of the <strong class="source-inline">date</strong> column to <strong class="source-inline">Date</strong> using the pandas <strong class="source-inline">to_datetime</strong> function:<p class="source-code">df['Date'] = pd.to_datetime(df['Date'])</p></li>
				<li>Create dummy columns for <strong class="source-inline">year</strong> using the pandas <strong class="source-inline">get_dummies</strong> function. Pass in the year of the <strong class="source-inline">date</strong> column as the first argument and add a prefix to the columns of the resultant DataFrame. Print out the resultant DataFrame:<p class="source-code">year_dummies = pd.get_dummies(df['Date'].dt.year, \</p><p class="source-code">                              prefix='year')</p><p class="source-code">year_dummies</p><p>The output will be as follows:</p><div id="_idContainer115" class="IMG---Figure"><img src="image/B16341_02_09.jpg" alt="Figure 2.9: Output of the get_dummies function applied to the year of the date column&#13;&#10;"/></div><p class="figure-caption">Figure 2.9: Output of the get_dummies function applied to the year of the date column</p><p>The resultant DataFrame contains only 0s and 1s. <strong class="source-inline">1</strong> corresponds to the value present in the original <strong class="source-inline">date</strong> column. Null values will have 0s for all columns in the newly created DataFrame.</p></li>
				<li>Repeat this for the month by creating dummy columns from the month of the <strong class="source-inline">date</strong> column. Print out the resulting DataFrame:<p class="source-code">month_dummies = pd.get_dummies(df['Date'].dt.month, \</p><p class="source-code">                               prefix='month')</p><p class="source-code">month_dummies</p><p>The output will be as follows:</p><div id="_idContainer116" class="IMG---Figure"><img src="image/B16341_02_10.jpg" alt="Figure 2.10: The output of the get_dummies function applied &#13;&#10;to the month of the date column&#13;&#10;"/></div><p class="figure-caption">Figure 2.10: The output of the get_dummies function applied to the month of the date column</p><p>The resultant DataFrame now contains only 0s and 1s for the month in the <strong class="source-inline">date</strong> column.</p></li>
				<li>Concatenate the original DataFrame and the dummy DataFrames you created in <em class="italic">Steps 5</em> and <em class="italic">6</em>:<p class="source-code">df = pd.concat([df, month_dummies, year_dummies], \</p><p class="source-code">               axis=1)</p></li>
				<li>Drop the original <strong class="source-inline">date</strong> column since it is now redundant:<p class="source-code">df.drop('Date', axis=1, inplace=True)</p></li>
				<li>Verify that all the columns are now of the numerical data type:<p class="source-code">df.dtypes</p><p>The output will be as follows:</p><div id="_idContainer117" class="IMG---Figure"><img src="image/B16341_02_11.jpg" alt="Figure 2.11: Output of the dtypes attribute of the resultant DataFrame &#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.11: Output of the dtypes attribute of the resultant DataFrame </p>
			<p>Here, you can see that all the data types of the resultant DataFrame are numerical. This means they can now be passed into an ANN for modeling.</p>
			<p>In this exercise, you successfully imported tabular data and preprocessed the <strong class="source-inline">date</strong> column using the pandas and scikit-learn libraries. You utilized the <strong class="source-inline">get_dummies</strong> function to convert categorical data into numerical data types.</p>
			<p class="callout-heading">Note </p>
			<p class="callout">Another method to attain a numerical data type from date data types is by using the <strong class="source-inline">pandas.Series.dt</strong> accessor object. More information about the available options can be found here: <a href="https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html">https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html</a>.</p>
			<p>Processing non-numerical data is an important step in creating performant models. If possible, any domain knowledge should be imparted to the training data features. For example, when forecasting the temperature using the date, like the dataset used in the prior exercises and activity of this chapter, encoding the month would be helpful since the temperature is likely highly correlated with the month of the year. Encoding the day of the week, however, may not be useful as there is likely no correlation between the day of the week and temperature. Using this domain knowledge can aid the model to learn the underlying relationship between the features and the target.</p>
			<p>In the next section, you will learn how to process image data so that it can be input into machine learning models.</p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor052"/>Processing Image Data</h1>
			<p>A plethora of images is being generated every day by various organizations that can be used to create predictive models for tasks such as object detection, image classification, and object segmentation. When working with image data and some other raw data types, you often need to preprocess the data. Creating models from raw data with minimal preprocessing is one of the biggest benefits of using ANNs for modeling since the feature engineering step is minimal. Feature engineering usually involves using domain knowledge to create features out of the raw data, which is time consuming and has no guarantee of improvements in model performance. Utilizing ANNs with no feature engineering streamlines the training process and has no need for domain knowledge.</p>
			<p>For example, locating tumors in medical images requires expert knowledge from those who have been trained for many years, but for ANNs, all that is required is sufficient labeled data for training. There will be a small amount of preprocessing that generally needs to be applied to these images. These steps are optional but helpful for standardizing the training process and creating performant models.</p>
			<p>One preprocessing step is rescaling. Since images have color values that are integers that range between <strong class="source-inline">0</strong> and <strong class="source-inline">255</strong>, they are scaled to have values between <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>, similar to <em class="italic">Activity 2.01</em>, <em class="italic">Loading Tabular Data and Rescaling Numerical Fields with a MinMax Scaler</em>. Another common preprocessing step that you will explore later in this section is image augmentation, which is essentially the act of augmenting images to add a greater number of training examples and build a more robust model.</p>
			<p>This section also covers batch processing. Batch processing loads in the training data one batch at a time. This can result in slower training times than if the data was loaded in at once; however, this does allow you to train your models on very large-volume datasets. Training on images or audio are examples that often require large volumes to achieve performant results.</p>
			<p>For example, a typical image may be 100 KB in size. For a training dataset of 1 million images, you would need 100 GB of memory, which may be unattainable to most. If the model is trained in batches of 32 images, the memory requirement is orders of magnitude less. Batch training allows you to augment the training data, as you will explore in a later section.</p>
			<p>Images can be loaded into memory using a class named <strong class="source-inline">ImageDataGenerator</strong>, which can be imported from Keras' preprocessing package. This is a class originally from Keras that can now be used in TensorFlow. When loading in images, you can rescale them. It is common practice to rescale images by the value of 1/255 pixels. This means that images that have values from 0 to 255 will now have values from 0 to 1. </p>
			<p><strong class="source-inline">ImageDataGenerator</strong> can be initialized with rescaling, as follows:</p>
			<p class="source-code">datagenerator = ImageDataGenerator(rescale = 1./255)</p>
			<p>Once the <strong class="source-inline">ImageDataGenerator</strong> class has been initialized, you can use the <strong class="source-inline">flow_from_directory</strong> method and pass in the directory that the images are located in. The directory should include sub-directories labeled with the class labels, and they should contain the images of the corresponding class. Another argument to be passed in is the desired size for the images, the batch size, and the class mode. The class mode determines the type of label arrays that are produced. Using the <strong class="source-inline">flow_from_directory</strong> method for binary classification with a batch size of 25 and an image size of 64x64 can be done as follows:</p>
			<p class="source-code">dataset = datagenerator.flow_from_directory\</p>
			<p class="source-code">          ('path/to/data',\</p>
			<p class="source-code">           target_size = (64, 64),\</p>
			<p class="source-code">           batch_size = 25,\</p>
			<p class="source-code">           class_mode = 'binary')</p>
			<p>In the following exercise, you will load images into memory by utilizing the <strong class="source-inline">ImageDataGenerator</strong> class.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The image data provided comes from the Open Image dataset, a full description of which can be found here: <a href="https://storage.googleapis.com/openimages/web/index.html">https://storage.googleapis.com/openimages/web/index.html</a>.</p>
			<p>Images can be viewed by plotting them using Matplotlib. This is a useful exercise for verifying that the images match their respective labels.</p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor053"/>Exercise 2.03: Loading Image Data for Batch Processing</h2>
			<p>In this exercise, you'll learn how to load in image data for batch processing. The <strong class="source-inline">image_data</strong> folder contains a set of images of boats and airplanes. You will load the images of boats and airplanes for batch processing and rescale them so that the image values range between <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>. You are then tasked with printing the labeled images of a batch from the data generator.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can find <strong class="source-inline">image_data</strong> here: <a href="https://packt.link/jZ2oc">https://packt.link/jZ2oc</a>.</p>
			<p>Perform the following steps to complete this exercise:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this exercise. Save the file as <strong class="source-inline">Exercise2-03.ipnyb</strong>.</li>
				<li>In a new Jupyter Notebook cell, import the <strong class="source-inline">ImageDataGenerator</strong> class from <strong class="source-inline">tensorflow.keras.preprocessing.image</strong>:<p class="source-code">from tensorflow.keras.preprocessing.image \</p><p class="source-code">     import ImageDataGenerator</p></li>
				<li>Instantiate the <strong class="source-inline">ImageDataGenerator</strong> class and pass the <strong class="source-inline">rescale</strong> argument with the value <strong class="source-inline">1./255</strong> to convert image values so that they're between <strong class="source-inline">0</strong> and <strong class="source-inline">1</strong>:<p class="source-code">train_datagen = ImageDataGenerator(rescale =  1./255)</p></li>
				<li>Use the data generator's <strong class="source-inline">flow_from_directory</strong> method to direct the data generator to the image data. Pass in the arguments for the target size, the batch size, and the class mode:<p class="source-code">training_set = train_datagen.flow_from_directory\</p><p class="source-code">               ('image_data',\</p><p class="source-code">                target_size = (64, 64),\</p><p class="source-code">                batch_size = 25,\</p><p class="source-code">                class_mode = 'binary')</p></li>
				<li>Create a function to display the images in the batch. The function will plot the first 25 images in a 5x5 array with their associated labels:<p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">def show_batch(image_batch, label_batch):\</p><p class="source-code">    lookup = {v: k for k, v in \</p><p class="source-code">              training_set.class_indices.items()}</p><p class="source-code">    label_batch = [lookup[label] for label in \</p><p class="source-code">                   label_batch]</p><p class="source-code">    plt.figure(figsize=(10,10))</p><p class="source-code">    for n in range(25):</p><p class="source-code">        ax = plt.subplot(5,5,n+1)</p><p class="source-code">        plt.imshow(image_batch[n])</p><p class="source-code">        plt.title(label_batch[n].title())</p><p class="source-code">        plt.axis('off')</p></li>
				<li>Take a batch from the data generator and pass it to the function to display the images and their labels:<p class="source-code">image_batch, label_batch = next(training_set)</p><p class="source-code">show_batch(image_batch, label_batch)</p><p>The output will be as follows:</p><div id="_idContainer118" class="IMG---Figure"><img src="image/B16341_02_12.jpg" alt="Figure 2.12: The images from a batch&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.12: The images from a batch</p>
			<p>Here, you can see the output of a batch of images of boats and airplanes that can be input into a model. Note that all the images are the same size, which was achieved by modifying the aspect ratio of the images. This ensures consistency in the images as they are passed into an ANN.</p>
			<p>In this exercise, you learned how to import images in batches so they can be used for training ANNs. Images are loaded one batch at a time and by limiting the number of training images per batch, you can ensure that the RAM of the machine is not exceeded.</p>
			<p>In the following section, you will see how to augment images as they are loaded in.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor054"/>Image Augmentation</h1>
			<p>Image augmentation is the process of modifying images to increase the number of training examples available. This process can include zooming in on the image, rotating the image, or flipping the image vertically or horizontally. This can be performed if the augmentation process does not change the context of the image. For example, an image of a banana, when flipped horizontally, is still recognizable as a banana, and new images of bananas are likely to be of either orientation. In this case, providing a model for both orientations during the training process will help build a robust model.</p>
			<p>However, if you have an image of a boat, it may not be appropriate to flip it vertically, as this does not represent how boats commonly exist in images, upside-down. Ultimately the goal of image augmentation is to increase the number of training images that resemble the object in its everyday occurrence, preserving the context. This will help the trained model perform well on new, unseen images. An example of image augmentation can be seen in the following figure, in which an image of a banana has been augmented three times; the left image is the original image, and those on the right are the augmented images. </p>
			<p>The top-right image is the original image flipped horizontally, the middle-right image is the original image zoomed in by 15%, and the bottom-right image is the original image rotated by 10 degrees. After this augmentation process, you have four images of a banana, each of which has the banana in different positions and orientations:</p>
			<div>
				<div id="_idContainer119" class="IMG---Figure">
					<img src="image/B16341_02_13.jpg" alt="Figure 2.13: An example of image augmentation&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.13: An example of image augmentation</p>
			<p>Image augmentation can be achieved with TensorFlow's <strong class="source-inline">ImageDataGenerator</strong> class when the images are loaded with each batch. Similar to image rescaling, various image augmentation processes can be applied. The arguments for common augmentation processes include the following:</p>
			<ul>
				<li><strong class="source-inline">horizontal_flip</strong>: Flips the image horizontally.</li>
				<li><strong class="source-inline">vertical_flip</strong>: Flips the image vertically.</li>
				<li><strong class="source-inline">rotation_range</strong>: Rotates the image up to a given number of degrees.</li>
				<li><strong class="source-inline">width_shift_range</strong>: Shifts the image along its width axis up to a given fraction or pixel amount.</li>
				<li><strong class="source-inline">height_shift_range</strong>: Shifts the image along its height axis up to a given fraction or pixel amount.</li>
				<li><strong class="source-inline">brightness_range</strong>: Modifies the brightness of the image up to a given amount.</li>
				<li><strong class="source-inline">shear_range</strong>: Shears the image up to a given amount.</li>
				<li><strong class="source-inline">zoom_range</strong>: Zooms in the image up to a given amount.</li>
			</ul>
			<p>Image augmentation can be applied when instantiating the <strong class="source-inline">ImageDataGenerator</strong> class, as follows:</p>
			<p class="source-code">datagenerator = ImageDataGenerator(rescale = 1./255,\</p>
			<p class="source-code">                                   shear_range = 0.2,\</p>
			<p class="source-code">                                   rotation_range= 180,\</p>
			<p class="source-code">                                   zoom_range = 0.2,\</p>
			<p class="source-code">                                   horizontal_flip = True)</p>
			<p>In the following activity, you perform image augmentation using TensorFlow's <strong class="source-inline">ImageDataGenerator</strong> class. The process is as simple as passing in parameters. You will use the same dataset that you used in <em class="italic">Exercise 2.03</em>, <em class="italic">Loading Image Data for Batch Processing</em>, which contains images of boats and airplanes.</p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor055"/>Activity 2.02: Loading Image Data for Batch Processing</h2>
			<p>In this activity, you will load image data for batch processing and augment the images in the process. The <strong class="source-inline">image_data</strong> folder contains a set of images of boats and airplanes. You are required to load in image data for batch processing and adjust the input data with random perturbations such as rotations, flipping the image horizontally, and adding shear to the images. This will create additional training data from the existing image data and will lead to more accurate and robust machine learning models by increasing the number of different training examples even if only a few are available. You are then tasked with printing the labeled images of a batch from the data generator.</p>
			<p>The steps for this activity are as follows:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this activity.</li>
				<li>Import the <strong class="source-inline">ImageDataGenerator</strong> class from <strong class="source-inline">tensorflow.keras.preprocessing.image</strong>.</li>
				<li>Instantiate <strong class="source-inline">ImageDataGenerator</strong> and set the <strong class="source-inline">rescale=1./255</strong>, <strong class="source-inline">shear_range=0.2</strong>, <strong class="source-inline">rotation_range=180</strong>, <strong class="source-inline">zoom_range=0.2</strong>, and <strong class="source-inline">horizontal_flip=True</strong> arguments.</li>
				<li>Use the <strong class="source-inline">flow_from_directory</strong> method to direct the data generator to the images while passing in the target size as <strong class="source-inline">64x64</strong>, a batch size of <strong class="source-inline">25</strong>, and the class mode as <strong class="source-inline">binary</strong>.</li>
				<li>Create a function to display the first 25 images in a 5x5 array with their associated labels.</li>
				<li>Take a batch from the data generator and pass it to the function to display the images and their labels.<p class="callout-heading">Note</p><p class="callout">The solution to this activity can be found via <a href="B16341_Solution_ePub.xhtml#_idTextAnchor256">this link</a>.</p></li>
			</ol>
			<p>In this activity, you augmented images in batches so they could be used for training ANNs. You've seen that when images are used as input, they can be augmented to generate a larger number of effective training examples.</p>
			<p>You learned how to load images in batches, which enables you to train on huge volumes of data that may not fit into the memory of your machine at one time. You also learned how to augment images using the <strong class="source-inline">ImageDataGenerator</strong> class, which essentially generates new training examples from the images in your training set.</p>
			<p>In the next section, you will learn how to load and preprocess text data.</p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor056"/>Text Processing</h1>
			<p>Text data represents a large class of raw data that is readily available. For example, text data can be from web pages such as Wikipedia, transcribed speech, or social media conversations—all of which are increasing at a massive scale and must be processed before they can be used for training machine learning models.</p>
			<p>Working with text data can be challenging for several different reasons, including the following:</p>
			<ul>
				<li>Thousands of different words exist.</li>
				<li>Different languages present challenges.</li>
				<li>Text data often varies in size.</li>
			</ul>
			<p>There are many ways to convert text data into a numerical representation. One way is to one-hot encode the words, much like you did with the date field in <em class="italic">Exercise 2.02</em>, <em class="italic">Preprocessing Non-Numerical Data</em>. However, this presents issues when training models since large datasets with many unique words will result in a sparse dataset and can lead to slow training speeds and potentially inaccurate models. Moreover, if a new word is encountered that was not in the training data, the model cannot use that word.</p>
			<p>One popular method that's used to represent text data is to convert the entire piece of text into embedding vectors. Pretrained models exist to convert raw text into vectors. These models are usually trained on large volumes of text. Using word embedding vectors from pretrained models has some distinct advantages:</p>
			<ul>
				<li>The resulting vectors have a fixed size.</li>
				<li>The vectors maintain contextual information, so they benefit from transfer learning.</li>
				<li>No further preprocessing of the data needs to be done and the results of the embedding can be fed directly into an ANN.</li>
			</ul>
			<p>While TensorFlow Hub will be covered in more depth in the next chapter, the following is an example of how to use pretrained models as a preprocessing step. To load in the pretrained model, you need to import the <strong class="source-inline">tensorflow_hub</strong> library. By doing this, the URL of the model can be loaded. Then, the model can be loaded into the environment by calling the <strong class="source-inline">KerasLayer</strong> class, which wraps the model so that it can be used like any other TensorFlow model. It can be created as follows:</p>
			<p class="source-code">import tensorflow_hub as hub</p>
			<p class="source-code">model_url = "url_of_model"</p>
			<p class="source-code">hub_layer = hub.KerasLayer(model_url, \</p>
			<p class="source-code">                           input_shape=[], dtype=tf.string, \</p>
			<p class="source-code">                           trainable=True)</p>
			<p>The data type of the input data, indicated by the <strong class="source-inline">dtype</strong> parameter, should be used as input for the <strong class="source-inline">KerasLayer</strong> class, as well as a Boolean argument indicating whether the weights are trainable. Once the model has been loaded using the <strong class="source-inline">tensorflow_hub</strong> library, it can be called on text data, as follows:</p>
			<p class="source-code">hub_layer(data)</p>
			<p>This will run the data through the pretrained model. The output will be based on the architecture and weights of the pretrained model.</p>
			<p>In the following exercise, you will explore how to load in data that includes a text field, batch the dataset, and apply a pretrained model to the text field to convert the field into embedded vectors.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The pretrained model can be found here: <a href="https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1">https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1</a>.</p>
			<p class="callout">The dataset can be found here: <a href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29">https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29</a>.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor057"/>Exercise 2.04: Loading Text Data for TensorFlow Models</h2>
			<p>The dataset, <strong class="source-inline">drugsComTrain_raw.tsv</strong>, contains information related to patient reviews on specific drugs, along with their related conditions and a rating indicating the patient's satisfaction with the drug. In this exercise, you will load in text data for batch processing. You will apply a pretrained model from TensorFlow Hub to perform a word embedding on the patient reviews. You are required to work on the <strong class="source-inline">review</strong> field only as that contains text data.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this exercise. Save the file as <strong class="source-inline">Exercise2-04.ipnyb</strong>.</li>
				<li>In a new Jupyter Notebook cell, import the TensorFlow library: <p class="source-code">import tensorflow as tf</p></li>
				<li>Create a TensorFlow dataset object using the library's <strong class="source-inline">make_csv_dataset</strong> function. Set the <strong class="source-inline">batch_size</strong> argument equal to <strong class="source-inline">1</strong> and the <strong class="source-inline">field_delim</strong> argument to <strong class="source-inline">'\t'</strong> since the dataset is tab-delimited:<p class="source-code">df = tf.data.experimental.make_csv_dataset\</p><p class="source-code">     ('../Datasets/drugsComTest_raw.tsv', \</p><p class="source-code">      batch_size=1, field_delim='\t')</p></li>
				<li>Create a function that takes a dataset object as input and shuffles, repeats, and batches the dataset:<p class="source-code">def prep_ds(ds, shuffle_buffer_size=1024, \</p><p class="source-code">            batch_size=32):</p><p class="source-code">    # Shuffle the dataset</p><p class="source-code">    ds = ds.shuffle(buffer_size=shuffle_buffer_size)</p><p class="source-code">    # Repeat the dataset</p><p class="source-code">    ds = ds.repeat()</p><p class="source-code">    # Batch the dataset</p><p class="source-code">    ds = ds.batch(batch_size)</p><p class="source-code">    return ds</p></li>
				<li>Apply the function to the dataset object you created in <em class="italic">Step 3</em>, setting <strong class="source-inline">batch_size</strong> equal to <strong class="source-inline">5</strong>:<p class="source-code">ds = prep_ds(df, batch_size=5)</p></li>
				<li>Take the first batch and print it out:<p class="source-code">for x in ds.take(1):\</p><p class="source-code">    print(x)</p><p>You should get output similar to the following:</p><div id="_idContainer120" class="IMG---Figure"><img src="image/B16341_02_14.jpg" alt="Figure 2.14: A batch from the dataset object&#13;&#10;"/></div><p class="figure-caption">Figure 2.14: A batch from the dataset object</p><p>The output represents the input data in tensor format.</p></li>
				<li>Import the pretrained word embedding model from TensorFlow Hub and create a Keras layer: <p class="source-code">import tensorflow_hub as hub</p><p class="source-code">embedding = "https://tfhub.dev/google/tf2-preview"\</p><p class="source-code">            "/gnews-swivel-20dim/1"</p><p class="source-code">hub_layer = hub.KerasLayer(embedding, input_shape=[], \</p><p class="source-code">                           dtype=tf.string, \</p><p class="source-code">                           trainable=True)</p></li>
				<li>Take one batch from the dataset, flatten the tensor corresponding to the <strong class="source-inline">review</strong> field, apply the pretrained layer, and print it out: <p class="source-code">for x in ds.take(1):\</p><p class="source-code">    print(hub_layer(tf.reshape(x['review'],[-1])))</p><p>This will display the following output:</p><div id="_idContainer121" class="IMG---Figure"><img src="image/B16341_02_15.jpg" alt="Figure 2.15: A batch of the review column after the pretrained model &#13;&#10;has been applied to the text&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.15: A batch of the review column after the pretrained model has been applied to the text</p>
			<p>The preceding output represents the embedding vectors for the first batch of drug reviews. The specific values may not mean much at first glance but encoded within the embeddings is contextual information based on the dataset that the embedding model was trained upon. The batch size is equal to <strong class="source-inline">5</strong> and the embedding vector size is <strong class="source-inline">20</strong>, which means the resulting size, after applying the pretrained layer, is <strong class="source-inline">5x20</strong>.</p>
			<p>In this exercise, you learned how to import tabular data that might contain a variety of data types. You took the <strong class="source-inline">review</strong> field and applied a pretrained word embedding model to convert the text into a numerical tensor. Ultimately, you preprocessed and batched the text data so that it was appropriate for large-scale training. This is one way to represent text so that it can be input into machine learning models in TensorFlow. In fact, other pretrained word embedding models can be used and are available on TensorFlow Hub. You will learn more about how to utilize TensorFlow Hub in the next chapter.</p>
			<p>In this section, you learned about one way to preprocess text data for use in machine learning models. There are a number of different methods you could have used to generate a numerical tensor from the text. For example, you could have one-hot encoded the words, removed the stop words, stemmed and lemmatized the words, or even done something as simple as counting the number of words in each review. The method demonstrated in this section is advantageous as it is simple to implement. Also, the word embedding incorporates contextual information in the text that is difficult to encode in other methods, such as one-hot encoding.</p>
			<p>Ultimately, it is up to the practitioner to apply any domain knowledge to the preprocessing step to retain as much contextual information as possible. This will allow any subsequent models to learn the underlying function between the features and the target variable.</p>
			<p>In the next section, you will learn how to load and process audio data so that the data can be used for TensorFlow models.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor058"/>Audio Processing</h1>
			<p>This section will demonstrate how to load audio data in batches, as well as how to process it so that it can be used to train machine learning models. There is some advanced signal processing that takes place to preprocess audio files. Some of these steps are optional, but they are presented to provide a comprehensive approach to processing audio data. Since each audio file can be hundreds of KB, you will utilize batch processing, as you did when processing image data. Batch processing can be achieved by creating a dataset object. A generic method for creating a dataset object from raw data is using TensorFlow's <strong class="source-inline">from_tensor_slice</strong> function. This function generates a dataset object by slicing a tensor along its first dimension. It can be used as follows:</p>
			<p class="source-code">dataset = tf.data.Dataset\</p>
			<p class="source-code">            .from_tensor_slices([1, 2, 3, 4, 5])</p>
			<p>Loading audio data into a Python environment can be achieved using TensorFlow by reading the file into memory using the <strong class="source-inline">read_file</strong> function, then decoding the file using the <strong class="source-inline">decode_wav</strong> function. When using the <strong class="source-inline">decode_wav</strong> function, the sample rate, which represents how many data points comprise 1 second of data, as well as the desired channel to use must be passed in as arguments. For example, if a value of <strong class="source-inline">-1</strong> is passed for the desired channel, then all the audio channels will be decoded. Importing the audio file can be achieved as follows:</p>
			<p class="source-code">sample_rate = 44100</p>
			<p class="source-code">audio_data = tf.io.read_file('path/to/file')</p>
			<p class="source-code">audio, sample_rate = tf.audio.decode_wav\</p>
			<p class="source-code">                     (audio_data,\</p>
			<p class="source-code">                      desired_channels=-1,\</p>
			<p class="source-code">                      desired_samples=sample_rate)</p>
			<p>As with text data, you must preprocess the data so that the resulting numerical tensor has the same size as the data. This is achieved by sampling the audio file after converting the data into the frequency domain. Sampling the audio can be thought of as splitting the audio file into chunks that are always the same size. For example, a 30-second audio file can be split into 30 1-second non-overlapping audio samples, and in the same way, a 15-second audio file can be split into 15 1-second non-overlapping samples. Thus, your result is 45 equally sized audio samples.</p>
			<p>Another common preprocessing step that can be performed on audio data is to convert the audio sample from the time domain into the frequency domain. Interpreting the data in the time domain is useful for understanding the intensity or volume of the audio, whereas the frequency domain can help you discover which frequencies are present. This is useful for classifying sounds since different objects have different characteristic sounds that will be present in the frequency domain. Audio data can be converted from the time domain into the frequency domain using the <strong class="source-inline">stft</strong> function.</p>
			<p>This function takes the short-time Fourier transform of the input data. The arguments to the function include the frame length, which is an integer value that indicates the window length in samples; the frame step, which is an integer value that describes the number of samples to step; and the <strong class="bold">Fast Fourier Transform</strong> (<strong class="bold">FFT</strong>) length, which is an integer value that indicates the length of the FFT to apply. A spectrogram is the absolute value of the short-time Fourier transform as it is useful for visual interpretation. The short-time Fourier transform and spectrogram can be created as follows:</p>
			<p class="source-code">stfts = tf.signal.stft(audio, frame_length=1024,\</p>
			<p class="source-code">                       frame_step=256,\</p>
			<p class="source-code">                       fft_length=1024)</p>
			<p class="source-code">spectrograms = tf.abs(stfts)</p>
			<p>Another optional preprocessing step is to generate the <strong class="bold">Mel-Frequency Cepstral Coefficients</strong> (<strong class="bold">MFCCs</strong>). As the name suggests, the MFCCs are the coefficients of the mel-frequency cepstrum. The cepstrum is a representation of the short-term power spectrum of an audio signal. MFCCs are commonly used in applications for speech recognition and music information retrieval. As such, it may not be important to understand each step of how the MFCCs are generated but understanding that they can be applied as a preprocessing step to increase the information density of the audio data pipeline is beneficial.</p>
			<p>MFCCs are generated by creating a matrix to warp the linear scale to the mel scale. This matrix can be created using <strong class="source-inline">linear_to_mel_weight_matrix</strong> and by passing in the number of bands in the resulting mel spectrum, the number of bins in the source spectrogram, the sample rate, and the lower and upper frequencies to be included in the mel spectrum. Once the linear-to-mel weight matrix has been created, a tensor contraction with the spectrograms is applied along the first axis using the <strong class="source-inline">tensordot</strong> function. </p>
			<p>Following this, the log of the values is applied to generate the log mel spectrograms. Finally, the <strong class="source-inline">mfccs_from_log_mel_spectrograms</strong> function can be applied to generate the MFCCs that are passing in the log mel spectrograms. These steps can be applied as follows:</p>
			<p class="source-code">lower_edge_hertz, upper_edge_hertz, num_mel_bins \</p>
			<p class="source-code">    = 80.0, 7600.0, 80</p>
			<p class="source-code">linear_to_mel_weight_matrix \</p>
			<p class="source-code">    = tf.signal.linear_to_mel_weight_matrix\</p>
			<p class="source-code">      (num_mel_bins, num_spectrogram_bins, sample_rate, \</p>
			<p class="source-code">       lower_edge_hertz, upper_edge_hertz)</p>
			<p class="source-code">mel_spectrograms = tf.tensordot\</p>
			<p class="source-code">                   (spectrograms, \</p>
			<p class="source-code">                    linear_to_mel_weight_matrix, 1)</p>
			<p class="source-code">mel_spectrograms.set_shape\</p>
			<p class="source-code">    (spectrograms.shape[:-1].concatenate\</p>
			<p class="source-code">    (linear_to_mel_weight_matrix.shape[-1:]))</p>
			<p class="source-code">log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)</p>
			<p class="source-code">mfccs = tf.signal.mfccs_from_log_mel_spectrograms\</p>
			<p class="source-code">        (log_mel_spectrograms)[..., :num_mfccs]</p>
			<p>In the following exercise, you will understand how audio data can be processed. In a similar manner to what you did in <em class="italic">Exercise 2.03</em>, <em class="italic">Loading Image Data for Batch Processing</em>, and <em class="italic">Exercise</em> <em class="italic">2.04</em>, <em class="italic">Loading Text Data for TensorFlow Models</em>, you will load the data in batches for efficient and scalable training. You will load in the audio files using TensorFlow's generic <strong class="source-inline">read_file</strong> function, then decode the audio data using TensorFlow's <strong class="source-inline">decode_wav</strong> function. You will then create a function that will generate the MFCCs from each audio sample. Finally, a dataset object will be generated that can be passed into a TensorFlow model for training. The dataset that you will be utilizing is Google's speech commands dataset, which consists of 1-second-long utterances of words.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset can be found here: <a href="https://packt.link/Byurf">https://packt.link/Byurf</a>.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor059"/>Exercise 2.05: Loading Audio Data for TensorFlow Models</h2>
			<p>In this exercise, you'll learn how to load in audio data for batch processing. The dataset, <strong class="source-inline">data_speech_commands_v0.02</strong>, contains speech samples of people speaking the word <strong class="source-inline">zero</strong> for exactly 1 second with a sample rate of 44.1 kHz, meaning that for every second, there are 44,100 data points. You will apply some common audio preprocessing techniques, including converting the data into the Fourier domain, sampling the data to ensure the data has the same size as the model, and generating MFCCs for each audio sample. This will generate a preprocessed dataset object that can be input into a TensorFlow model for training.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this exercise. Save the file as <strong class="source-inline">Exercise2-05.ipnyb</strong>.</li>
				<li>In a new Jupyter Notebook cell, import the <strong class="source-inline">tensorflow</strong> and <strong class="source-inline">os</strong> libraries:<p class="source-code">import tensorflow as tf</p><p class="source-code">import os</p></li>
				<li>Create a function that will load an audio file using TensorFlow's <strong class="source-inline">read_file</strong> function and <strong class="source-inline">decode_wav</strong> function, respectively. Return the transpose of the resultant tensor:<p class="source-code">def load_audio(file_path, sample_rate=44100):</p><p class="source-code">    # Load audio at 44.1kHz sample-rate</p><p class="source-code">    audio = tf.io.read_file(file_path)</p><p class="source-code">    audio, sample_rate = tf.audio.decode_wav\</p><p class="source-code">                         (audio,\</p><p class="source-code">                          desired_channels=-1,\</p><p class="source-code">                          desired_samples=sample_rate)</p><p class="source-code">    return tf.transpose(audio)</p></li>
				<li>Load in the paths to the audio data as a list using <strong class="source-inline">os.list_dir</strong>:<p class="source-code">prefix = " ../Datasets/data_speech_commands_v0.02"\</p><p class="source-code">        "/zero/"</p><p class="source-code">paths = [os.path.join(prefix, path) for path in \</p><p class="source-code">         os.listdir(prefix)]</p></li>
				<li>Test the function by loading in the first audio file from the list and plotting it:<p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">audio = load_audio(paths[0])</p><p class="source-code">plt.plot(audio.numpy().T)</p><p class="source-code">plt.xlabel('Sample')</p><p class="source-code">plt.ylabel('Value')</p><p>The output will be as follows:</p><div id="_idContainer122" class="IMG---Figure"><img src="image/B16341_02_16.jpg" alt="Figure 2.16: A visual representation of an audio file&#13;&#10;"/></div><p class="figure-caption">Figure 2.16: A visual representation of an audio file</p><p>The figure shows the waveform of the speech sample. The amplitude at a given time corresponds to the volume of the sound; high amplitude relates to high volume.</p></li>
				<li>Create a function to generate the MFCCs from the audio data. First, apply the short-time Fourier transform passing in the audio signal as the first argument, the frame length set to <strong class="source-inline">1024</strong> as the second argument, the frame step set to <strong class="source-inline">256</strong> as the third argument, and the FFT length as the fourth parameter. Then, take the absolute value of the result to compute the spectrograms. The number of spectrogram bins is given by the length along the last axis of the short-time Fourier transform. Next, define the upper and lower bounds of the mel weight matrix as <strong class="source-inline">80</strong> and <strong class="source-inline">7600</strong> respectively and the number of mel bins as <strong class="source-inline">80</strong>. Then, compute the mel weight matrix using <strong class="source-inline">linear_to_mel_weight_matrix</strong> from TensorFlow's signal package. Next, compute the mel spectrograms via tensor contraction using TensorFlow's <strong class="source-inline">tensordot</strong> function along axis 1 of the spectrograms with the mel weight matrix. Then, take the log of the mel spectrograms before finally computing the MFCCs using TensorFlow's <strong class="source-inline">mfccs_from_log_mel_spectrograms</strong> function. Then, return the MFCCs from the function:<p class="source-code">def apply_mfccs(audio, sample_rate=44100, num_mfccs=13):</p><p class="source-code">    stfts = tf.signal.stft(audio, frame_length=1024, \</p><p class="source-code">                           frame_step=256, \</p><p class="source-code">                           fft_length=1024)</p><p class="source-code">    spectrograms = tf.abs(stfts)</p><p class="source-code">    num_spectrogram_bins = stfts.shape[-1]#.value</p><p class="source-code">    lower_edge_hertz, upper_edge_hertz, \</p><p class="source-code">    num_mel_bins = 80.0, 7600.0, 80</p><p class="source-code">    linear_to_mel_weight_matrix = \</p><p class="source-code">      tf.signal.linear_to_mel_weight_matrix\</p><p class="source-code">      (num_mel_bins, num_spectrogram_bins, \</p><p class="source-code">       sample_rate, lower_edge_hertz, upper_edge_hertz)</p><p class="source-code">    mel_spectrograms = tf.tensordot\</p><p class="source-code">                       (spectrograms, \</p><p class="source-code">                        linear_to_mel_weight_matrix, 1)</p><p class="source-code">    mel_spectrograms.set_shape\</p><p class="source-code">    (spectrograms.shape[:-1].concatenate\</p><p class="source-code">    (linear_to_mel_weight_matrix.shape[-1:]))</p><p class="source-code">    log_mel_spectrograms = tf.math.log\</p><p class="source-code">                           (mel_spectrograms + 1e-6)</p><p class="source-code">    #Compute MFCCs from log_mel_spectrograms</p><p class="source-code">    mfccs = tf.signal.mfccs_from_log_mel_spectrograms\</p><p class="source-code">            (log_mel_spectrograms)[..., :num_mfccs]</p><p class="source-code">    return mfccs</p></li>
				<li>Apply the function to generate the MFCCs for the audio data you loaded in <em class="italic">Step 5</em>:<p class="source-code">mfcc = apply_mfccs(audio)</p><p class="source-code">plt.pcolor(mfcc.numpy()[0])</p><p class="source-code">plt.xlabel('MFCC log coefficient')</p><p class="source-code">plt.ylabel('Sample Value')</p><p>The output will be as follows:</p><div id="_idContainer123" class="IMG---Figure"><img src="image/B16341_02_17.jpg" alt="Figure 2.17: A visual representation of the MFCCs of an audio file&#13;&#10;"/></div><p class="figure-caption">Figure 2.17: A visual representation of the MFCCs of an audio file</p><p>The preceding plot shows the MFCC values on the <em class="italic">x</em> axis and various points of the audio sample on the <em class="italic">y</em> axis. MFCCs are a different representation of the raw audio signal displayed in <em class="italic">Step 5</em> that has been proven to be useful in applications related to speech recognition.</p></li>
				<li>Load <strong class="source-inline">AUTOTUNE</strong> so that you can use all the available threads of the CPU. Create a function that will take a dataset object, shuffle it, load the audio using the function you created in <em class="italic">Step 3</em>, generate the MFCCs using the function you created in <em class="italic">Step 6</em>, repeat the dataset object, batch it, and prefetch it. Use <strong class="source-inline">AUTOTUNE</strong> to prefetch with a buffer size based on your available CPU:<p class="source-code">AUTOTUNE = tf.data.experimental.AUTOTUNE</p><p class="source-code">def prep_ds(ds, shuffle_buffer_size=1024, \</p><p class="source-code">            batch_size=64):</p><p class="source-code">    # Randomly shuffle (file_path, label) dataset</p><p class="source-code">    ds = ds.shuffle(buffer_size=shuffle_buffer_size)</p><p class="source-code">    # Load and decode audio from file paths</p><p class="source-code">    ds = ds.map(load_audio, num_parallel_calls=AUTOTUNE)</p><p class="source-code">    # generate MFCCs from the audio data</p><p class="source-code">    ds = ds.map(apply_mfccs)</p><p class="source-code">    # Repeat dataset forever</p><p class="source-code">    ds = ds.repeat()</p><p class="source-code">    # Prepare batches</p><p class="source-code">    ds = ds.batch(batch_size)</p><p class="source-code">    # Prefetch</p><p class="source-code">    ds = ds.prefetch(buffer_size=AUTOTUNE)</p><p class="source-code">    return ds</p></li>
				<li>Generate the training dataset using the function you created in <em class="italic">Step 8</em>. To do this, create a dataset object using TensorFlow's <strong class="source-inline">from_tensor_slices</strong> function and pass in the paths to the audio files. After that, you can use the function you created in <em class="italic">Step 8</em>:<p class="source-code">ds = tf.data.Dataset.from_tensor_slices(paths)</p><p class="source-code">train_ds = prep_ds(ds)</p></li>
				<li>Take the first batch of the dataset and print it out:<p class="source-code">for x in train_ds.take(1):\</p><p class="source-code">    print(x)</p><p>The output will be as follows:</p><div id="_idContainer124" class="IMG---Figure"><img src="image/B16341_02_18.jpg" alt="Figure 2.18: A batch of the audio data after the MFCCs have been generated&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.18: A batch of the audio data after the MFCCs have been generated</p>
			<p>The output shows the first batch of MFCC spectrum values in tensor form.</p>
			<p>In this exercise, you imported audio data. You processed the dataset and batched the dataset so that it is appropriate for large-scale training. This method was a comprehensive approach in which the data was loaded and converted into the frequency domain, spectrograms were generated, and then finally the MFCCs were generated.</p>
			<p>In the next activity, you will load in audio data and take the absolute value of the input, followed by scaling the values logarithmically. This will ensure that there are no negative values in the dataset. You will use the same audio dataset that you used in <em class="italic">Exercise 2.05</em>, <em class="italic">Loading Audio Data for TensorFlow Models</em>, that is, Google's speech commands dataset. This dataset consists of 1-second-long utterances of words.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor060"/>Activity 2.03: Loading Audio Data for Batch Processing</h2>
			<p>In this activity, you will load audio data for batch processing. The audio preprocessing techniques that will be performed include taking the absolute value and using the logarithm of 1 plus the value. This will ensure the resulting values are non-negative and logarithmically scaled. The result will be a preprocessed dataset object that can be input into a TensorFlow model for training.</p>
			<p>The steps for this activity are as follows:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook to implement this activity.</li>
				<li>Import the TensorFlow and <strong class="source-inline">os</strong> libraries.</li>
				<li>Create a function that will load and then decode an audio file using TensorFlow's <strong class="source-inline">read_file</strong> function followed by the <strong class="source-inline">decode_wav</strong> function, respectively. Return the transpose of the resultant tensor from the function.</li>
				<li>Load the file paths into the audio data as a list using <strong class="source-inline">os.list_dir</strong>.</li>
				<li>Create a function that takes a dataset object, shuffles it, loads the audio using the function you created in <em class="italic">step 2</em>, and applies the absolute value and the <strong class="source-inline">log1p</strong> function to the dataset. This function adds <strong class="source-inline">1</strong> to each value in the dataset and then applies the logarithm to the result. Next, repeat the dataset object, batch it, and prefetch it with a buffer size equal to the batch size.</li>
				<li>Create a dataset object using TensorFlow's <strong class="source-inline">from_tensor_slices</strong> function and pass in the paths to the audio files. Then, apply the function you created in <em class="italic">Step 4</em> to the dataset created in <em class="italic">Step 5</em>.</li>
				<li>Take the first batch of the dataset and print it out.</li>
				<li>Plot the first audio file from the batch.<p>The output will look as follows:</p><div id="_idContainer125" class="IMG---Figure"><img src="image/B16341_02_19.jpg" alt="Figure 2.19: Expected output of Activity 2.03&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.19: Expected output of Activity 2.03</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution to this activity can be found via <a href="B16341_Solution_ePub.xhtml#_idTextAnchor257">this link</a>.</p>
			<p>In this activity, you learned how to load and preprocess audio data in batches. You used most of the functions that you used in <em class="italic">Exercise 2.05</em>, <em class="italic">Loading Audio Data for TensorFlow Models</em>, to load in the data and decode the raw data. The difference between <em class="italic">Exercise 2.05</em>, <em class="italic">Loading Audio Data for TensorFlow Models</em>, and <em class="italic">Activity 2.03</em>, <em class="italic">Loading Audio Data for Batch Processing</em>, is the preprocessing steps; <em class="italic">Exercise 2.05</em>, <em class="italic">Loading Audio Data for TensorFlow Models</em>, involved generating MFCCs for the audio data, whereas <em class="italic">Activity 2.03</em>, <em class="italic">Loading Audio Data for Batch Processing</em>, involved scaling the data logarithmically. Both demonstrate common preprocessing techniques that can be used for all applications involving modeling on audio data.</p>
			<p>In this section, you have explored how audio data can be loaded in batches for TensorFlow modeling. The comprehensive approach demonstrated many advanced signal processing techniques that should provide practitioners who wish to use audio data for their own applications with a good starting point.</p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor061"/>Summary</h1>
			<p>In this chapter, you learned how to load different forms of data and perform some preprocessing steps for a variety of data types. You began with tabular data in the form of a CSV file. Since the dataset consisted of a single CSV file, you utilized the pandas library to load the file into memory.</p>
			<p>You then proceeded to preprocess the data by scaling the fields and converting all the fields into numerical data types. This is important since TensorFlow models can only be trained on numerical data, and the training process is improved in terms of speed and accuracy if all the fields are of the same scale.</p>
			<p>Next, you explored how to load the image data. You batched the data so that you did not have to load in the entire dataset at once, which allowed you to augment the images. Image augmentation is useful as it increases the effective number of training examples and can help make a model more robust.</p>
			<p>You then learned how to load in text data and took advantage of pretrained models. This helped you embed text into vectors that retain contextual information about the text. This allowed text data to be input into TensorFlow models since they require numerical tensors as inputs.</p>
			<p>Finally, the final section covered how to load and process audio data and demonstrated some advanced signal processing techniques, including generating MFCCs, which can be used to generate informationally dense numerical tensors that can be input into TensorFlow models.</p>
			<p>Loading and preprocessing data so that it can be input into machine learning models is an important and necessary first step to training any machine learning model. In the next chapter, you will explore many resources that TensorFlow provides to aid in the development of model building.</p>
		</div>
		<div>
			<div id="_idContainer127" class="Content">
			</div>
		</div>
	</body></html>