<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Object Detection at a Large Scale with TensorFlow</h1>
                </header>
            
            <article>
                
<p><span>The rece</span><span>nt breakthroughs in the field of <strong>Artificial Intelligence</strong> (<strong>AI</strong>) have brought deep learning to the forefront. Today, even more organizations are employing deep learning technologies for analyzing their data, which is often voluminous in nature. Hence, it's imperative that deep learning frameworks such as TensorFlow can be combined with big data platforms and pipelines.</span></p>
<p><span>The 2017 Facebook paper regarding training ImageNet in one hour using 256 GPUs spread over 32 servers (</span><a href="https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h5.pdf">https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h5.pdf</a><span>) and a recent paper by Hong Kong Baptist University where they train ImageNet in four minutes using 2,048 GPUs (</span><a href="https://arxiv.org/pdf/1807.11205.pdf">https://arxiv.org/pdf/1807.11205.pdf</a><span>) prove that distributed AI can be a viable solution.</span></p>
<p>The main idea behind distributed AI is that the task can be divided into different processing clusters. A large number of frameworks have been proposed for distributed AI. We can use either distributed TensorFlow or TensorFlowOnSpark, two popular choices for distributed AI. Both have their own sets of pros and cons, as we'll learn in this chapter.</p>
<p>Applying computationally expensive deep learning applications at a large scale can be an enormous challenge. Using TensorFlowOnSpark, we can distribute these computationally expensive processes in the cluster, enabling us to perform computations at a larger scale.</p>
<p><span>I</span><span>n this chapter, we'll explore Yahoo's TensorFlowOnSpark framework for distributed deep learning on Spark clusters. Then, </span>we'll apply TensorFlowOnSpark on a large scale dataset of images and train the network to detect objects. In this chapter, we'll cover the following topics:</p>
<ul>
<li>The need for distributed AI</li>
<li>An introduction to the Apache Spark platform for big data</li>
<li>TensorFlowOnSpark <span>–</span> a Python framework to run TensorFlow on Spark clusters</li>
<li>Performing object detection using TensorFlowOnSpark and the Sparkdl API</li>
</ul>
<p>For big data, Spark is the de facto choice, so we'll start with an introduction to Spark. Then, we'll explore the two popular choices: distributed TensorFlow, and TensorFlowOnSpark.</p>
<div class="packt_tip">The code for this chapter can be found at <a href="https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Projects/tree/master/Chapter12">https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Projects/tree/master/Chapter12</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing Apache Spark</h1>
                </header>
            
            <article>
                
<p>If you have worked in big data, there is a high probability that you already know what Apache Spark is, and you can skip this section. But if you don't, don't worry—we'll go through the basics.</p>
<p>Spark is a powerful, fast, and scalable real-time data analytics engine for large scale data processing. It's an open source framework that was developed initially by the UC Berkeley AMPLab around the year 2009. Around 2013, AMPLab contributed Spark to the Apache Software Foundation, with Apache Spark Community releasing Spark 1.0 in 2014.</p>
<p>The community continues to make regular releases and brings new features into the project. At the time of writing this book, we have the Apache Spark 2.4.0 release and active community on GitHub. It's a real-time data analytics engine that allows you to distribute programs across a cluster of machines.</p>
<p>The beauty of Spark lays in the fact that it's <strong>scalable</strong>: it runs on top of a cluster manager, allowing you to use the scripts written in Python (Java or Scala, too) with minimal change. Spark is made up of many components. At the heart, we have the Spark core, which distributes the processing of data and the mapping and reducing of large datasets. There are several libraries that run on top of it. Here are some of the important components of the Spark API:</p>
<ul>
<li><strong>Resilient Distributed Dataset (RDD)</strong>:<strong> </strong>RDD is the base element of the Spark API. It's a fault-tolerant collection of elements that can be operated on in parallel, which means that the elements in RDD can be accessed and operated upon by the workers in the cluster at the same time.</li>
<li><strong>Transformations and actions</strong>: On the Spark RDD, we can perform two types of operations, transformations and actions. Transformations take RDDs as their argument and return another RDD. Actions take an RDD as an argument and return the local results. All transformations in Spark are lazy, which means that the results are not computed right away. Instead, they are computed only when an action requires a result to be returned. </li>
<li><strong>DataFrames</strong>: These are very similar to pandas DataFrames. Like pandas, we can read from various file formats in the DataFrame (JSON, Parquet, Hive, and so on) and perform an operation on the entire DataFrame with single command functions. They are distributed across the cluster. Spark uses an engine called Catalyst to optimize their usage.</li>
</ul>
<p>Spark uses a master/worker architecture. It has a master node/process and many worker nodes/processes. The driver, SparkContext, is the heart of Spark Application. It's the main entry point and the master of the Spark application. It sets up the internal services and establishes a connection with the Spark execution environment. The following diagram shows Spark's architecture:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1031 image-border" src="assets/81a07ebd-ff60-49e1-b2ed-6af95112f289.png" style="width:141.17em;height:70.42em;"/></p>
<div class="packt_infobox">So far, we have provided an introduction to Apache Spark. It's a big and vast subject, and we would recommend readers to refer to the Apache documentation for more information: <a href="https://spark.apache.org/documentation.html">https://spark.apache.org/documentation.html</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding distributed TensorFlow</h1>
                </header>
            
            <article>
                
<p>TensorFlow also supports distributed computing, allowing us to partition a graph and compute it on different processes. Distributed TensorFlow works like a client-server model, or to be more specific, a master-workers model. In TensorFlow, we first create a cluster of workers, with one being the master-worker. The master coordinates the distribution of tasks to different workers. </p>
<p>The first thing to do when you have to work with many machines (or processors) is to define their name and job type, that is, make a cluster of machines (or processors). Each machine in the cluster is assigned a unique address (for example, <kbd>worker0.example.com:2222</kbd>), and they have a specific job, such as <kbd>type: master</kbd> (parameter server), or worker. Later, the TensorFlow server assigns a specific task to each worker. To create a cluster, we first need to define cluster specification. This is a dictionary that maps worker processes and jobs. The following code creates a cluster with the job name <kbd>work</kbd> and two worker processes:</p>
<pre>import tensorflow as tf<br/>cluster = tf.train.ClusterSpec({<br/>   "worker":["worker0.example.com:2222",<br/>           "worker1.example.com:2222"]<br/>})</pre>
<p>Next, we can start the process by using the <kbd>Server</kbd> class and specifying the task and task index. The following code will start the <kbd>worker</kbd> job on <kbd>worker1</kbd>:</p>
<pre>server = tf.train.Server(cluster, job_name = "worker", task_index = 1)</pre>
<p>We'll need to define a <kbd>Server</kbd> class for each worker in the cluster. This will start all of the workers, making us ready to distribute. To place TensorFlow operations on a particular task, we'll use <kbd>tf.device</kbd> to specify which tasks run on a particular worker. Consider the following code, which distributes the task between two workers:</p>
<div>
<pre>import tensorflow as tf<br/><br/># define Clusters with two workers<br/>cluster = tf.train.ClusterSpec({<br/>    "worker": [<br/>        "localhost:2222",<br/>        "localhost:2223"<br/>         ]})<br/><br/># define Servers<br/>worker0 = tf.train.Server(cluster, job_name="worker", task_index=0)<br/>worker1 = tf.train.Server(cluster, job_name="worker", task_index=1)<br/><br/>with tf.device("/job:worker/task:1"):<br/>    a = tf.constant(3.0, dtype=tf.float32)<br/>    b = tf.constant(4.0) <br/>    add_node = tf.add(a,b)<br/><br/>with tf.device("/job:worker/task:0"):<br/>    mul_node = a * b<br/><br/>with tf.Session("grpc://localhost:2222") as sess:<br/>    result = sess.run([add_node, mul_node])<br/>    print(result)</pre></div>
<p>The preceding code creates two workers on the same machine. In this case, the work is divided between the two workers via the <kbd>tf.device</kbd> function. The variables are created on the respective workers; TensorFlow inserts the appropriate data transfers between the jobs/workers.</p>
<p>This is done by creating a <span><kbd>GrpcServer</kbd>, which is created with the target, <kbd>grpc://localhost:2222</kbd>. This server knows how to talk to the tasks in the same job via <kbd>GrpcChannels</kbd>. In the following screenshot, you can see the output of the previous code:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1127 image-border" src="assets/f35bd435-a9c4-48ed-82b2-197f09604d2e.png" style="width:162.50em;height:24.33em;"/></p>
<div class="packt_infobox">The code for this chapter is located in the repository under the <kbd>Chapter12/distributed.py</kbd> directory.</div>
<p>This looked easy, right? But what if we want to extend this to our deep learning pipeline?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning through distributed TensorFlow</h1>
                </header>
            
            <article>
                
<p><span>At the heart of any deep learning algorithm is the stochastic gradient descent optimizer. This is what makes the model learn and, at the same time, makes learning computationally expensive. Distributing the computation to different nodes on the cluster should reduce the training time.</span> <span>TensorFlow allows us to split the computational graph, describes the model to different nodes in the cluster, and finally merges the result. </span></p>
<p><span>This is achieved in TensorFlow with the help of master nodes, worker nodes, and parameter nodes. The actual computation is done by the worker nodes; the computed parameters are kept by the parameter nodes and shared with worker nodes. The master node is responsible for coordinating the workload among different worker nodes. There are two popular approaches that are employed for distributed computing:<br/></span></p>
<ul>
<li><strong>Synchronous approach</strong>: In this case, the mini-batches are divided among the workers. Each worker has a replica of the model and calculates the gradients separately for the mini-batches allocated to it. Later, the gradients are combined at the master and updates are applied to the parameters at the same time.</li>
<li><strong>Asynchronous approach</strong>: Here, the updates to the model parameters are applied asynchronously.</li>
</ul>
<p>These two approaches are shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1033 image-border" src="assets/2342b586-d056-42f5-8109-ef177e503ca4.png" style="width:42.25em;height:35.33em;"/></p>
<p>Now, let's look at how we can incorporate distributed TensorFlow in a deep learning pipeline. The following code is based upon the following Medium post, <a href="https://medium.com/@ntenenz/distributed-tensorflow-2bf94f0205c3">https://medium.com/@ntenenz/distributed-tensorflow-2bf94f0205c3</a>:</p>
<ol>
<li>Import the necessary modules. Here, we are importing only the necessary ones to demonstrate the changes needed to convert existing deep learning code to distributed TensorFlow code:</li>
</ol>
<pre style="padding-left: 60px">import sys<br/>import tensorflow as tf<br/># Add other module libraries you may need</pre>
<ol start="2">
<li>Define the cluster. We'll create it with one master at the address and two workers. In our case, the machine we want to make master has an IP address assigned to it, that is, <kbd>192.168.1.3</kbd>, and we specify port <kbd>2222</kbd>. You can modify them with the addresses of your machines:</li>
</ol>
<pre style="padding-left: 60px">cluster = tf.train.ClusterSpec(<br/>          {'ps':['192.168.1.3:2222'],<br/>           'worker': ['192.168.1.4:2222',<br/>                      '192.168.1.5:2222',<br/>                      '192.168.1.6:2222',<br/>                      '192.168.1.7:2222']<br/> })</pre>
<ol start="3">
<li>The same code executes on each machine, so we need to parse the command-line arguments:</li>
</ol>
<pre style="padding-left: 60px">job = sys.argv[1]<br/>task_idx = sys.argv[2]</pre>
<ol start="4">
<li>Create the TensorFlow server for each worker and the master so that the nodes in the cluster can communicate:</li>
</ol>
<pre style="padding-left: 60px">server = tf.train.Server(cluster, job_name=job, task_index= int(task_idx))</pre>
<ol start="5">
<li>Ensure that the variables are allocated on the same worker device. TensorFlow's <kbd>tf.train.replica_device_setter()</kbd> function helps us to automatically assign devices to <kbd>Operation</kbd> objects as they are constructed. At the same time, we want the parameter server to wait until the server shuts down. This is achieved by using the <kbd>server.join()</kbd> method at the parameter server:</li>
</ol>
<pre style="padding-left: 60px">if job == 'ps':  <br/>    # Makes the parameter server wait <br/>    # until the Server shuts down<br/>    server.join()<br/>else:<br/>    # Executes only on worker machines    <br/>    with tf.device(tf.train.replica_device_setter(cluster=cluster, worker_device='/job:worker/task:'+task_idx)):<br/>        #build your model here like you are working on a single machine<br/><br/>    with tf.Session(server.target):<br/>        # Train the model </pre>
<div class="packt_infobox">You can access this script from GitHub or from the <kbd>Chapter12/tensorflow_distributed_dl.py</kbd> directory. Remember that the same script needs to be executed on each machine in the cluster, but with different command-line arguments.</div>
<p>The same script now needs to be executed on the parameter server and the four workers:</p>
<p>Use the following code to execute the script on the parameter server (<kbd>192.168.1.3:2222</kbd>):</p>
<pre>python tensorflow_distributed_dl.py ps 0</pre>
<ol>
<li>Use the following code to execute the script on worker 0 <span>(<kbd>192.168.1.4:2222</kbd>)</span>:</li>
</ol>
<pre style="padding-left: 60px">python tensorflow_distributed_dl.py worker 0</pre>
<ol start="2">
<li>Use the following code to execute the script on <kbd>worker 1</kbd> <span>(<kbd>192.168.1.5:2222</kbd>)</span>:</li>
</ol>
<pre style="padding-left: 60px">python tensorflow_distributed_dl.py worker 1</pre>
<ol start="3">
<li>Use the following code to execute the script on <kbd>worker 2</kbd> <span>(<kbd>192.168.1.6:2222</kbd>)</span>:</li>
</ol>
<pre style="padding-left: 60px">python tensorflow_distributed_dl.py worker 2</pre>
<ol start="4">
<li>Use the following code to execute the script on <kbd>worker 3</kbd> <span>(<kbd>192.168.1.6:2222</kbd>)</span>:</li>
</ol>
<pre style="padding-left: 60px">python tensorflow_distributed_dl.py worker 3</pre>
<p>The major disadvantage of distributed TensorFlow is that we need to specify the IP addresses and ports of all of the nodes in the cluster at startup. This puts a limitation on the scalability of distributed TensorFlow. In the next section, you will learn about TensorFlowOnSpark, an API built by Yahoo. It provides a simplified API to run deep learning models on the distributed Spark platform. </p>
<div class="packt_infobox">To find out more about distributed TensorFlow, we suggest that you read the paper <em>TensorFlow:</em> <em>Large Scale Machine Learning on Heterogeneous Distributed Systems</em> by Google REsearch teamNIPS, 2012 (<a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">http://download.tensorflow.org/paper/whitepaper2015.pdf</a>).</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning about TensorFlowOnSpark</h1>
                </header>
            
            <article>
                
<p><span>In the year 2016, Yahoo open sourced TensorFlowOnSpark, a Python framework for performing TensorFlow-based distributed deep learning on Spark clusters. Since then, it has undergone a lot of developmental changes and is one of the most active repositories regarding the distributed deep learning framework.</span></p>
<p>The <strong>TensorFlowOnSpark</strong> (<strong>TFoS</strong>) framework allows you to run distributed TensorFlow applications from within Spark programs. It runs on the existing Spark and Hadoop clusters. It can use existing Spark libraries such as SparkSQL or MLlib (the Spark machine learning library).</p>
<p><span>TFoS is automatic, so we do not need to define the nodes as PS nodes, nor do we need to upload the same code to all of the nodes in the cluster. By just performing a few modifications, we can run our existing TensorFlow code.</span> It allows us to scale up the existing TensorFlow apps with minimal changes. It supports all of the existing TensorFlow functionality such as synchronous/asynchronous training, data parallelism, and TensorBoard. Basically, it's a PySpark wrapper for the TensorFlow code. It launches distributed TensorFlow clusters using Spark executors. To support TensorFlow data ingestion, it adds <kbd>feed_dict</kbd> and <kbd>queue_runner</kbd>, allowing direct HDFS access from TensorFlow. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the architecture of TensorFlowOnSpark </h1>
                </header>
            
            <article>
                
<p>The following diagram depicts the architecture of TFoS. We can see that TFoS does not involve Spark drivers in tensor communication, giving the same scalability as standalone TensorFlow clusters:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1034 image-border" src="assets/cb60c0c1-2ed6-45ef-aaf7-d1f78d082151.png" style="width:157.25em;height:80.58em;"/></p>
<p>TFoS provides two input modes to take in data for training and inference:</p>
<ul>
<li><strong>Spark RDD</strong>: Spark RDD data is fed to each Spark executor. The executor, in turn, feeds the data to the TensorFlow graph using <kbd>feed_dict</kbd>. However, in this mode, TensorFlow worker failures stay hidden from Spark.</li>
<li><strong>TensorFlow QueueRunners</strong>: Here, the TensorFlow worker runs in the foreground. TFoS takes advantage of the TensorFlow file readers and QueueRunners to read data directly from HDFS files. <span>TensorFlow</span> worker failures are retired as Spark Tasks, and it restores them from the checkpoint. </li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep delving inside the TFoS API</h1>
                </header>
            
            <article>
                
<p>The use of TFoS can be divided into three basic steps:</p>
<ol>
<li> Launch the TensorFlow cluster. We can launch the cluster using <kbd>TFCluster.run</kbd>:</li>
</ol>
<pre style="padding-left: 60px">cluster = TFCluster.run(sc, map_fn, args, num_executors, num_ps, tensorboard, input_mode)</pre>
<ol start="2">
<li>Feed the data into the TensorFlow app. The data is given for both training and inference. To train, we use the <kbd>train</kbd> method:</li>
</ol>
<pre style="padding-left: 60px">cluster.train(dataRDD, num_epochs)</pre>
<p class="mce-root" style="padding-left: 60px">We perform the inference with the help of <kbd>cluster.inference(dataRDD)</kbd>. </p>
<ol start="3">
<li>Finally, shut down the TensorFlow cluster with <kbd>cluster.shutdown()</kbd>.</li>
</ol>
<p><span>We can modify any TensorFlow program to work with TFoS. In the following section, we'll look at how we can train a model to recognize handwritten digits using TFoS.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handwritten digits using TFoS</h1>
                </header>
            
            <article>
                
<p>In this section, we'll look at how to convert our TensorFlow code to run on TFoS. To do this, first, we need to build an EC2 cluster on Amazon AWS. One of the easy ways to do this is to use Flintrock, a CLI tool for launching Apache Spark clusters from your local machine.</p>
<p>The following are the prerequisites that you'll need to complete this section:</p>
<ul>
<li>Hadoop</li>
<li>PySpark</li>
<li>Flintrock</li>
<li>Python</li>
<li>TensorFlow</li>
<li>TensorFlowOnSpark</li>
</ul>
<p>Now, let's see how we can do this. We're using the MNIST dataset (<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>). The following code is taken from the TensorFlowOnSpark GitHub. The repository contains the links to documentation and more examples (<a href="https://github.com/yahoo/TensorFlowOnSpark">https://github.com/yahoo/TensorFlowOnSpark</a>):</p>
<ol>
<li>Define the model architecture and training in the <kbd>main(argv, ctx)</kbd> function, where the <kbd>argv</kbd> parameter contains the arguments supplied at the command line, and <kbd>ctx</kbd> contains the node metadata such as <kbd>job</kbd> and <kbd>task_idx</kbd>. The <kbd>cnn_model_fn</kbd> model function is the CNN model that's defined as a function:</li>
</ol>
<div>
<pre style="padding-left: 60px">def main(args, ctx):<br/>    # Load training and eval data<br/>    mnist = tf.contrib.learn.datasets.mnist.read_data_sets(args.data_dir)<br/>    train_data = mnist.train.images # Returns np.array<br/>    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)<br/>    eval_data = mnist.test.images # Returns np.array<br/>    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)<br/><br/>    # Create the Estimator<br/>    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=args.model)<br/><br/>    # Set up logging for predictions<br/>    # Log the values in the "Softmax" tensor with label "probabilities"<br/><br/>    tensors_to_log = {"probabilities": "softmax_tensor"}<br/>    logging_hook = tf.train.LoggingTensorHook( tensors=tensors_to_log, every_n_iter=50)<br/><br/>    # Train the model<br/>    train_input_fn = tf.estimator.inputs.numpy_input_fn(<br/>         x={"x": train_data}, y=train_labels, <br/>         batch_size=args.batch_size, num_epochs=None, <br/>         shuffle=True)<br/><br/>      eval_input_fn = tf.estimator.inputs.numpy_input_fn(<br/>         x={"x": eval_data},<br/>         y=eval_labels,<br/>         num_epochs=1,<br/>         shuffle=False)<br/><br/>    #Using tf.estimator.train_and_evaluate<br/>    train_spec = tf.estimator.TrainSpec(<br/>        input_fn=train_input_fn, <br/>        max_steps=args.steps, <br/>        hooks=[logging_hook])<br/>    eval_spec = tf.estimator.EvalSpec(<br/>        input_fn=eval_input_fn)<br/>    tf.estimator.train_and_evaluate(<br/>        mnist_classifier, train_spec, eval_spec)<span><br/></span></pre></div>
<ol start="2">
<li>In the <kbd>if  __name__=="__main__"</kbd> block, add the following imports:</li>
</ol>
<pre style="padding-left: 60px">from pyspark.context import SparkContext<br/>from pyspark.conf import SparkConf<br/>from tensorflowonspark import TFCluster<br/>import argparse</pre>
<ol start="3">
<li>Launch the Spark Driver and initiate the TensorFlowOnSpark cluster:</li>
</ol>
<div>
<pre style="padding-left: 60px">sc = SparkContext(conf=SparkConf()<br/>        .setAppName("mnist_spark"))<br/>executors = sc._conf.get("spark.executor.instances")<br/>num_executors = int(executors) if executors is not None else 1</pre></div>
<ol start="4">
<li>Parse the arguments:</li>
</ol>
<pre style="padding-left: 60px">parser = argparse.ArgumentParser()<br/>parser.add_argument("--batch_size", <br/>            help="number of records per batch", <br/>            type=int, default=100)<br/>parser.add_argument("--cluster_size", <br/>            help="number of nodes in the cluster", <br/>            type=int, default=num_executors)<br/>parser.add_argument("--data_dir", <br/>            help="path to MNIST data", <br/>            default="MNIST-data")<br/>parser.add_argument("--model", <br/>            help="path to save model/checkpoint", <br/>            default="mnist_model")<br/>parser.add_argument("--num_ps", <br/>            help="number of PS nodes in cluster", <br/>            type=int, default=1)<br/>parser.add_argument("--steps", <br/>            help="maximum number of steps", <br/>            type=int, default=1000)<br/>parser.add_argument("--tensorboard", <br/>            help="launch tensorboard process", <br/>            action="store_true")<br/><br/><br/>args = parser.parse_args()</pre>
<ol start="5">
<li>Use <kbd>TFCluster.run</kbd> to manage the cluster:</li>
</ol>
<div>
<pre style="padding-left: 60px">cluster = TFCluster.run(sc, main, args, <br/>        args.cluster_size, args.num_ps, <br/>        tensorboard=args.tensorboard, <br/>        input_mode=TFCluster.InputMode.TENSORFLOW, <br/>        log_dir=args.model, master_node='master')</pre></div>
<ol start="6">
<li>Once the training is over, shut down the cluster:</li>
</ol>
<pre style="padding-left: 60px">cluster.shutdown()</pre>
<p>The complete code is available in the GitHub repository in the <kbd>Chapter12/mnist_TFoS.py</kbd> directory.</p>
<p>To execute the code on the EC2 cluster, you'll need to submit it to Spark cluster using <kbd>spark-submit</kbd>:</p>
<pre>${SPARK_HOME}/bin/spark-submit \<br/>--master ${MASTER} \<br/>--conf spark.cores.max=${TOTAL_CORES} \<br/>--conf spark.task.cpus=${CORES_PER_WORKER} \<br/>--conf spark.task.maxFailures=1 \<br/>--conf spark.executorEnv.JAVA_HOME="$JAVA_HOME" \<br/>${TFoS_HOME}/examples/mnist/estimator/mnist_TFoS.py \<br/>--cluster_size ${SPARK_WORKER_INSTANCES} \<br/>--model ${TFoS_HOME}/mnist_model</pre>
<p>The model learned in 6.6 minutes on the EC2 cluster with two workers:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1035 image-border" src="assets/57532b58-b342-4bf2-9abf-24125871d75f.png" style="width:100.08em;height:49.08em;"/></p>
<div class="CDPAlignLeft CDPAlign packt_tip">We can use TensorBoard to visualize the model architecture. Once we run the code successfully, the event file is created and it can be viewed on the TensorBoard. </div>
<p>When we visualize loss, we can see that the loss decreases as the network learns:</p>
<p class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1036 image-border" src="assets/a95a92b5-e3a7-4608-8ceb-14f0b745b946.png" style="width:65.58em;height:36.50em;"/></p>
<p>The model provides 75% accuracy on the test data set on only 1,000 steps, with a very basic CNN model. We can further optimize the result by using a better model architecture and tuning hyperparameters. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Object detection using TensorFlowOnSpark and Sparkdl</h1>
                </header>
            
            <article>
                
<p class="mce-root">Apache Spark has a higher level API Sparkdl for scalable deep learning in Python. In this section, we'll use the Sparkdl API. In this section, you will learn how to build a model over the pre-trained Inception v3 model to detect cars and buses. This technique of using a pre-trained model is called <strong>transfer learning</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transfer learning</h1>
                </header>
            
            <article>
                
<p>Learning in humans is a continuous process—whatever we learn today is built upon the learning we have had in the past. For example, if you know how to drive a bicycle, you can extend the same knowledge to drive a motorcycle, or drive a car. The driving rule remains the same—<span>the only thing that changes is the control panel and actuators. However, in deep learning, we often start afresh. Is it possible to use the knowledge the model has gained in solving a problem in one domain, to solve the problem in another related domain? </span></p>
<p>Yes, it's indeed possible, and it's called transfer learning. Though a lot of research is still going on in the field, a great deal of success has been achieved in applying transfer learning in the area of computer vision. This is due to the fact that for computer vision tasks <strong>Convolutional Neural Networks</strong> (<strong>CNNs</strong>) are preferred since they are good in extracting features from the image (features such as lines, circles, and squares, at lower layers, and higher abstract features such as ears and nose at the higher layers). Hence, the features extracted by convolutional layers while learning one type of image dataset can be reused in other similar domain images. This can help in reducing the training time.</p>
<p>In this section, we'll use Inception v3 (<a href="https://arxiv.org/pdf/1512.00567v1.pdf">https://arxiv.org/pdf/1512.00567v1.pdf</a>), a state-of-the-art CNN trained on the ImageNet dataset. ImageNet (<a href="http://image-net.org/">http://image-net.org/</a>) contains over 14 million labelled high-resolution hand-annotated images that have been classified into 22,000 categories. Inception v3 was trained on a subset of it consisting of about 1.3 million images with 1,000 categories. </p>
<p>In the transfer learning approach, you keep the feature extractor CNN layers but replace the classifier layers with a new classifier. This new classifier is then trained on the new images. Two approaches are generally followed: either we only train the new classifier or we fine-tune the entire network. In the first case, we extract the features from our new dataset, called <strong>bottleneck features</strong>, by feeding the new dataset into CNN layers. The extracted bottleneck features are then used to train the final classifier. In the second case, we train the entire network, the original CNN, along with the new classifier on the training dataset. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the Sparkdl interface </h1>
                </header>
            
            <article>
                
<p>To access Spark functionality in the deep learning pipeline, we need to use a Spark driver program. From Spark 2.0.0, we have a single point entry using <kbd>SparkSession</kbd>. The simplest way to do this is by using <kbd>builder</kbd>:</p>
<pre>SparkSession.builder().getOrCreate()</pre>
<p>This can allow us to get an existing session or create a new session. At the time of instantiation, we can use the <kbd>.config()</kbd>, <kbd>.master()</kbd>, and <kbd>.appName()</kbd> methods to set configuration options, set the Spark master, and set the application name.</p>
<p>To read and manipulate images, Sparkdl provides the <kbd>ImageSchema</kbd> class. Out of its many methods, we'll be using the <kbd>readImages</kbd> method to read the directory of images. It returns a Spark DataFrame with a single column <span>–</span> <kbd>image</kbd>, of images. </p>
<p>We can add or remove column/rows from the Spark DataFrames using transformations. The example code in this section uses the <kbd>withColumn</kbd> transformation to add a column named <kbd>label</kbd> and assign label classes to our dataset. Just like with a pandas Dataframe, we can view the rows of the Spark DataFrame with the help of the <kbd>show()</kbd> method. The Spark DataFrames can also be split or combined together.</p>
<p>The Sparkdl API has methods to enable fast transfer learning. It provides the <kbd>DeepImageFeaturizer</kbd> class, which automatically peels the classifier layer from the pre-trained model and uses the features (bottleneck features) from the pre-trained CNN layers as an input to the new classifier. </p>
<p>One advantage of working with Sparkdl is that we can access all of the Spark APIs—even its machine learning API MLlib from the same <kbd>SparkSession</kbd> instance. Using MLlib, we can easily combine multiple algorithms into a single a pipeline. The Spark machine learning API MLlib also provides support for various classification and regression methods. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building an object detection model</h1>
                </header>
            
            <article>
                
<p class="mce-root">We'll now make some code by using TFoS and Sparkdl. The dataset consists of images of buses and cars that have been curated from a Google image search. The aim is to train a model so that it can differentiate between cars and buses. The <span>following </span>is a list of prerequisites that you will need for this code to work:</p>
<ul>
<li>PySpark</li>
<li>Python</li>
<li>TensorFlow</li>
<li>TensorFlowOnSpark</li>
<li>Pillow</li>
<li>Keras</li>
<li>TensorFrames</li>
<li>Wrapt</li>
<li>pandas</li>
<li>FindSpark</li>
<li>py4j</li>
</ul>
<p>First, let's explore our dataset. Inception v3 was trained on ImageNet data with 1,000 categories. These included images of various vehicles as well. We have 49 images for buses and 41 images of cars. Here,<span> </span>you can see the sample images from the dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1090 image-border" src="assets/d1e926c3-d5ac-4d48-834b-a05f458bcda5.png" style="width:71.58em;height:22.50em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1091 image-border" src="assets/f7acc5e6-ee73-440b-b004-434ac416c2a2.png" style="width:71.67em;height:22.25em;"/></p>
<p>Now, let's build the code:</p>
<ol>
<li>This time, we'll not be using <kbd>spark-submit</kbd>. Instead, we'll run the code like any standard Python code. Therefore, we'll define the location of spark driver and the Spark deep learning package in the code itself and create a Spark session using PySpark's <kbd>SparkSession</kbd> builder. One thing to keep in mind here is the memory allocated to the heap: Spark executor and Spark driver. The values should be based on your machine's specifications:</li>
</ol>
<div>
<pre style="padding-left: 60px">import findspark<br/>findspark.init('/home/ubuntu/spark-2.4.0-bin-hadoop2.7')<br/><br/>import os<br/>SUBMIT_ARGS = "--packages databricks:spark-deep-learning:1.3.0-spark2.4-s_2.11 pyspark-shell"<br/>os.environ["PYSPARK_SUBMIT_ARGS"] = SUBMIT_ARGS<br/><br/>from pyspark.sql import SparkSession<br/>spark = SparkSession.builder \<br/>    .appName("ImageClassification") \<br/>    .config("spark.executor.memory", "70g") \<br/>    .config("spark.driver.memory", "50g") \<br/>    .config("spark.memory.offHeap.enabled",True) \<br/>    .config("spark.memory.offHeap.size","16g") \<br/>    .getOrCreate()</pre></div>
<ol start="2">
<li>The images are loaded in the Spark DataFrame using PySpark's <kbd>ImageSchema</kbd> class. The bus and cars images are loaded in different Spark DataFrames:</li>
</ol>
<div>
<pre style="padding-left: 60px">import pyspark.sql.functions as f<br/>import sparkdl as dl<br/>from pyspark.ml.image import ImageSchema<br/><br/>dfbuses = ImageSchema.readImages('buses/').withColumn('label', f.lit(0))<br/>dfcars = ImageSchema.readImages('cars/').withColumn('label', f.lit(1))</pre></div>
<ol start="3">
<li>You can see the top five rows of the Spark DataFrame here:</li>
</ol>
<pre style="padding-left: 60px">dfbuses.show(5)<br/>dfcars.show(5)</pre>
<p style="padding-left: 60px">The output of the preceding code is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1037 image-border" src="assets/70221402-30db-4f84-8719-ac9fb0414f7a.png" style="width:20.33em;height:28.58em;"/></p>
<ol start="4">
<li>We split the dataset into the training-test datasets, with a ratio of 60% training and 40% test. Remember that these values are random and you can vary them accordingly:</li>
</ol>
<div>
<pre style="padding-left: 60px">trainDFbuses, testDFbuses = dfbuses.randomSplit([0.60,0.40], seed = 123)<br/>trainDFcars, testDFcars = dfcars.randomSplit([0.60,0.40], seed = 122)</pre></div>
<ol start="5">
<li>The training dataset for buses and cars is combined. The same is done for the test dataset:</li>
</ol>
<div>
<pre style="padding-left: 60px">trainDF = trainDFbuses.unionAll(trainDFcars)<br/>testDF = testDFbuses.unionAll(testDFcars)</pre></div>
<ol start="6">
<li>We use the Sparkdl API to get the pre-trained Inception v3 model and on top of the CNN layers of Inception, we add a logistic regressor. Now, we'll train the model on our dataset:</li>
</ol>
<div>
<div>
<div>
<pre style="padding-left: 60px">from pyspark.ml.classification import LogisticRegression<br/>from pyspark.ml import Pipeline<br/>vectorizer = dl.DeepImageFeaturizer(inputCol="image",<br/>         outputCol="features", <br/>        modelName="InceptionV3")<br/><br/>logreg = LogisticRegression(maxIter=30, labelCol="label")<br/>pipeline = Pipeline(stages=[vectorizer, logreg])<br/>pipeline_model = pipeline.fit(trainDF)</pre></div>
</div>
</div>
<ol start="7">
<li>Let's see how the trained model fairs on the test dataset. Let's use a perfect confusion matrix:</li>
</ol>
<div>
<pre style="padding-left: 60px">predictDF = pipeline_model.transform(testDF)<br/>predictDF.select('prediction', 'label').show(n = testDF.toPandas().shape[0], truncate=False)<br/>predictDF.crosstab('prediction', 'label').show()</pre></div>
<p style="padding-left: 60px"><span>The output of the preceding code is as follows:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1038 image-border" src="assets/9ebcccea-cfec-43ab-910f-ec6742d7112a.png" style="width:15.08em;height:7.08em;"/></p>
<ol start="8">
<li>For the test dataset, the model gives 100% accuracy:</li>
</ol>
<div>
<pre style="padding-left: 60px">from pyspark.ml.evaluation import MulticlassClassificationEvaluator<br/>scoring = predictDF.select("prediction", "label")<br/>accuracy_score = MulticlassClassificationEvaluator(metricName="accuracy")<br/>rate = accuracy_score.evaluate(scoring)*100<br/>print("accuracy: {}%" .format(round(rate,2)))</pre></div>
<p>Our model is giving such a good performance because the Inception v3 model that we have used as the base model for transfer learning has already been trained on a lot of vehicle images. A word of caution, however—100% accuracy doesn't mean it's the best model, just that it does well on the present test images.</p>
<div class="packt_infobox">Developed by DataBricks, Sparkdl is part of the Deep Learning Pipelines. They provide high-level APIs for scalable deep learning in Python with Apache Spark. You can learn more about its features and how to use it here: <a href="https://github.com/databricks/spark-deep-learning">https://github.com/databricks/spark-deep-learning</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Deep learning models provide better performance when the training dataset is large (big data). Training models for big data is computationally expensive. This problem can be handled using the divide and conquer approach: we divide the extensive computation part to many machines in a cluster, in other words, distributed AI.</p>
<p>One way of achieving this is by using Google's distributed TensorFlow, the API that helps in distributing the model training among different worker machines in the cluster. You need to specify the address of each worker machine and the parameter server. This makes the task of scaling the model difficult and cumbersome.</p>
<p>This problem can be solved by using the TensorFlowOnSpark API. By making minimal changes to the preexisting TensorFlow code, we can make it run on the cluster. The Spark framework handles the distribution among executor machines and the master, shielding the user from the details and giving better scalability.</p>
<p>In this chapter, the TensorFlowOnSpark API was used to train a model to recognize handwritten digits. This solved the problem of scalability, but we still had to process data so that it's available in the right format for training. Unless you are well-versed with the Spark infrastructure, especially Hadoop, this can be a difficult task.</p>
<p>To ease the difficulty, we can make use of another API, Sparkdl, which provides the complete deep learning pipeline on Spark for training using Spark DataFrames. Finally, this chapter used the Sparkdl API for object detection. A model was built over the pre-trained Inception v3 model to classify images of buses and cars. </p>
<p>In the next chapter, you will learn how to generate book scripts using RNN. Who knows—it may win the Booker Prize!</p>


            </article>

            
        </section>
    </body></html>