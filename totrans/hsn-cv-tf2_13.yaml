- en: Migrating from TensorFlow 1 to TensorFlow 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since TensorFlow 2 has only been released very recently, most of the projects
    that are available online are still built for TensorFlow 1\. While this first
    version was already packed with useful features, such as AutoGraph and the Keras
    API, it is recommended that you migrate to the latest version of TensorFlow so
    as to avoid any technical debt. Thankfully, TensorFlow 2 comes with an automatic
    migration tool that is able to convert most projects to its latest version. It
    requires little effort and outputs functional code. However, migrating to idiomatic
    TensorFlow 2 code requires some diligence and knowledge of both versions. In this
    section, we will introduce the migration tool and compare TensorFlow 1 concepts
    with their TensorFlow 2 counterparts.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic migration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After installing TensorFlow 2, the migration tool is available from the command
    line. To convert a project directory, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a sample of the command''s logs on an example project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The conversion tool details all the changes it made to the files. In the rare
    case when it detects a code line that requires manual attention, it outputs a
    warning with instructions to update.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the outdated calls are moved to `tf.compat.v1`. Indeed, despite the
    deprecation of many concepts, TensorFlow 2 still provides access to the old API
    through this module. However, be aware that calls to `tf.contrib` will cause the
    conversion tool to fail and generate an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Migrating TensorFlow 1 code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the tool runs without any error, the code can be used as is. However, the
    `tf.compat.v1` module used by the migration tool is deemed to be deprecated. Calling
    this module already outputs deprecation warnings, and its content will not be
    further updated by the community. For this reason, it is recommended that you
    refactor the code in order to make it more idiomatic. In the following sections,
    we will introduce TensorFlow 1 concepts and explain how to migrate them to TensorFlow
    2\. In the following examples, `tf1` will be used instead of `tf` to denote the
    use of TensorFlow 1.13.
  prefs: []
  type: TYPE_NORMAL
- en: Sessions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since TensorFlow 1 does not use eager execution by default, the results of
    the operations are not directly available. For instance, when summing two constants,
    the output object is an operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To compute a result, you need to manually create `tf1.Session`. A session takes
    care of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Managing the memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running operations on CPU or GPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running on several machines if necessary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The most common way of using a session is through the `with` statement in Python.
    As with other unmanaged resources, the `with` statement guarantees that the session
    is properly closed after we use it. If the session is not closed, it may keep
    using memory. Sessions in TensorFlow 1 are, therefore, typically instantiated
    and used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also explicitly close a session, but it is not recommended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In TensorFlow 2, session management happens behind the scenes. As the new version
    uses eager execution, there is no need for this superfluous code to compute results.
    Calls to `tf1.Session()` can, therefore, be removed.
  prefs: []
  type: TYPE_NORMAL
- en: Placeholders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous example, we computed the sum of two vectors. However, we defined
    the value of those vectors when creating the graph. If we wanted to use variables
    instead, we could have used `tf1.placeholder`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In TensorFlow 1, placeholders are mostly used to provide input data. Their type
    and shape have to be defined. In our example, the shape is `(None,)` because we
    may want to run the operation on vectors of any size. When running the graph,
    we have to provide specific values for our placeholders. This is why we use the `feed_dict` argument
    in `sess.run`, passing the content of variables as a dictionary, with the placeholders
    as keys. Failing to provide a value for all placeholders would cause an exception.
  prefs: []
  type: TYPE_NORMAL
- en: Before TensorFlow 2, placeholders were used to provide input data, as well as
    layers' parameters. The former use case can be replaced with `tf.keras.Input`,
    while the latter can be addressed using `tf.keras.layers.Layer` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Variable management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In TensorFlow 1, variables were created globally. Each variable had a unique
    name and the best practice in terms of creating them was to use `tf1.get_variable()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we created a global variable named `W`. Deleting the Python `weights` variable
    (using the Python `del weights` command, for instance) would have no effect on
    TensorFlow memory. In fact, if we try to create the same variable again, we would
    end up with an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'While `tf1.get_variable()` allows you to reuse variables, its default behavior
    is to throw an error if a variable with the chosen name already exists, preventing
    you from mistakenly overriding variables. To avoid this error, we can update our
    call to `tf1.variable_scope(...)` and employ the `reuse` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `variable_scope` context manager was used to manage variable creation. On
    top of handling variable reuse, it was useful to group variables together by appending
    a prefix to their name. In the previous example, the variable would be named `conv1/W`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, setting reuse to `True` means that if TensorFlow encounters a
    variable called `conv1/W`, it will not throw an error as it did before. Instead,
    it will reuse the existing variable, including its content. However, if you try
    calling the preceding code and the variable named `conv1/W` does not exist, you
    will encounter the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Indeed, `reuse=True` can only be specified when reusing an existing variable.
    If you want to create a variable if it does not exist, and reuse it when it does
    exist, you can pass `reuse=tf.AUTO_REUSE`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In TensorFlow 2, the behavior is different. While variable scope still exists
    to make naming and debugging easier, variables are no longer global. They are
    handled at the Python level. As long as you can access the Python reference (the
    `weights` variable, in our example), you can modify the variable. To delete the
    variable, you need to delete its reference, for instance, by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Previously, variables could be accessed and modified globally, and could potentially
    be overridden by other pieces of code. The deprecation of global variables makes
    TensorFlow code more readable and less prone to errors.
  prefs: []
  type: TYPE_NORMAL
- en: Layers and models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TensorFlow models were originally defined using `tf1.layers`. As this module
    has been deprecated in TensorFlow 2, the replacement of choice is `tf.keras.layers`.
    To train a model using TensorFlow 1, a *train operation* has to be defined using
    an optimizer and a loss. For instance, if `y` is the output of a fully connected
    layer, we would define the training operation using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Every time we call this operation, a batch of images will be fed to the network
    and a single step of backpropagation will happen. We then run a loop to compute
    multiple training steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: When opening the session, a call to `tf1.global_variables_initializer()` is
    necessary so that layers are initialized with the correct weights. A failure to
    do so would throw an exception. In TensorFlow 2, the initialization of variables
    is handled automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Other concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We detailed the most common TensorFlow 1 concepts that were deprecated in the
    new version. Many smaller modules and paradigms were also redesigned in TensorFlow
    2\. When migrating a project, we recommend having a thorough look at the documentation
    of both versions. To ensure that a migration went well and the TensorFlow 2 version
    works as expected, we recommend that you log both inference metrics (such as latency,
    accuracy, or average precision) and training metrics (such as the number of iterations
    before convergence), and compare their values between the old and new versions.
  prefs: []
  type: TYPE_NORMAL
- en: As it is open source and backed by an active community, TensorFlow is constantly
    evolving—integrating new features, optimizing others, improving the developer
    experience, and more. While this may sometimes require some additional effort,
    upgrading to the latest version as soon as possible will provide you with the
    best environment to develop more performant recognition applications.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section lists the scientific papers and other web resources mentioned in
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter 1: Computer Vision and Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., 2008\. *A Fast and Incremental
    Method for Loop-Closure Detection Using Bags of Visual Words*. *IEEE Transactions
    on Robotics 1027–1037*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bradski, G., Kaehler, A., 2000\. OpenCV. *Dr. Dobb’s Journal of Software Tools
    3*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cortes, C., Vapnik, V., 1995\. *Support-Vector Networks*. *Machine Learning
    20, 273–297*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Drucker, H., Burges, C.J., Kaufman, L., Smola, A.J., Vapnik, V., 1997\. *Support
    Vector Regression Machines. In: Advances in Neural Information Processing Systems,
    pp. 155–161*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012\. *ImageNet Classification
    with Deep Convolutional Neural Networks*. *In: Advances in Neural Information
    Processing Systems, pp. 1097–1105*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., 1997\. *Face Recognition:
    A Convolutional Neural-Network Approach*. *IEEE Transactions on Neural Networks
    8, 98–113*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard,
    W.E., Jackel, L.D., 1990\. *Handwritten Digit Recognition with a Back-Propagation
    Network*. *In: Advances in Neural Information Processing Systems, pp. 396–404*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun, Y., Cortes, C., Burges, C., 2010\. *MNIST Handwritten Digit Database.
    AT&T Labs [Online]*. Available at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)
    2, 18.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lowe, D.G., 2004\. *Distinctive Image Features from Scale-Invariant Keypoints*.
    *International Journal of Computer Vision 60, 91–110*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minsky, M., 1961\. *Steps Toward Artificial Intelligence*. *Proceedings of the
    IRE 49, 8–30*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minsky, M., Papert, S.A., 2017\. *Perceptrons: An Introduction to Computational
    Geometry. MIT press*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moravec, H., 1984\. *Locomotion, Vision, and Intelligence*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papert, S.A., 1966\. *The Summer Vision Project*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plaut, D.C., et al., 1986\. *Experiments on Learning by Back Propagation*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rosenblatt, F., 1958\. *The Perceptron: A Probabilistic Model for Information
    Storage and Organization in the Brain*. *Psychological Review 65, 386*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turk, M., Pentland, A., 1991\. *Eigenfaces for Recognition. Journal of Cognitive
    Neuroscience 3, 71–86*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wold, S., Esbensen, K., Geladi, P., 1987\. *Principal Component Analysis. Chemometrics
    and Intelligent Laboratory Systems 2, 37–52*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 2: TensorFlow Basics and Training a Model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado,
    G.S., Davis, A., Dean, et al. *TensorFlow: Large-Scale Machine Learning on Heterogeneous
    Distributed Systems 19*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*API Documentation [WWW Document], n.d. TensorFlow*. URL: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)
    (accessed December 14, 2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chollet, F., 2018\. TensorFlow is the platform of choice for deep learning in
    the research community. There are deep learning framework mentions on arXiv over
    the past three months, *pic.twitter.com/v6ZEi63hzP. @fchollet*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goldsborough, P., 2016\. *A Tour of TensorFlow. arXiv:1610.01178 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 3: Modern Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
    Ghemawat, S., Irving, G., Isard, M., et al., 2016\. *Tensorflow: A System for
    Large-Scale Machine Learning. In: OSDI, pp. 265–283*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*API Documentation, URL*: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)
    (accessed December 14, 2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bottou, L., 2010\. *Large-Scale Machine Learning with Stochastic Gradient Descent.
    In: Proceedings of COMPSTAT''2010*. *Springer, pp. 177–186*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bottou, L., Curtis, F.E., Nocedal, J., 2018\. *Optimization Methods for Large-Scale
    Machine Learning. SIAM Review 60, 223–311*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dozat, T., 2016\. *Incorporating Nesterov Momentum into Adam*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duchi, J., Hazan, E., Singer, Y., 2011\. *Adaptive Subgradient Methods for Online
    Learning and Stochastic Optimization. Journal of Machine Learning Research 12,
    2121–2159*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gardner, W.A., 1984\. *Learning Characteristics of Stochastic Gradient Descent
    Algorithms: A General Study, Analysis, and Critique. Signal Processing 6, 113–133*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Girosi, F., Jones, M., Poggio, T., 1995\. *Regularization Theory and Neural
    Networks Architectures*. *Neural Computation 7, 219–269*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe, S., Szegedy, C., 2015\. *Batch Normalization: Accelerating Deep Network
    Training by Reducing Internal Covariate Shift.* *arXiv preprint arXiv:1502.03167*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Karpathy, A., n.d. *Stanford University CS231n: Convolutional Neural Networks
    for Visual Recognition [WWW Document]*. URL: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
    (accessed December 14, 2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kingma, D.P., Ba, J., 2014\. *Adam: A Method for Stochastic Optimization. arXiv
    preprint arXiv:1412.6980*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012\. *ImageNet Classification
    with Deep Convolutional Neural Networks*. *In: Advances in Neural Information
    Processing Systems, pp. 1097–1105*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., 1997\. *Face Recognition:
    A Convolutional Neural Network Approach*. *IEEE Transactions on Neural Networks
    8, 98–113*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le and Borji – 2017 – *What are the Receptive, Effective Receptive, and P.pdf,
    n.d*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le, H., Borji, A., 2017\. *What are the Receptive, Effective Receptive, and
    Projective Fields of Neurons in Convolutional Neural Networks? arXiv:1705.07049
    [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun, Y., Cortes, C., Burges, C., 2010\. *MNIST Handwritten Digit Database.
    AT&T Labs [Online]*. Available at [http://yann.lecun.com/exdb/mnist](http://yann.lecun.com/exdb/mnist)
    2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LeCun, Y., et al., 2015\. LeNet-5, *Convolutional Neural Networks*. URL: [http://yann.lecun.com/exdb/lenet](http://yann.lecun.com/exdb/lenet)
    20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lenail, A., *n.d. NN SVG [WWW Document]*. URL: [http://alexlenail.me/NN-SVG/](http://alexlenail.me/NN-SVG/)
    (accessed December 14, 2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo, W., Li, Y., Urtasun, R., Zemel, R., n.d. *Understanding the Effective Receptive
    Field in Deep Convolutional Neural Networks 9*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nesterov, Y., 1998\. *Introductory Lectures on Convex Programming Volume I:
    Basic Course. Lecture notes*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perkins, E.S., Davson, H., n.d. *Human Eye | Definition, Structure, & Function
    [WWW Document]*. *Encyclopedia Britannica*. URL: [https://www.britannica.com/science/human-eye](https://www.britannica.com/science/human-eye)
    (accessed December 14, 2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perone, C.S., n.d. *The effective receptive field on CNNs | Terra Incognita.
    Terra Incognita*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polyak, B.T., 1964\. *Some methods of speeding up the convergence of iteration
    methods. USSR Computational Mathematics and Mathematical Physics 4, 1–17*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raj, D., 2018\. *A Short Note on Gradient Descent Optimization Algorithms*.
    *Medium*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simard, P.Y., Steinkraus, D., Platt, J.C., 2003\. *Best Practices for Convolutional
    Neural Networks Applied to Visual Document Analysis. In: Null, p. 958*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.,
    2014\. *Dropout: A Simple Way to Prevent Neural Networks from Overfitting. The
    Journal of Machine Learning Research 15, 1929–1958*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sutskever, I., Martens, J., Dahl, G., Hinton, G., 2013\. *On the importance
    of initialization and momentum in deep learning. In: International Conference
    on Machine Learning, pp. 1139–1147*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tieleman, T., Hinton, G., 2012\. *Lecture 6.5-rmsprop:* *Divide the gradient
    by a running average of its recent magnitude. COURSERA: Neural Networks for Machine
    Learning 4, 26–31*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Walia, A.S., 2017\. *Types of Optimization Algorithms Used in Neural Networks
    and Ways to Optimize Gradient Descent [WWW Document]. Towards Data Science*. URL: [https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f)
    (accessed December 14, 2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeiler, M.D., 2012\. *ADADELTA: An Adaptive Learning Rate Method. arXiv preprint
    arXiv:1212.5701*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang, T., 2004\. *Solving large-scale linear prediction problems using stochastic
    gradient descent algorithms*. *In: Proceedings of the Twenty-first International
    Conference on Machine Learning, p. 116*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 4: Influential Classification Tools'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*API Documentation [WWW Document], n.d. TensorFlow*. URL: [https://www.tensorflow.org/api_docs/](https://www.tensorflow.org/api_docs/)
    (accessed December 14, 2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow, I., Bengio, Y., Courville, A., 2016\. *Deep Learning. MIT Press*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He, K., Zhang, X., Ren, S., Sun, J., 2015\. *Deep Residual Learning for Image
    Recognition. arXiv:1512.03385 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto,
    M., Adam, H., 2017\. *MobileNets: Efficient Convolutional Neural Networks for
    Mobile Vision Applications. arXiv:1704.04861 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang, G., Liu, Z., van der Maaten, L., Weinberger, K.Q., 2016\. *Densely Connected
    Convolutional Networks. arXiv:1608.06993 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Karpathy, A., n.d. *Stanford University CS231n: Convolutional Neural Networks
    for Visual Recognition [WWW Document]*. URL: [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)
    (accessed December 14, 2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karpathy, A. *What I learned from competing against a ConvNet on ImageNet [WWW
    Document], n.d*. URL: [http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/)
    (accessed January 4, 2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin, M., Chen, Q., Yan, S., 2013\. *Network In Network. arXiv:1312.4400 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan, S.J., Yang, Q., 2010\. *A Survey on Transfer Learning. IEEE Transactions
    on Knowledge and Data Engineering 22, 1345–1359*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang,
    Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2014\. *ImageNet
    Large-Scale Visual Recognition Challenge. arXiv:1409.0575 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarkar, D. (DJ), 2018\. *A Comprehensive Hands-on Guide to Transfer Learning
    with Real-World Applications in Deep Learning [WWW Document]. Towards Data Science*.
    URL: [https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)
    (accessed January 15, 2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: shu-yusa, 2018\. *Using Inception-v3 from TensorFlow Hub for Transfer Learning.
    Medium.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Simonyan, K., Zisserman, A., 2014\. Very Deep Convolutional Networks for Large-Scale
    Image Recognition. arXiv:1409.1556 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Srivastava, R.K., Greff, K., Schmidhuber, J., 2015\. *Highway Networks. arXiv:1505.00387
    [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A., 2016\. *Inception-v4, Inception-ResNet
    and the Impact of Residual Connections on Learning. arXiv:1602.07261 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan,
    D., Vanhoucke, V., Rabinovich, A., 2014\. *Going Deeper with Convolutions. arXiv:1409.4842
    [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., 2015\. *Rethinking
    the Inception Architecture for Computer Vision. arXiv:1512.00567 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thrun, S., Pratt, L., 1998\. *Learning to Learn*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeiler, Matthew D., Fergus, R., 2014\. *Visualizing and Understanding Convolutional
    Networks*. In: Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T. (Eds.), *Computer
    Vision – ECCV 2014\. Springer International Publishing, Cham, pp. 818–833*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeiler, Matthew D, Fergus, R., 2014\. *Visualizing and Understanding Convolutional
    Networks. In: European Conference on Computer Vision, pp. 818–833*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 5: Object Detection Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Everingham, M., Eslami, S.M.A., Van Gool, L., Williams, C.K.I., Winn, J., Zisserman,
    A., 2015\. *The Pascal Visual Object Classes Challenge: A Retrospective. International
    Journal of Computer Vision 111, 98–136*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Girshick, R., 2015\. *Fast R-CNN. arXiv:1504.08083 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Girshick, R., Donahue, J., Darrell, T., Malik, J., 2013\. *Rich feature hierarchies
    for accurate object detection and semantic segmentation. arXiv:1311.2524 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2015\. *You Only Look Once:
    Unified, Real-Time Object Detection. arXiv:1506.02640 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon, J., Farhadi, A., 2016\. YOLO9000: *Better, Faster, Stronger. arXiv:1612.08242
    [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon, J., Farhadi, A., 2018\. YOLOv3: *An Incremental Improvement. arXiv:1804.02767
    [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren, S., He, K., Girshick, R., Sun, J., 2015\. *Faster R-CNN: Towards Real-Time
    Object Detection with Region Proposal Networks. arXiv:1506.01497 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 6: Enhancing and Segmenting Images'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bai, M., Urtasun, R., 2016\. *Deep Watershed Transform for Instance Segmentation.
    arXiv:1611.08303 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Beyer, L., 2019\. *Python wrapper to Philipp Krähenbühl''s dense (fully connected)
    CRFs with gaussian edge potentials: lucasb-eyer/pydensecr**f*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Building Autoencoders in Keras [WWW Document]*, n.d. URL: [https://blog.keras.io/building-autoencoders-in-keras.html](https://blog.keras.io/building-autoencoders-in-keras.html)
    (accessed January 18, 2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
    Franke, U., Roth, S., Schiele, B., 2016\. *The Cityscapes Dataset for Semantic
    Urban Scene Understanding. In: 2016 IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR)*. *Presented at the 2016 IEEE Conference on Computer Vision
    and Pattern Recognition (CVPR)*, *IEEE, Las Vegas, NV, USA, pp. 3213–3223*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dice, L.R., 1945\. *Measures of the Amount of Ecologic Association Between Species.
    Ecology 26, 297–302*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drozdzal, M., Vorontsov, E., Chartrand, G., Kadoury, S., Pal, C., 2016\. *The
    Importance of Skip Connections in Biomedical Image Segmentation. arXiv:1608.04117
    [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dumoulin, V., Visin, F., 2016\. *A Guide to Convolution Arithmetic for Deep
    Learning. arXiv:1603.07285 [cs, stat]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guan, S., Khan, A., Sikdar, S., Chitnis, P.V., n.d. *Fully Dense UNet for 2D
    Sparse Photoacoustic Tomography Artifact Removal 8*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017\. *Mask R-CNN. arXiv:1703.06870
    [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kaggle. 2018 Data Science Bowl [WWW Document]*, n.d. URL: [https://kaggle.com/c/data-science-bowl-2018](https://kaggle.com/c/data-science-bowl-2018)
    (accessed February 8, 2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krähenbühl, P., Koltun, V., n.d. *Efficient Inference in Fully Connected CRFs
    with Gaussian Edge Potentials 9*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lan, T., Li, Y., Murugi, J.K., Ding, Y., Qin, Z., 2018\. *RUN: Residual U-Net
    for Computer-Aided Detection of Pulmonary Nodules without Candidate Selection.
    arXiv:1805.11856 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li, X., Chen, H., Qi, X., Dou, Q., Fu, C.-W., Heng, P.A., 2017\. *H-DenseUNet:
    Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes.
    arXiv:1709.07330 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin, T.-Y., Goyal, P., Girshick, R., He, K., Dollár, P., 2017\. *Focal Loss
    for Dense Object Detection. arXiv:1708.02002 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Milletari, F., Navab, N., Ahmadi, S.-A., 2016\. *V-Net: Fully Convolutional
    Neural Networks for Volumetric Medical Image Segmentation*. *In: 2016 Fourth International
    Conference on 3D Vision (3DV)*. *Presented at the 2016 Fourth International Conference
    on 3D Vision (3DV), IEEE, Stanford, CA, USA, pp. 565–571*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Noh, H., Hong, S., Han, B., 2015\. *Learning Deconvolution Network for Semantic
    Segmentation*. In: 2015 *IEEE International Conference on Computer Vision (ICCV)*.
    *Presented at the 2015 ICCV, IEEE, Santiago, Chile, pp. 1520–1528*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Odena, A., Dumoulin, V., Olah, C., 2016\. *Deconvolution and Checkerboard Artifacts.
    Distill 1, e3*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronneberger, O., Fischer, P., Brox, T., 2015\. *U-Net: Convolutional Networks
    for Biomedical Image Segmentation. arXiv:1505.04597 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shelhamer, E., Long, J., Darrell, T., 2017\. *Fully Convolutional Networks for
    Semantic Segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence
    39, 640–651*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sørensen, T., 1948\. *A method of establishing groups of equal amplitude in
    plant sociology based on similarity of species and its application to analyses
    of the vegetation on Danish commons. Biol. Skr. 5, 1–34*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Unsupervised Feature Learning and Deep Learning Tutorial [WWW Document]*,
    n.d. URL: [http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)
    (accessed January 17, 2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeiler, M.D., Fergus, R., 2013\. *Visualizing and Understanding Convolutional
    Networks. arXiv:1311.2901 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang, Z., Liu, Q., Wang, Y., 2018\. *Road Extraction by Deep Residual U-Net.
    IEEE Geoscience and Remote Sensing Letters 15, 749–753*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 7: Training on Complex and Scarce Datasets'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., 2017a. *Unsupervised
    Pixel-Level Domain Adaptation with Generative Adversarial Networks*. *In: 2017
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Presented at
    the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE,
    Honolulu*, *HI, pp. 95–104*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bousmalis, K., Silberman, N., Dohan, D., Erhan, D., Krishnan, D., 2017b. *Unsupervised
    Pixel-Level Domain Adaptation with Generative Adversarial Networks. In: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3722–3731*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brodeur, S., Perez, E., Anand, A., Golemo, F., Celotti, L., Strub, F., Rouat,
    J., Larochelle, H., Courville, A., 2017\. *HoME: a Household Multimodal Environment.
    arXiv:1711.11017 [cs, eess]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang, A.X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., Savarese,
    S., Savva, M., Song, S., Su, H., Xiao, J., Yi, L., Yu, F., 2015\. ShapeNet: *An
    Information-Rich 3D Model Repository (No. arXiv:1512.03012 [cs.GR]). Stanford
    University – Princeton University – Toyota Technological Institute at Chicago*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen, Y., Li, W., Sakaridis, C., Dai, D., Van Gool, L., 2018\. *Domain Adaptive
    Faster R-CNN for Object Detection in the Wild. In: 2018 IEEE/CVF Conference on
    Computer Vision and Pattern Recognition*. *Presented at the 2018 IEEE/CVF Conference
    on Computer Vision and Pattern Recognition (CVPR), IEEE, Salt Lake City, UT, USA,
    pp. 3339–3348*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
    Franke, U., Roth, S., Schiele, B., 2016\. *The Cityscapes Dataset for Semantic
    Urban Scene Understanding. In: Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, pp. 3213–3223*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette,
    F., Marchand, M., Lempitsky, V., 2017\. *Domain-Adversarial Training of Neural
    Networks. In: Csurka, G. (Ed.), Domain Adaptation in Computer Vision Applications.
    Springer International Publishing, Cham, pp. 189–209*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., Courville, A., Bengio, Y., 2014\. *Generative Adversarial Nets. In: Advances
    in Neural Information Processing Systems, pp. 2672–2680*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gschwandtner, M., Kwitt, R., Uhl, A., Pree, W., 2011\. *BlenSor: Blender Sensor
    Simulation Toolbox. In: International Symposium on Visual Computing, pp. 199–208*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hernandez-Juarez, D., Schneider, L., Espinosa, A., Vázquez, D., López, A.M.,
    Franke, U., Pollefeys, M., Moure, J.C., 2017\. *Slanted Stixels: Representing
    San Francisco''s Steepest Streets. arXiv:1707.05397 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros,
    A.A., Darrell, T., 2017\. *CyCADA: Cycle-Consistent Adversarial Domain Adaptation.
    arXiv:1711.03213 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Isola, P., Zhu, J.-Y., Zhou, T., Efros, A.A., 2017\. *Image-to-Image Translation
    with Conditional Adversarial Networks. In: Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pp. 1125–1134*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma, D.P., Welling, M., 2013\. *Auto-encoding Variational Bayes. arXiv preprint
    arXiv:1312.6114*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long, M., Cao, Y., Wang, J., Jordan, M.I., n.d. *Learning Transferable Features
    with Deep Adaptation Networks 9*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Planche, B., Wu, Z., Ma, K., Sun, S., Kluckner, S., Lehmann, O., Chen, T.,
    Hutter, A., Zakharov, S., Kosch, H., et al., 2017\. *Depthsynth: Real-Time Realistic
    Synthetic Data Generation from CAD Models for 2.5D Recognition. In: 2017 International
    Conference on 3D Vision (3DV), pp*. 1–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Planche, B., Zakharov, S., Wu, Z., Hutter, A., Kosch, H., Ilic, S., 2018\. *Seeing
    Beyond Appearance—Mapping Real Images into Geometrical Domains for Unsupervised
    CAD-based Recognition. arXiv preprint arXiv:1810.04158*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Protocol Buffers [WWW Document], n.d. Google Developers*. URL: [https://developers.google.com/protocol-buffers/](https://developers.google.com/protocol-buffers/)
    (accessed February 23, 2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford, A., Metz, L., Chintala, S., 2015\. *Unsupervised Representation Learning
    with Deep Convolutional Generative Adversarial Networks. arXiv:1511.06434 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Richter, S.R., Vineet, V., Roth, S., Koltun, V., 2016\. *Playing for Data:
    Ground Truth from Computer Games. In: European Conference on Computer Vision,
    pp. 102–118*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ros, G., Sellart, L., Materzynska, J., Vazquez, D., Lopez, A.M., 2016\. *The
    SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation
    of Urban Scenes. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR). Presented at the 2016 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR), IEEE, Las Vegas, NV, USA, pp. 3234–3243*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rozantsev, A., Lepetit, V., Fua, P., 2015\. *On Rendering Synthetic Images for
    Training an Object Detector. Computer Vision and Image Understanding 137, 24–37*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tremblay, J., Prakash, A., Acuna, D., Brophy, M., Jampani, V., Anil, C., To,
    T., Cameracci, E., Boochoon, S., Birchfield, S., 2018\. *Training Deep Networks
    with Synthetic Data: Bridging the Reality Gap by Domain Randomization. In: 2018
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)*.
    *Presented at the 2018 IEEE/CVF CVPRW, IEEE, Salt Lake City, UT, pp. 1082–10828*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., 2017\. *Adversarial Discriminative
    Domain Adaptation. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR)*. *Presented at the 2017 IEEE CVPR, IEEE, Honolulu, HI, pp. 2962–2971*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., 2017\. *Unpaired Image-to-Image
    Translation Using Cycle-Consistent Adversarial Networks. In: Proceedings of the
    IEEE International Conference on Computer Vision, pp. 2223–2232*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 8: Video and Recurrent Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Britz, D., 2015\. *Recurrent Neural Networks Tutorial, Part 3 – Backpropagation
    Through Time and Vanishing Gradients. WildML*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brown, C., 2019\. *repo for learning neural nets and related material: go2carter/nn-learn.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chung, J., Gulcehre, C., Cho, K., Bengio, Y., 2014\. Empirical Evaluation
    of Gated Recurrent Neural Networks on Sequence Modeling. arXiv:1412.3555 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter, S., Schmidhuber, J., 1997\. *Long Short-Term Memory. Neural Computation
    9, 1735–1780*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lipton, Z.C., Berkowitz, J., Elkan, C., 2015\. *A Critical Review of Recurrent
    Neural Networks for Sequence Learning. arXiv:1506.00019 [cs]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Soomro, K., Zamir, A.R., Shah, M., 2012\. *UCF101: A Dataset of 101 Human Actions
    Classes From Videos in The Wild. arXiv:1212.0402 [cs]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chapter 9: Optimizing Models and Deploying on Mobile Devices'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Goodfellow, I.J., Erhan, D., Carrier, P.L., Courville, A., Mirza, M., Hamner,
    B., Cukierski, W., Tang, Y., Thaler, D., Lee, D.-H., Zhou, Y., Ramaiah, C., Feng,
    F., Li, R., Wang, X., Athanasakis, D., Shawe-Taylor, J., Milakov, M., Park, J.,
    Ionescu, R., Popescu, M., Grozea, C., Bergstra, J., Xie, J., Romaszko, L., Xu,
    B., Chuang, Z., Bengio, Y., 2013\. *Challenges in Representation Learning: A Report
    on Three Machine Learning Contests. arXiv:1307.0414 [cs, stat]*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton, G., Vinyals, O., Dean, J., 2015\. *Distilling the Knowledge in a Neural
    Network. arXiv:1503.02531 [cs, stat]*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hoff, T., n.d. *The Technology Behind Apple Photos and the Future of Deep Learning
    and Privacy – High Scalability*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tencent, n.d. Tencent/PocketFlow: An Automatic Model Compression (AutoMC)
    Framework for Developing Smaller and Faster AI Applications*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
