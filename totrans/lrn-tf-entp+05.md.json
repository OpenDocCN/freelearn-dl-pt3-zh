["```\n    PROJECT_ID = '<PROJECT_ID>' \n    import tensorflow as tf\n    import pandas as pd\n    ```", "```\n    %%bigquery train_raw_df\n    SELECT countries_and_territories, geo_id, country_territory_code, \n    year, month, day, confirmed_cases, daily_deaths, pop_data_2019\n    FROM bigquery-public-data.covid19_ecdc.covid_19_geographic_distribution_worldwide\n    ```", "```\n    train_raw_df.sample(n=5)\n    ```", "```\n    train_raw_df['countries_and_territories'] = pd.Categorical(train_raw_df['countries_and_territories'])\n    ```", "```\n    train_raw_df['countries_and_territories'] = train_raw_df.countries_and_territories.cat.codes\n    ```", "```\n    train_raw_df['geo_id'] = pd.Categorical(train_raw_df['geo_id'])\n    train_raw_df['geo_id'] = train_raw_df.geo_id.cat.codes\n    train_raw_df['country_territory_code'] = pd.Categorical(train_raw_df['country_territory_code'])\n    train_raw_df['country_territory_code'] = train_raw_df.country_territory_code.cat.codes\n    ```", "```\n    int32_features = ['confirmed_cases']\n    float32_features = ['pop_data_2019']\n    int16_features = ['year', 'month', 'day']\n    categorical_features = ['countries_and_territories', 'geo_id', 'country_territory_code']\n    int32_target = ['daily_deaths']\n    ```", "```\n    training_dataset = tf.data.Dataset.from_tensor_slices(\n            (\n                tf.cast(train_raw_df[int32_features].values, \n                tf.int32),\n                tf.cast(train_raw_df[float32_features].\n                values, tf.float32),\n                tf.cast(train_raw_df[int16_features].values, \n                tf.int16),\n                tf.cast(train_raw_df[categorical_features].\n                values, tf.int32),\n                tf.cast(train_raw_df[int32_target].values, \n                tf.int32)\n            )\n        )\n    ```", "```\n    training_dataset\n    ```", "```\n    <TensorSliceDataset shapes: ((1,), (1,), (3,), (3,), (1,)), types: (tf.int32, tf.float32, tf.int16, tf.int32, tf.int32)>\n    ```", "```\n<FILE_NAME>-<pattern>-001.csv\n```", "```\n…\n```", "```\n<FILE_NAME>-<pattern>-00n.csv\n```", "```\n<FILE_NAME>-<pattern>-aa.csv\n```", "```\n…\n```", "```\n<FILE_NAME>-<pattern>-zz.csv\n```", "```\nwget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n```", "```\n['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigree', 'Age', 'Outcome']\n```", "```\n    awk '{filename = 'pima_indian_diabetes_data_part0' int((NR-1)/200) '.csv'; print >> filename}' pima-indians-diabetes.data.csv\n    ```", "```\n    -rw-r--r--  1 mbp16  staff      6043 Jul 21 16:25 pima_indian_diabetes_data_part00.csv\n    -rw-r--r--  1 mbp16  staff      6085 Jul 21 16:25 pima_indian_diabetes_data_part01.csv\n    -rw-r--r--  1 mbp16  staff      6039 Jul 21 16:25 pima_indian_diabetes_data_part02.csv\n    -rw-r--r--  1 mbp16  staff      5112 Jul 21 16:25 pima_indian_diabetes_data_part03.csv\n    ```", "```\nimport tensorflow as tf\n```", "```\ndistributed_files_pattern = 'gs://myworkdataset/pima_indian_diabetes_data_part*'\n```", "```\nfilenames = tf.io.gfile.glob(distributed_files_pattern)\n```", "```\n['gs://myworkdataset/pima_indian_diabetes_data_part00.csv',\n```", "```\n 'gs://myworkdataset/pima_indian_diabetes_data_part01.csv',\n```", "```\n 'gs://myworkdataset/pima_indian_diabetes_data_part02.csv',\n```", "```\n 'gs://myworkdataset/pima_indian_diabetes_data_part03.csv']\n```", "```\nCOLUMN_NAMES = ['Pregnancies', 'Glucose', 'BloodPressure', \n```", "```\n                'SkinThickness', 'Insulin', 'BMI', \n```", "```\n                'DiabetesPedigree', 'Age', 'Outcome']\n```", "```\nds = tf.data.experimental.make_csv_dataset(\n```", "```\n      filenames,\n```", "```\n      header = False,\n```", "```\n      column_names = COLUMN_NAMES,\n```", "```\n      batch_size=5, # Intentionally make it small for \n```", "```\n      # convenience.\n```", "```\n      label_name='Outcome',\n```", "```\n      num_epochs=1,\n```", "```\n      ignore_errors=True)\n```", "```\nfor features, target in ds.take(1):\n```", "```\n    print(''Outcome': {}'.format(target))\n```", "```\n    print(''Features:'')\n```", "```\n    for k, v in features.items():\n```", "```\n        print('  {!r:20s}: {}'.format(k, v))\n```", "```\n'Outcome': [1 0 0 0 0]\n```", "```\n'Features:'\n```", "```\n  'Pregnancies'       : [ 7 12  1  0  2]\n```", "```\n  'Glucose'           : [129  88 128  93  96]\n```", "```\n  'BloodPressure'     : [ 68  74  82 100  68]\n```", "```\n  'SkinThickness'     : [49 40 17 39 13]\n```", "```\n  'Insulin'           : [125  54 183  72  49]\n```", "```\n  'BMI'               : [38.5 35.3 27.5 43.4 21.1]\n```", "```\n  'DiabetesPedigree'  : [0.439 0.378 0.115 1.021 0.647]\n```", "```\n  'Age'               : [43 48 22 35 26]\n```", "```\n    import IPython.display as display\n    my_image = 'images-ai-platform-example/maldives/maldives-1.jpg'\n    display.display(display.Image(filename=my_image))\n    ```", "```\n    image_labels = {\n        my_image : 0\n    }\n    image_labels.items()\n    ```", "```\n    dict_items([('images-ai-platform-example/maldives/maldives-1.jpg', 0)])\n    ```", "```\n    def _bytes_feature(value):\n      '''Returns a bytes_list from a string / byte.'''\n      if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a \n        # string from an EagerTensor.\n      return tf.train.Feature(bytes_list=\n      tf.train.BytesList(value=[value]))\n    def _float_feature(value):\n      '''Returns a float_list from a float / double.'''\n      return tf.train.Feature(float_list=\n      tf.train.FloatList(value=[value]))\n    def _int64_feature(value):\n      '''Returns an int64_list from a bool / enum / int / \n      uint.'''\n      return tf.train.Feature(int64_list=\n      tf.train.Int64List(value=[value]))\n    ```", "```\n    image_string = open(my_image, 'rb').read()\n    image_shape = tf.image.decode_jpeg(image_string).shape\n    image_shape\n    ```", "```\n    label = image_labels[my_image]\n    feature_dictionary = {\n          'height': _int64_feature(image_shape[0]),\n          'width': _int64_feature(image_shape[1]),\n          'depth': _int64_feature(image_shape[2]),\n          'label': _int64_feature(label),\n          'image_raw': _bytes_feature(image_string),\n      }\n    ```", "```\n    features_msg = tf.train.Features(feature=feature_dictionary)\n    ```", "```\n    example_msg = tf.train.Example(features=features_msg)\n    ```", "```\n    !mkdir tfrecords-collection\n    ```", "```\n    record_file = 'tfrecords-collection/maldives-1.tfrecord'\n    with tf.io.TFRecordWriter(record_file) as writer:\n        writer.write(example_msg.SerializeToString())\n    ```", "```\n    read_back_tfrecord = tf.data.TFRecordDataset('tfrecords-collection/maldives-1.tfrecord')\n    ```", "```\n    # Create a dictionary describing the features.\n    image_feature_description = {\n        'height': tf.io.FixedLenFeature([], tf.int64),\n        'width': tf.io.FixedLenFeature([], tf.int64),\n        'depth': tf.io.FixedLenFeature([], tf.int64),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n        'image_raw': tf.io.FixedLenFeature([], tf.string),\n    }\n    def _parse_image_function(example_proto):\n      # Parse the input tf.Example proto using the dictionary \n      # above.\n      return tf.io.parse_single_example(example_proto, \n      image_feature_description)\n    parsed_image_dataset = read_back_tfrecord.map(_parse_image_function)\n    ```", "```\n    for image_features in parsed_image_dataset:\n      image_raw = image_features['image_raw'].numpy()\n      display.display(display.Image(data=image_raw))\n    ```", "```\n/home/<user_name>/Documents/<project_name>\n```", "```\n/home/<user_name>/Documents/<project_name>train\n```", "```\n/home/<user_name>/Documents/<project_name>train/<class_1_dir>\n```", "```\n/home/<user_name>/Documents/<project_name>train/<class_2_dir>\n```", "```\n/home/<user_name>/Documents/<project_name>train/<class_n_dir>\n```", "```\n/home/<user_name>/Documents/<project_name>validation\n```", "```\n/home/<user_name>/Documents/<project_name>/validation/<class_1_dir>\n```", "```\n/home/<user_name>/Documents/<project_name>/validation/<class_2_dir>\n```", "```\n/home/<user_name>/Documents/<project_name>/validation/<class_n_dir>\n```", "```\n/home/<user_name>/Documents/<project_name>test\n```", "```\n/home/<user_name>/Documents/<project_name> /test /<class_1_dir>\n```", "```\n/home/<user_name>/Documents/<project_name> test/<class_2_dir>\n```", "```\n/home/<user_name>/Documents/<project_name> /test/<class_n_dir>\n```", "```\n-base_dir\n```", "```\n       -train_dir\n```", "```\n            -class_1_dir \n```", "```\n            -class_2_dir\n```", "```\n            -class_n_dir\n```", "```\n       -validation_dir\n```", "```\n           -class_1_dir\n```", "```\n           -class_2_dir\n```", "```\n           -class_n_dir\n```", "```\n       -test\n```", "```\n          -class_1_dir\n```", "```\n          -class_2_dir\n```", "```\n          -class_n_dir\n```", "```\n-bucket\n```", "```\n -badlands (Badlands national park)\n```", "```\n -kistefos (Kistefos Museum)\n```", "```\n -maldives (Maldives beaches)\n```", "```\n    !mkdir from_gs\n    !gsutil cp -r gs://image-collection from_gs\n    ```", "```\n    import tensorflow as tf\n    import numpy as np\n    import IPython.display as display\n    import pathlib\n    data_dir = pathlib.Path('from_gs/image-collection')\n    data_dir = pathlib.Path(data_dir)\n    CLASS_NAMES = np.array([item.name for item in data_dir.glob('*')])\n    CLASS_NAMES\n    ```", "```\n    array(['kistefos', 'badlands', 'maldives'], dtype='<U8')\n    ```", "```\n    import glob\n    file_name_list = []\n    class_list = []\n    for name in glob.glob('from_gs/image-collection/*/*.jpg', recursive=True): \n      file_name_list.append(name)\n      # label is next to the last substring before the file \n      # name.\n      class_str = name.split('/')[-2]\n      idx_tuple = np.where(CLASS_NAMES == class_str)\n      idx = int(idx_tuple[0]) # first element of the idx \n      # tuple is the index\n      class_list.append(idx)\n    ```", "```\n    image_label_dict = dict(zip(file_name_list, class_list))\n    image_label_dict should look similar to:\n    {'from_gs/image-collection/kistefos/kistefos-1.jpg': 0,\n     'from_gs/image-collection/kistefos/kistefos-3.jpg': 0,\n     'from_gs/image-collection/kistefos/kistefos-2.jpg': 0,\n     'from_gs/image-collection/badlands/badlands-1.jpg': 1,\n     'from_gs/image-collection/badlands/badlands-2.jpg': 1,\n     'from_gs/image-collection/maldives/maldives-2.jpg': 2,\n     'from_gs/image-collection/maldives/maldives-1.jpg': 2}\n    ```", "```\n        def _bytes_feature(value):\n          if not tf.is_tensor(value):\n            value = tf.convert_to_tensor(value)\n          value = value.numpy()\n          bytes_list_msg = tf.train.BytesList(value = [value])\n          coerced_list = tf.train.Feature(bytes_list = \n          bytes_list_msg)\n          return coerced_list\n        ```", "```\n        def _float_feature(value):\n          float_list_msg = tf.train.FloatList(value=[value])\n          coerced_list = tf.train.Feature(float_list = \n          float_list_msg)\n          return coerced_list\n        ```", "```\n    def _int64_feature(value):\n      int64_list_msg = tf.train.Int64List(value=[value])\n      coerced_list = tf.train.Feature(int64_list = \n      int64_list_msg)\n      return coerced_list\n    ```", "```\n    def image_example(image_str, label):\n      image_shape = tf.image.decode_jpeg(image_string).shape\n      feature = {\n          'height': _int64_feature(image_shape[0]),\n          'width': _int64_feature(image_shape[1]),\n          'depth': _int64_feature(image_shape[2]),\n          'label': _int64_feature(label),\n          'image_raw': _bytes_feature(image_string),\n      }\n      features_msg = tf.train.Features(feature=feature)\n      example_msg = tf.train.Example(features=features_msg)\n      return example_msg\n    ```", "```\n    record_file = 'image-collection.tfrecords'\n    with tf.io.TFRecordWriter(record_file) as writer:\n      for filename, label in image_image_label_dict.items():\n        image_string = open(filename, 'rb').read()\n        tf_example = image_example(image_string, label)\n        writer.write(tf_example.SerializeToString())\n    ```", "```\n    image_collection_dataset = tf.data.TFRecordDataset('image-collection.tfrecords')\n    ```", "```\n    feature_specs = {\n        'height': tf.io.FixedLenFeature([], tf.int64),\n        'width': tf.io.FixedLenFeature([], tf.int64),\n        'depth': tf.io.FixedLenFeature([], tf.int64),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n        'image_raw': tf.io.FixedLenFeature([], tf.string),\n    }\n    ```", "```\n    def parse_image(example):\n      return tf.io.parse_single_example(example, \n      feature_specs)\n    parsed_image_dataset = image_collection_dataset.map(parse_image)\n    ```", "```\n    import IPython.display as display\n    for image_features in parsed_image_dataset:\n      image_raw = image_features['image_raw'].numpy()\n      display.display(display.Image(data=image_raw))\n    ```"]