<html><head></head><body>
		<div>
			<div id="_idContainer083" class="Content">
			</div>
		</div>
		<div id="_idContainer084" class="Content">
			<h1 id="_idParaDest-98">4. <a id="_idTextAnchor100"/>Productization</h1>
		</div>
		<div id="_idContainer091" class="Content">
			<p class="callout-heading"><a id="_idTextAnchor101"/><a id="_idTextAnchor102"/>Overview</p>
			<p class="callout">In this chapter, you will handle new data and create a model that is able to learn continuously from the patterns it is shown and help make better predictions. We will use a web application as an example to show how to deploy deep learning models not only because of the simplicity and prevalence of web apps, but also the different possibilities they provide, such as getting predictions on mobile using a web browser and making REST APIs for users.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor103"/>Introduction</h1>
			<p>This chapter focuses on how to <em class="italic">productize</em> a deep learning model. We use the word productize to define the creation of a software product from a deep learning model that can be used by other people and applications.</p>
			<p>We are interested in models that use new data as and when it becomes available, continuously learn patterns from new data, and consequently, make better predictions. In this chapter, we will study two strategies to deal with new data: one that retrains an existing model, and another that creates a completely new model. Then, we implement the latter strategy in our Bitcoin price prediction model so that it can continuously predict new Bitcoin prices.</p>
			<p>By the end of this chapter, we will be able to deploy a working web application (with a functioning HTTP API) and modify it to our heart's content.</p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor104"/>Handling New Data</h1>
			<p>Models can be trained once using a set of data and can then be used to make predictions. Such static models can be very useful, but it is often the case that we want our model to continuously learn from new data—and to continuously get better as it does so.</p>
			<p>In this section, we will discuss two strategies of handling new data and see how to implement them in Python.</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor105"/>Separating Data and Model</h2>
			<p>When building a deep learning application, the two most important areas are data and model. From an architectural point of view, it is recommended that these two areas be kept separate. We believe that is a good suggestion because each of these areas includes functions inherently separate from each other. Data is often required to be collected, cleaned, organized, and normalized, whereas models need to be trained, evaluated, and able to make predictions. </p>
			<p>Following that suggestion, we will be using two different code bases to help us build our web application: the Yahoo Finance API and <strong class="source-inline">Model()</strong>:</p>
			<ul>
				<li>The Yahoo Finance API: The API can be installed by using <strong class="source-inline">pip</strong> with the following command:<p class="source-code">pip install yfinance</p><p>After installation, we will be able to access all the historical data related to the finance domain. </p></li>
				<li><strong class="source-inline">Model()</strong>: This class implements all the code we have written so far into a single class. It provides facilities for interacting with our previously trained models and allows us to make predictions using de-normalized data, which is much easier to understand. The <strong class="source-inline">Model()</strong> class is our model component.</li>
			</ul>
			<p>These two code bases are used extensively throughout our example application and define the data and model components.</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor106"/>The Data Component</h2>
			<p>The Yahoo Finance API helps to retrieve and parse the historical data of stocks. It contains one relevant method, <strong class="source-inline">history()</strong>, which is detailed in the following code:</p>
			<p class="source-code">import yfinance as yf</p>
			<p class="source-code">ticker =  yf.Ticker("BTC-USD")</p>
			<p class="source-code">historic_data = ticker.history(period='max')</p>
			<p>This <strong class="source-inline">history()</strong> method collects data from the Yahoo Finance website, parses it, and returns a pandas DataFrame that is ready to be used by the <strong class="source-inline">Model()</strong> class.</p>
			<p>The Yahoo Finance API uses the parameter ticker to determine what cryptocurrency to collect. The Yahoo Finance API has many other cryptocurrencies available, including popular ones such as Ethereum and Bitcoin Cash. Using the <strong class="source-inline">ticker</strong> parameter, you can change the cryptocurrency and train a different model apart from the Bitcoin model created in this book.</p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor107"/>The Model Component</h2>
			<p>The <strong class="source-inline">Model()</strong> class is where we implement the application's model component. The <strong class="source-inline">Model()</strong> class contains five methods that implement all the different modeling topics from this book. They are the following: </p>
			<ul>
				<li><strong class="source-inline">build()</strong>: This method builds an LSTM model using TensorFlow. This method works as a simple wrapper for a manually created model.</li>
				<li><strong class="source-inline">train()</strong>: This method trains the model using data that the class was instantiated with.</li>
				<li><strong class="source-inline">evaluate()</strong>: This method evaluates the model using a set of loss functions.</li>
				<li><strong class="source-inline">save()</strong>: This method saves the model locally as a file.</li>
				<li><strong class="source-inline">predict()</strong>: This method makes and returns predictions based on an input sequence of observations ordered by week.</li>
			</ul>
			<p>We will use these methods throughout this chapter to work, train, evaluate, and issue predictions with our model. The <strong class="source-inline">Model()</strong> class is an example of how to wrap essential TensorFlow functions into a web application. The preceding methods can be implemented almost exactly as in previous chapters, but with enhanced interfaces. For example, the <strong class="source-inline">train()</strong> method implemented in the following code trains a model available in <strong class="source-inline">self.model</strong> using data from <strong class="source-inline">self.X</strong> and <strong class="source-inline">self.Y</strong>:</p>
			<p class="source-code">def train(self, data=None, epochs=300, verbose=0, batch_size=1): </p>
			<p class="source-code">    self.train_history = self.model.fit(x=self.X, y=self.Y, \</p>
			<p class="source-code">                                        batch_size=batch_size, \</p>
			<p class="source-code">                                        epochs=epochs, \</p>
			<p class="source-code">                                        verbose=verbose, \</p>
			<p class="source-code">                                        shuffle=False)</p>
			<p class="source-code">    self.last_trained = datetime.now()\</p>
			<p class="source-code">    .strftime('%Y-%m-%d %H:%M:%S') </p>
			<p class="source-code">    return self.train_history</p>
			<p>The general idea is that each of the processes from the Keras workflow (build or design, train, evaluate, and predict) can easily be turned into distinct parts of a program. In our case, we have made them into methods that can be invoked from the <strong class="source-inline">Model()</strong> class. This organizes our program and provides a series of constraints (such as on the model architecture or certain API parameters), which help us deploy our model in a stable environment.</p>
			<p>In the following sections, we will explore common strategies for dealing with new data.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor108"/>Dealing with New Data</h2>
			<p>The core idea of machine learning models—neural networks included—is that they can learn patterns from data. Imagine that a model was trained with a certain dataset and it is now issuing predictions. Now, imagine that new data is available. There are different strategies you can employ so that a model can take advantage of the newly available data to learn new patterns and improve its predictions. In this section, we will discuss two strategies:</p>
			<ul>
				<li>Retraining an old model</li>
				<li>Training a new model</li>
			</ul>
			<h3 id="_idParaDest-105"><a id="_idTextAnchor109"/>Retraining an Old Model</h3>
			<p>In this strategy, we retrain an existing model with new data. Using this strategy, you can continuously adjust the model parameters to adapt to new phenomena. However, data used in later training periods might be significantly different from earlier data. Such differences might cause significant changes to the model parameters, such as making it learn new patterns and forget old patterns. This phenomenon is generally referred to as <strong class="bold">catastrophic forgetting</strong>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Catastrophic forgetting is a common phenomenon affecting neural networks. Deep learning researchers have been trying to tackle this problem for many years. DeepMind, a Google-owned deep learning research group from the United Kingdom, has made notable advancements in finding a solution. The article, <em class="italic">Overcoming</em> <em class="italic">Catastrophic Forgetting in Neural Networks</em>, <em class="italic">James Kirkpatrick</em>, <em class="italic">et. al</em>. is a good reference for such work, and is available at <a href="https://arxiv.org/pdf/1612.00796.pdf">https://arxiv.org/pdf/1612.00796.pdf</a>.</p>
			<p>The interface used for training (<strong class="source-inline">model.fit()</strong>) for the first time can be used for training with new data as well. The following snippet loads the data and helps to train a model specifying the epochs and batch size:</p>
			<p class="source-code">X_train_new, Y_train_new = load_new_data()</p>
			<p class="source-code">model.fit(x=X_train_new, y=Y_train_new, batch_size=1, \</p>
			<p class="source-code">          epochs=100, verbose=0)</p>
			<p>In TensorFlow, when models are trained, the model's state is saved as weights on the disk. When you use the <strong class="source-inline">model.save()</strong> method, that state is also saved. And when you invoke the <strong class="source-inline">model.fit()</strong> method, the model is retrained with the new dataset, using the previous state as a starting point.</p>
			<p>In typical Keras models, this technique can be used without further issues. However, when working with LSTM models, this technique has one key limitation: the shape of both train and validation data must be the same. For example, in <em class="italic">Chapter 3</em>, <em class="italic">Real-World Deep Learning with TensorFlow and Keras: Evaluating the Bitcoin Model</em>, our LSTM model (<strong class="source-inline">bitcoin_lstm_v0</strong>) uses 186 weeks to predict one week into the future. If we attempt to retrain the model with 187 weeks to predict the coming week, the model raises an exception with information regarding the incorrect shape of data.</p>
			<p>One way of dealing with this is to arrange data in the format expected by the model. For example, to make predictions based on a year's data (52 weeks), we would need to configure a model to predict a future week using 40 weeks. In this case, we first train the model with the first 40 weeks of 2019, then continue to retrain it over the following weeks until we reach week 51. We use the <strong class="source-inline">Model()</strong> class to implement a retraining technique in the following code:</p>
			<p class="source-code">M = Model(data=model_data[0*7:7*40 + 7], variable='close', \</p>
			<p class="source-code">          predicted_period_size=7)</p>
			<p class="source-code">M.build()</p>
			<p class="source-code">M.train()</p>
			<p class="source-code">for i in range(41, 52):</p>
			<p class="source-code">    j = i - 40</p>
			<p class="source-code">    M.train(model_data.loc[j*7:7*i + 7])</p>
			<p>This technique tends to be fast to train and tends to work well with series that are large. The next technique is easier to implement and works well in smaller series.</p>
			<h3 id="_idParaDest-106"><a id="_idTextAnchor110"/>Training a New Model</h3>
			<p>Another strategy is to create and train a new model every time new data is available. This approach tends to reduce catastrophic forgetting, but training time increases as data increases. Its implementation is quite simple.</p>
			<p>Using the Bitcoin model as an example, let's now assume that we have old data for 49 weeks of 2019, and that after a week, new data is available. We represent this with the <strong class="source-inline">old_data</strong> and <strong class="source-inline">new_data</strong> variables in the following snippet, in which we implement a strategy for training a new model when new data is available:</p>
			<p class="source-code">old_data = model_data[0*7:7*48 + 7]</p>
			<p class="source-code">new_data = model_data[0*7:7*49 + 7]</p>
			<p class="source-code">M = Model(data=old_data,\</p>
			<p class="source-code">          variable='close', predicted_period_size=7)</p>
			<p class="source-code">M.build()</p>
			<p class="source-code">M.train()</p>
			<p class="source-code">M = Model(data=new_data,\</p>
			<p class="source-code">          variable='close', predicted_period_size=7)</p>
			<p class="source-code">M.build()</p>
			<p class="source-code">M.train()</p>
			<p>This approach is very simple to implement and tends to work well for small datasets. This will be the preferred solution for our Bitcoin price-predictions application.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor111"/>Exercise 4.01: Retraining a Model Dynamically</h2>
			<p>In this exercise, you have to retrain a model to make it dynamic. Whenever new data is loaded, it should be able to make predictions accordingly. Here are the steps to follow:</p>
			<p>Start by importing <strong class="source-inline">cryptonic</strong>. Cryptonic is a simple software application developed for this book that implements all the steps up to this section using Python classes and modules. Consider Cryptonic as a template to be used to create applications. Cryptonic, provided as a Python module for this exercise, can be found at the following GitHub link: <a href="https://packt.live/325WdZQ">https://packt.live/325WdZQ</a>.</p>
			<ol>
				<li>First, we will start a Jupyter Notebook instance, and then we will load the <strong class="source-inline">cryptonic</strong> package.</li>
				<li>Using your Terminal, navigate to the <strong class="source-inline">Chapter04/Exercise4.01</strong> directory and execute the following code to start a Jupyter Notebook instance:<p class="source-code">$ jupyter-lab</p><p>The server will automatically open in your browser, then open the Jupyter Notebook named <strong class="source-inline">Exercise4.01_Re_training_a_model_dynamically.ipynb</strong>.</p></li>
				<li>Now, we will import classes from the <strong class="source-inline">cryptonic</strong> package: <strong class="source-inline">Model()</strong> and the Yahoo Finance API. These classes facilitate the process of manipulating our model.</li>
				<li>In the Jupyter Notebook instance, navigate to the header <strong class="source-inline">Fetching Real-Time Data</strong>. We will now be fetching updated historical data from Yahoo Finance by calling the <strong class="source-inline">history()</strong> method:<p class="source-code">import yfinance as yf</p><p class="source-code">ticker =  yf.Ticker("BTC-USD")</p><p class="source-code">historic_data = ticker.history(period='max')</p><p>The <strong class="source-inline">historic_data</strong> variable is now populated with a pandas DataFrame that contains historic data of Bitcoin rates up to the time of running this code. This is great and makes it easier to retrain our model when more data is available. </p></li>
				<li>You can view the first three rows of data stored in <strong class="source-inline">historic_data</strong> using the following command:<p class="source-code">historic_data.head(3)</p><p>You can then view this data stored in <strong class="source-inline">historic_data</strong>:</p><div id="_idContainer085" class="IMG---Figure"><img src="image/B15911_04_01.jpg" alt="Figure 4.1: Output displaying the head of the data&#13;&#10;"/></div><p class="figure-caption">Figure 4.1: Output displaying the head of the data</p><p>The data contains practically the same variables from the Bitcoin dataset we used. However, much of the data comes from an earlier period, 2017 to 2019.</p></li>
				<li>Using the pandas API, filter the data for only the dates available in 2019, and store them in <strong class="source-inline">model_data</strong>. You should be able to do this by using the date variable as the filtering index. Make sure the data is filtered before you continue:<p class="source-code">start_date = '01-01-2019'</p><p class="source-code">end_date = '31-12-2019'</p><p class="source-code">mask = ((historic_data['date'] \</p><p class="source-code">         &gt;= start_date) &amp; (historic_data['date'] \</p><p class="source-code">         &lt;= end_date))</p><p class="source-code">model_data = historic_data[mask]</p><p>Run <strong class="source-inline">model_data</strong> in next cell and the output model can be seen as follows:</p><div id="_idContainer086" class="IMG---Figure"><img src="image/B15911_04_02.jpg" alt="Figure 4.2: The model_data variable showing historical data&#13;&#10;"/></div><p class="figure-caption">Figure 4.2: The model_data variable showing historical data</p><p>The <strong class="source-inline">Model()</strong> class compiles all the code we have written so far in all of our activities. We will use that class to build, train, and evaluate our model in this activity.</p></li>
				<li>We will now use the filtered data to train the model:<p class="source-code">M = Model(data=model_data, \</p><p class="source-code">          variable='close', predicted_period_size=7)</p><p class="source-code">M.build()</p><p class="source-code">M.train()</p><p class="source-code">M.predict(denormalized=True)</p></li>
				<li>Run the following command to see the trained model:<p class="source-code">M.train(epochs=100, verbose=1)</p><p>The trained model is shown in the following screenshot:</p><div id="_idContainer087" class="IMG---Figure"><img src="image/B15911_04_03.jpg" alt="Figure 4.3: The output showing our trained model&#13;&#10;"/></div><p class="figure-caption">Figure 4.3: The output showing our trained model</p><p>The preceding steps showcase the complete workflow when using the <strong class="source-inline">Model()</strong> class to train a model.</p><p class="callout-heading">Note</p><p class="callout">For the complete code, use the <strong class="source-inline">Chapter04/Exercise4.01</strong> folder.</p></li>
				<li>Next, we'll focus on retraining our model every time more data is available. This readjusts the weights of the network to new data.<p>In order to do this, we have configured our model to predict a week using 40 weeks. We now want to use the remaining 11 full weeks to create overlapping periods of 40 weeks. These include one of those 11 weeks at a time, and retrain the model for every one of those periods.</p></li>
				<li>Navigate to the <strong class="source-inline">Re-Train Old Model</strong> header in the Jupyter Notebook. Now, complete the <strong class="source-inline">range</strong> function and the <strong class="source-inline">model_data</strong> filtering parameters using an index to split the data into overlapping groups of seven days. Then, retrain our model and collect the results:<p class="source-code">results = []</p><p class="source-code">for i in range(A, B): </p><p class="source-code">    M.train(model_data[C:D])</p><p class="source-code">    results.append(M.evaluate())</p><p>The <strong class="source-inline">A</strong>, <strong class="source-inline">B</strong>, <strong class="source-inline">C</strong>, and <strong class="source-inline">D</strong> variables are placeholders. Use integers to create overlapping groups of seven days in which the overlap is of one day.</p><p>Replacing these placeholders with weeks, we run the loop as follows:</p><p class="source-code">results = []</p><p class="source-code">for i in range(41, 52):</p><p class="source-code">    j = i-40</p><p class="source-code">    print("Training model {0} for week {1}".format(j,i))</p><p class="source-code">    M.train(model_data.loc[j*7:7*i+7])</p><p class="source-code">    results.append(M.evaluate())</p><p>Here's the output showing the results of this loop:</p><p class="source-code">Training model 1 for week 41</p><p class="source-code">Training model 2 for week 42</p><p class="source-code">Training model 3 for week 43</p><p class="source-code">Training model 4 for week 44</p><p class="source-code">Training model 5 for week 45</p><p class="source-code">Training model 6 for week 46</p><p class="source-code">Training model 7 for week 47</p><p class="source-code">Training model 8 for week 48</p><p class="source-code">Training model 9 for week 49</p><p class="source-code">Training model 10 for week 50</p><p class="source-code">Training model 11 for week 51</p></li>
				<li>After you have retrained your model, go ahead and invoke the <strong class="source-inline">M.predict(denormalized=True)</strong> function and examine the results:<p class="source-code">array([7187.145 , 7143.798 , 7113.7324, 7173.985 , 7200.346 ,</p><p class="source-code">       7300.2896, 7175.3203], dtype=float32)</p></li>
				<li>Next, we'll focus on creating and training a new model every time new data is available. In order to do this, we now assume that we have old data for 49 weeks of 2019, and after a week, we now have new data. We represent this with the <strong class="source-inline">old_data</strong> and <strong class="source-inline">new_data</strong> variables.</li>
				<li>Navigate to the <strong class="source-inline">New Data New Model</strong> header and split the data between the <strong class="source-inline">old_data</strong> and <strong class="source-inline">new_data</strong> variables:<p class="source-code">old_data = model_data[0*7:7*48 + 7]</p><p class="source-code">new_data = model_data[0*7:7*49 + 7]</p></li>
				<li>Then, train the model with <strong class="source-inline">old_data</strong> first:<p class="source-code">M = Model(data=old_data,\</p><p class="source-code">          variable='close', predicted_period_size=7)</p><p class="source-code">M.build()</p><p class="source-code">M.train()</p><p>We now have all the pieces that we need in order to train our model dynamically.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2AQb3bE">https://packt.live/2AQb3bE</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/322KuLl">https://packt.live/322KuLl</a>. You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>In the next section, we will deploy our model as a web application, making its predictions available in the browser via an HTTP API.</p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor112"/>Deploying a Model as a Web Application</h2>
			<p>In this section, we will deploy our model as a web application. We will use the Cryptonic web application to deploy our model, exploring its architecture so that we can make modifications in the future. The intention is to have you use this application as a starter for more complex applications—a starter that is fully working and can be expanded as you see fit.</p>
			<p>Aside from familiarity with Python, this topic assumes familiarity with creating web applications. Specifically, we assume that you have some knowledge of web servers, routing, the HTTP protocol, and caching. You will be able to locally deploy the demonstrated Cryptonic application without extensive knowledge of these web servers, the HTTP protocol, and caching, but learning these topics will make any future development much easier.</p>
			<p>Finally, Docker is used to deploy our web applications, so basic knowledge of that technology is also useful.</p>
			<p>Before we continue, make sure that you have the following applications installed and available on your computer:</p>
			<ul>
				<li>Docker (Community Edition) 17.12.0-ce or later</li>
				<li>Docker Compose (<strong class="source-inline">docker-compose</strong>) 1.18.0 or later</li>
			</ul>
			<p>Both these components can be downloaded and installed on all major systems from <a href="http://docker.com/">http://docker.com/</a>. These are essential for completing this activity. Make sure these are available in your system before moving forward.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor113"/>Application Architecture and Technologies</h2>
			<p>In order to deploy our web applications, we will use the tools and technologies described in <em class="italic">Figure 4.4</em>. Flask is key because it helps us create an HTTP interface for our model, allowing us to access an HTTP endpoint (such as <strong class="source-inline">/predict</strong>) and receive data back in a universal format. The other components are used because they are popular choices when developing web applications:</p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B15911_04_04.jpg" alt="Figure 4.4: Tools and technologies used for deploying a deep learning web application&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4: Tools and technologies used for deploying a deep learning web application</p>
			<p>These components fit together as shown in the following diagram:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B15911_04_05.jpg" alt="Figure 4.5: System architecture for the web application built in this project&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.5: System architecture for the web application built in this project</p>
			<p>A user visits the web application using their browser. That traffic is then routed by Nginx to the Docker container containing the Flask application (by default, running on port <strong class="source-inline">5000</strong>). The Flask application has instantiated our Bitcoin model at startup. If a model has been given, it uses that model without training; if not, it creates a new model and trains it from scratch using data from Yahoo Finance.</p>
			<p>After having a model ready, the application verifies if the request has been cached on Redis; if yes, it returns the cached data. If no cache exists, then it will go ahead and issue predictions, which are rendered in the UI.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor114"/>Exercise 4.02: Deploying and Using Cryptonic</h2>
			<p>Cryptonic is developed as a dockerized application. In Docker terms, this means that the application can be built as a Docker image and then deployed as a Docker container in either a development or a production environment. </p>
			<p>In this exercise, we will see how to use Docker and Cryptonic to deploy the application. Before you begin, download Docker for Desktop from <a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a> Make sure that this application is running in the background before beginning the exercise.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The complete code for this exercise can be found at <a href="https://packt.live/2AM5mLP">https://packt.live/2AM5mLP</a>.</p>
			<ol>
				<li value="1">Docker uses files called <strong class="source-inline">Dockerfiles</strong> to describe the rules for how to build an image and what happens when that image is deployed as a container. Cryptonic's Dockerfile is available in the following code:<p class="callout-heading">Note</p><p class="callout">The triple-quotes ( <strong class="source-inline">"""</strong> ) shown in the code snippet below are used to denote the start and end points of a multi-line code comment. Comments are added into code to help explain specific bits of logic.</p><p class="source-code">FROM python:3.6 </p><p class="source-code">ENV TZ=America/New_York</p><p class="source-code">"""</p><p class="source-code">Setting up timezone to EST (New York)</p><p class="source-code">Change this to whichever timezone your data is configured to use.</p><p class="source-code">"""</p><p class="source-code">RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone</p><p class="source-code">COPY . /cryptonic</p><p class="source-code">WORKDIR "/cryptonic"</p><p class="source-code">RUN pip install -r requirements.txt</p><p class="source-code">EXPOSE 5000</p><p class="source-code">CMD ["python", "run.py"]</p></li>
				<li>A Dockerfile can be used to build a Docker image with the following command:<p class="source-code">$ docker build --tag cryptonic:latest</p><p>This command will make the <strong class="source-inline">cryptonic:latest</strong> image available to be deployed as a container. The building process can be repeated on a production server, or the image can be directly deployed and then run as a container.</p></li>
				<li>After an image has been built and is available, you can run the Cryptonic application by using the <strong class="source-inline">docker run</strong> command, as shown in the following code:<p class="source-code">$ docker run --publish 5000:5000 \</p><p class="source-code">--detach cryptonic:latest</p><p>The <strong class="source-inline">--publish</strong> flag binds port <strong class="source-inline">5000</strong> on localhost to port <strong class="source-inline">5000</strong> on the Docker container, and <strong class="source-inline">--detach</strong> runs the container as a daemon in the background.</p><p>In case you have trained a different model and would like to use that instead of training a new model, you can alter the <strong class="source-inline">MODEL_NAME</strong> environment variable on the <strong class="source-inline">docker-compose.yml</strong>. That variable should contain the filename of the model you have trained and want served (for example, <strong class="source-inline">bitcoin_lstm_v1_trained.h5</strong>); it should also be a Keras model. If you do that, make sure to also mount a local directory into the <strong class="source-inline">/models</strong> folder. The directory that you decide to mount must contain your model file.</p><p>The Cryptonic application also includes several environment variables that you may find useful when deploying your own model:</p><p><strong class="source-inline">MODEL_NAME</strong>: Allows us to provide a trained model to be used by the application.</p><p><strong class="source-inline">BITCOIN_START_DATE</strong>: Determines which day to use as the starting day for the Bitcoin series. Bitcoin prices have a lot more variance in recent years than earlier ones. This parameter filters the data to only years of interest. The default is <strong class="source-inline">January 1, 2017</strong>.</p><p><strong class="source-inline">PERIOD_SIZE</strong>: Sets the period size in terms of days. The default is <strong class="source-inline">7</strong>.</p><p><strong class="source-inline">EPOCHS</strong>: Configures the number of epochs that the model trains on every run. The default is <strong class="source-inline">300</strong>.</p><p>These variables can be configured in the <strong class="source-inline">docker-compose.yml</strong> file. A part of this file is shown in the following code snippet:</p><p class="source-code">version: "3" </p><p class="source-code">   services:</p><p class="source-code">      cache:</p><p class="source-code">         image: cryptonic-cache:latest</p><p class="source-code">         build:</p><p class="source-code">            context: ./cryptonic-cache</p><p class="source-code">            dockerfile: ./Dockerfile</p><p class="source-code">         volumes:</p><p class="source-code">            - $PWD/cache_data:/data</p><p class="source-code">         networks:</p><p class="source-code">            - cryptonic</p><p class="source-code">      cryptonic:</p><p class="source-code">         image: cryptonic:latest</p><p class="source-code">         build:</p><p class="source-code">            context: .</p><p class="source-code">            dockerfile: ./Dockerfile</p><p class="source-code">         ports:</p><p class="source-code">            - "5000:5000"</p><p class="source-code">         environment:</p><p class="source-code">            - BITCOIN_START_DATE=2019-01-01</p><p class="source-code">            - EPOCH=50</p><p class="source-code">            - PERIOD_SIZE=7</p></li>
				<li>The easiest way to deploy Cryptonic is to use the <strong class="source-inline">docker-compose.yml</strong> file in the repository (<a href="https://packt.live/2AM5mLP">https://packt.live/2AM5mLP</a>).<p>This file contains all the specifications necessary for the application to run, including instructions on how to connect with the Redis cache and what environment variables to use. After navigating to the location of the <strong class="source-inline">docker-compose.yml</strong> file, Cryptonic can then be started with the <strong class="source-inline">docker-compose up</strong> command, as shown in the following code:</p><p class="source-code">$ docker-compose up -d</p><p>The <strong class="source-inline">-d</strong> flag executes the application in the background.</p></li>
				<li>After deployment, Cryptonic can be accessed on port <strong class="source-inline">5000</strong> via a web browser. The application has an HTTP API that makes predictions when invoked. The API has the endpoint <strong class="source-inline">/predict</strong>, which returns a JSON object containing the de-normalized Bitcoin price prediction for a week into the future. Here's a snippet showing an example JSON output from the <strong class="source-inline">/predict</strong> endpoint:<p class="source-code">{</p><p class="source-code">  message: "API for making predictions.",</p><p class="source-code">  period_length: 7,</p><p class="source-code">    result: [ 15847.7,</p><p class="source-code">      15289.36,</p><p class="source-code">      17879.07,</p><p class="source-code">      …</p><p class="source-code">      17877.23,</p><p class="source-code">      17773.08</p><p class="source-code">    ],</p><p class="source-code">    success: true,</p><p class="source-code">    7</p><p class="source-code">}</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2ZZlZMm">https://packt.live/2ZZlZMm</a>.</p><p class="callout">This section does not currently have an online interactive example, and will need to be run locally.</p></li>
			</ol>
			<p>The application can now be deployed on a remote server and you can then use it to continuously predict Bitcoin prices. You'll be deploying an application in the activity that follows.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor115"/>Activity 4.01: Deploying a Deep Learning Application</h2>
			<p>In this section, based on the concepts explained up to now, try deploying the model as a local web application. You will need to follow these steps:</p>
			<ol>
				<li value="1">Navigate to the <strong class="source-inline">cryptonic</strong> directory.</li>
				<li>Build the Docker images for the required components.</li>
				<li>Change the necessary parameters in <strong class="source-inline">docker-compose.yml</strong>.</li>
				<li>Deploy the application using Docker on the localhost.</li>
			</ol>
			<p>The expected output would be as follows:</p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B15911_04_06.jpg" alt="Figure 4.6: Expected output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.6: Expected output</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found on page 150. </p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor116"/>Summary</h1>
			<p>This lesson concludes our journey into creating a deep learning model and deploying it as a web application. Our very last steps included deploying a model that predicts Bitcoin prices built using Keras and the TensorFlow engine. We finished our work by packaging the application as a Docker container and deploying it so that others can consume the predictions of our model, as well as other applications, via its API.</p>
			<p>Aside from that work, you have also learned that there is much that can be improved. Our Bitcoin model is only an example of what a model can do (particularly LSTMs). The challenge now is twofold: how can you make that model perform better as time passes? And what features can you add to your web application to make your model more accessible? With the concepts you've learned in this book, you will be able to develop models and keep enhancing them to make accurate predictions.</p>
		</div>
		<div>
			<div id="_idContainer092" class="Content">
			</div>
		</div>
	</body></html>