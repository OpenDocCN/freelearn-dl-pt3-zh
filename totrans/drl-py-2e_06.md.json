["```\ngit clone https://github.com/JKCooper2/gym-bandits \n```", "```\ncd gym-bandits\npip install -e . \n```", "```\nimport gym_bandits\nimport gym \n```", "```\nenv = gym.make(\"BanditTwoArmedHighLowFixed-v0\") \n```", "```\nprint(env.action_space.n) \n```", "```\n2 \n```", "```\nprint(env.p_dist) \n```", "```\n[0.8, 0.2] \n```", "```\nimport gym\nimport gym_bandits\nimport numpy as np \n```", "```\nenv = gym.make(\"BanditTwoArmedHighLowFixed-v0\") \n```", "```\nprint(env.p_dist) \n```", "```\n[0.8, 0.2] \n```", "```\ncount = np.zeros(2) \n```", "```\nsum_rewards = np.zeros(2) \n```", "```\nQ = np.zeros(2) \n```", "```\nnum_rounds = 100 \n```", "```\ndef epsilon_greedy(epsilon):\n\n    if np.random.uniform(0,1) < epsilon:\n        return env.action_space.sample()\n    else:\n        return np.argmax(Q) \n```", "```\nfor i in range(num_rounds): \n```", "```\n arm = epsilon_greedy(epsilon=0.5) \n```", "```\n next_state, reward, done, info = env.step(arm) \n```", "```\n count[arm] += 1 \n```", "```\n sum_rewards[arm]+=reward \n```", "```\n Q[arm] = sum_rewards[arm]/count[arm] \n```", "```\nprint(Q) \n```", "```\n[0.83783784 0.34615385] \n```", "```\nprint('The optimal arm is arm {}'.format(np.argmax(Q)+1)) \n```", "```\nThe optimal arm is arm 1 \n```", "```\nimport gym\nimport gym_bandits\nimport numpy as np \n```", "```\nenv = gym.make(\"BanditTwoArmedHighLowFixed-v0\") \n```", "```\ncount = np.zeros(2) \n```", "```\nsum_rewards = np.zeros(2) \n```", "```\nQ = np.zeros(2) \n```", "```\nnum_rounds = 100 \n```", "```\ndef softmax(T): \n```", "```\n denom = sum([np.exp(i/T) for i in Q])\n    probs = [np.exp(i/T)/denom for i in Q] \n```", "```\n arm = np.random.choice(env.action_space.n, p=probs)\n\n    return arm \n```", "```\nT = 50 \n```", "```\nfor i in range(num_rounds): \n```", "```\n arm = softmax(T) \n```", "```\n next_state, reward, done, info = env.step(arm) \n```", "```\n count[arm] += 1 \n```", "```\n sum_rewards[arm]+=reward \n```", "```\n Q[arm] = sum_rewards[arm]/count[arm] \n```", "```\n T = T*0.99 \n```", "```\nprint(Q) \n```", "```\n[0.77700348 0.1971831 ] \n```", "```\nprint('The optimal arm is arm {}'.format(np.argmax(Q)+1)) \n```", "```\nThe optimal arm is arm 1 \n```", "```\nimport gym\nimport gym_bandits\nimport numpy as np \n```", "```\nenv = gym.make(\"BanditTwoArmedHighLowFixed-v0\") \n```", "```\ncount = np.zeros(2) \n```", "```\nsum_rewards = np.zeros(2) \n```", "```\nQ = np.zeros(2) \n```", "```\nnum_rounds = 100 \n```", "```\ndef UCB(i): \n```", "```\n ucb = np.zeros(2) \n```", "```\n if i < 2:\n        return i \n```", "```\n else:\n        for arm in range(2):\n            ucb[arm] = Q[arm] + np.sqrt((2*np.log(sum(count))) / count[arm])\n        return (np.argmax(ucb)) \n```", "```\nfor i in range(num_rounds): \n```", "```\n arm = UCB(i) \n```", "```\n next_state, reward, done, info = env.step(arm) \n```", "```\n count[arm] += 1 \n```", "```\n sum_rewards[arm]+=reward \n```", "```\n Q[arm] = sum_rewards[arm]/count[arm] \n```", "```\nprint('The optimal arm is arm {}'.format(np.argmax(Q)+1)) \n```", "```\nThe optimal arm is arm 1 \n```", "```\nimport gym\nimport gym_bandits\nimport numpy as np \n```", "```\nenv = gym.make(\"BanditTwoArmedHighLowFixed-v0\") \n```", "```\ncount = np.zeros(2) \n```", "```\nsum_rewards = np.zeros(2) \n```", "```\nQ = np.zeros(2) \n```", "```\nalpha = np.ones(2) \n```", "```\nbeta = np.ones(2) \n```", "```\nnum_rounds = 100 \n```", "```\ndef thompson_sampling(alpha,beta):\n\n    samples = [np.random.beta(alpha[i]+1,beta[i]+1) for i in range(2)]\n    return np.argmax(samples) \n```", "```\nfor i in range(num_rounds): \n```", "```\n arm = thompson_sampling(alpha,beta) \n```", "```\n next_state, reward, done, info = env.step(arm) \n```", "```\n count[arm] += 1 \n```", "```\n sum_rewards[arm]+=reward \n```", "```\n Q[arm] = sum_rewards[arm]/count[arm] \n```", "```\n if reward==1:\n        alpha[arm] = alpha[arm] + 1\n    else:\n        beta[arm] = beta[arm] + 1 \n```", "```\nprint('The optimal arm is arm {}'.format(np.argmax(Q)+1)) \n```", "```\nThe optimal arm is arm 1 \n```", "```\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot') \n```", "```\ndf = pd.DataFrame()\nfor i in range(5):\n    df['Banner_type_'+str(i)] = np.random.randint(0,2,100000) \n```", "```\ndf.head() \n```", "```\nnum_iterations = 100000 \n```", "```\nnum_banner = 5 \n```", "```\ncount = np.zeros(num_banner) \n```", "```\nsum_rewards = np.zeros(num_banner) \n```", "```\nQ = np.zeros(num_banner) \n```", "```\nbanner_selected = [] \n```", "```\ndef epsilon_greedy_policy(epsilon):\n\n    if np.random.uniform(0,1) < epsilon:\n        return np.random.choice(num_banner)\n    else:\n        return np.argmax(Q) \n```", "```\nfor i in range(num_iterations): \n```", "```\n banner = epsilon_greedy_policy(0.5) \n```", "```\n reward = df.values[i, banner] \n```", "```\n count[banner] += 1 \n```", "```\n sum_rewards[banner]+=reward \n```", "```\n Q[banner] = sum_rewards[banner]/count[banner] \n```", "```\n banner_selected.append(banner) \n```", "```\nprint( 'The best banner is banner {}'.format(np.argmax(Q))) \n```", "```\nThe best banner is banner 2 \n```", "```\nax = sns.countplot(banner_selected)\nax.set(xlabel='Banner', ylabel='Count')\nplt.show() \n```"]