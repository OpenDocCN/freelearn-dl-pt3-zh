<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">TensorFlow Graph Architecture</h1>
                </header>
            
            <article>
                
<p>The most concise and complete explanation of what TensorFlow is can be found on the project home page (<a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>) and it highlights every important part of the library. T<span>ensorFlow</span><span> is an open source software library for high-performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, and TPUs), from desktops to clusters of servers, to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google's AI organization, it comes with strong support for machine learning and deep learning, and the flexible numerical computation core is used across many other scientific domains.</span></p>
<p>TensorFlow's strengths and most important features can be summarized in the following three points:</p>
<ul>
<li><strong>High-performance numerical computation library</strong>: <span>TensorFlow can be used in many different applications just by importing it. It is written in C++ and it offers bindings for several languages. The most complete, high-level, and widely used binding is the Python one. TensorFlow is a high-performance computational library that can be used in several domains (not only machine learning!) to execute numerical computation efficiently.</span></li>
<li><strong>Flexible architecture</strong>: TensorFlow has been designed to work on different hardware (GPUs, CPUs, and TPUs) and different network architectures; its abstraction level is so high that (almost) the same code can train a model on a single computer or a cluster of machines in a data center.</li>
<li><strong>Production-oriented</strong>: TensorFlow has been developed by the Google Brain team as a tool for developing and serving machine learning models at scale. It was designed with the idea of simplifying the whole design-to-production pipeline; the library already comes with several APIs ready to be used in a production environment.</li>
</ul>
<p>TensorFlow, thus, is a numerical computational library—keep that in mind. You can use it to perform any mathematical operation it offers, leveraging the power of all the hardware you have at your disposal, without doing anything ML-related.</p>
<p><span>In this chapter, you'll learn everything you need to know about the TensorFlow architecture: what TensorFlow is, how to set up your environment to test both versions 1.x and 2.0 to see the differences, and you will learn a lot about how a computational graph is built; in the process, you will also learn how to use TensorBoard to visualize graphs.</span></p>
<p class="mce-root">In this chapter, you'll (finally!) start reading some code. Please don't just read the code and the related explanations; write all the code you read and try to execute it. Follow the instructions on how to set up the two virtual environments we need and get your hands dirty with the code. At the end of this chapter, you'll be familiar with the fundamentals of TensorFlow that are valid for every TensorFlow version.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Environment setup</li>
<li>Dataflow graphs</li>
<li>Model definition and training</li>
<li>Interacting with the graph using Python</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Environment setup</h1>
                </header>
            
            <article>
                
<p class="mce-root">In order to understand the structure of TensorFlow, all the examples presented in this chapter will use the latest TensorFlow 1.x release: 1.15; however, we will also set up everything needed to run TensorFlow 2.0 since we are going to use it in the next chapter, <a href="655b734e-1636-4e11-b944-a71fafacb977.xhtml">Chapter 4</a>, <em>TensorFlow 2.0 Architecture.</em></p>
<p class="mce-root">All the examples presented in this book specify the version of TensorFlow to use when running it. Being a library, we can just install it specifying the version we need. Of course, having two different versions of the same library installed on one system would be a mistake. In order to be able to switch between versions, we are going to use two different <em>Python virtual environments.</em></p>
<p>An explanation of what a <strong>virtual environment</strong> (<strong>virtualenv</strong>) is and why it perfectly fits our needs follows here, from the official introduction to virtual environments (<a href="https://docs.Python.org/3/tutorial/venv.html#introduction">https://docs.Python.org/3/tutorial/venv.html#introduction</a>):</p>
<div class="packt_quote">Python applications will often use packages and modules that don't come as part of the standard library. Applications will sometimes need a specific version of a library, because the application may require that a particular bug has been fixed or the application may be written using an obsolete version of the library's interface.<br/>
This means it may not be possible for one Python installation to meet the requirements of every application. If application A needs version 1.0 of a particular module, but application B needs version 2.0, then the requirements are in conflict and installing either version 1.0 or 2.0 will leave one application unable to run.<br/>
The solution to this problem is to create a virtual environment, a self-contained directory tree that contains a Python installation for a particular version of Python, plus a number of additional packages.<br/>
Different applications can then use different virtual environments. To resolve the earlier example of conflicting requirements, application A can have its own virtual environment with version 1.0 installed, while application B has another virtual environment with version 2.0. If application B requires a library to be upgraded to version 3.0, this will not affect application A's environment.</div>
<p>In order to create virtual environments in the easiest way, we use <kbd>pipenv</kbd>: the definitive tool for <kbd>virtualenv</kbd> creation and management; follow the installation guide at <a href="https://github.com/pypa/pipenv">https://github.com/pypa/pipenv</a>. Being a cross-platform tool, using Windows, Mac, or Linux makes no difference. Having installed <kbd>pipenv</kbd>, we just need to create these two separate virtual environments for the two different TensorFlow versions.</p>
<div class="packt_infobox">We'll install TensorFlow without GPU support because <kbd>tensorflow-gpu</kbd> depends on CUDA and a recent NVIDIA GPU is required to use the GPU acceleration provided by the <kbd>CUDA</kbd> package. If you own a recent NVIDIA GPU, you can install the <kbd>tensorflow-gpu</kbd> package, but you have to take care to install the version of CUDA required by the TensorFlow package you are installing (TensorFlow 2.0 and TensorFlow 1.15 require CUDA 10). Moreover, you have to ensure that both the <kbd>tensorflow-gpu</kbd> packages installed in the <kbd>virtualenvs</kbd> depend on the same CUDA version (CUDA 10); otherwise, one installation will work and the other won't. However, if you stick with versions 2.0 and 1.15 of TensorFlow, both are compiled with CUDA 10 support, hence, installing them in their GPU version and having CUDA 10 installed on your system should work perfectly.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow 1.x environment</h1>
                </header>
            
            <article>
                
<p>Create a folder, <kbd>tf1</kbd>, step inside it, and run the following commands to create an environment, activate it, and install TensorFlow using <kbd>pip</kbd>:</p>
<pre># create the virtualenv in the current folder (tf1)<br/><strong>pipenv --python 3.7</strong><br/># run a new shell that uses the just created virtualenv<br/><strong>pipenv shell</strong><br/># install, in the current virtualenv, tensorflow<br/><strong>pip install tensorflow==1.15</strong><br/>#or for GPU support: pip install tensorflow-gpu==1.15</pre>
<div class="packt_infobox">Using Python 3.7 is not strictly mandatory; TensorFlow comes with support for Python 3.5, 3.6, and 3.7. Hence, if you are using a distribution/operating system that ships an older Python version, such as Python 3.5, you just have to change the Python version in the <kbd>pipenv</kbd> command.</div>
<p>So far, so good. Right now, you are in an environment that uses Python 3.7 and has <kbd>tensorflow==1.15</kbd> installed. In order to create a new environment for TensorFlow 2.0, we have to first exit from the <kbd>pipenv shell</kbd><span> </span>created for us, which we're currently using. As a general rule, to switch from one <kbd>virtualenv</kbd> to another, we activate it using <kbd>pipenv shell</kbd> and deactivate it, exiting the session from the shell, by typing <kbd>exit</kbd>.</p>
<p>Thus, before creating the second virtual environment, just close the currently running shell by typing <kbd>exit</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow 2.0 environment</h1>
                </header>
            
            <article>
                
<p>In the same manner as with the TensorFlow 1.x environment, create a folder, <kbd>tf2</kbd>, step inside it, and run the following commands:</p>
<pre># create the virtualenv in the current folder (tf2)<br/><strong>pipenv --python 3.7</strong><br/># run a new shell that uses the just created virtualenv<br/><strong>pipenv shell</strong><br/># install, in the current virtualenv, tensorflow<br/><strong>pip install tensorflow==2.0</strong><br/>#or for GPU support: pip install tensorflow-gpu==2.0</pre>
<div class="packt_infobox">In the rest of the book, whether the TensorFlow 1.x or 2.0 environment should be used is indicated by the <kbd>(tf1)</kbd> or <kbd>(tf2)</kbd> symbol before the code.</div>
<p>We can now start digging inside the TensorFlow structure, analyzing, and describing something that was explicit in TensorFlow 1.x and hidden in TensorFlow 2.0 (but still present!): the data flow graph. Since the analysis that follows looks at the details of how a graph is built and how various low-level operations can be used to build graphs, almost every code snippet uses the TensorFlow 1.x environment. If you are interested in version 2.0 only because you already know and use TensorFlow 1.x, you can skip this section; although, reading it is also recommended for the experienced user.</p>
<div class="packt_tip">It is possible to use only the <kbd>tensorflow 2.0</kbd> environment and replace every call to the <kbd>tensorflow</kbd> package, <kbd>tf</kbd>, using the compatibility module present in TensorFlow 2; therefore, to have a single <kbd>(tf2)</kbd> environment, you must replace every <kbd>tf.</kbd> with <kbd>tf.compat.v1.</kbd> and disable eager execution by adding the <kbd>tf.compat.v1.disable_eager_execution()</kbd> line just after importing the TensorFlow package.</div>
<p>Now that we have our environment setup complete, let's move on to dataflow graphs and learn how to start working on some practical code.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dataflow graphs</h1>
                </header>
            
            <article>
                
<p>In order to be a highly efficient, flexible, and production-ready library, TensorFlow uses dataflow graphs to represent computation in terms of the relationships between individual operations. Dataflow is a programming model widely used in parallel computing and, i<span>n a dataflow graph, the nodes represent units of computation while the edges represent the data consumed or produced by a computation unit. </span></p>
<p>As seen in the previous chapter, <a href="ad05a948-1703-460a-afaf-2bf1fcdfba5a.xhtml">Chapter 2</a>, <em>Neural Networks and Deep Learning, </em>representing computation using graphs comes with the advantage of being able to run the forward and backward passes required to train a parametric machine learning model via gradient descent, applying the chain rule to compute the gradient as a local process to every node; however, this is not the only advantage of using graphs.</p>
<p>Reducing the abstraction level and thinking about the implementation details of representing computation using graphs brings the following advantages:</p>
<ul>
<li><strong>Parallelism</strong>: Using nodes to represent operations and edges that represent their dependencies, TensorFlow is able to identify operations that can be executed in parallel.</li>
<li><strong>Computation optimization</strong>: Being a graph, a well-known data structure, it is possible to analyze it with the aim of optimizing execution speed. For example, it is possible to detect unused nodes in the graph and remove them, hence optimizing it for size; it is also possible to detect redundant operations or sub-optimal graphs and replace them with the best alternatives.</li>
<li><strong>Portability</strong>: A graph is a language-neutral and platform-neutral representation of computation. TensorFlow uses <strong>Protocol Buffers</strong> (<strong>Protobuf</strong>), which is a simple language-neutral, platform-neutral, and extensible mechanism for serializing structured data to store graphs. This, in practice, means that a model defined in Python using TensorFlow can be saved in its language-neutral representation (Protobuf) and then used inside another program written in another language.</li>
<li><strong>Distributed execution</strong>: Every graph's node can be placed on an independent device and on a different machine. TensorFlow will take care of the communication between the nodes and ensure that the execution of a graph is correct. Moreover, TensorFlow itself is able to partition a graph across multiple devices, knowing that certain operations perform better on certain devices.</li>
</ul>
<p>Let's describe our first dataflow graph to compute a product and a sum between matrices and a vector; save the graphical representation and use TensorBoard to visualize it:<br/>
<kbd>(tf1)</kbd></p>
<pre>import tensorflow as tf<br/><br/># Build the graph<br/>A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)<br/>x = tf.constant([[0, 10], [0, 0.5]])<br/>b = tf.constant([[1, -1]], dtype=tf.float32)<br/>y = tf.add(tf.matmul(A, x), b, name="result") #y = Ax + b<br/><br/>writer = tf.summary.FileWriter("log/matmul", tf.get_default_graph())<br/>writer.close()</pre>
<p class="mce-root">In these few lines, there are a lot of peculiarities of TensorFlow and its way of building a computational graph. This graph represents the matrix product between the constant tensor identified by the <kbd>A</kbd> <span>Python variable </span>and the constant tensor identified by the <kbd>x</kbd> <span>Python variable </span>and the sum of the resulting matrix with the tensor identified by the <kbd>b</kbd> <span>Python variable. </span></p>
<p class="mce-root"/>
<p class="mce-root">The result of the computation is represented by the <kbd>y</kbd> <span>Python variable,</span> also known as the output of the <kbd>tf.add</kbd> node named <kbd>result</kbd> in the graph.</p>
<div class="packt_infobox">Please note the separation between the concept of a Python variable and a node in the graph: we're using Python only to describe the graph; the name of the Python variable means nothing in the graph definition.</div>
<p>Moreover, we created <kbd>tf.summary.SummaryWriter</kbd> to save a graphical representation of the graph we've built. The <kbd>writer</kbd> object has been created, specifying the path in which to store the representation (<kbd>log/matmul</kbd>) and a <kbd>tf.Graph</kbd> object obtained using the <kbd>tf.get_default_graph</kbd> function call that returns the default graph since at least one graph is always present in any TensorFlow application.</p>
<p>You can now visualize the graph using TensorBoard, the data visualization tool that comes free with TensorFlow. TensorBoard works by reading the log files placed in the specified <kbd>--logdir</kbd> and creates a web server so we're able to visualize our graph by using a browser.</p>
<p>To execute TensorBoard and visualize the graph, just type the command that follows and open a web browser at the address indicated by TensorBoard itself:</p>
<pre><strong>tensorboard --logdir log/matmul</strong></pre>
<p>The following screenshot shows the built graph, as seen in TensorBoard, and the detail of the node <span class="packt_screen">result</span>. The screenshot allows an understanding of how TensorFlow represents the nodes and which features every node has:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="aligncenter size-full wp-image-815 image-border" src="assets/ca188909-c582-473a-9fbe-16c999310c42.png" style="width:37.83em;height:18.50em;"/></div>
<div class="packt_figref">The computational graph that describes the operation y = Ax +b. The result node is highlighted in red and its details are shown in the right-hand column.</div>
<p>Please note that <strong>we are just describing the graph</strong>—the calls to the TensorFlow API are just adding operations (nodes) and connections (edges) among them; there is <strong>no computation</strong> performed in this phase. In TensorFlow 1.x, the following approach needs to be followed—static graph definition and execution, while this is no longer mandatory in 2.0.</p>
<p>Since the computational graph is the fundamental building block of the framework (in every version), it is mandatory to understand it in depth, since even after transitioning to 2.0, having an understanding of what's going on under the hood makes the difference (and it helps a lot with debugging!).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The main structure – tf.Graph</h1>
                </header>
            
            <article>
                
<p>As stated in the previous section, there's no relation between the Python variables' name and the names of the nodes. Always keep in mind that TensorFlow is a C++ library and we're using Python to build a graph in an easy way. Python simplifies the graph description phase since it even creates a graph without the need to explicitly define it; in fact, there are two different ways to define a graph:</p>
<ul>
<li class="mce-root"><strong>Implicit</strong>: Just define a graph using the <kbd>tf.*</kbd> methods. If a graph is not explicitly defined, TensorFlow always defines a default <kbd>tf.Graph</kbd>, accessible by calling <kbd>tf.get_default_graph</kbd>. The implicit definition limits the expressive power of a TensorFlow application since it is constrained to using a single graph.</li>
<li class="mce-root"><strong>Explicit</strong>: It is possible to explicitly define a computational graph and thus have more than one graph per application. This option has more expressive power, but is usually not needed since applications that need more than one graph are not common.</li>
</ul>
<p class="mce-root">In order to explicitly define a graph, TensorFlow allows the creation of <kbd>tf.Graph</kbd> objects that, through the <kbd>as_default</kbd> method, create a context manager; every operation defined inside the context is placed inside the associated graph. In practice, a <kbd>tf.Graph</kbd> object defines a namespace for the <kbd>tf.Operation</kbd> objects it contains.</p>
<p>The second peculiarity of the <kbd>tf.Graph</kbd> structure is its <strong>graph c</strong><strong>ollections</strong>. Every <kbd>tf.Graph</kbd> uses the collection mechanism to store metadata associated with the graph structure. A collection is uniquely identified by a key and its content is a list of objects/operations. The user does not usually need to worry about the existence of a collection since they are used by TensorFlow itself to correctly define a graph.</p>
<p>For example, when defining a parametric machine learning model, the graph must know which <kbd>tf.Variable</kbd> objects are the variables to update during the learning phase and which other variables are not part of the model but are something else (such as moving the mean/variance computed during the training process—these are variables but not trainable). In this case, when, as we will see in the following section, a <kbd>tf.Variable</kbd> is created, <span>it is added by default to two collections: the global variable and trainable variable collections.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Graph definition – from tf.Operation to tf.Tensor</h1>
                </header>
            
            <article>
                
<p>A dataflow graph is the representation of a computation where the nodes represent units of computation, and the edges represent the data consumed or produced by the computation.</p>
<p class="mce-root">In the context of <kbd>tf.Graph</kbd>, every API call defines <kbd>tf.Operation</kbd> (node) that can have multiple inputs and outputs <kbd>tf.Tensor</kbd> (edges). For instance, referring to our main example, when calling <kbd>tf.constant([[1, 2], [3, 4]], dtype=tf.float32)</kbd>, a new node (<kbd>tf.Operation</kbd>) named <kbd>Const</kbd> is added to the default <kbd>tf.Graph</kbd> inherited from the context. This node returns a <kbd>tf.Tensor</kbd> (edge) named <kbd>Const:0</kbd>.</p>
<p class="mce-root">Since each node in a graph is unique, if there is already a node named <em>Const</em> <span>in the graph </span>(that is the default name given to all the constants), TensorFlow will make it unique by appending the suffix '_1', '_2', and so on to the name. If a name is not provided, as in our example, TensorFlow gives a default name to each operation added and adds the suffix to make them unique in this case too.</p>
<p class="mce-root">The output <kbd>tf.Tensor</kbd> has the same name as the associated <kbd>tf.Operation</kbd>, with the addition of the <em>:ID</em> suffix. The <em>ID</em> is a progressive number that indicates how many outputs the operation produces. In the case of <kbd>tf.constant</kbd>, the output is just a single tensor, therefore <em>ID=0</em>; but there can be operations with more than one output, and in this case, the suffixes <em>:0, :1,</em> and so on are added to the <kbd>tf.Tensor</kbd> name generated by the operation.</p>
<p class="mce-root">It is also possible to add a name scope prefix to all operations created within a context—a context defined by the <kbd>tf.name_scope</kbd> call. The default name scope prefix is a <kbd>/</kbd> delimited list of names of all the active <kbd>tf.name_scope</kbd> context managers. In order to guarantee the uniqueness of the operations defined within the scopes and the uniqueness of the scopes themselves, the same suffix appending rule used for <kbd>tf.Operation</kbd> holds.</p>
<p class="mce-root">The following code snippet shows how our baseline example can be wrapped into a separate graph, how a second independent graph can be created in the same Python script, and how we can change the node names, adding a prefix, using <kbd>tf.name_scope</kbd>. First, we import the TensorFlow library:</p>
<p class="mce-root"><kbd>(tf1)</kbd></p>
<pre class="mce-root">import tensorflow as tf</pre>
<p class="mce-root">Then, we define two <kbd>tf.Graph</kbd> objects (the scoping system allows you to use multiple graphs easily):</p>
<pre class="mce-root">g1 = tf.Graph()<br/>g2 = tf.Graph()<br/><br/>with g1.as_default():<br/>    A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)<br/>    x = tf.constant([[0, 10], [0, 0.5]])<br/>    b = tf.constant([[1, -1]], dtype=tf.float32)<br/>    y = tf.add(tf.matmul(A, x), b, name="result")<br/><br/>with g2.as_default():<br/>    with tf.name_scope("scope_a"):<br/>        x = tf.constant(1, name="x")<br/>        print(x)<br/>    with tf.name_scope("scope_b"):<br/>        x = tf.constant(10, name="x")<br/>        print(x)<br/>    y = tf.constant(12)<br/>    z = x * y</pre>
<p class="mce-root">Then, we define two summary writers. We need to use two different <kbd>tf.summary.FileWriter</kbd> objects to log two separate graphs.</p>
<pre class="mce-root">writer = tf.summary.FileWriter("log/two_graphs/g1", g1)<br/>writer = tf.summary.FileWriter("log/two_graphs/g2", g2)<br/>writer.close()</pre>
<p>Run the example and use TensorBoard to visualize the two graphs, using the left-hand column on TensorBoard to switch between "runs."</p>
<p>Nodes with the same name, <kbd>x</kbd> in the example, can live together in the same graph, but they have to be under different scopes. In fact, being under different scopes makes the nodes completely independent and completely different objects. The node name, in fact, is not only the parameter <kbd>name</kbd> passed to the operation definition, but its full path, complete with <span>all </span>of the prefixes.</p>
<p>In fact, running the script, the output is as follows:</p>
<pre>Tensor("scope_a/x:0", shape=(), dtype=int32)<br/>Tensor("scope_b/x:0", shape=(), dtype=int32)</pre>
<p>As we can see, the full names are different and we also have other information about the tensors produced. In general, every tensor has a name, a type, a rank, and a shape:</p>
<ul>
<li>The<span> </span><strong>name</strong><span> </span>uniquely identifies the tensor in the computational graphs. Using <kbd>tf.name_scope</kbd>, we can prefix tensor names, thus changing their full path. We can also specify the name using the <kbd>name</kbd> attribute of every <kbd>tf.*</kbd> API call.</li>
<li>The<span> </span><strong>type</strong><span> </span>is the data type of the tensor; for example, <kbd>tf.float32</kbd>, <kbd>tf.int8</kbd>, and so on.</li>
<li>The<span> </span><strong>rank</strong>, in the TensorFlow world (this is different from the strictly mathematical definition), is just the number of dimensions of a tensor; for example, a scalar has rank 0, a vector has rank 1, a matrix has rank 2, and so on.</li>
<li>The<span> </span><strong>shape</strong><span> </span>is the number of elements in each dimension; for example, a scalar has rank 0 and an empty shape of <kbd>()</kbd>, a vector has rank 1 and a shape of<span> <kbd>(D0)</kbd>, a matrix has rank 2 and a shape of <kbd>(D0, D1)</kbd>, and so on.</span><span> </span></li>
</ul>
<div class="packt_infobox">Sometimes, it is possible to see a shape with a dimension of <kbd>-1</kbd>. This is a particular syntax that tells TensorFlow to infer from the other, well-defined, dimensions of the tensor which value should be placed in that position. Usually, a negative shape is used in the <kbd>tf.reshape</kbd> operation, which is able to change the shape of a tensor if the requested one is compatible with the number of elements of the tensor.<br/>
When defining a tensor, instead, it is possible to see one or more dimensions with the value of <kbd>None</kbd>. In this case, the full shape definition is delegated to the execution phase, since using <kbd>None</kbd> instructs TensorFlow to expect a value in that position known only at runtime.</div>
<p>Being a C++ library, TensorFlow is strictly statically typed. This means that the type of every operation/tensor must be known at graph definition time. Moreover, this also means that it is not possible to execute an operation among incompatible types.</p>
<p>Looking closely at the baseline example, it is possible to see that both matrix multiplication and addition operations are performed on tensors with the same type, <kbd>tf.float32</kbd>. The tensors identified by the Python variables <kbd>A</kbd> and <kbd>b</kbd> have been defined, making the type clear in the operation definition, while tensor <kbd>x</kbd> has the same <kbd>tf.float32</kbd> type; but in this case, it has been inferred by the Python bindings, which are able to look inside the constant value and infer the type to use when creating the operation.</p>
<p>Another peculiarity of Python bindings is their simplification in the definition of some common mathematical operations using operator overloading. The most common mathematical operations have their counterpart as <kbd>tf.Operation</kbd>; therefore, using operator overloading to simplify the graph definition is natural.</p>
<p>The following table shows the available operators overloaded in the TensorFlow Python API:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr style="height: 29px">
<td class="CDPAlignCenter CDPAlign" style="height: 29px"><strong>Python operator</strong></td>
<td class="CDPAlignCenter CDPAlign" style="height: 29px"><strong>Operation name</strong></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__neg__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">unary <kbd>-</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__abs__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>abs()</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__invert__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">unary <kbd>~</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__add__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>+</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__sub__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>-</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__mul__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary elementwise <kbd>*</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__floordiv__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>//</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__truediv__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>/</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__mod__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>%</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__pow__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>**</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__and__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>&amp;</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__or__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>|</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__xor__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>^</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__le__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>&lt;</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__lt__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>&lt;=</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__gt__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>&gt;</kbd></td>
</tr>
<tr style="height: 30px">
<td class="CDPAlignCenter CDPAlign" style="height: 30px"><kbd>__ge__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 30px">binary <kbd>&lt;=</kbd></td>
</tr>
<tr style="height: 28.2158px">
<td class="CDPAlignCenter CDPAlign" style="height: 28.2158px"><kbd>__matmul__</kbd></td>
<td class="CDPAlignCenter CDPAlign" style="height: 28.2158px">binary <kbd>@</kbd></td>
</tr>
</tbody>
</table>
<p class="mce-root">Operator overloading allows a faster graph definition and is completely equivalent to their <kbd>tf.*</kbd> API call (for example, using <kbd>__add__</kbd> is the same as using the <kbd>tf.add</kbd> function). There is only one case in which it is beneficial to use the TensorFlow API call instead of the associated operator overload: when a name for the operation is needed. Usually, when defining a graph, we're interested in giving meaningful names only to the input and output nodes, while any other node can just be automatically named by TensorFlow.</p>
<p>Using overloaded operators, we can't specify the node name and thus the output tensor's name. In fact, in the baseline example, we defined the addition operation using the <kbd>tf.add</kbd> method, because we wanted to give the output tensor a meaningful name (result). In practice, these two lines are equivalent:</p>
<pre class="mce-root"># Original example, using only API calls<br/>y = tf.add(tf.matmul(A, x), b, name="result")<br/><br/># Using overloaded operators<br/>y = A @ x + b</pre>
<p>As mentioned at the beginning of this section, TensorFlow itself can place specific nodes on different devices better suited to the operation execution. The framework is so flexible that it allows the user to manually place operations on different local and remote devices just using the <kbd>tf.device</kbd> context manager.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Graph placement – tf.device</h1>
                </header>
            
            <article>
                
<p><kbd>tf.device</kbd> creates a context manager that matches a device. The function allows the user to request that all operations created within the context it creates are placed on the same device. The devices identified by <kbd>tf.device</kbd> are more than physical devices; in fact, it is capable of identifying devices such as remote servers, remote devices, remote workers, and different types of physical devices (GPUs, CPUs, and TPUs). It is required to follow a device specification to correctly instruct the framework to use the desired device. A device specification has the following form:</p>
<pre class=""><span class="str">/job:&lt;JOB_NAME&gt;/</span><span class="pln">task</span><span class="pun">:&lt;</span><span class="pln">TASK_INDEX</span><span class="pun">&gt;/</span><span class="pln">device</span><span class="pun">:&lt;</span><span class="pln">DEVICE_TYPE</span><span class="pun">&gt;:&lt;</span><span class="pln">DEVICE_INDEX</span><span class="pun">&gt;</span></pre>
<p>Broken down as follows:</p>
<ul>
<li><span><kbd>&lt;JOB_NAME&gt;</kbd> </span>is an alpha-numeric string that does not start with a number</li>
<li><kbd>&lt;DEVICE_TYPE&gt;</kbd> is a registered device type (such as<span><span> GPU or CPU)</span></span></li>
<li><span><kbd>&lt;TASK_INDEX&gt;</kbd> </span>is a non-negative integer representing the index of the task in the job named <span><kbd>&lt;JOB_NAME&gt;</kbd></span></li>
<li><span><kbd>&lt;DEVICE_NAME&gt;</kbd> </span>is a non-negative integer representing the index of the device; for example, <kbd>/GPU:0</kbd> is the first GPU</li>
</ul>
<p>There is no need to specify every part of a device specification. For example, when running a single-machine configuration with a single GPU, you might use<span> <kbd>tf.device</kbd> to pin some operations to the CPU and GPU.</span></p>
<p><span>We can thus extend our baseline example to place the operations on the device we choose. Thus, it is possible to place the matrix multiplication on the GPU, since it is hardware optimized for this kind of operation, while keeping all the other operations on the CPU.<br/>
Please note that since this is only a graph description, there's no need to physically have a GPU or to use the <kbd>tensorflow-gpu</kbd> package. First, we import the TensorFlow library:<br/></span> <a href="https://www.tensorflow.org/api_docs/python/tf/device"/></p>
<p><kbd>(tf1)</kbd></p>
<pre class="mce-root">import tensorflow as tf</pre>
<p class="mce-root">Now, use the context manager to place operations on different devices, first, on the first CPU of the local machine:</p>
<pre class="mce-root">with tf.device("/CPU:0"):<br/>    A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)<br/>    x = tf.constant([[0, 10], [0, 0.5]])<br/>    b = tf.constant([[1, -1]], dtype=tf.float32)</pre>
<p class="mce-root">Then, on the first GPU of the local machine:</p>
<pre class="mce-root">with tf.device("/GPU:0"):<br/>    mul = A @ x</pre>
<p class="mce-root">When the device is not forced by a scope, TensorFlow decides which device is better to place the operation on:</p>
<pre class="mce-root">y = mul + b</pre>
<p>Then, we define the summary writer:</p>
<pre class="mce-root">writer = tf.summary.FileWriter("log/matmul_optimized", tf.get_default_graph())<br/>writer.close()</pre>
<p>If we look at the generated graph, we'll see that it is identical to the one generated by the baseline example, with two main differences:</p>
<ul>
<li>Instead of having a meaningful name for the output tensor, we have just the default one</li>
<li>Clicking on the matrix multiplication node, it is possible to see (in TensorBoard) that this operation must be executed in the first GPU of the local machine</li>
</ul>
<p><span>The </span><kbd>matmul</kbd><span> node is placed on the first GPU of the local machine, while any other operation is executed in the CPU. TensorFlow takes care of communication among different devices in a transparent manner:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-816 image-border" src="assets/4982764b-9b4f-4813-af3f-ed57cec12b46.png" style="width:42.50em;height:23.08em;"/></p>
<p><span>Please also note that even though we have defined constant operations that produce constant tensors, their values are not visible among the attributes of the node nor among the input/output properties.</span></p>
<p>When using the static-graph and session execution parading, the execution is completely separated from the graph definition. This is no longer true in eager execution, but since, in this chapter, the focus is on the TensorFlow architecture, it is worth also focusing on the execution part using <kbd>tf.Session</kbd>: in TensorFlow 2.0, the session is still present, but hidden, as we will see in the next chapter, <a href="655b734e-1636-4e11-b944-a71fafacb977.xhtml">Chapter 4</a><span>, </span><em>TensorFlow 2.0 Architecture</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Graph execution – tf.Session</h1>
                </header>
            
            <article>
                
<p><kbd>tf.Session</kbd> is a class that TensorFlow provides to represent a connection between the Python program and the C++ runtime. </p>
<p>The <kbd>tf.Session</kbd> object is the only object able to communicate <span>directly </span>with the hardware (through the C++ runtime), placing operations on the specified devices, using the local and distributed TensorFlow runtime, with the goal of concretely building the defined graph. The <kbd>tf.Session</kbd> object is highly optimized and, once correctly built, caches <kbd>tf.Graph</kbd> in order to speed up its execution.</p>
<p>Being the owner of physical resources, the <kbd>tf.Session</kbd> object must be used as a file descriptor to do the following:</p>
<ul>
<li>Acquire the resources by creating a<span> </span><kbd>tf.Session</kbd> (the equivalent of the <kbd>open</kbd> operating system call)</li>
<li>Use the resources (the equivalent of using the <kbd>read/write</kbd> operation on the file descriptor)</li>
<li>Release the resources with <kbd>tf.Session.close</kbd> (the equivalent of the <kbd>close</kbd> call)</li>
</ul>
<p>Typically, instead of manually defining a session and taking care of its creation and destruction, a session is used through a context manager that automatically closes the session at the block exit.</p>
<p>The constructor of <kbd>tf.Session</kbd> is fairly complex and highly customizable since it is used to configure and create the execution of the computational graph.</p>
<p>In the simplest and most common scenario, we just want to use the current local hardware to execute the previously described computational graph as follows:</p>
<p><kbd>(tf1)</kbd></p>
<pre># The context manager opens the session<br/>with tf.Session() as sess:<br/>    # Use the session to execute operations<br/>    sess.run(...)<br/># Out of the context, the session is closed and the resources released</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>There are more complex scenarios in which we wouldn't want to use the local execution engine, but use a remote TensorFlow server that gives access to all the devices it controls. This is possible by specifying the <kbd>target</kbd> parameter of <kbd>tf.Session</kbd> just by using the URL (<kbd>grpc://</kbd>) of the server:</p>
<p><kbd>(tf1)</kbd></p>
<pre># the IP and port of the TensorFlow server<br/>ip = "192.168.1.90"<br/>port = 9877<br/>with tf.Session(f"grpc://{ip}:{port}") as sess:<br/>    sess.run(...)</pre>
<p><span>By default, the <kbd>tf.Session</kbd> will capture and use the default <kbd>tf.Graph</kbd> object, but when working with multiple graphs, it is possible to specify which graph to use by using the <kbd>graph</kbd> parameter. It's easy to understand why working with multiple graphs is unusual, since even the <kbd>tf.Session</kbd> object is able to work with only a single graph at a time.</span></p>
<p>The third and last parameter of the <kbd>tf.Session</kbd> object is the hardware/network configuration specified through the <kbd>config</kbd> parameter. The configuration is specified through the <kbd>tf.ConfigProto</kbd> object, which is able to control the behavior of the session. The <kbd>tf.ConfigProto</kbd> object is fairly complex and rich with options, the most common and widely used being the following two (all the others are options used in distributed, complex environments):</p>
<ul>
<li><kbd>allow_soft_placement</kbd>: If set to <kbd>True</kbd>, it enables a soft device placement. Not every operation can be placed indifferently on the CPU and GPU, because the GPU implementation of the operation may be missing, for example, and using this option allows TensorFlow to ignore the device specification made via <kbd>tf.device</kbd> and place the operation on the correct device when an unsupported device is specified at graph definition time.</li>
<li><kbd>gpu_options.allow_growth</kbd>: If set to <kbd>True</kbd>, it changes the TensorFlow GPU memory allocator; the default allocator allocates all the available GPU memory as soon as the <kbd>tf.Session</kbd> is created, while the allocator used when <kbd>allow_growth</kbd> is <kbd>True</kbd> gradually increases the amount of memory allocated. The default allocator works in this way because, in production environments, the physical resources are completely dedicated to the <kbd>tf.Session</kbd> execution, while, in a standard research environment, the resources are usually shared (the GPU is a resource that can be used by other processes while the TensorFlow <kbd>tf.Session</kbd> is in execution).</li>
</ul>
<p>The baseline example can now be extended to not only define a graph, but to proceed on to an effective construction and the execution of it:</p>
<pre>import tensorflow as tf<br/>import numpy as np<br/><br/>A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)<br/>x = tf.constant([[0, 10], [0, 0.5]])<br/>b = tf.constant([[1, -1]], dtype=tf.float32)<br/>y = tf.add(tf.matmul(A, x), b, name="result")<br/><br/>writer = tf.summary.FileWriter("log/matmul", tf.get_default_graph())<br/>writer.close()<br/><br/>with tf.Session() as sess:<br/>    A_value, x_value, b_value = sess.run([A, x, b])<br/>    y_value = sess.run(y)<br/><br/>    # Overwrite<br/>    y_new = sess.run(y, feed_dict={b: np.zeros((1, 2))})<br/><br/>print(f"A: {A_value}\nx: {x_value}\nb: {b_value}\n\ny: {y_value}")<br/>print(f"y_new: {y_new}")</pre>
<p>The first <kbd>sess.run</kbd> call evaluates the three <kbd>tf.Tensor</kbd> objects, <kbd>A, x, b</kbd>, and returns their values as <kbd>numpy</kbd> arrays.</p>
<p>The second call, <kbd>sess.run(y)</kbd>, works in the following way:</p>
<ol>
<li><kbd>y</kbd> is an output node of an operation: backtrack to its inputs</li>
<li>Recursively backtrack through every node until all the nodes without a parent are found</li>
<li>Evaluate the input; in this case, the <kbd>A, x, b</kbd> tensors</li>
<li>Follow the dependency graph: the multiplication operation must be executed before the addition of its result with <kbd>b</kbd></li>
<li>Execute the matrix multiplication</li>
<li>Execute the addition</li>
</ol>
<p><span>The addition is the entry point of the graph resolution (Python variable </span><kbd>y</kbd><span>) and the computation ends.</span></p>
<p>The first print call, therefore, produces the following output:</p>
<pre>A: [[1. 2.]<br/>    [3. 4.]]<br/>x: [[ 0. 10. ]<br/>    [ 0. 0.5]]<br/>b: [[ 1. -1.]]<br/>y: [[ 1. 10.]<br/>    [ 1. 31.]]</pre>
<p>The third <kbd>sess.run</kbd> call shows how it is possible to inject into the computational graph values from the outside, as <kbd>numpy</kbd> arrays, overwriting a node. The <kbd>feed_dict</kbd> parameter allows you to do this: usually, inputs are passed to the graph using the <kbd>feed_dict</kbd> parameter and through the overwriting of the <kbd>tf.placeholder</kbd> operation created exactly for this purpose.</p>
<p><kbd>tf.placeholder</kbd> is just a placeholder created with the aim of throwing an error when values from the outside are not injected inside the graph. However, the <kbd>feed_dict</kbd> parameter is more than just a way to feed the placeholders. In fact, the preceding example shows how it can be used to overwrite any node. The result produced by the overwriting of the node identified by the Python variable, <kbd>b</kbd>, with a <kbd>numpy</kbd> array that must be compatible, in terms of both type and shape, with the overwritten variable, is as follows:</p>
<pre>y_new: [[ 0. 11.]<br/>        [ 0. 32.]]</pre>
<p>The baseline example has been updated in order to show the following:</p>
<ul>
<li>How to build a graph</li>
<li>How to save a graphical representation of the graph</li>
<li>How to create a session and execute the defined graph</li>
</ul>
<p>So far, we have used graphs with constant values and used the <kbd>feed_dict</kbd> parameter of the <kbd>sess.run</kbd> call to overwrite a node parameter. However, since TensorFlow is designed to solve complex problems, the concept of <kbd>tf.Variable</kbd> has been introduced: every parametric machine learning model can be defined and trained with TensorFlow.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Variables in static graphs</h1>
                </header>
            
            <article>
                
<p>A variable is an object that maintains a state in the graph across multiple calls to <kbd>sess.run</kbd>. A variable is added to <kbd>tf.Graph</kbd> by constructing an instance of the <kbd>tf.Variable</kbd> class.</p>
<p>A variable is completely defined by the pair (type, shape), and variables created by calling <kbd>tf.Variable</kbd> can be used as input for other nodes in the graph; in fact, the <kbd>tf.Tensor</kbd> and <kbd>tf.Variable</kbd> objects can be used in the same manner when building a graph.</p>
<p>Variables have more attributes with respect to tensors: a variable object must be initialized and thus have its initializer; a variable is, by default, added to the global variables and trainable variable graph collections. If a variable is set as non-trainable, it can be used by the graph to store the state, but the optimizers will ignore it when performing the learning process.</p>
<p>There are two ways of declaring a variable in a graph: <kbd>tf.Variable</kbd> and <kbd>tf.get_variable</kbd>. Using <kbd>tf.Variable</kbd> is easier but less powerful—the second way is more complex to use, but has more expressive power.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">tf.Variable</h1>
                </header>
            
            <article>
                
<p>Creating a variable by calling <kbd>tf.Variable</kbd> will always create a new variable and it always requires an initial value to be specified. In the following lines, the creation of a variable named <kbd>W</kbd> with shape <kbd>(5, 5, size_in, size_out)</kbd> and a variable, <kbd>B</kbd>, with shape <kbd>(size_out)</kbd> is shown:</p>
<pre>w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name="W")<br/>b = tf.Variable(tf.constant(0.1, shape=[size_out]), name="B")</pre>
<p>The <kbd>w</kbd> initial value is generated by the <kbd>tf.truncated_normal</kbd> operation, which samples from a normal distribution with 0 mean and a standard deviation of 0.1 the <kbd>5 x 5 x size_in x size_out</kbd> (total number) values required to initialize the tensor, while <kbd>b</kbd> is initialized using the constant value of 0.1 generated by the <kbd>tf.constant</kbd> operation.</p>
<p class="mce-root"/>
<p>Since each call to <kbd>tf.Variable</kbd> creates a new variable in the graph, it is the perfect candidate for the creation of layers: every layer (for example, a convolutional layer/a fully connected layer) definition requires the creation of a new variable. For instance, the following lines of code show the definition of two functions that can be used to define a convolutional neural network and/or a fully connected neural network:</p>
<p><kbd><span>(tf1)</span></kbd></p>
<p>The first function creates a 2D convolutional layer (with a 5 x 5 kernel) followed by a max-pool operation to halve the output's spatial extent:</p>
<pre>def conv2D(input, size_in, size_out, name="conv"):<br/>"""Define a 2D convolutional layer + max pooling.<br/>Args:<br/>    input: Input tensor: 4D.<br/>    size_in: it could be inferred by the input (input.shape[-1])<br/>    size_out: the number of convolutional kernel to learn<br/>    name: the name of the operation, using name_scope.<br/>Returns:<br/>    The result of the convolution as specified + a max pool operation<br/>    that halves the spatial resolution.<br/>"""<br/>    with tf.name_scope(name):<br/>        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name="W")<br/>        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name="B")<br/>        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding="SAME")<br/>        act = tf.nn.relu(conv + b)<br/>        tf.summary.histogram("w", w)<br/>        tf.summary.histogram("b", b)<br/>        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")</pre>
<p>The second function defines a fully connected layer:</p>
<p><kbd><span>(tf1)</span></kbd></p>
<pre>def fc(input, size_in, size_out, name="fc"):<br/>"""Define a fully connected layer.<br/>Args:<br/>    input: Input tensor: 2D.<br/>    size_in: it could be inferred by the input (input.shape[-1])<br/>    size_out: the number of output neurons kernel to learn<br/>    name: the name of the operation, using name_scope.<br/>Returns:<br/>    The linear neurons output.<br/>"""</pre>
<p>Both functions also use the <kbd>tf.summary</kbd> module to log the histograms of the weight, bias, and activation values, which can change during training.</p>
<p>The call to a <kbd>tf.summary</kbd> method automatically adds the summaries to a global collection that is used by <kbd>tf.Saver</kbd> and <kbd>tf.SummaryWriter</kbd> objects to log every summary value in the TensorBoard log directory:</p>
<p><kbd>(tf1)</kbd></p>
<pre>with tf.name_scope(name):<br/>    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name="W")<br/>    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name="B")<br/>    act = tf.matmul(input, w) + b<br/>    tf.summary.histogram("w", w)<br/>    tf.summary.histogram("b", b)<br/>    return act</pre>
<p>A layer definition made in this way is perfect for the most common scenarios in which a user wants to define a deep learning model composed by a stack of several layers and train it given a single input that flows from the first to the last layer.</p>
<p>What if, instead, the training phase is not standard and there is the need to share the variable's values among different inputs?</p>
<p>We need to use the TensorFlow feature called <strong>variable sharing</strong>, which is not possible using a layer definition made with <kbd>tf.Variable</kbd>, so we have to instead use the most powerful method, <kbd>tf.get_variable</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">tf.get_variable</h1>
                </header>
            
            <article>
                
<p>Like <kbd>tf.Variable</kbd>, <kbd>tf.get_variable</kbd> <span>also </span>allows the definition and creation of new variables. The main difference is that its behavior changes if the variable has already been defined.</p>
<p><kbd>tf.get_variable</kbd> is always used together with <kbd>tf.variable_scope</kbd> since it enables the variable sharing capabilities of <kbd>tf.get_variable</kbd> through its <kbd>reuse</kbd> parameter. The following example clarifies the concept:</p>
<p><kbd>(tf1)</kbd></p>
<pre>with tf.variable_scope("scope"):<br/>    a = tf.get_variable("v", [1]) # a.name == "scope/v:0"<br/>with tf.variable_scope("scope"):<br/>    b = tf.get_variable("v", [1]) # ValueError: Variable scope/v:0 already exists<br/>with tf.variable_scope("scope", reuse=True):<br/>    c = tf.get_variable("v", [1]) # c.name == "scope/v:0"</pre>
<p>In the preceding example, the Python variables <kbd>a</kbd> and <kbd>c</kbd> point to the same graph variable, named <kbd>scope/v:0</kbd>. Hence, a layer that uses <kbd>tf.get_variable</kbd> to define variables can be used in conjunction with <kbd>tf.variable_scope</kbd> to define or reuse the layer's variables. This is extremely useful and powerful when training generative models using adversarial training, as we will see in <a href="66948c53-131c-43ef-a7fc-3d242d1e0664.xhtml">Chapter 9</a>, <em>Generative Adversarial Networks</em>.</p>
<p>Different from <kbd>tf.Variable</kbd>, in this case, we can't pass an initial value in a raw way (passing the value directly as input to the <kbd><span>call </span></kbd>method ); we always have to explicitly use an initializer. The previously defined layer can be written using <kbd>tf.get_variable</kbd> (and this is the recommended way to define variables) as follows:</p>
<p><kbd>(tf1)</kbd></p>
<pre>def conv2D(input, size_in, size_out):<br/>    w = tf.get_variable(<br/>        'W', [5, 5, size_in, size_out],<br/>        initializer=tf.truncated_normal_initializer(stddev=0.1))<br/>    b = tf.get_variable(<br/>        'B', [size_out], initializer=tf.constant_initializer(0.1))<br/>    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding="SAME")<br/>    act = tf.nn.relu(conv + b)<br/>    tf.summary.histogram("w", w)<br/>    tf.summary.histogram("b", b)<br/>    return tf.nn.max_pool(<br/>        act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")<br/><br/>def fc(input, size_in, size_out):<br/>    w = tf.get_variable(<br/>        'W', [size_in, size_out],<br/>        initializer=tf.truncated_normal_initializer(stddev=0.1))<br/>    b = tf.get_variable(<br/>        'b', [size_out], initializer=tf.constant_initializer(0.1))<br/>    act = tf.matmul(input, w) + b<br/>    tf.summary.histogram("w", w)<br/>    tf.summary.histogram("b", b)<br/>    return act</pre>
<p class="mce-root"/>
<p>Invoking <kbd>conv2D</kbd> or <kbd>fc</kbd> defines the variables needed to define a layer in the current scope; hence, to define two convolutional layers without having naming conflicts, <kbd>tf.variable_scope</kbd> must be used:</p>
<pre>input = tf.placeholder(tf.float32, (None, 28,28,1))<br/>with tf.variable_scope("first)":<br/>    conv1 = conv2d(input, input.shape[-1].value, 10)<br/>with tf.variable_scope("second"): #no conflict, variables under the second/ scope<br/>    conv2 = conv2d(conv1, conv1.shape[-1].value, 1)<br/># and so on...</pre>
<p class="mce-root">Manually defining layers is a good exercise, and knowing that TensorFlow has all the primitives required to define every ML layer is something every ML practitioner should know. However, manually defining every single layer is tedious and repetitive (we need fully connected, convolutional, dropout, and batch normalization layers in almost every project), and, for this reason, TensorFlow already comes with a module named <kbd>tf.layers</kbd>, which contains all the most common and widely used layers, defined using <kbd>tf.get_variable</kbd> under the hood, and therefore, layers can be used in conjunction with <kbd>tf.variable_scope</kbd> to share their variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model definition and training</h1>
                </header>
            
            <article>
                
<p>Disclaimer: the layer module has been completely removed in TensorFlow 2.0, and the layer definition using <kbd>tf.keras.layers</kbd> is the new standard; however, an overview of <kbd>tf.layers</kbd> is still worth reading because it shows how reasoning layer by layer to define deep models is the natural way to proceed and it also gives us an idea of the reasons behind the migration from <kbd>tf.layers</kbd> to <kbd>tf.keras.layers</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Defining models with tf.layers</h1>
                </header>
            
            <article>
                
<p>As shown in the previous section, TensorFlow provides all the primitive features to define a neural network layer: the user should take care when defining the variables, the operation nodes, the activation functions, and the logging, and define a proper interface to handle all cases (adding, or not, the bias term, adding regularization to the layer parameters, and so on).</p>
<p class="mce-root"/>
<p>The <kbd>tf.layers</kbd> module in TensorFlow 1.x and the <kbd>tf.keras.layers</kbd> module in TensorFlow 2.0 provide an excellent API to define machine learning models in a convenient and powerful way. Every layer in <kbd>tf.layers</kbd>, defines variables using <kbd>tf.get_variable</kbd>, and therefore, each layer defined in this way can use the variable-sharing features provided by <kbd>tf.variable_scope</kbd>.</p>
<p>The previously manually defined 2D convolution and fully connected layers are clearly present and well-defined in <kbd>tf.layers</kbd> and using them to define a LeNet-like CNN is easy, as shown. First, we define a convolutional neural network for classification:</p>
<p><kbd>(tf1)</kbd></p>
<pre class="mce-root">def define_cnn(x, n_classes, reuse, is_training):<br/>    """Defines a convolutional neural network for classification.<br/>    Args:<br/>        x: a batch of images: 4D tensor.<br/>        n_classes: the number of classes, hence, the number of output neurons.<br/>        reuse: the `tf.variable_scope` reuse parameter.<br/>        is_training: boolean variable that indicates if the model is in training.<br/>    Returns:<br/>        The output layer.<br/>    """<br/>    with tf.variable_scope('cnn', reuse=reuse):<br/>        # Convolution Layer with 32 learneable filters 5x5 each<br/>        # followed by max-pool operation that halves the spatial extent.<br/>        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)<br/>        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)<br/><br/>        # Convolution Layer with 64 learneable filters 3x3 each.<br/>        # As above, max pooling to halve.<br/>        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)<br/>        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)</pre>
<p class="mce-root">Then, we flatten the data to a 1D vector so that we can use a fully connected layer. Please note how the new shape is computed and the negative dimension in the batch size position:</p>
<pre class="mce-root">        shape = (-1,conv2.shape[1].value * conv2.shape[2].value * conv2.shape[3].value)<br/>        fc1 = tf.reshape(conv2, shape)<br/><br/>        # Fully connected layer<br/>        fc1 = tf.layers.dense(fc1, 1024)<br/>        # Apply (inverted) dropout when in training phase.<br/>        fc1 = tf.layers.dropout(fc1, rate=0.5, training=is_training)<br/><br/>        # Prediction: linear neurons<br/>        out = tf.layers.dense(fc1, n_classes)<br/><br/>    return out<br/><br/>input = tf.placeholder(tf.float32, (None, 28, 28, 1))<br/>logits = define_cnn(input, 10, reuse=False, is_training=True)</pre>
<p>Being high-level wrappers on primitive TensorFlow operations, there is no need to detail what every layer does <span>in this book </span>since it is pretty clear from the layer names themselves and from the documentation. The reader is invited to become familiar with the official TensorFlow documentation, and, in particular, to try to define their own classification model using layers: <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers</a><a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers">.</a></p>
<p>Using the baseline example and replacing the graph with this CNN definition, using TensorFlow, it is possible to see how every layer has its own scope, how the layers are connected among them, and, as shown in the second diagram, by double-clicking on a layer, it is possible to see its contents to understand how it is implemented without having to look at the code. </p>
<p>The following <span><span>diagram shows</span></span> the architecture of the defined LeNet-like CNN. The whole architecture is placed under the <em>cnn</em> scope; the input node is a placeholder. It is possible to visualize how the layers are connected and how TensorFlow added the <kbd>_1</kbd> suffix to blocks with the same name to avoid conflicts:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-817 image-border" src="assets/c6aedc60-0542-4150-8377-b04cad633ac1.png" style="width:22.75em;height:52.75em;"/></p>
<p class="mce-root"><span>Double-clicking on the </span><kbd>conv2d</kbd> <span>block allows you to analyze how the various components defined by the layers are connected to each other. Please note how, different from our layer implementation, the TensorFlow developers used an operation named </span><kbd>BiasAdd</kbd> <span>to add the bias and not the raw </span><kbd>Add</kbd> <span>operation. The behavior is the same, but the semantics are clearer:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-818 image-border" src="assets/40e6d1cd-926e-4334-bc2c-1f8b77660c67.png" style="width:37.67em;height:40.08em;"/></p>
<p>As an exercise, you can try to extend the baseline by defining a CNN like the one just presented to visualize and understand the layer structure.</p>
<p>We always have to keep in mind that TensorFlow 1.x follows the graph definition and session execution approach. This means that even the training phase should be described within the same <kbd>tf.Graph</kbd> object before being executed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Automatic differentiation – losses and optimizers</h1>
                </header>
            
            <article>
                
<p>TensorFlow uses automatic differentiation—a differentiator is an object that contains all the rules required to build a new graph that takes the derivative of each node it traverses. The <kbd>tf.train</kbd> module in TensorFlow 1.x contains the most widely used type of differentiator, called optimizers here. In the module, among the other optimizers, it is possible to find the ADAM optimizer as <kbd>tf.train.AdamOptimizer</kbd> and the standard gradient descent optimizer as <kbd>tf.train.GradientDescentOptimizer</kbd>. Each optimizer is an object that implements a common interface. The interface standardizes how to use an optimizer to train a model. Performing a mini-batch gradient descent step is just a matter of executing a train operation <span>in a Python loop;</span> that is, an operation returned by the <kbd>.minimize</kbd> method of every optimizer.</p>
<p>As you will know from the theory presented in the previous chapter, <a href="ad05a948-1703-460a-afaf-2bf1fcdfba5a.xhtml">Chapter 2</a>, <em>Neural Networks and Deep Learning, </em>to train a classifier using cross-entropy loss, it is necessary to one-hot encode the labels. TensorFlow has a module, <kbd>tf.losses</kbd>, that contains the most commonly used loss functions that are also capable of performing the one-hot encoding of labels by themselves. Moreover, every loss function expects the <kbd>logits</kbd> tensor as input; that is, the linear output of the model without the application of the softmax/sigmoid activation function. The name of the <kbd>logits</kbd> tensor is a TensorFlow design choice: it is called in this way even if no sigmoidal transformation has been applied to it (a better choice would be naming this parameter <kbd>unscaled_logits</kbd>).</p>
<p>The reason for this choice is to let the user focus on the network design without having to worry about the numerical instability problems that could arise when computing certain loss functions; in fact, every loss defined in the <kbd>tf.losses</kbd> module is numerically stable.</p>
<p>In order to have a complete understanding of the topic and to show that an optimizer just builds a graph connected to the previous one (it only adds nodes in practice), it is possible to mix the baseline example that logs the graph together with the example that defines the network with its loss function and an optimizer.</p>
<p>Thus, the previous example can be modified as follows. To define the input placeholder for the labels, we can define the loss function (<kbd>tf.losses.sparse_softmax_cross_entropy</kbd>) and instantiate the ADAM optimizer to minimize it:</p>
<pre># Input placeholders: input is the cnn input, labels is the loss input.<br/>input = tf.placeholder(tf.float32, (None, 28, 28, 1))<br/>labels = tf.placeholder(tf.int32, (None,))<br/><br/>logits = define_cnn(input, 10, reuse=False, is_training=True)<br/># Numerically stable loss<br/>loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)<br/># Instantiate the Optimizer and get the operation to use to minimize the loss<br/>train_op = tf.train.AdamOptimizer().minimize(loss)<br/><br/># As in the baseline example, log the graph<br/>writer = tf.summary.FileWriter("log/graph_loss", tf.get_default_graph())<br/>writer.close()</pre>
<p>TensorBoard allows us to visualize the graph built as shown:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-819 image-border" src="assets/b8f0e238-3feb-4ad1-9816-bf5f0c3d6fc2.png" style="width:64.67em;height:27.17em;"/></p>
<p class="CDPAlignLeft CDPAlign">The preceding diagram shows the structure of the graph when a loss function is defined, and the <kbd>.minimize</kbd> method is invoked.</p>
<p>The ADAM optimizer is a separate block that only has inputs—the model (<em>cnn</em>), the gradients, and the nontrainable <em>beta1</em> and <em>beta2</em> parameters used by ADAM (and specified in its constructor, left at their default values in this case). The gradients, as you will know from the theory, are computed with respect to the model parameters to minimize the loss function: the graph on the left perfectly describes this construction. The gradient block created by the minimize method invocation is a named scope, and as such, it can be analyzed by double-clicking on it just like any other block in TensorBoard.</p>
<p><span>The following graph shows the gradient block expanded: it contains a mirrored structure of the graph used for the forward model. Every block the optimizer uses to optimize the parameters is an input of the gradient block. The gradients are the input of the optimizer (ADAM):</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-820 image-border" src="assets/932f5a8d-ca86-41f6-96c6-51aa85c5dba8.png" style="width:44.67em;height:50.00em;"/></p>
<p>Following on from the theory, the differentiator (optimizer) created a new graph that mirrors the original graph; this second graph, inside the gradient block, performs the gradient calculation. The optimizer uses the gradients produced to apply the variables update rule it defines and implements the learning process.</p>
<p>A brief recap on what we have seen so far for the static-graph and session execution is as follows:</p>
<ol>
<li>Define the model inputs using placeholders or other optimized methods, as shown in later chapters</li>
<li>Define the model as a function of the input</li>
<li>Define the loss function as a function of the model output</li>
<li>Define the optimizer and invoke the <kbd>.minimize</kbd> method to define the gradient computation graph</li>
</ol>
<p>These four steps allow us to define a simple training loop and train our model. However, we're skipping some important parts:</p>
<ul>
<li>Model performance measurement on training and validation sets</li>
<li>Saving the model parameters</li>
<li>Model selection</li>
</ul>
<p>Moreover, since the input is defined using placeholders, we have to take care of everything related to the input: splitting the dataset, creating the mini-batches, keeping track of the training epochs, and so on.</p>
<p>TensorFlow 2.0 with <kbd>tfds</kbd> (TensorFlow Datasets) simplified and standardized the input pipeline definition, as we will see in later chapters; however, having a clear idea about what happens under the hood is always an advantage, therefore, it's a good exercise for the reader to continue with the following low-level use of placeholders in order to have a better understanding of the problems <kbd>tfds</kbd> solves.</p>
<p>So far, you should have a clear understanding of the operations that must be executed in a computational graph, and you should have understood that Python is used only to build a graph and to do non-learning related operations (hence, it's not Python that performs the variable update, but it is the execution within a session of a Python variable that represents the training operation that triggers all the required operations to make the model learn).</p>
<p>In the next section, the previous CNN example is extended, adding all the functionality on the Python-side that is required to perform model selection (saving the model, measuring performance, making the training loop, and feeding the input placeholders).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Interacting with the graph using Python</h1>
                </header>
            
            <article>
                
<p>Python is the language of choice to train a TensorFlow model; however, after defining a computational graph in Python, there are no constraints regarding using it with another language to execute the learning operations defined.</p>
<div class="packt_infobox">Always keep in mind that we use Python to define a graph and this definition can be exported in a portable and language-agnostic representation (Protobuf)—this representation can then be used in any other language to create a concrete graph and using it within a session.</div>
<p>The TensorFlow Python API is complete and easy to use. Therefore, we can extend the previous example to measure the accuracy (defining the accuracy measurement operation in the graph) and use this metric to perform model selection.</p>
<p>Selecting the best model means storing the model parameters at the end of each epoch and moving the parameters that produced the highest metric value <span>in a different folder</span>. To do this, we have to define the input pipeline in Python and use the Python interpreter to interact with the graph.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feeding placeholders</h1>
                </header>
            
            <article>
                
<p>As mentioned in the previous section, placeholders are the easiest to use but are also the least performant and most error-prone way to build a data input pipeline. In later chapters, a better, highly efficient solution will be presented. This highly efficient solution has the complete input pipeline completely defined inside the graph. However, the placeholder solution is not only the easiest but also the only one that can be used in certain scenarios (for example, when training reinforcement learning agents, input via a placeholder is the preferred solution).</p>
<p>In <a href="0dff1bba-f231-45fa-9a89-b4f127309579.xhtml">Chapter 1</a>, <em>What is Machine Learning?</em>, the Fashion-MNIST dataset was described, and we're now going to use it as the input dataset for our model—the previously defined CNN will be used to classify the fashion items.</p>
<p>Fortunately, we don't have to worry about the dataset download and processing part, since TensorFlow, in its <kbd>keras</kbd> module, already has a function that downloads and processes the dataset for us to have the training images and the test images together with their labels in the expected form (28 x 28 images):</p>
<p><kbd>(tf1)</kbd></p>
<pre>from tensorflow.keras.datasets import fashion_mnist<br/><br/>(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()<br/># Scale input in [-1, 1] range<br/>train_x = train_x / 255. * 2 - 1<br/>test_x = test_x / 255. * 2 - 1<br/># Add the last 1 dimension, so to have images 28x28x1<br/>train_x = np.expand_dims(train_x, -1)<br/>test_x = np.expand_dims(test_x, -1)</pre>
<p><kbd>train_x</kbd> and <kbd>test_x</kbd> contain the whole dataset—training a model using a single batch containing the complete dataset is not tractable on a standard computer; therefore, using Python, we have to take care when splitting the dataset and building mini-batches to make the training process affordable.</p>
<p>Let's say we want to train the model for 10 epochs using batches of 32 elements each; it is easy to compute the number of batches needed to train the model for an epoch and then run a training loop that iterates over the batches:</p>
<p><kbd>(tf1)</kbd></p>
<pre>epochs = 10<br/>batch_size = 32<br/>nr_batches_train = int(train_x.shape[0] / batch_size)<br/>print(f"Batch size: {batch_size}")<br/>print(f"Number of batches per epoch: {nr_batches_train}")</pre>
<p>Of course, since we need to perform model selection, we need to first define an operation that computes the accuracy as a function of the model and the input and then use the <kbd>tf.summary.SummaryWriter</kbd> object to write the train and validation accuracy on the same graph.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Writing summaries</h1>
                </header>
            
            <article>
                
<p>The baseline example already uses a <kbd>tf.summary.SummaryWriter</kbd> object to write the graph in the log directory and make it appear in the graph section of TensorBoard. However, <kbd>SummaryWriter</kbd> can be used to write not only the graph but also a histogram, scalar values, distributions, log images, and many other data types.</p>
<p>The <kbd>tf.summary</kbd> package is filled with easy-to-use methods to log any data. For instance, we are interested in logging the loss value; the loss value is a scalar and, therefore, <kbd>tf.summary.scalar</kbd> is the method to use. The package is well-documented, and you should take the time to explore it: <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf</a><a href="https://www.tensorflow.org/versions/r1.15/api_docs/Python/tf">.</a></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>To extend the previous example, we can define the accuracy operation as a function of the input placeholders. In this way, we can run the same operation, changing the input when needed. For instance, we could be interested in measuring both the training and validation accuracy at the end of each training epoch.</p>
<p>The same reasoning applies to the loss value: defining the loss as a function of the model and the model as a function of a placeholder, we are able to measure how the loss changes on the training and validation input <span>just by changing the input</span>:</p>
<p><kbd>(tf1)</kbd></p>
<pre># Define the accuracy operation over a batch<br/>predictions = tf.argmax(logits, 1)<br/># correct predictions: [BATCH_SIZE] tensor<br/>correct_predictions = tf.equal(labels, predictions)<br/>accuracy = tf.reduce_mean(<br/>    tf.cast(correct_predictions, tf.float32), name="accuracy")<br/><br/># Define the scalar summarie operation that once executed produce<br/># an input for the tf.train.SummaryWriter.<br/><br/>accuracy_summary = tf.summary.scalar("accuracy", accuracy)<br/>loss_summary = tf.summary.scalar("loss", loss)</pre>
<p>A single <kbd>tf.train.FileWriter</kbd> object is associated with a unique path on the disk, called <strong>run</strong>. A run represents a different configuration of the current experiment. For example, the default run is usually the training phase. At this phase, hence at this run, the metrics attached (loss, accuracy, logs of images, and so on) are measured during the training phase, on the training set.</p>
<p>A different run can be created by creating a new <kbd>tf.train.FileWriter</kbd> with a different path associated with it, but with the same root of the other (training) <kbd>FileWriter</kbd>. In this way, using TensorBoard, we can visualize different curves <span>on the same graph; for</span> example, visualizing the validation accuracy and the training accuracy on the same plot. This feature is of extreme importance when analyzing the behavior of an experiment and when you are interested in comparing different experiments at a glance.</p>
<p>Hence, since we want to visualize the training and the validation curves <span>on the same plot, </span>we can create two different writers:</p>
<pre>writer = tf.summary.FileWriter("log/graph_loss", tf.get_default_graph())<br/>validation_summary_writer = tf.summary.FileWriter(<br/>    "log/graph_loss/validation")</pre>
<p>The first one is the train phase writer; the second, the validation phase one.</p>
<p class="mce-root"/>
<p>Now, potentially, we could measure the validation accuracy and the training accuracy, just by running the <kbd>accuracy</kbd> tensor, changing the input placeholder values accordingly; this means that we are already able to perform model selection: the model with the highest validation accuracy is the one to select.</p>
<p>To save the model parameters, a <kbd>tf.Saver</kbd> object is required.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Saving model parameters and model selection</h1>
                </header>
            
            <article>
                
<p>Saving model parameters is important since it's the only way to continue to train a model after an interruption, and the only way to checkpoint a model status for any reason—training finished, the model reached the best validation performance.</p>
<p><kbd>tf.Saver</kbd> is the object the TensorFlow Python API provides to save the current model variables. Please note that the <kbd>tf.Saver</kbd> object saves the variables only and not the graph structure!</p>
<p>To save both the graph structure and variables, a <kbd>SavedModel</kbd> object is required; however, since the <kbd>SavedModel</kbd> object is more connected with putting a trained model into production, its definition and usage are demanded to the paragraph dedicated to the production.</p>
<p>The <kbd>tf.Saver</kbd> object saves the list of the trainable variables plus any other nontrainable variables specified in its constructor. Once created, the object provides the <kbd>save</kbd> method, which accepts the path used to store the variables. A single <kbd>Saver</kbd> object can be used to create several checkpoints and thus save the model that reached the top performance on the validation metric <span>in a different path</span>, in order to perform model selection.</p>
<p>Moreover, the <kbd>Saver</kbd> object offers the <kbd>restore</kbd> method, which can be used to populate the variables of the previously defined graph, before starting to train them, to restart an interrupted training phase. Eventually, it is possible to specify the list of the variables to restore from the checkpoint <span>in the restore call</span>, making it possible to use pre-trained layers and fine-tune them. The <kbd>tf.Saver</kbd> is the main object involved when doing transfer learning and fine-tuning a model.</p>
<p>The previous example can thus be extended to perform logging of the measured training/validation accuracy <span>in TensorBoard </span>(in the code, the accuracy is measured on a batch of 128 elements at the end of each epoch), the training/validation loss, and to perform model selection using the measured validation accuracy and a new saver.</p>
<p class="mce-root"/>
<p><span><span>Y</span></span>ou are invited to analyze and run the complete example to completely understand how every presented object works in detail. For any additional tests, always keep the TensorFlow API reference and documentation open and try everything:</p>
<p><kbd>(tf1)</kbd></p>
<pre>def train():<br/>    input = tf.placeholder(tf.float32, (None, 28, 28, 1))<br/>    labels = tf.placeholder(tf.int64, (None,))<br/>    logits = define_cnn(input, 10, reuse=False, is_training=True)<br/>    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)<br/>    global_step = tf.train.get_or_create_global_step()<br/>    train_op = tf.train.AdamOptimizer().minimize(loss, global_step)<br/><br/>    writer = tf.summary.FileWriter("log/graph_loss", tf.get_default_graph())<br/>    validation_summary_writer = tf.summary.FileWriter(<br/>        "log/graph_loss/validation")<br/><br/>    init_op = tf.global_variables_initializer()<br/><br/>    predictions = tf.argmax(logits, 1)<br/>    # correct predictions: [BATCH_SIZE] tensor<br/>    correct_predictions = tf.equal(labels, predictions)<br/>    accuracy = tf.reduce_mean(<br/>        tf.cast(correct_predictions, tf.float32), name="accuracy")<br/><br/>    accuracy_summary = tf.summary.scalar("accuracy", accuracy)<br/>    loss_summary = tf.summary.scalar("loss", loss)<br/>    # Input preprocessing a Python stuff<br/>    (train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()<br/>    # Scale input in [-1, 1] range<br/>    train_x = train_x / 255. * 2 - 1<br/>    train_x = np.expand_dims(train_x, -1)<br/>    test_x = test_x / 255. * 2 - 1<br/>    test_x = np.expand_dims(test_x, -1)<br/><br/>    epochs = 10<br/>    batch_size = 32<br/>    nr_batches_train = int(train_x.shape[0] / batch_size)<br/>    print(f"Batch size: {batch_size}")<br/>    print(f"Number of batches per epoch: {nr_batches_train}")<br/><br/>    validation_accuracy = 0<br/>    saver = tf.train.Saver()<br/>    with tf.Session() as sess:<br/>        sess.run(init_op)<br/><br/>        for epoch in range(epochs):<br/>            for t in range(nr_batches_train):<br/>                start_from = t * batch_size<br/>                to = (t + 1) * batch_size<br/><br/>                loss_value, _, step = sess.run(<br/>                    [loss, train_op, global_step],<br/>                    feed_dict={<br/>                        input: train_x[start_from:to],<br/>                        labels: train_y[start_from:to]<br/>                    })<br/>                if t % 10 == 0:<br/>                    print(f"{step}: {loss_value}")<br/>            print(<br/>                f"Epoch {epoch} terminated: measuring metrics and logging summaries"<br/>            )<br/><br/>            saver.save(sess, "log/graph_loss/model")<br/>            start_from = 0<br/>            to = 128<br/>            train_accuracy_summary, train_loss_summary = sess.run(<br/>                [accuracy_summary, loss_summary],<br/>                feed_dict={<br/>                    input: train_x[start_from:to],<br/>                    labels: train_y[start_from:to]<br/>                })<br/><br/>            validation_accuracy_summary, validation_accuracy_value, validation_loss_summary = sess.run(<br/>                [accuracy_summary, accuracy, loss_summary],<br/>                feed_dict={<br/>                    input: test_x[start_from:to],<br/>                    labels: test_y[start_from:to]<br/>                })<br/><br/>            # save values in TensorBoard<br/>            writer.add_summary(train_accuracy_summary, step)<br/>            writer.add_summary(train_loss_summary, step)<br/><br/>            validation_summary_writer.add_summary(validation_accuracy_summary,<br/>                                                  step)<br/>            validation_summary_writer.add_summary(validation_loss_summary, step)<br/><br/>            validation_summary_writer.flush()<br/>            writer.flush()<br/><br/>            # model selection<br/>            if validation_accuracy_value &gt; validation_accuracy:<br/>                validation_accuracy = validation_accuracy_value<br/>                saver.save(sess, "log/graph_loss/best_model/best")<br/><br/>    writer.close()</pre>
<p>The result, as seen in TensorBoard, is shown in the following two screenshots. The first one shows that, by using two different writers, it is possible to write two different curves on the same plot; while the second one shows the graph tab:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-821 image-border" src="assets/45b985d8-952d-479c-bf17-40455e27ab0d.png" style="width:88.33em;height:55.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Using two <kbd>SummaryWriter</kbd>, it's possible to draw different curves <span>on the same plot</span>. The graph on top is the validation graph; the one on the bottom is the loss graph. Orange is the color of the training run, while blue is validation.</div>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-822 image-border" src="assets/76b43e22-a414-4379-b2a2-6768af93ee5e.png" style="width:40.50em;height:33.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The resulting graph—please note how proper use of the variable scopes makes the graph easy to read and understand</div>
<p>It is worth noting that, even if trained for only a few epochs, the model defined already reaches notable performance, although it should be clear from the accuracy plot that it suffers from overfitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we analyzed how TensorFlow works under the hood—the separation between the graph definition phase and its execution within a session, how to use the Python API to interact with a graph, and how to define a model and measure the metrics during training.</p>
<p class="mce-root"/>
<p>It's worth noting that this chapter analyzed how TensorFlow works in its static graph version, which is no longer the default in TensorFlow 2.0; however, the graph is still present and even when used in eager mode, every API call produces operations that can be executed inside a graph to speed up execution. As will be shown in the next chapter, TensorFlow 2.0 still allows models to be defined in static graph mode, especially when defining models using the Estimator API.</p>
<p>Having knowledge of graph representation is of fundamental importance, and having at least an intuitive idea about the advantages that representing computation using dataflow graphs brings should make it clear why TensorFlow scales so well, even in huge, complex environments such as Google data centers.</p>
<p>The exercise section is incredibly important—it asks you to solve problems not introduced in the previous sections because this is the only way to become familiar with the TensorFlow documentation and code base. Keep track of the time it takes you to solve every exercise and try to figure out the solution by yourself with only the help of the TensorFlow documentation and some Stack Overflow questions!</p>
<p>In the next chapter, <span><a href="655b734e-1636-4e11-b944-a71fafacb977.xhtml">Chapter 4</a>, </span><em>TensorFlow 2.0 Architecture</em><em>,</em> you'll deep dive into the TensorFlow 2.0 world: eager mode; automatic graph conversion; a better, cleaner code base; and a Keras-based approach.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercises</h1>
                </header>
            
            <article>
                
<ol>
<li>Why is it possible to assess that the model suffers from overfitting only by looking at the graph?</li>
<li>Extend the baseline example to place the matrix multiplication operation on a remote device at IP 192.168.1.12; visualize the result on TensorBoard.</li>
<li>Is it necessary to have a remote device to place an operation on?</li>
<li>Extend the CNN architecture defined in the <kbd>define_cnn</kbd> method: add a batch normalization layer (from <kbd>tf.layers</kbd>) between the output of the convolutional layer and its activation function.</li>
<li>Try to train the model with the extended CNN architecture: the batch normalization layer adds two update operations that must be executed before running the training operation. Become familiar with the <kbd>tf.control_dependencies</kbd><span> </span>method to force the execution of the operations contained inside the collection <kbd>tf.GraphKeys.UPDATE_OPS</kbd>, to be executed before the train operation (look at the documentation of <kbd>tf.control_dependencies</kbd><span> </span>and <kbd>tf.get_collection</kbd>!).</li>
</ol>
<ol start="6">
<li>Log the training and validation images in TensorBoard.</li>
<li>Has the model selection in the last example been performed <span>correctly </span>? Probably not. Extend the Python script to measure the accuracy on the complete dataset and not just a batch.</li>
<li>Replace the<span> </span>accuracy measurement performed manually with the accuracy operation provided in the <kbd>tf.metrics</kbd><span> </span>package.</li>
<li>Process the fashion-MNIST dataset and make it a binary dataset: all the items with a label different from 0 are now labeled as 1. The dataset is unbalanced now. Which metric should you use to measure the model performance and perform model selection? <span>Give reasons for</span> your answer<span> </span>(see<span> </span><a href="0dff1bba-f231-45fa-9a89-b4f127309579.xhtml">Chapter 1</a>, <em>What is Machine Learning?</em>) and implement the metric manually.</li>
<li>Replace the manually implemented metric using the same metric defined in the <kbd>tf.metrics</kbd><span> </span>package.</li>
</ol>


            </article>

            
        </section>
    </body></html>