- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book provides a summary of several different **reinforcement learning**
    (**RL**) algorithms, including the theory involved in the algorithms as well as
    coding them using Python and TensorFlow. Specifically, the algorithms covered
    in this book are Q-learning, SARSA, DQN, DDPG, A3C, TRPO, and PPO. The applications
    of these RL algorithms include computer games from OpenAI Gym and autonomous driving
    using the TORCS racing car simulator.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is designed for **machine learning** (**ML**) practitioners interested
    in learning RL. It will help ML engineers, data scientists, and graduate students.
    A basic knowledge of ML, and experience of coding in Python and TensorFlow, is
    expected of the reader in order to be able to complete this book successfully.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](eabadc99-98c0-4419-81fc-533264228962.xhtml), *Up and Running with
    Reinforcement Learning*, provides an overview of the basic concepts of RL, such
    as an agent, an environment, and the relationship between them. It also covers
    topics such as reward functions, discounted rewards, and value and advantage functions.
    The reader will also get familiar with the Bellman equation, on-policy and off-policy
    algorithms, as well as model-free and model-based RL algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](72e58e29-a6e5-46b4-9d3e-d1baf4dc57f5.xhtml), *Temporal Difference,
    SARSA, and Q-learning*, introduces the reader to temporal difference learning,
    SARSA, and Q-learning. It also summarizes how to code these algorithms in Python,
    and to train and test them on two classical RL problems – GridWorld and Cliff
    Walking.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](1bf60e32-a842-4f5c-b7be-c1dc50a43c1e.xhtml), *Deep Q-Network*,
    introduces the reader to the first deep RL algorithm of the book, DQN. It will
    also discuss how to code this in Python and TensorFlow. The code will then be
    used to train an RL agent to play *Atari Breakout*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](ac0b4811-f9fc-474c-b1d6-3f8a43dc018c.xhtml), *Double DQN, Dueling
    Architectures, and Rainbow*, builds on the previous chapter and extends it to
    double DQN. It also discusses dueling network architectures that involve value
    and advantage streams. These extensions will be coded in Python and TensorFlow,
    and will be used to train RL agents to play *Atari Breakout*. Finally, Google''s
    dopamine code will be introduced and will be used to train a Rainbow DQN agent.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](c74c5dbc-8070-48da-889b-c6b357e07b92.xhtml), *Deep Deterministic
    Policy Gradient*, is the first actor-critic algorithm of the book as well as the
    first RL algorithm for continuous control. It introduces policy gradients to the
    reader and discusses how to use it to train the policy for the actor. The chapter
    will code this algorithm using Python and TensorFlow and use it to train an agent
    to play the inverted pendulum problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](f9b2e0f4-90ce-4070-b030-b47339ca1aa8.xhtml), *Asynchronous Methods
    – A3C and A2C*, introduces the reader to the A3C algorithm, which is an asynchronous
    RL algorithm where one master processor will update the policy network, and multiple
    worker processors will use it to collect experience samples, which will be used
    to compute the policy gradients, and then passed on to the master processor. Also
    in this chapter, A3C will be used to train RL agents to play OpenAI Gym''s *CartPole*
    and *LunarLander*. Finally, A2C is also briefly introduced.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](7f55a061-06a5-4f69-ab05-4eff75c2dacd.xhtml), *Trust Region Policy
    Optimization and Proximal Policy Optimization*, discusses two RL algorithms based
    on the policy distribution ratio—TRPO and PPO. This chapter also discusses how
    to code PPO using Python and TensorFlow, and will use it to train an RL agent
    to solve the MountainCar problem in OpenAI Gym.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8](f4774497-444a-4174-b7d4-a8ef21928320.xhtml), *Deep RL Applied to
    Autonomous Driving*, introduces the reader to the TORCS racing car simulator,
    coding the DDPG algorithm for training an agent to drive a car autonomously. The
    code files for this chapter also include the PPO algorithm for the same TORCS
    problem, and is provided as an exercise for the reader.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reader is expected to have a good knowledge of ML algorithms, such as deep
    neural networks, convolutional neural networks, stochastic gradient descent, and
    Adam optimization. The reader is also expected to have hands-on coding experience
    in Python and TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packt.com/support](http://www.packt.com/support)
    and register to have the files emailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register at [www.packt.com](http://www.packt.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the SUPPORT tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Code Downloads & Errata.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  prefs: []
  type: TYPE_NORMAL
- en: WinRAR/7-Zip for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipeg/iZip/UnRarX for Mac
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7-Zip/PeaZip for Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for the book is also hosted on GitHub at **[https://github.com/PacktPublishing/TensorFlow-Reinforcement-Learning-Quick-Start-Guide](https://github.com/PacktPublishing/TensorFlow-Reinforcement-Learning-Quick-Start-Guide)**. In
    case there's an update to the code, it will be updated on the existing GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/9781789533583_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/9781789533583_ColorImages.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "Mount the downloaded `WebStorm-10*.dmg` disk image file as
    another disk in your system."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    screen. For example, words in menus or dialog boxes appear in the text like this.
    Here is an example: "Select System info from the Administration panel."'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings or important notes appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    mention the book title in the subject of your message and email us at `customercare@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packt.com/submit-errata](http://www.packt.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packt.com` with a link
    to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in, and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  prefs: []
  type: TYPE_NORMAL
- en: For more information about Packt, please visit [packt.com](http://www.packt.com/).
  prefs: []
  type: TYPE_NORMAL
