["```\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import clear_output\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns_colors = sns.color_palette('colorblind')\nfrom numpy.random import uniform, seed\nfrom scipy.interpolate import griddata\nfrom matplotlib.font_manager import FontProperties\nfrom sklearn.metrics import roc_curve \n```", "```\ndef one_hot_cat_column(feature_name, vocab):\n    return tf.feature_column.indicator_column(\n    tf.feature_column.categorical_column_with_vocabulary_list(feature_name,                                                               vocab)) \n```", "```\nxtrain = pd.read_csv('../input/hotel-booking-                              demand/hotel_bookings.csv')\nxtrain.head(3) \n```", "```\nxvalid = xtrain.loc[xtrain['reservation_status_date'] >= '2017-08-01']\nxtrain = xtrain.loc[xtrain['reservation_status_date'] < '2017-08-01'] \n```", "```\nytrain, yvalid = xtrain['is_canceled'], xvalid['is_canceled']\nxtrain.drop('is_canceled', axis = 1, inplace = True)\nxvalid.drop('is_canceled', axis = 1, inplace = True) \n```", "```\nxtrain.drop(['arrival_date_year','assigned_room_type', 'booking_changes', 'reservation_status', 'country', 'days_in_waiting_list'], axis =1, inplace = True)\nnum_features = [\"lead_time\",\"arrival_date_week_number\",               \n                \"arrival_date_day_of_month\",\n                \"stays_in_weekend_nights\",                   \n                \"stays_in_week_nights\",\"adults\",\"children\",\n                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n                \"required_car_parking_spaces\",                 \n                \"total_of_special_requests\", \"adr\"]\ncat_features = [\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n                \"distribution_channel\",\"reserved_room_type\",                  \n                \"deposit_type\",\"customer_type\"]\ndef one_hot_cat_column(feature_name, vocab):\n    return tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(                                                feature_name,\n                                                vocab))\nfeature_columns = []\nfor feature_name in cat_features:\n    # Need to one-hot encode categorical features.\n    vocabulary = xtrain[feature_name].unique()\n    feature_columns.append(one_hot_cat_column(feature_name, vocabulary))\nfor feature_name in num_features:\n    feature_columns.append(tf.feature_column.numeric_column(feature_name,\n                                           dtype=tf.float32)) \n```", "```\nNUM_EXAMPLES = len(ytrain)\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n\n    def input_fn():\n\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n        if shuffle:\n\n            dataset = dataset.shuffle(NUM_EXAMPLES)\n        # For training, cycle thru dataset as many times as need (n_epochs=None).\n        dataset = dataset.repeat(n_epochs)\n        # In memory training doesn't use batching.\n        dataset = dataset.batch(NUM_EXAMPLES)\n        return dataset\n    return input_fn\n# Training and evaluation input functions.\ntrain_input_fn = make_input_fn(xtrain, ytrain)\neval_input_fn = make_input_fn(xvalid, yvalid, shuffle=False,                                                 n_epochs=1) \n```", "```\nparams = {\n  'n_trees': 125,\n  'max_depth': 5,\n  'n_batches_per_layer': 1,\n  'center_bias': True\n}\nest = tf.estimator.BoostedTreesClassifier(feature_columns, **params)\n# Train model.\nest.train(train_input_fn, max_steps=100) \n```", "```\n# Evaluation\nresults = est.evaluate(eval_input_fn)\npd.Series(results).to_frame() \n```", "```\npred_dicts = list(est.predict(eval_input_fn))\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts]) \n```", "```\nfpr, tpr, _ = roc_curve(yvalid, probs)\nplt.plot(fpr, tpr)\nplt.title('ROC curve')\nplt.xlabel('false positive rate')\nplt.ylabel('true positive rate')\nplt.xlim(0,); plt.ylim(0,); plt.show() \n```", "```\npred_dicts = list(est.experimental_predict_with_explanations(eval_input_fn))\n# Create DFC Pandas dataframe.\nlabels = yvalid.values\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\ndf_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\ndf_dfc.describe().T \n```", "```\ndef _get_color(value):\n    \"\"\"To make positive DFCs plot green, negative DFCs plot red.\"\"\"\n    green, red = sns.color_palette()[2:4]\n    if value >= 0: return green\n    return red\ndef _add_feature_values(feature_values, ax):\n    \"\"\"Display feature's values on left of plot.\"\"\"\n    x_coord = ax.get_xlim()[0]\n    OFFSET = 0.15\n    for y_coord, (feat_name, feat_val) in enumerate(feature_values.                                                    items()):\n        t = plt.text(x_coord, y_coord - OFFSET, '{}'.format(feat_val),                                                     size=12)\n        t.set_bbox(dict(facecolor='white', alpha=0.5))\n    from matplotlib.font_manager import FontProperties\n    font = FontProperties()\n    font.set_weight('bold')\n    t = plt.text(x_coord, y_coord + 1 - OFFSET, 'feature\\nvalue',\n    fontproperties=font, size=12)\ndef plot_example(example):\n  TOP_N = 8 # View top 8 features.\n  sorted_ix = example.abs().sort_values()[-TOP_N:].index  # Sort by magnitude.\n  example = example[sorted_ix]\n  colors = example.map(_get_color).tolist()\n  ax = example.to_frame().plot(kind='barh',\n                          color=[colors],\n                          legend=None,\n                          alpha=0.75,\n                          figsize=(10,6))\n  ax.grid(False, axis='y')\n  ax.set_yticklabels(ax.get_yticklabels(), size=14)\n  # Add feature values.\n  _add_feature_values(xvalid.iloc[ID][sorted_ix], ax)\n  return ax \n```", "```\nID = 10\nexample = df_dfc.iloc[ID]  # Choose ith example from evaluation set.\nTOP_N = 8  # View top 8 features.\nsorted_ix = example.abs().sort_values()[-TOP_N:].index\nax = plot_example(example)\nax.set_title('Feature contributions for example {}\\n pred: {:1.2f}; label: {}'.format(ID, probs[ID], labels[ID]))\nax.set_xlabel('Contribution to predicted probability', size=14)\nplt.show() \n```", "```\ndef permutation_importances(est, X_eval, y_eval, metric, features):\n    \"\"\"Column by column, shuffle values and observe effect on eval set.\n    source: http://explained.ai/rf-importance/index.html\n    A similar approach can be done during training. See \"Drop-column importance\"\n    in the above article.\"\"\"\n    baseline = metric(est, X_eval, y_eval)\n    imp = []\n    for col in features:\n        save = X_eval[col].copy()\n        X_eval[col] = np.random.permutation(X_eval[col])\n        m = metric(est, X_eval, y_eval)\n        X_eval[col] = save\n        imp.append(baseline - m)\n    return np.array(imp)\ndef accuracy_metric(est, X, y):\n    \"\"\"TensorFlow estimator accuracy.\"\"\"\n    eval_input_fn = make_input_fn(X,\n                                  y=y,\n                                  shuffle=False,\n                                  n_epochs=1)\n    return est.evaluate(input_fn=eval_input_fn)['accuracy'] \n```", "```\nfeatures = CATEGORICAL_COLUMNS + NUMERIC_COLUMNS\nimportances = permutation_importances(est, dfeval, y_eval, accuracy_metric,\n                                      features)\ndf_imp = pd.Series(importances, index=features)\nsorted_ix = df_imp.abs().sort_values().index\nax = df_imp[sorted_ix][-5:].plot(kind='barh', color=sns_colors[2], figsize=(10, 6))\nax.grid(False, axis='y')\nax.set_title('Permutation feature importance')\nplt.show() \n```", "```\nimportances = est.experimental_feature_importances(normalize=True)\ndf_imp = pd.Series(importances)\n# Visualize importances.\nN = 8\nax = (df_imp.iloc[0:N][::-1]\n    .plot(kind='barh',\n          color=sns_colors[0],\n          title='Gain feature importances',\n          figsize=(10, 6)))\nax.grid(False, axis='y') \n```", "```\ndfc_mean = df_dfc.abs().mean()\nN = 8\nsorted_ix = dfc_mean.abs().sort_values()[-N:].index  # Average and sort by absolute.\nax = dfc_mean[sorted_ix].plot(kind='barh',\n                       color=sns_colors[1],\n                       title='Mean |directional feature contributions|',\n                       figsize=(10, 6))\nax.grid(False, axis='y') \n```"]