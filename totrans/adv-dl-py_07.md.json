["```\nimport matplotlib.pyplot as plt\nfrom matplotlib.markers import MarkerStyle\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Lambda, Input, Dense\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.models import Model\n```", "```\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nimage_size = x_train.shape[1] * x_train.shape[1]\nx_train = np.reshape(x_train, [-1, image_size])\nx_test = np.reshape(x_test, [-1, image_size])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n```", "```\ndef build_vae(intermediate_dim=512, latent_dim=2):\n   # encoder first\n    inputs = Input(shape=(image_size,), name='encoder_input')\n    x = Dense(intermediate_dim, activation='relu')(inputs)\n\n    # latent mean and variance\n    z_mean = Dense(latent_dim, name='z_mean')(x)\n    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n\n    # Reparameterization trick for random sampling\n    # Note the use of the Lambda layer\n    # At runtime, it will call the sampling function\n    z = Lambda(sampling, output_shape=(latent_dim,), \n    name='z')([z_mean, z_log_var])\n\n    # full encoder encoder model\n    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n    encoder.summary()\n\n    # decoder\n    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n    outputs = Dense(image_size, activation='sigmoid')(x)\n\n    # full decoder model\n    decoder = Model(latent_inputs, outputs, name='decoder')\n    decoder.summary()\n\n    # VAE model\n    outputs = decoder(encoder(inputs)[2])\n    vae = Model(inputs, outputs, name='vae')\n\n    # Loss function\n    # we start with the reconstruction loss\n    reconstruction_loss = binary_crossentropy(inputs, outputs) *\n    image_size\n\n    # next is the KL divergence\n    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n\n    # we combine them in a total loss\n    vae_loss = K.mean(reconstruction_loss + kl_loss)\n    vae.add_loss(vae_loss)\n\n    return encoder, decoder, vae\n```", "```\ndef sampling(args: tuple):\n    \"\"\"\n    :param args: (tensor, tensor) mean and log of variance of \n    q(z|x)\n    \"\"\"\n\n    # unpack the input tuple\n    z_mean, z_log_var = args\n\n    # mini-batch size\n    mb_size = K.shape(z_mean)[0]\n\n    # latent space size\n    dim = K.int_shape(z_mean)[1]\n\n    # random normal vector with mean=0 and std=1.0\n    epsilon = K.random_normal(shape=(mb_size, dim))\n\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n```", "```\ndef plot_latent_distribution(encoder, x_test, y_test, batch_size=128):\n    z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n    plt.figure(figsize=(6, 6))\n\n    markers = ('o', 'x', '^', '<', '>', '*', 'h', 'H', 'D', 'd',\n    'P', 'X', '8', 's', 'p')\n\n    for i in np.unique(y_test):\n        plt.scatter(z_mean[y_test == i, 0], z_mean[y_test == i, 1],\n                                marker=MarkerStyle(markers[i], \n                                fillstyle='none'),\n                                edgecolors='black')\n\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.show()\n```", "```\ndef plot_generated_images(decoder):\n    # display a nxn 2D manifold of digits\n    n = 15\n    digit_size = 28\n\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-4, 4, n)\n    grid_y = np.linspace(-4, 4, n)[::-1]\n\n    # start sampling z1 and z2 in the ranges grid_x and grid_y\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            slice_i = slice(i * digit_size, (i + 1) * digit_size)\n            slice_j = slice(j * digit_size, (j + 1) * digit_size)\n            figure[slice_i, slice_j] = digit\n\n    # plot the results\n    plt.figure(figsize=(6, 5))\n    start_range = digit_size // 2\n    end_range = n * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n   plt.imshow(figure, cmap='Greys_r')\n    plt.show()\n```", "```\nif __name__ == '__main__':\n    encoder, decoder, vae = build_vae()\n\n    vae.compile(optimizer='adam')\n    vae.summary()\n\n    vae.fit(x_train,\n            epochs=50,\n            batch_size=128,\n            validation_data=(x_test, None))\n\n    plot_latent_distribution(encoder, x_test, y_test,\n                                      batch_size=128)\n\n    plot_generated_images(decoder)\n```", "```\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import \\\n    Conv2D, Conv2DTranspose, BatchNormalization, Dropout, Input,\n    Dense, Reshape, Flatten\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\n```", "```\ndef build_generator(latent_input: Input):\n    model = Sequential([\n        Dense(7 * 7 * 256, use_bias=False,\n        input_shape=latent_input.shape[1:]),\n        BatchNormalization(), LeakyReLU(),\n\n        Reshape((7, 7, 256)),\n\n        # expand the input with transposed convolutions\n        Conv2DTranspose(filters=128, kernel_size=(5, 5), \n                        strides=(1, 1), \n                        padding='same', use_bias=False),\n        BatchNormalization(), LeakyReLU(),\n\n        # gradually reduce the volume depth\n        Conv2DTranspose(filters=64, kernel_size=(5, 5),\n                        strides=(2, 2),\n                        padding='same', use_bias=False),\n        BatchNormalization(), LeakyReLU(),\n\n        Conv2DTranspose(filters=1, kernel_size=(5, 5), \n                        strides=(2, 2), padding='same', \n                        use_bias=False, activation='tanh'),\n    ])\n\n    # this is forward phase\n    generated = model(latent_input)\n\n    return Model(z, generated)\n```", "```\ndef build_discriminator():\n    model = Sequential([\n        Conv2D(filters=64, kernel_size=(5, 5), strides=(2, 2),\n               padding='same', input_shape=(28, 28, 1)),\n        LeakyReLU(), Dropout(0.3),\n        Conv2D(filters=128, kernel_size=(5, 5), strides=(2, 2),\n               padding='same'),\n        LeakyReLU(), Dropout(0.3),\n        Flatten(),\n        Dense(1, activation='sigmoid'),\n    ])\n\n    image = Input(shape=(28, 28, 1))\n    output = model(image)\n\n    return Model(image, output)\n```", "```\ndef train(generator, discriminator, combined, steps, batch_size):\n    # Load the dataset\n    (x_train, _), _ = mnist.load_data()\n\n    # Rescale in [-1, 1] interval\n    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n    x_train = np.expand_dims(x_train, axis=-1)\n\n    # Discriminator ground truths\n    real = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n\n    latent_dim = generator.input_shape[1]\n```", "```\nfor step in range(steps):\n    # Train the discriminator\n\n    # Select a random batch of images\n    real_images = x_train[np.random.randint(0, x_train.shape[0],\n    batch_size)]\n\n    # Random batch of noise\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n\n    # Generate a batch of new images\n    generated_images = generator.predict(noise)\n\n    # Train the discriminator\n    discriminator_real_loss = discriminator.train_on_batch\n    (real_images, real)\n    discriminator_fake_loss = discriminator.train_on_batch\n    (generated_images, fake)\n    discriminator_loss = 0.5 * np.add(discriminator_real_loss,\n    discriminator_fake_loss)\n\n    # Train the generator\n    # random latent vector z\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n\n    # Train the generator\n    # Note that we use the \"valid\" labels for the generated images\n    # That's because we try to maximize the discriminator loss\n    generator_loss = combined.train_on_batch(noise, real)\n\n    # Display progress\n    print(\"%d [Discriminator loss: %.4f%%, acc.: %.2f%%] [Generator\n    loss: %.4f%%]\" % (step, discriminator_loss[0], 100 *\n    discriminator_loss[1], generator_loss))\n```", "```\ndef plot_generated_images(generator):\n    n = 10\n    digit_size = 28\n\n    # big array containing all images\n    figure = np.zeros((digit_size * n, digit_size * n))\n\n    latent_dim = generator.input_shape[1]\n\n    # n*n random latent distributions\n    noise = np.random.normal(0, 1, (n * n, latent_dim))\n\n    # generate the images\n    generated_images = generator.predict(noise)\n\n    # fill the big array with images\n    for i in range(n):\n        for j in range(n):\n            slice_i = slice(i * digit_size, (i + 1) * digit_size)\n            slice_j = slice(j * digit_size, (j + 1) * digit_size)\n            figure[slice_i, slice_j] = np.reshape\n                          (generated_images[i * n + j], (28, 28))\n\n    # plot the results\n    plt.figure(figsize=(6, 5))\n    plt.axis('off')\n    plt.imshow(figure, cmap='Greys_r')\n    plt.show()\n```", "```\nlatent_dim = 64\n\n# Build the generator\n# Generator input z\nz = Input(shape=(latent_dim,))\n\ngenerator = build_generator(z)\n\ngenerated_image = generator(z)\n\n# we'll use Adam optimizer\noptimizer = Adam(0.0002, 0.5)\n\n# Build and compile the discriminator\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy',\n                      optimizer=optimizer,\n                      metrics=['accuracy'])\n\n# Only train the generator for the combined model\ndiscriminator.trainable = False\n\n# The discriminator takes generated image as input and determines validity\nreal_or_fake = discriminator(generated_image)\n\n# Stack the generator and discriminator in a combined model\n# Trains the generator to deceive the discriminator\ncombined = Model(z, real_or_fake)\ncombined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\ntrain(generator, discriminator, combined, steps=50000, batch_size=100)\n\nplot_generated_images(generator)\n```", "```\ndef build_generator(z_input: Input, label_input: Input):\n    model = Sequential([\n        Dense(128, input_dim=latent_dim),\n        LeakyReLU(alpha=0.2), BatchNormalization(momentum=0.8),\n        Dense(256),\n        LeakyReLU(alpha=0.2), BatchNormalization(momentum=0.8),\n        Dense(512),\n        LeakyReLU(alpha=0.2), BatchNormalization(momentum=0.8),\n        Dense(np.prod((28, 28, 1)), activation='tanh'),\n        # reshape to MNIST image size\n        Reshape((28, 28, 1))\n    ])\n    model.summary()\n\n    # the latent input vector z\n    label_embedding = Embedding(input_dim=10, \n    output_dim=latent_dim)(label_input)\n    flat_embedding = Flatten()(label_embedding)\n\n    # combine the noise and label by element-wise multiplication\n    model_input = multiply([z_input, flat_embedding])\n    image = model(model_input)\n\n    return Model([z_input, label_input], image)\n```", "```\ndef build_discriminator():\n    model = Sequential([\n        Flatten(input_shape=(28, 28, 1)),\n        Dense(256),\n        LeakyReLU(alpha=0.2),\n        Dense(128),\n        LeakyReLU(alpha=0.2),\n        Dense(1, activation='sigmoid'),\n    ], name='discriminator')\n    model.summary()\n\n    image = Input(shape=(28, 28, 1))\n    flat_img = Flatten()(image)\n\n    label_input = Input(shape=(1,), dtype='int32')\n    label_embedding = Embedding(input_dim=10, output_dim=np.prod(\n    (28, 28, 1)))(label_input)\n    flat_embedding = Flatten()(label_embedding)\n\n    # combine the noise and label by element-wise multiplication\n    model_input = multiply([flat_img, flat_embedding])\n\n    validity = model(model_input)\n\n    return Model([image, label_input], validity)\n```", "```\ndef train(generator, critic, combined, steps, batch_size, n_critic, clip_value):\n    # Load the dataset\n    (x_train, _), _ = mnist.load_data()\n\n    # Rescale in [-1, 1] interval\n    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n\n    # We use FC networks, so we flatten the array\n    x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n\n    # Discriminator ground truths\n    real = np.ones((batch_size, 1))\n    fake = -np.ones((batch_size, 1))\n\n    latent_dim = generator.input_shape[1]\n```", "```\n    for step in range(steps):\n        # Train the critic first for n_critic steps\n        for _ in range(n_critic):\n            # Select a random batch of images\n            real_images = x_train[np.random.randint(0, x_train.shape[0], \n            batch_size)]\n\n            # Sample noise as generator input\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n\n            # Generate a batch of new images\n            generated_images = generator.predict(noise)\n\n            # Train the critic\n            critic_real_loss = critic.train_on_batch(real_images, real)\n            critic_fake_loss = critic.train_on_batch(generated_images,\n            fake)\n            critic_loss = 0.5 * np.add(critic_real_loss, critic_fake_loss)\n\n            # Clip critic weights\n            for l in critic.layers:\n                weights = l.get_weights()\n                weights = [np.clip(w, -clip_value, clip_value) for w in\n                weights]\n                l.set_weights(weights)\n\n        # Train the generator\n        # Note that we use the \"valid\" labels for the generated images\n        # That's because we try to maximize the discriminator loss\n        generator_loss = combined.train_on_batch(noise, real)\n\n        # Display progress\n        print(\"%d [Critic loss: %.4f%%] [Generator loss: %.4f%%]\" %\n              (step, critic_loss[0], generator_loss))\n```", "```\ndef wasserstein_loss(y_true, y_pred):\n    \"\"\"The Wasserstein loss implementation\"\"\"\n    return tensorflow.keras.backend.mean(y_true * y_pred)\n```", "```\nlatent_dim = 100\n\n# Build the generator\n# Generator input z\nz = Input(shape=(latent_dim,))\n\ngenerator = build_generator(z)\n\ngenerated_image = generator(z)\n\n# we'll use RMSprop optimizer\noptimizer = RMSprop(lr=0.00005)\n\n# Build and compile the discriminator\ncritic = build_critic()\ncritic.compile(optimizer, wasserstein_loss,\n               metrics=['accuracy'])\n\n# The discriminator takes generated image as input and determines validity\nreal_or_fake = critic(generated_image)\n\n# Only train the generator for the combined model\ncritic.trainable = False\n\n# Stack the generator and discriminator in a combined model\n# Trains the generator to deceive the discriminator\ncombined = Model(z, real_or_fake)\ncombined.compile(loss=wasserstein_loss, optimizer=optimizer)\n```", "```\n# train the GAN system\ntrain(generator, critic, combined,\n      steps=40000, batch_size=100, n_critic=5, clip_value=0.01)\n\n# display some random generated images\nplot_generated_images(generator)\n```", "```\ndef build_generator(img: Input) -> Model:\n```", "```\n    def downsampling2d(layer_input, filters: int):\n        \"\"\"Layers used in the encoder\"\"\"\n        d = Conv2D(filters=filters,\n                   kernel_size=4,\n                   strides=2,\n                   padding='same')(layer_input)\n        d = LeakyReLU(alpha=0.2)(d)\n        d = InstanceNormalization()(d)\n        return d\n```", "```\n    def upsampling2d(layer_input, skip_input, filters: int):\n        \"\"\"\n        Layers used in the decoder\n        :param layer_input: input layer\n        :param skip_input: another input from the corresponding encoder block\n        :param filters: number of filters\n        \"\"\"\n        u = UpSampling2D(size=2)(layer_input)\n        u = Conv2D(filters=filters,\n                   kernel_size=4,\n                   strides=1,\n                   padding='same',\n                   activation='relu')(u)\n        u = InstanceNormalization()(u)\n        u = Concatenate()([u, skip_input])\n        return u\n```", "```\n    # Encoder\n    gf = 32\n    d1 = downsampling2d(img, gf)\n    d2 = downsampling2d(d1, gf * 2)\n    d3 = downsampling2d(d2, gf * 4)\n    d4 = downsampling2d(d3, gf * 8)\n\n    # Decoder\n    # Note that we concatenate each upsampling2d block with\n    # its corresponding downsampling2d block, as per U-Net\n    u1 = upsampling2d(d4, d3, gf * 4)\n    u2 = upsampling2d(u1, d2, gf * 2)\n    u3 = upsampling2d(u2, d1, gf)\n\n    u4 = UpSampling2D(size=2)(u3)\n    output_img = Conv2D(3, kernel_size=4, strides=1, padding='same',\n    activation='tanh')(u4)\n\n    model = Model(img, output_img)\n\n    model.summary()\n\n    return model\n```", "```\n# Input shape\nimg_shape = (IMG_SIZE, IMG_SIZE, 3)\n\n# Configure data loader\ndata_loader = DataLoader(dataset_name='facades',\n                         img_res=(IMG_SIZE, IMG_SIZE))\n```", "```\nlambda_cycle = 10.0  # Cycle-consistency loss\nlambda_id = 0.1 * lambda_cycle  # Identity loss\n\noptimizer = Adam(0.0002, 0.5)\n```", "```\n# Build and compile the discriminators\nd_X = build_discriminator(Input(shape=img_shape))\nd_Y = build_discriminator(Input(shape=img_shape))\nd_X.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\nd_Y.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n\n# Build the generators\nimg_X = Input(shape=img_shape)\ng_XY = build_generator(img_X)\n\nimg_Y = Input(shape=img_shape)\ng_YX = build_generator(img_Y)\n\n# Translate images to the other domain\nfake_Y = g_XY(img_X)\nfake_X = g_YX(img_Y)\n\n# Translate images back to original domain\nreconstr_X = g_YX(fake_Y)\nreconstr_Y = g_XY(fake_X)\n\n# Identity mapping of images\nimg_X_id = g_YX(img_X)\nimg_Y_id = g_XY(img_Y)\n\n# For the combined model we will only train the generators\nd_X.trainable = False\nd_Y.trainable = False\n\n# Discriminators determines validity of translated images\nvalid_X = d_X(fake_X)\nvalid_Y = d_Y(fake_Y)\n\n# Combined model trains both generators to fool the two discriminators\ncombined = Model(inputs=[img_X, img_Y],\n                 outputs=[valid_X, valid_Y,\n                          reconstr_X, reconstr_Y,\n                          img_X_id, img_Y_id])\n```", "```\ncombined.compile(loss=['mse', 'mse',\n                       'mae', 'mae',\n                       'mae', 'mae'],\n                 loss_weights=[1, 1,\n                               lambda_cycle, lambda_cycle,\n                               lambda_id, lambda_id],\n                 optimizer=optimizer)\n```", "```\ntrain(epochs=200, batch_size=1, data_loader=data_loader,\n      g_XY=g_XY,\n      g_YX=g_YX,\n      d_X=d_X,\n      d_Y=d_Y,\n      combined=combined,\n      sample_interval=200)\n```", "```\ndef train(epochs: int, data_loader: DataLoader,\n          g_XY: Model, g_YX: Model, d_X: Model, d_Y: Model, \n          combined:Model, batch_size=1, sample_interval=50):\n    start_time = datetime.datetime.now()\n\n    # Calculate output shape of D (PatchGAN)\n    patch = int(IMG_SIZE / 2 ** 4)\n    disc_patch = (patch, patch, 1)\n\n    # GAN loss ground truths\n    valid = np.ones((batch_size,) + disc_patch)\n    fake = np.zeros((batch_size,) + disc_patch)\n\n    for epoch in range(epochs):\n        for batch_i, (imgs_X, imgs_Y) in\n        enumerate(data_loader.load_batch(batch_size)):\n            # Train the discriminators\n\n            # Translate images to opposite domain\n            fake_Y = g_XY.predict(imgs_X)\n            fake_X = g_YX.predict(imgs_Y)\n\n            # Train the discriminators (original images = real /\n            translated = Fake)\n            dX_loss_real = d_X.train_on_batch(imgs_X, valid)\n            dX_loss_fake = d_X.train_on_batch(fake_X, fake)\n            dX_loss = 0.5 * np.add(dX_loss_real, dX_loss_fake)\n\n            dY_loss_real = d_Y.train_on_batch(imgs_Y, valid)\n            dY_loss_fake = d_Y.train_on_batch(fake_Y, fake)\n            dY_loss = 0.5 * np.add(dY_loss_real, dY_loss_fake)\n\n            # Total discriminator loss\n            d_loss = 0.5 * np.add(dX_loss, dY_loss)\n\n            # Train the generators\n            g_loss = combined.train_on_batch([imgs_X, imgs_Y],\n                                             [valid, valid,\n                                              imgs_X, imgs_Y,\n                                              imgs_X, imgs_Y])\n\n            elapsed_time = datetime.datetime.now() - start_time\n\n            # Plot the progress\n            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%]\n            [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\ \n            % (epoch, epochs, batch_i, data_loader.n_batches, d_loss[0], \n            100 * d_loss[1], g_loss[0], np.mean(g_loss[1:3]),\n            np.mean(g_loss[3:5]), np.mean(g_loss[5:6]), elapsed_time))\n\n            # If at save interval => save generated image samples\n            if batch_i % sample_interval == 0:\n                sample_images(epoch, batch_i, g_XY, g_YX, data_loader)\n```"]