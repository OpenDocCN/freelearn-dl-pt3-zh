["```\nhping3 -c 10000 -d 120 -S -w 64 -p 21 --flood --rand-source example.com\n\n```", "```\n#Importing all the required Libraries\nimport pandas as pd\nIDSdata = pd.read_csv(\"kddcup.data_10_percent.csv\",header = None,engine = 'python',sep=\",\")\n\n# Add column header\nIDSdata.columns = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragement\",\"urgent\",               \"hot\",\"num_failed_logins\",\"logged_in\",\"num_compressed\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\", \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_hot_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\"]\n\n# Explore the Application Layer IDS Data\nApplicationLayer = IDSdata[(IDSdata['labels'].isin(['normal.','smurf.','back.','satan.','pod.','guess_passwd.','buffer_overflow.','warezmaster.','imap.','loadmodule.','ftp_write.','multihop.','perl.']))]\nprint (ApplicationLayer['labels'].value_counts())\n\n# Save a Applayer data only into a text file\nApplicationLayer.to_csv('Final_App_Layer.txt',header = None,index = False)\n\n# Explore the Transport Layer IDS Data\nTransportLayer = IDSdata[(IDSdata['labels'].isin(['normal.','neptune.','portsweep.','teardrop.','buffer_overflow.','land.','nmap.']))]\nprint (TransportLayer['labels'].value_counts())\nTransportLayer.to_csv('Final_Transport_Layer.txt',header = None,index = False)\n\n# Explore the Network Layer IDS Data\nNetworkLayer = IDSdata[(IDSdata['labels'].isin(['normal.','smurf.','ipsweep.','pod.','buffer_overflow.']))]\nprint (NetworkLayer['labels'].value_counts())\nNetworkLayer.to_csv('Final_Network_Layer.txt',header = None,index = False)\n```", "```\ndef DataPreprocessing(IDSdataframe):\n # Duplicate entry removal\n    recordcount = len(IDSdataframe)\n    print (\"Original number of records in the training dataset before removing duplicates is: \" , recordcount)\n    IDSdataframe.drop_duplicates(subset=None, inplace=True)  # Python command to drop duplicates\n    newrecordcount = len(IDSdataframe)\n    print (\"Number of records in the training dataset after removing the duplicates is :\", newrecordcount,\"\\n\")\n\n    #Dropping the labels to a different dataset which is used to train the recurrent neural network classifier\n    df_X = IDSdataframe.drop(IDSdataframe.columns[41],axis=1,inplace = False)\n    df_Y = IDSdataframe.drop(IDSdataframe.columns[0:41],axis=1, inplace = False)\n\n    # Categorial data to numerical data conversion\n    df_X[df_X.columns[1:4]] = df_X[df_X.columns[1:4]].stack().rank(method='dense').unstack()\n\n    # Coding the normal as \" 1 0\" and attack as \"0 1\"\n    df_Y[df_Y[41]!='normal.'] = 0\n    df_Y[df_Y[41]=='normal.'] = 1\n\n    #converting input data into float\n    df_X = df_X.loc[:,df_X.columns[0:41]].astype(float)\n\n    # Normal is \"1 0\" and the attack is \"0 1\"\n    df_Y.columns = [\"y1\"]\n    df_Y.loc[:,('y2')] = df_Y['y1'] ==0\n    df_Y.loc[:,('y2')] = df_Y['y2'].astype(int)\n    return df_X,df_Y\n```", "```\ndef FeatureSelection(myinputX, myinputY):\n    labels = np.array(myinputY).astype(int)\n    inputX = np.array(myinputX)\n\n    #Random Forest Model\n    model = RandomForestClassifier(random_state = 0)\n    model.fit(inputX,labels)\n    importances = model.feature_importances\n\n    #Plotting the Features agains their importance scores\n    indices = np.argsort(importances)[::-1]\n    std = np.std([tree.feature_importances_ for tree in model.estimators_],\naxis=0)            \n    plt.figure(figsize = (10,5))\n    plt.title(\"Feature importances (y-axis) vs Features IDs(x-axis)\")\n    plt.bar(range(inputX.shape[1]), importances[indices],\n       color=\"g\", yerr=std[indices], align=\"center\")\n    plt.xticks(range(inputX.shape[1]), indices)\n    plt.xlim([-1, inputX.shape[1]])\n    plt.show()\n\n    # Selecting top featueres which have higher importance values\n    newX = myinputX.iloc[:,model.feature_importances_.argsort()[::-1][:10]]\n\n   # Converting the dataframe into tensors\n    myX = newX.as_matrix()\n    myY = labels\n    return myX,myY\n```", "```\npython lstm_anomaly_detection.py \n```", "```\npython IDS_AutoEncoder_KDD.py\n```", "```\npython DNN-KDD-Overall.py\n```", "```\ntensorboard --logdir logs\n```"]