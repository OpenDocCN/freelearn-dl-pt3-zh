- en: Network Anomaly Detection with AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The current level of interconnection that can be established between different
    devices (for example, think of the **Internet of Things** (**IoT**)) has reached
    such a complexity that it seriously questions the effectiveness of traditional
    concepts such as perimeter security. As a matter of fact, cyberspace's attack
    surface grows exponentially, and it is therefore essential to resort to automated
    tools for the effective detection of network anomalies associated with unprecedented
    cybersecurity threats.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Network anomaly detection techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to classify network attacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting botnet topology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different **machine learning** (**ML**) algorithms for botnet detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will focus on anomaly detection related to network security,
    postponing the discussion of the aspects of fraud detection and user anomaly behavior
    detection until the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Network anomaly detection techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The techniques we have seen so far can also be adopted to manage anomaly detection
    and related attempts to gain unauthorized access to the corporate network. To
    fully understand the potential of anomaly detection techniques, we will trace
    its evolution in the cybersecurity area, illustrating the basic principles that
    characterize it.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, anomaly detection has always been a research area of cybersecurity,
    particularly in the field of network security protection. However, anomaly detection
    is not limited to identifying and preventing network attacks, but can also be
    adopted in other areas, such as fraud detection and in the identification of possible
    compromises of user profiles.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection rationales
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the area of ​​network intrusion detection in particular, the following two
    different approaches have been followed over time:'
  prefs: []
  type: TYPE_NORMAL
- en: Signature-based detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first case, we start from the analysis of attacks that are already known,
    building a knowledge base of signatures of attacks that were previously detected.
    This gets combined with an alert system to be launched whenever a correspondence
    with archived signatures is detected in the network traffic. The analogies of
    signature-based detection systems with various antivirus software are obvious,
    and the disadvantages are equally evident, hence the knowledge base of the signatures
    must be constantly updated to detect new types of attacks.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of anomaly detection, on the other hand, an attempt is made to identify
    network traffic behavior that can be defined as **normal**, in order to detect
    differences in behavior that deviate from normality as **anomalous**. This approach,
    therefore, makes it possible to detect the new types of attack by analyzing the
    characteristics of network traffic that could be considered as anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it will be necessary to identify what constitutes **abnormal behavior** in
    terms of network traffic.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to detect anomalous traffic, some elements that can be taken into
    consideration are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of connections to and from a specific host
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unusual remote communication ports or unexpected traffic patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unusual traffic peaks occurring at particular times of the day (for example,
    traffic carrying on during the night)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication bandwidth heavily occupied by particular hosts within the network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these events may be considered as suspicious on the basis of the analysis
    previously conducted with respect to the network traffic that was regarded as
    normal. The basis of this comparison is that it is possible to define appropriate
    filters and associate alarm signals (alerts) with them, which, once triggered,
    can even determine the dropping of the corresponding network traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, it will also be necessary to take into account novelties in the network
    traffic that are not associated with suspicious behavior. If, for example, a new
    communication channel has been added that did not exist before, this change will
    have to be taken into account, and considered as normal.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, one of the sensitive aspects of anomaly detection, as we will see,
    is the distinction between true positives and false positives.
  prefs: []
  type: TYPE_NORMAL
- en: Intrusion Detection Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Traditionally, intrusion detection activity has been managed through the introduction
    of specialized devices, known as **Intrusion Detection Systems** (**IDS**). These
    devices were usually divided into the following two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Host-based IDS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network-based IDS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With the introduction of **Artificial Intelligence** (**AI**) techniques in
    the field of cybersecurity, a third type of IDS has also been added to the aforementioned
    two traditional types: anomaly-driven IDS.'
  prefs: []
  type: TYPE_NORMAL
- en: To fully understand the differences and advantages of anomaly-driven IDS, it
    is appropriate to briefly describe the two traditional types of IDS.
  prefs: []
  type: TYPE_NORMAL
- en: Host Intrusion Detection Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The task of **Host Intrusion Detection Systems** (**HIDS**) is to detect possible
    intrusions affecting host machines within an organization, especially the machines
    that are considered critical. To this end, HIDS monitors some of the system metrics
    that are supposed to be significant for identifying possible attacks, such as
    system information associated with the following system metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Number and type of running processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number, type, and creation of user accounts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kernel modules loading (device drivers included)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: File and directory activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task scheduler activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Registry key modification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Background processes (daemons and services)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operating system** (**OS**) modules loaded at startup'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Host network activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typically, the identification of the system metrics to be monitored is strictly
    dependent on the adopted threat model, and in order to collect the information
    to be monitored, it is possible to use the tools that come installed with the
    OS of the host machines, or by installing specialized system monitoring tools.
  prefs: []
  type: TYPE_NORMAL
- en: Network Intrusion Detection Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The typical task of **Network Intrusion Detection Systems** (**NIDS**) is to
    identify possible attack patterns by analyzing network traffic; that is, by processing
    network packets in transit—both incoming and outgoing—and detecting known attacking
    patterns in the flow of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the network attacks typically detected by NIDS are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Adware (resulting in unsolicited and malicious **advertisements** (**AD**) downloads
    from remote hosts)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spyware (sensitive information transmitted toward remote hosts)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Advanced Persistent Threats** (**APTs**) (APT-targeted attacks that leverage
    specific organization flaws or misconfigured services)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Botnets (a typical **Command and Control** (**C2**) attack that leverages organization
    network resources by transforming hosts into zombie machines, executing remote
    instructions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The implementation of NIDS can leverage network diagnostic tools including sniffers
    (such as `tcpdump` and Wireshark).
  prefs: []
  type: TYPE_NORMAL
- en: NIDS can also deploy integrated software solutions, such as Snort, which represents
    a valid solution for real-time detection of possible network intrusions.
  prefs: []
  type: TYPE_NORMAL
- en: This helps to define ad hoc rules on the basis of which to make comparisons
    between normal and malicious network traffic, thus activating triggers that perform
    the appropriate actions once the attack is identified.
  prefs: []
  type: TYPE_NORMAL
- en: Often, these triggers are associated with a given threshold, which is a predetermined
    value that reliably separates the events among them. Obviously, the problem of
    how to adequately determine this threshold value arises, and whether this value
    can be validly used in relation to different contexts. In the same way, an attacker
    could try to modify this threshold value, or discover what this value actually
    is set to, try to adopt a stealth-access mode (by keeping their activity constantly
    below the threshold), and make themselves invisible to IDS.
  prefs: []
  type: TYPE_NORMAL
- en: It would therefore be preferable to adopt a dynamic threshold (rather than relying
    on a hardcoded value) by systematically recalculating its value over time. These
    improvements can be obtained by resorting to statistical metrics, calculated on
    a time series (moving averages), for example, or through the re-elaboration of
    statistical measurements made on the distribution of the data (for example, adopting
    position measurements such as the median or the **interquartile range** (**IQR**)).
  prefs: []
  type: TYPE_NORMAL
- en: Although useful, this statistical approach for determining the trigger threshold
    is inevitably ineffective in the most complex cases of intrusion detection, which
    needs to take into account the possible correlations existing between the various
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, it is likely that in certain scenarios, the trigger thresholds
    to be triggered simultaneously are more than one, since the anomalies are represented
    by different features in relation to each other.
  prefs: []
  type: TYPE_NORMAL
- en: Given the complexity that characterizes the network data flow, it is therefore
    necessary to introduce the **stateful inspection**—also known as **Packet Filtering**
    activity—as separate from the common network monitoring (aimed at extracting information
    from different types of packets).
  prefs: []
  type: TYPE_NORMAL
- en: By keeping track of the various packets being transferred and received, the
    stateful inspection is characterized by the ability to correlate different types
    of packets in order to identify connection attempts toward certain network services,
    attempts to saturate network resources (**Denial of Service** (**DoS**)), or attacks
    conducted at the lower network protocol levels (such as ARP cache poisoning).
  prefs: []
  type: TYPE_NORMAL
- en: Given its advanced network analysis features, stateful inspection can be associated
    with more sophisticated forms of anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly-driven IDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the introduction of AI techniques to the field of NIDS, it is now possible
    to evolve traditional IDS toward more advanced detection solutions, exploiting
    supervised and unsupervised learning algorithms, as well as reinforcement learning
    and deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the clustering techniques analyzed in the previous chapters, which
    exploit the concepts of similarity between the categories of data, can validly
    be used for the implementation of anomaly-based IDS.
  prefs: []
  type: TYPE_NORMAL
- en: 'In choosing the algorithms for the anomaly detection network, however, some
    characteristic aspects of the network environment must be taken into consideration:'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of solutions based on supervised learning algorithms, we will have
    to categorize (label) all the data since, by definition, in supervised learning
    the classes to which sample data belongs are known in advance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The categorization of all the data inevitably involves a computational overload
    and a possible slowdown in the network performance, since the network traffic
    must be analyzed before being sent to the destination. In this sense, we could
    decide to resort to unsupervised learning algorithms, not only to let the algorithm
    identify unknown classes, but also to reduce the computational overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, the algorithms that exploit the concept of similarity (such as clustering
    algorithms) are well suited for the implementation of anomaly detection solutions.
    However, it is also necessary in this case to pay particular attention to the
    type of metrics used to define the concept of similarity that distinguishes the
    traffic considered as normal from that being considered as anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: 'Commonly, in the implementation of anomaly detection solutions, scoring systems
    are used for the assessment of traffic: identifying thresholds of values ​​that
    separate the different types of traffic from each other (normal versus anomalous).
    For this purpose, when choosing the most appropriate metrics, we must take into
    consideration the ordering and distribution of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, an anomaly detection system can use—as a scoring metric—the
    distance existing between the values ​​of the dataset (considered as points of
    the *n*-dimensional space representing the different features), or evaluate the
    regularity in the distribution of data, with respect to a distribution considered
    representative of the phenomenon under investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Turning service logs into datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the problems related to network anomaly detection is how to collect sufficient
    and reliable data to perform algorithm analysis and training. There are hundreds
    of datasets freely available on the internet, and there are different datasets
    on which to carry out our analysis; however, it is also possible to use our own
    network devices to accumulate data that is more representative of our specific
    reality.
  prefs: []
  type: TYPE_NORMAL
- en: 'To this end, we can use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Network devices, such as routers or network sensors, using tools such as `tcpdump`
    for data collection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services logs and system logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Within the operating system, services logs and system logs can be stored in
    various places. In the case of a Unix-like system, the services logs are usually
    stored as text files inside the `/var/log` directory and its relative subdirectories.
    In the case of Windows OSes, logs are distinguished between Windows logs (including
    security logs and system logs) and application logs. They are accessible through
    the Windows Event Viewer application, or by accessing file system locations such
    as `%SystemRoot%\System32\Config`.
  prefs: []
  type: TYPE_NORMAL
- en: In both the cases of Unix-like systems and Windows OSes, the log files are of
    a text-based format according to predefined templates, with the difference being
    that, in the case of Windows, an event ID is also associated with each event recorded
    in the corresponding log file. The textual nature of the logs files is well suited
    for the integration of the information stored in the logs.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of integrating network data with service logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Both data sources, that is, network data and services logs, entail advantages
    and disadvantages for the purposes of network anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: However, their integration makes it possible to limit the disadvantages in favor
    of the advantages.
  prefs: []
  type: TYPE_NORMAL
- en: It is no coincidence that in recent years, several software solutions (both
    proprietary and open source) have been released to solve the task of integrating
    different data sources, allowing users to utilize methods of analysis from data
    science and big data analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Among the most widespread solutions, we can mention the **ElasticSearch, Logstash,
    Kibana** (**ELK**) suite, which allows the indexing of events extracted from log
    files and can be represented in an intuitive visual form.
  prefs: []
  type: TYPE_NORMAL
- en: Other widespread proprietary networking solutions are based on Cisco's NetFlow
    protocol, which allows for a compact representation of network traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Reconstructing the events of interest starting from the raw data is anything
    but easy. This moreover lends itself—if carried out in an automated manner—to
    the generation of unreliable signals (false positives) that represent a problem
    in the management of security.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, in the case of network data, they are representative of the individual
    services to which they refer, while in the case of service logs, they are directly
    related to the processes that generated them.
  prefs: []
  type: TYPE_NORMAL
- en: The integration of both data sources (network data and service logs) therefore
    allows for a contextualization of the events being analyzed, consequently increasing
    contextual awareness, and reducing the effort required for interpreting events
    when starting from raw data.
  prefs: []
  type: TYPE_NORMAL
- en: How to classify network attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen that it is possible to use all different types of algorithms (such
    as supervised, unsupervised, and reinforcement learning), even in the implementation
    of network anomaly detection systems.
  prefs: []
  type: TYPE_NORMAL
- en: But how can we effectively train these algorithms in order to identify the anomalous
    traffic?
  prefs: []
  type: TYPE_NORMAL
- en: It will be necessary to first identify a training dataset that is representative
    of the traffic considered normal within a given organization.
  prefs: []
  type: TYPE_NORMAL
- en: To this end, we will have to adequately choose the representative features of
    our model.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of features is of particular importance, as they provide a contextual
    value to the analyzed data, and consequently determine the reliability and accuracy
    of our detection system.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, choosing features that are not characterized by high correlation with
    possible anomalous behaviors translates into high error rates (false positives),
    which therefore invalidate their usefulness.
  prefs: []
  type: TYPE_NORMAL
- en: A solution to choosing reliable features could be to evaluate existing anomalies
    in the use of network protocols.
  prefs: []
  type: TYPE_NORMAL
- en: Attacks—such as SYN floods—are characterized by the anomalous use of the TCP/IP
    handshake (in which the packet with the SYN flag set is not followed by packets
    with the ACK flag set, in order to establish a valid connection).
  prefs: []
  type: TYPE_NORMAL
- en: A feature can be characterized by one or more attributes related to the protocol
    or the header of the network packet, just as different types of network attributes
    constitute a feature represented by the specific network connection being analyzed
    (that is, a telnet session is characterized by a connection to a remote port `23`,
    which is carried out between two endpoints having their respective IP addresses
    and IP ports).
  prefs: []
  type: TYPE_NORMAL
- en: Most common network attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given the enormous variety of combinations that we can identify by putting together
    different features, it is inevitable that we have to resort to a threat model
    that reflects the level of risk to which a given organization is subjected, and
    on the basis of this model, to identify the most representative feature of combinations
    for possible attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this sense, it can be useful to analyze which are the most frequent types
    of network attacks:'
  prefs: []
  type: TYPE_NORMAL
- en: Malware-based
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-day exploits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data exfiltration via network sniffing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saturation of network resources (DoS)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Session hijacking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection spoofing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Port scanning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the basis of a similar classification (to be adapted to the specific context
    and constantly updated), we can identify which features to consider, feeding our
    algorithms with more representative datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have therefore seen that the very concept of anomaly detection refers to
    a behavior that is different from what was expected; this difference, in technical
    terms, translates into outlier detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'To identify the outliers, it is possible to follow different strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Analyzing a sequence of events within a time series**: The data is collected
    at regular intervals, evaluating the changes that occur in the series over time.
    This is a technique widely used in the analysis of financial markets, but it can
    be also validly used in the cybersecurity context to detect the frequency of characters
    (or commands) entered by the user in a remote session. Even the simple unnatural
    increase in the frequency of data entered per unit of time is indicative of an
    anomaly that can be traced back to the presence of an automated agent (instead
    of a human user) in the remote endpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using supervised learning algorithms**: This approach makes sense when normal
    and anomalous behaviors can be reliably distinguished from each other, as in the
    case of credit card fraud, in which it is possible to detect predefined patterns
    of suspicious behavior, relying on the fact that future fraud attempts are attributable
    to a predefined scheme.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using unsupervised learning algorithms**: In this case, it is not possible
    to trace the anomalies back to predefined behaviors, as it is not possible to
    identify a reliable and representative training dataset for supervised learning.
    This scenario is the one that most commonly describes the reality of cybersecurity,
    characterized by new forms of attack or exploits of new vulnerabilities (zero-day
    attacks). Similarly, it is often difficult to trace all the theoretically possible
    intrusions back to a single predefined scheme.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection assumptions and challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From a methodological point of view, there is no doubt that outliers represent
    a problem for learning algorithms, as they constitute a disturbing element in
    the identification of a descriptive model, starting from training data.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with an anomalous value, how should the algorithm behave? Should
    it take into account the determination of the model or should it discard it, considering
    it as an estimation error? Or do the outliers represent novelties in the dataset
    that testify to real changes in the phenomenon being under scrutiny? To answer
    these questions, we need to investigate the most probable origin of the outliers.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the outliers are a combination of uncommon values, they are estimate
    errors, or they originate from the joining of multiple datasets with different
    semantics that produce unreliable or highly unlikely samples. Their presence,
    however, represents a disturbing element, especially for the algorithms that are
    based on metrics consisting of estimating the distances between expected values
    ​​and observed values. In technical terms, this implies an increase in overall
    variance that can cause the algorithm to overestimate the error to the detriment
    of the signal (a well-known phenomenon that goes by the name of **overfitting**).
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, not all algorithms are equally sensitive to the presence of outliers.
    However, it is good practice to try to make the learning process robust, smoothing
    the parameter-updating phase, weighting those anomalous values that, even if lower
    in numerical terms with respect to normal values, might otherwise affect the correct
    parameters estimation.
  prefs: []
  type: TYPE_NORMAL
- en: To identify the possible presence of outliers within the dataset, it is good
    practice to conduct a preliminary analysis of the data, known as **exploratory
    data analysis** (**EDA**), using visual tools and calculating simple descriptive
    statistical measurements (such as the average or the median).
  prefs: []
  type: TYPE_NORMAL
- en: In this way, it is possible to intuitively spot the presence of anomalous values,
    in addition to verifying any asymmetries in the data, evidenced by the increasing
    distance between the values ​​of the average and the median in the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Some statistical measurements are less sensitive to the presence of extreme
    values. The measures aimed at representing the ordering of the data are, in fact,
    more robust with respect to the presence of anomalous values ​​in the distribution
    (such as the IQRs).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, one of the fundamental assumptions in outlier detection is that there
    are many more normal observations within a dataset with respect to anomalous observations.
    However, the fact remains that, often, the correct identification of the outliers
    is not an easy task to accomplish.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this sense, if we decide to use statistical measures to determine the presence
    of the outliers, we can proceed with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate statistical values ​​representative of the data to be used as comparison
    terms to determine the anomalous values ​​(that is, the values ​​that deviate
    from the representative ones the most)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify a reference model for anomaly detection, which can be based on distance
    measurements, or assume a known **statistical distribution** (that is, a normal
    distribution) as representative of normal values
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a confidence interval and evaluate the probability (likelihood) of outlier's
    presence, given a chosen distribution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The statistical approach to the identification of outliers, while being easy
    and immediate to apply, nevertheless presents important methodological limits:'
  prefs: []
  type: TYPE_NORMAL
- en: Most of the statistical tests take into account only single features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, the underlying distribution of the data is unknown, or not attributable
    to a known statistical distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the presence of complex and multi dimensional cases (in which several features
    must be taken into account simultaneously), the presence of outliers determines
    an increase in the total variance, making the identified representative models
    less significant in predictive terms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting botnet topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most common pitfalls in network anomaly detection has to do with
    the detection of botnets within the corporate network. Given the danger of such
    hidden networks, the detection of botnets is particularly relevant, not only for
    preventing the exhaustion of the organization's computational and network resources
    by external attackers, but also for preventing the dissemination of sensitive
    information (data leakage) outward.
  prefs: []
  type: TYPE_NORMAL
- en: However, identifying the presence of a botnet in time is often an operation
    that is anything but simple. This is why it is important to understand the very
    nature of botnets.
  prefs: []
  type: TYPE_NORMAL
- en: What is a botnet?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **botnet** comes from the juxtaposition of the words **bot** and **net**.
    In the case of the term **net**, we evidently have to deal with the concept of
    networking; in the case of the term **bot**, we have to spend a few more words.
  prefs: []
  type: TYPE_NORMAL
- en: The term bot is, in fact, increasingly associated with the spread of automated
    agents within cyberspace.
  prefs: []
  type: TYPE_NORMAL
- en: Starting from **chatbots** (software agents that are commonly present in websites
    for the management of the preliminary phases of customer care, but are also increasingly
    widespread, even on the social networks for the most disparate purposes) all the
    way to trolls (software agents aimed at distracting users or confusing them with
    the dissemination of false information), cyberspace is increasingly becoming infested
    with the presence of such software agents that automate the activities and interactions
    between humans and digital devices.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of botnets, the attacker's intent is to transform the victim host
    (by installing malware) into an automated agent that fulfills the orders received
    by the attacker, through a C2 console that is usually managed by a centralized
    server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The victim machine thus becomes part of a vast network of compromised machines
    (the botnet), contributing toward a common goal with its own computational and
    network resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Taking part in email spamming campaigns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing **Distributed Denial of Services** (**DDoS**) toward institutional
    or private third-party sites
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bitcoin and cryptocurrency mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Password cracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Credit card cracking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data leakages and data breaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For an organization, dealing with a botnet (even unconsciously) represents a
    serious risk in terms of legal responsibility toward third parties; it is not
    just a waste of company resources.
  prefs: []
  type: TYPE_NORMAL
- en: This is why it is important to monitor the company network by trying to promptly
    identify the presence of hosts that might be part of a botnet.
  prefs: []
  type: TYPE_NORMAL
- en: The botnet kill chain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to promptly identify the possible presence of a botnet, it may be useful
    to consider its kill chain (the different phases that characterize its realization).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can, therefore, distinguish the following phases:'
  prefs: []
  type: TYPE_NORMAL
- en: Malicious software installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Joining the botnet via C2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spreading the botnet to other hosts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Among the events to constantly monitor for the possible presence of a botnet,
    the connections made at regular intervals to remote hosts should be included.
    Rather than monitoring the quality of the traffic itself (very often, in fact,
    botnets make use of apparently harmless communication protocols, such as HTTP
    traffic, using the service's default port `80`, in order to mask its presence
    within the logs files), the real nature of network connections should be investigated.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a botnet, the victim host must constantly call home to receive
    new orders and send the information gathered to the C2 server, along with the
    results obtained from the processes that were performed on the victim system.
  prefs: []
  type: TYPE_NORMAL
- en: This phenomenon is known as **beaconing** and is characterized precisely by
    the presence within the network of connections made on a regular basis (even during
    closing hours) between infected hosts and remote destinations (which can also
    be legitimate websites compromised by the attacker).
  prefs: []
  type: TYPE_NORMAL
- en: 'The phenomenon of beaconing is usually characterized by the presence of the
    following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: Long-term user sessions, with the exchange of empty packages (keepalive packets)
    necessary to keep the connection open
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data exchange between hosts on a regular basis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The problem with beaconing is that it cannot always be identified reliably;
    thus, they constitute a symptom of the presence of a botnet, as other legitimate
    services also show characteristics similar to those mentioned previously. To capture
    the reliable signals that attest the presence of a real beaconing process—telling
    it apart from a benign SSH or telnet session, as well as from the systematic download
    of updates carried out by an antivirus software—therefore requires in-depth network
    traffic monitoring, along with statistical analysis of a time series and calculating
    position measures such as the median and IQR, in order to spot communications
    that are taking place on a regular basis.
  prefs: []
  type: TYPE_NORMAL
- en: Subsequently, it is necessary to graphically visualize the mapping of the local
    and remote hosts that present these connections, in order to identify a possible
    network topology with stable characteristics that can reasonably raise suspects
    of the presence of a botnet.
  prefs: []
  type: TYPE_NORMAL
- en: From this description of the necessary preliminary analysis activities, it is
    easy to deduce how high the risk is of ending up trapped in a network of false
    positives, rather than in a real botnet, especially if the number of potential
    appliances that are constantly connected to the network increases exponentially
    (a scenario that is progressively becoming more realistic than ever before, due
    to the spread of the IoT).
  prefs: []
  type: TYPE_NORMAL
- en: Different ML algorithms for botnet detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From what we have described so far, it is clear that it is not advisable to
    exclusively rely on automated tools for network anomaly detection, but it may
    be more productive to adopt AI algorithms that are able to dynamically learn how
    to recognize the presence of any anomalies within the network traffic, thus allowing
    the analyst to perform an in-depth analysis of only really suspicious cases. Now,
    we will demonstrate the use of different ML algorithms for network anomaly detection,
    which can also be used to identify a botnet.
  prefs: []
  type: TYPE_NORMAL
- en: The selected features in our example consist of the values of network latency
    and network throughput. In our threat model, anomalous values ​​associated with
    these features can be considered as representative of the presence of a botnet.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each example, the accuracy of the algorithm is calculated, in order to
    be able to make comparisons between the results obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Gaussian anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most widespread approaches for detecting regularity within data distribution
    makes use of the Gaussian distribution of probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: As we shall see, this statistical distribution presents a series of interesting
    characteristics that help to adequately model many natural, social, and economic
    phenomena.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, not all the phenomena under investigation can be represented by the
    Gaussian distribution (very often, as we have seen, the underlying distribution
    of the analyzed phenomena is unknown); however, it constitutes a reliable reference
    point in many cases of anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we must see the characteristics of the Gaussian distribution in order
    to understand why it is frequently used.
  prefs: []
  type: TYPE_NORMAL
- en: The Gaussian distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In mathematical terms, the Gaussian distribution (also known as the **normal
    distribution**) represents a probability distribution of random variables, which
    takes the following mathematical form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/855e4324-2b8a-43bb-a832-38021286110a.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *µ* represents the average, and *σ²* is the variance (which is representative
    of the variability of the data around the average value). In its standard form,
    the mean, *µ*, assumes the value of *0*, and *σ*^(*2*) assumes the value of *1*.
  prefs: []
  type: TYPE_NORMAL
- en: The strength of the Gaussian distribution is the central limit theorem, which,
    in general terms, establishes that the average of the observational data of a
    random variable—extracted independently—converges to the normal value as the number
    of observations increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, the observations, as their number increases, are distributed
    symmetrically (and with greater probability) around the mean, *µ*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d85c75c0-4d94-4314-bcb5-52500391417b.png)'
  prefs: []
  type: TYPE_IMG
- en: While they deviate from the average value (tending to be distributed in the
    left and right extremities) for increasing values of *σ*, the normal distribution
    is therefore adequately represented by the values assumed by *µ* and *σ*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, it is possible to determine the probability with which the observations
    are distributed around the average value, in proportion to the value of the variance;
    in other words, we can determine the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 68% of observations fall within the range between *µ - σ* and *µ + σ*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 95% of observations fall within the range between *µ - 2σ* and *µ + 2σ*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 99.7% of observations fall within the range between *µ - 3σ* and *µ + 3σ*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection using the Gaussian distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Gaussian distribution can be used to identify the outliers. Also, in this
    case, the anomaly element consists of the significant difference assumed by the
    outliers with respect to the rest of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the more the majority of the data is firmly concentrated around the
    mean value, *µ*, with a low variance, *σ*, the more significant the anomalous
    value assumed by the outlier is.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the Gaussian distribution in anomaly detection, we will have to perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Assume that the features of the training set are normally distributed (this
    can also be verified intuitively from the visual analysis of plotted data)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Estimate the *µ* and *σ* values, representative of the distribution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose an adequate threshold, representative of the probability that the observations
    are anomalous
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assess the reliability of the algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following example, we will show an implementation of Gaussian anomaly
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian anomaly detection example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First of all, let''s import the necessary Python libraries, and then load the
    data from a `.csv` file that represents the latency and network throughput values
    of each data stream we detected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the data is loaded into memory, we verify whether the distribution of
    the samples might resemble a Gaussian distribution, displaying the corresponding
    values in the form of a histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2f7eb18f-881b-4aa1-bf9b-feff330cf362.png)'
  prefs: []
  type: TYPE_IMG
- en: 'At this point, we perform the data plotting on a scatter diagram, visually
    identifying the possible outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef93f94d-3568-4861-863e-e9203e14e9d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As can also be seen visually, most of the observations are concentrated around
    the average values, except for some cases. We therefore want to verify whether
    the anomalous cases are real, and then we proceed to estimate the representative
    values, *µ* and *σ*, of the underlying Gaussian distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We then proceed to estimate the probabilities and threshold value, which we
    can then compare to identify the anomalous data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we are able to identify the outliers by comparing the individual
    probabilities of the samples with the previously estimated optimal threshold value,
    visualizing their presence in a scatter diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4635736b-5bd7-4c39-9ed5-a24a49643e7f.png)'
  prefs: []
  type: TYPE_IMG
- en: The time has come to make some assessments on the estimates made by the algorithm.
    But first, we will have to introduce some concepts related to the identification
    of false alarms in anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: False alarm management in anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have previously seen how anomaly detection gives rise to rather consistent
    estimation errors. In particular, in the case of IDS based on signatures, the
    risk of error is represented by the high number of false negatives, that is, attacks
    that are not detected.
  prefs: []
  type: TYPE_NORMAL
- en: It is the same type of risk that we incur when using antivirus software. When
    a correspondence with the suspicious signature is not found, the IDS does not
    detect any anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, in the case of anomaly-driven IDS, which is programmed to
    detect anomalies automatically, we face the risk of having a high number of false
    positives; that is, anomalies that are detected despite not being harmful.
  prefs: []
  type: TYPE_NORMAL
- en: To adequately manage these false alarms, we need to introduce some metrics that
    will help us to estimate these errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is `True Positive Rate` (also known as `Sensitivity` or the recall
    rate):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we have `False Positive Rate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'On the basis of these metrics, it is possible to estimate the `F1` value, which
    represents the harmonic average between `Precision` and `Sensitivity`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`F1` can be used to evaluate the results obtained from Gaussian anomaly detection.
    The best estimates are obtained with `F1` values close to `1`, while the worst
    estimates correspond to `F1` values that are close to `0`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example of Gaussian anomaly detection, the value of `F1` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This `F1` value is rather close to `1`, which does not surprise us, since in
    choosing the best threshold, our Gaussian anomaly detection model selects the
    value that corresponds to the highest `F1` score.
  prefs: []
  type: TYPE_NORMAL
- en: Receiver operating characteristic analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Often, between false positives and false negatives, there is a trade-off. Reducing
    the number of false negatives or the number of attacks not detected leads to an
    increase in false positive attacks being detected. To show the existence of this
    trade-off, a particular curve, known as the **receiver operating characteristic**
    (**ROC**) curve, is used. In our example, the ROC curve is calculated by using
    `roc_curve()` of `scikit-learn`, to which the target values and the corresponding
    probabilities are passed as parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to note the link between **True Positive Rate** (`TPR` or sensitivity),
    **False Positive Rate** (`FPR`), and the ROC curve (the `OPC` value instead represents
    a control coefficient, known as the **Operating Characteristic**, such as the
    total number of connections).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can therefore represent sensitivity by plotting the `TPR` value with respect
    to the value of the `OPC` control coefficient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/05f306df-6364-47da-88b2-7db76d048996.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also see how sensitivity (`TPR`) decreases as the value of `OPC` increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, we can draw the ROC curve by comparing the sensitivity (`TPR`)
    with the `FPR` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d14a609c-a646-46ad-9b5a-fd4768b067d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In an increasingly interconnected world, and with the progressive spread of
    the IoT, it becomes essential to effectively analyze network traffic in search
    of anomalies that can represent reliable indications of possible compromises (such
    as the presence of botnets).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the exclusive use of automated systems in performing network
    anomaly detection tasks exposes us to the risk of having to manage an increasing
    number of misleading signals (false positives).
  prefs: []
  type: TYPE_NORMAL
- en: It is, therefore, more appropriate to integrate the automated anomaly detection
    activities with analysis carried out by human operators, exploiting AI algorithms
    as filters, in order to only select the anomalies that are really worthy of in-depth
    attention from the analysts.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter we will deal with AI solutions for securing user authentication.
  prefs: []
  type: TYPE_NORMAL
