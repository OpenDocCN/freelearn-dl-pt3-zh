- en: Deep Learning on Microsoft Azure Using Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to end our cloud API exploration journey with this chapter. So
    far, we have gently introduced ourselves to the wonderful world of APIs, specifically
    the APIs that let us carry out deep learning with ease. We have seen how to consume
    REST APIs and use them programmatically. Like **Google Cloud Platform** (**GCP**)
    and **Amazon Web Services** (**AWS**), Microsoft also offers its own cloud service
    platform, which is called Azure. As in previous chapters, we will only be focusing
    on the deep learning-based solutions that Azure has to offer. We will be shifting
    gears a bit and will also take a look at Microsoft's **Cognitive Toolkit** (**CNTK**),
    which is a deep learning framework like Keras.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up your account in Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A quick walk-through of the deep learning solutions offered by Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Face API in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Text Analytics API in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to CNTK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can access the code for this chapter from [https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter8](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter8).
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the code used in this chapter, you''ll need the following software:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.6+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Python PIL library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Matplotlib library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All other installations, such as CNTK and Django, will be described during the
    course of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up your account in Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From your previous cloud platform usage experience, you may have realized that
    it all starts with setting up your account and billing in a cloud provider. This
    is a pretty standard workflow and Azure is no exception. So, let''s head over
    to [https://azure.microsoft.com](https://azure.microsoft.com/) and follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the Start free button, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/01908bbd-6abc-4f1b-8b26-2d05cab0472d.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that you will need a Microsoft account to proceed with the following steps.
    So, if you do not have one, create one at [https://account.microsoft.com/account](https://account.microsoft.com/account).
  prefs: []
  type: TYPE_NORMAL
- en: You will be redirected to another page, where you will again see another Start
    free button. Click on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e67d8ec9-75a8-48a3-aa96-a76668954eb7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You will be asked to log in to your Microsoft account to proceed. Give the
    credentials accordingly and you should land on a page as in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/89e7d103-9c26-4a97-aaa8-78989fd0b407.png)'
  prefs: []
  type: TYPE_IMG
- en: If you are a first-time user, you will get $200 of credit (depending on your
    currency) for free for 30 days to explore different services offered by Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Fill in your details, which will also include verification of your identity
    by card.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You might be charged a very nominal fee for this. Be sure to review the terms
    and conditions of the Azure free tier, which you will find at [https://azure.microsoft.com/en-in/offers/ms-azr-0003p/](https://azure.microsoft.com/en-in/offers/ms-azr-0003p/).
  prefs: []
  type: TYPE_NORMAL
- en: Once this process is complete, you are all set up and ready to move to your
    Azure portal ([https://portal.azure.com](https://portal.azure.com/#home)), which
    acts in the same way as the GCP and AWS consoles that you have seen in previous
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Azure portal looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be9a0fa6-08a0-474a-8d62-b28113ea7fcf.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that you have set up your Azure account, let's explore the deep learning-based
    offerings of Azure in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: A walk-through of the deep learning services provided by Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Azure''s deep learning- (and general machine learning-) based offerings are
    broadly divided into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Azure Machine Learning service** ([https://azure.microsoft.com/en-in/services/machine-learning-service/](https://azure.microsoft.com/en-in/services/machine-learning-service/)),
    which provides an end-to-end machine learning life cycle, including model building,
    training, and deployment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/5e49fe53-bc9e-41e1-b544-97bdfb6d9e0a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Machine Learning APIs** ([https://gallery.azure.ai/machineLearningAPIs](https://gallery.azure.ai/machineLearningAPIs)),
    which provide APIs for a wide range of learning tasks, such as content moderation,
    translation, anomaly detection, and so on:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3172ed87-5c07-4de6-bcb3-8a1c49c9ac02.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Azure AI** ([https://azure.microsoft.com/en-in/overview/ai-platform/](https://azure.microsoft.com/en-in/overview/ai-platform/)),
    which focuses on topics such as **knowledge mining**, **decision mining**, and
    many other similar machine learning capabilities in the domains of computer vision
    and language modeling:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/a33df20e-bf48-44a2-b065-44b02e2bf715.png)'
  prefs: []
  type: TYPE_IMG
- en: We will now study two APIs for a computer vision task and a natural language
    understanding task, respectively. We will also look at how to use these APIs from
    Python. Let's dive in.
  prefs: []
  type: TYPE_NORMAL
- en: Object detection using the Face API and Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Object detection is a classic use case of computer vision and is widely applied
    to a number of real-world problems, such as video surveillance systems. In this
    section, we will be using the Face API to detect faces from a given image. This
    has direct use when designing video surveillance systems. You can learn more about
    the Face API from its official page at [https://azure.microsoft.com/en-us/services/cognitive-services/face/](https://azure.microsoft.com/en-us/services/cognitive-services/face/).
  prefs: []
  type: TYPE_NORMAL
- en: The initial setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Azure lets you try this API for free for a duration of 7 days, as well. But
    since you already have an Azure account (with free credit, I am assuming), we
    can do it another way, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign in to your Azure account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to [https://azure.microsoft.com/en-us/services/cognitive-services/face/](https://azure.microsoft.com/en-us/services/cognitive-services/face/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Already using Azure? Try this service for free now.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should now have a window as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1b88b0e-e960-4830-9440-3e4ffa4ab083.png)'
  prefs: []
  type: TYPE_IMG
- en: Fill in the details accordingly and hit Create once you are done. You will get
    a popup that reads Submitting deployment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the deployment is completed, you should land on a page as in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d44a941-a39a-4c25-8b07-1457bef65c63.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on Go to resource and you should be redirected to the resources page,
    which contains a bunch of details on it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/08af55b4-5b80-44b4-9943-282a9618ff8d.png)'
  prefs: []
  type: TYPE_IMG
- en: Just scroll down a bit and you will be able to see the endpoint of the Face
    API. Note that it will vary depending on the configuration details you entered
    while creating the deployment. The endpoint looks like [https://eastus.api.cognitive.microsoft.com/face/v1.0](https://eastus.api.cognitive.microsoft.com/face/v1.0).
    Note this down.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to be able to use the Face API programmatically, you need to create the
    respective API keys. On that same page, there is a section at the top that says
    **Grab your keys**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15e48360-dd9c-48f2-b123-c6e1680e2514.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Under that section, click Keys and you will see something as in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6166e10e-a211-4053-9236-f678e04822cc.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that you have the API keys for the Face API, you are ready to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming the Face API from Python code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When your program includes security credentials such as API keys, it is often
    a good practice to define those keys as environmental variables and then call
    them in your program. So, go ahead and create an environment variable to store
    one of the API keys of the Face API.
  prefs: []
  type: TYPE_NORMAL
- en: To add an environment variable to your computer, you can follow this article
    at [https://www.twilio.com/blog/2017/01/how-to-set-environment-variables.html](https://www.twilio.com/blog/2017/01/how-to-set-environment-variables.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'In my case, I have named the environment variable `face_api_key`. You can put
    any image that contains faces in it. For this example, I will be using this image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5429ceba-947a-43c2-abbe-7e92043a3fdf.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Create a new Jupyter notebook and follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now load up the environment variable using Python, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, assign your Face API endpoint (for object detection) to a variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, upload the image you want to test to an online file server, such as Imgur,
    and retrieve the URL that allows fetching the raw image from Imgur.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In my case, I have uploaded the image to a GitHub repository and used the respective
    URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note that in the preceding API, only the endpoint name at the end of the URL
    changes. In most cases, the part before the endpoint name will remain constant
    throughout your use of Cognitive Services, unless a change is required by the
    Azure platform itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, import the `requests` module and set up the API payload as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are in a position to make a request to the Face API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following lines of code do this for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now display the response received from the API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the code returned is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Pay attention to the `returnFaceAttributes` body parameter, which lets you specify
    several attributes of faces and the Face API will analyze the given faces with
    respect to those attributes. To find out more about these attributes, check out
    the documentation at [http://bit.ly/2J3j6nM](http://bit.ly/2J3j6nM).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s embed the response we got from the API in the image in a presentable
    manner. We will show the probable gender and probable age of the detected faces
    in the image. We will do this using the `matplotlib`, `PIL`, and `io` libraries
    and we''ll be using a Jupyter notebook to work on the following segments of code
    in this section. We will start by importing the libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To display overlays on the image with the response received from the API, we
    use the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Store the API response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an image from the response content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an empty figure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Show the image created with the response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Iterate over the faces specified in the earlier section and extract the necessary
    information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You should have an image like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6602861e-76f7-4378-afcc-db74b1161cf8.png)'
  prefs: []
  type: TYPE_IMG
- en: You are encouraged to play around with the different parameters that the API
    provides. We will now study a **Natural Language Understanding** (**NLU**) API.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting text information using the Text Analytics API and Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whether knowingly or unknowingly, we must all have encountered some of the astonishing
    use cases of natural language processing. Be it autocorrect, the next word suggestion,
    or language translation, these use cases are too important to neglect. In this
    section, we are going to use the Text Analytics API ([https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/](https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/))
    to extract meaningful information from a given piece of text.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can try the API for free using the previously mentioned link and see its
    power. In the following example, I entered the phrase `I want to attend NeurIPS
    someday and present a paper there` and the Text Analytics API extracted four meaningful
    pieces of information from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e67aa8f4-cd9d-4d88-922a-4c94bd55d0b0.png)'
  prefs: []
  type: TYPE_IMG
- en: Observe how gracefully the API was able to extract all the key pieces of information
    from the phrase.
  prefs: []
  type: TYPE_NORMAL
- en: We will now see how to do this programmatically using Python. The setup steps
    are going to be exactly the same as the preceding ones. Just go to [https://portal.azure.com/#create/Microsoft.CognitiveServicesTextAnalytics](https://portal.azure.com/#create/Microsoft.CognitiveServicesTextAnalytics)
    and follow the steps there. Once you have the respective API keys to consume the
    Text Analytics API, move on to the following subsection. Do not forget to note
    down the respective endpoint, as well. The endpoint should start with [https://eastus.api.cognitive.microsoft.com/text/analytics/v2.0](https://eastus.api.cognitive.microsoft.com/text/analytics/v2.0).
    This URL will not work alone; it needs to have a suffix pointing to the right
    method to be invoked.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Text Analytics API from Python code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section will show you how to use the Text Analytics API in your own Python
    code. The following are the steps for using it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin this section by importing the libraries we need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then load the API key for the Text Analytics API from the environment
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now specify a few URLs to store the API endpoints:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now define the `headers` parameter by supplying the API key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also define the body parameter. In my case, I will keep the same phrase
    I showed earlier in the GUI-based demo:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now make calls to the respective APIs of Text Analytics. Let''s start
    by detecting the language:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the response accordingly, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/16b55881-1edf-4f83-9814-5cd3c785a8da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that I have highlighted the language. Now, let''s move on to the sentiment
    analysis part:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The sentiment displayed is as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/37049f4f-493f-4703-a41c-52f3a69aeb73.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that the phrase used here contains neither a positive sentiment nor a
    negative sentiment, hence the score. We will now extract the key phrases from
    the given text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The key phrases are as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e957a31-82f6-4670-8ad7-eaded45163f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice how the endpoints have changed with respect to the tasks. You can explore
    more about the different parameters of the endpoints we used in the preceding
    example at [http://bit.ly/2JjLRfi](http://bit.ly/2JjLRfi).
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to CNTK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CNTK is an offering by Microsoft. The framework is a part of the ONNX format
    initiative, which allows easy conversion of models between different neural toolkit
    frameworks. The framework is responsible for a huge portion of the deep learning
    production workload on Microsoft software and platforms. Launched in 2016, the
    framework has been a contender to popular frameworks such as TensorFlow, PyTorch,
    and so on. The framework is completely open source and can be found at [https://github.com/microsoft/CNTK](http://github.com/microsoft/CNTK).
  prefs: []
  type: TYPE_NORMAL
- en: CNTK powers enterprise services, such as Cortana and Bing, and advertisements,
    such as Skype Translate, Microsoft Cognitive Services, and several others. It
    has been proven to work faster than competitors such as TensorFlow and PyTorch
    on several applications.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will study some fundamentals of CNTK and then proceed to
    create a Django application to carry over the CNTK-based model to the web.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with CNTK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CNTK is one of the easiest frameworks to get started with, thanks to its simple
    syntax and ability to work without the concept of sessions, as is the case in
    TensorFlow, which is confusing to most learners. Let's see how we can set up CNTK
    on our local machines or on Google Colaboratory.
  prefs: []
  type: TYPE_NORMAL
- en: Installation on a local machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CNTK framework supports both 64-bit and 32-bit architecture machines. However,
    it only supports Python versions up to version 3.6, at the time of writing this
    book. You can verify the latest supported versions at [https://pypi.org/project/cntk/](https://pypi.org/project/cntk/).
    Furthermore, CNTK is not available as a built binary on macOS, currently.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the framework, you can either use the `pip` package manager or install
    it using compiled binaries on Anaconda. Assuming a Python environment is set up,
    you can use the following commands to install CNTK on both Windows and Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Without Anaconda, use the following for the CPU version:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the following for the GPU-enabled version:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'On Anaconda-enabled machines, the CNTK framework can be installed using `pip`
    with the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`<url>` can be obtained from the CNTK website at [http://tiny.cc/cntk](http://tiny.cc/cntk).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The command will resemble the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We can now begin with its installation on Google Colaboratory.
  prefs: []
  type: TYPE_NORMAL
- en: Installation on Google Colaboratory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The CNTK framework is not available on the Google Colaboratory platform by
    default and so must be installed along with other requisite modules. To install
    CNTK on a Google Colaboratory runtime, use the following command at the top of
    the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Note that the preceding command is a single-line command. If you break it up
    into multiple lines, you should make sure you add the required changes to the
    command.
  prefs: []
  type: TYPE_NORMAL
- en: Once the preceding step runs successfully, you will not need to use this command
    again in that runtime. So, the command can be commented out in future runs of
    the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is conventional to import CNTK to Python projects by the `C` alias. We use
    the following code to import the library to the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check the version of CNTK installed using the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: With CNTK imported to the project, we're ready to proceed with the precursory
    requirements of creating a deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a CNTK neural network model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll complete the steps required before creating a predictive
    neural network and then we will create the neural network itself:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by importing the necessary modules to the project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `fetch_openml()` method of the `sklearn` modules helps us directly download
    the dataset used in this example to the project—the MNIST Handwritten Digits dataset.
    The `OneHotEncoder` method is used for the one-hot encoding of the labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the few constants that are required during the program execution are
    set up:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We will perform the training on 60,000 samples with an initial learning rate
    of `0.1`. This rate can be dynamically updated during the training.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then need to create a method for generating random mini-batches for the
    training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The preceding method on each call generates batches equal to the size set in
    the previous step—for example, 64 samples in each batch. These samples are taken
    randomly from the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset now needs to be fetched; to do so, we use the following line of
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the data has been fetched, it can be separated into training and test
    datasets, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Labels in the datasets need to be one-hot encoded before being fed into the
    training model. To do so, we use the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now create a generator object for the training batches generator, as
    shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly carry out the preceding steps for the `test` dataset, too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s create a CNTK neural network model. We first begin by defining
    some constants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: We define the dimensions of the input data as `784`. Recall our example from
    [Chapter 3](a33bccdc-8664-4ae7-be82-b066e5b64850.xhtml), *Creating Your First
    Deep Learning Web Application*, where we used the MNIST dataset. The images in
    the MNIST dataset are stored in the format of single-dimension arrays containing
    28 x 28 values in the range of `0` to `255`. The images belong to 10 different
    classes, corresponding to each digit in the Arabic numeral system. We keep a provision
    of 3 hidden layers, each with 400 neurons in them.
  prefs: []
  type: TYPE_NORMAL
- en: We then create two CNTK `input` variables to use while creating the model. This
    is one of the most important concepts of CNTK.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'An `input` variable in CNTK is essentially a placeholder that we use to fill
    samples during model training and evaluation or testing. The shape of the input
    from the dataset must exactly match the dimensions declared in the `input` variables
    declaration in this step. It is important to mention here that a lot of people
    confuse the dimensions of input with the number of features a dataset has. A dataset
    that has *N* number of features and *M* number of samples has an (*M*, *N*) shape
    and so the dimensions of this dataset is simply `2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We create the `create_model()` method, which takes the input of the features
    as the argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: First, the defaults are set for the model to use the uniform distribution of
    the initialization of weights and other values. The default activation function
    is set to `ReLU`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first layer contains the features themselves and the final layer contains
    a vector with a dimension equal to the number of classes. All the layers in between
    contain a completely connected network of 3 hidden layers with 400 neurons each
    and ReLU activation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we create the model using the previous function. Dividing by `255`
    provides normalization to the dataset, rendering the values in the image arrays
    between `0` and `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Training the CNTK model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the model created, we can now move on to training the model and making
    it learn to predict. To do so, we need to use the CNTK model object and fit the
    samples in the dataset to it. We can, at the same time, log `loss` and other evaluation
    metrics. We need to carry out the following steps to train our model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create placeholders for `loss` and the classification error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can set up a `trainer` object for the CNTK framework, which is used
    to perform the actual training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s perform the training now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We set the number of epochs for training as `10` to allow quick training and
    evaluations. You can set it to a higher value for more accuracy in training; however,
    this may lead to no better training or overfitting, in some cases. At every 1,000th
    iteration, we display the loss and evaluation error obtained up to then. The general
    trend for these should be toward decline.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and saving the CNTK model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before continuing with turning this project into a web application using the
    Django framework, let''s quickly test the accuracy obtained in this training of
    the model. We will carry out the following to make predictions from the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates a NumPy array of probabilities for each label in the dataset.
    This has to be converted into indices and compared to the labels of the test data.
    We do this as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'We find around 98% accuracy in the prediction. This is a very good value and
    we will move on to saving the model and using it through Django. To save the CNTK
    model, we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: With the model saved successfully, you will have to download the `model` file
    to your local system if you've used Colaboratory to build the model. Next, we
    can move on to deploying the model on a Django-based server.
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to Django web development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Django is one of the most popular frameworks for web development using Python.
    The framework is lightweight, robust, and actively maintained by the community,
    which quickly patches security holes and adds new features. In this book, we've
    covered the Flask framework, which is essentially a bare-bones framework for Python
    web development. However, Django comes with a lot of built-in features that implement
    state-of-the-art methods and practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Django project is initially structured in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/220c2b95-9ed4-4521-9ee1-9937f6e28fec.png)'
  prefs: []
  type: TYPE_IMG
- en: These files are auto-generated when you create a new Django project using the
    `django-admin` tool. The top-level directory, `mysite`, represents the name of
    the Django project. Each Django project contains apps. Apps are similar to the
    concept of modules in software development. They are usually independent pieces
    of the complete project and are put together by the `mysite` master app within
    the project directory. Each project can have several apps inside it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's learn how to get started with Django and create a new project!
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Django
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The foremost step before using Django is to install it. Fortunately, the framework
    is easily installable as a module from the Python PIP repository. It is also available
    on the Conda repository. To install Django, open a new terminal window and use
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, if you prefer PIP, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This will install the Django module to your Python environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check whether it has been successfully installed, use the following command
    in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: This should produce an output of a version number—for example, `- 2.0.8`. If
    not, check your installation of Django.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new Django project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Django provides a handy utility named the `django-admin` tool, which can be
    used to generate the boilerplate code required for a Django project. To create
    a new project named, say, `cntkdemo`, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create all the boilerplate folders and files. However, we must create
    at least one app within the project. Change your active working directory to the
    `cntkdemo` folder using the terminal. Use the following command to create an app
    inside this project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we have created a folder named `api` with the following folders inside
    it; all the files are auto-generated with placeholder code and documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d297b46-da99-422e-aab5-4dfb5cbc90e6.png)'
  prefs: []
  type: TYPE_IMG
- en: We can now proceed with the coding of the initial UI.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the home page template
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's now create a web page that loads when the `/` route is accessed. Remember
    the `api` app that we created in the project? Let's make the index page a part
    of this app for the sake of simplicity. While it is possible to create this route
    in the `urls.py` file of the `mysite` app, we will provide the `api` app with
    its own route handling file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin with the steps for setting up the home page template:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file, `urls.py`, inside the `api` folder. The complete path of this
    file relative to the project directory would be `mysite/api/urls.py`. Inside this
    file, let''s add the `/` route, using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Save this file. The preceding code essentially adds a new path, `/`, to the
    `api` app (note, not to the project!). It imports all the views available in the
    `views.py` file of the `api` app. Note that `indexView` still does not exist.
    We will create this view after the next step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `api` app is not linked to the main project app. We need to add the following
    lines to the `mysite/mysite/urls.py` file to enable the route handling by the
    `api` app''s route handler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: The first line imports a utility for including app-specific routing settings
    to the project app. We use this to include the `urls.py` file inside the `api`
    app using the `api.urls` string. This automatically converts the strings to lines
    of code that try to find and include the correct file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `views.py` file inside the `api` app directory, add the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The `HttpResponse` method allows the `view` method to return an HTML response.
    The `loader` class provides us with methods to load HTML templates from the disk.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now create the `indexView` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The `indexView` method loads the `api/index.html` template file and renders
    it with the variables provided in the `context` dictionary, along with the `request`
    parameters available to the template. Currently, we pass a blank context because
    we do not have any values to send to the template. But again, the `api/index.html`
    file defined previously does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create the folder for holding templates and link it to the project settings.
    To do so, go to the root directory of the project and create a folder named `templates`.
    We need the project to be able to recognize this folder as the directory for the
    templates. To do so, we need to modify the `TEMPLATES` settings in the `mysite/mysite/settings.py`
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Upon adding the preceding line, the project will look for the templates inside
    the `mysite/templates/` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Create the `index.html` template file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Notice that our template file route in step 4 exists within an `api` directory.
    Create a folder named `api` inside the `templates` directory. Inside this, create
    the `index.html` file with the following code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: We've included some required scripts at the end of the preceding code block,
    including a script to fetch the CSRF token from the backend.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s add a `canvas` element to `div` with the `jumbotron` class in the
    previous code block, where we will draw the digits. We''ll also add a slider for
    selecting the width of the drawing pen, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The `template` file also includes two static files—`style.css` and `script.js`.
    We will be creating these files in the upcoming section. We have not yet created
    the script for sending the data to the server and rendering the response received.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will begin adding the JavaScript code required to communicate with
    the backend APIs. First, we create a method to check whether we need a CSRF token
    to communicate with the backend. This is only a utility function and is not related
    to calling the backend APIs, which may, at times, be designed to accept requests
    without CSRF tokens. We create this function as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we create a `click` handler for the `Predict` button. This handler function
    first sets up the proper headers required to make the call to the backend APIs
    and then converts the drawing present on the canvas into a data URL string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we add the code to the `click` handler function of the `Predict` button
    to make the Ajax call to the backend with the data from the canvas, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we can create the static files, we need to create a folder for them
    and link it to the project. This is similar to how we created the `templates`
    folder. First, create a folder, `static`, in the project directory with a `mysite/static/`
    path. Then, modify the `STATIC` configuration in the `mysite/mysite/settings.py`
    file, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: We can now create and load static files into the project templates using the
    `{% load static %}` directive at the top of the template files, as we did in the
    `index.html` file.
  prefs: []
  type: TYPE_NORMAL
- en: Create `style.css` and `script.js`—since these files are not explicitly relevant
    to the context of this book, you can download them directly from [http://tiny.cc/cntk-demo](http://tiny.cc/cntk-demo).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please note here that without the `script.js` file, the project will not run.
  prefs: []
  type: TYPE_NORMAL
- en: We have created the setup for the prediction of the images drawn on a canvas
    present in the `index.html` template file. However, the `/predict` route is yet
    to be created. Let's see how CNTK models can be loaded and used in Django in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions using CNTK from the Django project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll first set the required route, the view, and the imports
    for the CNTK model to work with Django. We will then load the CNTK model from
    the saved file and make predictions using it.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the predict route and view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall how we created the `/` route and its corresponding view in the `api`
    app:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, add the following line to `mysite/api/urls.py`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: This creates the `/predict` route. However, the view, `predictView`, is not
    yet created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following lines to the `views.py` file in the `api` app:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Notice the placeholders in the preceding lines. We'll add more here in the next
    steps.
  prefs: []
  type: TYPE_NORMAL
- en: Making the necessary module imports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s load all the modules required to make predictions with the CNTK
    model, as in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following lines of imports to the `views.py` file of the `api` app:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll need the preceding imports to load the model from the disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The preceding lines import the CNTK module to the Django project. The `load_model`
    method will help us load the saved CNTK model file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following modules are used to manipulate the images that the predictions
    will be made on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The following modules provide utility for handling Base64-encoded strings,
    which is the format that the `index.html` page sends the canvas data in the request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The other libraries will be explained when they are used in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and predicting using the CNTK model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now further edit the `predictView` view by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, read the Base64-encoded image string data to a variable using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: The Base64-decoded string does not have proper padding and contains spaces that
    need to be converted into `+`. The last two lines in the previous code block perform
    the same manipulations on the string.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will convert this Base64-encoded string into a PNG image and save
    it to disk with the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: The first line creates a 32-character-long random string for the filename. The
    next line calls the `convertImage` method, which stored the `base64` string as
    the filename provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the `convertImage` method has not yet been defined. Outside of the
    `predictView` method, add the definition for the function, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: The method strips out the extra metadata from the string. It then decodes the
    string and saves it as a PNG file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s return back to the `predictView` method. We will first load the saved
    `image` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: We will also convert the image into a black and white channel only. This reduces
    the number of channels in the image from 3 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that all images in the MNIST dataset have dimensions of 28 x 28\. We
    must resize our current image to the same dimensions. We do so with the following
    line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we convert the image into a NumPy array with the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '`np.expanded_dims` is a simple utility in NumPy used to add an extra dimension
    to the array for proper compatibility with most machine learning libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: Load the CNTK model. First, create a folder named `data` in the root directory
    of the project and copy the saved `model` file there in `mysite/data/cntk.model`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We now load the CNTK model in the `predictView` method, as shown:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can predict the label of the image, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: The `eval` method, in its first argument, expects the NumPy array of the image
    and returns a list of probabilities of each output class. The `np.argmax` method
    is used to find the index of the class with the highest probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'To return the output, modify the `return` part of the `predictView` method,
    as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: The predicted label for the image is sent as a digit contained in the `data`
    variable of the JSON response, which is displayed on the page.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the web app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, we can test the CNTK + Django app we have developed. To do so, open
    the terminal and direct it to the root directory of the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to start the Django server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The server starts at [http://localhost:8000](http://localhost:8000) if the
    port is free. Open the page in a web browser. Draw your digit on the canvas provided
    and click on the Predict button. You will be able to see the result from the model
    at the bottom of the page, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b717132a-d629-41e8-b622-7424137ccf76.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that the model returns the correct output in the preceding screenshot,
    which is 2\. Hence, we conclude the deployment of CNTK models using Django.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the offerings from Microsoft AI and the Azure cloud
    for performing deep learning on websites. We saw how the Face API can be used
    to predict the gender and age of people in images, as well as how the Text Analytics
    API can be used to predict the language of a given text and the key phrases in
    the provided text or the sentiment of any sentence. Finally, we created a deep
    learning model using CNTK on the MNIST dataset. We saw how the model can be saved
    and then deployed via a Django-based web application in the form of an API. This
    deployment of the saved model via Django can be easily adapted for other deep
    learning frameworks, such as TensorFlow or PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss a generalized framework for building production-grade
    deep learning applications using Python.
  prefs: []
  type: TYPE_NORMAL
