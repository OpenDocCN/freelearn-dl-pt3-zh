- en: 10\. Custom TensorFlow Components
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will dive a level deeper into the TensorFlow framework
    and build custom modules. By the end of it, you will know how to create custom
    TensorFlow components to use within your models, such as loss functions and layers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, you learned how to build CNN or RNN models from predefined
    TensorFlow modules. You have been using one of the APIs offered by TensorFlow
    called the sequential API. This API is a great way to start building "simple"
    deep learning architecture with few lines of code. But if you want to achieve
    higher performance, you may want to build your own custom architecture. In this
    case, you will need to use another API called the functional API. Researchers
    use functional APIs while defining their model architecture. By learning how to
    use it, you will be able to create custom loss functions or modules, such as a
    residual block from the ResNet architecture.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow APIs
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using TensorFlow, you can choose from the sequential, functional, or subclassing
    APIs to define your models. For most, the sequential API will be the go-to option.
    However, as time goes by and you are exposed to more complexity, your needs will
    expand as well.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: The **sequential API** is the simplest API used for creating TensorFlow models.
    It works by stacking different layers one after the other. For example, you will
    create a sequential model with a first layer that's a convolution layer, followed
    by a dropout layer, and then a fully connected layer. This model is sequential
    as the input data will be passed to each defined layer sequentially.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The **functional API** provides more flexibility. You can define models with
    different layers that interact with each other not in a sequential manner. For
    instance, you can create two different layers both of which will feed into a third
    one. This can be easily achieved with the functional API.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '`Layer` or `Model`. You can define your own custom layers or models, but this
    means you will need to comply with all the requirements of the inherited TensorFlow
    classes, such as coding mandatory methods.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram provides a quick overview of the three different APIs
    offered by TensorFlow:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1: Diagram showing a comparison of all three APIs'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_10_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10.1: Diagram showing a comparison of all three APIs'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: In the section ahead, you will learn how to define a custom loss function.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Custom Loss Functions
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several types of loss functions that are commonly used for machine
    learning. In *Chapter 5*, *Classification*, you studied different types of loss
    functions and used them with different classification models. TensorFlow has quite
    a few built-in loss functions to choose from. The following are just a few of
    the more common loss functions:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Error (MAE)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean Squared Error (MSE)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary cross-entropy
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorical cross-entropy
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinge
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huber
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean Squared Logarithmic Error (MSLE)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方对数误差（MSLE）
- en: As a quick reminder, you can think of loss functions as a kind of compass that
    allows you to clearly see what is working in an algorithm and what isn't. The
    higher the loss, the less accurate the model, and so on.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，你可以将损失函数视为一种指南针，它可以帮助你清晰地了解算法中哪些部分是有效的，哪些部分是无效的。损失值越高，模型的准确度越低，反之亦然。
- en: Although TensorFlow has several loss functions available, at some point, you
    will most likely need to create your own loss function for your specific needs.
    For instance, if you are building a model that is predicting stock prices, you
    want to define a loss function that will penalize substantially incorrect values.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 TensorFlow 提供了多种现成的损失函数，但在某些情况下，你很可能需要为特定需求创建自己的损失函数。例如，如果你正在构建一个预测股票价格的模型，你可能需要定义一个损失函数，以显著惩罚那些大幅错误的预测值。
- en: The following section will show you how to build a custom loss function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将向你展示如何构建自定义损失函数。
- en: Building a Custom Loss Function with the Functional API
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用函数式 API 构建自定义损失函数
- en: 'You saw in the previous chapters how to use predefined loss functions from
    TensorFlow. But if you want to build your own custom functions, you can use either
    the functional API or model subclassing. Let''s say you want to build a loss function
    that will raise the difference between the predictions and the actual values to
    the power of 4:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你在前几章中看到过如何使用 TensorFlow 提供的预定义损失函数。但如果你想构建自己的自定义函数，可以使用函数式 API 或者模型子类化方法。假设你想创建一个损失函数，它将预测值与实际值之间的差异的四次方作为误差：
- en: '![Figure 10.2: Formula for custom loss'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2：自定义损失函数的公式'
- en: '](img/B16341_10_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_02.jpg)'
- en: 'Figure 10.2: Formula for custom loss'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2：自定义损失函数的公式
- en: 'While creating a custom loss function, you will always need two arguments:
    `y_true` (actual values) and `y_pred` (predictions). A loss function will calculate
    the difference between these two values and return an error value that represents
    how far the predictions of your model are from the actual values. In the case
    of MAE, this loss function will return the absolute value of this error. On the
    other hand, MSE will square the difference between the actual value and the predicted
    value. But in the preceding example, the error should be raised to the power of
    `4`.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建自定义损失函数时，你总是需要两个参数：`y_true`（实际值）和`y_pred`（预测值）。损失函数会计算这两个值之间的差异，并返回一个误差值，表示模型的预测值与实际值之间的距离。在
    MAE 的情况下，损失函数将返回这个误差的绝对值。另一方面，MSE 会将实际值和预测值之间的差值平方。但在前面的例子中，误差应该被提升到 `4` 次方。
- en: 'Let''s see how you can implement this using the functional API. Firstly, you
    will need to import the TensorFlow library using the following command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用函数式 API 来实现这一点。首先，你需要通过以下命令导入 TensorFlow 库：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you will have to create a function called `custom_loss` that takes as
    input the `y_true` and `y_pred` arguments. You will then use the `pow` function
    to raise the calculated error to the power of `4`. Finally, you will return the
    calculated error:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要创建一个名为`custom_loss`的函数，该函数接收`y_true`和`y_pred`作为输入参数。接下来，你将使用`pow`函数将计算得到的误差的四次方。最后，你将返回计算得到的误差：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You have created your own custom loss function using the functional API. You
    can now pass it to the `compile` method, instead of the predefined loss functions,
    before training your model:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经使用函数式 API 创建了自己的自定义损失函数。现在，你可以在训练模型之前，将它传递给`compile`方法，而不是使用预定义的损失函数：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After this, you can train your model exactly the same way as you did in previous
    chapters. TensorFlow will use your custom loss function to optimize the learning
    process of your model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，你可以像在前几章中那样训练你的模型。TensorFlow 会使用你自定义的损失函数来优化模型的学习过程。
- en: Building a Custom Loss Function with the Subclassing API
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用子类化 API 构建自定义损失函数
- en: 'There is another way to define a custom loss function: using the subclassing
    API. In this case, rather than building a function, you will define a custom class
    for it. This is quite useful if you want to extend it with additional custom attributes
    or methods. With subclassing, you can create a custom class that will inherit
    attributes and methods from the `Loss` class of the `keras.losses` module. You
    will then need to define the `__init__()` and `call()` methods, which are required
    in the `Loss` class. The `__init__` method is where you will define all the attributes
    of your custom class, and the `call()` method is where you will specify the logic
    for calculating the loss.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种定义自定义损失函数的方法：使用子类化API。在这种情况下，你将定义一个自定义类，而不是创建一个函数。如果你希望添加更多自定义属性或方法，这种方法非常有用。通过子类化，你可以创建一个自定义类，该类将继承`keras.losses`模块中的`Loss`类的属性和方法。然后，你需要定义`__init__()`和`call()`方法，这是`Loss`类要求的方法。`__init__`方法是定义自定义类所有属性的地方，而`call()`方法则是你定义计算损失逻辑的地方。
- en: 'The following is a brief example of how you can implement your custom loss,
    using the subclassing API, where the error should be raised to the power of `4`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用子类化API实现自定义损失函数的简要示例，其中误差应提升到`4`的幂：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding example, you have reimplemented the same loss function as previously
    (power of 4) but used subclassing from `keras.losses.Loss`. You started by initializing
    the attributes of your class in the `__init__()` method using the `self` parameter,
    which refers to the object itself.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你重新实现了之前相同的损失函数（4的幂），但使用了从`keras.losses.Loss`进行子类化的方法。你首先通过`__init__()`方法初始化了类的属性，并使用`self`参数，这指向类的实例。
- en: Then, in the `call()` method, you defined the logic of your loss function, which
    calculated the error and raised it to the power of 4.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在`call()`方法中，你定义了损失函数的逻辑，它计算了误差并将其提升到4的幂。
- en: Now that you're up to speed with loss functions, it's time for you to build
    one in the next exercise.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了损失函数的基础知识，接下来是时候在下一个练习中自己动手构建一个损失函数了。
- en: 'Exercise 10.01: Building a Custom Loss Function'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 10.01：构建自定义损失函数
- en: In this exercise, you will create your own custom loss function to train a CNN
    model to distinguish between images of apples and tomatoes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将创建一个自定义损失函数，用于训练一个卷积神经网络（CNN）模型，以区分苹果和西红柿的图片。
- en: You will use the `Apple-or-Tomato` dataset for this exercise. The dataset is
    a subset of the `Fruits 360` dataset on GitHub. The `Fruits 360` dataset consists
    of 1,948 total color images with dimensions of 100 by 100 pixels. The `Apple-or-Tomato`
    dataset has 992 apple images with 662 in the training set and 330 in the test
    dataset. There are a total of 956 tomato images, with 638 in the training dataset
    and 318 in the test dataset.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本次练习中使用`Apple-or-Tomato`数据集。该数据集是GitHub上的`Fruits 360`数据集的一个子集。`Fruits 360`数据集包含1,948张总色彩图像，图像尺寸为100x100像素。`Apple-or-Tomato`数据集包含992张苹果图像，其中662张在训练集中，330张在测试集中。番茄图像总数为956张，其中638张在训练集中，318张在测试集中。
- en: '**Note**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'You can get the `Apple-or-Tomato` dataset at the following link: [https://packt.link/28kZY](https://packt.link/28kZY).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接获取`Apple-or-Tomato`数据集：[https://packt.link/28kZY](https://packt.link/28kZY)。
- en: 'You can find the `Fruits 360` dataset here: [https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip](https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到`Fruits 360`数据集：[https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip](https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip)。
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开一个新的Colab或Jupyter Notebook。如果你使用的是Google Colab，你需要先将数据集下载到Google Drive中：
- en: Open a new Jupyter notebook or Google Colab notebook.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter Notebook或Google Colab笔记本。
- en: 'If you are using Google Colab, upload your dataset locally with the following
    code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate to the CSV
    file and click `Open`. Save the file as `uploaded`. Then, go to the folder where
    you have saved the dataset:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用的是Google Colab，请使用以下代码将数据集本地上传。否则，请跳到*步骤4*。点击`Choose Files`选择CSV文件并点击`Open`。保存文件为`uploaded`。然后，进入你保存数据集的文件夹：
- en: '[PRE4]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Unzip the dataset in the current folder:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在当前文件夹中解压数据集：
- en: '[PRE5]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量`directory`，它包含数据集的路径：
- en: '[PRE6]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Import the `pathlib` library:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pathlib`库：
- en: '[PRE7]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a variable, `path`, that contains the full path to the dataset using
    `pathlib.Path`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create two variables, `train_dir` and `validation_dir`, that take the full
    paths to the train and validation folders, respectively:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create four variables, `train_apple_dir`, `train_tomato_dir`, `validation_apple_dir`,
    and `validation_tomato_dir`, that take the full paths to the `apple` and `tomato`
    folders for the train and validation sets, respectively:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Import the `os` package:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Create two variables, called `total_train` and `total_val`, that will get the
    number of images for the training and validation sets, respectively:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Import `ImageDataGenerator` from the `tensorflow.keras.preprocessing` module:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Instantiate two `ImageDataGenerator` classes, `train_image_generator` and `validation_image_generator`,
    that will rescale the images by dividing by 255:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `224`, and `224`, respectively:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a data generator called `train_data_gen`, using `     flow_from_directory()`, and specify the batch size, the path to the training folder,
    the value of the `shuffle` parameter, the size of the target, and the class mode:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a data generator called `val_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the validation
    folder, the size of the target, and the class mode:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Import `matplotlib` and create a `for` loop that will iterate through five
    images from `train_data_gen` and plot them:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You should get the following output:'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.3: Sample of images from the dataset'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_03a.jpg)![10.3 b](img/B16341_10_03b.jpg)![Figure 10.3: Sample
    of images from the dataset'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_03c.jpg)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.3: Sample of images from the dataset'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding results show some examples of the images contained in this dataset.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create your custom loss function that will square the calculated error:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Import the `NASNetMobile` model from the `tensorflow.keras.applications` module:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Instantiate this model with the ImageNet weights, remove the top layer, and
    specify the right input dimensions:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Freeze all the layers of this model so that you are not going to update the
    model weights of `NASNetMobile`:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Import the `Flatten` and `Dense` layers from the `tensorflow.keras.layers`
    module:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a new model that combines the `NASNetMobile` model with two new top
    layers (with 500 and 1 units, respectively) and ReLu and sigmoid as activation functions:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Print the summary of your model:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You will get the following output:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.4: Model summary'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_04.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.4: Model summary'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here, you can see the layers on the left-hand side. You have `Output Shape`
    shown—for example, `(None, 224, 224, 3)`. Then, the number of parameters is shown
    under `Param #`. At the bottom, you will find the summary, including trainable
    and non-trainable parameters.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile this model by providing your custom loss function, with Adam as the
    optimizer and accuracy as the metric to be displayed:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供自定义损失函数、Adam优化器和精度度量，来编译此模型并显示结果：
- en: '[PRE27]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Fit the model and provide the train and validation data generators, the number
    of steps per epoch, and the number of validation steps:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型并提供训练和验证数据生成器、每个epoch的步数以及验证步骤的数量：
- en: '[PRE28]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should get the following output:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 10.5: Screenshot of training progress'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图10.5：训练进度截图'
- en: '](img/B16341_10_05.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_05.jpg)'
- en: 'Figure 10.5: Screenshot of training progress'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：训练进度截图
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch. On the fifth epoch, the model is `96%` accurate
    on both the training set and the validation set.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图显示了TensorFlow在训练模型期间显示的信息。你可以看到每个epoch在训练集和验证集上达到的准确度。在第五个epoch时，模型在训练集和验证集上的准确度均为`96%`。
- en: In this exercise, you have successfully built your own loss function and trained
    a binary classifier with it to recognize images of apples or tomatoes. In the
    following section, you will take it a step further and build your own custom layers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你已经成功地构建了自己的损失函数，并用它训练了一个二分类器，识别苹果或番茄的图像。在接下来的章节中，你将更进一步，构建你自己的自定义层。
- en: Implementing Custom Layers
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现自定义层
- en: Previously, you looked at implementing your own custom loss function with either
    the TensorFlow functional API or the subclassing approach. These concepts can
    also be applied to creating custom layers for a deep learning model. In this section,
    you will build a ResNet module from scratch.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，你已经学习了如何使用TensorFlow的功能性API或子类化方法实现自定义损失函数。这些概念也可以应用于为深度学习模型创建自定义层。在本节中，你将从零开始构建一个ResNet模块。
- en: Introduction to ResNet Blocks
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ResNet块简介
- en: '**Residual neural network**, or **ResNet**, was first proposed by *Kaiming
    He* in his paper *Deep Residual Learning for Image Recognition* in 2015\. He introduced
    a new concept called a residual block that tackles the problem of vanishing gradients,
    which limits the ability of training very deep networks (with a lot of layers).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**残差神经网络**，或称**ResNet**，最早由*何恺明*在2015年的论文《深度残差学习用于图像识别》中提出。他引入了一个新的概念——残差块，用以解决梯度消失问题，这一问题限制了训练非常深的网络（具有大量层）的能力。'
- en: A residual block is composed of multiple layers. But instead of having a single
    path where each layer is stacked and executed sequentially, a residual block contains
    two different paths. The first path has two different convolution layers. The
    second path, called the **skip connection**, takes the input and forwards it to
    the last layer of the first path. So, the input of a residual block will go through
    the first path with the sequence of convolution layers, and its result will be
    combined with the original input coming from the second path (skip connection),
    as shown in *Figure 10.6*. Without going too much into the mathematical details,
    this extra path allows the architecture to pass through the gradients in a deeper
    layer without impacting the overall performance.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一个残差块由多个层组成。但不同于将每一层堆叠并顺序执行的单一路径，残差块包含两条不同的路径。第一条路径有两个不同的卷积层。第二条路径，称为**跳跃连接**，将输入传递给第一条路径的最后一层。因此，残差块的输入将经过第一条路径的卷积层序列，结果将与来自第二条路径（跳跃连接）的原始输入结合，如*图10.6*所示。简言之，这条额外的路径允许架构在更深层次上传递梯度，而不会影响整体性能。
- en: '![Figure 10.6: Skip connection'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.6：跳跃连接'
- en: '](img/B16341_10_06.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_06.jpg)'
- en: 'Figure 10.6: Skip connection'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：跳跃连接
- en: As you can see, if you want to build an architecture for the preceding residual
    block, it will be quite hard with the TensorFlow sequential API. Here, you need
    to build a very customized layer. This is the reason why you need to use either
    the functional API or model subclassing instead.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，如果你想为前面的残差块构建一个架构，使用TensorFlow的顺序API会相当困难。这里，你需要构建一个非常定制化的层。这就是为什么你需要使用功能性API或模型子类化的方法。
- en: Building Custom Layers with the Functional API
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用功能性API构建自定义层
- en: In this section, you will see how to use the TensorFlow functional API to build
    a custom layer.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用TensorFlow的功能性API来构建自定义层。
- en: 'To start, you will build a function that takes your input as a tensor and adds
    ReLU and batch normalization to it. For example, in the following code snippet,
    the `relu_batchnorm_layer` function takes input and then returns a tensor. This
    makes a composite layer with ReLU activation and batch normalization in succession:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你将构建一个函数，该函数将输入作为张量并对其添加 ReLU 激活和批量归一化。例如，在下面的代码片段中，`relu_batchnorm_layer`
    函数接收输入并返回一个张量。这将创建一个包含 ReLU 激活和批量归一化的复合层：
- en: '[PRE29]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, create a function for your residual block. You''ll need to take a tensor
    as input and pass it to two Conv2D layers. Then, you will add the output of the
    second Conv2D layer to the original input, which represents the skip connection.
    The output of this addition will then be passed to the `relu_batchnorm_layer()`
    function that you defined in the preceding code snippet. The output will be given
    to another Conv2D layer:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个函数来实现你的残差块。你需要接收一个张量作为输入，并将其传递给两个 Conv2D 层。然后，你将第二个 Conv2D 层的输出与原始输入相加，这代表了跳跃连接。该加法的输出将传递给你在前面代码片段中定义的
    `relu_batchnorm_layer()` 函数。最后，输出将传递给另一个 Conv2D 层：
- en: '[PRE30]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, you can use this custom layer in your model. In the following code snippet,
    you will define a simple model with a Conv2D layer followed by a residual block:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以在模型中使用这个自定义层。在以下代码片段中，你将定义一个简单的模型，其中包含一个 Conv2D 层，后跟一个残差块：
- en: '[PRE31]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Let's now build custom layers using subclassing in the following section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在下面的章节中使用子类化来构建自定义层。
- en: Building Custom Layers with Subclassing
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用子类化构建自定义层
- en: Previously, you looked at how to create a simplified version of a residual block
    using the functional API. Now, you will see how to use model subclassing to create
    a custom layer.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，你已经学习了如何使用函数式 API 创建简化版的残差块。现在，你将看到如何使用模型子类化来创建自定义层。
- en: 'To begin, you need to import the `Model` class together with a few layers:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要导入 `Model` 类和一些层：
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Then, you use model subclassing to create a model with two dense layers. Firstly,
    define a model subclass denoted as `MyModel`. The objects that you will generate
    from this class are models with two dense layers.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你将使用模型子类化来创建一个包含两个全连接层的模型。首先，定义一个名为 `MyModel` 的模型子类。从这个类生成的对象将是具有两个全连接层的模型。
- en: 'Define the two dense layers within the `init` method. For instance, the first
    one can have `64` units and the ReLU activation function, while the second one
    can have `10` units without an activation function (in this case, the default
    activation function used is the linear one). After this, in the `call` method,
    you set up the forward pass by calling the previously defined dense layers. Firstly,
    you can place the `dense_1` layer to take the inputs and after it, the `dense_2`
    layer that returns the outputs of the layer:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `init` 方法中定义两个全连接层。例如，第一个可以有 `64` 个单元并使用 ReLU 激活函数，而第二个可以有 `10` 个单元并且没有激活函数（在这种情况下，默认的激活函数是线性函数）。之后，在
    `call` 方法中，通过调用之前定义的全连接层来设置前向传播。首先，你可以放置 `dense_1` 层来接收输入，接着是 `dense_2` 层，它返回层的输出：
- en: '[PRE33]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The next step is to instantiate the model. For this, just call the class with
    no argument inside the brackets. Next, call the model on a random input to create
    the weights. For the input, this example uses a one-dimensional vector with `10`
    elements, but feel free to use a different input. You can then print the summary
    of the model where you can see the dense layers that you defined before.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是实例化模型。为此，只需在括号内调用类，不带参数。接下来，用随机输入调用模型以创建权重。对于输入，本例使用一个包含 `10` 个元素的一维向量，但你也可以使用不同的输入。然后，你可以打印模型的摘要，查看之前定义的全连接层。
- en: 'Consider the following model summary:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下模型摘要：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The resulting output should be like the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的输出应如下所示：
- en: '![Figure 10.7: Model summary'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7：模型概述'
- en: '](img/B16341_10_07.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_07.jpg)'
- en: 'Figure 10.7: Model summary'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7：模型概述
- en: 'Now, you can modify the `call` method by including a keyword argument called
    `training`. This is useful if you want to have different behaviors in training
    and inference. For example, you can create a dropout layer that will be activated
    only if `training` is `true`. Firstly, you need to define a dropout layer within
    the `init` method, given your learning rate of `0.4`. Then, in the `call` method,
    write an `if` clause with the `training` keyword is set to `true` by default.
    Inside it, just call the dropout layer:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过添加一个名为 `training` 的关键字参数来修改 `call` 方法。如果你希望在训练和推理时有不同的行为，这将非常有用。例如，你可以创建一个只有在
    `training` 为 `true` 时才会激活的 dropout 层。首先，你需要在 `init` 方法中定义一个 dropout 层，并设置学习率为
    `0.4`。然后，在 `call` 方法中，写一个 `if` 语句，默认情况下 `training` 为 `true`。在其中，调用 dropout 层：
- en: '[PRE35]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, consider the model summary:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑模型总结：
- en: '[PRE36]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The summary is displayed as follows, upon running the preceding command:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 执行上述命令后，模型总结将如下所示：
- en: '![Figure 10.8: Model summary'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.8：模型总结'
- en: '](img/B16341_10_08.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_08.jpg)'
- en: 'Figure 10.8: Model summary'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8：模型总结
- en: In the following exercise, you will build a custom layer.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，你将构建一个自定义层。
- en: 'Exercise 10.02: Building a Custom Layer'
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 10.02：构建自定义层
- en: The `Healthy-Pneumonia` dataset is a subset of the `National Institute for Health
    NIH` dataset. The dataset consists of 9,930 total color images with dimensions
    of 100 by 100 pixels. The `pneumonia-or-healthy` dataset has 1,965 total healthy
    images with 1,375 images in the training dataset and 590 images in the test dataset.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`Healthy-Pneumonia` 数据集是 `National Institute for Health NIH` 数据集的一个子集。该数据集包含
    9,930 张总共 100x100 像素的彩色图像。`pneumonia-or-healthy` 数据集包含 1,965 张健康图像，其中训练集有 1,375
    张图像，测试集有 590 张图像。'
- en: You will create a custom ResNet block that consists of a Conv2D layer, a batch
    normalization layer, and a ReLU activation function. You will perform binary classification
    on the images to distinguish between healthy and pneumonic images.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你将创建一个自定义的 ResNet 块，包含一个 Conv2D 层、一个批归一化层和一个 ReLU 激活函数。你将对图像进行二分类，以区分健康图像和肺炎图像。
- en: Note
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can get the `pneumonia-or-healthy` dataset here: [https://packt.link/IOpUX](https://packt.link/IOpUX).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里获取 `pneumonia-or-healthy` 数据集：[https://packt.link/IOpUX](https://packt.link/IOpUX)。
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，打开一个新的 Colab 或 Jupyter Notebook。如果你使用的是 Google Colab，你需要先将数据集下载到你的 Google
    Drive 中：
- en: Open a new Jupyter notebook or Google Colab.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter notebook 或 Google Colab。
- en: 'If you are using Google Colab, you can upload your dataset locally with the
    following code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate
    to the CSV file and click `Open`. Save the file as `uploaded`. Then, go to the
    folder where you saved the dataset:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用的是 Google Colab，可以使用以下代码在本地上传数据集。否则，请转到 *第 4 步*。点击 `Choose Files`，找到 CSV
    文件并点击 `Open`。将文件保存为 `uploaded`，然后进入你保存数据集的文件夹：
- en: '[PRE37]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Unzip the dataset in the current folder:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在当前文件夹中解压数据集：
- en: '[PRE38]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量 `directory`，它包含数据集的路径：
- en: '[PRE39]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Import the `pathlib` library:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pathlib` 库：
- en: '[PRE40]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Create a variable, `path`, that contains the full path to the data using `pathlib.Path`:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量 `path`，它使用 `pathlib.Path` 包含数据的完整路径：
- en: '[PRE41]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create two variables, called `train_dir` and `validation_dir`, that take the
    full paths to the train and validation folders, respectively:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别为 `train_dir` 和 `validation_dir`，它们分别存储训练集和验证集文件夹的完整路径：
- en: '[PRE42]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Create four variables, called `train_healthy_dir`, `train_pneumonia_dir`, `validation_healthy_dir`,
    and `validation_pneumonia_dir`, that take the full paths to the healthy and pneumonia
    folders for the train and validation sets, respectively:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建四个变量，分别为 `train_healthy_dir`、`train_pneumonia_dir`、`validation_healthy_dir`
    和 `validation_pneumonia_dir`，它们分别存储训练集和验证集的健康和肺炎文件夹的完整路径：
- en: '[PRE43]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Import the `os` package:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `os` 包：
- en: '[PRE44]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Create two variables, called `total_train` and `total_val`, to get the number
    of images for the training and validation sets, respectively:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别为 `total_train` 和 `total_val`，用来获取训练集和验证集中的图像数量：
- en: '[PRE45]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tensorflow.keras.preprocessing` 导入 `ImageDataGenerator`：
- en: '[PRE46]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Instantiate two `ImageDataGenerator` classes and call them `train_image_generator`
    and `validation_image_generator`, which will rescale the images by dividing by
    255:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化两个 `ImageDataGenerator` 类，并分别命名为 `train_image_generator` 和 `validation_image_generator`，它们将通过除以
    255 来重新缩放图像：
- en: '[PRE47]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `100`, and `100`, respectively:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Create a data generator called `train_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the training folder,
    the value of the `shuffle` parameter, the size of the target, and the class mode:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Create a data generator called `val_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the validation
    folder, the size of the target, and the class mode:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Import `matplotlib` and create a `for` loop that will iterate through five
    images from `train_data_gen` and plot them:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You should see the following output:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.9: Sample of images from the dataset'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_09a.jpg)![10.9 b](img/B16341_10_09b.jpg)![10.9 c](img/B16341_10_09c.jpg)'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.9: Sample of images from the dataset'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding results show some examples of the images contained in this dataset.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Import `Input`, `Conv2D`, `ReLU`, `BatchNormalization`, `Add`, `AveragePooling2D`,
    `Flatten`, and `Dense`:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Build a function that takes your input as a tensor and adds ReLU and batch
    normalization to it:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Create a function to build your residual block. You will need to take a tensor
    (`input`) as your input and pass it to two Conv2D layers with a stride of `2`.
    Next, add the input to the output, followed by ReLU and batch normalization, returning
    a tensor. Add another Conv2D layer with `kernel_size=1`. Add its result to the
    output of the previous Conv2D layer. Finally, apply `relu_batchnorm_layer()` and
    return its value. You will apply the exact same filters (numbers and dimensions
    are defined by two input parameters of the construction function) to all Conv2D
    layers:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Import the `Model` module:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Use `keras.layers.Input()` to define the input layer to the model. Here, your
    shape is 100 pixels by 100 pixels and has three colors (RGB):'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Apply batch normalization to the input, followed by a Conv2D layer with `32`
    filters of size `3*3`, stride `1`, and `same` padding. Finally, apply the `relu_batchnorm_layer()`
    function to its output:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Provide the output of the previous layer to the `residual_block()` function
    with `32` filters. Then, pass its output an average pooling layer with four units
    and then flatten its results before feeding it to a fully connected layer of `1`
    unit with sigmoid as the activation function:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Instantiate a `Model()` class with the original input and the output of the
    fully connected layer:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Get the summary of your model:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'You will see a summary, including trainable and non-trainable parameters, as follows:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.10: Model summary'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_10.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.10: Model summary'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile the model by providing binary cross-entropy as the loss function, Adam
    as the optimizer, and accuracy as the metric to be displayed:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Fit the model and provide the train and validation data generators, the number
    of epochs, the steps per epoch, and the validation steps:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'You should get output like the following:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.11: Screenshot of training progress'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_11.jpg)'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.11: Screenshot of training progress'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you created your own custom layer for the network. Now, let's
    test the knowledge you have gained so far in the following activity.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 10.01: Building a Model with Custom Layers and a Custom Loss Function'
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `table-or-glass` dataset is a subset of images taken from the `Open Images
    V6` dataset. The `Open Images V6` dataset has around 9 million images. The `table-or-glass`
    dataset consists of 7,484 total color images with dimensions of 100 by 100 pixels.
    The `table-or-glass` dataset has 3,741 total glass images with 2,618 in the training
    and 1,123 in the test dataset. There are a total of 3,743 table images with 2,618
    in the training and 1,125 in the test dataset. You are required to train a more
    complex model that can distinguish images of glasses and tables using custom ResNet
    blocks and a custom loss function.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the dataset here: [https://packt.link/bE5F6](https://packt.link/bE5F6).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this activity:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Import the dataset and unzip the file into a local folder.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the list of images for both the training and testing sets.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze the distribution of the target variable.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocess the images (standardization and reshaping).
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a custom loss function that will calculate the average squared error.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a custom residual block constructor function.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train your model.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the learning curves for accuracy and loss.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor283).
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter demonstrated how to build and utilize custom TensorFlow components.
    You learned how to design and implement custom loss functions, layers, and residual
    blocks. Using the TensorFlow functional API or model subclassing allows you to
    build more complex deep learning models that may be a better fit for your projects.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: In the next and final chapter, you will explore and build generative models
    that can learn patterns and relationships within data, and use those relationships
    to generate new, unique data.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
