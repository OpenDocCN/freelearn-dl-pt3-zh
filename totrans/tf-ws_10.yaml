- en: 10\. Custom TensorFlow Components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will dive a level deeper into the TensorFlow framework
    and build custom modules. By the end of it, you will know how to create custom
    TensorFlow components to use within your models, such as loss functions and layers.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, you learned how to build CNN or RNN models from predefined
    TensorFlow modules. You have been using one of the APIs offered by TensorFlow
    called the sequential API. This API is a great way to start building "simple"
    deep learning architecture with few lines of code. But if you want to achieve
    higher performance, you may want to build your own custom architecture. In this
    case, you will need to use another API called the functional API. Researchers
    use functional APIs while defining their model architecture. By learning how to
    use it, you will be able to create custom loss functions or modules, such as a
    residual block from the ResNet architecture.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using TensorFlow, you can choose from the sequential, functional, or subclassing
    APIs to define your models. For most, the sequential API will be the go-to option.
    However, as time goes by and you are exposed to more complexity, your needs will
    expand as well.
  prefs: []
  type: TYPE_NORMAL
- en: The **sequential API** is the simplest API used for creating TensorFlow models.
    It works by stacking different layers one after the other. For example, you will
    create a sequential model with a first layer that's a convolution layer, followed
    by a dropout layer, and then a fully connected layer. This model is sequential
    as the input data will be passed to each defined layer sequentially.
  prefs: []
  type: TYPE_NORMAL
- en: The **functional API** provides more flexibility. You can define models with
    different layers that interact with each other not in a sequential manner. For
    instance, you can create two different layers both of which will feed into a third
    one. This can be easily achieved with the functional API.
  prefs: []
  type: TYPE_NORMAL
- en: '`Layer` or `Model`. You can define your own custom layers or models, but this
    means you will need to comply with all the requirements of the inherited TensorFlow
    classes, such as coding mandatory methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram provides a quick overview of the three different APIs
    offered by TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1: Diagram showing a comparison of all three APIs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_10_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10.1: Diagram showing a comparison of all three APIs'
  prefs: []
  type: TYPE_NORMAL
- en: In the section ahead, you will learn how to define a custom loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Custom Loss Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several types of loss functions that are commonly used for machine
    learning. In *Chapter 5*, *Classification*, you studied different types of loss
    functions and used them with different classification models. TensorFlow has quite
    a few built-in loss functions to choose from. The following are just a few of
    the more common loss functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Mean Absolute Error (MAE)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean Squared Error (MSE)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary cross-entropy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorical cross-entropy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huber
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean Squared Logarithmic Error (MSLE)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a quick reminder, you can think of loss functions as a kind of compass that
    allows you to clearly see what is working in an algorithm and what isn't. The
    higher the loss, the less accurate the model, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Although TensorFlow has several loss functions available, at some point, you
    will most likely need to create your own loss function for your specific needs.
    For instance, if you are building a model that is predicting stock prices, you
    want to define a loss function that will penalize substantially incorrect values.
  prefs: []
  type: TYPE_NORMAL
- en: The following section will show you how to build a custom loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Custom Loss Function with the Functional API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You saw in the previous chapters how to use predefined loss functions from
    TensorFlow. But if you want to build your own custom functions, you can use either
    the functional API or model subclassing. Let''s say you want to build a loss function
    that will raise the difference between the predictions and the actual values to
    the power of 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2: Formula for custom loss'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_10_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10.2: Formula for custom loss'
  prefs: []
  type: TYPE_NORMAL
- en: 'While creating a custom loss function, you will always need two arguments:
    `y_true` (actual values) and `y_pred` (predictions). A loss function will calculate
    the difference between these two values and return an error value that represents
    how far the predictions of your model are from the actual values. In the case
    of MAE, this loss function will return the absolute value of this error. On the
    other hand, MSE will square the difference between the actual value and the predicted
    value. But in the preceding example, the error should be raised to the power of
    `4`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how you can implement this using the functional API. Firstly, you
    will need to import the TensorFlow library using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you will have to create a function called `custom_loss` that takes as
    input the `y_true` and `y_pred` arguments. You will then use the `pow` function
    to raise the calculated error to the power of `4`. Finally, you will return the
    calculated error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You have created your own custom loss function using the functional API. You
    can now pass it to the `compile` method, instead of the predefined loss functions,
    before training your model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After this, you can train your model exactly the same way as you did in previous
    chapters. TensorFlow will use your custom loss function to optimize the learning
    process of your model.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Custom Loss Function with the Subclassing API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is another way to define a custom loss function: using the subclassing
    API. In this case, rather than building a function, you will define a custom class
    for it. This is quite useful if you want to extend it with additional custom attributes
    or methods. With subclassing, you can create a custom class that will inherit
    attributes and methods from the `Loss` class of the `keras.losses` module. You
    will then need to define the `__init__()` and `call()` methods, which are required
    in the `Loss` class. The `__init__` method is where you will define all the attributes
    of your custom class, and the `call()` method is where you will specify the logic
    for calculating the loss.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a brief example of how you can implement your custom loss,
    using the subclassing API, where the error should be raised to the power of `4`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, you have reimplemented the same loss function as previously
    (power of 4) but used subclassing from `keras.losses.Loss`. You started by initializing
    the attributes of your class in the `__init__()` method using the `self` parameter,
    which refers to the object itself.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in the `call()` method, you defined the logic of your loss function, which
    calculated the error and raised it to the power of 4.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you're up to speed with loss functions, it's time for you to build
    one in the next exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 10.01: Building a Custom Loss Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will create your own custom loss function to train a CNN
    model to distinguish between images of apples and tomatoes.
  prefs: []
  type: TYPE_NORMAL
- en: You will use the `Apple-or-Tomato` dataset for this exercise. The dataset is
    a subset of the `Fruits 360` dataset on GitHub. The `Fruits 360` dataset consists
    of 1,948 total color images with dimensions of 100 by 100 pixels. The `Apple-or-Tomato`
    dataset has 992 apple images with 662 in the training set and 330 in the test
    dataset. There are a total of 956 tomato images, with 638 in the training dataset
    and 318 in the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get the `Apple-or-Tomato` dataset at the following link: [https://packt.link/28kZY](https://packt.link/28kZY).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the `Fruits 360` dataset here: [https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip](https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook or Google Colab notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you are using Google Colab, upload your dataset locally with the following
    code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate to the CSV
    file and click `Open`. Save the file as `uploaded`. Then, go to the folder where
    you have saved the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Unzip the dataset in the current folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pathlib` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `path`, that contains the full path to the dataset using
    `pathlib.Path`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables, `train_dir` and `validation_dir`, that take the full
    paths to the train and validation folders, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables, `train_apple_dir`, `train_tomato_dir`, `validation_apple_dir`,
    and `validation_tomato_dir`, that take the full paths to the `apple` and `tomato`
    folders for the train and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `os` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables, called `total_train` and `total_val`, that will get the
    number of images for the training and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from the `tensorflow.keras.preprocessing` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate two `ImageDataGenerator` classes, `train_image_generator` and `validation_image_generator`,
    that will rescale the images by dividing by 255:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `224`, and `224`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen`, using `     flow_from_directory()`, and specify the batch size, the path to the training folder,
    the value of the `shuffle` parameter, the size of the target, and the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the validation
    folder, the size of the target, and the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `matplotlib` and create a `for` loop that will iterate through five
    images from `train_data_gen` and plot them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.3: Sample of images from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_03a.jpg)![10.3 b](img/B16341_10_03b.jpg)![Figure 10.3: Sample
    of images from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_03c.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.3: Sample of images from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding results show some examples of the images contained in this dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create your custom loss function that will square the calculated error:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `NASNetMobile` model from the `tensorflow.keras.applications` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate this model with the ImageNet weights, remove the top layer, and
    specify the right input dimensions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Freeze all the layers of this model so that you are not going to update the
    model weights of `NASNetMobile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `Flatten` and `Dense` layers from the `tensorflow.keras.layers`
    module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new model that combines the `NASNetMobile` model with two new top
    layers (with 500 and 1 units, respectively) and ReLu and sigmoid as activation functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the summary of your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.4: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.4: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here, you can see the layers on the left-hand side. You have `Output Shape`
    shown—for example, `(None, 224, 224, 3)`. Then, the number of parameters is shown
    under `Param #`. At the bottom, you will find the summary, including trainable
    and non-trainable parameters.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile this model by providing your custom loss function, with Adam as the
    optimizer and accuracy as the metric to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model and provide the train and validation data generators, the number
    of steps per epoch, and the number of validation steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.5: Screenshot of training progress'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.5: Screenshot of training progress'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch. On the fifth epoch, the model is `96%` accurate
    on both the training set and the validation set.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you have successfully built your own loss function and trained
    a binary classifier with it to recognize images of apples or tomatoes. In the
    following section, you will take it a step further and build your own custom layers.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Custom Layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously, you looked at implementing your own custom loss function with either
    the TensorFlow functional API or the subclassing approach. These concepts can
    also be applied to creating custom layers for a deep learning model. In this section,
    you will build a ResNet module from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to ResNet Blocks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Residual neural network**, or **ResNet**, was first proposed by *Kaiming
    He* in his paper *Deep Residual Learning for Image Recognition* in 2015\. He introduced
    a new concept called a residual block that tackles the problem of vanishing gradients,
    which limits the ability of training very deep networks (with a lot of layers).'
  prefs: []
  type: TYPE_NORMAL
- en: A residual block is composed of multiple layers. But instead of having a single
    path where each layer is stacked and executed sequentially, a residual block contains
    two different paths. The first path has two different convolution layers. The
    second path, called the **skip connection**, takes the input and forwards it to
    the last layer of the first path. So, the input of a residual block will go through
    the first path with the sequence of convolution layers, and its result will be
    combined with the original input coming from the second path (skip connection),
    as shown in *Figure 10.6*. Without going too much into the mathematical details,
    this extra path allows the architecture to pass through the gradients in a deeper
    layer without impacting the overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6: Skip connection'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_10_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10.6: Skip connection'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, if you want to build an architecture for the preceding residual
    block, it will be quite hard with the TensorFlow sequential API. Here, you need
    to build a very customized layer. This is the reason why you need to use either
    the functional API or model subclassing instead.
  prefs: []
  type: TYPE_NORMAL
- en: Building Custom Layers with the Functional API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will see how to use the TensorFlow functional API to build
    a custom layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, you will build a function that takes your input as a tensor and adds
    ReLU and batch normalization to it. For example, in the following code snippet,
    the `relu_batchnorm_layer` function takes input and then returns a tensor. This
    makes a composite layer with ReLU activation and batch normalization in succession:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a function for your residual block. You''ll need to take a tensor
    as input and pass it to two Conv2D layers. Then, you will add the output of the
    second Conv2D layer to the original input, which represents the skip connection.
    The output of this addition will then be passed to the `relu_batchnorm_layer()`
    function that you defined in the preceding code snippet. The output will be given
    to another Conv2D layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can use this custom layer in your model. In the following code snippet,
    you will define a simple model with a Conv2D layer followed by a residual block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Let's now build custom layers using subclassing in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Building Custom Layers with Subclassing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previously, you looked at how to create a simplified version of a residual block
    using the functional API. Now, you will see how to use model subclassing to create
    a custom layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, you need to import the `Model` class together with a few layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Then, you use model subclassing to create a model with two dense layers. Firstly,
    define a model subclass denoted as `MyModel`. The objects that you will generate
    from this class are models with two dense layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the two dense layers within the `init` method. For instance, the first
    one can have `64` units and the ReLU activation function, while the second one
    can have `10` units without an activation function (in this case, the default
    activation function used is the linear one). After this, in the `call` method,
    you set up the forward pass by calling the previously defined dense layers. Firstly,
    you can place the `dense_1` layer to take the inputs and after it, the `dense_2`
    layer that returns the outputs of the layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The next step is to instantiate the model. For this, just call the class with
    no argument inside the brackets. Next, call the model on a random input to create
    the weights. For the input, this example uses a one-dimensional vector with `10`
    elements, but feel free to use a different input. You can then print the summary
    of the model where you can see the dense layers that you defined before.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following model summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting output should be like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7: Model summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_10_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10.7: Model summary'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you can modify the `call` method by including a keyword argument called
    `training`. This is useful if you want to have different behaviors in training
    and inference. For example, you can create a dropout layer that will be activated
    only if `training` is `true`. Firstly, you need to define a dropout layer within
    the `init` method, given your learning rate of `0.4`. Then, in the `call` method,
    write an `if` clause with the `training` keyword is set to `true` by default.
    Inside it, just call the dropout layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, consider the model summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The summary is displayed as follows, upon running the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8: Model summary'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_10_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10.8: Model summary'
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, you will build a custom layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 10.02: Building a Custom Layer'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Healthy-Pneumonia` dataset is a subset of the `National Institute for Health
    NIH` dataset. The dataset consists of 9,930 total color images with dimensions
    of 100 by 100 pixels. The `pneumonia-or-healthy` dataset has 1,965 total healthy
    images with 1,375 images in the training dataset and 590 images in the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You will create a custom ResNet block that consists of a Conv2D layer, a batch
    normalization layer, and a ReLU activation function. You will perform binary classification
    on the images to distinguish between healthy and pneumonic images.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get the `pneumonia-or-healthy` dataset here: [https://packt.link/IOpUX](https://packt.link/IOpUX).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook or Google Colab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you are using Google Colab, you can upload your dataset locally with the
    following code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate
    to the CSV file and click `Open`. Save the file as `uploaded`. Then, go to the
    folder where you saved the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Unzip the dataset in the current folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pathlib` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable, `path`, that contains the full path to the data using `pathlib.Path`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables, called `train_dir` and `validation_dir`, that take the
    full paths to the train and validation folders, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables, called `train_healthy_dir`, `train_pneumonia_dir`, `validation_healthy_dir`,
    and `validation_pneumonia_dir`, that take the full paths to the healthy and pneumonia
    folders for the train and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `os` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables, called `total_train` and `total_val`, to get the number
    of images for the training and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate two `ImageDataGenerator` classes and call them `train_image_generator`
    and `validation_image_generator`, which will rescale the images by dividing by
    255:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `100`, and `100`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the training folder,
    the value of the `shuffle` parameter, the size of the target, and the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the validation
    folder, the size of the target, and the class mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `matplotlib` and create a `for` loop that will iterate through five
    images from `train_data_gen` and plot them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.9: Sample of images from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_09a.jpg)![10.9 b](img/B16341_10_09b.jpg)![10.9 c](img/B16341_10_09c.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.9: Sample of images from the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding results show some examples of the images contained in this dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `Input`, `Conv2D`, `ReLU`, `BatchNormalization`, `Add`, `AveragePooling2D`,
    `Flatten`, and `Dense`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build a function that takes your input as a tensor and adds ReLU and batch
    normalization to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function to build your residual block. You will need to take a tensor
    (`input`) as your input and pass it to two Conv2D layers with a stride of `2`.
    Next, add the input to the output, followed by ReLU and batch normalization, returning
    a tensor. Add another Conv2D layer with `kernel_size=1`. Add its result to the
    output of the previous Conv2D layer. Finally, apply `relu_batchnorm_layer()` and
    return its value. You will apply the exact same filters (numbers and dimensions
    are defined by two input parameters of the construction function) to all Conv2D
    layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `Model` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `keras.layers.Input()` to define the input layer to the model. Here, your
    shape is 100 pixels by 100 pixels and has three colors (RGB):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply batch normalization to the input, followed by a Conv2D layer with `32`
    filters of size `3*3`, stride `1`, and `same` padding. Finally, apply the `relu_batchnorm_layer()`
    function to its output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Provide the output of the previous layer to the `residual_block()` function
    with `32` filters. Then, pass its output an average pooling layer with four units
    and then flatten its results before feeding it to a fully connected layer of `1`
    unit with sigmoid as the activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate a `Model()` class with the original input and the output of the
    fully connected layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the summary of your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will see a summary, including trainable and non-trainable parameters, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.10: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.10: Model summary'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Compile the model by providing binary cross-entropy as the loss function, Adam
    as the optimizer, and accuracy as the metric to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model and provide the train and validation data generators, the number
    of epochs, the steps per epoch, and the validation steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get output like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.11: Screenshot of training progress'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_10_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 10.11: Screenshot of training progress'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, you created your own custom layer for the network. Now, let's
    test the knowledge you have gained so far in the following activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 10.01: Building a Model with Custom Layers and a Custom Loss Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `table-or-glass` dataset is a subset of images taken from the `Open Images
    V6` dataset. The `Open Images V6` dataset has around 9 million images. The `table-or-glass`
    dataset consists of 7,484 total color images with dimensions of 100 by 100 pixels.
    The `table-or-glass` dataset has 3,741 total glass images with 2,618 in the training
    and 1,123 in the test dataset. There are a total of 3,743 table images with 2,618
    in the training and 1,125 in the test dataset. You are required to train a more
    complex model that can distinguish images of glasses and tables using custom ResNet
    blocks and a custom loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the dataset here: [https://packt.link/bE5F6](https://packt.link/bE5F6).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the dataset and unzip the file into a local folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the list of images for both the training and testing sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze the distribution of the target variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocess the images (standardization and reshaping).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a custom loss function that will calculate the average squared error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a custom residual block constructor function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train your model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the learning curves for accuracy and loss.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor283).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter demonstrated how to build and utilize custom TensorFlow components.
    You learned how to design and implement custom loss functions, layers, and residual
    blocks. Using the TensorFlow functional API or model subclassing allows you to
    build more complex deep learning models that may be a better fit for your projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the next and final chapter, you will explore and build generative models
    that can learn patterns and relationships within data, and use those relationships
    to generate new, unique data.
  prefs: []
  type: TYPE_NORMAL
