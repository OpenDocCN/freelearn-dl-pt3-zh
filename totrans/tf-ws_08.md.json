["```\nimport tensorflow as tf\nfrom tensorflow.keras.applications import InceptionV3\n```", "```\nmodel = InceptionV3(input_shape=(224, 224, 3), \\\n                    weights='imagenet', include_top=True)\n```", "```\nmodel.predict(input_image)\n```", "```\nmodel = InceptionV3(input_shape=(224, 224, 3), \\\n                    weights='imagenet', include_top=False)\n```", "```\nmodel.trainable = False\n```", "```\ntop_layer = tf.keras.layers.Dense(20, activation='softmax')\n```", "```\nnew_model = tf.keras.Sequential([model, top_layer])\n```", "```\nnew_model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=tf.keras.optimizers.Adam(0.001))\nnew_model.fit(X_train, t_train, epochs=50)\n```", "```\n    import tensorflow as tf\n    ```", "```\n    file_url = 'https://storage.googleapis.com'\\\n              '/mledu-datasets/cats_and_dogs_filtered.zip'\n    ```", "```\n    zip_dir = tf.keras.utils.get_file('cats_and_dogs.zip', \\\n                                      origin=file_url, extract=True)\n    ```", "```\n    import pathlib\n    ```", "```\n    path = pathlib.Path(zip_dir).parent / 'cats_and_dogs_filtered'\n    ```", "```\n    train_dir = path / 'train'\n    validation_dir = path / 'validation'\n    ```", "```\n    train_cats_dir = train_dir / 'cats'\n    train_dogs_dir = train_dir /'dogs'\n    validation_cats_dir = validation_dir / 'cats'\n    validation_dogs_dir = validation_dir / 'dogs'\n    ```", "```\n    import os\n    ```", "```\n    total_train = len(os.listdir(train_cats_dir)) \\\n                  + len(os.listdir(train_dogs_dir))\n    total_val = len(os.listdir(validation_cats_dir)) \\\n                + len(os.listdir(validation_dogs_dir))\n    ```", "```\n    from tensorflow.keras.preprocessing.image\n        import ImageDataGenerator\n    ```", "```\n    train_image_generator = ImageDataGenerator(rescale=1./255)\n    validation_image_generator = ImageDataGenerator(rescale=1./255)\n    ```", "```\n    batch_size = 16\n    img_height = 224\n    img_width = 224\n    ```", "```\n    train_data_gen = train_image_generator.flow_from_directory\\\n                     (batch_size = batch_size, \\\n                      directory = train_dir, \\\n                      shuffle=True, \\\n                      target_size = (img_height, img_width), \\\n                      class_mode='binary')\n    ```", "```\n    val_data_gen = validation_image_generator.flow_from_directory\\\n                   (batch_size = batch_size, \\\n                    directory = validation_dir, \\\n                    target_size=(img_height, img_width), \\\n                    class_mode='binary')\n    ```", "```\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```\n    from tensorflow.keras.applications import NASNetMobile\n    ```", "```\n    base_model = NASNetMobile(include_top=False, \\\n                              input_shape=(img_height, img_width, 3),\\\n                              weights='imagenet')\n    ```", "```\n    base_model.trainable = False\n    ```", "```\n    base_model.summary()\n    ```", "```\n    model = tf.keras.Sequential([base_model,\\\n                                 layers.Flatten(),\n                                 layers.Dense(500, \\\n                                              activation='relu'),\n                                 layers.Dense(1, \\\n                                              activation='sigmoid')])\n    ```", "```\n    model.compile(loss='binary_crossentropy', \\\n                  optimizer=tf.keras.optimizers.Adam(0.001), \\\n                  metrics=['accuracy'])\n    ```", "```\n    model.fit(train_data_gen, \\\n              steps_per_epoch = total_train // batch_size, \\\n              epochs=5, \\\n              validation_data = val_data_gen, \\\n              validation_steps = total_val // batch_size)\n    ```", "```\n    from tensorflow.keras.applications import MobileNetV2\n    base_model = MobileNetV2(input_shape=(224, 224, 3), \\\n                             weights='imagenet', include_top=False)\n    ```", "```\n    for layer in base_model.layers[:100]:\n        layer.trainable = False\n    ```", "```\n    prediction_layer = tf.keras.layers.Dense(20, activation='softmax')\n    model = tf.keras.Sequential([base_model, prediction_layer])\n    ```", "```\n    model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer = tf.keras.optimizers.Adam(0.001))\n    model.fit(features_train, label_train, epochs=5)\n    ```", "```\n    Rescale = 1./255, \n    rotation_range = 40, \n    width_shift_range = 0.1, \n    height_shift_range = 0.1, \n    shear_range = 0.2, \n    zoom_range = 0.2, \n    horizontal_flip = True, \n    fill_mode = 'nearest\n    ```", "```\npip install tensorflow-hub\n```", "```\nimport tensorflow_hub as hub\nMODULE_HANDLE = 'https://tfhub.dev/tensorflow/efficientnet'\\\n                '/b0/classification/1'\nmodule = hub.load(MODULE_HANDLE)\n```", "```\nimport tensorflow as tf\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(MODULE_HANDLE,input_shape=(224, 224, 3)),\n    tf.keras.layers.Activation('softmax')\n])\n```", "```\nmodel.predict(data)\n```", "```\nimport tensorflow_hub as hub\nMODULE_HANDLE = 'https://tfhub.dev/google/efficientnet/b0'\\\n                '/feature-vector/1'\nmodule = hub.load(MODULE_HANDLE)\n```", "```\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(MODULE_HANDLE, input_shape=(224, 224, 3)),\n    tf.keras.layers.Dense(20, activation='softmax')\n])\n```", "```\nmodel.compile(optimizer=optimizer, \\\n              loss='sparse_categorical_crossentropy', \\\n              metrics=['accuracy'])\nmodel.fit(X_train, epochs=5)\n```"]