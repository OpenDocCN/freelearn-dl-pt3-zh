["```\ndef squash(vectors, name=None):\n \"\"\"\n Squashing Function as implemented in the paper\n :parameter vectors: vector input that needs to be squashed\n :parameter name: Name of the tensor on the graph\n :return: a tensor with same shape as vectors but squashed as mentioned in the paper\n \"\"\"\n with tf.name_scope(name, default_name=\"squash_op\"):\n s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=-2, keepdims=True)\n scale = s_squared_norm / (1\\. + s_squared_norm) / tf.sqrt(s_squared_norm + tf.keras.backend.epsilon())\n return scale*vectors\n```", "```\ndef routing(u):\n    \"\"\"\n    This function performs the routing algorithm as mentioned in the paper\n    :parameter u: Input tensor with [batch_size, num_caps_input_layer=1152, 1, caps_dim_input_layer=8, 1] shape.\n                NCAPS_CAPS1: num capsules in the PrimaryCaps layer l\n                CAPS_DIM_CAPS2: dimensions of output vectors of Primary caps layer l\n\n    :return: \"v_j\" vector (tensor) in Digitcaps Layer\n             Shape:[batch_size, NCAPS_CAPS1=10, CAPS_DIM_CAPS2=16, 1]\n    \"\"\"\n    #local variable b_ij: [batch_size, num_caps_input_layer=1152,\n                           num_caps_output_layer=10, 1, 1]\n    #num_caps_output_layer: number of capsules in Digicaps layer l+1\n    b_ij = tf.zeros([BATCH_SIZE, NCAPS_CAPS1, NCAPS_CAPS2, 1, 1], dtype=np.float32, name=\"b_ij\")\n\n    # Preparing the input Tensor for total number of DigitCaps capsule for multiplication with W\n    u = tf.tile(u, [1, 1, b_ij.shape[2].value, 1, 1])   # u => [batch_size, 1152, 10, 8, 1]\n\n    # W: [num_caps_input_layer, num_caps_output_layer, len_u_i, len_v_j] as mentioned in the paper\n    W = tf.get_variable('W', shape=(1, u.shape[1].value, b_ij.shape[2].value,    \n        u.shape[3].value, CAPS_DIM_CAPS2),dtype=tf.float32,\n        initializer=tf.random_normal_initializer(stddev=STDEV))\n    W = tf.tile(W, [BATCH_SIZE, 1, 1, 1, 1]) # W => [batch_size, 1152, 10, 8, 16]\n\n    #Computing u_hat (as mentioned in the paper)\n    u_hat = tf.matmul(W, u, transpose_a=True)  # [batch_size, 1152, 10, 16, 1]\n\n    # In forward, u_hat_stopped = u_hat;\n    # In backward pass, no gradient pass from  u_hat_stopped to u_hat\n    u_hat_stopped = tf.stop_gradient(u_hat, name='gradient_stop')\n\n```", "```\n# Routing Algorithm Begins here\nfor r in range(ROUTING_ITERATIONS):\n    with tf.variable_scope('iterations_' + str(r)):\n        c_ij = tf.nn.softmax(b_ij, axis=2) # [batch_size, 1152, 10, 1, 1]\n\n        # At last iteration, use `u_hat` in order to back propagate gradient\n        if r == ROUTING_ITERATIONS - 1:\n            s_j = tf.multiply(c_ij, u_hat) # [batch_size, 1152, 10, 16, 1]\n            # then sum as per paper\n            s_j = tf.reduce_sum(s_j, axis=1, keep_dims=True) # [batch_size, 1, 10, 16, 1]\n\n            v_j = squash(s_j) # [batch_size, 1, 10, 16, 1]\n\n        elif r < ROUTING_ITERATIONS - 1:  # No backpropagation in these iterations\n            s_j = tf.multiply(c_ij, u_hat_stopped)\n            s_j = tf.reduce_sum(s_j, axis=1, keepdims=True)\n            v_j = squash(s_j)\n            v_j = tf.tile(v_j, [1, u.shape[1].value, 1, 1, 1]) # [batch_size, 1152, 10, 16, 1]\n\n            # Multiplying in last two dimensions: [16, 1]^T x [16, 1] yields [1, 1]\n            u_hat_dot_v = tf.matmul(u_hat_stopped, v_j, transpose_a=True) # [batch_size, 1152, 10, 1, 1]\n\n            b_ij = tf.add(b_ij,u_hat_dot_v)\nreturn tf.squeeze(v_j, axis=1) # [batch_size, 10, 16, 1]\n```", "```\ndef load_data(load_type='train'):\n    '''\n\n    :param load_type: train or test depending on the use case\n    :return: x (images), y(labels)\n    '''\n    data_dir = os.path.join('data','fashion-mnist')\n    if load_type == 'train':\n        image_file = open(os.path.join(data_dir,'train-images-idx3-ubyte'))\n        image_data = np.fromfile(file=image_file, dtype=np.uint8)\n        x = image_data[16:].reshape((60000, 28, 28, 1)).astype(np.float32)\n\n        label_file = open(os.path.join(data_dir, 'train-labels-idx1-ubyte'))\n        label_data = np.fromfile(file=label_file, dtype=np.uint8)\n        y = label_data[8:].reshape(60000).astype(np.int32)\n\n        x_train = x[:55000] / 255.\n        y_train = y[:55000]\n        y_train = (np.arange(N_CLASSES) == y_train[:, None]).astype(np.float32)\n\n        x_valid = x[55000:, ] / 255.\n        y_valid = y[55000:]\n        y_valid = (np.arange(N_CLASSES) == y_valid[:, None]).astype(np.float32)\n        return x_train, y_train, x_valid, y_valid\n    elif load_type == 'test':\n        image_file = open(os.path.join(data_dir, 't10k-images-idx3-ubyte'))\n        image_data = np.fromfile(file=image_file, dtype=np.uint8)\n        x_test = image_data[16:].reshape((10000, 28, 28, 1)).astype(np.float)\n\n        label_file = open(os.path.join(data_dir, 't10k-labels-idx1-ubyte'))\n        label_data = np.fromfile(file=label_file, dtype=np.uint8)\n        y_test = label_data[8:].reshape(10000).astype(np.int32)\n        y_test = (np.arange(N_CLASSES) == y_test[:, None]).astype(np.float32)\n return x_test / 255., y_test\n```", "```\nwith tf.variable_scope('Conv1_layer'):\n    conv1_layer = tf.layers.conv2d(self.X, name=\"conv1_layer\", **CONV1_LAYER_PARAMS) # [batch_size, 20, 20, 256]\n\nwith tf.variable_scope('PrimaryCaps_layer'):\n    conv2_layer = tf.layers.conv2d(conv1_layer, name=\"conv2_layer\", **CONV2_LAYER_PARAMS) # [batch_size, 6, 6, 256]\n\n    primary_caps = tf.reshape(conv2_layer, (BATCH_SIZE, NCAPS_CAPS1, CAPS_DIM_CAPS1, 1), name=\"primary_caps\") # [batch_size, 1152, 8, 1]\n    primary_caps_output = squash(primary_caps, name=\"caps1_output\")\n    # [batch_size, 1152, 8, 1]\n\n# DigitCaps layer, return [batch_size, 10, 16, 1]\nwith tf.variable_scope('DigitCaps_layer'):\n    digitcaps_input = tf.reshape(primary_caps_output, shape=(BATCH_SIZE, NCAPS_CAPS1, 1, CAPS_DIM_CAPS1, 1)) # [batch_size, 1152, 1, 8, 1]\n    # [batch_size, 1152, 10, 1, 1]\n    self.digitcaps_output = routing(digitcaps_input) # [batch_size, 10, 16, 1]\n```", "```\n# Decoder\nwith tf.variable_scope('Masking'):\n    self.v_norm = tf.sqrt(tf.reduce_sum(tf.square(self.digitcaps_output), axis=2, keep_dims=True) + tf.keras.backend.epsilon())\n\n    predicted_class = tf.to_int32(tf.argmax(self.v_norm, axis=1)) #[batch_size, 10,1,1]\n    self.y_predicted = tf.reshape(predicted_class, shape=(BATCH_SIZE,))  #[batch_size]\n    y_predicted_one_hot = tf.one_hot(self.y_predicted, depth=NCAPS_CAPS2)  #[batch_size,10]  One hot operation\n\n    reconstruction_targets = tf.cond(self.mask_with_labels,  # condition\n                              lambda: self.Y,  # if True (Training)\n                              lambda: y_predicted_one_hot,  # if False (Test)\n                              name=\"reconstruction_targets\")\n\n    digitcaps_output_masked = tf.multiply(tf.squeeze(self.digitcaps_output), tf.expand_dims(reconstruction_targets, -1)) # [batch_size, 10, 16]\n\n    #Flattening as suggested by the paper\n    decoder_input = tf.reshape(digitcaps_output_masked, [BATCH_SIZE, -1]) # [batch_size, 160]\n\nwith tf.variable_scope('Decoder'):\n    fc1 = tf.layers.dense(decoder_input, layer1_size, activation=tf.nn.relu, name=\"FC1\") # [batch_size, 512]\n    fc2 = tf.layers.dense(fc1, layer2_size, activation=tf.nn.relu, name=\"FC2\") # [batch_size, 1024]\n    self.decoder_output = tf.layers.dense(fc2, output_size, activation=tf.nn.sigmoid, name=\"FC3\") # [batch_size, 784]\n```", "```\nwith tf.variable_scope('Margin_Loss'):\n    # max(0, m_plus-||v_c||)^2\n    positive_error = tf.square(tf.maximum(0., 0.9 - self.v_norm)) # [batch_size, 10, 1, 1]\n    # max(0, ||v_c||-m_minus)^2\n    negative_error = tf.square(tf.maximum(0., self.v_norm - 0.1)) # [batch_size, 10, 1, 1]\n    # reshape: [batch_size, 10, 1, 1] => [batch_size, 10]\n    positive_error = tf.reshape(positive_error, shape=(BATCH_SIZE, -1))\n    negative_error = tf.reshape(negative_error, shape=(BATCH_SIZE, -1))\n\n    Loss_vec = self.Y * positive_error + 0.5 * (1- self.Y) * negative_error # [batch_size, 10]\n    self.margin_loss = tf.reduce_mean(tf.reduce_sum(Loss_vec, axis=1), name=\"margin_loss\")\n\n```", "```\nwith tf.variable_scope('Reconstruction_Loss'):\n    ground_truth = tf.reshape(self.X, shape=(BATCH_SIZE, -1))\n    self.reconstruction_loss = tf.reduce_mean(tf.square(self.decoder_output - ground_truth))\n```", "```\ndef define_accuracy(self):\n    with tf.variable_scope('Accuracy'):\n        correct_predictions = tf.equal(tf.to_int32(tf.argmax(self.Y, axis=1)), self.y_predicted)\n        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n\ndef define_optimizer(self):\n    with tf.variable_scope('Optimizer'):\n        optimizer = tf.train.AdamOptimizer()\n        self.train_optimizer = optimizer.minimize(self.combined_loss, name=\"training_optimizer\")\n```", "```\ndef train(model):\n    global fd_train\n    x_train, y_train, x_valid, y_valid = load_data(load_type='train')\n    print('Data set Loaded')\n    num_batches = int(y_train.shape[0] / BATCH_SIZE)\n    if not os.path.exists(CHECKPOINT_PATH_DIR):\n        os.makedirs(CHECKPOINT_PATH_DIR)\n\n    with tf.Session() as sess:\n        if RESTORE_TRAINING:\n            saver = tf.train.Saver()\n            ckpt = tf.train.get_checkpoint_state(CHECKPOINT_PATH_DIR)\n            saver.restore(sess, ckpt.model_checkpoint_path)\n            print('Model Loaded')\n            start_epoch = int(str(ckpt.model_checkpoint_path).split('-')[-1])\n            train_file, val_file, best_loss_val = load_existing_details()\n        else:\n            saver = tf.train.Saver(tf.global_variables())\n            tf.global_variables_initializer().run()\n            print('All variables initialized')\n            train_file, val_file = write_progress('train')\n            start_epoch = 0\n            best_loss_val = np.infty\n        print('Training Starts')\n        acc_batch_all = loss_batch_all = np.array([])\n        train_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n        for epoch in range(start_epoch, EPOCHS):\n            # Shuffle the input data\n            x_train, y_train = shuffle_data(x_train, y_train)\n            for step in range(num_batches):\n                start = step * BATCH_SIZE\n                end = (step + 1) * BATCH_SIZE\n                global_step = epoch * num_batches + step\n                x_batch, y_batch = x_train[start:end], y_train[start:end]\n                feed_dict_batch = {model.X: x_batch, model.Y: y_batch, model.mask_with_labels: True}\n                if not (step % 100):\n                    _, acc_batch, loss_batch, summary_ = sess.run([model.train_optimizer, model.accuracy,\n                                                                     model.combined_loss, model.summary_],\n                                                                    feed_dict=feed_dict_batch)\n                    train_writer.add_summary(summary_, global_step)\n                    acc_batch_all = np.append(acc_batch_all, acc_batch)\n                    loss_batch_all = np.append(loss_batch_all, loss_batch)\n                    mean_acc,mean_loss = np.mean(acc_batch_all),np.mean(loss_batch_all)\n                    summary_ = tf.Summary(value=[tf.Summary.Value(tag='Accuracy', simple_value=mean_acc)])\n                    train_writer.add_summary(summary_, global_step)\n                    summary_ = tf.Summary(value=[tf.Summary.Value(tag='Loss/combined_loss', simple_value=mean_loss)])\n                    train_writer.add_summary(summary_, global_step)\n\n                    train_file.write(str(global_step) + ',' + str(mean_acc) + ',' + str(mean_loss) + \"\\n\")\n                    train_file.flush()\n                    print(\"  Batch #{0}, Epoch: #{1}, Mean Training loss: {2:.4f}, Mean Training accuracy: {3:.01%}\".format(\n                        step, (epoch+1), mean_loss, mean_acc))\n                    acc_batch_all = loss_batch_all = np.array([])\n                else:\n                    _, acc_batch, loss_batch = sess.run([model.train_optimizer, model.accuracy, model.combined_loss],\n                                                        feed_dict=feed_dict_batch)\n                    acc_batch_all = np.append(acc_batch_all, acc_batch)\n                    loss_batch_all = np.append(loss_batch_all, loss_batch)\n\n            # Validation metrics after each EPOCH\n            acc_val, loss_val = eval_performance(sess, model, x_valid, y_valid)\n            val_file.write(str(epoch + 1) + ',' + str(acc_val) + ',' + str(loss_val) + '\\n')\n            val_file.flush()\n            print(\"\\rEpoch: {}  Mean Train Accuracy: {:.4f}% ,Mean Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n                epoch + 1, mean_acc * 100, acc_val * 100, loss_val,\n                \" (improved)\" if loss_val < best_loss_val else \"\"))\n\n            # Saving the improved model\n            if loss_val < best_loss_val:\n                saver.save(sess, CHECKPOINT_PATH_DIR + '/model.tfmodel', global_step=epoch + 1)\n                best_loss_val = loss_val\n        train_file.close()\n        val_file.close()\n```", "```\ndef reconstruct_sample(model, n_samples=5):\n    x_test, y_test = load_data(load_type='test')\n    sample_images, sample_labels = x_test[:BATCH_SIZE], y_test[:BATCH_SIZE]\n    saver = tf.train.Saver()\n    ckpt = tf.train.get_checkpoint_state(CHECKPOINT_PATH_DIR)\n    with tf.Session() as sess:\n        saver.restore(sess, ckpt.model_checkpoint_path)\n        feed_dict_samples = {model.X: sample_images, model.Y: sample_labels}\n        decoder_out, y_predicted = sess.run([model.decoder_output, model.y_predicted],\n                                       feed_dict=feed_dict_samples)\n    reconstruction(sample_images, sample_labels, decoder_out, y_predicted, n_samples)\n```", "```\ndef reconstruction(x, y, decoder_output, y_pred, n_samples):\n    '''\n    This function is used to reconstruct sample images for analysis\n    :param x: Images\n    :param y: Labels\n    :param decoder_output: output from decoder\n    :param y_pred: predictions from the model\n    :param n_samples: num images\n    :return: saves the reconstructed images\n    '''\n\n    sample_images = x.reshape(-1, IMG_WIDTH, IMG_HEIGHT)\n    decoded_image = decoder_output.reshape([-1, IMG_WIDTH, IMG_WIDTH])\n\n    fig = plt.figure(figsize=(n_samples * 2, 3))\n    for i in range(n_samples):\n        plt.subplot(1, n_samples, i+ 1)\n        plt.imshow(sample_images[i], cmap=\"binary\")\n        plt.title(\"Label:\" + IMAGE_LABELS[np.argmax(y[i])])\n        plt.axis(\"off\")\n    fig.savefig(RESULTS_DIR + '/' + 'input_images.png')\n    plt.show()\n\n    fig = plt.figure(figsize=(n_samples * 2, 3))\n    for i in range(n_samples):\n        plt.subplot(1, n_samples, i + 1)\n        plt.imshow(decoded_image[i], cmap=\"binary\")\n        plt.title(\"Prediction:\" + IMAGE_LABELS[y_pred[i]])\n        plt.axis(\"off\")\n    fig.savefig(RESULTS_DIR + '/' + 'decoder_images.png')\n    plt.show()\n```"]