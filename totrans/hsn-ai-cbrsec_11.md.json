["```\nnoise = np.random.normal(0, 1, (half_batch, self.latent_dim))\n```", "```\ntrain(self, n_epochs, batch_size=128, save_interval=50)\n```", "```\n# The generator wants the discriminator to label the generated samples as valid\n\nvalid = np.concatenate((np.ones((batch_size, 1)), np.zeros((batch_size, 1))), axis=1)\n\n# Train the generator\ng_loss, g_acc = self.combined.train_on_batch(noise, valid)\n```", "```\nfrom __future__ import print_function, division\nfrom sklearn import datasets\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport progressbar\n\nfrom sklearn.datasets import fetch_openml\nfrom mlxtend.data import loadlocal_mnist\n\nfrom mlfromscratch.deep_learning.optimizers import Adam\nfrom mlfromscratch.deep_learning.loss_functions import CrossEntropy\nfrom mlfromscratch.deep_learning.layers import Dense, Dropout, Flatten, Activation, Reshape, BatchNormalization\nfrom mlfromscratch.deep_learning import NeuralNetwork\n\n```", "```\nclass GAN():\n\n    def __init__(self):\n        self.img_rows = 28 \n        self.img_cols = 28\n        self.img_dim = self.img_rows * self.img_cols\n        self.latent_dim = 100\n\n        optimizer = Adam(learning_rate=0.0002, b1=0.5)\n        loss_function = CrossEntropy\n\n        # Build the discriminator\n        self.discriminator = self.build_discriminator(optimizer, loss_function)\n\n        # Build the generator\n        self.generator = self.build_generator(optimizer, loss_function)\n\n        # Build the combined model\n        self.combined = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n        self.combined.layers.extend(self.generator.layers)\n        self.combined.layers.extend(self.discriminator.layers)\n\n        print ()\n        self.generator.summary(name=\"Generator\")\n        self.discriminator.summary(name=\"Discriminator\")\n\n```", "```\n    def build_generator(self, optimizer, loss_function):\n\n        model = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n\n        model.add(Dense(256, input_shape=(self.latent_dim,)))\n        model.add(Activation('leaky_relu'))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(Activation('leaky_relu'))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(Activation('leaky_relu'))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(self.img_dim))\n        model.add(Activation('tanh'))\n\n        return model\n\n    def build_discriminator(self, optimizer, loss_function):\n\n        model = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n\n        model.add(Dense(512, input_shape=(self.img_dim,)))\n        model.add(Activation('leaky_relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(256))\n        model.add(Activation('leaky_relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(2))\n        model.add(Activation('softmax'))\n\n        return model\n```", "```\n    def train(self, n_epochs, batch_size=128, save_interval=50):  \n\n        X, y = loadlocal_mnist(images_path='./MNIST/train-images.idx3-ubyte', labels_path='./MNIST/train-labels.idx1-ubyte')  \n\n        # Rescale [-1, 1]\n        X = (X.astype(np.float32) - 127.5) / 127.5\n\n        half_batch = int(batch_size / 2)\n\n        for epoch in range(n_epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            self.discriminator.set_trainable(True)\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, X.shape[0], half_batch)\n            imgs = X[idx]\n\n            # Sample noise to use as generator input\n            noise = np.random.normal(0, 1, (half_batch, self.latent_dim))\n\n            # Generate a half batch of images\n            gen_imgs = self.generator.predict(noise)\n\n            # Valid = [1, 0], Fake = [0, 1]\n            valid = np.concatenate((np.ones((half_batch, 1)), np.zeros((half_batch, 1))), axis=1)\n            fake = np.concatenate((np.zeros((half_batch, 1)), np.ones((half_batch, 1))), axis=1)\n\n            # Train the discriminator\n            d_loss_real, d_acc_real = self.discriminator.train_on_batch(imgs, valid)\n            d_loss_fake, d_acc_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n            d_loss = 0.5 * (d_loss_real + d_loss_fake)\n            d_acc = 0.5 * (d_acc_real + d_acc_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # We only want to train the generator for the combined model\n            self.discriminator.set_trainable(False)\n\n            # Sample noise and use as generator input\n            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n\n            # The generator wants the discriminator to label the generated samples as valid\n            valid = np.concatenate((np.ones((batch_size, 1)), np.zeros((batch_size, 1))), axis=1)\n\n            # Train the generator\n            g_loss, g_acc = self.combined.train_on_batch(noise, valid)\n\n            # Display the progress\n            print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, acc: %.2f%%]\" % (epoch, d_loss, 100*d_acc, g_loss, 100*g_acc))\n\n            # If at save interval => save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch)\n```", "```\n    def save_imgs(self, epoch):\n        r, c = 5, 5 # Grid size\n        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n        # Generate images and reshape to image shape\n        gen_imgs = self.generator.predict(noise).reshape((-1, self.img_rows, self.img_cols))\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        plt.suptitle(\"Generative Adversarial Network\")\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt,:,:], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"mnist_%d.png\" % epoch)\n        plt.close()\n\n```", "```\nif __name__ == '__main__':\n\n    gan = GAN()\n    gan.train(n_epochs=200000, batch_size=64, save_interval=400)\n\n```", "```\npip install cleverhans\n```", "```\npip install -r requirements_cpu.txt\n```", "```\npip install -r requirements_gpu.txt\n```", "```\nmkdir downloads; curl -sL https://github.com/mzweilin/EvadeML-Zoo/releases/download/v0.1/downloads.tar.gz | tar xzv -C downloads\n```", "```\nusage: python main.py [-h] [--dataset_name DATASET_NAME] [--model_name MODEL_NAME]\n [--select [SELECT]] [--noselect] [--nb_examples NB_EXAMPLES]\n [--balance_sampling [BALANCE_SAMPLING]] [--nobalance_sampling]\n [--test_mode [TEST_MODE]] [--notest_mode] [--attacks ATTACKS]\n [--clip CLIP] [--visualize [VISUALIZE]] [--novisualize]\n [--robustness ROBUSTNESS] [--detection DETECTION]\n [--detection_train_test_mode [DETECTION_TRAIN_TEST_MODE]]\n [--nodetection_train_test_mode] [--result_folder RESULT_FOLDER]\n [--verbose [VERBOSE]] [--noverbose]\n\n optional arguments:\n -h, --help            show this help message and exit\n --dataset_name DATASET_NAME\n Supported: MNIST, CIFAR-10, ImageNet, SVHN.\n --model_name MODEL_NAME\n Supported: cleverhans, cleverhans_adv_trained and\n carlini for MNIST; carlini and DenseNet for CIFAR-10;\n ResNet50, VGG19, Inceptionv3 and MobileNet for\n ImageNet; tohinz for SVHN.\n --select [SELECT]     Select correctly classified examples for the\n experiment.\n --noselect\n --nb_examples NB_EXAMPLES\n The number of examples selected for attacks.\n --balance_sampling [BALANCE_SAMPLING]\n Select the same number of examples for each class.\n --nobalance_sampling\n --test_mode [TEST_MODE]\n Only select one sample for each class.\n --notest_mode\n --attacks ATTACKS     Attack name and parameters in URL style, separated by\n semicolon.\n --clip CLIP           L-infinity clip on the adversarial perturbations.\n --visualize [VISUALIZE]\n Output the image examples for each attack, enabled by\n default.\n --novisualize\n --robustness ROBUSTNESS\n Supported: FeatureSqueezing.\n --detection DETECTION\n Supported: feature_squeezing.\n --detection_train_test_mode [DETECTION_TRAIN_TEST_MODE]\n Split into train/test datasets.\n --nodetection_train_test_mode\n --result_folder RESULT_FOLDER\n The output folder for results.\n --verbose [VERBOSE]   Stdout level. The hidden content will be saved to log\n files anyway.\n --noverbose\n```", "```\npython main.py --dataset_name MNIST --model_name carlini \\\n --nb_examples 2000 --balance_sampling \\\n --attacks \"FGSM?eps=0.1;\" \\\n --robustness \"none;FeatureSqueezing?squeezer=bit_depth_1;\" \\\n --detection \"FeatureSqueezing?squeezers=bit_depth_1,median_filter_2_2&distance_measure=l1&fpr=0.05;\"\n\nDefense-GAN library\n```", "```\npip install -r requirements.txt\n```", "```\npython download_dataset.py [mnist|f-mnist|celeba]\n```", "```\npython train.py --cfg  --is_train\n\n --cfg This can be set to either a .yml configuration file like the ones in experiments/cfgs, or an output directory path.\n can be any parameter that is defined in the config file.\n```", "```\npython blackbox.py --cfg  \\\n     --results_dir  \\\n     --bb_model {A, B, C, D, E} \\\n     --sub_model {A, B, C, D, E} \\\n     --fgsm_eps  \\\n     --defense_type {none|defense_gan|adv_tr}\n     [--train_on_recs or --online_training]  \n```", "```\npython blackbox.py --cfg output/gans/mnist \\\n --results_dir defensegan \\\n --bb_model A \\\n --sub_model B \\\n --fgsm_eps 0.3 \\\n --defense_type defense_gan\n```", "```\npython whitebox.py --cfg  \\\n        --results_dir  \\\n        --attack_type {fgsm, rand_fgsm, cw} \\\n        --defense_type {none|defense_gan|adv_tr} \\\n        --model {A, B, C, D} \\\n        [--train_on_recs or --online_training]\n\n```", "```\npython whitebox.py --cfg  \\\n        --results_dir whitebox \\\n        --attack_type fgsm \\\n        --defense_type defense_gan \\\n        --model A\n```", "```\n\"\"\"\n MalGAN v2 Class definition\n https://github.com/yanminglai/Malware-GAN/blob/master/MalGAN_v2.py\n Released under GPL 3.0 LICENSE: https://github.com/yanminglai/Malware-GAN/blob/master/LICENSE  \n\n \"\"\"\n\n from keras.layers import Input, Dense, Activation\n from keras.layers.merge import Maximum, Concatenate\n from keras.models import Model\n from keras.optimizers import Adam\n from numpy.lib import format\n from sklearn.ensemble import RandomForestClassifier\n from sklearn import linear_model, svm\n from sklearn.model_selection import train_test_split\n import matplotlib.pyplot as plt\n from load_data import *\n import numpy as np\n```", "```\n class MalGAN():\n     def __init__(self):\n         self.apifeature_dims = 74\n         self.z_dims = 10\n         self.hide_layers = 256\n         self.generator_layers = [self.apifeature_dims+self.z_dims, self.hide_layers, self.apifeature_dims]\n         self.substitute_detector_layers = [self.apifeature_dims, self.hide_layers, 1]\n         self.blackbox = 'RF'\n         optimizer = Adam(lr=0.001)\n\n         # Build and Train blackbox_detector\n         self.blackbox_detector = self.build_blackbox_detector()\n\n         # Build and compile the substitute_detector\n         self.substitute_detector = self.build_substitute_detector()\n         self.substitute_detector.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n         # Build the generator\n         self.generator = self.build_generator()\n\n         # The generator takes malware and noise as input and generates adversarial malware examples\n         example = Input(shape=(self.apifeature_dims,))\n         noise = Input(shape=(self.z_dims,))\n         input = [example, noise]\n         malware_examples = self.generator(input)\n\n         # For the combined model we will only train the generator\n         self.substitute_detector.trainable = False\n\n         # The discriminator takes generated images as input and determines validity\n         validity = self.substitute_detector(malware_examples)\n\n         # The combined model  (stacked generator and substitute_detector)\n         # Trains the generator to fool the discriminator\n         self.combined = Model(input, validity)\n         self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n```", "```\n     def build_blackbox_detector(self):\n\n         if self.blackbox is 'RF':\n             blackbox_detector = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=1)\n         return blackbox_detector\n\n     def build_generator(self):\n\n         example = Input(shape=(self.apifeature_dims,))\n         noise = Input(shape=(self.z_dims,))\n         x = Concatenate(axis=1)([example, noise])\n         for dim in self.generator_layers[1:]:\n             x = Dense(dim)(x)\n         x = Activation(activation='sigmoid')(x)\n         x = Maximum()([example, x])\n         generator = Model([example, noise], x, name='generator')\n         generator.summary()\n         return generator\n\n     def build_substitute_detector(self):\n\n         input = Input(shape=(self.substitute_detector_layers[0],))\n         x = input\n         for dim in self.substitute_detector_layers[1:]:\n             x = Dense(dim)(x)\n         x = Activation(activation='sigmoid')(x)\n         substitute_detector = Model(input, x, name='substitute_detector')\n         substitute_detector.summary()\n         return substitute_detector\n```", "```\n     def train(self, epochs, batch_size=32):\n\n         # Load the dataset\n         (xmal, ymal), (xben, yben) = self.load_data('mydata.npz')\n         xtrain_mal, xtest_mal, ytrain_mal, ytest_mal = train_test_split(xmal, ymal, test_size=0.20)\n         xtrain_ben, xtest_ben, ytrain_ben, ytest_ben = train_test_split(xben, yben, test_size=0.20)\n\n         # Train blackbox_detector\n         self.blackbox_detector.fit(np.concatenate([xmal, xben]),\n                                    np.concatenate([ymal, yben]))\n\n         ytrain_ben_blackbox = self.blackbox_detector.predict(xtrain_ben)\n         Original_Train_TPR = self.blackbox_detector.score(xtrain_mal, ytrain_mal)\n         Original_Test_TPR = self.blackbox_detector.score(xtest_mal, ytest_mal)\n         Train_TPR, Test_TPR = [Original_Train_TPR], [Original_Test_TPR]\n         best_TPR = 1.0\n         for epoch in range(epochs):\n\n             for step in range(xtrain_mal.shape[0] // batch_size):\n                 # ---------------------\n                 #  Train substitute_detector\n                 # ---------------------\n\n                 # Select a random batch of malware examples\n                 idx = np.random.randint(0, xtrain_mal.shape[0], batch_size)\n                 xmal_batch = xtrain_mal[idx]\n                 noise = np.random.uniform(0, 1, (batch_size, self.z_dims))   #noise as random uniform\n                 idx = np.random.randint(0, xmal_batch.shape[0], batch_size)\n                 xben_batch = xtrain_ben[idx]\n                 yben_batch = ytrain_ben_blackbox[idx]\n\n                 # Generate a batch of new malware examples\n                 gen_examples = self.generator.predict([xmal_batch, noise])\n                 ymal_batch = self.blackbox_detector.predict(np.ones(gen_examples.shape)*(gen_examples > 0.5))\n\n                 # Train the substitute_detector\n                 d_loss_real = self.substitute_detector.train_on_batch(gen_examples, ymal_batch)\n                 d_loss_fake = self.substitute_detector.train_on_batch(xben_batch, yben_batch)\n                 d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)               \n```", "```\n\n                 idx = np.random.randint(0, xtrain_mal.shape[0], batch_size)\n                 xmal_batch = xtrain_mal[idx]\n                 noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n\n                 # Train the generator\n                 g_loss = self.combined.train_on_batch([xmal_batch, noise], np.zeros((batch_size, 1)))\n\n             # Compute Train TPR\n             noise = np.random.uniform(0, 1, (xtrain_mal.shape[0], self.z_dims))\n             gen_examples = self.generator.predict([xtrain_mal, noise])\n             TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytrain_mal)\n             Train_TPR.append(TPR)\n\n             # Compute Test TPR\n             noise = np.random.uniform(0, 1, (xtest_mal.shape[0], self.z_dims))\n             gen_examples = self.generator.predict([xtest_mal, noise])\n             TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytest_mal)\n             Test_TPR.append(TPR)\n\n             # Save best model\n             if TPR < best_TPR:\n                 self.combined.save_weights('saves/malgan.h5')\n                 best_TPR = TPR\n```", "```\n if __name__ == '__main__':\n     malgan = MalGAN()\n     malgan.train(epochs=50, batch_size=64)\n\n```", "```\n\"\"\"\n Script name: facenet_fgsm.py  \n https://github.com/tensorflow/cleverhans/blob/master/examples/facenet_adversarial_faces/facenet_fgsm.py\n Released under MIT LICENSE:  \n https://github.com/tensorflow/cleverhans/blob/master/LICENSE\n \"\"\"\n\n import facenet\n import tensorflow as tf\n import numpy as np\n from cleverhans.model import Model\n from cleverhans.attacks import FastGradientMethod\n\n import set_loader\n\n```", "```\n class InceptionResnetV1Model(Model):\n   model_path = \"models/facenet/20170512-110547/20170512-110547.pb\"\n\n   def __init__(self):\n     super(InceptionResnetV1Model, self).__init__(scope='model')\n\n     # Load Facenet CNN\n     facenet.load_model(self.model_path)\n     # Save input and output tensors references\n     graph = tf.get_default_graph()\n     self.face_input = graph.get_tensor_by_name(\"input:0\")\n     self.embedding_output = graph.get_tensor_by_name(\"embeddings:0\")\n\n   def convert_to_classifier(self):\n     # Create victim_embedding placeholder\n     self.victim_embedding_input = tf.placeholder(\n         tf.float32,\n         shape=(None, 128))\n\n     # Squared Euclidean Distance between embeddings\n     distance = tf.reduce_sum(\n         tf.square(self.embedding_output - self.victim_embedding_input),\n         axis=1)\n\n     # Convert distance to a softmax vector\n     # 0.99 out of 4 is the distance threshold for the Facenet CNN\n     threshold = 0.99\n     score = tf.where(\n         distance > threshold,\n         0.5 + ((distance - threshold) * 0.5) / (4.0 - threshold),\n         0.5 * distance / threshold)\n     reverse_score = 1.0 - score\n     self.softmax_output = tf.transpose(tf.stack([reverse_score, score]))\n\n     # Save softmax layer\n     self.layer_names = []\n     self.layers = []\n     self.layers.append(self.softmax_output)\n     self.layer_names.append('probs')\n\n   def fprop(self, x, set_ref=False):\n     return dict(zip(self.layer_names, self.layers))\n\n```", "```\n\n with tf.Graph().as_default():\n   with tf.Session() as sess:\n     # Load model\n     model = InceptionResnetV1Model()\n     # Convert to classifier\n     model.convert_to_classifier()\n\n     # Load pairs of faces and their labels in one-hot encoding\n     faces1, faces2, labels = set_loader.load_testset(1000)\n\n     # Create victims' embeddings using Facenet itself\n     graph = tf.get_default_graph()\n     phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n     feed_dict = {model.face_input: faces2,\n                  phase_train_placeholder: False}\n     victims_embeddings = sess.run(\n         model.embedding_output, feed_dict=feed_dict)\n\n     # Define FGSM for the model\n     steps = 1\n     eps = 0.01\n     alpha = eps / steps\n     fgsm = FastGradientMethod(model)\n     fgsm_params = {'eps': alpha,\n                    'clip_min': 0.,\n                    'clip_max': 1.}\n     adv_x = fgsm.generate(model.face_input, **fgsm_params)\n\n     # Run FGSM\n     adv = faces1\n     for i in range(steps):\n       print(\"FGSM step \" + str(i + 1))\n       feed_dict = {model.face_input: adv,\n                    model.victim_embedding_input: victims_embeddings,\n                    phase_train_placeholder: False}\n       adv = sess.run(adv_x, feed_dict=feed_dict)\n\n```", "```\nmodel_path = \"models/facenet/20170512-110547/20170512-110547.pb\"\n```", "```\npython facenet_fgsm.py\n```"]