- en: 8\. Pre-Trained Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will analyze pre-trained models. You will get hands-on
    experience using the different state-of-the-art model architectures available
    on TensorFlow. You will explore concepts such as transfer learning and fine-tuning
    and look at TensorFlow Hub and its published deep learning resources.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the chapter, you will be able to use pre-trained models directly
    from TensorFlow and TensorFlow Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how **convolution neural networks** (**CNNs**)
    analyze images and learn relevant patterns to classify their main subjects or
    identify objects within them. You also saw the different types of layers used
    for such models.
  prefs: []
  type: TYPE_NORMAL
- en: But rather than training a model from scratch, it would be more efficient if
    you could reuse existing models with pre-calculated weights. This is exactly what
    **transfer learning** and **fine-tuning** are about. You will learn how to apply
    these techniques to your own projects and datasets in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: You will also look at the ImageNet competition and the corresponding dataset
    that is used by deep learning researchers to benchmark their models against state-of-the-art
    algorithms. Finally, you will learn how to use TensorFlow Hub's resources to build
    your own model.
  prefs: []
  type: TYPE_NORMAL
- en: ImageNet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ImageNet is a large dataset containing more than 14 million images annotated
    for image classification or object detection. It was first consolidated by Fei-Fei
    Li and her team in 2007\. The goal was to build a dataset that computer vision
    researchers could benefit from.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset was presented for the first time in 2009, and every year since 2010,
    an annual competition called the **ImageNet Large-Scale Visual Recognition Challenge**
    (**ILSVRC**) has been organized for image classification and object detection
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: Examples of images from ImageNet'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_08_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.1: Examples of images from ImageNet'
  prefs: []
  type: TYPE_NORMAL
- en: Over the years, some of the most famous CNN architectures (such as AlexNet,
    Inception, VGG, and ResNet) have achieved amazing results in this ILSVRC competition.
    In the following graph, you can see how some of the most famous CNN architectures
    performed in this competition. In less than 10 years, performance increased from
    50% accuracy to almost 90%.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: Model benchmarking from paperswithcode.com'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16341_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.2: Model benchmarking from paperswithcode.com'
  prefs: []
  type: TYPE_NORMAL
- en: You will see in the next section how you can use transfer learning with these
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you got hands-on practice training different CNN models
    for image classification purposes. Even though you achieved good results, the
    models took quite some time to learn the relevant parameters. If you kept training
    the models, you could have achieved even better results. Using **graphical processing
    units** (**GPUs**) can shorten the training time, but it will still take a bit
    of time, especially for bigger or more complex datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning researchers have published their work for the benefit of the community.
    Everyone can benefit by taking existing model architectures and customizing them,
    rather than designing architectures from scratch. More than this though, researchers
    also share the weights of their models. You can then not only reuse an architecture
    but also leverage all the training performed on it. This is what transfer learning
    is about. By reusing pre-trained models, you don't have to start from scratch.
    These models are trained on a large dataset such as ImageNet and have learned
    how to recognize thousands of different categories of objects. You can reuse these
    state-of-the-art models straight out of the box without having to train them.
    Isn't that amazing? Rather than training a model for weeks, you can now just use
    an existing model.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow provides a list of state-of-the-art models pre-trained on the ImageNet
    dataset for transfer learning in its Keras API.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the full list of pre-trained models available in TensorFlow at
    the following link: [https://www.tensorflow.org/api_docs/python/tf/keras/applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Importing a pre-trained model is quite simple in TensorFlow, as shown with
    the following example, where you load the `InceptionV3` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that you have imported the class for the pre-trained model, you need to
    instantiate it by specifying the dimensions of the input image and `imagenet`
    as the pre-trained weights to be loaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `include_top=True` parameter specifies that you will be re-using the exact
    same top layer (which is the final layer) as for the original model trained on
    ImageNet. This means that the last layer is designed to predict the 1,000 classes
    that are in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have instantiated your pre-trained model, you can make predictions
    from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you want to use this pre-trained model to predict different categories than
    the ones from ImageNet, you will need to replace the top layer with another one
    that will be trained to recognize the specific categories of the input dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to remove this layer by specifying `include_top=False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, you have loaded an `InceptionV3` model. The next
    step will be to *freeze* all the layers from this model so that their weights
    will not be updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After this, you will instantiate a new fully connected layer with the number
    of units and activation function of your choice. In the following example, you
    want to predict 50 different classes. To do this, you create a dense layer with
    `20` units and use softmax as the activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you need to add this fully connected layer to your base model with the
    Sequential API from Keras:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can train this model and only the top-layer weights will be updated.
    All the other layers have been frozen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In just a few lines of code, you have loaded the Inception V3 model, which is
    a state-of-the-art model that won the ILSVRC competition in 2016\. You learned
    how to adapt it to your own project and dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, you will have hands-on practice on transfer learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8.01: Classifying Cats and Dogs with Transfer Learning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will use transfer learning to correctly classify images
    as either cats or dogs. You will use a pre-trained model, NASNet-Mobile, that
    is already available in TensorFlow. This model comes with pre-trained weights
    on ImageNet.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The original dataset used in this exercise has been provided by Google. It contains
    25,000 images of dogs and cats. It can be found here: [https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip](https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip).'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the TensorFlow library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `file_url` containing a link to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the dataset using `tf.keras.get_file`, with `''cats_and_dogs.zip''`,
    `origin=file_url`, and `extract=True` as parameters, and save the result to a
    variable called `zip_dir`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pathlib` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable called `path` containing the full path to the `cats_and_dogs_filtered`
    directory using `pathlib.Path(zip_dir).parent`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `train_dir` and `validation_dir` that take the
    full path to the `train` and `validation` folders, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create four variables called `train_cats_dir`, `train_dogs_dir`, `validation_cats_dir`,
    and `validation_dogs_dir` that take the full path to the `cats` and `dogs` folders
    for the train and validation sets, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `os` package. In the next step, you will need to count the number
    of images from a folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create two variables called `total_train` and `total_val` that get the number
    of images for the training and validation sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate two `ImageDataGenerator` classes and call them `train_image_generator`
    and `validation_image_generator`. These will rescale images by dividing by `255`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create three variables called `batch_size`, `img_height`, and `img_width` that
    take the values `16`, `224`, and `224`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `train_data_gen` using `flow_from_directory()`
    method, and specify the batch size, the path to the training folder, the size
    of the target, and the mode of the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a data generator called `val_data_gen` using `flow_from_directory()`
    method and specify the batch size, the path to the validation folder, the size
    of the target, and the mode of the class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set `8` (this is totally arbitrary) as `seed` for NumPy and TensorFlow:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `NASNETMobile` model from `tensorflow.keras.applications`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the model with the ImageNet weights, remove the top layer, and specify
    the correct input dimensions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Freeze all the layers of this model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print a summary of the model using the `summary()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.3: Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.3: Summary of the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a new model that combines the `NASNETMobile` model with two new top
    layers with `500` and `1` unit(s) and ReLu and sigmoid as the activation functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile the model by providing `binary_crossentropy` as the `loss` function,
    an Adam optimizer with a learning rate of `0.001`, and `accuracy` as the metric
    to be displayed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the model, provide the train and validation data generators, and run it
    for five epochs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.4: Model training output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.4: Model training output'
  prefs: []
  type: TYPE_NORMAL
- en: You can observe that the model achieved an accuracy score of `0.99` on the training
    set and `0.98` on the validation set. This is quite a remarkable result given
    that you only trained the last two layers, and it took less than a minute. This
    is the benefit of applying transfer learning and using pre-trained state-of-the-art
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will see how you can apply fine-tuning to a pre-trained
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously, you used transfer learning to leverage pre-trained models on your
    own dataset. You used the weights of state-of-the-art models that have been trained
    on large datasets such as ImageNet. These models learned the relevant parameters
    to recognize different patterns from images and helped you to achieve amazing
    results on different datasets.
  prefs: []
  type: TYPE_NORMAL
- en: But there is a catch with this approach. Transfer learning works well in general
    if the classes you are trying to predict belong to the same list as that of ImageNet.
    If this is the case, the weight learned from ImageNet will also be relevant to
    your dataset. For example, the `cats` and `dogs` classes from the preceding exercise
    are present in ImageNet, so its weights will also be relevant for this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: However, if your dataset is very different from ImageNet, then the weights from
    these pre-trained models may not all be relevant. For example, if your dataset
    contains satellite images, and you are trying to determine whether a house has
    solar panels installed on its roof, this will be very different compared to ImageNet.
    The weights from the last layers will be very specific to the classes from ImageNet,
    such as cat whiskers or car wheels (which are not very useful for the satellite
    image dataset case), while the ones from earlier layers will be more generic,
    such as for detecting shapes, colors, or texture (which can be applied to the
    satellite image dataset).
  prefs: []
  type: TYPE_NORMAL
- en: So, it will be great to still leverage some of the weights from earlier layers
    but train the final layers so that your models can learn the specific patterns
    relevant to your dataset and improve its performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique is called fine-tuning. The idea behind it is quite simple: you
    freeze early layers and update the weights of the final layers only. Let''s see
    how you can achieve this in TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, instantiate a pre-trained `MobileNetV2` model without the top layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, iterate through the first layers and freeze them by setting them as non-trainable.
    In the following example, you will freeze only the first `100` layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now you need to add your custom top layer to your base model. In the following
    example, you will be predicting 20 different classes, so you need to add a fully
    connected layer of `20` units with the softmax activation function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, you will compile and then train this model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will display a number of logs, as seen in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.5: Fine-tuning results on a pre-trained MobileNetV2 model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.5: Fine-tuning results on a pre-trained MobileNetV2 model'
  prefs: []
  type: TYPE_NORMAL
- en: That's it. You have just performed fine-tuning on a pre-trained MobileNetV2
    model. You have used the first 100 pre-trained weights from ImageNet and only
    updated the weights from layer 100 onward according to your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the next activity, you will put into practice what you have just learned
    and apply fine-tuning to a pre-trained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 8.01: Fruit Classification with Fine-Tuning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Fruits 360` dataset ([https://arxiv.org/abs/1712.00580](https://arxiv.org/abs/1712.00580)),
    which was originally shared by *Horea Muresan and Mihai Oltean, Fruit recognition
    from images using deep learning, Acta Univ. Sapientiae, Informatica Vol. 10, Issue
    1, pp. 26-42, 2018*, contains more than 82,000 images of 120 different types of
    fruit. You will be using a subset of this dataset with more than 16,000 images.
    The numbers of images in the training and validation sets are `11398` and `4752`
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, you are tasked with training a `NASNetMobile` model to recognize
    images of different varieties of fruits (classification into 120 different classes).
    You will use fine-tuning to train the final layers of this model.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset can be found here: [http://packt.link/OFUJj](http://packt.link/OFUJj).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the dataset and unzip the file using TensorFlow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a data generator with the following data augmentation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Load a pre-trained `NASNetMobile` model from TensorFlow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Freeze the first `600` layers of the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add two fully connected layers on top of `NASNetMobile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: – A fully connected layer with `Dense(1000, activation=relu)`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – A fully connected layer with `Dense(120, activation='softmax')`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Specify an Adam optimizer with a learning rate of `0.001`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the model on the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The expected output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.6: Expected output of the activity'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.6: Expected output of the activity'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor274).
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know how to use pre-trained models from TensorFlow, you will learn
    how models can be accessed from TensorFlow Hub in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Hub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow Hub is a repository of TensorFlow modules shared by publishers such
    as Google, NVIDIA, and Kaggle. TensorFlow modules are self-contained models built
    on TensorFlow that can be reused for different tasks. Put simply, it is an external
    collection of published TensorFlow modules for transfer learning and fine-tuning.
    With TensorFlow Hub, you can access different deep learning models or weights
    than the ones provided directly from TensorFlow's core API.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find more information about TensorFlow Hub here: [https://tfhub.dev/](https://tfhub.dev/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use it, you first need to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Once it''s installed, you can load available classification models with the
    `load()` method by specifying the link to a module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, you have loaded the **EfficientNet B0** model, which
    was trained on ImageNet. You can find more details on this at the TensorFlow Hub
    page: [https://tfhub.dev/tensorflow/efficientnet/b0/classification/1](https://tfhub.dev/tensorflow/efficientnet/b0/classification/1).'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'TensorFlow Hub provides a search engine to find a specific module: [https://tfhub.dev/s?subtype=module,placeholder](https://tfhub.dev/s?subtype=module,placeholder).'
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, modules loaded from TensorFlow Hub contain the final layer of a
    model without an activation function. For classification purposes, you need to
    add an activation layer of your choice. To do so, you can use the Sequential API
    from Keras. You just need to convert your model into a Keras layer with the `KerasLayer`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can use your final model to perform predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: You just performed transfer learning with a model from TensorFlow Hub. This
    is very similar to what you learned previously using the Keras API, where you
    loaded an entire model with `include_top=True`. With TensorFlow Hub, you can access
    a library of pre-trained models for object detection or image segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will learn how to extract features from TensorFlow
    Hub pre-trained modules.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Extraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TensorFlow Hub provides the option of downloading a model without the final
    layer. In this case, you will be using a TensorFlow module as a feature extractor;
    you can design your custom final layers on top of it. In TensorFlow Hub, a module
    used for feature extraction is known as a feature vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'To find all the available feature vectors on TensorFlow Hub, you can use its
    search engine: [https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2](https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once loaded, you can add your own final layer to the feature vector with the
    Sequential API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, you added a fully connected layer of `20` units with
    the softmax activation function. Next, you need to compile and train your model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: And with that, you just used a feature vector from TensorFlow Hub and added
    your custom final layer to train the final model on your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Now, test the knowledge you have gained so far in the next activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 8.02: Transfer Learning with TensorFlow Hub'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, you are required to correctly classify images of cats and
    dogs using transfer learning. Rather than training a model from scratch, you will
    benefit from the **EfficientNet B0** feature vector from TensorFlow Hub, which
    contains pre-computed weights that can recognize different types of objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the dataset here: [https://packt.link/RAAtm](https://packt.link/RAAtm).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the dataset and unzip the file using TensorFlow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a data generator that will perform rescaling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load a pre-trained **EfficientNet B0** feature vector from TensorFlow Hub.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add two fully connected layers on top of the feature vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: – A fully connected layer with `Dense(500, activation=relu)`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – A fully connected layer with `Dense(1, activation='sigmoid')`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Specify an Adam optimizer with a learning rate of `0.001`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the model on the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The expected output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.7: Expected output of the activity'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16341_08_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 8.7: Expected output of the activity'
  prefs: []
  type: TYPE_NORMAL
- en: The expected accuracy scores should be around `1.0` for the training and validation
    sets.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor277).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you learned two very important concepts: transfer learning
    and fine-tuning. Both help deep learning practitioners to leverage existing pre-trained
    models and adapt them to their own projects and datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning is the re-use of models that have been trained on large datasets
    such as ImageNet (which contains more than 14 million images). TensorFlow provides
    a list of such pre-trained models in its core API. You can also access other models
    from renowned publishers such as Google and NVIDIA through TensorFlow Hub.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you got some hands-on practice fine-tuning a pre-trained model. You
    learned how to freeze the early layers of a model and only train the last layers
    according to the specificities of the input dataset.
  prefs: []
  type: TYPE_NORMAL
- en: These two techniques were a major breakthrough for the community as they facilitated
    access to state-of-the-art models for anyone interested in applying deep learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will look at another type of model architecture, **recurrent
    neural networks** (**RNNs**). This type of architecture is well suited for sequential
    data such as time series or text.
  prefs: []
  type: TYPE_NORMAL
