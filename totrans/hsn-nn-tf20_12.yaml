- en: Generative Adversarial Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, **Generative Adversarial Networks** (**GANs**) and the adversarial
    training process will be presented. In the first section, we will go over a theoretical
    overview of the GAN framework, while highlighting the strengths of the adversarial
    training process and the flexibility that was introduced by using neural networks
    as the model of choice for creating GANs. The theoretical part will give you an
    intuitive idea about which part of the GAN value function is being optimized during
    the adversarial training process and show you why the non-saturating value function
    should be used instead of the original one.
  prefs: []
  type: TYPE_NORMAL
- en: We will then go through a step-by-step implementation of GAN models and their
    training, with a visual explanation of what happens during this process. You will
    become familiar with the concept of target and learned distributions, which happens
    by watching the model learn.
  prefs: []
  type: TYPE_NORMAL
- en: The natural extension of the GAN framework to the conditional version is presented
    in the second part of this chapter, and how to create a conditional image generator
    will be shown. This chapter, just like the previous ones, will end with an exercise
    section that you are encouraged not to skip.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding GANs and their applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unconditional GANs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditional GANs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding GANs and their applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduced in 2014 by *Ian Goodfellow et a*l. in the paper *Generative Adversarial
    Networks*, GANs have revolutionized the field of generative models, opening the
    road to incredible applications.
  prefs: []
  type: TYPE_NORMAL
- en: GANs are frameworks that are used for the estimation of generative models via
    an adversarial process in which two models, the Generator and the Discriminator,
    are trained simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of the generative model (Generator) is to capture the data distribution
    contained in the training set, while the discriminative model acts as a binary
    classifier. Its goal is to estimate the probability of a sample to come from the
    training data rather than from the Generator. In the following diagram, the general
    architecture of adversarial training is shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fba6a37e-b988-4e77-8349-1136b7967d6e.png)'
  prefs: []
  type: TYPE_IMG
- en: Graphical representation of the adversarial training process. The generator
    goal is used to fool the Discriminator by learning to generate samples that are
    more and more similar to the training set. (Image source: [https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/](https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/)—by
    Thalles Silva)
  prefs: []
  type: TYPE_NORMAL
- en: The idea is to train a generative model without explicitly defining a loss function.
    Instead, we use a signal coming from another network as feedback. The Generator's
    aim is to fool the Discriminator, while the Discriminator's aim is to correctly
    classify whether the input samples are real or fake. The power of adversarial
    training comes from the fact that both the Generator and the Discriminator can
    be non-linear, parametric models such as neural networks. It is therefore possible
    to use gradient descent to train them.
  prefs: []
  type: TYPE_NORMAL
- en: To learn about generator distribution over the data, the generator builds a *mapping*
    from a **prior noise distribution**, ![](img/d91fb882-7ced-4adc-8bdb-288dc00f1560.png), to
    a data space ![](img/3471d5f4-6777-44d6-a144-c7ee3752541a.png).
  prefs: []
  type: TYPE_NORMAL
- en: The Discriminator, ![](img/0928f736-02e1-4807-a547-532c511468a9.png), is a function
    (neural network) that outputs a single scalar representing the probability that
    ![](img/84ccb37f-c4bc-4a14-93a7-e97a3c82eb2a.png) came from the real data distribution
    rather than ![](img/334013b8-4a01-4e39-b5ae-946dacf66adf.png).
  prefs: []
  type: TYPE_NORMAL
- en: The original GAN framework is expressed by using a game-theory approach to the
    problem and poses it as a min-max game in which two players, the Generator and
    the Discriminator, compete against each other.
  prefs: []
  type: TYPE_NORMAL
- en: Value function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The value function is a mathematical way of representing the goals of the players
    in terms of expected returns. The GAN game is expressed by the following value
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3613a64-5f05-4433-9fe0-a6c87efcc08e.png)'
  prefs: []
  type: TYPE_IMG
- en: This value function represents the game that the two players are playing, along
    with their respective long-term goals.
  prefs: []
  type: TYPE_NORMAL
- en: The Discriminator's goal is to correctly classify the real and fake samples,
    and this goal is expressed as the **maximization** of both the ![](img/19a63dae-6136-4f21-ac4c-f4b38a1c29b7.png) and ![](img/a1aa6880-eb9b-4525-8622-68a508d897fd.png) terms.
    The former represents the correct classification of the samples coming from the
    real data distribution (therefore, the goal is to get ![](img/e83ace9e-d8be-4a3f-8c7c-b668fd0dad27.png)),
    while the latter is the correct classification of fake samples (and in this case,
    the goal is to get ![](img/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png)).
  prefs: []
  type: TYPE_NORMAL
- en: The generator, on the other hand, is trained to fool the Discriminator, and
    its goal is to **minimize** ![](img/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png).
    The way you minimize this term is by producing samples that are more and more
    similar to the real ones, thereby trying to fool the Discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: A subtlety worth noting is that the min-max game is played only in the second
    term of the value function since, in the first term, only the Discriminator plays.
    It does this by learning to correctly classify the data coming from the real data
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Although clear and pretty easy to understand, this formulation has a practical
    disadvantage. In the early training steps, the Discriminator can easily learn
    how to correctly classify fake data by maximizing ![](img/a1aa6880-eb9b-4525-8622-68a508d897fd.png) because
    the generated samples are too different from the real ones. Since learning from
    the quality of the generated samples is poor, the Discriminator can reject samples
    with high confidence because they are clearly different from the training data.
    This rejection consists of classing the correct classification of the generated
    samples as fake (![](img/661edc6d-d6d9-4a46-a80f-560c12e7e73d.png)), making the
    term ![](img/53ae8b8b-a838-42c6-87a3-31ff8ec90a2f.png) saturate. It follows that
    the previous equation may not provide a sufficient gradient for *G* to learn well.
    The solution to this practical problem is the definition of a new value function
    that does not saturate.
  prefs: []
  type: TYPE_NORMAL
- en: Non-saturating value function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The proposed solution is to train *G* to **maximize** ![](img/ec6f3dc9-5b0c-45ca-ad62-cdeb1404156e.png) instead
    of minimizing ![](img/30b90557-a9fe-474e-a64d-b6908d6af3d4.png). Intuitively,
    we can see the proposed solution as a way of playing the same min-max game in
    a different manner.
  prefs: []
  type: TYPE_NORMAL
- en: The Discriminator's goal is to maximize the probability of correctly classifying
    the real and fake samples, with no changes with respect to the previous formulation.
    The Generator's goal, on the other hand, is to minimize the Discriminator's probability
    of correctly classifying the generated samples as fake but to explicitly fool
    the Discriminator by making it classify the fake samples as real.
  prefs: []
  type: TYPE_NORMAL
- en: 'The value function of the same game, which is played in a different manner
    by the two players, can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/162c9bb9-438c-4a07-bd81-08ffc92c02a4.png)'
  prefs: []
  type: TYPE_IMG
- en: As we stated previously, the power of the adversarial training frameworks comes
    from the fact that both *G* and *D* can be neural networks and that they can both
    be trained via gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: Model definition and training phase
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Defining the Generator and the Discriminator as neural networks allows us to
    tackle the problem using all the neural network architectures that have been developed
    over the years, with each one specialized to work with a certain data type.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are no constraints in the model''s definition; in fact, it is possible
    to define their architecture in a completely arbitrary manner. The only constraints
    are given by the structure of the data we are working on; the architectures depend
    on the data type, all of which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Images**: Convolutional neural networks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sequences, Text**: Recurrent neural networks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Numerical, Categorical values**: Fully connected networks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we've defined the model's architecture as a function of the data type,
    it is possible to use them to play the min-max game.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adversarial training consists of alternating the execution of training steps.
    Every training step is a player action, and the Generator and Discriminator compete
    against each other in turn. The game follows the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Discriminator**: The Discriminator plays first and can repeat the following
    three steps from 1 to *k* times, where *k* is a hyperparameter (often, *k* equals
    1):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sample a minibatch of *m* noise samples, ![](img/8c7a168d-8b67-487c-a89b-caac740d62f9.png), from
    the noise prior to ![](img/ab6c44ac-0ebc-4771-9cd5-8bd7ae76b1da.png)
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample a minibatch of *m* samples, ![](img/d26d6ddc-669a-47fd-b298-b7464f068ece.png), from
    the real data distribution, ![](img/12e80660-9f99-4caf-abe9-f848567808e5.png)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Train the Discriminator via stochastic gradient ascent: **![](img/e43e40a8-c222-4ba9-9f07-0009b1325e5a.png)**'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Here, ![](img/5a54844b-6ec5-4e7e-92cd-686cfec824fd.png) is the Discriminator's
    parameters
  prefs: []
  type: TYPE_NORMAL
- en: '**Generator**: The Generator always plays after the Discriminator''s turn,
    and it plays only once:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sample a minibatch of *m* noise samples, ![](img/6f6acbf8-4fcc-4154-a9bc-ee1c64d5b85b.png), from
    the noise prior to ![](img/e4c37a82-c37a-46d9-aad3-aed8b32e47b1.png)
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Train the Generator via stochastic gradient ascent (this is a maximization
    problem since the game is targeted the non-saturating value function):'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7042fc2f-3c83-4eab-9725-72b756c3d182.png)'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_IMG
- en: Here, ![](img/da88d371-aa89-428a-88c7-ccd6fe0b3780.png) is the Generator's parameters
  prefs: []
  type: TYPE_NORMAL
- en: Just like any other neural network that's trained via gradient descent, the
    updates can use any standard optimization algorithm (Adam, SGD, SGD with Momentum,
    and so on). The game should go on until the Discriminator isn't completely fooled
    by the Generator, that is, when the Discriminator always predicts a probability
    of 0.5 for every input sample. The value of 0.5 may sound strange, but intuitively,
    this means that the Generator is now able to generate samples that are similar
    to the real ones and the Discriminator can now only make random guesses.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At first glance, Generative models have a limited utility. What is the purpose
    of having a model that generates something similar to what we already have (the
    real sample dataset)?
  prefs: []
  type: TYPE_NORMAL
- en: In practice, learning from a data distribution is extremely useful in the anomaly
    detection domain and in "human-only" fields such as art, painting, and music generation.
    Moreover, the applications of GANs in their conditional formulation are astonishing
    and used to create applications with a great market value (see the *Conditional
    GANs* section of this chapter for more information).
  prefs: []
  type: TYPE_NORMAL
- en: 'With GANs, it is possible to make a machine generate extremely realistic faces,
    starting from random noise. The following image shows applying GAN to the face
    generation problem. These results were obtained in the paper titled *Progressive
    Growing of GANs for Improved Quality, Stability, and Variation* (T. Karras et
    al. 2017, NVIDIA):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/59076122-b87b-4fd7-8c15-03c3de5b7f29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: These people do not exist. Every image, although super realistic, is GAN generated.
    You can try this out for yourself by going to [https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/) (Image
    source, the paper titled *Progressive Growing of GANs for Improved Quality, Stability,
    and Variation*).
  prefs: []
  type: TYPE_NORMAL
- en: Another astonishing application from before GANs were introduced that was practically
    impossible to achieve was domain translation, which is where you use a GAN to
    go from one domain to another, for example, from sketches to a realistic image
    or from an aerial view to a map.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image, which was retrieved from the paper *Image-to-Image Translation
    with Conditional Adversarial Networks* (Isola et al., 2017) shows how (conditional)
    GANs are able to solve tasks that were considered impossible only some years ago:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15b3d462-f535-4de8-b74e-8b735b20c47b.jpg)'
  prefs: []
  type: TYPE_IMG
- en: GANs allow you to solve the domain translation problem. Colorizing a black and
    white image or generating photos only from sketches is now possible. Image source:*Image-to-Image
    Translation with Conditional Adversarial Networks* (Isola et al., 2017).
  prefs: []
  type: TYPE_NORMAL
- en: GAN applications are astonishing and their practical applications are always
    being discovered. Starting from the next section, we'll learn how to implement
    some of them in pure TensorFlow 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: Unconditional GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It isn''t common to see GANs mentioned as unconditional since this is the default
    and original configuration. In this book, however, we decided to stress this characteristic
    of the original GAN formulation in order to make you aware of the two main GAN
    classifications:'
  prefs: []
  type: TYPE_NORMAL
- en: Unconditional GANs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditional GANs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generative model that we described in the previous section falls under the
    category of unconditional GANs. The generative model is trained to capture the
    training data distribution and to generate samples that have been randomly sampled
    from the captured distribution. The conditional configuration is a slightly modified
    version of the framework and is presented in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to TensorFlow 2.0's eager-by-default style, the implementation of adversarial
    training is straightforward. In practice, to implement the adversarial training
    loop as described in the Goodfellow et al. paper (*Generative Adversarial Networks)*,
    it is required to implement it as it is defined, line by line. Of course, the
    best way to create a custom training loop that requires the alternate training
    steps of two different models is not to use Keras, but to implement it manually.
  prefs: []
  type: TYPE_NORMAL
- en: Just like in any other machine learning problem, we have to start with the data.
    In this section, we will define a generative model, with the goal of learning
    about the random normal data distribution, centered at 10 and with a small standard
    deviation.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since the goal of this section is to learn about data distribution, we will
    start from the foundations in order to build a strong intuition of the adversarial
    training process. The most simple and the easiest way to visualize data distribution
    is by looking at the random normal distribution. We can, therefore, pick a Gaussian
    (or normal) centered at 10 and with a standard deviation of 0.1 as our target
    data distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e95a6682-606a-49cd-b738-469c61356163.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Thanks to the eager execution process, we can use TensorFlow 2.0 itself to
    sample a value from the target distribution. We do this by using the `tf.random.normal`
    function. The following code snippet shows a function that samples (2,000) data
    points from the target distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To have a better understanding of what a GAN can learn, and of what happens
    during the adversarial training itself, we use `matplotlib` to visualize the data
    on a histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This displays the target distribution that''s shown in the following image.
    As expected, if we have a small standard deviation, the histogram peaks at the
    mean value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3addb3b9-567b-43ac-b27a-7a7fc3340faa.png)'
  prefs: []
  type: TYPE_IMG
- en: The histogram of the target distribution – 5,000 data points sampled from a
    Gaussian distribution with a mean of 10 and a stddev of 0.1
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've defined the target data distribution and we have a function that
    samples from it (`sample_dataset`), we are ready to define the Generator and Discriminator
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: As we stated at the beginning of this chapter, the power of the adversarial
    training process is that both the Generator and the Discriminator can be neural
    networks, and the models can be trained using gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Generator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Generator's goal is to behave like the target distribution. For this reason,
    we have to define it as a network with a single neuron. We can sample one number
    at a time from the target distribution, and the same should be possible from the
    Generator.
  prefs: []
  type: TYPE_NORMAL
- en: There is no guideline or constraint for the model architecture definition. The
    only restrictions are given from the nature of the problem, and these are the
    input and output dimensions. The output dimension, as we explained previously,
    depends on the target distribution, while the input dimension is the arbitrary
    dimension of the noise prior, which is often set to 100.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, we are going to define a simple three-layer neural network,
    with two hidden layers with 64 neurons each:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `generator` function returns a Keras model. The Keras functional API has
    been used to define the model, although a Sequential was enough.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Discriminator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like the Generator, the Discriminator architecture depends on the target
    distribution. The goal is to classify samples into two categories. The input layer,
    therefore, depends on the size of the samples that have been sampled from the
    target distribution; in our case, it is one. The output layer is a single linear
    neuron that's used to classify the sample into two categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'The activation function is linear because the Keras loss function applies the
    sigmoid:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After defining the Generator and Discriminator architecture, we only have to
    instantiate the Keras models by specifying the correct input shapes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The models and the target data distribution have been defined; the only thing
    that's missing is expressing the relationships between them, which is done by
    defining the loss functions.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the loss functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As shown in the previous section, the Discriminator''s output is linear because
    the `loss` function we are going to use applies the nonlinearity for us. To implement
    the adversarial training process by following the original formulation, the `loss`
    function to use is binary cross-entropy:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The `bce` object is used to compute the binary cross-entropy between two distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: The learned distribution, which is represented by the Discriminator's output,
    is squashed into the [0,1] range (by applying it the sigmoid ![](img/6a8ca1bf-50ed-4882-a26a-b442cf60f361.png) function,
    since the `from_logits` parameter is set to `True`). This produces a value closer
    to one if the Discriminator classifies the input as coming from the real data
    distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conditional empirical distribution over class labels, that is, a discrete
    probability distribution where the probability of it being a real sample, is labeled
    as 1 and is 0 otherwise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathematically, the binary cross-entropy between the conditional empirical
    distribution over class labels (![](img/7ce7c2cd-5b7a-4df6-9de3-9b7a0b6a1c1f.png))
    and the generator output squashed in [0,1] (![](img/47650b3e-1949-4757-99e5-f10970d72bcf.png))
    is expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74737ade-b438-4b83-bbc1-336c6f8297fb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We want to train the Discriminator to correctly classify real and fake data:
    correctly classifying the real data can be seen as the maximization of ![](img/f4a69c26-6d2d-4d9d-acd3-19c9797b2aac.png), while
    the correct classification of the fake data is the maximization of ![](img/bd7a3ae6-9748-49ae-bee6-0430dc8d0b53.png).'
  prefs: []
  type: TYPE_NORMAL
- en: 'By replacing the expected value with the empirical mean over a batch of *m*
    samples, it is possible to express the maximization of the log probability of
    correctly classifying a sample as the sum of two BCEs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/decb28ca-6b2f-450b-a5a4-6503df00be02.png)'
  prefs: []
  type: TYPE_IMG
- en: The first term is the BCE between the label ![](img/538f700e-e62b-4f8a-a414-9eebc0e3b525.png) and
    the Discriminator output when given a real sample as input, while the second term
    is the BCE between the label ![](img/43bf107b-e712-4374-97ac-33403ff44bc0.png) and
    the Discriminator output when given a fake sample as input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementing this loss function in TensorFlow is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The same `bce` object we created previously is used inside the `d_loss` function
    since it is a stateless object that only computes the binary cross-entropy between
    its inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that there is no need to add a minus sign in front of the `bce`
    invocations to maximize them; the mathematical formulation of the BCE already
    contains the minus sign.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generator loss function follows on from this theory. Implementing the non-saturating
    value function only consists of the TensorFlow implementation of the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c6fa83f-45fe-48eb-a1e1-3121fc5cb745.png)'
  prefs: []
  type: TYPE_IMG
- en: This formula is the binary cross-entropy between the log probability of the
    generated images and the distribution of the real images (labeled with 1). In
    practice, we want to maximize the log probability of the generated samples, updating
    the Generator parameters in order to make the Discriminator classify them as real
    (label 1).
  prefs: []
  type: TYPE_NORMAL
- en: 'The TensorFlow implementation is trivial:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Everything is set up to implement the adversarial training process.
  prefs: []
  type: TYPE_NORMAL
- en: Adversarial training process in unconditional GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we explained at the beginning of this chapter, the adversarial training process
    is where we alternate the execution of the training steps for the Discriminator
    and Generator. The Generator requires the value that's computed by the Discriminator
    to perform its parameter update, while the Discriminator requires the generated
    samples (also known as fake input) and the real samples.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow allows us to define a custom training loop easily. The `tf.GradientTape`
    object, in particular, is extremely useful for computing the gradient of a specific
    model, even when there are two models interacting. In fact, thanks to the `trainable_variables` property
    of every Keras model, it is possible to compute the gradient of a certain function,
    but only with respect to these variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training process is exactly like the one that''s described in the GAN paper (*Generative
    Adversarial Networks - Ian Goodfellow et al.)*, thanks to the eager mode. Moreover,
    since this training process can be computationally intensive (especially on big
    datasets where the data distribution that we want to capture is complex), it is
    worth decorating the training step function with `@tf.function` in order to speed
    up the computation by converting it into a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to visualize what the Generator is learning during the training process,
    we plot the same graph values that were sampled from the target distribution (in
    orange), as well as the values that were sampled from the Generator (in blue):'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now that we've defined the whole training loop as a function, we can execute
    it by calling `train()`.
  prefs: []
  type: TYPE_NORMAL
- en: The `train_step` function is the most important of the whole snippet since it
    contains the implementation of the adversarial training. A peculiarity that is
    worth highlighting is how, by using `trainable_variables`, it has been possible
    to compute the gradients of the loss function with respect to the model parameters
    we are interested in, while considering everything else constant.
  prefs: []
  type: TYPE_NORMAL
- en: The second peculiarity has been the usage of a persistent gradient tape object.
    Using a persistent tape allowed us to keep track of the execution while allocating
    a single object in memory (the tape) and using it twice. If the tape had been
    created non-persistently, we couldn't reuse it since it would be automatically
    destroyed after the first `.gradient` invocation.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of visualizing the data using TensorBoard (this is left as an exercise
    for you), we followed the matplotlib approach we've used so far and sampled 5,000
    data points every 200 training steps from both the target and the learned distributions,
    and then visualized them by plotting the corresponding histograms.
  prefs: []
  type: TYPE_NORMAL
- en: 'During the initial training steps, the learned distribution is different from
    the target one, as shown in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3c0953dc-73f8-4d9d-bc28-086ed9940865.png)'
  prefs: []
  type: TYPE_IMG
- en: Data visualization at the 2,600th training step. The target distribution is
    a random normal distribution with a mean of 10 and a standard deviation of 0.1\.
    The values that were sampled from the learned distribution are slowly shifting
    toward the target distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'During the training phase, it is possible to appreciate how the Generator is
    learning to approximate the target distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/44a936c4-6db5-4e5b-981c-c0fe8d062daf.png)'
  prefs: []
  type: TYPE_IMG
- en: Data visualization at the 27,800th training step. The learned distribution is
    approaching the mean value of 10 and is reducing its variance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the late training stages, the two distributions almost completely overlap
    and the training process can be stopped:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1a6d82a3-cbfb-47a2-91a7-8b77ca46ce64.png)'
  prefs: []
  type: TYPE_IMG
- en: Data visualization at the 39,000th training step. The target distribution and
    the learned distribution overlap.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to the expressive power of the Keras model and the ease of usage of the
    TensorFlow eager mode (plus the graph-conversion via `tf.function`), defining
    two models and training them by manually implementing the adversarial training
    process has been almost trivial.
  prefs: []
  type: TYPE_NORMAL
- en: Although trivial, this is the very same training loop that we use when working
    with different data types. In fact, the same training loop can be used to train
    image, text, and even audio generators, except that we use different Generator
    and Discriminator architectures in those cases.
  prefs: []
  type: TYPE_NORMAL
- en: A slightly modified version of the GAN framework allows you to collect a conditional
    generation of samples; for example, the Generator is trained to generate specific
    samples when given a condition.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional GANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mirza et al. in their paper, *Conditional Generative Adversarial Nets*, introduced
    a conditional version of the GAN framework. This modification is extremely easy
    to understand and is the foundation of amazing GAN applications that are widely
    used in today's world.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the most astonishing GAN applications, such as the generation of a street
    scene from a semantic label to the colorization of an image given a grayscale
    input, pass through image super-resolution as specialized versions of the conditional
    GAN idea.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conditional GANs are based on the idea that GANs can be extended to a conditional
    model if both G and D are conditioned on some additional information, *y*. This
    additional information can be any kind of additional information, from class labels
    to semantic maps, or data from other modalities. It is possible to perform this
    conditioning by feeding the additional information into both the Generator and
    the Discriminator as an additional input layer. The following diagram, which was
    taken from the *Conditional Generative Adversarial Nets* paper, clearly shows
    how the Generator and Discriminator models can be extended to support the conditioning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c2f44c63-45d8-4591-972b-2f778dcecb59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Conditional GANs. The Generator and the Discriminator have one additional input,
    y, which represents the auxiliary information that conditions the models (Image
    source: *Conditional Generative Adversarial Nets*, Mirza et al., 2014).'
  prefs: []
  type: TYPE_NORMAL
- en: The generator architecture is extended to combine the joint hidden representation
    of the noise prior to the condition. There are no constraints on how to feed the
    condition to the Generator network. You can simply concatenate the condition to
    the noise vector. Alternatively, if the condition is complex, you can encode it
    using a neural network and concatenate its output to one layer of the Generator.
    The same reasoning applies to the Discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conditioning the models changes the value''s function since the data distributions
    that we sample from are now conditioned:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/398f42ea-5f04-438b-a766-c0ab7da52270.png)'
  prefs: []
  type: TYPE_IMG
- en: There are no other changes in regards to the adversarial training process, and
    the same considerations about the non-saturating value function still apply.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to implement a conditional Fashion-MNIST generator.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data for a conditional GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By using TensorFlow Datasets, getting the data is straightforward. Since the
    goal is to create a Fashion-MNIST generator, we will use the class labels as a
    condition. The data that''s returned from the `tfds.load` call is in a dictionary
    format. Therefore, we need to define a function that maps the dictionary to a
    tuple that contains only the image and the corresponding label. In this phase,
    we can also prepare the whole data input pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Defining the Generator in a conditional GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we are working with images, the natural choice is to use a convolutional
    neural network. In particular, using the deconvolution operation we introduced
    in [Chapter 8](51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml), *Semantic Segmentation
    and Custom Dataset Builder*, it is possible to easily define a decoder-like network
    that generates images, starting from a latent representation and a condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Defining the Discriminator in a conditional GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Discriminator architecture is straightforward. A standard way of conditioning
    the Discriminator consists of concatenating the encoded representation of the
    image, with the encoded representation of the condition being placed in a unique
    vector. Doing this requires the definition of two subnetworks – the first one
    encodes the image in a feature vector, while the second one encodes the condition
    in another vector. The following code clarifies this concept:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'After defining the encoder subnetwork that encoded the image into a feature
    vector, we are ready to create a hidden representation of the condition and concatenate
    it with the feature vector. After doing it, we can create the Keras model and
    return it:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Adversarial training process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The adversarial training process is the same as what we presented for the unconditional
    GAN. The `loss` functions are exactly the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The only difference is that our models now accept two input parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'After deciding on the noise''s prior dimension and instantiated the G and D
    models, defining the train function requires a slight modification of the previous
    training loop. As for the unconditional GAN training loop definition, matplotlib
    has been used to log the images. Improving this script is left as an exercise
    for you to carry out:'
  prefs: []
  type: TYPE_NORMAL
- en: '`(tf2)`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The training loop loops over the training set for 10 epochs and displays an
    image of a generated Fashion-MNIST element, along with its label. After a few
    epochs, the generated images become more and more realistic and they start matching
    the label, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3cf10f11-0a41-45fa-938c-710062e95f9a.png)'
  prefs: []
  type: TYPE_IMG
- en: A generated sample feeding in input to the Generator's random noise and the
    condition T-shirt/top
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at GANs and the adversarial training process. In
    the first section, a theoretical explanation of the adversarial training process
    was presented, with a focus on the value function, which is used to formulate
    the problem as a min-max game. We also showed how the non-saturating value function
    is, in practice, the solution to making the Generator learn how to solve the saturation
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: We then looked at implementing the Generator and Discriminator models that are
    used to create an unconditional GAN in pure TensorFlow 2.0\. In this section,
    the expressive power of TensorFlow 2.0 and the definition of custom training loops
    was presented. In fact, it has been shown how straightforward it is to create
    Keras models and write the custom training loop that implements the adversarial
    training process, just by following the steps described in the GAN paper (*Generative
    Adversarial Networks - Ian Goodfellow et al.)**.*
  prefs: []
  type: TYPE_NORMAL
- en: The Keras functional API has been also extensively used, where a conditional
    generator of Fashion-MNIST-like images has been implemented. The implementation
    showed us how, by using the Keras functional API, it is possible to feed a second
    input (the condition) to both the Generator and Discriminator and define a flexible
    neural network architecture easily.
  prefs: []
  type: TYPE_NORMAL
- en: The GAN universe is rich in terms of very complex architectures and clever ideas
    for astonishing applications. This chapter aims to explain the GAN framework without
    claiming to be complete; there's enough material out there about GANs for me to
    write more than a whole book.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter ends with an exercise section, which contains a challenge for
    you (questions 16 and 17): can you create a conditional GAN that generates realistic
    images, starting from a semantic label?'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've focused on how to train various models, from simple classifiers
    to generative models, without worrying about the deployment stage.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [Chapter 10](889170ef-f89d-4485-a111-6cd4e72f0daa.xhtml), *Bringing
    a Model to Production*, the final step of every real-life machine learning application
    will be presented – the deployment of learned models.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Try answering and working on the following exercises to expand the knowledge
    that you''ve gained from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the adversarial training process?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the value function of the min-max game that the Discriminator and Generator
    are playing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain why the min-max value function formulation can saturate in the early
    training step of training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write and explain the non-saturating value function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the rules of the adversarial training process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there any recommendations on how to feed a condition to a GAN?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does it mean to create a conditional GAN?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can only the fully connected neural networks be used to create GANs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which neural network architecture works better for the image generation problem?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update the code of the Unconditional GAN: Log the Generator and Discriminator
    loss value on TensorBoard, and also log matplotlib plots.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Unconditional GAN: Save the model parameter in a checkpoint at every epoch.
    Add support for the model''s restoration, restarting from the latest checkpoint.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extend the code of the unconditional GAN by making it conditional. Given the
    condition of 0, the Generator must behave like the normal distribution, with a
    mean of 10 and a standard deviation of 0.1\. Given the condition of 1, the Generator
    must produce a value that has been sampled from a Gaussian distribution with a
    mean of 100 and a standard deviation of 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log the magnitude of the Gradient that was computed to update the Discriminator
    and Generator in TensorBoard. Apply gradient clipping if the magnitude is greater
    than 1 in an absolute value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat exercises 1 and 2 for the conditional GAN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Conditional GAN: Do not use matplotlib to plot the images; use `tf.summary.image`
    and TensorBoard.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the dataset we created in the previous chapter, [Chapter 8](51f4dcda-add6-4e58-a660-75f34a7e5593.xhtml), *Semantic
    Segmentation and Custom Dataset Builder*, create a conditional GAN that performs
    domain translation, from the semantic label to an image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use TensorFlow Hub to download a pre-trained feature extractor and use it as
    a building block to create the Discriminator for a conditional GAN that generates
    realistic scenes from semantic labels.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
