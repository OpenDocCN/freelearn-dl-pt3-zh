<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer096">
<h1 class="chapter-number" id="_idParaDest-91"><a id="_idTextAnchor105"/>5</h1>
<h1 id="_idParaDest-92"><a id="_idTextAnchor106"/>Image Classification with Neural Networks</h1>
<p>Up until this point, we have built models to solve both regression and classification problems on structured data with much success. The next question that comes to mind is: can we build models that can tell the difference between a dog and a cat, or a car and a plane? Today, with the aid of frameworks such <a id="_idIndexMarker219"/>as <strong class="bold">TensorFlow</strong> and <strong class="bold">PyTorch</strong>, developers<a id="_idIndexMarker220"/> can now build such ML solutions with a few lines <span class="No-Break">of code.</span></p>
<p>In this chapter, we will explore the anatomy<a id="_idIndexMarker221"/> of <strong class="bold">neural networks</strong> and learn how we can apply them to building models for computer vision problems. We will start by examining what a neural network is and the architecture of a multilayer neural network. We will look at some important ideas such as forward propagation, backward propagation, optimizers, loss function, learning rate, and activation functions, and where and how they <span class="No-Break">fit in.</span></p>
<p>After we build a solid base in the core fundamentals, we will build an image classifier using a custom dataset from TensorFlow. Here, we will walk through the end-to-end process of model building using the TensorFlow dataset. The good part of using these custom datasets is that the bulk of the preprocessing steps are already done, and our data can be modeled without any blockers. So, we will use this dataset to build a neural network with a few lines of code in TensorFlow with <a id="_idIndexMarker222"/>the <strong class="bold">Keras</strong> API, so that our model will be able to tell the difference between a bag and a shirt, and a shoe and <span class="No-Break">a coat.</span></p>
<p>In this chapter, we’ll cover the <span class="No-Break">following topics:</span></p>
<ul>
<li>The anatomy of <span class="No-Break">neural networks</span></li>
<li>Building an image classifier with a <span class="No-Break">neural network</span></li>
</ul>
<h1 id="_idParaDest-93"><a id="_idTextAnchor107"/>Technical requirements</h1>
<p>We will be using <strong class="bold">Google Colab</strong> to run the coding exercise that requires <strong class="source-inline">python &gt;= 3.8.0</strong>, along with the following packages that can be installed using the <strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install</strong></span><span class="No-Break"> command:</span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline">tensorflow&gt;=2.7.0</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">tensorflow-datasets==4.4.0</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">pillow==8.4.0</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">pandas==1.3.4</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">numpy==1.21.4</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">matplotlib &gt;=3.4.0</strong></span></li>
</ul>
<p>The code for this chapter is available at <a href="https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205">https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205</a>. Also, solutions to all exercises can be found in the GitHub <span class="No-Break">repository itself.</span></p>
<h1 id="_idParaDest-94"><a id="_idTextAnchor108"/>The anatomy of neural networks</h1>
<p>In the first section<a id="_idIndexMarker223"/> of this book, we talked about models. These models that we spoke about and used for various use cases are neural networks. A neural network is a deep learning algorithm inspired by the functionality of the human brain, but by no means does it operate like the human brain. It learns useful representation of the input data using a layered approach, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer082">
<img alt="Figure 5.1 – Neural network" height="732" src="image/B18118_05_001.jpg" width="1190"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Neural network</p>
<p>Neural <a id="_idIndexMarker224"/>networks are ideal for tackling complex problems due to their ability to identify very complex patterns in data. This makes them well suited for building solutions around text and image data (unstructured data), tasks that traditional machine learning algorithms struggle with. Neural networks develop rules to map input data to the target or labels using layered representation. When we train them on labeled data, they learn the patterns and use this knowledge to map the new input data to their <span class="No-Break">corresponding labels.</span></p>
<p>In <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em>, we see all the neurons of the input layer are connected to the neurons of the first hidden layer, and all the neurons of the first hidden layer are connected to all the neurons of the second hidden layer. The same applies from the second hidden layer to the outer layer. This type of network, where each layer’s neurons are fully connected to the neurons of the next layer, is <a id="_idIndexMarker225"/>called a <strong class="bold">fully connected neural network</strong>. A neural network with more than two hidden layers is called a <strong class="bold">deep neural network</strong> (<strong class="bold">DNN</strong>) and the <a id="_idIndexMarker226"/>depth of the network is determined by its number <span class="No-Break">of layers.</span></p>
<p>Let’s take a deep dive into the individual layers of a neural <span class="No-Break">network architecture:</span></p>
<ul>
<li><strong class="bold">Input layer</strong>: This is the<a id="_idIndexMarker227"/> layer through which we fed the input data (text, image, tabular data) into the network. Here, we have to specify the right input shape, something we have done previously in our regression case study in <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><em class="italic">, Linear Regression With TensorFlow</em>, and in our classification case study in <a href="B18118_04.xhtml#_idTextAnchor085"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic">, Classification With TensorFlow</em>. It is important to note that the input data will be presented to our neural network in numerical format. In this layer, no computation takes place. It’s more of a passthrough layer to the <span class="No-Break">hidden layer.</span></li>
<li><strong class="bold">Hidden layer</strong>: This is the<a id="_idIndexMarker228"/> next layer and it lies between the input and output layers. It is referred to as hidden because it is not visible to external systems. Here, lots of computation takes place to extract patterns from our input data. The more layers we add to the hidden layer, the more complex our model becomes and the more time it takes to process <span class="No-Break">our data.</span></li>
<li><strong class="bold">Output layer</strong>: This layer <a id="_idIndexMarker229"/>produces the output of the neural network. The number of output layer neurons is determined by the task at hand. If we have a binary classification task, we will use one output neuron, while for multiclass classification, such as in our case study where we had 10 different labels, we will have 10 neurons, one for each of the classes in <span class="No-Break">our data.</span></li>
</ul>
<p>We now know the layers of a neural network, but the key questions are: how does a neural network work, and what enables it to take a special position in <span class="No-Break">machine learning?</span></p>
<p>Neural networks solve complex tasks by the application of both forward and backward propagation. Let’s start by examining <span class="No-Break">forward propagation.</span></p>
<h2 id="_idParaDest-95"><a id="_idTextAnchor109"/>Forward propagation</h2>
<p>Imagine we want to<a id="_idIndexMarker230"/> teach our<a id="_idIndexMarker231"/> neural network to effectively identify the images shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.2</em>. We will pass lots of representative samples of each of the images we want our neural network to recognize. The idea here is that our neural network will learn from the samples and use what it has learned to identify new items within the sample space. Let’s say, for example, we want our model to recognize shirts; we will pass shirts of different colors and sizes. Our model will learn what defines a shirt, irrespective of its color, size, or style. This learned representation of the core attributes of a shirt is what the model will use to identify <span class="No-Break">new shirts.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<img alt="Figure 5.2 – Sample images from Fashion MNIST dataset" height="517" src="image/B18118_05_002.jpg" width="517"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Sample images from Fashion MNI<a id="_idTextAnchor110"/>ST dataset</p>
<p>Let us look at what <a id="_idIndexMarker232"/>happens under the hood. In our training data, we pass the images (<em class="italic">X</em>) through our model <span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">.</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">.</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">→</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span>, where <span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span> is the model’s predicted output. Here, the neural network randomly initializes weights that are used to predict the output (<span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span>). This process is<a id="_idIndexMarker233"/> called <strong class="bold">forward propagation</strong> or <strong class="bold">forward pass</strong> and is depicted in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Weights are trainable parameters that are updated during the training process. After training, the model’s weights are optimized to the specific dataset it is trained on. If we tune the weight properly during training, we can develop a <span class="No-Break">well-performing model.</span></p>
<p>As input data flows through the network, it experiences transformations due to the impact of the node’s weight and bias, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.3</em>, thus producing a new set of information that will now pass through an <em class="italic">activation function</em>. If the new information learned is desired, the activation function triggers an output signal that serves as input to<a id="_idIndexMarker234"/> the next layer. This<a id="_idIndexMarker235"/> process continues until an output is generated in the <span class="No-Break">output layer:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<img alt="Figure 5.3 – Forward propagation of a neural network" height="658" src="image/B18118_05_003.jpg" width="1317"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Forward propagation of a neural network</p>
<p>Let’s talk a bit more about activation functions and what they do in our <span class="No-Break">neural network.</span></p>
<h2 id="_idParaDest-96"><a id="_idTextAnchor111"/>Activation functions</h2>
<p>Imagine you had to pick<a id="_idIndexMarker236"/> the good apples <a id="_idIndexMarker237"/>from a basket of apples. By inspecting the apples, you can pick the good ones and drop the bad ones. This is how an activation function works – it plays the role of a separator and thus defines what will pass through, which in our case is the useful representation it has learned, and drops the non-useful data. In essence, it helps to extract useful information, such as the good apples, and drop the useless data, which in our scenario are the bad apples. Now, the activation function determines which connected neuron of the next layer will be activated. It uses mathematical operations to determine whether a learned representation is useful enough for the next layer <span class="No-Break">or not.</span></p>
<p>Activation functions can add nonlinearity to our neural network, a characteristic that is required for neural networks to learn complex patterns. There are different activation functions; for output layers, the selection of activation function depends on the type of task <span class="No-Break">at hand:</span></p>
<ul>
<li>For binary classification, <a id="_idIndexMarker238"/> we usually use sigmoid function because it maps the input to output values between 0 and 1, representing the probability of belonging to a particular class. We usually set the threshold point as 0.5, hence values above this point are set to 1 and values below it is set <span class="No-Break">to 0.</span></li>
<li>For multiclass classification, we <a id="_idIndexMarker239"/>use <strong class="bold">softmax</strong><strong class="bold"> activation</strong> as the output layer’s activation function. Let’s say we want to build an image classifier to classify four fruits (apples, grapes, mangoes, and oranges) as illustrated in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.4.</em> One neuron is assigned in the output layer to each of the fruits and we will apply the softmax activation function to generate the likelihood of the output being one of the fruits we want to predict. When we sum up the probabilities of it being an apple, grape, mango, and orange, we get 1. For classification, we select the class with highest probability of the four fruits as the output label from the probabilities generated by the Softmax activation function. In this case, the output with the highest probability is <span class="No-Break">an orange:</span></li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer085">
<img alt="Figure 5.4 – Application of the SoftMax activation function" height="482" src="image/B18118_05_004.jpg" width="1437"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Application of the SoftMax activation function</p>
<p>For hidden<a id="_idIndexMarker240"/> layers, we will <a id="_idIndexMarker241"/>use <a id="_idIndexMarker242"/>the <strong class="bold">rectified linear unit</strong> (<strong class="bold">ReLU</strong>) activation function. This activation function removes negative values (useless representations), while it passes learned representations with values greater than 0. ReLU offers excellent performance for hidden layers as it converges quickly as well as supports backward propagation, a concept we will be <span class="No-Break">discussing next.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">It is more efficient to use sigmoid for binary classification, when we do this, we have one output neuron as against two output neurons which would be the case when we use Softmax. Also, it is easier to understand that we are working on a case of binary classification when we read <span class="No-Break">the code.</span></p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor112"/>Backward propagation</h2>
<p>When we begin training a <a id="_idIndexMarker243"/>model, the weights are initially random, making it more likely that<a id="_idIndexMarker244"/> the model will guess wrongly that the fruit in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.4</em> is an orange. Here comes the intelligence of our neural network; it autocorrects itself, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer086">
<img alt="Figure 5.5 – Forward and backward propagations of a neural network" height="401" src="image/B18118_05_005.jpg" width="885"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Forward and backward propagations of a neural network</p>
<p>Here, the neural <a id="_idIndexMarker245"/>network measures how correct the predicted output (<span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span>) is in comparison to the ground truth (<em class="italic">y</em>). This loss is computed <a id="_idIndexMarker246"/>by the <strong class="bold">loss function</strong>, which can also be referred to as<a id="_idIndexMarker247"/> the <strong class="bold">cost function</strong>. This information is passed on to<a id="_idIndexMarker248"/> an <strong class="bold">optimizer</strong>, whose job is to update the weights of the layers in the neural network with the aim of reducing the loss over the next iterations, thus getting our prediction closer to the ground truth. This process continues until we <a id="_idIndexMarker249"/>achieve <strong class="bold">convergence</strong>. Convergence occurs when the model is trained such that the loss is at its <span class="No-Break">barest minimum.</span></p>
<p>The <a id="_idIndexMarker250"/>loss function<a id="_idIndexMarker251"/> is applied with respect to the task at hand. When we are working on a binary classification task, we<a id="_idIndexMarker252"/> use <strong class="bold">binary cross-entropy</strong>; for multiclass<a id="_idIndexMarker253"/> classification, if the target labels are integer values (for example, 0 to 9) we use <strong class="bold">sparse categorical cross-entropy</strong>, whereas we<a id="_idIndexMarker254"/> use <strong class="bold">categorical cross-entropy</strong> if we decide to one-hot encode our target labels. Like loss functions, we also have different types<a id="_idIndexMarker255"/> of optimizers; however, we will experiment with <strong class="bold">stochastic gradient descent</strong> (<strong class="bold">SGD</strong>) and <a id="_idIndexMarker256"/>the <strong class="bold">Adam optimizer</strong>, which is an improved version of SGD. Hence, we will use this as our <a id="_idTextAnchor113"/><span class="No-Break">default optimizer.</span></p>
<h2 id="_idParaDest-98"><a id="_idTextAnchor114"/>Learning rate</h2>
<p>We now know that weights are randomly<a id="_idIndexMarker257"/> initialized, and optimizers aim to use this information about the loss function to update the weights with a view to achieving convergence. Neural networks use optimizers<a id="_idIndexMarker258"/> to iteratively update the weights until the loss function is at a minimum, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.6</em>. Optimizers let you set an important hyperparameter <a id="_idIndexMarker259"/>called the <strong class="bold">learning rate</strong>, which controls the speed of convergence and is how our model learns. To get to the bottom of the slope, we will have to take steps toward the base (see <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">):</span></p>
<div>
<div class="IMG---Figure" id="_idContainer087">
<img alt="Figure 5.6 – Gradient descent" height="725" src="image/B18118_05_006.jpg" width="1208"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – Gradient descent</p>
<p>The step size we take will determine how quickly we get to the base. If we take very small steps, it will take too long to reach the base and lead to slower convergence, and there is also a risk that the optimization process could get stuck along the way to the minimum point. On the flip side, if the steps are too large, there is a risk we may overshoot the minimum and experience erratic and unstable training behavior. The right step size will get<a id="_idIndexMarker260"/> us to the base <a id="_idIndexMarker261"/>of the slope in time without overshooting the minimum point. This step size we refer to here is the <span class="No-Break">learning rate.</span></p>
<p>We have now covered the intuition behind neural networks at a high level. Let us proceed and look at our case study, directly applying what we have <span class="No-Break">just learned.</span></p>
<h1 id="_idParaDest-99"><a id="_idTextAnchor115"/>Building an image classifier with a neural network</h1>
<p>We are back at our<a id="_idIndexMarker262"/> fictional company, and we want to use the intuition of neural networks to build an image classifier. Here, we are to teach computers to identify clothing. Thankfully, we do not need to find data in the wild; we have TensorFlow datasets that include the fashion dataset. In our case study, our aim is to classify a fashion dataset made up of 28 x 28 grayscale images into 10 classes (from 0 to 9) with pixel values between 0 and 255, using a well-known dataset called the <em class="italic">Fashion MNIST dataset</em>. This dataset is made up of 60,000 training images and 10,000 test images. Our dataset has all the images in the same shape, so we have little preprocessing to do. The idea here is for us to build a neural network quickly with little <span class="No-Break">preprocessing complexities.</span></p>
<p>To train the <a id="_idIndexMarker263"/>neural network, we will pass the training images with the idea that our neural network will learn to map the images (<em class="italic">X</em>) to their corresponding labels (<em class="italic">y</em>). After we have concluded the training process, we will use our test set to evaluate the model on new unseen images. Again, the idea is that the model will correctly identify test images based on what it has learned throughout the training process. <span class="No-Break">Let’s begin.</span></p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor116"/>Loading the data</h2>
<p>Here, we will<a id="_idIndexMarker264"/> start with learning how to work with images using TensorFlow datasets. In <a href="B18118_07.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><em class="italic">,</em><em class="italic"> </em><em class="italic">Image Classification with Convolutional Neural Networks</em>, we will work on real-world images that will require more work to model our data; however, it will build on what we will learn here. That said, let us see how we can load our custom dataset <span class="No-Break">from TensorFlow:</span></p>
<ol>
<li>Before <a id="_idIndexMarker265"/>we can load our data, we need to load the necessary libraries. Let’s do <span class="No-Break">that here:</span><pre class="source-code">
import tensorflow as tf</pre><pre class="source-code">
from tensorflow import keras</pre><pre class="source-code">
import pandas as pd</pre><pre class="source-code">
import random</pre><pre class="source-code">
import numpy as np</pre><pre class="source-code">
import matplotlib.pyplot as plt #helper libraries</pre><pre class="source-code">
from tensorflow.keras.utils import plot_model</pre></li>
<li>Next, we import the <strong class="source-inline">fashion_mnist</strong> dataset from TensorFlow and create our training and testing dataset using the <span class="No-Break"><strong class="source-inline">load_data()</strong></span><span class="No-Break"> method:</span><pre class="source-code">
#Lets import the fa<a id="_idTextAnchor117"/>shion mnist</pre><pre class="source-code">
fashion_data = keras.datasets.fashion_mnist</pre><pre class="source-code">
#Lets create of numpy array of training and testing data</pre><pre class="source-code">
(train_images, train_labels), (test_images,</pre><pre class="source-code">
    test_labels) = fashion_data.load_data()</pre><p class="list-inset">If everything goes according to plan, we should get an output as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">:</span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer088">
<img alt="Figure 5.7 – Data import from TensorFlow datasets" height="241" src="image/B18118_05_007.jpg" width="1181"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Data import from TensorFlow datasets</p>
<ol>
<li value="3">Now, rather than using numeric labels, let us create labels that match our data such that we can call a dress a dress, rather than call it number 3. We will do that by creating a list of <a id="_idIndexMarker266"/>our labels, which we will map to the corresponding <span class="No-Break">numeric values:</span><pre class="source-code">
#We create a list of the categories</pre><pre class="source-code">
class_names=['Top', 'Trouser','Pullover', 'Dress', 'Coat', </pre><pre class="source-code">
    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankleboot']</pre></li>
</ol>
<p>Now that we have our data, let us explore the data and see what we can find. Rather than agree with everything we are told, let’s explore the data to verify the size, the shape, and the <span class="No-Break">data distributions.</span></p>
<h2 id="_idParaDest-101"><a id="_idTextAnchor118"/>Performing exploratory data analysis</h2>
<p>After we <a id="_idIndexMarker267"/>load the data, the next step is to examine it to get a sense of what the data is. Of course, in this instance, we have some basic information from TensorFlow about the data distribution. Also, we have the data already available in training and test sets. However, let us confirm all the details using code, as well as view the class distribution of our <span class="No-Break">target label:</span></p>
<ol>
<li>We will use the <strong class="source-inline">matplotlib</strong> library to generate image samples at index <strong class="source-inline">i</strong>, where <strong class="source-inline">i</strong> falls within the 60,000 <span class="No-Break">training samples:</span><pre class="source-code">
# Display a sample image from the training data (index 7)</pre><pre class="source-code">
plt.imshow(train_images[7])</pre><pre class="source-code">
plt.grid(False)</pre><pre class="source-code">
plt.axis('off')</pre><pre class="source-code">
plt.show()</pre><p class="list-inset">We run the code using index <strong class="source-inline">7</strong>, which returns a top as seen in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">:</span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer089">
<img alt="Figure 5.8 – A photo of a pullover at index 7 of the Fashion MNIST dataset" height="231" src="image/B18118_05_008.jpg" width="231"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – A photo of a pullover at index 7 of the Fashion MNIST dataset</p>
<p class="list-inset">We<a id="_idIndexMarker268"/> can switch the index values to see other apparels within the dataset; however, that is not the goal here. So, let’s proceed with our exploratory <span class="No-Break">data analysis.</span></p>
<ol>
<li value="2">Let’s look at the sample of <span class="No-Break">our data:</span><pre class="source-code">
#Lets check the shape of our training images and testing images</pre><pre class="source-code">
train_images.shape, test_images.shape</pre><p class="list-inset">As expected, we can see the training images consist of 60,000 28 x 28 images, and the test images are 10,000 in number and 28 x 28 <span class="No-Break">in resolution:</span></p><pre class="source-code">
((60000, 28, 28), (10000, 28, 28))</pre></li>
<li>Next, let us check the distribution of the data. It’s best practice to see how your data is distributed to ensure there is enough representation for each class of clothing we want to train the model on. Let’s do <span class="No-Break">that here:</span><pre class="source-code">
df=pd.DataFrame(np.unique(train_labels,</pre><pre class="source-code">
    return_counts=True)).T</pre><pre class="source-code">
dict = {0: ‹Label›,1: ‹Count›}</pre><pre class="source-code">
df.rename(columns=dict,</pre><pre class="source-code">
    inplace=True)</pre><pre class="source-code">
df</pre><p class="list-inset">This<a id="_idIndexMarker269"/> returns a <strong class="source-inline">DataFrame</strong> as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.9</em>. We can see that all the labels have the same number <span class="No-Break">of samples:</span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer090">
<img alt="Figure 5.9 – DataFrame showing labels and their counts" height="423" src="image/B18118_05_009.jpg" width="157"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – DataFrame showing labels and their counts</p>
<p class="list-inset">Of course, this type of data is more likely to be found in a controlled setting such <span class="No-Break">as academia.</span></p>
<ol>
<li value="4">Let us<a id="_idIndexMarker270"/> visualize some sample images from the training data here. Let’s look at 16 samples from our <span class="No-Break">training data:</span><pre class="source-code">
plt.figure(figsize=(9,9))</pre><pre class="source-code">
for i in range(16):</pre><pre class="source-code">
    plt.subplot(4,4,i+1)</pre><pre class="source-code">
    plt.xticks([])</pre><pre class="source-code">
    plt.yticks([])</pre><pre class="source-code">
    plt.grid(False)</pre><pre class="source-code">
    plt.imshow(train_images[i])</pre><pre class="source-code">
    plt.title(class_names[train_labels[i]])</pre><pre class="source-code">
plt.show()</pre></li>
<li>When <a id="_idIndexMarker271"/>we run the code, we get the image in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">:</span></li>
</ol>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer091">
<img alt="Figure 5.10 – 16 randomly selected images from the Fashion MNIST dataset" height="727" src="image/B18118_05_010.jpg" width="709"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – 16 randomly selected images from the Fashion MNIST dataset</p>
<p>Now we <a id="_idIndexMarker272"/>have confirmed the data size, the data distribution, and the shape, and seen some sample images and labels. Before we proceed with building and training our image classifier, recall our data is made up of grayscale images with values from 0 to 255. To bring the data to scale, we will have to normalize the data to improve the performance of our model during training. We can do this by simply dividing the training and testing data <span class="No-Break">by 255:</span></p>
<pre class="source-code">
#it's important that the training and testing set are preprocessed in the same way.
train_images=train_images/255.0
test_images=test_images/255.0</pre>
<p>Now that we <a id="_idIndexMarker273"/>have normalized our data, we are all set for modeling it. Let’s proceed with building our image <span class="No-Break">classifier next.</span></p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor119"/>Building the model</h2>
<p>Let us put <a id="_idIndexMarker274"/>everything we have learned so far in this chapter <span class="No-Break">into action:</span></p>
<pre class="source-code">
#Step 1:  Model configuration
model=keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.Dense(10,activation="softMax")
])
#Here we flatten the data</pre>
<p>The code we use to build our model is similar to what we used in <em class="italic">Part 1</em> of this book. We start by creating a sequential model using the Sequential API to define the number of layers we want to connect sequentially. If you are a keen observer, you will notice our first layer is a flatten layer. This is used to flatten the image data into a 1D array that will be passed into the hidden layer. The input layer has no neurons; it works as a data preprocessing layer, presenting the hidden layer with data flattened into a <span class="No-Break">1D array.</span></p>
<p>Next, we<a id="_idIndexMarker275"/> have one hidden layer of 64 neurons, and we apply a ReLU activation function to this hidden layer. Finally, we have an output layer of 10 neurons – one neuron for each output. We use a softmax function since we are working on multiclass classification. Softmax returns results in the form of probabilities across all classes. If you recall from the <em class="italic">Activation functions</em> section, the sum of the output probabilities adds up to 1, and the output with the largest probability value is the <span class="No-Break">predicted label.</span></p>
<p>Now that we are done with model building, let us proceed with compiling <span class="No-Break">our model.</span></p>
<h2 id="_idParaDest-103"><a id="_idTextAnchor120"/>Compiling the model</h2>
<p>The next step is<a id="_idIndexMarker276"/> to compile the model. We will use the <strong class="source-inline">compile</strong> method to do so. Here, we pass in the optimizer we wish to use; in this case, we apply <strong class="bold">Adam</strong>, which is our default optimizer. We also specify the loss and the evaluation <a id="_idIndexMarker277"/>metrics. We use sparse categorical cross-entropy for our loss since our labels are numeric values. For our evaluation metrics, we use accuracy, since our dataset is balanced. The accuracy metric will give a true reflection of our <span class="No-Break">model’s performance:</span></p>
<pre class="source-code">
#Step 2: Compiling the model, we add the loss, optimizer and evaluation metrics here
model.compile(optimizer='adam',
    loss=›sparse_categorical_crossentropy',
    metrics=[‹accuracy›])</pre>
<p>Before we proceed to fitting our model, let’s look at some ways of visualizing our model and <span class="No-Break">its parameters.</span></p>
<h2 id="_idParaDest-104"><a id="_idTextAnchor121"/>Model visualization</h2>
<p>To <a id="_idIndexMarker278"/>visualize our model, we use the <strong class="source-inline">summary()</strong> method. This provides us with a detailed visual representation of the model’s architecture, the layers, the number of parameters (trainable and non-trainable), and the <span class="No-Break">output shape</span><span class="No-Break">:</span></p>
<pre class="source-code">
model.summary()</pre>
<p>When we <a id="_idIndexMarker279"/>run the code, it returns the model’s details as illustrated in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.11</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer092">
<img alt="Figure 5.11 – Model summary" height="309" src="image/B18118_05_011.jpg" width="636"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.11 – Model summary</p>
<p>From <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.11</em>, we can see that the input layer has no parameters but an output shape of 784, which is the result of flattening our 28 × 28 image to a 1D array. To get the number of parameters of the dense layer, it’s 784 × 64 + 64 = 50240 (recall , where <em class="italic">X</em> is the input data, <em class="italic">w</em> is the weights, and <em class="italic">b</em> is the bias). The output layer (<strong class="source-inline">dense_1</strong>) has a shape of 10, with one neuron representing each class and 650 parameters. Recall the output from one layer serves as the input to the next layer. So, 64 × 10 + 10 = 650, where<a id="_idIndexMarker280"/> 64 is the output shape of the hidden layer and the input shape of the <span class="No-Break">output layer.</span></p>
<p>On the other hand, we can also display our model as a flowchart, as seen in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.12</em>, by using the <span class="No-Break">following code:</span></p>
<pre class="source-code">
plot_model(model, to_file='model_plot.png', show_shapes=True, 
    show_layer_names=True)</pre>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer093">
<img alt="Figure 5.12 – Model’s flowchart" height="354" src="image/B18118_05_012.jpg" width="340"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.12 – Model’s flowchart</p>
<p>This also<a id="_idIndexMarker281"/> gives us a sense of our model’s structure. The plot we generated will be saved with the filename <strong class="source-inline">model_plot.png</strong>. Here, we set <strong class="source-inline">show_shapes</strong> to <strong class="source-inline">true</strong>; this will display the output shapes of each layer in the plot. We also set the <strong class="source-inline">show_layer_name</strong> to <strong class="source-inline">true</strong> to show the names of the layers in the plot, as illustrated in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.12.</em></span></p>
<p>Next, let us fit our model to the <span class="No-Break">training data.</span></p>
<h2 id="_idParaDest-105"><a id="_idTextAnchor122"/>Model fitting</h2>
<p>By now, you <a id="_idIndexMarker282"/>should be familiar with this process. With a single line of code, we can use the <strong class="source-inline">fit</strong> method to fit our training images (<em class="italic">X</em>) and training <span class="No-Break">labels (</span><span class="No-Break"><em class="italic">y</em></span><span class="No-Break">):</span></p>
<pre class="source-code">
#Step 3: We fit our data to the model
 history= model.fit(train_images, train_labels, epochs=5)</pre>
<p>Here, we fit the data for five epochs. Our model returns the loss <span class="No-Break">and accuracy:</span></p>
<pre class="source-code">
1875/1875 [==============================] – 4s 2ms/step – loss: 0.5206 – accuracy: 0.8183
Epoch 2/5
1875/1875 [==============================] – 4s 2ms/step – loss: 0.3937 – accuracy: 0.8586
Epoch 3/5
1875/1875 [==============================] – 4s 2ms/step – loss: 0.3540 – accuracy: 0.8722
Epoch 4/5
1875/1875 [==============================] – 4s 2ms/step – loss: 0.3301 – accuracy: 0.8790
Epoch 5/5
1875/1875 [==============================] – 4s 2ms/step – loss: 0.3131 – accuracy: 0.8850</pre>
<p>We can <a id="_idIndexMarker283"/>see that in just five epochs, our model has achieved an accuracy of <strong class="source-inline">0.8850</strong>. This is a good start considering we trained our model for a very small number of epochs. Next, let us observe our model’s performance during training by plotting the loss and <span class="No-Break">accuracy plots.</span></p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor123"/>Training monitoring</h2>
<p>We<a id="_idIndexMarker284"/> return a <strong class="source-inline">history</strong> object when we fit our training data. Here, we use the <strong class="source-inline">history</strong> object to create a loss and accuracy curve. Here is the code to make <span class="No-Break">the plots:</span></p>
<pre class="source-code">
# Plot history for accuracy
plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train'], loc='lower right')
plt.show()
# Plot history for loss
plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train'], loc='upper right')
plt.show()</pre>
<p>When we run the<a id="_idIndexMarker285"/> code, we get back two plots as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.13</em>. We can see the training accuracy is still rising at the end of the fifth epoch, while the loss is still falling, although the rate is not rapid as it moves closer <span class="No-Break">to 0:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer094">
<img alt="Figure 5.13 – Accuracy and loss plots" height="282" src="image/B18118_05_013.jpg" width="792"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Accuracy and loss plots</p>
<p>Perhaps if we train for longer, we could see an improved performance. In the next chapter, we will examine what happens if we do train for longer, as well as look at other approaches to improve our model’s performance. Here, the aim is to understand what the plot <a id="_idIndexMarker286"/>means and gain enough information to direct our next line of action. Let’s evaluate our model on the <span class="No-Break">test set.</span></p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor124"/>Evaluating the model</h2>
<p>We evaluate the<a id="_idIndexMarker287"/> overall performance of our model on the test set <span class="No-Break">as follows:</span></p>
<pre class="source-code">
test_loss,test_acc =model.evaluate(test_images,test_labels)
print('Test Accuracy: ', test_acc)</pre>
<p>We get an accuracy of <strong class="source-inline">0.8567</strong> on the test set. The difference between the training accuracy and the test accuracy is a common problem in machine learning that we refer to as <strong class="bold">overfitting</strong>. Overfitting is a key issue in machine learning, and we will look at overfitting and various ways of handling it in <a href="B18118_08.xhtml#_idTextAnchor186"><span class="No-Break"><em class="italic">Chapter 8</em></span></a><em class="italic">, </em><span class="No-Break"><em class="italic">Handling Overfitting</em></span><span class="No-Break">.</span></p>
<p>Next, let us make some predictions with our trained <span class="No-Break">neural network.</span></p>
<h2 id="_idParaDest-108"><a id="_idTextAnchor125"/>Model prediction</h2>
<p>To <a id="_idIndexMarker288"/>make predictions on the model, we use the <strong class="source-inline">model.predict()</strong> method on unseen data from our test set. Let’s look at what the model predicts on the first instance of our <span class="No-Break">test data:</span></p>
<pre class="source-code">
predictions=model.predict(test_images)
predictions[0].round(2)</pre>
<p>When we run the code, we get back an array <span class="No-Break">of probabilities:</span></p>
<pre class="source-code">
array([0.  , 0.  , 0.  , 0.  , 0.  ,
    0.13, 0.  , 0.16, 0.  , 0.7 ],
    dtype=float32)</pre>
<p>If we inspect the probabilities, we see that the probability is highest at the ninth element. So, there is a 70% chance that this is our label. We will use <strong class="source-inline">np.argmax</strong> to extract the label and compare it to the test label at <span class="No-Break">index </span><span class="No-Break"><strong class="source-inline">0</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
np.argmax(predictions[0]),test_labels[0]</pre>
<p>We <a id="_idIndexMarker289"/>see that both the predicted label and test label return a value of <strong class="source-inline">9</strong>. Our model got this prediction right. Next, let us plot 16 random images and compare the predicted results with the ground label. This time, rather than returning the numeric values of our labels, we will return the labels themselves for <span class="No-Break">visual clarity:</span></p>
<pre class="source-code">
# Let us plot 16 random images and compare the labels with the model's prediction
figure = plt.figure(figsize=(9, 9))
for i, index in enumerate(np.random.choice(test_images.shape[0],
size=16, replace=False)):
    ax = figure.add_subplot(4,4,i + 1,xticks=[], yticks=[])
    # Display each image
    ax.imshow(np.squeeze(test_images[index]))
    predict_index = np.argmax(predictions[index])
    true_index = test_labels[index]
    # Set the title for each image
    ax.set_title(f»{class_names[predict_index]} (
    {class_names[true_index]})",color=(
        "green" if predict_index == true_index else «red»))</pre>
<p>The result is shown in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.14</em>. Although the model was able to classify 10 items correctly, it failed on one sample where it classified a shirt as <span class="No-Break">a pullover:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer095">
<img alt="Figure 5.14 – Visualizing the model’s prediction on test data" height="523" src="image/B18118_05_014.jpg" width="531"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.14 – Visualizing the model’s prediction on test data</p>
<p>In just a<a id="_idIndexMarker290"/> few lines of code, we have trained an image classifier. We reached an accuracy of 88.50% on our training data in five epochs and 85.67% on our test data. It is important to note that this is a toy dataset that is great for learning; however, real-world images are more complex and the training will take much longer and, in many instances, a more complex model architecture will <span class="No-Break">be required.</span></p>
<p>In this chapter, we have covered a lot of new concepts that will be very useful in later chapters and in the exams <span class="No-Break">as well.</span></p>
<h1 id="_idParaDest-109"><a id="_idTextAnchor126"/>Summary</h1>
<p>In this chapter, we discussed image classification modeling. Now, you should be able to explain what a neural network is, as well as forward and backward propagation. You should know the role of loss functions, activation functions, and optimizers in a neural network. Also, you should be able to find your way around loading data from a TensorFlow dataset. Finally, you should be familiar with how to build, compile, fit, and train a neural network for image classification as well as evaluate the model, plot the loss and accuracy curves, and interpret <span class="No-Break">these visualizations.</span></p>
<p>In the next chapter, we will explore several ideas we can apply to improve our <span class="No-Break">model’s performance.</span></p>
<h1 id="_idParaDest-110"><a id="_idTextAnchor127"/>Questions</h1>
<p>Let’s test what we learned in <span class="No-Break">this chapter:</span></p>
<ol>
<li>What is the function of the <span class="No-Break">activation function?</span></li>
<li>How does backward <span class="No-Break">propagation work?</span></li>
<li>What is the purpose of the input, hidden, and <span class="No-Break">output layers?</span></li>
<li>Using a TensorFlow dataset, load a handwritten digits dataset after which you will build, compile, train, and evaluate an image classifier. It’s a similar exercise to our case study. Go <span class="No-Break">for it.</span></li>
</ol>
<h1 id="_idParaDest-111"><a id="_idTextAnchor128"/>Further reading</h1>
<p>To learn more, you can check out the <span class="No-Break">following resources:</span></p>
<ul>
<li>Amr, T., 2020. <em class="italic">Hands-On Machine Learning with scikit-learn and Scientific Python Toolkits</em>. [S.l.]: <span class="No-Break">Packt Publishing.</span></li>
<li>Vasilev, I., 2019. <em class="italic">Advanced Deep Learning with Python</em>. 1st ed. <span class="No-Break">Packt Publishing.</span></li>
<li>Raschka, S. and Mirjalili, V., 2019. <em class="italic">Python Machine Learning</em>. 3rd ed. <span class="No-Break">Packt Publishing.</span></li>
<li>Gulli, A., Kapoor, A. and Pal, S., 2019. <em class="italic">Deep Learning with TensorFlow 2 and Keras</em>. Birmingham: <span class="No-Break">Packt Publishing.</span></li>
<li><em class="italic">TensorFlow </em><span class="No-Break"><em class="italic">Guide</em></span><span class="No-Break"> </span><a href="https://www.TensorFlow.org/guide"><span class="No-Break">https://www.TensorFlow.org/guide</span></a></li>
</ul>
</div>
</div></body></html>