["```\n# model is a tf.keras.Model model\npath = \"/tmp/model/1\"\ntf.saved_model.save(model, path)\n```", "```\nassets/\nvariables/\n    variables.data-?????-of-?????\n    variables.index\nsaved_model.pb\n```", "```\ndef pow(x, y):\n    return tf.math.pow(x, y)\n```", "```\nclass Wrapper(tf.Module):\n\n    def pow(self, x, y):\n        return tf.math.pow(x, y)\n```", "```\nclass Wrapper(tf.Module):\n\n    @tf.function(\n        input_signature=[\n            tf.TensorSpec(shape=None, dtype=tf.float32),\n            tf.TensorSpec(shape=None, dtype=tf.float32),\n        ]\n    )\n    def pow(self, x, y):\n        return tf.math.pow(x, y)\n\nobj = Wrapper()\ntf.saved_model.save(obj, \"/tmp/pow/1\")\n```", "```\npath = \"/tmp/pow/1\"\nimported = tf.saved_model.load(path)\n```", "```\nassert \"serving_default\" == list(imported.signatures)[0]\nassert len(imported.signatures) == 1\n```", "```\npow = imported.signatures[\"serving_default\"]\nresult = pow(x=tf.constant(2.0), y=tf.constant(5.0))\n```", "```\nassert result[\"output_0\"].numpy() == 32\n```", "```\n    def pow(self, x, y):\n        return tf.math.pow(x, y), tf.math.pow(y, x)\n```", "```\nclass Wrapper(tf.Module):\n\nclass Wrapper(tf.Module):\n    @tf.function(\n        input_signature=[\n            tf.TensorSpec(shape=None, dtype=tf.float32),\n            tf.TensorSpec(shape=None, dtype=tf.float32),\n        ]\n    )\n    def pow(self, x, y):\n        return {\"pow_x_y\":tf.math.pow(x, y), \"pow_y_x\": tf.math.pow(y, x)}\n\nobj = Wrapper()\ntf.saved_model.save(obj, \"/tmp/pow/1\")\n```", "```\npath = \"/tmp/pow/1\"\n\nimported = tf.saved_model.load(path)\nprint(imported.signatures[\"serving_default\"](\n        x=tf.constant(2.0),y=tf.constant(5.0)))\n```", "```\n{\n  'pow_x_y': <tf.Tensor: id=468, shape=(), dtype=float32, numpy=32.0>,\n  'pow_y_x': <tf.Tensor: id=469, shape=(), dtype=float32, numpy=25.0>\n}\n```", "```\nimported = tf.saved_model.load(path)\n# inputs is a input compatible with the serialized model\noutputs = imported(inputs)\n```", "```\nmodel = tf.keras.models.load_model(path)\n# models is now a tf.keras.Model object!\n```", "```\nimported = tf.saved_model.load(v1savedmodel_path)\npruned = imported.prune(\"input_:0\", \"cnn/out/identity:0\")\n# inputs is an input compatible with the flat graph\nout = pruned(inputs)\n```", "```\npip install tensorflowjs\n```", "```\ntensorflowjs_converter \\\n    --input_format \"tf_saved_model\" \\\n    --output_format \"tfjs_graph_model\" \\\n    /tmp/pow/1 \\\n    exported_js\n```", "```\n <html>\n    <head>\n        <title>Power</title>\n        <!-- Include the latest TensorFlow.js runtime -->\n        <script src=\"img/tfjs@latest\"></script>\n    </head>\n    <body>\n        x: <input type=\"number\" step=\"0.01\" id=\"x\"><br>\n        y: <input type=\"number\" step=\"0.01\" id=\"y\"><br>\n        <button id=\"pow\" name=\"pow\">pow</button><br>\n        <div>\n            x<sup>y</sup>: <span id=\"x_to_y\"></span>\n        </div>\n        <div>\n            y<sup>x</sup>: <span id=\"y_to_x\"></span>\n        </div>\n\n        <script>\n            document.getElementById(\"pow\").addEventListener(\"click\", async function() {\n                // Load the model\n                const model = await tf.loadGraphModel(\"exported_js/model.json\")\n                // Input Tensors\n                let x = tf.tensor1d([document.getElementById(\"x\").value], dtype='float32')\n                let y = tf.tensor1d([document.getElementById(\"y\").value], dtype='float32')\n                let results = model.execute({\"x\": x, \"y\": y})\n                let x_to_y = results[0].dataSync()\n                let y_to_x = results[1].dataSync()\n\n                document.getElementById(\"x_to_y\").innerHTML = x_to_y\n                document.getElementById(\"y_to_x\").innerHTML = y_to_x\n            });\n        </script>\n    </body>\n</html>\n```", "```\npython -m http.server\n```", "```\nimport tensorflowjs as tfjs\nfrom tensorflow import keras\n\nmodel = keras.models.Sequential() # for example\n# create the model by adding layers\n\n# Standard Keras way of defining and executing the training loop\n# (this can be replaced by a custom training loop)\nmodel.compile(...)\nmodel.fit(...)\n\n# Convert the model to the model.json in the exported_js dir\ntfjs_target_dir = \"exported_js\"\ntfjs.converters.save_keras_model(model, tfjs_target_dir)\n```", "```\n#!/usr/bin/env bash\n\n# variables\nTF_VERSION_MAJOR=1\nTF_VERSION_MINOR=13\nTF_VERSION_PATCH=1\n\ncurl -L \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-\"\"$TF_VERSION_MAJOR\".\"$TF_VERSION_MINOR\".\"$TF_VERSION_PATCH\"\".tar.gz\" | sudo tar -C /usr/local -xz\nsudo ldconfig\ngit clone https://github.com/tensorflow/tensorflow $GOPATH/src/github.com/tensorflow/tensorflow/\npushd $GOPATH/src/github.com/tensorflow/tensorflow/tensorflow/go\ngit checkout r\"$TF_VERSION_MAJOR\".\"$TF_VERSION_MINOR\"\ngo build\n```", "```\ngo get -u github.com/galeone/tfgo\n```", "```\nsaved_model_cli show --all --dir /tmp/pow/1\n```", "```\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['__saved_model_init_op']:\n  The given SavedModel SignatureDef contains the following input(s):\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['__saved_model_init_op'] tensor_info:\n        dtype: DT_INVALID\n        shape: unknown_rank\n        name: NoOp\n  Method name is: \n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['x'] tensor_info:\n        dtype: DT_FLOAT\n        shape: unknown_rank\n        name: serving_default_x:0\n    inputs['y'] tensor_info:\n        dtype: DT_FLOAT\n        shape: unknown_rank\n        name: serving_default_y:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['pow_x_y'] tensor_info:\n        dtype: DT_FLOAT\n        shape: unknown_rank\n        name: PartitionedCall:0\n    outputs['pow_y_x'] tensor_info:\n        dtype: DT_FLOAT\n        shape: unknown_rank\n        name: PartitionedCall:1\n  Method name is: tensorflow/serving/predict\n```", "```\npackage main\n\n import (\n \"fmt\"\n tg \"github.com/galeone/tfgo\"\n tf \"github.com/tensorflow/tensorflow/tensorflow/go\"\n )\n```", "```\nfunc main() {\n model := tg.LoadModel(\"/tmp/pow/1\", []string{\"serve\"}, nil)\n x, _ := tf.NewTensor(float32(2.0))\n y, _ := tf.NewTensor(float32(5.0))\n\nresults := model.Exec([]tf.Output{\n model.Op(\"PartitionedCall\", 0),\n }, map[tf.Output]*tf.Tensor{\n model.Op(\"serving_default_x\", 0): x,\n model.Op(\"serving_default_y\", 0): y,\n })\n\n predictions := results[0].Value().(float32)\n fmt.Println(predictions)\n }\n```"]