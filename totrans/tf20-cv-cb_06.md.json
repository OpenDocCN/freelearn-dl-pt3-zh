["```\n$> pip install tensorflow-datasets tqdm\n```", "```\n    import matplotlib.pyplot as plt\n    import tensorflow as tf\n    import tensorflow_datasets as tfds\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import BinaryCrossentropy\n    from tensorflow.keras.models import Model\n    from tensorflow.keras.optimizers import Adam\n    from tqdm import tqdm\n    ```", "```\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    ```", "```\n    class DCGAN(object):\n        def __init__(self):\n            self.loss = BinaryCrossentropy(from_logits=True)\n            self.generator = self.create_generator()\n            self.discriminator = self.create_discriminator()\n            self.generator_opt = Adam(learning_rate=1e-4)\n            self.discriminator_opt = Adam(learning_rate=1e-4)\n    ```", "```\n       @staticmethod\n        def create_generator(alpha=0.2):\n            input = Input(shape=(100,))\n            x = Dense(units=7 * 7 * 256, \n                     use_bias=False)(input)\n            x = LeakyReLU(alpha=alpha)(x)\n            x = BatchNormalization()(x)\n            x = Reshape((7, 7, 256))(x)\n    ```", "```\n            x = Conv2DTranspose(filters=128,\n                                strides=(1, 1),\n                                kernel_size=(5, 5),\n                                padding='same',\n                                use_bias=False)(x)\n            x = LeakyReLU(alpha=alpha)(x)\n            x = BatchNormalization()(x)\n    ```", "```\n            x = Conv2DTranspose(filters=64,\n                                strides=(2, 2),\n                                kernel_size=(5, 5),\n                                padding='same',\n                                use_bias=False)(x)\n            x = LeakyReLU(alpha=alpha)(x)\n            x = BatchNormalization()(x)\n    ```", "```\n            x = Conv2DTranspose(filters=1,\n                                strides=(2, 2),\n                                kernel_size=(5, 5),\n                                padding='same',\n                                use_bias=False)(x)\n            output = Activation('tanh')(x)\n            return Model(input, output)\n    ```", "```\n        @staticmethod\n        def create_discriminator(alpha=0.2, dropout=0.3):\n            input = Input(shape=(28, 28, 1))\n            x = Conv2D(filters=64,\n                       kernel_size=(5, 5),\n                       strides=(2, 2),\n                       padding='same')(input)\n            x = LeakyReLU(alpha=alpha)(x)\n            x = Dropout(rate=dropout)(x)\n            x = Conv2D(filters=128,\n                       kernel_size=(5, 5),\n                       strides=(2, 2),\n                       padding='same')(x)\n            x = LeakyReLU(alpha=alpha)(x)\n            x = Dropout(rate=dropout)(x)\n            x = Flatten()(x)\n            output = Dense(units=1)(x)\n            return Model(input, output)\n    ```", "```\n        def discriminator_loss(self, real, fake):\n            real_loss = self.loss(tf.ones_like(real), real)\n            fake_loss = self.loss(tf.zeros_like(fake), fake)\n            return real_loss + fake_loss\n    ```", "```\n        def generator_loss(self, fake):\n            return self.loss(tf.ones_like(fake), fake)\n    ```", "```\n        @tf.function\n        def train_step(self, images, batch_size):\n            noise = tf.random.normal((batch_size,noise_dimension))\n    ```", "```\n            with tf.GradientTape() as gen_tape, \\\n                    tf.GradientTape() as dis_tape:\n                generated_images = self.generator(noise,\n                                            training=True)\n    ```", "```\n                real = self.discriminator(images, \n                                          training=True)\n                fake = self.discriminator(generated_images,\n                                          training=True)\n                gen_loss = self.generator_loss(fake)\n                disc_loss = self.discriminator_loss(real, \n                                                   fake)\n    ```", "```\n            generator_grad = gen_tape \\\n                .gradient(gen_loss,\n                          self.generator.trainable_variables)\n            discriminator_grad = dis_tape \\\n                .gradient(disc_loss,\n                    self.discriminator.trainable_       variables)\n    ```", "```\n            opt_args = zip(generator_grad,\n                          self.generator.trainable_variables)\n            self.generator_opt.apply_gradients(opt_args)\n            opt_args = zip(discriminator_grad,\n\n                   self.discriminator.trainable_variables)\n            self.discriminator_opt.apply_gradients(opt_args)\n    ```", "```\n        def train(self, dataset, test_seed, epochs, \n                   batch_size):\n            for epoch in tqdm(range(epochs)):\n                for image_batch in dataset:\n                    self.train_step(image_batch, \n                                     batch_size)\n                if epoch == 0 or epoch % 10 == 0:\n\n               generate_and_save_images(self.generator,\n                                             epoch,\n                                             test_seed)\n    ```", "```\n    def generate_and_save_images(model, epoch, test_input):\n        predictions = model(test_input, training=False)\n        plt.figure(figsize=(4, 4))\n        for i in range(predictions.shape[0]):\n            plt.subplot(4, 4, i + 1)\n            image = predictions[i, :, :, 0] * 127.5 + 127.5\n            image = tf.cast(image, tf.uint8)\n            plt.imshow(image, cmap='gray')\n            plt.axis('off')\n        plt.savefig(f'{epoch}.png')\n        plt.show()\n    ```", "```\n    def process_image(input):\n        image = tf.cast(input['image'], tf.float32)\n        image = (image - 127.5) / 127.5\n        return image\n    ```", "```\n    BUFFER_SIZE = 1000\n    BATCH_SIZE = 512\n    train_dataset = (tfds\n                     .load('emnist', split='train')\n                     .map(process_image,\n                          num_parallel_calls=AUTOTUNE)\n                     .shuffle(BUFFER_SIZE)\n                     .batch(BATCH_SIZE))\n    ```", "```\n    noise_dimension = 100\n    num_examples_to_generate = 16\n    seed_shape = (num_examples_to_generate, \n                  noise_dimension)\n    test_seed = tf.random.normal(seed_shape)\n    ```", "```\n    EPOCHS = 200\n    dcgan = DCGAN()\n    dcgan.train(train_dataset, test_seed, EPOCHS, BATCH_SIZE)\n    ```", "```\n$> pip install tqdm\n```", "```\n    import numpy as np\n    from numpy.random import *\n    from tensorflow.keras import backend as K\n    from tensorflow.keras.datasets import fashion_mnist as fmnist\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.models import Model\n    from tensorflow.keras.optimizers import Adam\n    from tqdm import tqdm\n    ```", "```\n    def pick_supervised_subset(feats,\n                               labels,\n                               n_samples=1000,\n                               n_classes=10):\n        samples_per_class = int(n_samples / n_classes)\n        X = []\n        y = []\n        for i in range(n_classes):\n            class_feats = feats[labels == i]\n            class_sample_idx = randint(low=0,\n\n                                   high=len(class_feats),\n                                  size=samples_per_class)\n            X.extend([class_feats[j] for j in \n                      class_sample_idx])\n            y.extend([i] * samples_per_class)\n        return np.array(X), np.array(y)\n    ```", "```\n    def pick_samples_for_classification(feats, labels, \n                                         n_samples):\n        sample_idx = randint(low=0,\n                             high=feats.shape[0],\n                             size=n_samples)\n        X = np.array([feats[i] for i in sample_idx])\n        y = np.array([labels[i] for i in sample_idx])\n        return X, y\n    ```", "```\n    def pick_samples_for_discrimination(feats, n_samples):\n        sample_idx = randint(low=0,\n                             high=feats.shape[0],\n                             size=n_samples)\n        X = np.array([feats[i] for i in sample_idx])\n        y = np.ones((n_samples, 1))\n        return X, y\n    ```", "```\n    def generate_fake_samples(model, latent_size, \n                              n_samples):\n        z_input = generate_latent_points(latent_size, \n                                          n_samples)\n        images = model.predict(z_input)\n        y = np.zeros((n_samples, 1))\n        return images, y\n    ```", "```\n    def generate_fake_samples(model, latent_size, \n                              n_samples):\n        z_input = generate_latent_points(latent_size, \n                                          n_samples)\n        images = model.predict(z_input)\n        y = np.zeros((n_samples, 1))\n        return images, y\n    ```", "```\n    class SSGAN(object):\n        def __init__(self,\n                     latent_size=100,\n                     input_shape=(28, 28, 1),\n                     alpha=0.2):\n            self.latent_size = latent_size\n            self.input_shape = input_shape\n            self.alpha = alpha\n    ```", "```\n            (self.classifier,\n             self.discriminator) = self._create_discriminators()\n    ```", "```\n            clf_opt = Adam(learning_rate=2e-4, beta_1=0.5)\n            self.classifier.compile(\n                loss='sparse_categorical_crossentropy',\n                optimizer=clf_opt,\n                metrics=['accuracy'])\n            dis_opt = Adam(learning_rate=2e-4, beta_1=0.5)\n            self.discriminator.compile(loss='binary_crossentropy',\n                                       optimizer=dis_opt)\n    ```", "```\n            self.generator = self._create_generator()\n    ```", "```\n            self.gan = self._create_gan()\n            gan_opt = Adam(learning_rate=2e-4, beta_1=0.5)\n            self.gan.compile(loss='binary_crossentropy',\n                             optimizer=gan_opt)\n    ```", "```\n        def _create_discriminators(self, num_classes=10):\n            def custom_activation(x):\n                log_exp_sum = K.sum(K.exp(x), axis=-1,\n                                    keepdims=True)\n                return log_exp_sum / (log_exp_sum + 1.0)\n    ```", "```\n            input = Input(shape=self.input_shape)\n            x = input\n            for _ in range(3):\n                x = Conv2D(filters=128,\n                           kernel_size=(3, 3),\n                           strides=2,\n                           padding='same')(x)\n                x = LeakyReLU(alpha=self.alpha)(x)\n            x = Flatten()(x)\n            x = Dropout(rate=0.4)(x)\n            x = Dense(units=num_classes)(x)\n            clf_output = Softmax()(x)\n            clf_model = Model(input, clf_output)\n    ```", "```\n            dis_output = Lambda(custom_activation)(x)\n            discriminator_model = Model(input, dis_output)\n    ```", "```\n            return clf_model, discriminator_model\n    ```", "```\n        def _create_generator(self):\n            input = Input(shape=(self.latent_size,))\n            x = Dense(units=128 * 7 * 7)(input)\n            x = LeakyReLU(alpha=self.alpha)(x)\n            x = Reshape((7, 7, 128))(x)\n            for _ in range(2):\n                x = Conv2DTranspose(filters=128,\n                                    kernel_size=(4, 4),\n                                    strides=2,\n                                    padding='same')(x)\n                x = LeakyReLU(alpha=self.alpha)(x)\n            x = Conv2D(filters=1,\n                       kernel_size=(7, 7),\n                       padding='same')(x)\n            output = Activation('tanh')(x)\n            return Model(input, output)\n    ```", "```\n        def _create_gan(self):\n            self.discriminator.trainable = False\n            output = \n                  self.discriminator(self.generator.output)\n            return Model(self.generator.input, output)\n    ```", "```\n        def train(self, X, y, epochs=20, num_batches=100):\n            X_sup, y_sup = pick_supervised_subset(X, y)\n            batches_per_epoch = int(X.shape[0] / num_batches)\n            num_steps = batches_per_epoch * epochs\n            num_samples = int(num_batches / 2)\n    ```", "```\n            for _ in tqdm(range(num_steps)):\n                X_sup_real, y_sup_real = \\\n                    pick_samples_for_classification(X_sup,\n                                                    y_sup,\n                                              num_samples)\n                self.classifier.train_on_batch(X_sup_real,\n                                               y_sup_real)\n    ```", "```\n                X_real, y_real = \\\n                    pick_samples_for_discrimination(X,\n                                              num_samples)\n            self.discriminator.train_on_batch(X_real, y_real)\n    ```", "```\n                X_fake, y_fake = \\\n                    generate_fake_samples(self.generator,\n                                        self.latent_size,\n                                          num_samples)\n                self.discriminator.train_on_batch(X_fake, \n                                                 y_fake)\n    ```", "```\n                X_gan = generate_latent_points(self.latent_size,\n                          num_batches)\n                y_gan = np.ones((num_batches, 1))\n                self.gan.train_on_batch(X_gan, y_gan)\n    ```", "```\n    (X_train, y_train), (X_test, y_test) = fmnist.load_data()\n    X_train = np.expand_dims(X_train, axis=-1)\n    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n    X_test = np.expand_dims(X_test, axis=-1)\n    X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n    ```", "```\n    ssgan = SSGAN()\n    ssgan.train(X_train, y_train, epochs=30)\n    ```", "```\n    train_acc = ssgan.classifier.evaluate(X_train, \n                                          y_train)[1]\n    train_acc *= 100\n    print(f'Train accuracy: {train_acc:.2f}%')\n    test_acc = ssgan.classifier.evaluate(X_test, y_test)[1]\n    test_acc *= 100\n    print(f'Test accuracy: {test_acc:.2f}%')\n    ```", "```\n$> pip install tqdm\n```", "```\n    import pathlib\n    import cv2\n    import numpy as np\n    import tensorflow as tf\n    import tqdm\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import BinaryCrossentropy\n    from tensorflow.keras.models import *\n    from tensorflow.keras.optimizers import Adam\n    ```", "```\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    NEAREST_NEIGHBOR = tf.image.ResizeMethod.NEAREST_NEIGHBOR\n    IMAGE_WIDTH = 256\n    IMAGE_HEIGHT = 256\n    ```", "```\n    def load_image(image_path):\n        image = tf.io.read_file(image_path)\n        image = tf.image.decode_jpeg(image)\n        width = tf.shape(image)[1]\n        width = width // 2\n        real_image = image[:, :width, :]\n        input_image = image[:, width:, :]\n        input_image = tf.cast(input_image, tf.float32)\n        real_image = tf.cast(real_image, tf.float32)\n        return input_image, real_image\n    ```", "```\n     def resize(input_image, real_image, height, width):\n        input_image = tf.image.resize(input_image,\n                                  size=(height,width),\n                                 method=NEAREST_NEIGHBOR)\n        real_image = tf.image.resize(real_image,\n                                     size=(height, width),\n                                  method=NEAREST_NEIGHBOR)\n        return input_image, real_image\n    ```", "```\n    def random_crop(input_image, real_image):\n        stacked_image = tf.stack([input_image, \n                                 real_image],axis=0)\n        size = (2, IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n        cropped_image = tf.image.random_crop(stacked_image,\n                                             size=size)\n        input_image = cropped_image[0]\n        real_image = cropped_image[1]\n        return input_image, real_image\n    ```", "```\n    def normalize(input_image, real_image):\n        input_image = (input_image / 127.5) - 1\n        real_image = (real_image / 127.5) - 1\n        return input_image, real_image\n    ```", "```\n    @tf.function\n    def random_jitter(input_image, real_image):\n        input_image, real_image = resize(input_image, \n                                         real_image,\n                                         width=286, \n                                          height=286)\n        input_image, real_image = random_crop(input_image,\n                                              real_image)\n        if np.random.uniform() > 0.5:\n            input_image = \\\n                  tf.image.flip_left_right(input_image)\n            real_image = \\\n                 tf.image.flip_left_right(real_image)\n        return input_image, real_image\n    ```", "```\n    def load_training_image(image_path):\n        input_image, real_image = load_image(image_path)\n        input_image, real_image = \\\n            random_jitter(input_image, real_image)\n        input_image, real_image = \\\n            normalize(input_image, real_image)\n        return input_image, real_image\n    ```", "```\n    def load_test_image(image_path):\n        input_image, real_image = load_image(image_path)\n        input_image, real_image = resize(input_image, \n                                         real_image,\n                                       width=IMAGE_WIDTH,\n                                     height=IMAGE_HEIGHT)\n        input_image, real_image = \\\n            normalize(input_image, real_image)\n        return input_image, real_image\n    ```", "```\n    def generate_and_save_images(model, input, target,epoch):\n        prediction = model(input, training=True)\n        display_list = [input[0], target[0], prediction[0]]\n        image = np.hstack(display_list)\n        image *= 0.5\n        image += 0.5\n        image *= 255.0\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(f'{epoch + 1}.jpg', image)\n    ```", "```\n    class Pix2Pix(object):\n        def __init__(self, output_channels=3, \n                     lambda_value=100):\n            self.loss = BinaryCrossentropy(from_logits=True)\n            self.output_channels = output_channels\n            self._lambda = lambda_value\n            self.generator = self.create_generator()\n            self.discriminator = self.create_discriminator()\n            self.gen_opt = Adam(learning_rate=2e-4, \n                                 beta_1=0.5)\n            self.dis_opt = Adam(learning_rate=2e-4, \n                                 beta_1=0.5)\n    ```", "```\n        @staticmethod\n        def downsample(filters, size, batch_norm=True):\n           initializer = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2D(filters=filters,\n                              kernel_size=size,\n                              strides=2,\n                              padding='same',\n\n                          kernel_initializer=initializer,\n                              use_bias=False))\n            if batch_norm:\n                layers.add(BatchNormalization())\n            layers.add(LeakyReLU())\n            return layers\n    ```", "```\n        @staticmethod\n        def upsample(filters, size, dropout=False):\n            init = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2DTranspose(filters=filters,\n                                       kernel_size=size,\n                                       strides=2,\n                                       padding='same',\n                                 kernel_initializer=init,\n                                       use_bias=False))\n            layers.add(BatchNormalization())\n            if dropout:\n                layers.add(Dropout(rate=0.5))\n            layers.add(ReLU())\n            return layers\n    ```", "```\n        def create_generator(self, input_shape=(256, 256,3)):\n            down_stack = [self.downsample(64,4,batch_norm=False)]\n            for filters in (128, 256, 512, 512, 512, 512, \n                             512):\n                down_block = self.downsample(filters, 4)\n                down_stack.append(down_block)\n    ```", "```\n            up_stack = []\n            for _ in range(3):\n                up_block = self.upsample(512, 4,dropout=True)\n                up_stack.append(up_block)\n            for filters in (512, 256, 128, 64):\n                up_block = self.upsample(filters, 4)\n                up_stack.append(up_block)\n    ```", "```\n            inputs = Input(shape=input_shape)\n            x = inputs\n            skip_layers = []\n            for down in down_stack:\n                x = down(x)\n                skip_layers.append(x)\n            skip_layers = reversed(skip_layers[:-1])\n            for up, skip_connection in zip(up_stack, \n                                           skip_layers):\n                x = up(x)\n                x = Concatenate()([x, skip_connection])\n    ```", "```\n            init = tf.random_normal_initializer(0.0, 0.02)\n            output = Conv2DTranspose(\n                filters=self.output_channels,\n                kernel_size=4,\n                strides=2,\n                padding='same',\n                kernel_initializer=init,\n                activation='tanh')(x)\n            return Model(inputs, outputs=output)\n    ```", "```\n        def generator_loss(self,\n                           discriminator_generated_output,\n                           generator_output,\n                           target):\n            gan_loss = self.loss(\n                tf.ones_like(discriminator_generated_output),\n                discriminator_generated_output)\n            # MAE\n            error = target - generator_output\n            l1_loss = tf.reduce_mean(tf.abs(error))\n            total_gen_loss = gan_loss + (self._lambda * \n                                          l1_loss)\n            return total_gen_loss, gan_loss, l1_loss\n    ```", "```\n        def create_discriminator(self):\n            input = Input(shape=(256, 256, 3))\n            target = Input(shape=(256, 256, 3))\n            x = Concatenate()([input, target])\n            x = self.downsample(64, 4, False)(x)\n            x = self.downsample(128, 4)(x)\n            x = self.downsample(256, 4)(x)\n            x = ZeroPadding2D()(x)\n    ```", "```\n            init = tf.random_normal_initializer(0.0, 0.02)\n            x = Conv2D(filters=512,\n                       kernel_size=4,\n                       strides=1,\n                       kernel_initializer=init,\n                       use_bias=False)(x)\n            x = BatchNormalization()(x)\n            x = LeakyReLU()(x)\n            x = ZeroPadding2D()(x)\n            output = Conv2D(filters=1,\n                            kernel_size=4,\n                            strides=1,\n                            kernel_initializer=init)(x)\n            return Model(inputs=[input, target], \n                        outputs=output)\n    ```", "```\n        def discriminator_loss(self,\n                               discriminator_real_output,\n                             discriminator_generated_output):\n            real_loss = self.loss(\n                tf.ones_like(discriminator_real_output),\n                discriminator_real_output)\n            fake_loss = self.loss(\n                tf.zeros_like(discriminator_generated_output),\n                discriminator_generated_output)\n            return real_loss + fake_loss\n    ```", "```\n        @tf.function\n        def train_step(self, input_image, target):\n            with tf.GradientTape() as gen_tape, \\\n                    tf.GradientTape() as dis_tape:\n                gen_output = self.generator(input_image,\n                                            training=True)\n                dis_real_output = self.discriminator(\n                    [input_image, target], training=True)\n                dis_gen_output = self.discriminator(\n                    [input_image, gen_output], \n                            training=True)\n    ```", "```\n                (gen_total_loss, gen_gan_loss,   \n                   gen_l1_loss) = \\\n                    self.generator_loss(dis_gen_output,\n                                        gen_output,\n                                        target)\n                dis_loss = \\\n                    self.discriminator_loss(dis_real_output,\n\n                            dis_gen_output)\n            gen_grads = gen_tape. \\\n                gradient(gen_total_loss,\n                         self.generator.trainable_variables)\n            dis_grads = dis_tape. \\\n                gradient(dis_loss,\n                         self.discriminator.trainable_variables)\n    ```", "```\n            opt_args = zip(gen_grads,\n                           self.generator.trainable_variables)\n            self.gen_opt.apply_gradients(opt_args)\n            opt_args = zip(dis_grads,\n                           self.discriminator.trainable_variables)\n            self.dis_opt.apply_gradients(opt_args)\n    ```", "```\n        def fit(self, train, epochs, test):\n            for epoch in tqdm.tqdm(range(epochs)):\n                for example_input, example_target in \n                                  test.take(1):\n                    generate_and_save_images(self.generator,\n                                           example_input,\n                                           example_target,\n                                             epoch)\n                for input_image, target in train:\n                    self.train_step(input_image, target)\n    ```", "```\n    dataset_path = (pathlib.Path.home() / '.keras' / \n                    'datasets' /'cityscapes')\n    train_dataset_pattern = str(dataset_path / 'train' / \n                                 '*.jpg')\n    test_dataset_pattern = str(dataset_path / 'val' / \n                               '*.jpg')\n    ```", "```\n    BUFFER_SIZE = 400\n    BATCH_SIZE = 1\n    train_ds = (tf.data.Dataset\n                .list_files(train_dataset_pattern)\n                .map(load_training_image,\n                     num_parallel_calls=AUTOTUNE)\n                .shuffle(BUFFER_SIZE)\n                .batch(BATCH_SIZE))\n    test_ds = (tf.data.Dataset\n               .list_files(test_dataset_pattern)\n               .map(load_test_image)\n               .batch(BATCH_SIZE))\n    ```", "```\n    pix2pix = Pix2Pix()\n    pix2pix.fit(train_ds, epochs=150, test=test_ds)\n    ```", "```\n$> pip install opencv-contrib-python tqdm tensorflow-datasets\n```", "```\n    import cv2\n    import numpy as np\n    import tensorflow as tf\n    import tensorflow_datasets as tfds\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import BinaryCrossentropy\n    from tensorflow.keras.models import *\n    from tensorflow.keras.optimizers import Adam\n    from tqdm import tqdm\n    ```", "```\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    ```", "```\n    def random_crop(image):\n        return tf.image.random_crop(image, size=(256, 256, \n                                                   3))\n    ```", "```\n    def normalize(image):\n        image = tf.cast(image, tf.float32)\n        image = (image / 127.5) - 1\n        return image\n    ```", "```\n    def random_jitter(image):\n        method = tf.image.ResizeMethod.NEAREST_NEIGHBOR\n        image = tf.image.resize(image, (286, 286), \n                                method=method)\n        image = random_crop(image)\n        image = tf.image.random_flip_left_right(image)\n        return image\n    ```", "```\n    def preprocess_training_image(image, _):\n        image = random_jitter(image)\n        image = normalize(image)\n        return image\n    ```", "```\n    def preprocess_test_image(image, _):\n        image = normalize(image)\n        return image\n    ```", "```\n    def generate_images(model, test_input, epoch):\n        prediction = model(test_input)\n        image = np.hstack([test_input[0], prediction[0]])\n        image *= 0.5\n        image += 0.5\n        image *= 255.0\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(f'{epoch + 1}.jpg', image)\n    ```", "```\n    class InstanceNormalization(Layer):\n        def __init__(self, epsilon=1e-5):\n            super(InstanceNormalization, self).__init__()\n            self.epsilon = epsilon\n    ```", "```\n        def build(self, input_shape):\n            init = tf.random_normal_initializer(1.0, 0.02)\n            self.scale = self.add_weight(name='scale',\n                                   shape=input_shape[-1:],\n                                         initializer=init,\n                                         trainable=True)\n            self.offset = self.add_weight(name='offset',\n                                   shape=input_shape[-1:],\n                                      initializer='zeros',\n                                          trainable=True)\n    ```", "```\n        def call(self, x):\n            mean, variance = tf.nn.moments(x,\n                                           axes=(1, 2),\n                                           keepdims=True)\n            inv = tf.math.rsqrt(variance + self.epsilon)\n            normalized = (x - mean) * inv\n            return self.scale * normalized + self.offset\n    ```", "```\n    class CycleGAN(object):\n        def __init__(self, output_channels=3, \n                     lambda_value=10):\n            self.output_channels = output_channels\n            self._lambda = lambda_value\n            self.loss = BinaryCrossentropy(from_logits=True)\n            self.gen_g = self.create_generator()\n            self.gen_f = self.create_generator()\n            self.dis_x = self.create_discriminator()\n            self.dis_y = self.create_discriminator()\n            self.gen_g_opt = Adam(learning_rate=2e-4, \n                                   beta_1=0.5)\n            self.gen_f_opt = Adam(learning_rate=2e-4, \n                                  beta_1=0.5)\n            self.dis_x_opt = Adam(learning_rate=2e-4, \n                                  beta_1=0.5)\n            self.dis_y_opt = Adam(learning_rate=2e-4, \n                                  beta_1=0.5)\n    ```", "```\n        @staticmethod\n        def downsample(filters, size, norm=True):\n            initializer = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2D(filters=filters,\n                              kernel_size=size,\n                              strides=2,\n                              padding='same',\n\n                         kernel_initializer=initializer,\n                              use_bias=False))\n            if norm:\n                layers.add(InstanceNormalization())\n            layers.add(LeakyReLU())\n            return layers\n    ```", "```\n        @staticmethod\n        def upsample(filters, size, dropout=False):\n            init = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2DTranspose(filters=filters,\n                                       kernel_size=size,\n                                       strides=2,\n                                       padding='same',\n\n                                 kernel_initializer=init,\n                                       use_bias=False))\n            layers.add(InstanceNormalization())\n            if dropout:\n                layers.add(Dropout(rate=0.5))\n            layers.add(ReLU())\n            return layers\n    ```", "```\n        def create_generator(self):\n            down_stack = [\n                self.downsample(64, 4, norm=False),\n                self.downsample(128, 4),\n                self.downsample(256, 4)]\n            for _ in range(5):\n                down_block = self.downsample(512, 4)\n                down_stack.append(down_block)\n    ```", "```\n            for _ in range(3):\n                up_block = self.upsample(512, 4, \n                                       dropout=True)\n                up_stack.append(up_block)\n            for filters in (512, 256, 128, 64):\n                up_block = self.upsample(filters, 4)\n                up_stack.append(up_block)\n    ```", "```\n    inputs = Input(shape=(None, None, 3))\n            x = inputs\n            skips = []\n            for down in down_stack:\n                x = down(x)\n                skips.append(x)\n            skips = reversed(skips[:-1])\n            for up, skip in zip(up_stack, skips):\n                x = up(x)\n                x = Concatenate()([x, skip])\n    ```", "```\n            init = tf.random_normal_initializer(0.0, 0.02)\n            output = Conv2DTranspose(\n                filters=self.output_channels,\n                kernel_size=4,\n                strides=2,\n                padding='same',\n                kernel_initializer=init,\n                activation='tanh')(x)\n            return Model(inputs, outputs=output)\n    ```", "```\n        def generator_loss(self, generated):\n            return self.loss(tf.ones_like(generated), \n                             generated)\n    ```", "```\n        def create_discriminator(self):\n            input = Input(shape=(None, None, 3))\n            x = input\n            x = self.downsample(64, 4, False)(x)\n            x = self.downsample(128, 4)(x)\n            x = self.downsample(256, 4)(x)\n            x = ZeroPadding2D()(x)\n    ```", "```\n            init = tf.random_normal_initializer(0.0, 0.02)\n            x = Conv2D(filters=512,\n                       kernel_size=4,\n                       strides=1,\n                       kernel_initializer=init,\n                       use_bias=False)(x)\n            x = InstanceNormalization()(x)\n            x = LeakyReLU()(x)\n            x = ZeroPadding2D()(x)\n            output = Conv2D(filters=1,\n                            kernel_size=4,\n                            strides=1,\n                            kernel_initializer=init)(x)\n            return Model(inputs=input, outputs=output)\n    ```", "```\n        def discriminator_loss(self, real, generated):\n            real_loss = self.loss(tf.ones_like(real), \n                                         real)\n            generated_loss = \n                  self.loss(tf.zeros_like(generated),\n                                       generated)\n            total_discriminator_loss = real_loss + generated_loss\n            return total_discriminator_loss * 0.5\n    ```", "```\n        def calculate_cycle_loss(self, real_image, \n                                 cycled_image):\n            error = real_image - cycled_image\n            loss1 = tf.reduce_mean(tf.abs(error))\n            return self._lambda * loss1\n    ```", "```\n        def identity_loss(self, real_image, same_image):\n            error = real_image - same_image\n            loss = tf.reduce_mean(tf.abs(error))\n            return self._lambda * 0.5 * loss\n    ```", "```\n        @tf.function\n        def train_step(self, real_x, real_y):\n            with tf.GradientTape(persistent=True) as tape:\n                fake_y = self.gen_g(real_x, training=True)\n                cycled_x = self.gen_f(fake_y, \n                                     training=True)\n                fake_x = self.gen_f(real_y, training=True)\n                cycled_y = self.gen_g(fake_x, \n                                       training=True)\n    ```", "```\n                same_x = self.gen_f(real_x, training=True)\n                same_y = self.gen_g(real_y, training=True)\n    ```", "```\n                dis_real_x = self.dis_x(real_x, \n                                        training=True)\n                dis_real_y = self.dis_y(real_y, \n                                        training=True)\n                dis_fake_x = self.dis_x(fake_x,training=True)\n                dis_fake_y = self.dis_y(fake_y, \n                                       training=True)\n    ```", "```\n                gen_g_loss = self.generator_loss(dis_fake_y)\n                gen_f_loss = self.generator_loss(dis_fake_x)\n    ```", "```\n                cycle_x_loss = \\\n                    self.calculate_cycle_loss(real_x, \n                                              cycled_x)\n                cycle_y_loss = \\\n                    self.calculate_cycle_loss(real_y, \n                                             cycled_y)\n                total_cycle_loss = cycle_x_loss + \n                                       cycle_y_loss\n    ```", "```\n                identity_y_loss = \\\n                    self.identity_loss(real_y, same_y)\n                total_generator_g_loss = (gen_g_loss +\n                                          total_cycle_loss +\n                                          identity_y_loss)\n    ```", "```\n                identity_x_loss = \\\n                    self.identity_loss(real_x, same_x)\n                total_generator_f_loss = (gen_f_loss +\n                                          total_cycle_loss +\n                                          identity_x_loss)\n    ```", "```\n             dis_x_loss = \\\n               self.discriminator_loss(dis_real_x,dis_fake_x)\n             dis_y_loss = \\\n               self.discriminator_loss(dis_real_y,dis_fake_y)\n    ```", "```\n            gen_g_grads = tape.gradient(\n                total_generator_g_loss,\n                self.gen_g.trainable_variables)\n            gen_f_grads = tape.gradient(\n                total_generator_f_loss,\n                self.gen_f.trainable_variables)\n    ```", "```\n            dis_x_grads = tape.gradient(\n                dis_x_loss,\n                self.dis_x.trainable_variables)\n            dis_y_grads = tape.gradient(\n                dis_y_loss,\n                self.dis_y.trainable_variables)\n    ```", "```\n            gen_g_opt_params = zip(gen_g_grads,\n                             self.gen_g.trainable_variables)\n            self.gen_g_opt.apply_gradients(gen_g_opt_params)\n            gen_f_opt_params = zip(gen_f_grads,\n                                   self.gen_f.trainable_variables)\n            self.gen_f_opt.apply_gradients(gen_f_opt_params)\n    ```", "```\n            dis_x_opt_params = zip(dis_x_grads,\n                              self.dis_x.trainable_variables)\n            self.dis_x_opt.apply_gradients(dis_x_opt_params)\n            dis_y_opt_params = zip(dis_y_grads,\n                              self.dis_y.trainable_variables)\n            self.dis_y_opt.apply_gradients(dis_y_opt_params)\n    ```", "```\n        def fit(self, train, epochs, test):\n            for epoch in tqdm(range(epochs)):\n                for image_x, image_y in train:\n                    self.train_step(image_x, image_y)\n                test_image = next(iter(test))\n                generate_images(self.gen_g, test_image, \n                                   epoch)\n    ```", "```\n    dataset, _ = tfds.load('cycle_gan/summer2winter_  yosemite',\n                           with_info=True,\n                           as_supervised=True)\n    ```", "```\n    train_summer = dataset['trainA']\n    train_winter = dataset['trainB']\n    test_summer = dataset['testA']\n    test_winter = dataset['testB']\n    ```", "```\n    BUFFER_SIZE = 400\n    BATCH_SIZE = 1\n    train_summer = (train_summer\n                    .map(preprocess_training_image,\n                         num_parallel_calls=AUTOTUNE)\n                    .cache()\n                    .shuffle(BUFFER_SIZE)\n                    .batch(BATCH_SIZE))\n    train_winter = (train_winter\n                    .map(preprocess_training_image,\n                         num_parallel_calls=AUTOTUNE)\n                    .cache()\n                    .shuffle(BUFFER_SIZE)\n                    .batch(BATCH_SIZE))\n    ```", "```\n    test_summer = (test_summer\n                   .map(preprocess_test_image,\n                        num_parallel_calls=AUTOTUNE)\n                   .cache()\n                   .shuffle(BUFFER_SIZE)\n                   .batch(BATCH_SIZE))\n    test_winter = (test_winter\n                   .map(preprocess_test_image,\n                        num_parallel_calls=AUTOTUNE)\n                   .cache()\n                   .shuffle(BUFFER_SIZE)\n                   .batch(BATCH_SIZE))\n    ```", "```\n    cycle_gan = CycleGAN()\n    train_ds = tf.data.Dataset.zip((train_summer, \n                                    train_winter))\n    cycle_gan.fit(train=train_ds,\n                  epochs=40,\n                  test=test_summer)\n    ```", "```\n$> pip install opencv-contrib-python\n```", "```\n    import cv2\n    import tensorflow as tf\n    from tensorflow.keras.applications.nasnet import *\n    from tensorflow.keras.losses import CategoricalCrossentropy\n    ```", "```\n    def preprocess(image, target_shape):\n        image = tf.cast(image, tf.float32)\n        image = tf.image.resize(image, target_shape)\n        image = preprocess_input(image)\n        image = image[None, :, :, :]\n        return image\n    ```", "```\n    def get_imagenet_label(probabilities):\n        return decode_predictions(probabilities, top=1)[0][0]\n    ```", "```\n    def save_image(image, model, description):\n        prediction = model.predict(image)\n        _, label, conf = get_imagenet_label(prediction)\n        image = image.numpy()[0] * 0.5 + 0.5\n        image = (image * 255).astype('uint8')\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        conf *= 100\n        img_name = f'{description}, {label} ({conf:.2f}%).jpg'\n        cv2.imwrite(img_name, image)\n    ```", "```\n    def generate_adv_pattern(model,\n                             input_image,\n                             input_label,\n                             loss_function):\n        with tf.GradientTape() as tape:\n            tape.watch(input_image)\n            prediction = model(input_image)\n            loss = loss_function(input_label, prediction)\n        gradient = tape.gradient(loss, input_image)\n        signed_gradient = tf.sign(gradient)\n        return signed_gradient\n    ```", "```\n    pretrained_model = NASNetMobile(include_top=True,\n                                    weights='imagenet')\n    pretrained_model.trainable = False\n    ```", "```\n    image = tf.io.read_file('dog.jpg')\n    image = tf.image.decode_jpeg(image)\n    image = preprocess(image, pretrained_model.input.shape[1:-1])\n    image_probabilities = pretrained_model.predict(image)    \n    ```", "```\n    cce_loss = CategoricalCrossentropy()\n    pug_index = 254\n    label = tf.one_hot(pug_index, image_probabilities.shape[-1])\n    label = tf.reshape(label, (1, image_probabilities.shape[-1]))\n    disturbances = generate_adv_pattern(pretrained_model,\n                                        image,\n                                        label,\n                                        cce_loss)\n    ```", "```\n    for epsilon in [0, 0.005, 0.01, 0.1, 0.15, 0.2]:\n        corrupted_image = image + epsilon * disturbances\n        corrupted_image = tf.clip_by_value(corrupted_image, -1, 1)\n        save_image(corrupted_image,\n                   pretrained_model,\n                   f'Epsilon = {epsilon:.3f}')\n    ```"]