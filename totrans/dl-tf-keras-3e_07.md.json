["```\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns \n```", "```\n((x_train, y_train), (_, _)) = tf.keras.datasets.mnist.load_data() \n```", "```\nx_train = x_train / 255.\nx_train = x_train.astype(np.float32)\nx_train = np.reshape(x_train, (x_train.shape[0], 784))\nmean = x_train.mean(axis = 1)\nx_train = x_train - mean[:,None] \n```", "```\ns, u, v = tf.linalg.svd(x_train)\ns = tf.linalg.diag(s) \n```", "```\nk = 3\npca = tf.matmul(u[:,0:k], s[0:k,0:k]) \n```", "```\nprint('original data shape',x_train.shape)\nprint('reduced data shape', pca.shape) \n```", "```\noriginal data shape (60000, 784)\nreduced data shape (60000, 3) \n```", "```\nSet = sns.color_palette(\"Set2\", 10)\ncolor_mapping = {key:value for (key,value) in enumerate(Set)}\ncolors = list(map(lambda x: color_mapping[x], y_train))\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(pca[:, 0], pca[:, 1],pca[:, 2], c=colors) \n```", "```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\npoints_n = 200\nclusters_n = 3\niteration_n = 100\nseed = 123\nnp.random.seed(seed)\ntf.random.set_seed(seed) \n```", "```\npoints = np.random.uniform(0, 10, (points_n, 2))\ncentroids = tf.slice(tf.random.shuffle(points), [0, 0], [clusters_n, -1]) \n```", "```\nplt.scatter(points[:, 0], points[:, 1], s=50, alpha=0.5)\nplt.plot(centroids[:, 0], centroids[:, 1], 'kx', markersize=15)\nplt.show() \n```", "```\ndef closest_centroids(points, centroids):\n    distances = tf.reduce_sum(tf.square(tf.subtract(points, centroids[:,None])), 2)\n    assignments = tf.argmin(distances, 0)\n    return assignments \n```", "```\ndef move_centroids(points, closest, centroids):\n    return np.array([points[closest==k].mean(axis=0) for k in range(centroids.shape[0])]) \n```", "```\nfor step in range(iteration_n):\n    closest = closest_centroids(points, centroids)\n    centroids = move_centroids(points, closest, centroids) \n```", "```\nplt.scatter(points[:, 0], points[:, 1], c=closest, s=50, alpha=0.5)\nplt.plot(centroids[:, 0], centroids[:, 1], 'kx', markersize=15)\nplt.show() \n```", "```\ndef sse(points, centroids):\n    sse1 = tf.reduce_sum(tf.square(tf.subtract(points, centroids[:,None])), 2).numpy()\n    s = np.argmin(sse1, 0)\n    distance = 0\n    for i in range(len(points)):\n      distance += sse1[s[i], i]\n    return distance/len(points) \n```", "```\nw_sse = []\nfor n in range(1, 11):\n  centroids = tf.slice(tf.random.shuffle(points), [0, 0], [n, -1])\n  for step in range(iteration_n):\n    closest = closest_centroids(points, centroids)\n    centroids = move_centroids(points, closest, centroids)\n  #print(sse(points, centroids))\n  w_sse.append(sse(points, centroids))\nplt.plot(range(1, 11),w_sse) \nplt.xlabel('Number of clusters') \n```", "```\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt \n```", "```\n# Define the Winner Take All units\nclass WTU(object):\n  #_learned = False\n  def __init__(self, m, n, dim, num_iterations, eta = 0.5, sigma = None):\n    \"\"\"\n    m x n : The dimension of 2D lattice in which neurons are arranged\n    dim : Dimension of input training data\n    num_iterations: Total number of training iterations\n    eta : Learning rate\n    sigma: The radius of neighbourhood function.\n    \"\"\"\n    self._m = m\n    self._n = n\n    self._neighbourhood = []\n    self._topography = []\n    self._num_iterations = int(num_iterations)\n    self._learned = False\n    self.dim = dim\n    self.eta = float(eta)\n\n    if sigma is None:\n      sigma = max(m,n)/2.0 # Constant radius\n    else:\n      sigma = float(sigma)\n    self.sigma = sigma\n\n    print('Network created with dimensions',m,n)\n\n    # Weight Matrix and the topography of neurons\n    self._W = tf.random.normal([m*n, dim], seed = 0)\n    self._topography = np.array(list(self._neuron_location(m, n))) \n```", "```\ndef training(self,x, i):\n    m = self._m\n    n= self._n\n\n    # Finding the Winner and its location\n    d = tf.sqrt(tf.reduce_sum(tf.pow(self._W - tf.stack([x for i in range(m*n)]),2),1))\n    self.WTU_idx = tf.argmin(d,0)\n\n    slice_start = tf.pad(tf.reshape(self.WTU_idx, [1]),np.array([[0,1]]))\n    self.WTU_loc = tf.reshape(tf.slice(self._topography, slice_start,[1,2]), [2])\n\n    # Change learning rate and radius as a function of iterations\n    learning_rate = 1 - i/self._num_iterations\n    _eta_new = self.eta * learning_rate\n    _sigma_new = self.sigma * learning_rate\n\n    # Calculating Neighbourhood function\n    distance_square = tf.reduce_sum(tf.pow(tf.subtract(\n        self._topography, tf.stack([self.WTU_loc for i in range(m * n)])), 2), 1)\n    neighbourhood_func = tf.exp(tf.negative(tf.math.divide(tf.cast(\ndistance_square, \"float32\"), tf.pow(_sigma_new, 2))))\n\n    # multiply learning rate with neighbourhood func\n    eta_into_Gamma = tf.multiply(_eta_new, neighbourhood_func)\n\n    # Shape it so that it can be multiplied to calculate dW\n    weight_multiplier = tf.stack([tf.tile(tf.slice(\n        eta_into_Gamma, np.array([i]), np.array([1])), [self.dim])\n        for i in range(m * n)])\n    delta_W = tf.multiply(weight_multiplier,\n        tf.subtract(tf.stack([x for i in range(m * n)]),self._W))\n    new_W = self._W + delta_W\n    self._W = new_W \n```", "```\ndef fit(self, X):\n    \"\"\"\n    Function to carry out training\n    \"\"\"\n    for i in range(self._num_iterations):\n        for x in X:\n            self.training(x,i)\n    # Store a centroid grid for easy retrieval\n    centroid_grid = [[] for i in range(self._m)]\n    self._Wts = list(self._W)\n    self._locations = list(self._topography)\n    for i, loc in enumerate(self._locations):\n        centroid_grid[loc[0]].append(self._Wts[i])\n    self._centroid_grid = centroid_grid\n    self._learned = True \n```", "```\ndef winner(self, x):\n    idx = self.WTU_idx,self.WTU_loc\n    return idx\n\ndef _neuron_location(self,m,n):\n    \"\"\"\n    Function to generate the 2D lattice of neurons\n    \"\"\"\n    for i in range(m):\n       for j in range(n):\n          yield np.array([i,j])\ndef get_centroids(self):\n    \"\"\"\n    Function to return a list of 'm' lists, with each inner list containing the 'n' corresponding centroid locations as 1-D NumPy arrays.\n    \"\"\"\n    if not self._learned:\n       raise ValueError(\"SOM not trained yet\")\n    return self._centroid_grid\ndef map_vects(self, X):\n    \"\"\"\n    Function to map each input vector to the relevant neuron in the lattice\n    \"\"\"\n    if not self._learned:\n       raise ValueError(\"SOM not trained yet\")\n       to_return = []\n       for vect in X:\n          min_index = min([i for i in range(len(self._Wts))],\n                           key=lambda x: np.linalg.norm(vect -\n                           self._Wts[x]))\n          to_return.append(self._locations[min_index])\n       return to_return \n```", "```\ndef normalize(df):\n    result = df.copy()\n    for feature_name in df.columns:\n        max_value = df[feature_name].max()\n        min_value = df[feature_name].min()\n        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n    return result.astype(np.float32) \n```", "```\n## Reading input data from file\nimport pandas as pd\ndf = pd.read_csv('colors.csv')  # The last column of data file is a label\ndata = normalize(df[['R', 'G', 'B']]).values\nname = df['Color-Name'].values\nn_dim = len(df.columns) - 1\n# Data for Training\ncolors = data\ncolor_names = name \n```", "```\nsom = WTU(30, 30, n_dim, 400, sigma=10.0)\nsom.fit(colors) \n```", "```\n# Get output grid\nimage_grid = som.get_centroids()\n# Map colours to their closest neurons\nmapped = som.map_vects(colors)\n# Plot\nplt.imshow(image_grid)\nplt.title('Color Grid SOM')\nfor i, m in enumerate(mapped):\n    plt.text(m[1], m[0], color_names[i], ha='center', va='center',\n             bbox=dict(facecolor='white', alpha=0.5, lw=0)) \n```", "```\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt \n```", "```\n#Class that defines the behavior of the RBM\nclass RBM(object):\n\n    def __init__(self, input_size, output_size, lr=1.0, batchsize=100):\n        \"\"\"\n        m: Number of neurons in visible layer\n        n: number of neurons in hidden layer\n        \"\"\"\n        # Defining the hyperparameters\n        self._input_size = input_size # Size of Visible\n        self._output_size = output_size # Size of outp\n        self.learning_rate = lr # The step used in gradient descent\n        self.batchsize = batchsize         # The size of how much data will be used for training per sub iteration\n\n        # Initializing weights and biases as matrices full of zeroes\n        self.w = tf.zeros([input_size, output_size], np.float32) # Creates and initializes the weights with 0\n        self.hb = tf.zeros([output_size], np.float32) # Creates and initializes the hidden biases with 0\n        self.vb = tf.zeros([input_size], np.float32) # Creates and initializes the visible biases with 0 \n```", "```\n # Forward Pass\n    def prob_h_given_v(self, visible, w, hb):\n        # Sigmoid \n        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n    # Backward Pass\n    def prob_v_given_h(self, hidden, w, vb):\n        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb) \n```", "```\n # Generate the sample probability\n    def sample_prob(self, probs):\n        return tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs)))) \n```", "```\ndef rbm_reconstruct(self,X):\n    h = tf.nn.sigmoid(tf.matmul(X, self.w) + self.hb)\n    reconstruct = tf.nn.sigmoid(tf.matmul(h, tf.transpose(self.w)) + self.vb)\n    return reconstruct \n```", "```\n# Training method for the model\ndef train(self, X, epochs=10):\n\n    loss = []\n    for epoch in range(epochs):\n        #For each step/batch\n        for start, end in zip(range(0, len(X), self.batchsize),range(self.batchsize,len(X), self.batchsize)):\n            batch = X[start:end]\n\n            #Initialize with sample probabilities\n\n            h0 = self.sample_prob(self.prob_h_given_v(batch, self.w, self.hb))\n            v1 = self.sample_prob(self.prob_v_given_h(h0, self.w, self.vb))\n            h1 = self.prob_h_given_v(v1, self.w, self.hb)\n\n            #Create the Gradients\n            positive_grad = tf.matmul(tf.transpose(batch), h0)\n            negative_grad = tf.matmul(tf.transpose(v1), h1)\n\n            #Update learning rates \n            self.w = self.w + self.learning_rate *(positive_grad - negative_grad) / tf.dtypes.cast(tf.shape(batch)[0],tf.float32)\n            self.vb = self.vb +  self.learning_rate * tf.reduce_mean(batch - v1, 0)\n            self.hb = self.hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n\n        #Find the error rate\n        err = tf.reduce_mean(tf.square(batch - v1))\n        print ('Epoch: %d' % epoch,'reconstruction error: %f' % err)\n        loss.append(err)\n\n    return loss \n```", "```\n(train_data, _), (test_data, _) =  tf.keras.datasets.mnist.load_data()\ntrain_data = train_data/np.float32(255)\ntrain_data = np.reshape(train_data, (train_data.shape[0], 784))\ntest_data = test_data/np.float32(255)\ntest_data = np.reshape(test_data, (test_data.shape[0], 784))\n#Size of inputs is the number of inputs in the training set\ninput_size = train_data.shape[1]\nrbm = RBM(input_size, 200)\nerr = rbm.train(train_data,50) \n```", "```\nplt.plot(err)\nplt.xlabel('epochs')\nplt.ylabel('cost') \n```", "```\nout = rbm.rbm_reconstruct(test_data)\n# Plotting original and reconstructed images\nrow, col = 2, 8\nidx = np.random.randint(0, 100, row * col // 2)\nf, axarr = plt.subplots(row, col, sharex=True, sharey=True, figsize=(20,4))\nfor fig, row in zip([test_data,out], axarr):\n    for i,ax in zip(idx,row):\n        ax.imshow(tf.reshape(fig[i],[28, 28]), cmap='Greys_r')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False) \n```", "```\n #Create expected output for our DBN\n    def rbm_output(self, X):\n        out = tf.nn.sigmoid(tf.matmul(X, self.w) + self.hb)\n        return out \n```", "```\nRBM_hidden_sizes = [500, 200 , 50 ] #create 2 layers of RBM with size 400 and 100\n#Since we are training, set input as training data\ninpX = train_data\n#Create list to hold our RBMs\nrbm_list = []\n#Size of inputs is the number of inputs in the training set\ninput_size = train_data.shape[1]\n#For each RBM we want to generate\nfor i, size in enumerate(RBM_hidden_sizes):\n    print ('RBM: ',i,' ',input_size,'->', size)\n    rbm_list.append(RBM(input_size, size))\n    input_size = size \n```", "```\n---------------------------------------------------------------------\nRBM:  0   784 -> 500\nRBM:  1   500 -> 200\nRBM:  2   200 -> 50 \n```", "```\n#For each RBM in our list\nfor rbm in rbm_list:\n    print ('Next RBM:')\n    #Train a new one\n    rbm.train(tf.cast(inpX,tf.float32))\n    #Return the output layer\n    inpX = rbm.rbm_output(inpX) \n```"]