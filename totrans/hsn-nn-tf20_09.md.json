["```\nimport tensorflow_datasets as tfds\n\ndataset, info = tfds.load(\"tf_flowers\", with_info=True)\nprint(info)\n```", "```\ntfds.core.DatasetInfo(\n    name='tf_flowers',\n    version=1.0.0,\n    description='A large set of images of flowers',\n    urls=['http://download.tensorflow.org/example_images/flower_photos.tgz'],\n    features=FeaturesDict({\n        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5)\n    },\n    total_num_examples=3670,\n    splits={\n        'train': <tfds.core.SplitInfo num_examples=3670>\n    },\n    supervised_keys=('image', 'label'),\n    citation='\"\"\"\n        @ONLINE {tfflowers,\n        author = \"The TensorFlow Team\",\n        title = \"Flowers\",\n        month = \"jan\",\n        year = \"2019\",\n        url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\n\n    \"\"\"',\n    redistribution_info=,\n)\n```", "```\ndataset = dataset[\"train\"]\ntot = 3670\n\ntrain_set_size = tot // 2\nvalidation_set_size = tot - train_set_size - train_set_size // 2\ntest_set_size = tot - train_set_size - validation_set_size\n\nprint(\"train set size: \", train_set_size)\nprint(\"validation set size: \", validation_set_size)\nprint(\"test set size: \", test_set_size)\n\ntrain, test, validation = (\n    dataset.take(train_set_size),\n    dataset.skip(train_set_size).take(validation_set_size),\n    dataset.skip(train_set_size + validation_set_size).take(test_set_size),\n)\n```", "```\npip install tensorflow-hub>0.3\n```", "```\ndef to_float_image(example):\n    example[\"image\"] = tf.image.convert_image_dtype(example[\"image\"], tf.float32)\n    return example\n```", "```\ndef resize(example):\n    example[\"image\"] = tf.image.resize(example[\"image\"], (299, 299))\n    return example\n```", "```\ntrain = train.map(to_float_image).map(resize)\nvalidation = validation.map(to_float_image).map(resize)\ntest = test.map(to_float_image).map(resize)\n```", "```\nimport tensorflow_hub as hub\n\nhub.KerasLayer(\n    \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/2\",\n    output_shape=[2048],\n    trainable=False)\n```", "```\nnum_classes = 5\n\nmodel = tf.keras.Sequential(\n    [\n        hub.KerasLayer(\n            \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/2\",\n            output_shape=[2048],\n            trainable=False,\n        ),\n        tf.keras.layers.Dense(512),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Dense(num_classes), # linear\n    ]\n)\n```", "```\nimport os\nos.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"1\"\n```", "```\n# Training utilities\nloss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\nstep = tf.Variable(1, name=\"global_step\", trainable=False)\noptimizer = tf.optimizers.Adam(1e-3)\n\ntrain_summary_writer = tf.summary.create_file_writer(\"./log/transfer/train\")\nvalidation_summary_writer = tf.summary.create_file_writer(\"./log/transfer/validation\")\n\n# Metrics\naccuracy = tf.metrics.Accuracy()\nmean_loss = tf.metrics.Mean(name=\"loss\")\n\n@tf.function\ndef train_step(inputs, labels):\n    with tf.GradientTape() as tape:\n        logits = model(inputs)\n        loss_value = loss(labels, logits)\n\n    gradients = tape.gradient(loss_value, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    step.assign_add(1)\n\n    accuracy.update_state(labels, tf.argmax(logits, -1))\n    return loss_value\n\n# Configure the training set to use batches and prefetch\ntrain = train.batch(32).prefetch(1)\nvalidation = validation.batch(32).prefetch(1)\ntest = test.batch(32).prefetch(1)\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n\n    for example in train:\n        image, label = example[\"image\"], example[\"label\"]\n        loss_value = train_step(image, label)\n        mean_loss.update_state(loss_value)\n\n        if tf.equal(tf.math.mod(step, 10), 0):\n            tf.print(\n                step, \" loss: \", mean_loss.result(), \" acccuracy: \", accuracy.result()\n            )\n            mean_loss.reset_states()\n            accuracy.reset_states()\n\n    # Epoch ended, measure performance on validation set\n    tf.print(\"## VALIDATION - \", epoch)\n    accuracy.reset_states()\n    for example in validation:\n        image, label = example[\"image\"], example[\"label\"]\n        logits = model(image)\n        accuracy.update_state(label, tf.argmax(logits, -1))\n    tf.print(\"accuracy: \", accuracy.result())\n    accuracy.reset_states()\n```", "```\n10 loss: 1.15977693 acccuracy: 0.527777791\n20 loss: 0.626715124 acccuracy: 0.75\n30 loss: 0.538604617 acccuracy: 0.8125\n40 loss: 0.450686693 acccuracy: 0.834375\n50 loss: 0.56412369 acccuracy: 0.828125\n## VALIDATION - 0\naccuracy: 0.872410059\n\n[...]\n\n530 loss: 0.0310602095 acccuracy: 0.986607134\n540 loss: 0.0334353112 acccuracy: 0.990625\n550 loss: 0.029923955 acccuracy: 0.9875\n560 loss: 0.0309863128 acccuracy: 1\n570 loss: 0.0372043774 acccuracy: 0.984375\n580 loss: 0.0412098244 acccuracy: 0.99375\n## VALIDATION - 9\naccuracy: 0.866957486\n```", "```\nfrom time import time\n\n# [...]\nfor epoch in range(num_epochs):\n    start = time()\n    for example in train:\n        image, label = example[\"image\"], example[\"label\"]\n        loss_value = train_step(image, label)\n        mean_loss.update_state(loss_value)\n\n        if tf.equal(tf.math.mod(step, 10), 0):\n            tf.print(\n                step, \" loss: \", mean_loss.result(), \" acccuracy: \", accuracy.result()\n            )\n            mean_loss.reset_states()\n            accuracy.reset_states()\n    end = time()\n    print(\"Time per epoch: \", end-start)\n# remeaning code\n```", "```\nTime per epoch: 16.206\n```", "```\nhub.KerasLayer(\n    \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/2\",\n    output_shape=[2048],\n    trainable=True) # <- That's all!\n```", "```\noptimizer = tf.optimizers.Adam(1e-5)\n# [ ... ]\nmodel = tf.keras.Sequential(\n    [\n        hub.KerasLayer(\n            \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/2\",\n            output_shape=[2048],\n            trainable=True, # <- enables fine tuning\n        ),\n        tf.keras.layers.Dense(512),\n        tf.keras.layers.ReLU(),\n        tf.keras.layers.Dense(num_classes), # linear\n    ]\n)\n\n# [ ... ]\n# Same training loop\n```", "```\n10 loss: 1.59038031 acccuracy: 0.288194448\n20 loss: 1.25725865 acccuracy: 0.55625\n30 loss: 0.932323813 acccuracy: 0.721875\n40 loss: 0.63251847 acccuracy: 0.81875\n50 loss: 0.498087496 acccuracy: 0.84375\n## VALIDATION - 0\naccuracy: 0.872410059\n\n[...]\n\n530 loss: 0.000400377758 acccuracy: 1\n540 loss: 0.000466914673 acccuracy: 1\n550 loss: 0.000909397728 acccuracy: 1\n560 loss: 0.000376881275 acccuracy: 1\n570 loss: 0.000533850689 acccuracy: 1\n580 loss: 0.000438459858 acccuracy: 1\n## VALIDATION - 9\naccuracy: 0.925845146\n\n```"]