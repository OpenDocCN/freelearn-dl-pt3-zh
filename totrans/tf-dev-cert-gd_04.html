<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer070">
<h1 class="chapter-number" id="_idParaDest-75"><a id="_idTextAnchor085"/>4</h1>
<h1 id="_idParaDest-76"><a id="_idTextAnchor086"/>Classification with TensorFlow</h1>
<p>In the last chapter, we covered linear regression with TensorFlow, where we looked at both simple and multiple linear regression; we also explored various metrics for evaluating regression models. We concluded the chapter with a real-world use case, where we built a salary prediction model, and we used this to predict the salaries of new employees based on a set of features. In this chapter, we will continue with modeling in TensorFlow – this time, by exploring classification problems <span class="No-Break">with TensorFlow.</span></p>
<p>We will start by looking at the concept of classification modeling, after which we will examine the various evaluation metrics for classification modeling and how we can apply them to various use cases. We will look at binary, multi-class, and multi-label classification modeling. Finally, we will walk through a case study, putting all we have learned into practice by building a binary classification model to predict whether a student will drop out of university <span class="No-Break">or not.</span></p>
<p>By the end of this chapter, you should clearly understand what classification modeling in machine learning is and also be able to differentiate between binary, multi-class, and multi-label classification problems. You will be familiar with how to build, compile, train, predict, and evaluate <span class="No-Break">classification models.</span></p>
<p>In this chapter, we’ll cover the <span class="No-Break">following topics:</span></p>
<ul>
<li>Classification <span class="No-Break">with TensorFlow</span></li>
<li>A student <span class="No-Break">dropout prediction</span></li>
</ul>
<h1 id="_idParaDest-77"><a id="_idTextAnchor087"/>Technical requirements</h1>
<p>In this chapter, we will use Google Colab to run the coding exercise, and you will need to install Python &gt;= 3.8.0, along with the following packages, which can be installed using the <strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install</strong></span><span class="No-Break"> command:</span></p>
<ul>
<li><strong class="source-inline">tensorflow &gt;= </strong><span class="No-Break"><strong class="source-inline">2.7.0</strong></span></li>
<li><strong class="source-inline">tensorflow-datasets == </strong><span class="No-Break"><strong class="source-inline">4.4.0</strong></span></li>
<li><strong class="source-inline">Pillow == </strong><span class="No-Break"><strong class="source-inline">8.4.0</strong></span></li>
<li><strong class="source-inline">pandas == </strong><span class="No-Break"><strong class="source-inline">1.3.4</strong></span></li>
<li><strong class="source-inline">numpy == </strong><span class="No-Break"><strong class="source-inline">1.21.4</strong></span></li>
<li><strong class="source-inline">scipy == </strong><span class="No-Break"><strong class="source-inline">1.7.3</strong></span></li>
</ul>
<p>The code bundle for this book is available at the following GitHub link: <a href="https://github.com/PacktPublishing/TensorFlow-Developer-Certificate">https://github.com/PacktPublishing/TensorFlow-Developer-Certificate</a>. Solutions to all the exercises can also be found at <span class="No-Break">this link.</span></p>
<h1 id="_idParaDest-78"><a id="_idTextAnchor088"/>Classification with TensorFlow</h1>
<p>In <a href="B18118_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introduction to Machine Learning</em>, we talked about supervised learning and briefly<a id="_idIndexMarker177"/> talked about classification modeling. Classification<a id="_idIndexMarker178"/> modeling involves predicting classes in our target variable. When the classes we try to predict are binary (for example, trying to predict whether a pet is either a dog or a cat, whether an email is spam or not, or whether a patient has cancer or not), this type of classification scenario is referred <a id="_idIndexMarker179"/>to as <span class="No-Break"><strong class="bold">binary classification</strong></span><span class="No-Break">.</span></p>
<p>Then again, we may be faced with a problem where we want to build an ML model to predict the different breeds of dogs. In this case, we have more than two classes, so this type of classification <a id="_idIndexMarker180"/>is called <strong class="bold">multi-class classification</strong>. Just like binary classification problems, in multi-class classification, our target variable can only belong to one class out of multiple classes – our model will select either a bulldog, a German shepherd, or a pit bull. Here, the classes are <span class="No-Break"><em class="italic">mutually exclusive</em></span><span class="No-Break">.</span></p>
<p>Imagine that you are building a movie classifier, and you want to classifier a blockbuster movie such as <em class="italic">Avengers: Endgame</em>. This movie belongs to the action, adventure, superhero, epic, fantasy, and science fiction genres. From the movie’s label, we can see that our target variable belongs to more than one genre; hence, this type of classification<a id="_idIndexMarker181"/> is called <strong class="bold">multi-label classification</strong>, where the output class has more than one <span class="No-Break">target label.</span></p>
<p>Unlike in multi-class classification, where each example can only belong to one class, in multi-label classification, each example can belong to <span class="No-Break">multiple labels.</span></p>
<p>Unlike binary and multi-class, where each example can only belong to one class, in multi-label classification, each example can belong to multiple classes, just like the <em class="italic">Avengers</em> movie. Now that we have looked at the three main types of classification problems, the<a id="_idIndexMarker182"/> next <a id="_idIndexMarker183"/>question is, how do we evaluate classification models? What are the key metrics we need to look out for? Let us look at this now and understand what they mean and how to best apply them to various <span class="No-Break">classification problems.</span></p>
<h2 id="_idParaDest-79"><a id="_idTextAnchor089"/>Evaluating classification models</h2>
<p>Unlike regression <a id="_idIndexMarker184"/>problems, where we have numeric values in our target variable, in classification modeling, we have established that our output is classes. Hence, we cannot use the same metrics we used to evaluate our regression models in <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Linear Regression with TensorFlow</em>, since our output is not continuous numerical values but classes. For a classification problem, let’s say we build a spam filtering system to classify a client’s emails. The client has 250 emails that are not spam and another 250 emails that are spam. Using our spam filtering model, we are able to correctly flag 230 spam messages and also correctly identify 220 non-spam messages as <span class="No-Break">not spam.</span></p>
<p>When our spam filter correctly identifies a spam message as spam (which is what we want), we call <a id="_idIndexMarker185"/>this a <strong class="bold">true positive</strong>, and when the model misclassifies a spam message as not spam, this is<a id="_idIndexMarker186"/> called a <strong class="bold">false negative</strong>. In a case where the model correctly identifies a non-spam email as not spam, this is called a <strong class="bold">true negative</strong>; however, we <a id="_idIndexMarker187"/>occasionally find important emails in our spam folder, and these messages were wrongly filtered as spam when they were not. This scenario is<a id="_idIndexMarker188"/> called a <strong class="bold">false positive</strong>. We can now use these details to evaluate the performance of our <span class="No-Break">spam-filtering model.</span></p>
<p>Let us list the important details we<a id="_idTextAnchor090"/> <span class="No-Break">now know:</span></p>
<ul>
<li><strong class="bold">Total spam messages</strong>: <span class="No-Break">250 samples</span></li>
<li><strong class="bold">Correctly predicted spam messages (true positives)</strong>: <span class="No-Break">230 samples</span></li>
<li><strong class="bold">Wrongly predicted spam messages (false negatives or a type 2 error)</strong>: <span class="No-Break">20 samples</span></li>
<li><strong class="bold">Total non-spam messages</strong>: <span class="No-Break">250 samples</span></li>
<li><strong class="bold">Correctly predicted non-spam messages (true negatives)</strong>: <span class="No-Break">220 samples</span></li>
<li><strong class="bold">Wrongly predicted spam messages (false positive or a type 1 error)</strong>: <span class="No-Break">30 samples</span></li>
</ul>
<p>Now that we <a id="_idIndexMarker189"/>have gathered the key details, let us now use them to learn how to evaluate classification models. To do this, we will have to talk about the confusion <span class="No-Break">matrix next.</span></p>
<h2 id="_idParaDest-80"><a id="_idTextAnchor091"/>Confusion matrix</h2>
<p>The <strong class="bold">confusion matrix</strong> is an error <a id="_idIndexMarker190"/>matrix that displays the performance<a id="_idIndexMarker191"/> of a classification model in a tabular form, containing both the true values and the predicted values, as illustrated in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<img alt="Figure 4.1 – The confusion matrix" height="565" src="image/B18118_04_001.jpg" width="1507"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – The confusion matrix</p>
<p>Using the confusion matrix, we can calculate various classification evaluation metrics such as accuracy, precision, recall, and F1 score. In the confusion matrix, we can see the predicted class at the top, showing emails predicted as spam in the first column and those predicted as not spam in the second column, while the rows show us the true values. Here, we can see in the first row the true spam class and the true not-spam class. When we put it all together, we can see the true values and the wrong prediction in a tabular fashion, which gives us a quick view of the model and its performance across both classes. Let’s use these details to compute key performance metrics for <span class="No-Break">our model.</span></p>
<p><strong class="bold">Accuracy</strong> is quite intuitive, as<a id="_idIndexMarker192"/> it is the sum of the correctly predicted labels over the total available data. We can represent this with the <span class="No-Break">following equation:</span></p>
<p><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Let’s add our values and see what our accuracy will <span class="No-Break">look like:</span></p>
<p><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">230</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">220</span><span class="_-----MathTools-_Math_Number">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">230</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">30</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">220</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Number">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0.90</span></span></p>
<p>We get an accuracy of 90%. This is potentially exciting, but let us be more realistic with our data. When it comes to spam emails, we will likely have more legitimate emails than spam emails<a id="_idIndexMarker193"/> coming<a id="_idIndexMarker194"/> into <span class="No-Break">our mailbox.</span></p>
<p>Let’s imagine we have another client, B, with 500 emails, made up of the <span class="No-Break">following details:</span></p>
<ul>
<li><strong class="bold">Total spam messages</strong>: <span class="No-Break">40 samples</span></li>
<li><strong class="bold">Correctly predicted spam messages (true positives)</strong>: <span class="No-Break">20 samples</span></li>
<li><strong class="bold">Wrongly predicted spam messages (false negatives or a type 2 error)</strong>: <span class="No-Break">20 samples</span></li>
<li><strong class="bold">Total non-spam messages</strong>: <span class="No-Break">460 samples</span></li>
<li><strong class="bold">Correctly predicted non-spam messages (true negatives)</strong>: <span class="No-Break">430 samples</span></li>
<li><strong class="bold">Wrongly predicted spam messages (false positive or a type 1 error)</strong>: <span class="No-Break">30 samples</span></li>
</ul>
<p>If we compute the accuracy for client B, <span class="No-Break">we have:</span></p>
<p><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">430</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">30</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">430</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0.90</span></span></p>
<p>Again, we arrive at an accuracy of 90 percent, yet our model could only predict 50 percent of the spam emails as spam. This shows us that accuracy may not always be the best measure, especially when we deal with a use case made up of imbalanced data such as email classification, fraud detection, or <span class="No-Break">dis<a id="_idTextAnchor092"/>ease detection.</span></p>
<p>To get a better sense of how our model is doing, we will now turn our attention to precision and recall. Referring back to <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.2</em>, the ratio of the true positive to the positive class in the ground truth is called <em class="italic">sensitivity</em> or <em class="italic">recall</em>, or the <em class="italic">true positive rate</em> in ML lingo, and it is represented by the <span class="No-Break">following equation:</span></p>
<p><span class="_-----MathTools-_Math_Variable">R</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Whereas <em class="italic">precision</em> is the ratio of the true positive to the positive class predicted by the model, and we also represent it as <span class="No-Break">an equation:</span></p>
<p><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Using client B, let us calculate our model’s performance using precision <span class="No-Break">and recall:</span></p>
<p><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">30</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0.4</span></span></p>
<p><span class="_-----MathTools-_Math_Variable">R</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">20</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0.5</span></span></p>
<p>Now, we can<a id="_idIndexMarker195"/> see how <a id="_idIndexMarker196"/>badly our model is, although it has a high accuracy on the entirety of the data. Another important metric that we will come across for classification tasks is the F1 score. The <em class="italic">F1 score</em> combines recall and precision, and we arrive at it by computing the harmonic mean of precision <span class="No-Break">and recall:</span></p>
<p><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Let us calculate the F1 score for the second <span class="No-Break">case stud<a id="_idTextAnchor093"/>y:</span></p>
<p><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.4</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.5</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">0.4</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.5</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0.44</span></span></p>
<p>From our evaluation of Client B’s emails using our spam-filtering model, we now know we need to build a more effective model, one with much better precision and recall for our target class. However, achieving high precision and recall may not always be possible. In such a scenario, we are left with a trade-off, which is known as the <em class="italic">precision/recall trade-off</em>. In the case of detecting spam emails, we know clients are unlikely to switch to a different service provider should a few spam messages find their way into their inbox; however, they will be upset if they fail to find important messages in their inbox. In this instance, we will aim to achieve a higher recall. Conversely, let’s say we build an early cancer detection system, where our focus will be on achieving high precision to minimize false positives. It is important to note that precision and recall are not mutually exclusive, and we can achieve both high precision and recall with a well-tuned model in <span class="No-Break">many instances.</span></p>
<p>We have now<a id="_idIndexMarker197"/> covered<a id="_idIndexMarker198"/> some important classification metrics. Now, let us look at a case study (a student dropout prediction) where we will build and evaluate our classification models using different modules from TensorFlow and scikit-learn. Let’s <span class="No-Break">jump in.</span></p>
<h1 id="_idParaDest-81"><a id="_idTextAnchor094"/>A student dropout prediction</h1>
<p>In <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Linear Regression with TensorFlow</em>, you began your journey using TensorFlow <a id="_idIndexMarker199"/>to build a salary prediction model. Your boss was impressed, and now that you are fully settled in the data team, your manager wants you to work with a new client. Your job is to help them build a model that will predict whether a student will drop out of university or not, as this will help them support such students, thus preventing them from dropping out of school. Your manager has given you authorization and the task is now yours. For this task, historical data was made available to you by your client. Just like in <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Linear Regression with TensorFlow</em>, you had a rewarding chat with the client, and you identified the task as a binary classification problem. Let’s open the notebook labeled <strong class="source-inline">Classification with TensorFlow</strong> from the GitHub repository and <span class="No-Break">get started.</span></p>
<h2 id="_idParaDest-82"><a id="_idTextAnchor095"/>Loading the data</h2>
<p>Let’s start by<a id="_idIndexMarker200"/> loading the historical data that we received from <span class="No-Break">our client:</span></p>
<ol>
<li>We will start by importing the TensorFlow libraries that we will use to execute <span class="No-Break">our task:</span><pre class="source-code">
# import tensorflow</pre><pre class="source-code">
import tensorflow as tf</pre><pre class="source-code">
from tensorflow import keras</pre><pre class="source-code">
from tensorflow.keras import Sequential</pre><pre class="source-code">
from tensorflow.keras.layers import Dense</pre><pre class="source-code">
print(tf.__version__)</pre></li>
</ol>
<p>After running the code, we can see the version of TensorFlow we will use. In my case, it’s 2.8.0 at the time of writing. You will most likely have a newer version, but it should work just <span class="No-Break">as well:</span></p>
<pre class="source-code">
2.8.0</pre>
<ol>
<li value="2">Then, we will <a id="_idIndexMarker201"/>import some additional libraries that will help us simplify <span class="No-Break">our workflow.</span><pre class="source-code">
#import additional libraries</pre><pre class="source-code">
import numpy as np</pre><pre class="source-code">
import pandas as pd</pre><pre class="source-code">
# For visualizations</pre><pre class="source-code">
import matplotlib.pyplot as plt</pre><pre class="source-code">
import seaborn as sns</pre><pre class="source-code">
#for splitting the data into training and test set</pre><pre class="source-code">
from sklearn.model_selection import train_test_split</pre><pre class="source-code">
# For Normalization</pre><pre class="source-code">
from sklearn.preprocessing import MinMaxScaler</pre><pre class="source-code">
# Confusion matrix</pre><pre class="source-code">
from sklearn.metrics import confusion_matrix, classification_report</pre></li>
</ol>
<p>We previously discussed most of the libraries that we will use here, except for the last line of the code block, which we will use to import the confusion matrix and classification report from the scikit-learn library. We will use these functions to evaluate our model’s performance. If you are unclear about the other libraries, refer to <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Linear Regression with TensorFlow</em>, before proceeding with this <span class="No-Break">case study.</span></p>
<ol>
<li value="3">Now that we have loaded all the necessary libraries, let us make a DataFrame for <span class="No-Break">easy processing:</span><pre class="source-code">
#Loading data from the course GitHub repository</pre><pre class="source-code">
df=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/TensorFlow-Developer-Certificate/main/Chapter%204/Students-Dropout-Prediction.csv', index_col=0)</pre><pre class="source-code">
df.head()</pre></li>
</ol>
<p>When we run the code, if everything works as expected, we should get the first five rows of <span class="No-Break">our dataset.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<img alt="Figure 4.2 – A DataFrame showing the first five rows of our dataset" height="231" src="image/B18118_04_002.jpg" width="1238"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – A DataFrame showing the first five rows of our dataset</p>
<p>From the output, we<a id="_idIndexMarker202"/> can see that our data is made up of numerical and categorical columns. Each of the rows represents a student. Upon inspection, we can see that we have 12 columns, namely, <strong class="source-inline">Student ID</strong>, <strong class="source-inline">Student Name</strong>, <strong class="source-inline">Library</strong>, <strong class="source-inline">Resources</strong>, <strong class="source-inline">Finance</strong>, <strong class="source-inline">Scholarships</strong>, <strong class="source-inline">Study Time</strong>, <strong class="source-inline">Study Group</strong>, <strong class="source-inline">GPA</strong>, <strong class="source-inline">Test</strong>, <strong class="source-inline">Assignment</strong>, and <strong class="source-inline">Graduated</strong>. To efficiently model our data, we need to do some data preparation, so let’s start with some exploratory data analysis and see what we <span class="No-Break">can find.</span></p>
<h2 id="_idParaDest-83"><a id="_idTextAnchor096"/>Exploratory data analysis</h2>
<p>Perform the<a id="_idIndexMarker203"/> following steps to explore and analyze <span class="No-Break">the data:</span></p>
<ol>
<li>We will begin the exploratory data analysis process using the <strong class="source-inline">df.info()</strong> function to check for <strong class="source-inline">NULL</strong> values as well as the data types in our dataset, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer059">
<img alt="Figure 4.3 – Information about our dataset" height="414" src="image/B18118_04_003.jpg" width="418"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Information about our dataset</p>
<p>The good news is that we have no missing values in our dataset, and yes, we will work with a much larger dataset than in our regression task. Here, we have 25,000 data points representing students’ data collected from <span class="No-Break">the university.</span></p>
<ol>
<li value="2">The next step is to drop the irrelevant columns. By inspecting the available columns, we drop the <strong class="source-inline">student ID</strong> and <strong class="source-inline">student name</strong> columns, as these columns should have no impact on whether a student will graduate or not. Let’s do that here, using the <strong class="source-inline">drop</strong> function <span class="No-Break">from pandas:</span><pre class="source-code">
df = df.drop(['Student ID', 'Student Name'], axis=1)</pre></li>
<li>Next, let us use the <strong class="source-inline">describe</strong> function to generate key statistics of our dataset, as this will give us a sense of our data, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer060">
<img alt="Figure 4.4 – The summary statistics of the numerical columns" height="355" src="image/B18118_04_004.jpg" width="446"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – The summary statistics of the numerical columns</p>
<p>From <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.4</em>, we can see that the mean GPA is <strong class="source-inline">3.00</strong>, the lowest GPA is <strong class="source-inline">1.00</strong>, and the <a id="_idIndexMarker204"/>highest GPA is <strong class="source-inline">5.00</strong>. Both the <strong class="source-inline">Tes</strong>t and <strong class="source-inline">Assignment</strong> columns have a minimum score of 5 and a maximum score of 15. However, we have no sense of the distribution of our target column, as it is a categorical column; we will fix <span class="No-Break">that shortly.</span></p>
<ol>
<li value="4">Now, let us make a histogram plot of our categorical <span class="No-Break">target variable:</span><pre class="source-code">
plt.hist(df['Graduated'])</pre><pre class="source-code">
plt.show()</pre></li>
</ol>
<p>Running this code produces the plot shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.5</em>. Here, we use <strong class="source-inline">matplotlib</strong> to plot the <strong class="source-inline">Graduated</strong> column, and we can see almost 17,500 students who successfully graduated and roughly 7,500 students who failed to graduate. Of course, it is only logical to expect a larger number of students will graduate. In ML terms, we have on our plate an unbalanced dataset. However, the good part is that we still have enough samples to train our model from the minority class. Anyway, don’t take my word for it; shortly, we will train our models after we complete the data <span class="No-Break">preparation steps.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 4.5 – Summary statistics of the numeric columns" height="248" src="image/B18118_04_005.jpg" width="399"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – Summary statistics of the numeric columns</p>
<ol>
<li value="5">There are<a id="_idIndexMarker205"/> more plots in our notebook to explore, but we will keep it simple, since our main goal in this book is to focus on building models with TensorFlow. However, let’s look at one of the very <span class="No-Break">important plots:</span><pre class="source-code">
sns.set(style="darkgrid")</pre><pre class="source-code">
tdc =sns.scatterplot(x ='Library', y ='GPA',</pre><pre class="source-code">
    data = df, hue ='Graduated')</pre><pre class="source-code">
tdc.legend(loc='center left',</pre><pre class="source-code">
    bbox_to_anchor=(1.0, 0.5), ncol=1)</pre></li>
</ol>
<p>Here, we create a scatterplot using <strong class="source-inline">seaborn</strong>, showing the <strong class="source-inline">Library</strong> column on the <em class="italic">x</em> axis and <strong class="source-inline">GPA</strong> on the <em class="italic">y</em> axis, and we use the <strong class="source-inline">Graduate</strong> column to color our data points, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<img alt="Figure 4.6 – Library versus GPA" height="267" src="image/B18118_04_006.jpg" width="494"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Library versus GPA</p>
<p>From this plot, we can see that there is a good number of students with a GPA above 3.50 who graduated. However, don’t assume that everyone above a 3.50 GPA in the <strong class="source-inline">Average</strong>, <strong class="source-inline">Good</strong>, and <strong class="source-inline">Excellent</strong> columns graduated. In fact, let’s <span class="No-Break">check this:</span></p>
<pre class="source-code">
#To get the number of students with gpa equal to or greater than 3.5 and did not graduate
len(df[(df['GPA']&gt;=3.50)&amp;(df['Graduated']=="Drop out")])</pre>
<p>When we run this code, we get the total number of students who have a GPA of 3.50 or over and dropped out. In total, we have 76 students who dropped out. Remember, our <a id="_idIndexMarker206"/>plot covers 25,000 data points, so don’t be surprised if you did not find these data points in the plot in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">.</span></p>
<p>Now, let us proceed to prepare our data <span class="No-Break">for modeling.</span></p>
<h2 id="_idParaDest-84"><a id="_idTextAnchor097"/>Data preprocessing</h2>
<p>In <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Linear Regression with TensorFlow</em>, we emphasized the need to put our data in the <a id="_idIndexMarker207"/>right form, handle missing data, drop irrelevant features, convert categorical values to numeric values, and so on. We will continue in that <span class="No-Break">spirit here:</span></p>
<ol>
<li>Let us start by converting our labels to <span class="No-Break">numerical values:</span><pre class="source-code">
#Replace the classes in the graduate column</pre><pre class="source-code">
df['Graduated'] = df['Graduated'].replace(</pre><pre class="source-code">
    ['Graduated', 'Drop out'],[1,0])</pre></li>
</ol>
<p>Here, we assign a value of <strong class="source-inline">1</strong> to students who graduated and a value of <strong class="source-inline">0</strong> to students who <span class="No-Break">dropped out.</span></p>
<ol>
<li value="2">Now, let us examine the correlation between our numerical data and our target variable using the <span class="No-Break"><strong class="source-inline">corr()</strong></span><span class="No-Break"> function:</span><pre class="source-code">
df.corr()</pre></li>
</ol>
<p>When we run the code, we get the correlation table shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<img alt="Figure 4.7 – Correlation table for our dataset" height="215" src="image/B18118_04_007.jpg" width="609"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Correlation table for our dataset</p>
<p>From the highlighted column, we can see that <strong class="source-inline">GPA</strong> has the strongest correlation with the <span class="No-Break"><strong class="source-inline">Graduated</strong></span><span class="No-Break"> column.</span></p>
<ol>
<li value="3">Now, let us convert our categorical variables to numerical values. We will stick to using dummy variables to one-hot encode our <span class="No-Break">categorical variables:</span><pre class="source-code">
#Converting categorical variables to numeric values</pre><pre class="source-code">
df = pd.get_dummies(df, drop_first=True)</pre><pre class="source-code">
df.head()</pre></li>
</ol>
<p>Here, we drop the first column to avoid the dummy variable trap. When we run the code, we get a new DataFrame, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer064">
<img alt="Figure 4.8 – A DataFrame after one-hot encoding" height="247" src="image/B18118_04_008.jpg" width="1302"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – A DataFrame after one-hot encoding</p>
<ol>
<li value="4">Now that we have the attributes in numerical form, let’s see how correlated they are with our <span class="No-Break">target variable:</span><pre class="source-code">
tagret_corr= df.corr()</pre><pre class="source-code">
tagret_corr</pre><pre class="source-code">
tagret_corr['Graduated'].sort_values(ascending=False)</pre></li>
</ol>
<p>Once we run<a id="_idIndexMarker208"/> the code, it returns the correlation of all the columns with the target variable, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.9</em>. Our initial numerical variables are still the leading <span class="No-Break">correlation values.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer065">
<img alt="Figure 4.9 – A correlation of the attributes with the target column" height="372" src="image/B18118_04_009.jpg" width="323"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – A correlation of the attributes with the target column</p>
<ol>
<li value="5">We have<a id="_idIndexMarker209"/> successfully converted our data into numerical values, so let us proceed to split the data into attributes (<strong class="source-inline">X</strong>) and a <span class="No-Break">target (</span><span class="No-Break"><strong class="source-inline">y</strong></span><span class="No-Break">):</span><pre class="source-code">
# We split the attributes and labels into X and y variables</pre><pre class="source-code">
X = df.drop("Graduated", axis=1)</pre><pre class="source-code">
y = df["Graduated"]</pre></li>
<li>Don’t forget that we need to normalize our data. So, we bring all the attributes to scale for our <span class="No-Break">modeling process:</span><pre class="source-code">
# create a scaler object</pre><pre class="source-code">
scaler = MinMaxScaler()</pre><pre class="source-code">
# fit and transform the data</pre><pre class="source-code">
X_norm = pd.DataFrame(scaler.fit_transform(X),</pre><pre class="source-code">
    columns=X.columns)</pre><pre class="source-code">
X_norm.head()</pre></li>
</ol>
<p>Again, we use <strong class="source-inline">MinMaxScaler</strong> from the scikit-learn library, after which we split our data into training and testing sets. For training, we use 80 percent of our data, and we keep 20 percent as our holdout data to test our model’s generalization capability. We set a random state to 10 to ensure that we can reproduce the same <span class="No-Break">data split:</span></p>
<pre class="source-code">
# Create training and test sets
#We set the random state to ensure reproducibility
X_train, X_test, y_train, y_test =   train_test_split(
    X_norm, test_size=0.2, random_state=10)</pre>
<p>Now we are <a id="_idIndexMarker210"/>done with data preparation, let us proceed to model building <span class="No-Break">with TensorFlow.</span></p>
<h2 id="_idParaDest-85"><a id="_idTextAnchor098"/>Model building</h2>
<p>To build our<a id="_idIndexMarker211"/> model, we will start by creating a neural network architecture; here, we will use the sequential API to define the number of layers we want to connect sequentially. As shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.10</em>, we have only the input and output layers. Unlike in <a href="B18118_03.xhtml#_idTextAnchor065"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Linear Regression with TensorFlow</em>, where we predicted numeric values, our output layer here has only one neuron because we are dealing with a binary classification problem. For the output layer, the activation function used depends on the task at hand. When we deal with a binary classification task, we typically use the <em class="italic">sigmoid activation function</em>; for multi-class classification problems, we commonly use the <em class="italic">softmax activation function</em>; and when dealing with multi-label classification, we commonly use sigmoid as our <span class="No-Break">activation function.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer066">
<img alt="Figure 4.10 – Creating a classification model in TensorFlow" height="366" src="image/B18118_04_010.jpg" width="1199"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – Creating a classification model in TensorFlow</p>
<p>Let us proceed to compile our model. We will use <em class="italic">binary cross entropy</em> for our loss function when we deal with binary classification and <em class="italic">categorical cross entropy</em> or <em class="italic">sparse categorical cross entropy</em> when we deal with multi-class classification problems. In <a href="B18118_05.xhtml#_idTextAnchor105"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Image Classification with Neural Networks</em>, our discussion will deep-dive into activation functions and more, as we continue to build our understanding<a id="_idIndexMarker212"/> and application of <span class="No-Break">neural networks:</span></p>
<pre class="source-code">
#compile the model
model1.compile(loss='binary_crossentropy',
    optimizer='adam', metrics='accuracy')</pre>
<p>Next, let us compile our model. Here, we will use accuracy as our evaluation metric. We will also look at other classification metrics, which we discussed earlier when we begin evaluating our model’s performance on test data. After we compile our model, the next step is to fit our model. In <a href="B18118_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introduction to Machine Learning</em>, we talked about training, validation, and test splits. Since we will deal with a much larger dataset, let’s use a validation set to assess our model’s performance at the end of each epoch, allowing us to monitor how our model performs on unseen data before we test it out on the hold-out test set. We set our <strong class="source-inline">validation_split</strong> argument to <strong class="source-inline">0.2</strong>; this signifies that we will use 20 percent of our training data for validation during the training process, which will run for <span class="No-Break">40 epochs:</span></p>
<pre class="source-code">
#fit the model
history1= model1.fit(X_train, y_train, epochs=40,
    validation_split=0.2)</pre>
<p>In <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.11</em>, we can see the last five epochs of our <span class="No-Break">model’s output:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer067">
<img alt="Figure 4.11 – Model training (the last five epochs)" height="237" src="image/B18118_04_011.jpg" width="1264"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – Model training (the last five epochs)</p>
<p>The model reaches a training accuracy of 99.35% and a validation accuracy of 99.33%. Using just two layers and three simple steps in less than five minutes, we have arrived at almost 100 percent accuracy on both training and validation data. These results are impressive, yes; however, it is important to know this isn’t always the case, especially when we work<a id="_idIndexMarker213"/> with more complex datasets. They may require more complex architectures and longer training times to achieve good results. We will see this in <em class="italic">Section 2</em> of this book, where we will work with images. Before we proceed to evaluate our model, let us look at our model’s architecture using the <span class="No-Break"><strong class="source-inline">summary</strong></span><span class="No-Break"> function:</span></p>
<pre class="source-code">
model1.summary()</pre>
<p>When we run this line of code, we generate the <span class="No-Break">model’s architecture:</span></p>
<pre class="source-code">
Model: "sequential"
___________________________________________________________
 Layer (type)             Output Shape              Param #
===========================================================
 dense (Dense)            (None, 16)                256
 dense_1 (Dense)          (None, 1)                 17
===========================================================
Total params: 273
Trainable params: 273
Non-trainable params: 0
__________________________________<a id="_idTextAnchor099"/>_________________________</pre>
<p>The output shape shows us that the first <strong class="source-inline">dense</strong> layer (input layer) has 16 neurons and 256 params, since we passed in 16 attributes (16 columns x 16 neurons = 256 params), while the <strong class="source-inline">dense_1</strong> layer (the output layer) has 1 neuron and 17 params (17 columns x 1 neuron = 17 params). The total params are 273 and all the params are trainable, so we have 273 here, which means there will be zero non-trainable params. Now that we are done with model <a id="_idIndexMarker214"/>building, let’s shift our attention to evaluating our model. How well will it perform on the <span class="No-Break">test data?</span></p>
<h2 id="_idParaDest-86"><a id="_idTextAnchor100"/>Classification performance evaluation</h2>
<p>To evaluate our <a id="_idIndexMarker215"/>model in TensorFlow, all we need is one line of code – using the <strong class="source-inline">evaluate</strong> function on <span class="No-Break">our model:</span></p>
<pre class="source-code">
# Evaluate the Classication model
eval_model=model1.evaluate(X_test, y_test)
eval_model</pre>
<p>We then generate our model’s performance on our <span class="No-Break">holdout data:</span></p>
<pre class="source-code">
157/157 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9944
[0.05915425345301628, 0.9944000244140625]</pre>
<p>We arrive at an accuracy of 99.44% on our test data. This is good; however, let us look at the other classification metrics we talked about earlier in <span class="No-Break">this chapter:</span></p>
<pre class="source-code">
y_pred=model1.predict(X_test).flatten()
y_pred = np.round(y_pred).astype('int')
df_predictions = pd.DataFrame(
    {'Ground_Truth': y_test, 'Model_prediction': y_pred},
    columns=[ 'Ground_Truth', 'Model_prediction'])
len(df_predictions[(df_predictions[
    'Ground_Truth']!=df_predictions['Model_prediction'])])</pre>
<p>We generate our model’s prediction on the test data. Then, we convert the probabilities using the <strong class="source-inline">np.round()</strong> function and convert the data type to integers. Then, we create a pandas DataFrame, after which we generate the number of the misclassified labels in our DataFrame. In our case, the model misclassified 28 out of 5,000 data points in our test set. Now, we will generate a confusion matrix and classification reports to evaluate <span class="No-Break">our model:</span></p>
<pre class="source-code">
#Generating the confusion matrix
eval = confusion_matrix(y_test, y_pred)
print(eval)</pre>
<p>Running this code <a id="_idIndexMarker216"/>generates the confusion matrix shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer068">
<img alt="Figure 4.12 – A confusion matrix for our student dropout model" height="454" src="image/B18118_04_012.jpg" width="589"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – A confusion matrix for our student dropout model</p>
<p>The horizontal arrows point in the direction of the true values, while the vertical arrows are in the direction of the predicted labels. Our ground truth had (5 + 3,498) = 3,503 students in the graduated class, and our model predicted (3498 + 23) = 3,521 in our graduate class. Meanwhile, in the dropout class, our model predicted (5 + 1474) = 1,479 students dropped out, as against the ground truth (1,474 + 23) = 1497. From <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.14</em>, we can see that the model wrongly predicted that 23 students who dropped out were graduates and 5 students who graduated <span class="No-Break">were dropouts.</span></p>
<p>Next, let us print out our <span class="No-Break">classification report:</span></p>
<pre class="source-code">
class_names = [ 'Drop Out', 'Graduated']
print(classification_report(y_test, y_pred,
    target_names=class_names))</pre>
<p>Now that we have printed out our classification report, as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.15</em>, we can see our model’s precision, recall, and F1 score across both classes in our dataset, as well as the macro<a id="_idIndexMarker217"/> and <span class="No-Break">weighted averages.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer069">
<img alt="Figure 4.13 – The classification report" height="197" src="image/B18118_04_013.jpg" width="578"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.13 – The classification report</p>
<p>From the highlighted details in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.13</em>, we can see the model’s precision, recall, and F1 score. We have come a long way; this is a good result. If we wish to improve our result, we can try more experiments. Also, error analysis is very useful to help us understand misclassified data. We can drill down into the misclassified students, trying to understand patterns or common characteristics in cases the model failed to predict correctly. This can lead to further insights or help us identify issues regarding our data quality, among other possibilities. However, we will not delve into error analysis here. You have done a good job and achieved good results in <span class="No-Break">both classes.</span></p>
<p>Now, let’s save the model and present it to the manager using the <span class="No-Break"><strong class="source-inline">save</strong></span><span class="No-Break"> function:</span></p>
<pre class="source-code">
#saving our model
model1.save('classification_model.h5')</pre>
<p>We have completed our task, and we have a <span class="No-Break">near-perfect model.</span></p>
<p>Now, you should be able to build a real-world classifier with TensorFlow for structured data problems, using <a id="_idIndexMarker218"/>what you learned from our case study in <span class="No-Break">this chapter.</span></p>
<h1 id="_idParaDest-87"><a id="_idTextAnchor101"/>Summary</h1>
<p>In this chapter, we discussed classification modeling and looked at the main types of classification problems. We also discussed the main types of metrics for the evaluation of classification models and how to best apply them to real-world use cases. Then, we looked at a real-world use case, where we learned how to build, compile, and train a classification model with TensorFlow for a binary <span class="No-Break">classification problem.</span></p>
<p>Finally, we learned, hands-on, how to evaluate our classification models. We have now completed the first section of this book. Get ready for the next sections, where we will see the power of TensorFlow in its full glory as we work on unstructured data (image and <span class="No-Break">text data).</span></p>
<h1 id="_idParaDest-88"><a id="_idTextAnchor102"/>Questions</h1>
<p>Let’s test what we learned in <span class="No-Break">this chapter.</span></p>
<ol>
<li>What is <span class="No-Break">classification modeling?</span></li>
<li>What is the difference between multi-class and multi-label <span class="No-Break">classification problems?</span></li>
<li>You work for a streaming company offering interesting children content. Which metrics, between precision and recall, will you focus on improving, <span class="No-Break">and why?</span></li>
<li>Your company is building a loan prediction system to offer loans to clients. Which metrics, between precision and recall, will you focus on improving, <span class="No-Break">and why?</span></li>
</ol>
<h1 id="_idParaDest-89"><a id="_idTextAnchor103"/>Further reading</h1>
<p>To learn more, you can check out the <span class="No-Break">following resources:</span></p>
<ul>
<li>Amr, T., 2020. <em class="italic">Hands-On Machine Learning with scikit-learn and Scientific Python Toolkits</em>. [S.l.]: <span class="No-Break">Packt Publishing.</span></li>
<li>Beger, A., 2016. <em class="italic">Precision-Recall Curves</em>. <em class="italic">SSRN </em><span class="No-Break"><em class="italic">Electronic Journal</em></span><span class="No-Break">.</span></li>
<li>Raschka, S. and Mirjalili, V., 2019. <em class="italic">Python Machine Learning – Third Edition</em>. <span class="No-Break">Packt Publishing.</span></li>
<li><em class="italic">TensorFlow </em><span class="No-Break"><em class="italic">guide</em></span><span class="No-Break">: </span><a href="https://www.TensorFlow.org/guide"><span class="No-Break">https://www.TensorFlow.org/guide</span></a><span class="No-Break">.</span></li>
</ul>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer071">
<h1 id="_idParaDest-90" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor104"/>Part 2 – Image Classification with TensorFlow</h1>
<p>In this part, you will learn to build both binary and multiclass image classifiers with <strong class="bold">convolutional neural networks</strong> (<strong class="bold">CNNs</strong>), understand how to improve the model’s performance by tuning the hyperparameters, and how to handle the problem of overfitting. By the end, you should be comfortable with building real world image classifiers using <span class="No-Break">transfer learning.</span></p>
<p>This section comprises the <span class="No-Break">following chapters:</span></p>
<ul>
<li><a href="B18118_05.xhtml#_idTextAnchor105"><em class="italic">Chapter 5</em></a>, <em class="italic">Image Classification With Neural Networks</em></li>
<li><a href="B18118_06.xhtml#_idTextAnchor129"><em class="italic">Chapter 6</em></a>, <em class="italic">Improving the Model</em></li>
<li><a href="B18118_07.xhtml#_idTextAnchor146"><em class="italic">Chapter 7</em></a>, <em class="italic">Image Classification with Convolutional Neural Networks</em></li>
<li><a href="B18118_08.xhtml#_idTextAnchor186"><em class="italic">Chapter 8</em></a>, <em class="italic">Handling Overfitting</em></li>
<li><a href="B18118_09.xhtml#_idTextAnchor210"><em class="italic">Chapter 9</em></a>, <em class="italic">Transfer Learning</em></li>
</ul>
</div>
<div>
<div id="_idContainer072">
</div>
</div>
<div>
<div id="_idContainer073">
</div>
</div>
<div>
<div id="_idContainer074">
</div>
</div>
<div>
<div id="_idContainer075">
</div>
</div>
<div>
<div id="_idContainer076">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer077">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer078">
</div>
</div>
<div>
<div id="_idContainer079">
</div>
</div>
<div>
<div id="_idContainer080">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer081">
</div>
</div>
</div></body></html>