- en: Assessing your AI Arsenal
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to evaluating the effectiveness of their algorithms, it is also
    important to know the techniques that attackers exploit to evade Our AI-empowered
    tools. Only in this way is it possible to gain a realistic idea of the effectiveness
    and reliability of the solutions adopted. Also, the aspects related to the scalability
    of the solutions must be taken into consideration, along with their continuous
    monitoring, in order to guarantee reliability.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: How attackers leverage **Artificial Intelligence** (**AI**) to evade **Machine
    Learning** (**ML**) anomaly detectors
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The challenges we face when implementing ML anomaly detection
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to test our solutions for data and model quality
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to ensure security and reliability of our AI solutions for cybersecurity
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's begin with learning how attackers evade ML anomaly detectors.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Evading ML detectors
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 8](18f56dc2-fd40-4669-bef1-0b594d9e1572.xhtml), *GANs *– *Attacks
    and Defenses*, we showed how to use **Generative Adversarial Networks** (**GANs**)
    to deceive detection algorithms. Now, we will see that, it is not only GANs that
    pose a threat to our AI-based cybersecurity solutions, but more generally, it
    is possible to exploit Reinforcement Learning (RL) to render our detection tools
    ineffective.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: To understand how, we need to briefly introduce the fundamental concepts of
    RL.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Understanding RL
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Compared to the various forms of AI, RL is characterized by implementing a trial
    and error fashion of automated learning. In fact, the RL algorithms adapt their
    learning processes based on the feedback obtained from the environment. This feedback
    can be positive, that is, rewards; or negative, that is, punishments. In addition,
    feedback differs according to the successes and errors of the predictions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we can say that learning takes place on the basis of rewards and
    punishments obtained by an intelligent software: as such, the intelligent software
    (also known as the **agent**) learns from the feedbacks obtained from a given
    domain contest (also known as the **environment**).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Unlike ML, in RL the learning process does not take place on the basis of a
    training dataset, but on the mutual interaction of the agent with an environment
    that models real-world use cases. Each environment, on the other hand, is characterized
    by a substantial number of parameters and information on the basis of which the
    agent learns how to achieve its goals.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: In learning how to achieve its goals, the agent receives various feedback from
    the environment in the form of rewards and punishments.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical example of a RL agent''s goal consists of learning how to find the
    solution to games, such as mazes:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6d49b53-2eaf-498e-962c-429dd599564c.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: '(Image Credits: https://commons.wikimedia.org/wiki/File:Reinforcement_learning_diagram.svg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: The environment in which the learning process takes place can be known or even
    unknown to the agent. In achieving its goals, the agent follows the learning strategy
    that maximizes rewards.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 学习过程所发生的环境可以是已知的，也可以是未知的。在实现目标时，智能体遵循最大化奖励的学习策略。
- en: These characteristics make RL particularly suitable for solving problems in
    unknown contexts, such as learning the solutions of mazes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特点使得强化学习特别适用于解决未知环境中的问题，比如学习迷宫的解决方案。
- en: In solving the maze, the agent's ultimate goal consists of reaching the exit
    as soon as possible, without knowing the maze scheme in advance, by learning the
    route based on trial and error (that is, by leveraging the feedback obtained from
    the environment).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决迷宫问题时，智能体的最终目标是尽可能快地到达出口，而事先并不知道迷宫的布局，而是通过试错法学习路线（即，借助从环境获得的反馈）。
- en: 'To summarize, RL is characterized by the following elements:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，RL（强化学习）的特点如下：
- en: One or more agents
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个智能体
- en: An environment
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个环境
- en: States (places reached by the agent)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态（智能体到达的地方）
- en: Actions (moves performed by the agent to reach the different states)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作（智能体为了到达不同状态所执行的移动）
- en: Feedback (the scores associated with specific states)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反馈（与特定状态相关的得分）
- en: Let's see how all these elements interact in the learning process.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些元素在学习过程中的相互作用。
- en: RL feedback and state transition
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习的反馈与状态转移
- en: We have said that, in RL, the learning process is guided by feedback, emulating
    a decision-making approach led by trial and error. In achieving a goal such as
    finding the exit of the maze, the agent will perform actions (moves) that are
    associated with feedback (rewards or punishments) from different environments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到，在强化学习中，学习过程是由反馈引导的，模拟了一种通过试错法进行决策的方法。在实现目标（如找到迷宫出口）时，智能体会执行与反馈（奖励或惩罚）相关的动作（移动），这些反馈来自不同的环境。
- en: The feedback is emitted based on the state assumed by the agent after each action,
    that is, the place occupied by the agent after each move. Feedback is then sent
    from the environment to the agent. As a consequence, the agent iteratively updates
    its predictions for the next states, based on the rewards received, weighing the
    subsequent action's success with probabilistic estimates. By leveraging feedback,
    the agent adapts its behavior to the environment. This adaptation occurs in the
    transition from one state to another, during which the learning process takes
    place. This transition from one state to another is also known as the **state
    transition process**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈是基于智能体在每次行动后所处的状态发出的，也就是智能体在每次移动后的所在位置。然后，反馈会从环境发送给智能体。因此，智能体会根据收到的奖励迭代地更新其对下一个状态的预测，评估后续行动的成功概率。通过利用反馈，智能体能够调整其行为以适应环境。这种适应发生在从一个状态到另一个状态的过渡中，而学习过程也正是在这一过渡过程中发生的。这种从一个状态到另一个状态的过渡也被称为**状态转移过程**。
- en: After having quickly introduced the fundamental concepts of RL, let's see how
    we can apply them to evading malware ML detectors.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在简要介绍了强化学习的基本概念后，让我们看看如何将它们应用于规避恶意软件机器学习检测器。
- en: Evading malware detectors with RL
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用强化学习规避恶意软件检测器
- en: In [Chapter 4](3311e837-18a2-4a50-8322-f7b9c12bcbc8.xhtml), *Malware Threat
    Detection*, we thoroughly analyzed the advantages deriving from the implementation
    of malware detectors using ML algorithms.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](3311e837-18a2-4a50-8322-f7b9c12bcbc8.xhtml)，*恶意软件威胁检测*，我们详细分析了使用机器学习算法实现恶意软件检测器的优势。
- en: In [Chapter 8](18f56dc2-fd40-4669-bef1-0b594d9e1572.xhtml), *GANs *– *Attacks
    and Defenses*, we also showed how it is possible to use GANs to deceive these
    detectors.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](18f56dc2-fd40-4669-bef1-0b594d9e1572.xhtml)，*GANs*–*攻击与防御*，我们还展示了如何利用GANs来欺骗这些检测器。
- en: 'We said that the attack methods based on GANs can be distinguished as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到过，基于GAN（生成对抗网络）的攻击方法可以分为以下几种：
- en: '**White-box attacks**: The attacker knows the structure of the model on which
    the detector is based, and is able to perform queries to understand how to evade
    the detector'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白盒攻击**：攻击者知道模型的结构，且能够执行查询以理解如何规避检测器。'
- en: '**Black-box attacks**: The attacker does not know the structure or the characteristics
    of the detector, but has indirect access to the underlying model in order to perform
    a model substitution'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒攻击**：攻击者不知道检测器的结构或特征，但可以间接访问底层模型以执行模型替换。'
- en: Even in the case of black-box attacks, the attacker, although not aware of the
    structure and properties of the detector, must however know the complete features
    (feature space) of the target model. Therefore, to train the substitute model
    and carry out the attack via model substitution, the attacker must be aware of
    the features that characterize the original model, and this is where RL comes
    into play.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to RL, in fact, the attacker can perform the attack despite being totally
    unaware, not only of the structure and implementation features of the model underlying
    the malware detector, but also of the detection features.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: One of the first examples of using RL to attack malware detectors was described
    in the paper entitled *Evading Machine Learning Malware Detection*, by Hyrum S.
    Anderson, Anant Kharkar, Phil Roth, and Bobby Filar, whose results were presented
    at Black Hat USA 2017, July 22–27, 2017, Las Vegas, NV, USA.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: The cited paper shows an example of a black-box attack conducted against classifiers
    using the RL, in which not only the target classifier structure, but also its
    feature space, are completely unknown to the attacker. Nonetheless, the reduced
    information available to the attacker results in a lower attack rate than black-box
    attacks with GANs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: However, the paper demonstrates the possibility of carrying out a black-box
    attack, despite having limited information, by exploiting the RL.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Black-box attacks with RL
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the paper mentioned previously, an RL model is implemented to carry out a
    black-box attack against a malware detector, with the aim of evading a static
    Windows **Portable Executable** (**PE**) malware classifier.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'The attack scenario includes the following elements:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The RL model consists of an agent and an environment.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The agent iteratively chooses an action A to execute.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each action A is associated with a change in state space S.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every change of state is associated with feedback from the environment, in the
    form of a scalar award.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The feedback and their scalar awards are then fed back to the agent. The agent
    determines his next action based on such feedback, following a strategy, that
    is, an objective function that maximizes rewards. This objective function determines
    what action to perform next.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: In particular, the set of A actions represents the corresponding set of modifications
    that can be performed on the PE format executable file, in order to deceive the
    malware classifier, while maintaining the malware's functionality.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: In relation to each action, the scalar award is evaluated by the environment
    based on the outcome returned by the malware classifier.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: The authors of the paper also developed an evasion environment malware called
    **EvadeRL **([https://github.com/drhyrum/gym-malware](https://github.com/drhyrum/gym-malware))
    and its source code is released as an open source.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: EvadeRL is based on the OpenAI Gym framework ([https://gym.openai.com/](https://gym.openai.com/))
    that offers standardized preconfigured RL environments.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'The malware evasion environment consists of the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: An initial malware sample
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A customizable antimalware engine
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each step provides the following feedback to the agent:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '**Reward**: A value of `10.0` if the malware sample passes the malware engine
    control, or `0.0` if the malware sample fails'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Observation space**: A vector of features summarizing the composition of
    the malware sample'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on this feedback, the agent chooses the next action consisting of a modification
    performed on the malware sample PE file format, which does not alter the original
    functionality of the executable.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'The representation of the malware sample inside the environment takes the form
    of a 2,350-dimensional features vector, which includes the usual PE file format
    artifacts categories, such as the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: PE header
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PE sections
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import and export tables
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ASCII strings, such as file paths, URLs, and registry keys
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each action of the agent corresponds to a change of state that represents one
    of the possible modifications of the sample malware PE file format.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: 'Having to preserve both the integrity of the PE file format and the integrity
    of the functionality of the malware, the number of possible modifications is therefore
    relatively small, and some examples include the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Adding a new function to the **Import Address Table** (**IAT**), without this
    being called by the executable
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modification of the names of the exiting sections
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding new unused sections
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extra space padding at the end of each section
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the experiment conducted by the authors of the cited paper, a gradient-boosted
    decision tree classifier, whose training was carried out with a training dataset
    of 100,000 samples (both malicious and benign), is successfully attacked, achieving
    a **Area Under the ROC curve** (**AUC**) score equal to `0.96`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Challenging ML anomaly detection
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in [Chapter 5](a6eab48a-f031-44c9-ae4a-0cfd5db2e05e.xhtml), *Network
    Anomaly Detection with AI*, one of the areas in which ML has proved particularly
    useful is that of anomaly detection. However, even in the case of anomaly detection,
    the adoption of AI-based cybersecurity solutions must be carefully evaluated in
    light of the challenges that the complexity of these solutions inevitably introduces.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: In particular, the possible negative impact, both on the business and on the
    security of the errors originating from the anomaly detection systems, induced
    by both false positives and false negatives, must be carefully evaluated.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: As we know, there is usually a trade-off between false positives and false negatives;
    therefore, attempting to reduce the number of false negatives (the number of attacks
    that go undetected), almost inevitably leads to an increase in false positives
    (the detection of false attacks).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'More often than not, the costs deriving from classification errors are relevant:
    if, in fact, a false negative (that is, an attack that went undetected) can lead
    to the compromise of the integrity of the corporate''s sensitive data (or even
    the compromise of the system). At the same time, an excessive number of false
    positives (that is, the detection of actually non-existent attacks) can determine
    the unreliability of the detection system, preventing the timely recognition of
    real attacks.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 很多时候，由分类错误带来的成本是相关的：如果一个假阴性（即未检测到的攻击）可能导致企业敏感数据的完整性遭到破坏（甚至系统本身遭到破坏）。同时，过多的假阳性（即检测到实际上不存在的攻击）可能会导致检测系统的不可靠，阻碍实时识别真正的攻击。
- en: These are some of the reasons why **pure** anomaly detection systems (that is,
    detection systems that are based solely on automated procedures), are extremely
    rare in practice.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就是为什么**纯粹**的异常检测系统（即仅基于自动化程序的检测系统）在实践中极为罕见的一些原因。
- en: Both in the cases of the anomaly detection systems, and fraud detection and
    prevention systems (see [Chapter 7](98ce7db1-f53d-47ca-b6ca-ec0e5f882566.xhtml),
    *Fraud Prevention with Cloud AI Solutions*), reliability is increased by integrating
    the automated procedures with the feedback deriving from human operators (therefore
    achieving, for example, a greater reliability of the labels associated with the
    supervised algorithms).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是异常检测系统，还是欺诈检测和预防系统（见[第七章](98ce7db1-f53d-47ca-b6ca-ec0e5f882566.xhtml)，*云AI解决方案中的欺诈预防*），通过将自动化程序与人工操作员反馈结合，可靠性得到提高（因此，例如，监督算法相关标签的可靠性得到了增强）。
- en: Another order of problems has to do with the requisite of algorithm explainability,
    since the results obtained by the algorithms are often difficult to interpret
    (not surprisingly, the ML algorithms are often treated as black boxes).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是算法可解释性的要求，因为算法得到的结果往往难以解释（不足为奇，机器学习算法常被视为黑盒）。
- en: The difficulty in interpreting the results obtained by the algorithms can result
    in overwhelming investigative activities, due to the impenetrability of the reasons
    that led the algorithms to detect certain anomalies.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于算法结果难以解释，可能导致调查活动陷入困境，因无法理解算法为何会检测到某些异常。
- en: In other words, with the inevitable opacity associated with algorithms, learning
    processes, it is often difficult to reconcile with the need to reconstruct—in
    a precise (and repeatable) way—the process that led the system to report the anomaly.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，由于算法和学习过程固有的不可理解性，往往难以与需要精确（且可重复）地重建导致系统报告异常的过程这一需求相协调。
- en: These difficulties are aggravated if we consider the substantially dynamic nature
    of the concrete reality in which the detection systems are employed (due to the
    fact that, in a constantly evolving reality, there are always new **anomalous**
    cases that have not been previously encountered).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果考虑到检测系统所使用的实际环境具有本质上的动态性质（因为在不断发展的现实中，总会有之前未遇到过的新**异常**案例），这些困难会加剧。
- en: Incident response and threat mitigation
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件响应与威胁缓解
- en: Obviously, the implementation of an anomaly detection system assumes that the
    alerts generated are properly managed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，实施异常检测系统需要假设生成的警报得到了适当管理。
- en: With incident response, we indicate the set of activities carried out after
    alerts are delivered.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 事件响应指的是警报发出后进行的一系列活动。
- en: These activities are usually managed by human operators who are specialized
    in the various sectors of competence, engaged in investigating and deepening the
    evidence associated with alerts.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些活动通常由专门从事各个领域的人工操作员管理，他们负责调查并深入分析与警报相关的证据。
- en: Given the high level of specialization required to carry out such investigations
    (just think, for example, of digital forensics activities that originate from
    the reporting of a data breach), the adoption of automated procedures are usually
    limited to supporting human operators in their specialized activities, rather
    than replacing them.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于进行此类调查所需的高度专业化（例如，数字取证活动通常来源于数据泄露报告），自动化程序的采用通常仅限于支持人工操作员的专业活动，而不是取而代之。
- en: '**Threat mitigation**, instead, involves the prevention of future attacks or
    intrusions, or the countering of ongoing attacks.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**威胁缓解**，则涉及预防未来的攻击或入侵，或反制正在进行的攻击。'
- en: Although algorithmic procedures that automatically block suspicious activities
    can be successfully implemented in threat mitigation, they can also be exploited
    by attackers (for example, think of an attacker who wants to damage the reputation
    of an e-commerce website by causing the automated block of most parts of customers'
    IP addresses by simulating a **Distributed Denial of Service** (**DDoS**) attack).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Empowering detection systems with human feedback
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From what we have seen so far, the best use of anomaly detection systems sees
    the interaction of automated procedures with the specialized activities carried
    out by human operators.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the use of the anomaly detection systems as a support tool for human
    specialists allows the mitigation of the costs deriving from false positives,
    at the same time improving the ability to reduce false negatives by exploiting
    human feedback (as in the aforementioned case of improving the reliability of
    the classification sample labels used to train supervised algorithms).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: However, this human-machine synergy presupposes that algorithms are less opaque
    and more easily interpreted by humans, therefore increasing the transparency of
    the reasons that led the algorithm to report a specific anomaly (transparency
    that must be reserved only to insiders, to prevent attackers from exploiting it
    to their advantage).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: In the same way, an anomaly detection system must be easily maintainable, both
    in the sense of quickly adapting the algorithms to the inevitable changes of context,
    and in the sense of easily correcting the algorithms' classification errors reported
    by operator feedback.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Testing for data and model quality
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen the technical difficulties that we face in the implementation
    of our detection systems.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: More generally, every time we decide to use algorithms within our cybersecurity
    solutions, we must take into account the aspects of data quality and model quality,
    in order to ensure not only the accuracy of predictions, but also their reliability.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Let's continue by analyzing the aspects concerning the data quality process.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Assessing data quality
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have repeated several times throughout the book, and particularly in [Chapter
    9](55892989-888d-4407-ac91-7f939c0802bd.xhtml), *Evaluating Algorithms*,the choice
    of algorithm is undoubtedly important, but the selection of data is even more
    crucial for the achievement of our objectives.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, it is even preferable to use more data to feed a non-optimal
    algorithm, rather than trying to optimize the algorithm.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: It is therefore particularly important to make sure that the data used is reliable,
    as well as available in sufficient quantities to train our algorithms.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: One of the tasks performed by the data quality process is therefore the verification
    of the presence of bias within the sample datasets (not to be confused with the
    bias concerning the algorithms, which is the cause of underfitting, as we saw
    in the previous chapter).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Biased datasets
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The presence of bias within the sample datasets is often the result of the selection
    methods used to gather the data (known as **selection bias**). For example, in
    the training of malware detectors, we often use samples obtained from honeypots
    within the corporate security perimeter.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的偏差通常是由于收集数据时所使用的选择方法所导致的（称为**选择偏差**）。例如，在恶意软件检测器的训练中，我们通常使用从公司安全防护圈内的蜜罐中获得的样本。
- en: 'Honeypots are effective tools for gathering security information: they unveil
    the specific risks of tailored attacks to which the organization is exposed. However,
    honeypots are unlikely to ensure that the samples collected resemble all the different
    types of malware threats in the wild. Therefore, the use of honeypots may introduce
    selection bias into training datasets.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 蜜罐是收集安全信息的有效工具：它们揭示了组织面临的定制攻击的具体风险。然而，蜜罐不太可能确保收集的样本能代表所有不同类型的实际恶意软件威胁。因此，使用蜜罐可能会在训练数据集中引入选择偏差。
- en: 'Similar considerations can be made regarding the training of anti-spam classifiers:
    the collection of samples will hardly contain all the possible cases of threats
    that make use of emails as the attack vector, as such appropriately representing
    the complete population of possible attacks.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于反垃圾邮件分类器的训练也可以做类似的考虑：收集的样本几乎不可能包含所有可能利用电子邮件作为攻击向量的威胁情况，因此难以恰当地代表所有可能的攻击种类。
- en: In this case, we may face an **exclusion bias**, meaning that some representative
    samples of the population are excluded from the datasets.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可能会遇到**排除偏差**，即某些代表性样本被从数据集中排除。
- en: One of the most effective strategies to prevent the presence of bias within
    the datasets is to limit the scope of our algorithmic detectors, specifically
    identifying the threats that we intend to manage.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 防止数据集中的偏差出现的最有效策略之一是限制我们算法检测器的范围，特别是明确识别我们打算管理的威胁。
- en: In this way, even the data samples we collect to train the algorithms will be
    selected based on the chosen use cases.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，即使是我们收集的数据样本用于训练算法，也会根据选择的使用案例来进行筛选。
- en: Unbalanced and mislabeled datasets
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不平衡和错误标注的数据集
- en: Similarly, as we saw in [Chapter 7](98ce7db1-f53d-47ca-b6ca-ec0e5f882566.xhtml),
    *Frauds Prevention with Cloud AI Solutions*, when we analyze data on credit card
    fraud, we may face strongly unbalanced data distributions, or incorrectly classified
    sample datasets, which reduce the effectiveness of supervised algorithms.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，正如我们在[第7章](98ce7db1-f53d-47ca-b6ca-ec0e5f882566.xhtml)《利用云AI解决方案预防欺诈》中看到的，当我们分析信用卡欺诈数据时，可能会面临严重不平衡的数据分布，或者样本数据集被错误分类，从而降低了监督算法的效果。
- en: We have seen how it is possible to tackle and solve the problems related to
    mislabeled datasets by exploiting the feedback obtained from human operators (even
    if this solution is often burdensome in terms of both time and specialized resources
    employed).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，通过利用人类操作员获得的反馈，如何解决与错误标注数据集相关的问题（即使这种解决方案通常在时间和专业资源方面非常繁重）。
- en: In the case of unbalanced datasets (such as credit card transactions, where
    the samples belonging to the class of legitimate transactions largely exceed the
    samples of fraud transactions), we have seen how useful it is to resort to sampling
    techniques such as the **Synthetic Minority Over-sampling Technique** (**SMOTE**).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在不平衡的数据集的情况下（例如信用卡交易，其中属于合法交易类别的样本远远多于欺诈交易的样本），我们已经看到使用诸如**合成少数类过采样技术**（**SMOTE**）等采样技术是多么有效。
- en: Missing values in datasets
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集中的缺失值
- en: One of the most frequent problems that needs to be addressed during the data
    quality process has to do with missing values ​​within datasets.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据质量处理中需要解决的最常见问题之一与数据集中的缺失值有关。
- en: This problem occurs, for example, in cases where not all the values ​​of the
    columns are present, giving rise to null fields. The presence of null fields not
    only represents a problem for relational databases, but also for many ML algorithms.
    It is therefore necessary to eliminate these null fields to allow the algorithms
    to work correctly, without incurring classification errors.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题发生在例如列中的并非所有值都存在的情况下，从而导致空字段的出现。空字段的存在不仅对关系型数据库构成问题，还对许多机器学习算法构成问题。因此，有必要删除这些空字段，以便算法能够正确运行，避免分类错误。
- en: 'Some of the most common remedies to the problem of missing values ​​include
    the practice of the following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Excluding the lines that have null fields from the dataset
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Excluding the columns that present null fields from the dataset
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing the null fields with default values ​​(for example, 0) or recalculating
    the values on the basis of other values ​​in the dataset
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these remedies has disadvantages: in general, the exclusion of rows
    and columns that have null fields can result in the loss of important information
    contained in other non-null fields of the row or column we excluded.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the insertion of predefined or recalculated data can introduce bias
    within the dataset, especially in cases where the missing values ​​are numerous.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Missing values example
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To solve the problem of missing values in datasets, the `scikit-learn` library
    provides specialized classes for the purpose.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The strategy followed by `scikit-learn` consists of the imputation of the missing
    values by inferring new values from the known part of the dataset.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'The value imputation can be of two types:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Univariate imputation
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multivariate imputation
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of univariate imputation, the `SimpleImputer` class is used. This
    allows you to replace null values with a constant value, or with a positional
    statistics metric, such as mean, median, or mode, which is calculated on the remaining
    values of the column that contains the null value.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we see the replacement of null values (encoded as
    `np.nan`) with the mean value calculated on the values belonging to the same columns
    in which the null values are found:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the case of multivariate imputation, the missing values are estimated using
    a round robin strategy that takes into consideration the remaining features.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: With the round robin strategy (iteratively performed for each feature), a feature
    column is treated as input. The missing value is then estimated by applying a
    regression function.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we use the `IterativeImputer` class available in
    the `scikit-learn` package, `sklearn.impute`, to perform the multivariate imputation
    of the missing values:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The time has come to take care of the model quality process.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Assessing model quality
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have emphasized the importance of data over algorithms, and we have seen
    which strategies to follow in the data quality process.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Once we are sure that the data is reliable and complete, we must feed it to
    the algorithms selected for the implementation of our AI solutions, submitting
    the results obtained to the model quality process.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The model quality process involves all the phases of algorithm deployment.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: In fact, it is essential to monitor the performance of our algorithms, in order
    to constantly perform the fine tuning of the hyperparameters.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: By hyperparameters, we mean all the parameters that the algorithm receives from
    the outside (that is, parameters that are not set or updated in consequence of
    the learning process), but are decided by the analyst even before starting the
    training (such as the parameter *k* of the k-means clustering algorithm, or the
    number of perceptrons to be used in multilayer perceptron classifiers).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: This is why it is important to constantly monitor the performance of the algorithms,
    in order to be able to optimize these hyperparameters.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning hyperparameters
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While fine-tuning algorithm hyperparameters, we must keep in mind that there
    is no configuration that can be used in all cases; however, we must perform optimization
    on the basis of different scenarios we face, taking into account the different
    goals we want to achieve.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: The fine tuning of hyperparameters presupposes in-depth knowledge of the algorithm
    and its characteristics, in addition to the knowledge of the application domain
    (scenarios and use cases) in which our solution is deployed.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, fine-tuning must also take into consideration the possible impact
    caused by changes in input data (as we saw in [Chapter 3](aaf59353-00b3-4625-8732-63aad02cc8e5.xhtml), *Ham
    or Spam? Detecting Email Cybersecurity Threats with AI*, with regard to phishing
    detection, the use of decision trees involves a high sensitivity, even to small
    changes in input data).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, the analyst can resort to his own experience or decide to follow
    empirical heuristics in an attempt to optimize hyperparameters.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Also in this case, the `scikit-learn` library comes to our aid by providing
    us with the `GridSearchCV` class, which helps us to compare the performances of
    different algorithms by leveraging cross validation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Model optimization with cross validation
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following example shows how to use the `GridSearchCV` class, available in
    the `sklearn.model_selection` package, to perform the hyperparameter optimization
    of a classifier using cross validation (please refer to the *Algorithms Cross
    Validation* paragraph of [Chapter 9](55892989-888d-4407-ac91-7f939c0802bd.xhtml),
    *Evaluating Algorithms*, for the explanation of cross validation).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: We use the digit sample dataset that comes with the `scikit-learn` library.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is equally divided into training subset and testing subset, using
    the `train_test_split()` method, which is assigned the `test_size=0.5` parameter.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'The different performances of the **support vector classifier** (**SVC**) are
    then compared—in consequence of fine tuning the precision and recall metrics with
    different combinations of hyperparameters (defined in the `tuned_parameters` variable)—using
    the cross validation strategy implemented by the `GridSearchCV` class:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding script generates the following output:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Our assessment continues (and concludes) with our AI-empowered cybersecurity
    solutions.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring security and reliability
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing the security and reliability of our solutions is a critical aspect,
    which can determine its success or failure, regardless of the quality of the models
    implemented.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, ensuring security and reliability of AI-empowered solutions translates
    into the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring performance and scalability
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring resilience and availability
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring confidentiality and privacy
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We begin by analyzing how the performance and scalability requisites affect
    algorithms' reliability.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring performance and scalability
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Without a doubt, the performances of AI-based cybersecurity solutions are crucial
    to guarantee their success, especially if the objective to be achieved is to detect
    intrusion attempts or security breaches as quickly as possible. This translates into
    ensuring the low latency of the responses. However, the requirement of low latency
    contrasts with the very nature of the algorithms, which usually entail high computational
    loads. Furthermore, it is often difficult to guarantee the scalability of AI solutions
    when the amount of data to be processed grows explosively (as is typical in modern
    big data scenarios).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: In order to guarantee an adequate level of performance, it is therefore necessary
    to act on the various components of the solution, starting with the choice of
    the best performing algorithms, even at the expense of precision. At the same
    time, reducing the dataset dimensionality (that is, the number and type of features
    used) can dramatically improve the performance of our algorithms.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](f467340a-244d-4714-8a39-68b230db2404.xhtml), *Securing User Authentication*,
    we saw how it is possible to reduce the dimensionality of heavy datasets (such
    as those of images), even those using simple technical expedients, such as the
    **Principal components analysis** (**PCA**).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Also, the scalability of the algorithms is an essential element to improve performances,
    especially if we intend to deploy our solutions into the cloud.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: However, not all algorithms have been designed to guarantee scalability, while
    some algorithms (such as SVMs) are by their nature less efficient, as they are
    particularly slow in the training phase and require high hardware resources (in
    terms of memory, computational load, and other aspects).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: It is therefore necessary to carefully evaluate the advantages and disadvantages
    of each algorithm (as we did in the various chapters of the book) before making
    our decisions.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring resilience and availability
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we talk about security, we do not only mean the protection from attacks
    carried out through the use of traditional measures, such as the definition of
    the network security perimeter, or the use of antivirus software.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: The requirement of security in complex contexts (such as those in which cloud
    computing is used for both the development and the deployment of solutions) translates
    into assuring the requirements of resilience and high availability.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: The same traditional security measures, starting with antiviruses, up to the
    **intrusion detection system** (**IDS**) depend more and more on AI cloud-based
    solutions to achieve their goals (just think, for example, of the malware detection
    performed by an antivirus software that exploits cloud-based neural networks to
    carry out behavioral analysis of a suspect executable).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: By now, AI permeates all the value-added services offered to clients by corporates
    that use the internet and the web in their business.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'This is even more true for the cybersecurity sector: for example, consider
    biometric procedures that all adopt some form of AI for user recognition.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: It is therefore essential to continuously monitor the health status of the systems
    on which the AI-based cybersecurity solutions are deployed.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, guaranteeing the integrity and confidentiality of the data that feeds
    the algorithms is of fundamental importance to assure not only their security,
    but also their reliability.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: An attacker who managed to access the datasets used by the algorithms, would
    not only be able to emulate the behavior of the underlying predictive models,
    but could even poison the data, therefore modifying the predictions of the algorithms
    to their liking.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: We will deal with this topic in the next section.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring confidentiality and privacy
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The centrality of data in the correct functioning of data-driven solutions is
    attested by the principle known as **garbage in**, **garbage out**. Protecting
    the integrity of data is equally important in the AI, since—unlike what is commonly
    thought—algorithms are not **objective**, but can formulate radically different
    predictions based on the data supplied to them in the training phase.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: It is therefore possible to condition the results of predictive models simply
    by altering the data on which the algorithms work.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: This aspect is particularly delicate, as it transversally raises the need to
    guarantee the security and integrity of the data, together with the explicability
    and repeatability of the results obtained by the algorithms, and can have important
    negative repercussions, especially in the context of the privacy law compliance.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: As is known, the pervasive diffusion of data-driven technologies (such as AI
    and big data analytics) that make extensive use of users' and consumers' personal
    data, poses serious problems, not only of data security, but also of protection
    of confidentiality.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: In particular, by aggregating a sufficient amount of personal data, it is possible
    to reconstruct the profile of each individual with a high degree of statistical
    verisimilitude.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: When we add the fact that most business decisions are taken on the basis of
    an automated analysis of individual profiles to this, we realize the risks that
    can arise from the incorrect profiling of individuals.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, if a financial or insurance company denies an individual the signing
    of a financial contract on the basis of incorrect profiling, the individual is
    negatively discriminated because of the inadequate treatment of their personal
    data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, if a fraud detection algorithm reports a financial transaction as
    suspect by assessing the creditworthiness of the person who executed the transaction
    on the basis of incorrect profiling, in addition to reputational damage, there
    is a risk of incurring the sanctions envisaged for the illicit treatment of personal
    data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Even more serious consequences can be determined if the data being processed
    belongs to special categories (for example, biometric data such as iris, voice,
    fingerprints, face, and DNA) that are widely used in the cybersecurity field,
    for all the purposes of authentication, authorization, and detection.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: It therefore appears evident that guaranteeing the confidentiality and integrity
    of the data is of importance, not only in terms of security, but also in terms
    of legal liabilities deriving from failing to comply with national laws protecting
    privacy.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: To this end, it is appropriate to assure the adoption of data encryption in
    AI-based solutions, making sure to apply encryption to all the different states
    that the data can assume (data **in motion**, **in use**, and **at rest**).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we dealt with the assessment of our AI-based cybersecurity
    solutions, analyzing the aspects of security, data, and model quality, in order
    to guarantee the reliability and high availability of solutions deployed in production
    environments, without neglecting the requirements of privacy and confidentiality
    of the sensitive data used by algorithms.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
