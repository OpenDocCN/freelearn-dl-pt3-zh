- en: Object Detection – CIFAR-10 Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After covering the basics and the intuition/motivation behind **Convolution
    Neural Networks** (**CNNs**), we are going to demonstrate this on one of the most
    popular datasets available for object detection. We'll also see how the initial
    layers of the CNN get very basic features about our objects, but the final convolutional
    layers will get more semantic-level features that are built up from those basic
    features in the first layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CIFAR-10 object detection in mages—model building and training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Wikipedia states that:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Object detection – technology in the field of computer vision for finding
    and identifying objects in an image or video sequence. Humans recognize a multitude
    of objects in images with little effort, despite the fact that the image of the
    objects may vary somewhat in different view points, in many different sizes and
    scales or even when they are translated or rotated. Objects can even be recognized
    when they are partially obstructed from view. This task is still a challenge for
    computer vision systems. Many approaches to the task have been implemented over
    multiple decades."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Image analysis is one of the most prominent fields in deep learning. Images
    are easy to generate and handle, and they are exactly the right type of data for
    machine learning: easy to understand for human beings, but difficult for computers.
    Not surprisingly, image analysis played a key role in the history of deep neural
    networks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d82c9b0-e87a-4f16-a94c-805efcf6f9f5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Examples of detecting objects. Source: B. C. Russell, A. Torralba,
    C. Liu, R. Fergus, W. T. Freeman, Object Detection by Scene Alignment, Advances
    in Neural Information Processing Systems, 2007, at: http://bryanrussell.org/papers/nipsDetectionBySceneAlignment07.pdf'
  prefs: []
  type: TYPE_NORMAL
- en: With the rise of autonomous cars, facial detection, smart video surveillance,
    and people-counting solutions, fast and accurate object detection systems are
    in a big demand. These systems include not only object recognition and classification
    in an image, but can also locate each one of them by drawing appropriate boxes
    around them. This makes object detection a harder task than its traditional computer
    vision predecessor, image classification.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll look at object detection — finding out which objects
    are in an image. For example, imagine a self-driving car that needs to detect
    other cars on the road as in *Figure 11.1*. There are lots of complicated algorithms
    for object detection. They often require huge datasets, very deep convolutional
    networks, and long training times.
  prefs: []
  type: TYPE_NORMAL
- en: CIFAR-10 – modeling, building, and training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This example shows how to make a CNN for classifying images in the CIFAR-10
    dataset. We'll be using a simple convolution neural network implementation of
    a couple of convolutions and fully connected layers.
  prefs: []
  type: TYPE_NORMAL
- en: Even though the network architecture is very simple, you will see how well it
    performs when trying to detect objects in the CIFAR-10 images.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's start off this implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Used packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We import all the required packages for this implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Loading the CIFAR-10 dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this implementation, we''ll use CIFAR-10, which is one of the most widely
    used datasets for object detection. So, let''s start off by defining a helper
    class to download and extract the CIFAR-10 dataset, if it''s not already downloaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After downloading and extracting the CIFAR-10 dataset, you will find out that
    it''s already split into five batches. CIFAR-10 contains images for 10 categories/classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`airplane`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`automobile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bird`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cat`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dog`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`frog`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`horse`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ship`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`truck`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we dive into building the core of the network, let's do some data analysis
    and preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis and preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to analyze the dataset and do some basic preprocessing. So, let''s
    start off by defining some helper functions that will enable us to load a specific
    batch from the five batches that we have and print some analysis about this batch
    and its samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we define a function that can help us display the stats of a specific
    sample from a specific batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use this function to play around with our dataset and visualize
    specific images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ae827baa-2394-4eaf-93cd-018a7ae7b8a1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Sample image 6 from batch 3'
  prefs: []
  type: TYPE_NORMAL
- en: Before going ahead and feeding our dataset to the model, we need to normalize
    it to the range of zero to one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Batch normalization optimizes network training. It has been shown to have several
    benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Faster training**: Each training step will be slower because of the extra
    calculations during the forward pass of the network and the additional hyperparameters
    to train during backward propagation passes of the network. However, it should
    converge much more quickly, so training should be faster overall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Higher learning rates**: The gradient descent algorithm mostly requires small
    learning rates for the network to converge to the loss function''s minima. And
    as the neural networks get deeper, their gradient values get smaller and smaller
    during backpropagation, so they usually require even more iterations. Using the
    idea of batch normalization allows us to use much higher learning rates, which
    further increases the speed at which networks train.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easy to initialize weights**: Weight initialization can be difficult, and
    it will be even more difficult if we are using deep neural networks. Batch normalization
    seems to allow us to be much less careful about choosing our initial starting
    weights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So, let''s proceed by defining a function that will be responsible for normalizing
    a list of input images so that all the pixel values of these images are between
    zero and one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Next up, we need to implement another helper function to encode the labels of
    the input image. In this function, we will use one-hot encoding of sklearn, where
    each image label is represented by a vector of zeros except for the class index
    of the image that this vector represents.
  prefs: []
  type: TYPE_NORMAL
- en: 'The size of the output vector will be dependent on the number of classes that
    we have in the dataset, which is 10 classes in the case of CIFAR-10 data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it''s time to call the preceding helper functions to do the preprocessing
    and persist the dataset so that we can use it later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: So, we have the preprocessed data saved to disk.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to load the validation set for running the trained model on it
    at different epochs of the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Building the network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's now time to build the core of our classification application, which is
    the computational graph of this CNN architecture, but to maximize the benefits
    of this implementation, we aren't going to use the TensorFlow layers API. Instead,
    we are going to use the TensorFlow neural network version of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s start off by defining the model input placeholders which will input
    the images, target classes, and the keep probability parameter of the dropout
    layer (this helps us to reduce the complexity of the architecture by dropping
    some connections and hence reducing the chances of overfitting):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to use the TensorFlow neural network implementation version
    to build up our convolution layers with max pooling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As you have probably seen in the previous chapter, the output of the max pooling
    operation is a 4D tensor, which is not compatible with the required input format
    for the fully connected layers. So, we need to implement a flattened layer to
    convert the output of the max pooling layer from 4D to 2D tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we need to define a helper function that will enable us to add a fully
    connected layer to our architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, before using these helper functions to create the entire architecture,
    we need to create another one that will take the output of the fully connected
    layer and produce 10 real-valued corresponding to the number of classes that we
    have in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'So, let''s go ahead and define the function that will put all these bits and
    pieces together and create a CNN with three convolution layers. Each one of them
    is followed by max pooling operations. We''ll also have two fully connected layers,
    where each one of them is followed by a dropout layer to reduce the model complexity
    and prevent overfitting. Finally, we''ll have the output layer to produce 10 real-valued
    vectors, where each value represents a score for each class being the correct
    one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s call the preceding helper functions to build the network and define
    its loss and optimization criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have built the computational architecture of this network, it's
    time to kick off the training process and see some results.
  prefs: []
  type: TYPE_NORMAL
- en: Model training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, let''s define a helper function that will make us able to kick off the
    training process. This function will take the input images, one-hot encoding of
    the target classes, and the keep probability value as input. Then, it will feed
    these values to the computational graph and call the model optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll need to validate our model during different time steps in the training
    process, so we are going to define a helper function that will print out the accuracy
    of the model on the validation set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also define the model hyperparameters, which we can use to tune the
    model for better performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's kick off the training process, but only for a single batch of the
    CIFAR-10 dataset, and see what the model accuracy based on this batch is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before that, however, we are going to define a helper function that will load
    a batch training and also separate the input images from the target classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s start the training process for one batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the validation accuracy is not that good while training only
    on a single batch. Let''s see how the validation accuracy is going to change based
    on only a full training process of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Testing the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s test the trained model against the test set part of the CIFAR-10 dataset.
    First, we are going to define a helper function that will help us to visualize
    the predictions of some sample images and their corresponding true labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s restore the trained model and test it against the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/fc105794-646e-4a0a-8fe0-c7c432a1ccca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s visualize another example to see some errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee5f68c7-4a4e-40f9-9009-a78465f6559e.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we have a test accuracy of around 75%, which is not bad for a simple CNN
    like the one we have used.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter showed us how to make a CNN for classifying images in the CIFAR-10
    dataset. The classification accuracy was about 79% - 80% on the test set. The
    output of the convolutional layers was also plotted, but it was difficult to see
    how the neural network recognizes and classifies the input images. Better visualization
    techniques are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Next up, we'll use one of the modern and exciting practice of deep learning,
    which is transfer learning. Transfer learning allows you to use data-greedy architectures
    of deep learning with small datasets.
  prefs: []
  type: TYPE_NORMAL
