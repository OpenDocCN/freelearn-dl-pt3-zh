["```\npip install gym[box2d]\n```", "```\ndata_transform = torchvision.transforms.Compose([\n   torchvision.transforms.ToPILImage(),\n    torchvision.transforms.Grayscale(1),\n    torchvision.transforms.Pad((12, 12, 12, 0)),\n    torchvision.transforms.CenterCrop(84),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0,), (1,)),\n])\n```", "```\ndef create_datasets():\n```", "```\n    class TensorDatasetTransforms(torch.utils.data.TensorDataset):\n        def __init__(self, x, y):\n            super().__init__(x, y)\n\n        def __getitem__(self, index):\n            tensor = data_transform(self.tensors[0][index])\n            return (tensor,) + tuple(t[index] for t in self.tensors[1:])\n```", "```\n    x, y = read_data()\n    x = np.moveaxis(x, 3, 1)  # channel first (torch requirement)\n```", "```\n    # train dataset\n    x_train = x[:int(len(x) * TRAIN_VAL_SPLIT)]\n    y_train = y[:int(len(y) * TRAIN_VAL_SPLIT)]\n\n    train_set = TensorDatasetTransforms(torch.tensor(x_train), torch.tensor(y_train))\n\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n                                               shuffle=True, num_workers=2)\n\n    # test dataset\n    x_val, y_val = x[int(len(x_train)):], y[int(len(y_train)):]\n\n    val_set = TensorDatasetTransforms(torch.tensor(x_val), torch.tensor(y_val))\n\n    val_loader = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE,\n                                             shuffle=False, num_workers=2)\n\n    return train_loader, val_loader\n```", "```\ndef build_network():\n    return torch.nn.Sequential(\n        torch.nn.Conv2d(1, 32, 8, 4),\n        torch.nn.BatchNorm2d(32),\n        torch.nn.ELU(),\n        torch.nn.Dropout2d(0.5),\n        torch.nn.Conv2d(32, 64, 4, 2),\n        torch.nn.BatchNorm2d(64),\n        torch.nn.ELU(),\n        torch.nn.Dropout2d(0.5),\n        torch.nn.Conv2d(64, 64, 3, 1),\n        torch.nn.ELU(),\n        torch.nn.Flatten(),\n        torch.nn.BatchNorm1d(64 * 7 * 7),\n        torch.nn.Dropout(),\n        torch.nn.Linear(64 * 7 * 7, 120),\n        torch.nn.ELU(),\n        torch.nn.BatchNorm1d(120),\n        torch.nn.Dropout(),\n        torch.nn.Linear(120, len(available_actions)),\n    )\n```", "```\ndef train(model: torch.nn.Module, device: torch.device):\n    loss_function = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.Adam(model.parameters())\n\n    train_loader, val_order = create_datasets()  # read datasets\n\n    # train\n    for epoch in range(EPOCHS):\n        print('Epoch {}/{}'.format(epoch + 1, EPOCHS))\n\n        train_epoch(model, device, loss_function, optimizer, train_loader)\n\n        test(model, device, loss_function, val_order)\n\n        # save model\n        model_path = os.path.join(DATA_DIR, MODEL_FILE)\n        torch.save(model.state_dict(), model_path)\n```", "```\ndef train_epoch(model, device, loss_function, optimizer, data_loader):\n    model.train() # set model to training mode\n    current_loss, current_acc = 0.0, 0.0\n\n    for i, (inputs, labels) in enumerate(data_loader):\n        inputs, labels = inputs.to(device), labels.to(device) # send to device\n\n        optimizer.zero_grad() # zero the parameter gradients\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs) # forward\n            _, predictions = torch.max(outputs, 1)\n            loss = loss_function(outputs, labels)\n\n            loss.backward() # backward\n            optimizer.step()\n\n        current_loss += loss.item() * inputs.size(0) # statistics\n        current_acc += torch.sum(predictions == labels.data)\n\n    total_loss = current_loss / len(data_loader.dataset)\n    total_acc = current_acc / len(data_loader.dataset)\n\n    print('Train Loss: {:.4f}; Accuracy: {:.4f}'.format(total_loss, total_acc))\n\n```", "```\ndef nn_agent_drive(model: torch.nn.Module, device: torch.device):\n    env = gym.make('CarRacing-v0')\n\n    global human_wants_exit  # use ESC to exit\n    human_wants_exit = False\n\n    def key_press(key, mod):\n        \"\"\"Capture ESC key\"\"\"\n        global human_wants_exit\n        if key == 0xff1b:  # escape\n            human_wants_exit = True\n\n    state = env.reset()  # initialize environment\n    env.unwrapped.viewer.window.on_key_press = key_press\n```", "```\n    while 1:\n        env.render()\n\n        state = np.moveaxis(state, 2, 0) # channel first image\n        state = torch.from_numpy(np.flip(state, axis=0).copy()) # np to tensor\n        state = data_transform(state).unsqueeze(0) # apply transformations\n        state = state.to(device) # add additional dimension\n\n        with torch.set_grad_enabled(False): # forward\n            outputs = model(state)\n\n        normalized = torch.nn.functional.softmax(outputs, dim=1)\n\n        # translate from net output to env action\n        max_action = np.argmax(normalized.cpu().numpy()[0])\n        action = available_actions[max_action]\n        action[2] = 0.3 if action[2] != 0 else 0 # adjust brake power\n\n        state, _, terminal, _ = env.step(action) # one step\n\n        if terminal:\n            state = env.reset()\n\n        if human_wants_exit:\n            env.close()\n            return\n\n```", "```\n# create cuda device\ndev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# create the network\nmodel = build_network()\n\n# if true, try to restore the network from the data file\nrestore = False\nif restore:\n    model_path = os.path.join(DATA_DIR, MODEL_FILE)\n    model.load_state_dict(torch.load(model_path))\n\n# set the model to evaluation (and not training) mode\nmodel.eval()\n\n# transfer to the gpu\nmodel = model.to(dev)\n\n# train\ntrain(model, dev)\n\n# agent play\nnn_agent_drive(model, dev)\n```"]