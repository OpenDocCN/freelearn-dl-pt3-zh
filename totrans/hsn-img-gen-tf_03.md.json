["```\ndef Encoder(z_dim):\n    inputs  = layers.Input(shape=[28,28,1])\n    x = inputs    \n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(64, activation='relu')(x)\n    x = Dense(32, activation='relu')(x)    \n    z = Dense(z_dim, activation='relu')(x)\n\n    return Model(inputs=inputs, outputs=z, name='encoder')\n```", "```\ndef Encoder(z_dim):\n    inputs  = layers.Input(shape=[28,28,1])\n    x = inputs    \n    x = Conv2D(filters=8,  kernel_size=(3,3), strides=2,  \t  \t               padding='same', activation='relu')(x)\n    x = Conv2D(filters=8,  kernel_size=(3,3), strides=1, \t \t               padding='same', activation='relu')(x)\n    x = Conv2D(filters=8,  kernel_size=(3,3), strides=2,                \t               padding='same', activation='relu')(x)\n    x = Conv2D(filters=8,  kernel_size=(3,3), strides=1, \t \t               padding='same', activation='relu')(x)\n    x = Flatten()(x)\n    out = Dense(z_dim, activation='relu')(x)\n    return Model(inputs=inputs, outputs=out, name='encoder')\n```", "```\ndef Decoder(z_dim):\n    inputs  = layers.Input(shape=[z_dim])\n    x = inputs    \n    x = Dense(7*7*64, activation='relu')(x)\n    x = Reshape((7,7,64))(x)\n    x = Conv2D(filters=64, kernel_size=(3,3), strides=1,  \t \t               padding='same', activation='relu')(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2D(filters=32, kernel_size=(3,3), strides=1, \t \t               padding='same', activation='relu')(x)\n    x = UpSampling2D((2,2))(x)    \n    x = Conv2D(filters=32, kernel_size=(3,3), strides=2, \t \t               padding='same', activation='relu')(x)\n    out = Conv2(filters=1, kernel_size=(3,3), strides=1,  \t \t                padding='same', activation='sigmoid')(x)\n    return Model(inputs=inputs, outputs=out, name='decoder') \n```", "```\nz_dim = 10\nencoder = Encoder(z_dim)\ndecoder = Decoder(z_dim) \nmodel_input = encoder.input\nmodel_output = decoder(encoder.output)\nautoencoder = Model(model_input, model_output)\n```", "```\nclass GaussianSampling(Layer):        \n    def call(self, inputs):\n        means, logvar = inputs\n        epsilon = tf.random.normal(shape=tf.shape(means), \t \t                                   mean=0., stddev=1.)\n        samples = means + tf.exp(0.5*logvar)*epsilon\n        return samples\n```", "```\nclass Encoder(Layer):\n    def __init__(self, z_dim, name='encoder'):\n        super(Encoder, self).__init__(name=name)        \n        self.features_extract = Sequential([\n            Conv2D(filters=8,  kernel_size=(3,3), strides=2,  \t                   padding='same', activation='relu'),\n            Conv2D(filters=8,  kernel_size=(3,3), strides=1, \t                   padding='same', activation='relu'),\n            Conv2D(filters=8,  kernel_size=(3,3), strides=2,  \t                   padding='same', activation='relu'),\n            Conv2D(filters=8,  kernel_size=(3,3), strides=1, \t                   padding='same', activation='relu'),\n            Flatten()])\n        self.dense_mean = Dense(z_dim, name='mean')\n        self.dense_logvar = Dense(z_dim, name='logvar')\n        self.sampler = GaussianSampling()\n```", "```\n    def call(self, inputs):\n        x = self.features_extract(inputs)\n        mean = self.dense_mean(x)\n        logvar = self.dense_logvar(x)\n        z = self.sampler([mean, logvar])\n        return z, mean, logvar\n```", "```\ndef vae_kl_loss(y_true, y_pred):\n    kl_loss =  - 0.5 * tf.reduce_mean(vae.logvar - tf.exp(vae.logvar) - tf.square(vae.mean) - + 1)\n    return kl_loss    \n```", "```\ndef vae_rc_loss(y_true, y_pred):\n    rc_loss = tf.keras.losses.MSE(y_true, y_pred)\n    return rc_loss\n```", "```\ndef vae_loss(y_true, y_pred):\n    kl_loss = vae_kl_loss(y_true, y_pred)\n    rc_loss = vae_rc_loss(y_true, y_pred)\n    kl_weight_factor = 1e-2\n    return kl_weight_factor*kl_loss + rc_loss\n```", "```\nz_samples = np.random.normal(loc=0, scale=1, size=(image_num, \n                                                        z_dim))\nimages = vae.decoder(z_samples.astype(np.float32))\n```", "```\nnew_z_samples = z_samples +  smiling_magnitude*smiling_vector\n```", "```\ndef preprocess_attrib(sample, attribute):\n    image = sample['image']\n    image = tf.image.resize(image, [112,112])\n    image = tf.cast(image, tf.float32)/255.\n    return image, sample['attributes'][attribute]\nds = ds.map(lambda x: preprocess_attrib(x, attribute))\n```", "```\ndef preprocess(x):  \n    return preprocess_attrib(x, attribute))\n```"]