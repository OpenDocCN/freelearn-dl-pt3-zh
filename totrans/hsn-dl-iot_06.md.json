["```\n# Import the required modules\nimport urllib\nfrom bs4 import BeautifulSoup\nfrom selenium import webdriver\nimport os, os.path\nimport simplejson\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n```", "```\n# Create links book for the audio data to be downloaded: this may include repeated readers\nbook_links = []\nbrowser = webdriver.PhantomJS(executable_path = '/usr/local/bin/phantomjs')\n\nfor i in range(1): ## testing first 0-1 (2) pages of the site : to minimise the time require to downloads   \n    url = (\"https://librivox.org/search?title=&author=&reader=&keywords=&genre_id=0&status=all&project_type=solo&recorded_language=&sort_order=catalog_date&search_page={}&search_form=advanced\").format(i)\n    print(url)\n    browser.get(url)\n    element = WebDriverWait(browser, 100).until(\n    EC.presence_of_element_located((By.CLASS_NAME , \"catalog-result\")))\n    html = browser.page_source\n    soup = BeautifulSoup(html, 'html.parser')\n    ul_tag = soup.find('ul', {'class': 'browse-list'})   \n    for li_tag in ul_tag.find_all('li', {'class': 'catalog-result'}):\n        result_data = li_tag.find('div', {'class': 'result-data'})\n        book_meta = result_data.find('p', {'class': 'book-meta'})\n        link = result_data.a[\"href\"]\n        print(link)\n        if str(book_meta).find(\"Complete\") and link not in book_links:\n            book_links.append(link)      \n    print(len(book_links)) # links per page could be different from regular browsers\nbrowser.quit()\n```", "```\n#  List of Links or pages for the audio books to be downloaded\nf = open('audiodownload_links.txt', 'w')\nsimplejson.dump(download_links, f)\nf.close()\n\n# Record the file size of each reader's file\nf = open('audiodownload_sizes.txt', 'w')\nsimplejson.dump(download_sizes, f)\nf.close()\n\n# Download the audio files and save them in local directory\n def count_files():\n    dir = 'audio_files_downloaded'\n    list = [file for file in os.listdir(dir) if file.endswith('.zip')] # dir is your directory path\n    number_files = len(list)\n    return number_files\ncounter = 100 # this is for naming each downloaded file\nfor link, size in zip(download_links, download_sizes):\n    if size >= 50 and size <= 100:\n        localDestination = 'audio_files_downloaded/audio{}.zip'.format(counter)\n        resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n        counter += 1\ncnt2 =  0\nnum = count_files()\nif num < 200:\n    for link, size in zip(download_links, download_sizes):\n        if size > 100 and size <= 150:\n            localDestination = 'audio_files_downloaded/audio{}.zip'.format(counter)\n            resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n            counter += 1\n        cnt2 += 1\nnum = count_files()\nif num < 200:\n    for link, size in zip(download_links, download_sizes):        if size > 150 and size <= 200:\n            localDestination = 'audio_files_downloaded/audio{}.zip'.format(counter)\n            resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n            counter += 1\nnum = count_files()\nif num < 200:\n    for link, size in zip(download_links, download_sizes):\n        if size > 200 and size <= 250:\n            localDestination = 'audio_files_downloaded/audio{}.zip'.format(counter)\n            resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n            counter += 1\nnum = count_files()\nif num < 200:\n    for link, size in zip(download_links, download_sizes):\n        if size > 250 and size <= 300:\n            localDestination = 'audio_files_downloaded/audio{}.zip'.format(counter)\n            resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n            counter += 1\nnum = count_files()\nif num < 200:\n    for link, size in zip(download_links, download_sizes):\n        if size > 300 and size <= 350:\n            localDestination = \naudio_files_downloaded/audio{}.zip'.format(counter)\n            resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n            counter += 1\nnum = count_files()\nif num < 200:\n    for link, size in zip(download_links, download_sizes):\n        if size > 350 and size <= 400:\n            localDestination = 'audio_files_downloaded/audio{}.zip'.format(counter)\n            resultFilePath, responseHeaders = urllib.request.urlretrieve(link, localDestination)\n            counter += 1\n```", "```\n#!/bin/bash\n#for file in test/*/*.wav\nfor file in train/*/*.wav\ndo\n    outfile=${file%.*}\n          sox \"$file\" -n spectrogram -r -o ${outfile}.png\ndone\n```", "```\npython image_explorer.py\n```", "```\npython retrain.py \\\n--output_graph=trained_model_mobilenetv1/retrained_graph.pb \\\n--output_labels=trained_model_mobilenetv1/retrained_labels.txt   \\\n--architecture mobilenet_1.0_224 \\\n--image_dir= your dataset directory\n```", "```\ntensorboard --logdir retrain_logs\n```"]