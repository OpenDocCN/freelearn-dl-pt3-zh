- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep reinforcement learning enables the building of intelligent agents, products,
    and services that can go beyond computer vision or perception to perform actions.
    TensorFlow 2.x is the latest major release of the most popular deep learning framework
    that is used to develop and train **deep neural networks** (**DNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: The book begins with an introduction to the fundamentals of deep reinforcement
    learning and the latest major version of TensorFlow 2.x. You'll then cover OpenAI
    Gym, model-based RL, and model-free RL, and learn how to develop basic agents.
    Moving on, you will discover how to implement advanced deep reinforcement learning
    algorithms such as actor-critic, deep deterministic policy gradients, deep-Q networks,
    proximal policy optimization, deep recurrent Q-networks, and the soft actor-critic
    algorithm to train your RL agents. You'll also explore reinforcement learning
    in the real world by building cryptocurrency trading agents, stock/share trading
    agents, and intelligent agents for automating task completion. Lastly, you will
    find out how to deploy deep reinforcement learning agents to the cloud and build
    cross-platform apps for the web, mobile, and other platforms using TensorFlow
    2.x.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this cookbook, you will have gained a solid understanding of deep
    reinforcement learning algorithms with the help of easy-to-follow and concise
    implementations from scratch using TensorFlow 2.x.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The book is for machine learning application developers, AI and applied AI researchers,
    data scientists, deep learning practitioners, and students with a basic understanding
    of the reinforcement learning concepts who want to build, train, and deploy their
    own reinforcement learning systems from scratch using TensorFlow 2.x.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B15074_01_Final_AM.xhtml#_idTextAnchor015), *Developing Building
    Blocks for Deep Reinforcement Learning Using TensorFlow 2.x*, provides recipes
    for getting started with RL environments, deep neural network-based RL agents,
    evolutionary neural agents, and other building blocks for both discrete and continuous
    action-space RL applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B15074_02_Final_AM.xhtml#_idTextAnchor044), *Implementing Value-Based
    Policy Gradients and Actor-Critic Deep RL Algorithms*, includes recipes for implementing
    value iteration-based learning agents and breaks down the implementation of several
    foundational algorithms in RL, such as Monte-Carlo control, SARSA and Q-learning,
    actor-critic, and policy gradient algorithms into simple steps.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B15074_03_ePub_AM.xhtml#_idTextAnchor090), *Implementing Advanced
    RL Algorithms*, provides concise recipes to implement complete agent training
    systems using Deep Q-Network (DQN), Double and Dueling Deep Q-Network (DDQN, DDDQN),
    Deep Recurrent Q-Network (DRQN), Asynchronous Advantage Actor-Critic (A3C), Proximal
    Policy Optimization (PPO), and Deep Deterministic Policy Gradient (DDPG) RL algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B15074_04_ePub_AM.xhtml#_idTextAnchor135), *RL in the Real World*
    *–* *Building Cryptocurrency Trading Agents*, shows how to implement and train
    a soft actor-critic agent in custom RL environments for bitcoin and ether trading
    using real market data from trading exchanges such as Gemini, containing both
    tabular and visual (image) state/observation and discrete and continuous action
    spaces.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B15074_05_ePub_AM.xhtml#_idTextAnchor153), *RL in the Real World*
    *–* *Building Stock/Share Trading Agents*, covers how to train advanced RL agents
    to trade for profit in the stock market using visual price charts and/or tabular
    ticket data and more in custom RL environments powered by real stock market exchange
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B15074_06_ePub_AM.xhtml#_idTextAnchor167), *RL in the Real World*
    *–* *Building Intelligent Agents to Complete Your To-Dos*, provides recipes to
    build, train, and test vision-based RL agents for completing tasks on the web
    to help you automate tasks such as clicking on pop-up/confirmation dialogs on
    web pages, logging into various websites, finding and booking the cheapest flight
    tickets for your travel, decluttering your email inbox, and like/share/retweeting
    posts on social media sites to engage with your followers.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B15074_07_ePub_AM.xhtml#_idTextAnchor193), *Deploying Deep RL
    Agents to the Cloud*, contains recipes to equip you with tools and details to
    get ahead of the curve and build cloud-based Simulation-as-a-Service and Agent/Bot-as-a-Service
    programs using deep RL. Learn how to train RL agents using remote simulators running
    on the cloud, package runtime components of RL agents, and deploy deep RL agents
    to the cloud by deploying your own trading bot-as-a-service.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B15074_08_ePub_AM.xhtml#_idTextAnchor221), *Distributed Training
    for the Accelerated Development of Deep RL Agents*, contains recipes to speed
    up deep RL agent development using the distributed training of deep neural network
    models by leveraging TensorFlow 2.x''s capabilities. Learn how to utilize multiple
    CPUs and GPUs both on a single machine as well as on a cluster of machines to
    scale up/out your deep RL agent training and also learn how to leverage Ray, Tune,
    and RLLib for large-scale accelerated training.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B15074_09_ePub_AM.xhtml#_idTextAnchor244), *Deploying Deep RL
    Agents on Multiple Platforms*, provides customizable templates that you can utilize
    for building and deploying your own deep RL applications for your use cases. Learn
    how to export RL agent models for serving/deployment in various production-ready
    formats, such as TensorFlow Lite, TensorFlow.js, and ONNX, and learn how to leverage
    NVIDIA Triton or build your own solution to launch production-ready, RL-based
    AI services. You will also deploy an RL agent in a mobile and web app and learn
    how to deploy RL bots in your Node.js applications.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code in this book is extensively tested on Ubuntu 18.04 and Ubuntu 20.04
    and should work with later versions of Ubuntu if Python 3.6+ is available. With
    Python 3.6+ installed along with the necessary Python packages, as listed at the
    start of each of the recipes, the code should run fine on Windows and macOS X
    too.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15074_Table_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It is advised to create and use a Python virtual environment named tfrl-cookbook
    to install the packages and run the code in this book. A Miniconda or Anaconda
    installation for Python virtual environment management is recommended.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code via the GitHub repository (link available
    in the next section). Doing so will help you avoid any potential errors related
    to the copying and pasting of code.**'
  prefs: []
  type: TYPE_NORMAL
- en: It is highly recommended to star and fork the GitHub repository to receive updates
    and improvements to the code recipes.We urge you to share what you build and also
    engage with other readers and the community at[https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions).
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register at [www.packt.com](http://www.packt.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Support** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Code Downloads**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name of the book in the **Search** box and follow the onscreen instructions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  prefs: []
  type: TYPE_NORMAL
- en: WinRAR/7-Zip for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipeg/iZip/UnRarX for Mac
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7-Zip/PeaZip for Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781838982546_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838982546_ColorImages.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words used in the recipes. Here is an example:
    "We will start with the implementation of the `save` method in the `Actor` class
    to export the Actor model to TensorFlow''s `SavedModel` format."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "Click on the **Open an Existing Project** option and you will
    see a popup asking you to choose the directory on your filesystem. Navigate to
    the [*Chapter 9*](B15074_09_ePub_AM.xhtml#_idTextAnchor244) recipes and choose
    **9.2_rl_android_app**."'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '`customercare@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '`copyright@packt.com` with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  prefs: []
  type: TYPE_NORMAL
- en: For more information about Packt, please visit [packt.com](http://packt.com).
  prefs: []
  type: TYPE_NORMAL
