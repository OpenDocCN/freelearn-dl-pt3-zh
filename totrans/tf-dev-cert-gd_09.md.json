["```\n    #Import necessary libraries\n    ```", "```\n    import os\n    ```", "```\n    import pathlib\n    ```", "```\n    import matplotlib.pyplot as plt\n    ```", "```\n    import matplotlib.image as mpimg\n    ```", "```\n    import random\n    ```", "```\n    import numpy as np\n    ```", "```\n    from PIL import Image\n    ```", "```\n    import pandas as pd\n    ```", "```\n    import tensorflow as tf\n    ```", "```\n    from tensorflow import keras\n    ```", "```\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    ```", "```\n    from tensorflow.keras.callbacks import EarlyStopping\n    ```", "```\n    from tensorflow.keras import regularizer\n    ```", "```\n    !wget https://storage.googleapis.com/x_ray_dataset/dataset.zip\n    ```", "```\n    !unzip dataset.zip\n    ```", "```\n    root_dir = \"/content/dataset\"\n    ```", "```\n    for dirpath, dirnames, filenames in os.walk(root_dir):\n    ```", "```\n        print(f\"Directory: {dirpath}\")\n    ```", "```\n        print(f\"Number of images: {len(filenames)}\")\n    ```", "```\n        print()\n    ```", "```\n    view_random_images(\n    ```", "```\n        target_dir=\"/content/dataset/train\",num_images=4)\n    ```", "```\n    train_datagen = ImageDataGenerator(rescale=1./255)\n    ```", "```\n    valid_datagen = ImageDataGenerator(rescale=1./255)\n    ```", "```\n    # Set up the train and test directories\n    ```", "```\n    train_dir = \"/content/dataset/train/\"\n    ```", "```\n    val_dir = \"/content/dataset/val\"\n    ```", "```\n    test_dir = \"/content/dataset/test\"\n    ```", "```\n    train_data=train_datagen.flow_from_directory(\n    ```", "```\n        train_dir,target_size=(224,224),\n    ```", "```\n    # convert all images to be 224 x 224\n    ```", "```\n        class_mode=\"binary\")\n    ```", "```\n    valid_data=valid_datagen.flow_from_directory(val_dir,\n    ```", "```\n        target_size=(224,224),\n    ```", "```\n        class_mode=\"binary\",\n    ```", "```\n        shuffle=False)\n    ```", "```\n    test_data=valid_datagen.flow_from_directory(test_dir,\n    ```", "```\n        target_size=(224,224),\n    ```", "```\n        class_mode=\"binary\",\n    ```", "```\n        shuffle=False)\n    ```", "```\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1050, activation=\"relu\"),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n# Compile the model\nmodel_1.compile(loss=\"binary_crossentropy\",\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=[\"accuracy\"])\n#Fit the model\n# Add an early stopping callback\ncallbacks = [tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\", patience=3,\n    restore_best_weights=True)]\nhistory_1 = model_1.fit(train_data,epochs=20,\n    validation_data=valid_data,\n    callbacks=[callbacks]\n```", "```\nEpoch 4/20\n163/163 [==============================] – 53s 324ms/step – loss: 0.0632 – accuracy: 0.9774 – val_loss: 0.0803 – val_accuracy: 1.0000\nEpoch 5/20\n163/163 [==============================] – 53s 324ms/step – loss: 0.0556 – accuracy: 0.9797 – val_loss: 0.0501 – val_accuracy: 1.0000\nEpoch 6/20\n163/163 [==============================] – 53s 323ms/step – loss: 0.0412 – accuracy: 0.9854 – val_loss: 0.1392 – val_accuracy: 0.8750\nEpoch 7/20\n163/163 [==============================] – 54s 334ms/step – loss: 0.0314 – accuracy: 0.9875 – val_loss: 0.2450 – val_accuracy: 0.8750\n```", "```\nmodel_1.evaluate(test_data)\n```", "```\nfrom tensorflow.keras.applications import InceptionV3,\n    MobileNet, VGG16, ResNet50\n```", "```\n# Instantiate the VGG16 model\nvgg16 = VGG16(weights='imagenet', include_top=False,\n    input_shape=(224, 224, 3))\n```", "```\n# Freeze all layers in the VGG16 model\nfor layer in vgg16.layers:\n    layer.trainable = False\n```", "```\n# Create a new model on top of VGG16\nmodel_4 = tf.keras.models.Sequential()\nmodel_4.add(vgg16)\nmodel_4.add(tf.keras.layers.Flatten())\nmodel_4.add(tf.keras.layers.Dense(1024, activation='relu'))\nmodel_4.add(tf.keras.layers.Dropout(0.5))\nmodel_4.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n```", "```\n# Compile the model\nmodel_4.compile(optimizer='adam',\n    loss='binary_crossentropy', metrics=['accuracy'])\n# Fit the model\ncallbacks = [tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', patience=3,\n    restore_best_weights=True)]\nhistory_4 = model_4.fit(train_data,\n    epochs=20,\n    validation_data=valid_data,\n    callbacks=[callbacks]\n    )\n```", "```\nEpoch 1/20\n163/163 [==============================] - 63s 360ms/step - loss: 0.2737 - accuracy: 0.9375 - val_loss: 0.2021 - val_accuracy: 0.8750\nEpoch 2/20\n163/163 [==============================] - 57s 347ms/step - loss: 0.0818 - accuracy: 0.9699 - val_loss: 0.4443 - val_accuracy: 0.8750\nEpoch 3/20\n163/163 [==============================] - 56s 346ms/step - loss: 0.0595 - accuracy: 0.9774 - val_loss: 0.1896 - val_accuracy: 0.8750\nEpoch 4/20\n163/163 [==============================] - 58s 354ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.4209 - val_accuracy: 0.8750\n```", "```\n# Instantiate the MobileNet model\nmobilenet = MobileNet(weights='imagenet',\n    include_top=False, input_shape=(224, 224, 3))\n# Freeze all layers in the MobileNet model\nfor layer in mobilenet.layers:\n    layer.trainable = False\n# Create a new model on top of MobileNet\nmodel_10 = tf.keras.models.Sequential()\nmodel_10.add(mobilenet)\nmodel_10.add(tf.keras.layers.Flatten())\nmodel_10.add(tf.keras.layers.Dense(1024,activation='relu'))\nmodel_10.add(tf.keras.layers.Dropout(0.5))\nmodel_10.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n```", "```\n# Compile the model\nmodel_10.compile(optimizer='adam',\n    loss='binary_crossentropy', metrics=['accuracy'])\n# Fit the model\ncallbacks = [tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy', patience=3,\n    restore_best_weights=True)]\nhistory_10 = model_10.fit(train_data,\n    epochs=20,\n    validation_data=valid_data,\n    callbacks=[callbacks])\n```", "```\nEpoch 1/20\n163/163 [==============================] - 55s 321ms/step - loss: 3.1179 - accuracy: 0.9402 - val_loss: 1.8479 - val_accuracy: 0.8750\nEpoch 2/20\n163/163 [==============================] - 51s 313ms/step - loss: 0.3896 - accuracy: 0.9737 - val_loss: 1.1031 - val_accuracy: 0.8750\nEpoch 3/20\n163/163 [==============================] - 52s 320ms/step - loss: 0.0795 - accuracy: 0.9896 - val_loss: 0.8590 - val_accuracy: 0.8750\nEpoch 4/20\n163/163 [==============================] - 52s 318ms/step - loss: 0.0764 - accuracy: 0.9877 - val_loss: 1.1536 - val_accuracy: 0.8750\n```", "```\n# Load the InceptionV3 model\ninception = InceptionV3(weights='imagenet',\n    include_top=False, input_shape=(224, 224, 3))\n# Unfreeze the last 50 layers of the InceptionV3 model\nfor layer in inception.layers[-50:]:\n    layer.trainable = True\n```", "```\nEpoch 5/10\n163/163 [==============================] - 120s 736ms/step - loss: 0.1168 - accuracy: 0.9584 - val_loss: 0.1150 - val_accuracy: 1.0000\nEpoch 6/10\n163/163 [==============================] - 117s 716ms/step - loss: 0.1098 - accuracy: 0.9624 - val_loss: 0.2713 - val_accuracy: 0.8125\nEpoch 7/10\n163/163 [==============================] - 123s 754ms/step - loss: 0.1011 - accuracy: 0.9613 - val_loss: 0.2765 - val_accuracy: 0.7500\nEpoch 8/10\n163/163 [==============================] - 120s 733ms/step - loss: 0.0913 - accuracy: 0.9668 - val_loss: 0.2711 - val_accuracy: 0.8125\n```"]