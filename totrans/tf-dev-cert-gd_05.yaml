- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image Classification with Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up until this point, we have built models to solve both regression and classification
    problems on structured data with much success. The next question that comes to
    mind is: can we build models that can tell the difference between a dog and a
    cat, or a car and a plane? Today, with the aid of frameworks such as **TensorFlow**
    and **PyTorch**, developers can now build such ML solutions with a few lines of
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the anatomy of **neural networks** and learn
    how we can apply them to building models for computer vision problems. We will
    start by examining what a neural network is and the architecture of a multilayer
    neural network. We will look at some important ideas such as forward propagation,
    backward propagation, optimizers, loss function, learning rate, and activation
    functions, and where and how they fit in.
  prefs: []
  type: TYPE_NORMAL
- en: After we build a solid base in the core fundamentals, we will build an image
    classifier using a custom dataset from TensorFlow. Here, we will walk through
    the end-to-end process of model building using the TensorFlow dataset. The good
    part of using these custom datasets is that the bulk of the preprocessing steps
    are already done, and our data can be modeled without any blockers. So, we will
    use this dataset to build a neural network with a few lines of code in TensorFlow
    with the **Keras** API, so that our model will be able to tell the difference
    between a bag and a shirt, and a shoe and a coat.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The anatomy of neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an image classifier with a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will be using `python >= 3.8.0`, along with the following packages that
    can be installed using the `pip` `install` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tensorflow>=2.7.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tensorflow-datasets==4.4.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pillow==8.4.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas==1.3.4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy==1.21.4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib >=3.4.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code for this chapter is available at [https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate-Guide/tree/main/Chapter%205).
    Also, solutions to all exercises can be found in the GitHub repository itself.
  prefs: []
  type: TYPE_NORMAL
- en: The anatomy of neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the first section of this book, we talked about models. These models that
    we spoke about and used for various use cases are neural networks. A neural network
    is a deep learning algorithm inspired by the functionality of the human brain,
    but by no means does it operate like the human brain. It learns useful representation
    of the input data using a layered approach, as shown in *Figure 5**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Neural network](img/B18118_05_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Neural network
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are ideal for tackling complex problems due to their ability
    to identify very complex patterns in data. This makes them well suited for building
    solutions around text and image data (unstructured data), tasks that traditional
    machine learning algorithms struggle with. Neural networks develop rules to map
    input data to the target or labels using layered representation. When we train
    them on labeled data, they learn the patterns and use this knowledge to map the
    new input data to their corresponding labels.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 5**.1*, we see all the neurons of the input layer are connected to
    the neurons of the first hidden layer, and all the neurons of the first hidden
    layer are connected to all the neurons of the second hidden layer. The same applies
    from the second hidden layer to the outer layer. This type of network, where each
    layer’s neurons are fully connected to the neurons of the next layer, is called
    a **fully connected neural network**. A neural network with more than two hidden
    layers is called a **deep neural network** (**DNN**) and the depth of the network
    is determined by its number of layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a deep dive into the individual layers of a neural network architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input layer**: This is the layer through which we fed the input data (text,
    image, tabular data) into the network. Here, we have to specify the right input
    shape, something we have done previously in our regression case study in [*Chapter
    3*](B18118_03.xhtml#_idTextAnchor065)*, Linear Regression With TensorFlow*, and
    in our classification case study in [*Chapter 4*](B18118_04.xhtml#_idTextAnchor085)*,
    Classification With TensorFlow*. It is important to note that the input data will
    be presented to our neural network in numerical format. In this layer, no computation
    takes place. It’s more of a passthrough layer to the hidden layer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hidden layer**: This is the next layer and it lies between the input and
    output layers. It is referred to as hidden because it is not visible to external
    systems. Here, lots of computation takes place to extract patterns from our input
    data. The more layers we add to the hidden layer, the more complex our model becomes
    and the more time it takes to process our data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output layer**: This layer produces the output of the neural network. The
    number of output layer neurons is determined by the task at hand. If we have a
    binary classification task, we will use one output neuron, while for multiclass
    classification, such as in our case study where we had 10 different labels, we
    will have 10 neurons, one for each of the classes in our data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We now know the layers of a neural network, but the key questions are: how
    does a neural network work, and what enables it to take a special position in
    machine learning?'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks solve complex tasks by the application of both forward and backward
    propagation. Let’s start by examining forward propagation.
  prefs: []
  type: TYPE_NORMAL
- en: Forward propagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine we want to teach our neural network to effectively identify the images
    shown in *Figure 5**.2*. We will pass lots of representative samples of each of
    the images we want our neural network to recognize. The idea here is that our
    neural network will learn from the samples and use what it has learned to identify
    new items within the sample space. Let’s say, for example, we want our model to
    recognize shirts; we will pass shirts of different colors and sizes. Our model
    will learn what defines a shirt, irrespective of its color, size, or style. This
    learned representation of the core attributes of a shirt is what the model will
    use to identify new shirts.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Sample images from Fashion MNIST dataset](img/B18118_05_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – Sample images from Fashion MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: Let us look at what happens under the hood. In our training data, we pass the
    images (*X*) through our model f(x) . . →  ˆ y , where  ˆ y  is the model’s predicted
    output. Here, the neural network randomly initializes weights that are used to
    predict the output ( ˆ y ). This process is called **forward propagation** or
    **forward pass** and is depicted in *Figure 5**.3*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Weights are trainable parameters that are updated during the training process.
    After training, the model’s weights are optimized to the specific dataset it is
    trained on. If we tune the weight properly during training, we can develop a well-performing
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'As input data flows through the network, it experiences transformations due
    to the impact of the node’s weight and bias, as shown in *Figure 5**.3*, thus
    producing a new set of information that will now pass through an *activation function*.
    If the new information learned is desired, the activation function triggers an
    output signal that serves as input to the next layer. This process continues until
    an output is generated in the output layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Forward propagation of a neural network](img/B18118_05_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Forward propagation of a neural network
  prefs: []
  type: TYPE_NORMAL
- en: Let’s talk a bit more about activation functions and what they do in our neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine you had to pick the good apples from a basket of apples. By inspecting
    the apples, you can pick the good ones and drop the bad ones. This is how an activation
    function works – it plays the role of a separator and thus defines what will pass
    through, which in our case is the useful representation it has learned, and drops
    the non-useful data. In essence, it helps to extract useful information, such
    as the good apples, and drop the useless data, which in our scenario are the bad
    apples. Now, the activation function determines which connected neuron of the
    next layer will be activated. It uses mathematical operations to determine whether
    a learned representation is useful enough for the next layer or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activation functions can add nonlinearity to our neural network, a characteristic
    that is required for neural networks to learn complex patterns. There are different
    activation functions; for output layers, the selection of activation function
    depends on the type of task at hand:'
  prefs: []
  type: TYPE_NORMAL
- en: For binary classification, we usually use sigmoid function because it maps the
    input to output values between 0 and 1, representing the probability of belonging
    to a particular class. We usually set the threshold point as 0.5, hence values
    above this point are set to 1 and values below it is set to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For multiclass classification, we use **softmax** **activation** as the output
    layer’s activation function. Let’s say we want to build an image classifier to
    classify four fruits (apples, grapes, mangoes, and oranges) as illustrated in
    *Figure 5**.4.* One neuron is assigned in the output layer to each of the fruits
    and we will apply the softmax activation function to generate the likelihood of
    the output being one of the fruits we want to predict. When we sum up the probabilities
    of it being an apple, grape, mango, and orange, we get 1\. For classification,
    we select the class with highest probability of the four fruits as the output
    label from the probabilities generated by the Softmax activation function. In
    this case, the output with the highest probability is an orange:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Application of the SoftMax activation function](img/B18118_05_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Application of the SoftMax activation function
  prefs: []
  type: TYPE_NORMAL
- en: For hidden layers, we will use the **rectified linear unit** (**ReLU**) activation
    function. This activation function removes negative values (useless representations),
    while it passes learned representations with values greater than 0\. ReLU offers
    excellent performance for hidden layers as it converges quickly as well as supports
    backward propagation, a concept we will be discussing next.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is more efficient to use sigmoid for binary classification, when we do this,
    we have one output neuron as against two output neurons which would be the case
    when we use Softmax. Also, it is easier to understand that we are working on a
    case of binary classification when we read the code.
  prefs: []
  type: TYPE_NORMAL
- en: Backward propagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When we begin training a model, the weights are initially random, making it
    more likely that the model will guess wrongly that the fruit in *Figure 5**.4*
    is an orange. Here comes the intelligence of our neural network; it autocorrects
    itself, as shown in *Figure 5**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Forward and backward propagations of a neural network](img/B18118_05_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Forward and backward propagations of a neural network
  prefs: []
  type: TYPE_NORMAL
- en: Here, the neural network measures how correct the predicted output ( ˆ y ) is
    in comparison to the ground truth (*y*). This loss is computed by the **loss function**,
    which can also be referred to as the **cost function**. This information is passed
    on to an **optimizer**, whose job is to update the weights of the layers in the
    neural network with the aim of reducing the loss over the next iterations, thus
    getting our prediction closer to the ground truth. This process continues until
    we achieve **convergence**. Convergence occurs when the model is trained such
    that the loss is at its barest minimum.
  prefs: []
  type: TYPE_NORMAL
- en: The loss function is applied with respect to the task at hand. When we are working
    on a binary classification task, we use **binary cross-entropy**; for multiclass
    classification, if the target labels are integer values (for example, 0 to 9)
    we use **sparse categorical cross-entropy**, whereas we use **categorical cross-entropy**
    if we decide to one-hot encode our target labels. Like loss functions, we also
    have different types of optimizers; however, we will experiment with **stochastic
    gradient descent** (**SGD**) and the **Adam optimizer**, which is an improved
    version of SGD. Hence, we will use this as our default optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: Learning rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We now know that weights are randomly initialized, and optimizers aim to use
    this information about the loss function to update the weights with a view to
    achieving convergence. Neural networks use optimizers to iteratively update the
    weights until the loss function is at a minimum, as shown in *Figure 5**.6*. Optimizers
    let you set an important hyperparameter called the **learning rate**, which controls
    the speed of convergence and is how our model learns. To get to the bottom of
    the slope, we will have to take steps toward the base (see *Figure 5**.6*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Gradient descent](img/B18118_05_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Gradient descent
  prefs: []
  type: TYPE_NORMAL
- en: The step size we take will determine how quickly we get to the base. If we take
    very small steps, it will take too long to reach the base and lead to slower convergence,
    and there is also a risk that the optimization process could get stuck along the
    way to the minimum point. On the flip side, if the steps are too large, there
    is a risk we may overshoot the minimum and experience erratic and unstable training
    behavior. The right step size will get us to the base of the slope in time without
    overshooting the minimum point. This step size we refer to here is the learning
    rate.
  prefs: []
  type: TYPE_NORMAL
- en: We have now covered the intuition behind neural networks at a high level. Let
    us proceed and look at our case study, directly applying what we have just learned.
  prefs: []
  type: TYPE_NORMAL
- en: Building an image classifier with a neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are back at our fictional company, and we want to use the intuition of neural
    networks to build an image classifier. Here, we are to teach computers to identify
    clothing. Thankfully, we do not need to find data in the wild; we have TensorFlow
    datasets that include the fashion dataset. In our case study, our aim is to classify
    a fashion dataset made up of 28 x 28 grayscale images into 10 classes (from 0
    to 9) with pixel values between 0 and 255, using a well-known dataset called the
    *Fashion MNIST dataset*. This dataset is made up of 60,000 training images and
    10,000 test images. Our dataset has all the images in the same shape, so we have
    little preprocessing to do. The idea here is for us to build a neural network
    quickly with little preprocessing complexities.
  prefs: []
  type: TYPE_NORMAL
- en: To train the neural network, we will pass the training images with the idea
    that our neural network will learn to map the images (*X*) to their corresponding
    labels (*y*). After we have concluded the training process, we will use our test
    set to evaluate the model on new unseen images. Again, the idea is that the model
    will correctly identify test images based on what it has learned throughout the
    training process. Let’s begin.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we will start with learning how to work with images using TensorFlow
    datasets. In [*Chapter 7*](B18118_07.xhtml#_idTextAnchor146)*,**Image Classification
    with Convolutional Neural Networks*, we will work on real-world images that will
    require more work to model our data; however, it will build on what we will learn
    here. That said, let us see how we can load our custom dataset from TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can load our data, we need to load the necessary libraries. Let’s
    do that here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we import the `fashion_mnist` dataset from TensorFlow and create our
    training and testing dataset using the `load_data()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If everything goes according to plan, we should get an output as shown in *Figure
    5**.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Data import from TensorFlow datasets](img/B18118_05_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Data import from TensorFlow datasets
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, rather than using numeric labels, let us create labels that match our
    data such that we can call a dress a dress, rather than call it number 3\. We
    will do that by creating a list of our labels, which we will map to the corresponding
    numeric values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have our data, let us explore the data and see what we can find.
    Rather than agree with everything we are told, let’s explore the data to verify
    the size, the shape, and the data distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Performing exploratory data analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After we load the data, the next step is to examine it to get a sense of what
    the data is. Of course, in this instance, we have some basic information from
    TensorFlow about the data distribution. Also, we have the data already available
    in training and test sets. However, let us confirm all the details using code,
    as well as view the class distribution of our target label:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `matplotlib` library to generate image samples at index `i`,
    where `i` falls within the 60,000 training samples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We run the code using index `7`, which returns a top as seen in *Figure 5**.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.8 – A photo of a pullover at index 7 of the Fashion MNIST dataset](img/B18118_05_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – A photo of a pullover at index 7 of the Fashion MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: We can switch the index values to see other apparels within the dataset; however,
    that is not the goal here. So, let’s proceed with our exploratory data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the sample of our data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As expected, we can see the training images consist of 60,000 28 x 28 images,
    and the test images are 10,000 in number and 28 x 28 in resolution:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let us check the distribution of the data. It’s best practice to see
    how your data is distributed to ensure there is enough representation for each
    class of clothing we want to train the model on. Let’s do that here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This returns a `DataFrame` as shown in *Figure 5**.9*. We can see that all
    the labels have the same number of samples:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.9 – DataFrame showing labels and their counts](img/B18118_05_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – DataFrame showing labels and their counts
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this type of data is more likely to be found in a controlled setting
    such as academia.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us visualize some sample images from the training data here. Let’s look
    at 16 samples from our training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When we run the code, we get the image in *Figure 5**.10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.10 – 16 randomly selected images from the Fashion MNIST dataset](img/B18118_05_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – 16 randomly selected images from the Fashion MNIST dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have confirmed the data size, the data distribution, and the shape,
    and seen some sample images and labels. Before we proceed with building and training
    our image classifier, recall our data is made up of grayscale images with values
    from 0 to 255\. To bring the data to scale, we will have to normalize the data
    to improve the performance of our model during training. We can do this by simply
    dividing the training and testing data by 255:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have normalized our data, we are all set for modeling it. Let’s
    proceed with building our image classifier next.
  prefs: []
  type: TYPE_NORMAL
- en: Building the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us put everything we have learned so far in this chapter into action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The code we use to build our model is similar to what we used in *Part 1* of
    this book. We start by creating a sequential model using the Sequential API to
    define the number of layers we want to connect sequentially. If you are a keen
    observer, you will notice our first layer is a flatten layer. This is used to
    flatten the image data into a 1D array that will be passed into the hidden layer.
    The input layer has no neurons; it works as a data preprocessing layer, presenting
    the hidden layer with data flattened into a 1D array.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have one hidden layer of 64 neurons, and we apply a ReLU activation
    function to this hidden layer. Finally, we have an output layer of 10 neurons
    – one neuron for each output. We use a softmax function since we are working on
    multiclass classification. Softmax returns results in the form of probabilities
    across all classes. If you recall from the *Activation functions* section, the
    sum of the output probabilities adds up to 1, and the output with the largest
    probability value is the predicted label.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are done with model building, let us proceed with compiling our
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Compiling the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step is to compile the model. We will use the `compile` method to
    do so. Here, we pass in the optimizer we wish to use; in this case, we apply **Adam**,
    which is our default optimizer. We also specify the loss and the evaluation metrics.
    We use sparse categorical cross-entropy for our loss since our labels are numeric
    values. For our evaluation metrics, we use accuracy, since our dataset is balanced.
    The accuracy metric will give a true reflection of our model’s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Before we proceed to fitting our model, let’s look at some ways of visualizing
    our model and its parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Model visualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To visualize our model, we use the `summary()` method. This provides us with
    a detailed visual representation of the model’s architecture, the layers, the
    number of parameters (trainable and non-trainable), and the output shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the code, it returns the model’s details as illustrated in *Figure
    5**.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Model summary](img/B18118_05_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Model summary
  prefs: []
  type: TYPE_NORMAL
- en: From *Figure 5**.11*, we can see that the input layer has no parameters but
    an output shape of 784, which is the result of flattening our 28 × 28 image to
    a 1D array. To get the number of parameters of the dense layer, it’s 784 × 64
    + 64 = 50240 (recall , where *X* is the input data, *w* is the weights, and *b*
    is the bias). The output layer (`dense_1`) has a shape of 10, with one neuron
    representing each class and 650 parameters. Recall the output from one layer serves
    as the input to the next layer. So, 64 × 10 + 10 = 650, where 64 is the output
    shape of the hidden layer and the input shape of the output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, we can also display our model as a flowchart, as seen in
    *Figure 5**.12*, by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 5.12 – Model’s flowchart](img/B18118_05_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Model’s flowchart
  prefs: []
  type: TYPE_NORMAL
- en: This also gives us a sense of our model’s structure. The plot we generated will
    be saved with the filename `model_plot.png`. Here, we set `show_shapes` to `true`;
    this will display the output shapes of each layer in the plot. We also set the
    `show_layer_name` to `true` to show the names of the layers in the plot, as illustrated
    in *Figure 5**.12.*
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us fit our model to the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Model fitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By now, you should be familiar with this process. With a single line of code,
    we can use the `fit` method to fit our training images (*X*) and training labels
    (*y*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we fit the data for five epochs. Our model returns the loss and accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: We can see that in just five epochs, our model has achieved an accuracy of `0.8850`.
    This is a good start considering we trained our model for a very small number
    of epochs. Next, let us observe our model’s performance during training by plotting
    the loss and accuracy plots.
  prefs: []
  type: TYPE_NORMAL
- en: Training monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We return a `history` object when we fit our training data. Here, we use the
    `history` object to create a loss and accuracy curve. Here is the code to make
    the plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the code, we get back two plots as shown in *Figure 5**.13*. We
    can see the training accuracy is still rising at the end of the fifth epoch, while
    the loss is still falling, although the rate is not rapid as it moves closer to
    0:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Accuracy and loss plots](img/B18118_05_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Accuracy and loss plots
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps if we train for longer, we could see an improved performance. In the
    next chapter, we will examine what happens if we do train for longer, as well
    as look at other approaches to improve our model’s performance. Here, the aim
    is to understand what the plot means and gain enough information to direct our
    next line of action. Let’s evaluate our model on the test set.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We evaluate the overall performance of our model on the test set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We get an accuracy of `0.8567` on the test set. The difference between the training
    accuracy and the test accuracy is a common problem in machine learning that we
    refer to as **overfitting**. Overfitting is a key issue in machine learning, and
    we will look at overfitting and various ways of handling it in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*,*
    *Handling Overfitting*.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us make some predictions with our trained neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Model prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To make predictions on the model, we use the `model.predict()` method on unseen
    data from our test set. Let’s look at what the model predicts on the first instance
    of our test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'When we run the code, we get back an array of probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'If we inspect the probabilities, we see that the probability is highest at
    the ninth element. So, there is a 70% chance that this is our label. We will use
    `np.argmax` to extract the label and compare it to the test label at index `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that both the predicted label and test label return a value of `9`.
    Our model got this prediction right. Next, let us plot 16 random images and compare
    the predicted results with the ground label. This time, rather than returning
    the numeric values of our labels, we will return the labels themselves for visual
    clarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown in *Figure 5**.14*. Although the model was able to classify
    10 items correctly, it failed on one sample where it classified a shirt as a pullover:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Visualizing the model’s prediction on test data](img/B18118_05_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Visualizing the model’s prediction on test data
  prefs: []
  type: TYPE_NORMAL
- en: In just a few lines of code, we have trained an image classifier. We reached
    an accuracy of 88.50% on our training data in five epochs and 85.67% on our test
    data. It is important to note that this is a toy dataset that is great for learning;
    however, real-world images are more complex and the training will take much longer
    and, in many instances, a more complex model architecture will be required.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have covered a lot of new concepts that will be very useful
    in later chapters and in the exams as well.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed image classification modeling. Now, you should
    be able to explain what a neural network is, as well as forward and backward propagation.
    You should know the role of loss functions, activation functions, and optimizers
    in a neural network. Also, you should be able to find your way around loading
    data from a TensorFlow dataset. Finally, you should be familiar with how to build,
    compile, fit, and train a neural network for image classification as well as evaluate
    the model, plot the loss and accuracy curves, and interpret these visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore several ideas we can apply to improve our
    model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s test what we learned in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the function of the activation function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does backward propagation work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of the input, hidden, and output layers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using a TensorFlow dataset, load a handwritten digits dataset after which you
    will build, compile, train, and evaluate an image classifier. It’s a similar exercise
    to our case study. Go for it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more, you can check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amr, T., 2020\. *Hands-On Machine Learning with scikit-learn and Scientific
    Python Toolkits*. [S.l.]: Packt Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vasilev, I., 2019\. *Advanced Deep Learning with Python*. 1st ed. Packt Publishing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raschka, S. and Mirjalili, V., 2019\. *Python Machine Learning*. 3rd ed. Packt
    Publishing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gulli, A., Kapoor, A. and Pal, S., 2019\. *Deep Learning with TensorFlow 2
    and Keras*. Birmingham: Packt Publishing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TensorFlow* *Guide* [https://www.TensorFlow.org/guide](https://www.TensorFlow.org/guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
