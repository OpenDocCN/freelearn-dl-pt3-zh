<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer849">
<h1 class="chapterNumber">17</h1>
<h1 class="chapterTitle" id="_idParaDest-428">Graph Neural Networks</h1>
<p class="normal">In this chapter, we will look at a relatively new class of neural networks, the <strong class="keyWord">Graph Neural Network</strong> (<strong class="keyWord">GNN</strong>), which is ideally suited for processing graph data. Many real-life problems in areas such as social media, biochemistry, academic literature, and many others are inherently “graph-shaped,” meaning that their inputs are composed of data that can best be represented as graphs. We will cover what graphs are from a mathematical point of view, then explain the intuition behind “graph convolutions,” the main idea behind GNNs. We will then describe a few popular GNN layers that are based on variations of the basic graph convolution technique. We will describe three major applications of GNNs, covering node classification, graph classification, and edge prediction, with examples using TensorFlow and the <strong class="keyWord">Deep Graph Library</strong> (<strong class="keyWord">DGL</strong>). DGL provides the GNN layers we have just mentioned plus many more. In addition, it also provides some standard graph datasets, which we will use in the examples. Following on, we will show how you could build a DGL-compatible dataset from your own data, as well as your own layer using DGL’s low-level message-passing API. Finally, we will look at some extensions of graphs, such as heterogeneous graphs and temporal graphs.</p>
<p class="normal">We will cover the following topics in this chapter:</p>
<ul>
<li class="bulletList">Graph basics</li>
<li class="bulletList">Graph machine learning</li>
<li class="bulletList">Graph convolutions</li>
<li class="bulletList">Common graph layers</li>
<li class="bulletList">Common graph applications</li>
<li class="bulletList">Graph customizations</li>
<li class="bulletList">Future directions</li>
</ul>
<div class="note">
<p class="normal">All the code files for this chapter can be found at https://packt.link/dltfchp17</p>
</div>
<p class="normal">Let’s begin with the basics.</p>
<h1 class="heading-1" id="_idParaDest-429">Graph basics</h1>
<p class="normal">Mathematically speaking, a graph <em class="italic">G</em> is a data <a id="_idIndexMarker1536"/>structure consisting of a set of vertices (also called nodes) <em class="italic">V</em>, connected to each <a id="_idIndexMarker1537"/>other by a set of edges <em class="italic">E</em>, i.e:</p>
<p class="center"><img alt="" height="50" src="../Images/B18331_17_001.png" style="height: 1.25em !important;" width="175"/></p>
<p class="normal">A graph can be equivalently represented as an adjacency matrix <em class="italic">A</em> of size (<em class="italic">n</em>, <em class="italic">n</em>) where <em class="italic">n</em> is the number of vertices in the set <em class="italic">V</em>. The element <em class="italic">A[I, j]</em> of this adjacency matrix represents the edge between vertex <em class="italic">i</em> and vertex <em class="italic">j</em>. Thus the element <em class="italic">A[I, j] = 1</em> if there is an edge between vertex <em class="italic">i</em> and vertex <em class="italic">j</em>, and 0 otherwise. In the case of weighted graphs, the edges might have their own weights, and the adjacency matrix will reflect that by setting the edge weight to the element <em class="italic">A[i, j]</em>. Edges may be directed or undirected. For example, an edge representing the friendship between a pair of nodes <em class="italic">x</em> and <em class="italic">y</em> is undirected, since <em class="italic">x</em> is friends with <em class="italic">y</em> implies that <em class="italic">y</em> is friends with <em class="italic">x</em>. Conversely, a directed edge can be one in a follower network (social media), where <em class="italic">x</em> following <em class="italic">y</em> does not imply that <em class="italic">y</em> follows <em class="italic">x</em>. For undirected graphs, <em class="italic">A[I, j] = A[j, i]</em>.</p>
<p class="normal">Another interesting property of the adjacency matrix <em class="italic">A</em> is that <em class="italic">A</em><sup class="italic">n</sup>, i.e., the product of <em class="italic">A</em> taken <em class="italic">n</em> times, exposes <em class="italic">n</em>-hop connections between nodes.</p>
<p class="normal">The graph-to-matrix equivalence is bi-directional, meaning the adjacency matrix can be converted back to the graph<a id="_idIndexMarker1538"/> representation without any loss of information. Since <strong class="keyWord">Machine Learning</strong> (<strong class="keyWord">ML</strong>) methods, including <strong class="keyWord">Deep Learning</strong> (<strong class="keyWord">DL</strong>) methods, consume input data in the<a id="_idIndexMarker1539"/> form of tensors, this equivalence means that graphs can be efficiently represented as inputs to all kinds of machine learning algorithms.</p>
<p class="normal">Each node can also be associated with its own feature vector, much like records in tabular input. Assuming a feature vector of size <em class="italic">f</em>, the set of nodes <em class="italic">X</em> can be represented as <em class="italic">(n, f)</em>. It is also possible for edges to have their own feature vectors. Because of the equivalence between graphs and matrices, graphs are usually represented by libraries as efficient tensor-based structures. We will examine this in more detail later in this chapter.</p>
<h1 class="heading-1" id="_idParaDest-430">Graph machine learning</h1>
<p class="normal">The goal of any ML exercise is to learn a mapping <em class="italic">F</em> from an input space <em class="italic">X</em> to an output space <em class="italic">y</em>. Early machine<a id="_idIndexMarker1540"/> learning methods required feature engineering to define the appropriate features, whereas DL methods can infer the features from the training data itself. DL works by hypothesizing a model <em class="italic">M</em> with random weights <img alt="" height="42" src="../Images/B18331_17_002.png" style="height: 1.05em !important; vertical-align: -0.07em !important;" width="25"/>, formulating the task as an optimization problem over the parameters <img alt="" height="42" src="../Images/B18331_17_003.png" style="height: 1.05em !important; vertical-align: -0.07em !important;" width="25"/>:</p>
<p class="center"><img alt="" height="63" src="../Images/B18331_17_004.png" style="height: 1.57em !important; vertical-align: 0.05em !important;" width="250"/></p>
<p class="normal">and using gradient descent to update the model weights over multiple iterations until the parameters converge:</p>
<p class="center"><img alt="" height="46" src="../Images/B18331_17_005.png" style="height: 1.15em !important; vertical-align: 0.09em !important;" width="242"/></p>
<p class="normal">Not surprisingly, GNNs follow this basic model as well.</p>
<p class="normal">However, as you have seen in previous chapters, ML and DL are often optimized for specific structures. For example, you might instinctively choose a simple <strong class="keyWord">FeedForward Network</strong> (<strong class="keyWord">FFN</strong>) or “dense” network when<a id="_idIndexMarker1541"/> working with tabular data, a <strong class="keyWord">Convolutional Neural Network</strong> (<strong class="keyWord">CNN</strong>) when <a id="_idIndexMarker1542"/>dealing with image data, and a <strong class="keyWord">Recurrent Neural Network </strong>(<strong class="keyWord">RNN</strong>) when dealing with sequence data<a id="_idIndexMarker1543"/> like text or time series. Some inputs may reduce to simpler structures such as pixel lattices or token sequences, but not necessarily so. In their natural form, graphs are topologically complex structures of indeterminate size and are not permutation invariant (i.e., instances are not independent of each other).</p>
<p class="normal">For these reasons, we need special tooling to deal with graph data. We will introduce in this chapter the DGL, a cross-platform graph library that supports users of MX-Net, PyTorch, and TensorFlow through the use of a configurable backend and is widely considered one of the most powerful and easy-to-use graph libraries available.</p>
<h1 class="heading-1" id="_idParaDest-431">Graph convolutions – the intuition behind GNNs</h1>
<p class="normal">The convolution operator, which<a id="_idIndexMarker1544"/> effectively allows values of neighboring pixels on a 2D plane to be aggregated in a specific way, has been successful in deep neural networks for computer vision. The 1-dimensional variant has seen similar success in natural language processing and audio processing as well. As you will recall from <em class="chapterRef">Chapter 3</em>, <em class="italic">Convolutional Neural Networks</em>, a network applies convolution and pooling operations across successive layers and manages to learn enough global features across a sufficiently large number of input pixels to succeed at the task it is trained for.</p>
<p class="normal">Examining the analogy from the other end, an image (or each channel of an image) can be thought of as a lattice-shaped graph where neighboring pixels link to each other in a specific way. Similarly, a sequence of words or audio signals can be thought of as another linear graph where <a id="_idIndexMarker1545"/>neighboring tokens are linked to each other. In both cases, the deep learning architecture progressively applies convolutions and pooling operations across neighboring vertices of the input graph until it learns to perform the task, which is generally classification. Each convolution step encompasses an additional level of neighbors. For example, the first convolution merges signals from distance 1 (immediate) neighbors of a node, the second merges signals from distance 2 neighbors, and so on.</p>
<p class="normal"><em class="italic">Figure 17.1</em> shows the equivalence between a 3 x 3 convolution in a CNN and the corresponding “graph convolution” operation. The convolution operator applies the filter, essentially a set of nine learnable model parameters, to the input and combines them via a weighted sum. You can achieve the same effect by treating the pixel neighborhood as a graph of nine nodes centered around the middle pixel. </p>
<p class="normal">A graph convolution on such a structure would just be a weighted sum of the node features, the same as the convolution operator in the CNN:</p>
<figure class="mediaobject"><img alt="Diagram  Description automatically generated" height="358" src="../Images/B18331_17_01.png" width="642"/></figure>
<p class="packt_figref">Figure 17.1: Parallels between convolutions in images and convolutions in graphs. Image source: CS-224W machine learning with Graphs, Stanford Univ.</p>
<p class="normal">The corresponding <a id="_idIndexMarker1546"/>equations for the convolution operation on the CNN and the graph convolution are shown below. As you can see, on CNN, the convolution can be considered as a weighted linear combination of the input pixel and each of its neighbors. Each pixel brings its own weight in the form of the filter being applied. On the other hand, the graph convolution is also a weighted linear combination of the input pixel and an aggregate of all its neighbors. The aggregate effect of all neighbors is averaged into the convolution output:</p>
<p class="center"><img alt="" height="113" src="../Images/B18331_17_006.png" style="height: 2.83em !important; vertical-align: 0.03em !important;" width="771"/></p>
<p class="center"><img alt="" height="133" src="../Images/B18331_17_007.png" style="height: 3.33em !important; vertical-align: 0.03em !important;" width="842"/></p>
<p class="normal">Graph convolutions are thus a variation of convolutions that we are already familiar with. In the following section, we will see how these convolutions can be composed to build different kinds of GCN layers.</p>
<h1 class="heading-1" id="_idParaDest-432">Common graph layers</h1>
<p class="normal">All the graph layers that we discuss in this section use some variation of the graph convolution operation described above. Contributors<a id="_idIndexMarker1547"/> to graph libraries such as DGL provide prebuilt versions of many of these layers within a short time of it being proposed in an academic paper, so you will realistically never have to implement one of these. The information here is mainly for understanding how things work under the hood.</p>
<h2 class="heading-2" id="_idParaDest-433">Graph convolution network</h2>
<p class="normal">The <strong class="keyWord">Graph Convolution Network</strong> (<strong class="keyWord">GCN</strong>) is the graph convolution layer proposed by Kipf and Welling [1]. It was originally presented as a<a id="_idIndexMarker1548"/> scalable approach for semi-supervised learning on graph-structured data. They describe the GCN as an operation over the node feature vectors <em class="italic">X</em> and the adjacency matrix <em class="italic">A</em> of the underlying graph and point out that this can be exceptionally powerful when the information in <em class="italic">A</em> is not present in the data <em class="italic">X</em>, such as citation links between documents in a citation network, or relations in a knowledge graph.</p>
<p class="normal">GCNs combine the value of each node’s feature vector with those of its neighbors using some weights (initialized to random values). Thus, for every node, the sum of the neighboring node’s features is added. This operation can be represented as follows:</p>
<p class="center"><img alt="" height="54" src="../Images/B18331_17_008.png" style="height: 1.35em !important;" width="742"/></p>
<p class="normal">Here the <em class="italic">update</em> and <em class="italic">aggregate</em> are different kinds of summation functions. This sort of projection on node features is called a<a id="_idIndexMarker1549"/> message-passing mechanism. A single iteration of this message passing is equivalent to a graph convolution over each node’s immediate neighbors. If we wish to incorporate information from more distant nodes, we can repeat this operation several times.</p>
<p class="normal">The following equation describes the output of the GCN at layer <em class="italic">(l+1)</em> at node <em class="italic">i</em>. Here, <em class="italic">N(i)</em> is the set of neighbors of node <em class="italic">I</em> (including itself), <em class="italic">c</em><sub class="italic">ij</sub> is the product of the square root of node degrees, and sigma is an activation function. The <em class="italic">b(l)</em> term is an optional bias term:</p>
<p class="center"><img alt="" height="121" src="../Images/B18331_17_009.png" style="height: 3.02em !important; vertical-align: 0.03em !important;" width="575"/></p>
<p class="normal">Next up, we will look at the graph attention network, a variant of the GCN where the coefficients are learned via an attentional mechanism instead of being explicitly defined.</p>
<h2 class="heading-2" id="_idParaDest-434">Graph attention network</h2>
<p class="normal">The <strong class="keyWord">Graph Attention Network</strong> (<strong class="keyWord">GAT</strong>) layer was proposed by Velickovic, et al. [2]. Like the GCN, the GAT performs local averaging of its <a id="_idIndexMarker1550"/>neighbors’ features. The difference is instead of explicitly<a id="_idIndexMarker1551"/> specifying the normalization term <em class="italic">c</em><sub class="italic">ij</sub>, the GAT allows it to be learned using self-attention over the node features to do so. The corresponding normalization term is written as <img alt="" height="42" src="../Images/B18331_11_021.png" style="height: 1.05em !important; vertical-align: -0.07em !important;" width="25"/> for the GAT, which is computed based on the hidden features of the neighboring nodes and the learned attention vector. Essentially, the idea behind the GAT is to prioritize feature signals from similar neighbor nodes compared to dissimilar ones.</p>
<p class="normal">Every neighbor <img alt="" height="50" src="../Images/B18331_17_011.png" style="height: 1.25em !important; vertical-align: -0.29em !important;" width="46"/> neighborhood <em class="italic">N</em>(<em class="italic">i</em>) of node <em class="italic">i</em> sends its own vector of attentional coefficients <img alt="" height="54" src="../Images/B18331_17_012.png" style="height: 1.35em !important; vertical-align: -0.43em !important;" width="46"/>. The following set of equations describes the output of the GAT at layer (<em class="italic">i+1</em>) for node <em class="italic">i</em>. The attention <img alt="" height="42" src="../Images/B18331_11_021.png" style="height: 1.05em !important; vertical-align: -0.07em !important;" width="25"/> is computed using Bahdanau’s attention model using a feedforward network:</p>
<p class="center"><img alt="" height="113" src="../Images/B18331_17_014.png" style="height: 2.83em !important; vertical-align: 0.03em !important;" width="417"/></p>
<p class="center"><img alt="" height="54" src="../Images/B18331_17_015.png" style="height: 1.35em !important; vertical-align: 0.09em !important;" width="329"/></p>
<p class="center"><img alt="" height="54" src="../Images/B18331_17_016.png" style="height: 1.35em !important; vertical-align: 0.09em !important;" width="567"/></p>
<p class="normal">GCN and GAT architectures are suitable for small to medium-sized networks. The GraphSAGE architecture, described in the next section, is more suitable for larger networks.</p>
<h2 class="heading-2" id="_idParaDest-435">GraphSAGE (sample and aggregate)</h2>
<p class="normal">So far, the convolutions we have considered require that all nodes in the graph be present during the <a id="_idIndexMarker1552"/>training, and are therefore transductive and do not naturally<a id="_idIndexMarker1553"/> generalize to unseen nodes. Hamilton, Ying, and Leskovec [3] proposed GraphSAGE, a general, inductive framework that can generate embeddings for previously unseen nodes. It does so by sampling and aggregating from a node’s local neighborhood. GraphSAGE has proved successful at node classification on temporally evolving networks such as citation graphs and Reddit post data.</p>
<p class="normal">GraphSAGE samples a subset of neighbors instead of using them all. It can define a node neighborhood using random walks and sum up importance scores to determine the optimum sample. An aggregate function can be one of MEAN, GCN, POOL, and LSTM. Mean aggregation simply takes the element-wise mean of the neighbor vectors. The LSTM aggregation is more expressive but is inherently sequential and not symmetric; it is applied on an unordered set<a id="_idIndexMarker1554"/> derived from a random permutation of the node’s neighbors. The POOL aggregation is both symmetric and trainable; here, each neighbor vector is independently fed <a id="_idIndexMarker1555"/>through a fully connected neural network and max pooling is applied across the aggregate information across the neighbor set. </p>
<p class="normal">This set of equations shows how the output for node <em class="italic">i</em> at layer <em class="italic">(l+1)</em> is generated from node <em class="italic">i</em> and its neighbors <em class="italic">N(i)</em> at layer <em class="italic">l</em>:</p>
<p class="center"><img alt="" height="67" src="../Images/B18331_17_017.png" style="height: 1.68em !important;" width="592"/></p>
<p class="center"><img alt="" height="67" src="../Images/B18331_17_018.png" style="height: 1.68em !important;" width="550"/></p>
<p class="center"><img alt="" height="58" src="../Images/B18331_17_019.png" style="height: 1.45em !important; vertical-align: 0.10em !important;" width="367"/></p>
<p class="normal">Now that we have seen strategies for handling large networks using GNNs, we will look at strategies for maximizing the representational (and therefore the discriminative) power of GNNs, using the graph isomorphism network.</p>
<h2 class="heading-2" id="_idParaDest-436">Graph isomorphism network</h2>
<p class="normal">Xu, et al. [4] proposed<a id="_idIndexMarker1556"/> the <strong class="keyWord">Graph Isomorphism Network</strong> (<strong class="keyWord">GIN</strong>) as a graph layer with more expressive power compared to the ones available. Graph layers with high expressive power should be able to distinguish between a pair of graphs that are topologically similar but not identical. They showed that GCNs and GraphSAGE are unable to distinguish certain graph structures. They also showed that SUM aggregation is better than MEAN and MAX aggregation in terms of distinguishing graph structures. The GIN layer thus provides a better way to represent neighbor’s aggregation compared to GCNs and GraphSAGE.</p>
<p class="normal">The following equation shows the output at node <em class="italic">i</em> and layer <em class="italic">(l+1)</em>. Here, the function <em class="italic">f</em><sub class="italic">θ</sub> is a callable activation function, <em class="italic">aggregate</em> is an aggregation function such as SUM, MAX, or MEAN, and <img alt="" height="42" src="../Images/B18331_10_003.png" style="height: 1.05em !important; vertical-align: -0.07em !important;" width="21"/> is a learnable parameter that will be learned over the course of the training:</p>
<p class="center"><img alt="" height="63" src="../Images/B18331_17_021.png" style="height: 1.57em !important; vertical-align: 0.05em !important;" width="825"/></p>
<p class="normal">Having been introduced to<a id="_idIndexMarker1557"/> several popular GNN architectures, let us now direct our attention to the kind of tasks we can do with GNNs.</p>
<h1 class="heading-1" id="_idParaDest-437">Common graph applications</h1>
<p class="normal">We will now look at some common applications <a id="_idIndexMarker1558"/>of GNNs. Typically, applications fall into one of the three major classes listed below. In this section, we will see code examples on how to build and train GNNs for each of these tasks, using TensorFlow and DGL:</p>
<ul>
<li class="bulletList">Node classification</li>
<li class="bulletList">Graph classification</li>
<li class="bulletList">Edge classification (or link prediction)</li>
</ul>
<p class="normal">There are other applications of GNNs as well, such as graph clustering or generative graph models, but they are less common and we will not consider them here.</p>
<h2 class="heading-2" id="_idParaDest-438">Node classification</h2>
<p class="normal">Node classification is a popular task<a id="_idIndexMarker1559"/> on graph data. Here, a model is trained to predict the node category. Non-graph classification methods can use the node feature vectors alone to do so, and some pre-GNN methods such as DeepWalk and node2vec can use the adjacency matrix alone, but GNNs are the first class of techniques that can use both the node feature vectors and the connectivity information together to do node classification.</p>
<p class="normal">Essentially, the idea is to apply one or more graph convolutions (as described in the previous section) to all nodes of a graph, to project the feature vector of the node to a corresponding output category vector that can be used to predict the node category. Our node classification example will use the CORA dataset, a collection of 2,708 scientific papers classified into one of seven categories. The papers are organized into a citation network, which contains 5,429 links. Each paper is described by a word vector of size 1,433.</p>
<p class="normal">We first set up our imports. If you have not already done so, you will need to install the DGL library into your environment with <code class="inlineCode">pip install dgl</code>. You will also need to set the environment variable <code class="inlineCode">DGLBACKEND</code> to<a id="_idIndexMarker1560"/> TensorFlow. On the command line, this is achieved by the command <code class="inlineCode">export DGLBACKEND=tensorflow</code>, and in a notebook environment, you can try using the magic <code class="inlineCode">%env DGLBACKEND=tensorflow</code>:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> dgl
<span class="hljs-keyword">import</span> dgl.data
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> tensorflow_addons <span class="hljs-keyword">as</span> tfa
<span class="hljs-keyword">from</span> dgl.nn.tensorflow <span class="hljs-keyword">import</span> GraphConv
</code></pre>
<p class="normal">The CORA dataset is pre-packaged as a DGL dataset, so we load the dataset into memory using the following call:</p>
<pre class="programlisting code"><code class="hljs-code">dataset = dgl.data.CoraGraphDataset()
</code></pre>
<p class="normal">The first time this is called, it will log that it is downloading and extracting to a local file. Once done, it will print out some useful statistics about the CORA dataset. As you can see, there are 2,708 nodes and 10,566 edges in the graph. Each node has a feature vector of size 1,433 and a node is categorized as being in one of seven classes. In addition, we see that it has 140 training samples, 500 validation samples, and 1,000 test samples:</p>
<pre class="programlisting con"><code class="hljs-con">  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done saving data into cached files.
</code></pre>
<p class="normal">Since this is a graph dataset, it is expected to contain data pertaining to a set of graphs. However, CORA is a single citation graph. You can verify this by <code class="inlineCode">len(dataset)</code>, which will give you <code class="inlineCode">1</code>. This also means that downstream code will work on the graph given by <code class="inlineCode">dataset[0]</code> rather than on the complete dataset. The node features will be contained in the dictionary <code class="inlineCode">dataset[0].ndata</code> as key-value pairs, and the edge features in <code class="inlineCode">dataset[0].edata</code>. The <code class="inlineCode">ndata</code> contains the keys <code class="inlineCode">train_mask</code>, <code class="inlineCode">val_mask</code>, and <code class="inlineCode">test_mask</code>, which are Boolean masks signifying which nodes are part of the train, validation, and test splits, respectively, and a <code class="inlineCode">feat</code> key, which contains the feature vector for each node in the graph.</p>
<p class="normal">We will build a <code class="inlineCode">NodeClassifier</code> network with two <code class="inlineCode">GraphConv</code> layers. Each layer will compute a new node representation by aggregating neighbor information. <code class="inlineCode">GraphConv</code> layers are just simple <code class="inlineCode">tf.keras.layers.Layer</code> objects and can therefore be stacked. The first <code class="inlineCode">GraphConv</code> layer projects the incoming feature size (1,433) to a hidden feature vector of size 16, and the second <code class="inlineCode">GraphConv</code> layer projects the hidden feature vector to an output category vector of size 2, from which the category is read.</p>
<p class="normal">Note that <code class="inlineCode">GraphConv</code> is just <a id="_idIndexMarker1561"/>one of many graph layers that we can drop into the <code class="inlineCode">NodeClassifier</code> model. DGL makes available a variety of graph convolution layers that can be used to replace <code class="inlineCode">GraphConv</code> if needed:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">NodeClassifier</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.Model</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, g, in_feats, h_feats, num_classes</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>(NodeClassifier, self).__init__()
    self.g = g
    self.conv1 = GraphConv(in_feats, h_feats, activation=tf.nn.relu)
    self.conv2 = GraphConv(h_feats, num_classes)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, in_feat</span><span class="hljs-function">):</span>
    h = self.conv1(self.g, in_feat)
    h = self.conv2(self.g, h)
    <span class="hljs-keyword">return</span> h
g = dataset[<span class="hljs-number">0</span>]
model = NodeClassifier(
  g, g.ndata[<span class="hljs-string">"feat"</span>].shape[<span class="hljs-number">1</span>], <span class="hljs-number">16</span>, dataset.num_classes)
</code></pre>
<p class="normal">We will train this model with the CORA dataset using the code shown below. We will use the <code class="inlineCode">AdamW</code> optimizer (a variation of the more popular <code class="inlineCode">Adam </code>optimizer that results in models with better generalization capabilities), with a learning rate of <em class="italic">1e-2</em> and weight decay of <em class="italic">5e-4</em>. We will train for 200 epochs. Let us also detect if we have a GPU available, and if so, assign the graph to the GPU. </p>
<p class="normal">TensorFlow will automatically move the model to the GPU if the GPU is detected:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">set_gpu_if_available</span><span class="hljs-function">():</span>
  device = <span class="hljs-string">"/cpu:0"</span>
  gpus = tf.config.list_physical_devices(<span class="hljs-string">"GPU"</span>)
  <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(gpus) &gt; <span class="hljs-number">0</span>:
    device = gpus[<span class="hljs-number">0</span>]
  <span class="hljs-keyword">return</span> device
device = set_gpu_if_available()
g = g.to(device)
</code></pre>
<p class="normal">We also define a <code class="inlineCode">do_eval()</code> method that computes the accuracy given the features and the Boolean mask for the split being<a id="_idIndexMarker1562"/> evaluated:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">do_eval</span><span class="hljs-function">(</span><span class="hljs-params">model, features, labels, mask</span><span class="hljs-function">):</span>
  logits = model(features, training=<span class="hljs-literal">False</span>)
  logits = logits[mask]
  labels = labels[mask]
  preds = tf.math.argmax(logits, axis=<span class="hljs-number">1</span>)
  acc = tf.reduce_mean(tf.cast(preds == labels, dtype=tf.float32))
  <span class="hljs-keyword">return</span> acc.numpy().item()
</code></pre>
<p class="normal">Finally, we are ready to set up and run our training loop as follows:</p>
<pre class="programlisting code"><code class="hljs-code">NUM_HIDDEN = <span class="hljs-number">16</span>
LEARNING_RATE = <span class="hljs-number">1e-2</span>
WEIGHT_DECAY = <span class="hljs-number">5e-4</span>
NUM_EPOCHS = <span class="hljs-number">200</span>
<span class="hljs-keyword">with</span> tf.device(device):
  feats = g.ndata[<span class="hljs-string">"feat"</span>]
  labels = g.ndata[<span class="hljs-string">"label"</span>]
  train_mask = g.ndata[<span class="hljs-string">"train_mask"</span>]
  val_mask = g.ndata[<span class="hljs-string">"val_mask"</span>]
  test_mask = g.ndata[<span class="hljs-string">"test_mask"</span>]
  in_feats = feats.shape[<span class="hljs-number">1</span>]
  n_classes = dataset.num_classes
  n_edges = dataset[<span class="hljs-number">0</span>].number_of_edges()
  model = NodeClassifier(g, in_feats, NUM_HIDDEN, n_classes)
  loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>)
  optimizer = tfa.optimizers.AdamW(
    learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
  best_val_acc, best_test_acc = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>
  history = []
  <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_EPOCHS):
    <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:
      logits = model(feats)
      loss = loss_fcn(labels[train_mask], logits[train_mask])
      grads = tape.gradient(loss, model.trainable_weights)
      optimizer.apply_gradients(<span class="hljs-built_in">zip</span>(grads, model.trainable_weights))
    
    val_acc = do_eval(model, feats, labels, val_mask)
    history.append((epoch + <span class="hljs-number">1</span>, loss.numpy().item(), val_acc))
    <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
      print(<span class="hljs-string">"Epoch {:3d} | train loss: {:.3f} | val acc: {:.3f}"</span>.<span class="hljs-built_in">format</span>(
         epoch, loss.numpy().item(), val_acc))
</code></pre>
<p class="normal">The output of the training<a id="_idIndexMarker1563"/> run shows the training loss decreasing from <code class="inlineCode">1.9</code> to <code class="inlineCode">0.02</code> and the validation accuracy increasing from <code class="inlineCode">0.13</code> to <code class="inlineCode">0.78</code>:</p>
<pre class="programlisting con"><code class="hljs-con">Epoch   0 | train loss: 1.946 | val acc: 0.134
Epoch  10 | train loss: 1.836 | val acc: 0.544
Epoch  20 | train loss: 1.631 | val acc: 0.610
Epoch  30 | train loss: 1.348 | val acc: 0.688
Epoch  40 | train loss: 1.032 | val acc: 0.732
Epoch  50 | train loss: 0.738 | val acc: 0.760
Epoch  60 | train loss: 0.504 | val acc: 0.774
Epoch  70 | train loss: 0.340 | val acc: 0.776
Epoch  80 | train loss: 0.233 | val acc: 0.780
Epoch  90 | train loss: 0.164 | val acc: 0.780
Epoch 100 | train loss: 0.121 | val acc: 0.784
Epoch 110 | train loss: 0.092 | val acc: 0.784
Epoch 120 | train loss: 0.073 | val acc: 0.784
Epoch 130 | train loss: 0.059 | val acc: 0.784
Epoch 140 | train loss: 0.050 | val acc: 0.786
Epoch 150 | train loss: 0.042 | val acc: 0.786
Epoch 160 | train loss: 0.037 | val acc: 0.786
Epoch 170 | train loss: 0.032 | val acc: 0.784
Epoch 180 | train loss: 0.029 | val acc: 0.784
Epoch 190 | train loss: 0.026 | val acc: 0.784
</code></pre>
<p class="normal">We can now evaluate our trained node classifier against the hold-out test split:</p>
<pre class="programlisting code"><code class="hljs-code">test_acc = do_eval(model, feats, labels, test_mask)
print(<span class="hljs-string">"Test acc: {:.3f}"</span>.<span class="hljs-built_in">format</span>(test_acc))
</code></pre>
<p class="normal">This prints out the overall <a id="_idIndexMarker1564"/>accuracy of the model against the hold-out test split:</p>
<pre class="programlisting con"><code class="hljs-con">Test acc: 0.779
</code></pre>
<h2 class="heading-2" id="_idParaDest-439">Graph classification</h2>
<p class="normal">Graph classification is done by predicting some attribute of the entire graph by aggregating all node features and <a id="_idIndexMarker1565"/>applying one or more graph convolutions to it. This could be useful, for example, when trying to classify molecules during drug discovery as having a particular therapeutic property. In this section, we will showcase graph classification using an example.</p>
<p class="normal">In order to run the example, please make sure DGL is installed and set to use the TensorFlow backend; refer to the previous section on node classification for information on how to do this. To begin the example, let us import the necessary libraries:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> dgl.data
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> tensorflow_addons <span class="hljs-keyword">as</span> tfa
<span class="hljs-keyword">from</span> dgl.nn <span class="hljs-keyword">import</span> GraphConv
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
</code></pre>
<p class="normal">We will use the protein dataset from DGL. The dataset is a set of graphs, each with node features and a single label. Each graph represents a protein molecule and each node in the graph represents an atom in the molecule. Node features list the chemical properties of the atom. The label indicates if the protein molecule is an enzyme:</p>
<pre class="programlisting code"><code class="hljs-code">dataset = dgl.data.GINDataset(<span class="hljs-string">"</span><span class="hljs-string">PROTEINS"</span>, self_loop=<span class="hljs-literal">True</span>)
print(<span class="hljs-string">"node feature dimensionality:"</span>, dataset.dim_nfeats)
print(<span class="hljs-string">"number of graph categories:"</span>, dataset.gclasses)
print(<span class="hljs-string">"number of graphs in dataset:"</span>, <span class="hljs-built_in">len</span>(dataset))
</code></pre>
<p class="normal">The call above downloads the protein dataset locally and prints out some information about the dataset. As you can see, each node has a feature vector of size <code class="inlineCode">3</code>, the number of graph categories is <code class="inlineCode">2</code> (enzyme or not), and the number of graphs in the dataset is <code class="inlineCode">1113</code>:</p>
<pre class="programlisting con"><code class="hljs-con">node feature dimensionality: 3
number of graph categories: 2
number of graphs in dataset: 1113
</code></pre>
<p class="normal">We will first split the dataset into training, validation, and test. We will use the training dataset to train our GNN, validate using the validation dataset, and publish the results of our final model against the test dataset:</p>
<pre class="programlisting code"><code class="hljs-code">tv_dataset, test_dataset = train_test_split(
  dataset, shuffle=<span class="hljs-literal">True</span>, test_size=<span class="hljs-number">0.2</span>)
train_dataset, val_dataset = train_test_split(
  tv_dataset, test_size=<span class="hljs-number">0.1</span>)
print(<span class="hljs-built_in">len</span>(train_dataset), <span class="hljs-built_in">len</span>(val_dataset), <span class="hljs-built_in">len</span>(test_dataset))
</code></pre>
<p class="normal">This splits the dataset into <a id="_idIndexMarker1566"/>a training, validation, and test split of 801, 89, and 223 graphs, respectively. Since our datasets are large, we need to train our network using mini-batches so as not to overwhelm GPU memory. So, this example will also demonstrate mini-batch processing using our data.</p>
<p class="normal">Next, we define our GNN for graph classification. This consists of two <code class="inlineCode">GraphConv</code> layers stacked together that will encode the nodes into their hidden representations. Since the objective is to predict a single category for each graph, we need to aggregate all the node representations into a graph-level representation, which we do by averaging the node representations using <code class="inlineCode">dgl.mean_nodes()</code>:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">GraphClassifier</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.Model</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, in_feats, h_feats, num_classes</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>(GraphClassifier, self).__init__()
    self.conv1 = GraphConv(in_feats, h_feats, activation=tf.nn.relu)
    self.conv2 = GraphConv(h_feats, num_classes)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, g, in_feat</span><span class="hljs-function">):</span>
    h = self.conv1(g, in_feat)
    h = self.conv2(g, h)
    g.ndata[<span class="hljs-string">"h"</span>] = h
    <span class="hljs-keyword">return</span> dgl.mean_nodes(g, <span class="hljs-string">"h"</span>)
</code></pre>
<p class="normal">For the training, we set the training parameters and the <code class="inlineCode">do_eval()</code> function:</p>
<pre class="programlisting code"><code class="hljs-code">HIDDEN_SIZE = <span class="hljs-number">16</span>
BATCH_SIZE = <span class="hljs-number">16</span>
LEARNING_RATE = <span class="hljs-number">1e-2</span>
NUM_EPOCHS = <span class="hljs-number">20</span>
device = set_gpu_if_available()
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">do_eval</span><span class="hljs-function">(</span><span class="hljs-params">model, dataset</span><span class="hljs-function">):</span>
  total_acc, total_recs = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>
  indexes = tf.data.Dataset.from_tensor_slices(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(dataset)))
  indexes = indexes.batch(batch_size=BATCH_SIZE)
  <span class="hljs-keyword">for</span> batched_indexes <span class="hljs-keyword">in</span> indexes:
    graphs, labels = <span class="hljs-built_in">zip</span>(*[dataset[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> batched_indexes])
    batched_graphs = dgl.batch(graphs)
    batched_labels = tf.convert_to_tensor(labels, dtype=tf.int64)
    batched_graphs = batched_graphs.to(device)
    logits = model(batched_graphs, batched_graphs.ndata[<span class="hljs-string">"attr"</span>])
    batched_preds = tf.math.argmax(logits, axis=<span class="hljs-number">1</span>)
    acc = tf.reduce_sum(tf.cast(batched_preds == batched_labels,
                                dtype=tf.float32))
    total_acc += acc.numpy().item()
    total_recs += <span class="hljs-built_in">len</span>(batched_labels)
  <span class="hljs-keyword">return</span> total_acc / total_recs
</code></pre>
<p class="normal">Finally, we define and run our training<a id="_idIndexMarker1567"/> loop to train our <code class="inlineCode">GraphClassifier</code> model. We use the <code class="inlineCode">Adam</code> optimizer with a learning rate of <code class="inlineCode">1e-2</code> and the <code class="inlineCode">SparseCategoricalCrossentropy</code> as the loss function, training, or <code class="inlineCode">20</code> epochs:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">with</span> tf.device(device):
  model = GraphClassifier(
    dataset.dim_nfeats, HIDDEN_SIZE, dataset.gclasses)
  optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)
  loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=<span class="hljs-literal">True</span>)
  train_indexes = tf.data.Dataset.from_tensor_slices(
    <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(train_dataset)))
  train_indexes = train_indexes.batch(batch_size=BATCH_SIZE)
  <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_EPOCHS):
    total_loss = <span class="hljs-number">0</span>
    <span class="hljs-keyword">for</span> batched_indexes <span class="hljs-keyword">in</span> train_indexes:
      <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:
        graphs, labels = <span class="hljs-built_in">zip</span>(*[train_dataset[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> batched_indexes])
        batched_graphs = dgl.batch(graphs)
        batched_labels = tf.convert_to_tensor(labels, dtype=tf.int32)
        batched_graphs = batched_graphs.to(device)
        logits = model(batched_graphs, batched_graphs.ndata[<span class="hljs-string">"attr"</span>])
        loss = loss_fcn(batched_labels, logits)
        grads = tape.gradient(loss, model.trainable_weights)
        optimizer.apply_gradients(<span class="hljs-built_in">zip</span>(grads, model.trainable_weights))
        total_loss += loss.numpy().item()
  
    val_acc = do_eval(model, val_dataset)
    print(<span class="hljs-string">"Epoch {:3d} | train_loss: {:.3f} | val_acc: {:.3f}"</span>.<span class="hljs-built_in">format</span>(
        epoch, total_loss, val_acc))
</code></pre>
<p class="normal">The output shows that the loss<a id="_idIndexMarker1568"/> decreases and validation accuracy increases as the <code class="inlineCode">GraphClassifier</code> model is trained over 20 epochs:</p>
<pre class="programlisting con"><code class="hljs-con">Epoch   0 | train_loss: 34.401 | val_acc: 0.629
Epoch   1 | train_loss: 33.868 | val_acc: 0.629
Epoch   2 | train_loss: 33.554 | val_acc: 0.618
Epoch   3 | train_loss: 33.184 | val_acc: 0.640
Epoch   4 | train_loss: 32.822 | val_acc: 0.652
Epoch   5 | train_loss: 32.499 | val_acc: 0.663
Epoch   6 | train_loss: 32.227 | val_acc: 0.663
Epoch   7 | train_loss: 32.009 | val_acc: 0.697
Epoch   8 | train_loss: 31.830 | val_acc: 0.685
Epoch   9 | train_loss: 31.675 | val_acc: 0.685
Epoch  10 | train_loss: 31.580 | val_acc: 0.685
Epoch  11 | train_loss: 31.525 | val_acc: 0.708
Epoch  12 | train_loss: 31.485 | val_acc: 0.708
Epoch  13 | train_loss: 31.464 | val_acc: 0.708
Epoch  14 | train_loss: 31.449 | val_acc: 0.708
Epoch  15 | train_loss: 31.431 | val_acc: 0.708
Epoch  16 | train_loss: 31.421 | val_acc: 0.708
Epoch  17 | train_loss: 31.411 | val_acc: 0.708
Epoch  18 | train_loss: 31.404 | val_acc: 0.719
Epoch  19 | train_loss: 31.398 | val_acc: 0.719
</code></pre>
<p class="normal">Finally, we evaluate the trained model against our hold-out test dataset:</p>
<pre class="programlisting code"><code class="hljs-code">test_acc = do_eval(model, test_dataset)
print(<span class="hljs-string">"test accuracy: {:.3f}"</span>.<span class="hljs-built_in">format</span>(test_acc))
</code></pre>
<p class="normal">This prints out the accuracy of the trained <code class="inlineCode">GraphClassifier</code> model against the held-out test split:</p>
<pre class="programlisting con"><code class="hljs-con">test accuracy: 0.677
</code></pre>
<p class="normal">The accuracy shows that the<a id="_idIndexMarker1569"/> model can successfully identify a molecule as an enzyme or non-enzyme slightly less than 70% of the time.</p>
<h2 class="heading-2" id="_idParaDest-440">Link prediction</h2>
<p class="normal">Link prediction is a type of edge classification problem, where the task is to predict if an edge exists between two given nodes in the <a id="_idIndexMarker1570"/>graph. </p>
<p class="normal">Many applications, such as social recommendation, knowledge graph completion, etc., can be formulated as link prediction, which predicts whether an edge exists between a pair of nodes. In this example, we will predict if a citation relationship, either citing or cited, exists between two papers in a citation network.</p>
<p class="normal">The general approach would be to treat all edges in the graph as positive examples and sample a number of non-existent edges as negative examples and train the link prediction classifier for binary classification (edge exists or not) on these positive and negative examples.</p>
<p class="normal">Before running the example, please make sure DGL is installed and set to use the TensorFlow backend; refer to the <em class="italic">Node classification</em> section for information on how to do this. Let us start by importing the necessary libraries:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> dgl
<span class="hljs-keyword">import</span> dgl.data
<span class="hljs-keyword">import</span> dgl.function <span class="hljs-keyword">as</span> fn
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> itertools
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> scipy.sparse <span class="hljs-keyword">as</span> sp
<span class="hljs-keyword">from</span> dgl.nn <span class="hljs-keyword">import</span> SAGEConv
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score
</code></pre>
<p class="normal">For our data, we will reuse the CORA citation graph from the DGL datasets that we had used for our node classification example earlier. We already know what the dataset looks like, so we won’t dissect it again here. If you would like to refresh your memory, please refer to the node classification example for the relevant details:</p>
<pre class="programlisting code"><code class="hljs-code">dataset = dgl.data.CoraGraphDataset()
g = dataset[<span class="hljs-number">0</span>]
</code></pre>
<p class="normal">Now, let us prepare our data. For training our link prediction model, we need a set of positive edges and a set of negative edges. Positive edges are one of the 10,556 edges that already exist in the CORA citation graph, and negative edges are going to be 10,556 node pairs without connecting <a id="_idIndexMarker1571"/>edges sampled from the rest of the graph. In addition, we need to split both the positive and negative edges into training, validation, and test splits:</p>
<pre class="programlisting code"><code class="hljs-code">u, v = g.edges()
<span class="hljs-comment"># positive edges</span>
eids = np.arange(g.number_of_edges())
eids = np.random.permutation(eids)
test_size = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(eids) * <span class="hljs-number">0.2</span>)
val_size = <span class="hljs-built_in">int</span>((<span class="hljs-built_in">len</span>(eids) - test_size) * <span class="hljs-number">0.1</span>)
train_size = g.number_of_edges() - test_size - val_size
u = u.numpy()
v = v.numpy()
test_pos_u = u[eids[<span class="hljs-number">0</span>:test_size]]
test_pos_v = v[eids[<span class="hljs-number">0</span>:test_size]]
val_pos_u = u[eids[test_size:test_size + val_size]]
val_pos_v = v[eids[test_size:test_size + val_size]]
train_pos_u = u[eids[test_size + val_size:]]
train_pos_v = v[eids[test_size + val_size:]]
<span class="hljs-comment"># negative edges</span>
adj = sp.coo_matrix((np.ones(<span class="hljs-built_in">len</span>(u)), (u, v)))
adj_neg = <span class="hljs-number">1</span> - adj.todense() - np.eye(g.number_of_nodes())
neg_u, neg_v = np.where(adj_neg != <span class="hljs-number">0</span>)
neg_eids = np.random.choice(<span class="hljs-built_in">len</span>(neg_u), g.number_of_edges())
test_neg_u = neg_u[neg_eids[:test_size]]
test_neg_v = neg_v[neg_eids[:test_size]]
val_neg_u = neg_u[neg_eids[test_size:test_size + val_size]]
val_neg_v = neg_v[neg_eids[test_size:test_size + val_size]]
train_neg_u = neg_u[neg_eids[test_size + val_size:]]
train_neg_v = neg_v[neg_eids[test_size + val_size:]]
<span class="hljs-comment"># remove edges from training graph</span>
test_edges = eids[:test_size]
val_edges = eids[test_size:test_size + val_size]
train_edges = eids[test_size + val_size:]
train_g = dgl.remove_edges(g, np.concatenate([test_edges, val_edges]))
</code></pre>
<p class="normal">We now construct a GNN that will compute the node representation using two <code class="inlineCode">GraphSAGE</code> layers, each<a id="_idIndexMarker1572"/> layer computing the node representation by averaging its neighbor information:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">LinkPredictor</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.Model</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, g, in_feats, h_feats</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>(LinkPredictor, self).__init__()
    self.g = g
    self.conv1 = SAGEConv(in_feats, h_feats, <span class="hljs-string">'mean'</span>)
    self.relu1 = tf.keras.layers.Activation(tf.nn.relu)
    self.conv2 = SAGEConv(h_feats, h_feats, <span class="hljs-string">'mean'</span>)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, in_feat</span><span class="hljs-function">):</span>
    h = self.conv1(self.g, in_feat)
    h = self.relu1(h)
    h = self.conv2(self.g, h)
    <span class="hljs-keyword">return</span> h
</code></pre>
<p class="normal">However, link prediction requires us to compute representations of pairs of nodes, DGL recommends that you treat the pairs of nodes as another graph since you can define a pair of nodes as an edge. For link prediction, we will have a positive graph containing all the positive examples as edges, and a negative graph containing all the negative examples as edges. Both positive and negative graphs contain the same set of nodes as the original graph:</p>
<pre class="programlisting code"><code class="hljs-code">train_pos_g = dgl.graph((train_pos_u, train_pos_v), 
  num_nodes=g.number_of_nodes())
train_neg_g = dgl.graph((train_neg_u, train_neg_v), 
  num_nodes=g.number_of_nodes())
val_pos_g = dgl.graph((val_pos_u, val_pos_v), 
  num_nodes=g.number_of_nodes())
val_neg_g = dgl.graph((val_neg_u, val_neg_v), 
  num_nodes=g.number_of_nodes())
test_pos_g = dgl.graph((test_pos_u, test_pos_v), 
  num_nodes=g.number_of_nodes())
test_neg_g = dgl.graph((test_neg_u, test_neg_v), 
  num_nodes=g.number_of_nodes())
</code></pre>
<p class="normal">Next, we will define a predictor class that will take the set of node representations from the <code class="inlineCode">LinkPredictor</code> class and use the <code class="inlineCode">DGLGraph.apply_edges</code> method to compute edge feature scores, which are the <a id="_idIndexMarker1573"/>dot product of the source node features and the destination node features (both output together from the <code class="inlineCode">LinkPredictor</code> in this case):</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">DotProductPredictor</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.Model</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, g, h</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">with</span> g.local_scope():
      g.ndata[<span class="hljs-string">'h'</span>] = h
      <span class="hljs-comment"># Compute a new edge feature named 'score' by a dot-product </span>
      <span class="hljs-comment"># between the source node feature 'h' and destination node </span>
      <span class="hljs-comment"># feature 'h'.</span>
      g.apply_edges(fn.u_dot_v(<span class="hljs-string">'h'</span>, <span class="hljs-string">'h'</span>, <span class="hljs-string">'score'</span>))
      <span class="hljs-comment"># u_dot_v returns a 1-element vector for each edge so you </span>
      <span class="hljs-comment"># need to squeeze it.</span>
      <span class="hljs-keyword">return</span> g.edata[<span class="hljs-string">'score'</span>][:, <span class="hljs-number">0</span>]
</code></pre>
<p class="normal">You can also build a custom predictor such as a multi-layer perceptron with two dense layers, as the following code shows. Note that the <code class="inlineCode">apply_edges</code> method describes how the edge score is calculated:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">MLPPredictor</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.Model</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, h_feats</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>().__init__()
    self.W1 = tf.keras.layers.Dense(h_feats, activation=tf.nn.relu)
    self.W2 = tf.keras.layers.Dense(<span class="hljs-number">1</span>)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">apply_edges</span><span class="hljs-function">(</span><span class="hljs-params">self, edges</span><span class="hljs-function">):</span>
    h = tf.concat([edges.src[<span class="hljs-string">"h"</span>], edges.dst[<span class="hljs-string">"h"</span>]], axis=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> {
      <span class="hljs-string">"score"</span>: self.W2(self.W1(h))[:, <span class="hljs-number">0</span>]
    }
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, g, h</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">with</span> g.local_scope():
      g.ndata[<span class="hljs-string">'h'</span>] = h
      g.apply_edges(self.apply_edges)
      <span class="hljs-keyword">return</span> g.edata[<span class="hljs-string">'score'</span>]
</code></pre>
<p class="normal">We instantiate the <code class="inlineCode">LinkPredictor</code> model we defined earlier, select the <code class="inlineCode">Adam</code> optimizer, and declare our loss function to be <code class="inlineCode">BinaryCrossEntropy</code> (since our task is binary classification). The predictor head that we will use in our example is the <code class="inlineCode">DotProductPredictor</code>. However, the <code class="inlineCode">MLPPredictor</code> can be used as a drop-in replacement instead; just <a id="_idIndexMarker1574"/>replace the <code class="inlineCode">pred</code> variable below to point to the <code class="inlineCode">MLPPredictor</code> instead of the <code class="inlineCode">DotProductPredictor</code>:</p>
<pre class="programlisting code"><code class="hljs-code">HIDDEN_SIZE = <span class="hljs-number">16</span>
LEARNING_RATE = <span class="hljs-number">1e-2</span>
NUM_EPOCHS = <span class="hljs-number">100</span>
model = LinkPredictor(train_g, train_g.ndata[<span class="hljs-string">'feat'</span>].shape[<span class="hljs-number">1</span>], 
    HIDDEN_SIZE)
optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)
loss_fcn = tf.keras.losses.BinaryCrossentropy(from_logits=<span class="hljs-literal">True</span>)
pred = DotProductPredictor()
</code></pre>
<p class="normal">We also define a couple of convenience functions for our training loop. The first one computes the loss between the scores returned from the positive graph and the negative graphs, and the second computes<a id="_idIndexMarker1575"/> the <strong class="keyWord">Area Under the Curve</strong> (<strong class="keyWord">AUC</strong>) from the two scores. AUC is a popular metric to evaluate binary classification models:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">compute_loss</span><span class="hljs-function">(</span><span class="hljs-params">pos_score, neg_score</span><span class="hljs-function">):</span>
    scores = tf.concat([pos_score, neg_score], axis=<span class="hljs-number">0</span>)
    labels = tf.concat([
      tf.ones(pos_score.shape[<span class="hljs-number">0</span>]),
      tf.zeros(neg_score.shape[<span class="hljs-number">0</span>])
    ], axis=<span class="hljs-number">0</span>
)
    <span class="hljs-keyword">return</span> loss_fcn(labels, scores)
<span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">compute_auc</span><span class="hljs-function">(</span><span class="hljs-params">pos_score, neg_score</span><span class="hljs-function">):</span>
    scores = tf.concat([pos_score, neg_score], axis=<span class="hljs-number">0</span>).numpy()
    labels = tf.concat([
      tf.ones(pos_score.shape[<span class="hljs-number">0</span>]),
      tf.zeros(neg_score.shape[<span class="hljs-number">0</span>])
    ], axis=<span class="hljs-number">0</span>).numpy()
    <span class="hljs-keyword">return</span> roc_auc_score(labels, scores)
</code></pre>
<p class="normal">We now train our <code class="inlineCode">LinkPredictor</code> GNN for 100 epochs of training, using the following training loop:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_EPOCHS):
  in_feat = train_g.ndata[<span class="hljs-string">"feat"</span>]
  <span class="hljs-keyword">with</span> tf.GradientTape() <span class="hljs-keyword">as</span> tape:
    h = model(in_feat)
    pos_score = pred(train_pos_g, h)
    neg_score = pred(train_neg_g, h)
    loss = compute_loss(pos_score, neg_score)
    grads = tape.gradient(loss, model.trainable_weights)
    optimizer.apply_gradients(<span class="hljs-built_in">zip</span>(grads, model.trainable_weights))
  val_pos_score = pred(val_pos_g, h)
  val_neg_score = pred(val_neg_g, h)
  val_auc = compute_auc(val_pos_score, val_neg_score)
  <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">5</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">"Epoch {:3d} | train_loss: {:.3f}, val_auc: {:.3f}"</span>.<span class="hljs-built_in">format</span>(
      epoch, loss, val_auc))
</code></pre>
<p class="normal">This returns the following <a id="_idIndexMarker1576"/>training logs:</p>
<pre class="programlisting con"><code class="hljs-con">Epoch   0 | train_loss: 0.693, val_auc: 0.566
Epoch   5 | train_loss: 0.681, val_auc: 0.633
Epoch  10 | train_loss: 0.626, val_auc: 0.746
Epoch  15 | train_loss: 0.569, val_auc: 0.776
Epoch  20 | train_loss: 0.532, val_auc: 0.805
Epoch  25 | train_loss: 0.509, val_auc: 0.820
Epoch  30 | train_loss: 0.492, val_auc: 0.824
Epoch  35 | train_loss: 0.470, val_auc: 0.833
Epoch  40 | train_loss: 0.453, val_auc: 0.835
Epoch  45 | train_loss: 0.431, val_auc: 0.842
Epoch  50 | train_loss: 0.410, val_auc: 0.851
Epoch  55 | train_loss: 0.391, val_auc: 0.859
Epoch  60 | train_loss: 0.371, val_auc: 0.861
Epoch  65 | train_loss: 0.350, val_auc: 0.861
Epoch  70 | train_loss: 0.330, val_auc: 0.861
Epoch  75 | train_loss: 0.310, val_auc: 0.862
Epoch  80 | train_loss: 0.290, val_auc: 0.860
Epoch  85 | train_loss: 0.269, val_auc: 0.856
Epoch  90 | train_loss: 0.249, val_auc: 0.852
Epoch  95 | train_loss: 0.228, val_auc: 0.848
</code></pre>
<p class="normal">We can now evaluate the trained model against the hold-out test set:</p>
<pre class="programlisting code"><code class="hljs-code">pos_score = tf.stop_gradient(pred(test_pos_g, h))
neg_score = tf.stop_gradient(pred(test_neg_g, h))
print(<span class="hljs-string">'Test AUC'</span>, compute_auc(pos_score, neg_score))
</code></pre>
<p class="normal">This returns the following test AUC for our <code class="inlineCode">LinkPredictor</code> GNN:</p>
<pre class="programlisting con"><code class="hljs-con">Test AUC 0.8266960571287392
</code></pre>
<p class="normal">This is quite impressive <a id="_idIndexMarker1577"/>as it implies that the link predictor can correctly predict 82% of the links presented as ground truths in the test set.</p>
<h1 class="heading-1" id="_idParaDest-441">Graph customizations</h1>
<p class="normal">We have seen how to build and train GNNs for common graph ML tasks. However, for convenience, we have chosen to use prebuilt DGL graph convolution layers in our models. While unlikely, it is possible that you might need a layer that is not provided with the DGL package. DGL provides a <a id="_idIndexMarker1578"/>message passing API to allow you to build custom graph layers easily. In the first part of this section, we will look at an example where we use the message-passing API to build a custom graph convolution layer.</p>
<p class="normal">We have also loaded datasets from the DGL data package for our examples. It is far more likely that we will need to use our own data instead. So, in the second part of this section, we will see how to convert our own data into a DGL dataset.</p>
<h2 class="heading-2" id="_idParaDest-442">Custom layers and message passing</h2>
<p class="normal">Although DGL provides many <a id="_idIndexMarker1579"/>graph layers out of the box, there may be cases where the ones provided don’t meet our needs exactly and we need to build your<a id="_idIndexMarker1580"/> own. </p>
<p class="normal">Fortunately, all these graph layers are based on a common underlying concept of message passing between <a id="_idIndexMarker1581"/>nodes in the graph. So, in order to build a custom GNN layer, you need to understand how the message-passing paradigm works. This paradigm is also<a id="_idIndexMarker1582"/> known as the <strong class="keyWord">Message Passing Neural Network</strong> (<strong class="keyWord">MPNN</strong>) framework [5]:</p>
<p class="center"><img alt="" height="58" src="../Images/B18331_17_022.png" style="height: 1.45em !important;" width="554"/></p>
<p class="center"><img alt="" height="113" src="../Images/B18331_17_023.png" style="height: 2.83em !important; vertical-align: 0.03em !important;" width="313"/></p>
<p class="center"><img alt="" height="58" src="../Images/B18331_17_024.png" style="height: 1.45em !important;" width="379"/></p>
<p class="normal">Each node <em class="italic">u</em> in the graph has a hidden state (initially its feature vector) represented by <em class="italic">h</em><sub class="italic">u</sub>. For each node <em class="italic">u</em> and <em class="italic">v</em>, where nodes <em class="italic">u</em> and <em class="italic">v</em> are neighbors, i.e., connected by an edge <em class="italic">e</em><sub class="italic">u-&gt;v</sub>, we apply some <a id="_idIndexMarker1583"/>function <em class="italic">M</em> called the <em class="italic">message function</em>. The message function <em class="italic">M</em> is applied to every node on the graph. We then aggregate the output of <em class="italic">M</em> for all nodes with the output of all their neighboring nodes to produce the message <em class="italic">m</em>. Here <img alt="" height="46" src="../Images/B18331_07_002.png" style="height: 1.15em !important; vertical-align: -0.20em !important;" width="29"/> is <a id="_idIndexMarker1584"/>called the <em class="italic">reduce function</em>. Note that even though we represent the reduce function by the summation symbol <img alt="" height="46" src="../Images/B18331_07_002.png" style="height: 1.15em !important; vertical-align: -0.20em !important;" width="29"/>, it can be any aggregation function. Finally, we update the hidden state of node <em class="italic">v</em> using the obtained message and the previous state <a id="_idIndexMarker1585"/>of the node. The function <em class="italic">U</em> applied at this step<a id="_idIndexMarker1586"/> is called the <em class="italic">update function</em>.</p>
<p class="normal">The message-passing algorithm is repeated a specific number of times. After that, we reach the <em class="italic">readout phase</em> where we extract the feature vector from each node that represents the entire graph. For example, the final feature vector for a node might represent the node category in the case of node classification.</p>
<p class="normal">In this section, we will use the MPNN framework to implement a GraphSAGE layer. Even though DGL provides the <code class="inlineCode">dgl.nn.SAGEConv</code>, which implements this already, this is an example to illustrate the creation of custom graph layers using MPNN. The message-passing steps of a GraphSAGE layer are given by:</p>
<p class="center"><img alt="" height="58" src="../Images/B18331_17_027.png" style="height: 1.45em !important;" width="517"/></p>
<p class="center"><img alt="" height="58" src="../Images/B18331_17_028.png" style="height: 1.45em !important;" width="658"/></p>
<p class="normal">The code to implement our custom GraphSAGE layer using MPNN is shown below. The DGL function <code class="inlineCode">update_all</code> call allows you to specify a <code class="inlineCode">message_fn</code> and a <code class="inlineCode">reduce_fn</code>, which are also DGL built-in functions, and the <code class="inlineCode">tf.concat</code> and <code class="inlineCode">Dense</code> layers represent the final update function:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> dgl
<span class="hljs-keyword">import</span> dgl.data
<span class="hljs-keyword">import</span> dgl.function <span class="hljs-keyword">as</span> fn
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">CustomGraphSAGE</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.layers.Layer</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, in_feat, out_feat</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>(CustomGraphSAGE, self).__init__()
    <span class="hljs-comment"># A linear submodule for projecting the input and neighbor </span>
    <span class="hljs-comment"># feature to the output.</span>
    self.linear = tf.keras.layers.Dense(out_feat, activation=tf.nn.relu)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, g, h</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">with</span> g.local_scope():
        g.ndata[<span class="hljs-string">"h"</span>] = h
        <span class="hljs-comment"># update_all is a message passing API.</span>
        g.update_all(message_func=fn.copy_u(<span class="hljs-string">'h'</span>, <span class="hljs-string">'m'</span>),
                     reduce_func=fn.mean(<span class="hljs-string">'m'</span>, <span class="hljs-string">'h_N'</span>))
        h_N = g.ndata[<span class="hljs-string">'h_N'</span>]
        h_total = tf.concat([h, h_N], axis=<span class="hljs-number">1</span>)
        <span class="hljs-keyword">return</span> self.linear(h_total)
</code></pre>
<p class="normal">Here, we see that the <code class="inlineCode">update_all</code> function specifies a <code class="inlineCode">message_func</code>, which just copies the node’s current feature vector to <a id="_idIndexMarker1587"/>a message vector <em class="italic">m</em>, and then averages all the message vectors in the neighborhood of each node. As you can see, this faithfully follows the first GraphSAGE equation above. DGL provides many <a id="_idIndexMarker1588"/>such built-in functions (<a href="https://docs.dgl.ai/api/python/dgl.function.xhtml"><span class="url">https://docs.dgl.ai/api/python/dgl.function.xhtml</span></a>).</p>
<p class="normal">Once the neighborhood vector <em class="italic">h_N</em> is computed in the first step, it is concatenated with the input feature vector <em class="italic">h</em>, and then passed through a <code class="inlineCode">Dense</code> layer with a ReLU activation, as described by the second equation for GraphSAGE above. We have thus implemented the GraphSAGE layer with our <code class="inlineCode">CustomGraphSAGE</code> object.</p>
<p class="normal">The next step is to put it into a GNN to see how it works. The following code shows a <code class="inlineCode">CustomGNN</code> model that uses two layers of our custom <code class="inlineCode">SAGEConv</code> implementation:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">CustomGNN</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.Model</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, g, in_feats, h_feats, num_classes</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>(CustomGNN, self).__init__()
    self.g = g
    self.conv1 = CustomGraphSAGE(in_feats, h_feats)
    self.relu1 = tf.keras.layers.Activation(tf.nn.relu)
    self.conv2 = CustomGraphSAGE(h_feats, num_classes)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, in_feat</span><span class="hljs-function">):</span>
    h = self.conv1(self.g, in_feat)
    h = self.relu1(h)
    h = self.conv2(self.g, h)
    <span class="hljs-keyword">return</span> h
</code></pre>
<p class="normal">We will run it to do node classification against the CORA dataset, details of which should be familiar from previous examples.</p>
<p class="normal">The above code assumes an <a id="_idIndexMarker1589"/>unweighted graph, i.e., edges between nodes have the same weight. This condition is true for the CORA dataset, where each edge represents a citation from one paper to another. </p>
<p class="normal">However, we can imagine scenarios where edges may be weighted based on how many times some edge <a id="_idIndexMarker1590"/>has been invoked, for example, an edge that connects a product and a user for user recommendations. </p>
<p class="normal">The only change we need to make to handle weighted edges is to allow the weight to play a part in our message function. That is, if an edge between our node <code class="inlineCode">u</code> and a neighbor node <code class="inlineCode">v</code> occurs <code class="inlineCode">k</code> times, we should consider that edge <code class="inlineCode">k</code> times. The code below shows our custom GraphSAGE layer with the ability to handle weighted edges:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">CustomWeightedGraphSAGE</span><span class="hljs-class">(</span><span class="hljs-params">tf.keras.layers.Layer</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self, in_feat, out_feat</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>(CustomWeightedGraphSAGE, self).__init__()
    <span class="hljs-comment"># A linear submodule for projecting the input and neighbor </span>
    <span class="hljs-comment"># feature to the output.</span>
    self.linear = tf.keras.layers.Dense(out_feat, activation=tf.nn.relu)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">call</span><span class="hljs-function">(</span><span class="hljs-params">self, g, h, w</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">with</span> g.local_scope():
      g.ndata[<span class="hljs-string">'h'</span>] = h
      g.edata[<span class="hljs-string">'w'</span>] = w
      g.update_all(message_func=fn.u_mul_e(<span class="hljs-string">'h'</span>, <span class="hljs-string">'w'</span>, <span class="hljs-string">'m'</span>),
                   reduce_func=fn.mean(<span class="hljs-string">'m'</span>, <span class="hljs-string">'h_N'</span>))
      h_N = g.ndata[<span class="hljs-string">'h_N'</span>]
      h_total = tf.concat([h, h_N], axis=<span class="hljs-number">1</span>)
      <span class="hljs-keyword">return</span> self.linear(h_total)
</code></pre>
<p class="normal">This code expects an additional edge property <em class="italic">w</em>, which contains the edge weights, which you can simulate on the CORA dataset by:</p>
<pre class="programlisting code"><code class="hljs-code">g.edata[<span class="hljs-string">"w"</span>] = tf.cast(
   tf.random.uniform((g.num_edges(), <span class="hljs-number">1</span>), minval=<span class="hljs-number">3</span>, maxval=<span class="hljs-number">10</span>, 
                     dtype=tf.int32),
   dtype=tf.float32)
</code></pre>
<p class="normal">The <code class="inlineCode">message_func</code> in <code class="inlineCode">CustomWeightedGraphSAGE</code> has changed from simply copying the feature vector <em class="italic">h</em> to the message vector <em class="italic">m</em>, to multiplying <em class="italic">h</em> and <em class="italic">w</em> to produce the message vector <em class="italic">m</em>. Everything<a id="_idIndexMarker1591"/> else is the same as in <code class="inlineCode">CustomGraphSAGE</code>. The new <code class="inlineCode">CustomWeightedGraphSAGE</code> layer can now be simply<a id="_idIndexMarker1592"/> dropped into the calling class <code class="inlineCode">CustomGNN</code> where <code class="inlineCode">CustomGraphSAGE</code> was originally being called.</p>
<h2 class="heading-2" id="_idParaDest-443">Custom graph dataset</h2>
<p class="normal">A more common use case that you are likely to face is to use your own data to train a GNN model. Obviously, in such cases, you <a id="_idIndexMarker1593"/>cannot use a DGL-provided dataset (as we have been using in all our examples so far) and you must wrap your data into a custom graph dataset. </p>
<p class="normal">Your custom graph dataset should inherit from the <code class="inlineCode">dgl.data.DGLDataset</code> object provided by DGL and implement the following methods:</p>
<ul>
<li class="bulletList"><code class="inlineCode">__getitem__(self, i)</code> – retrieve the <code class="inlineCode">i</code>-th example from the dataset. The retrieved example contains a single DGL graph and its label if applicable.</li>
<li class="bulletList"><code class="inlineCode">__len__(self)</code> – the number of examples in the dataset.</li>
<li class="bulletList"><code class="inlineCode">process(self)</code> – defines how to load and process raw data from the disk.</li>
</ul>
<p class="normal">As we have seen before, node classification and link prediction operate on a single graph, and graph classification operates on a set of graphs. While the approach is largely identical for both cases, there are some concerns specific to either case, so we will provide an example to do each of these below.</p>
<h3 class="heading-3" id="_idParaDest-444">Single graphs in datasets</h3>
<p class="normal">For our example, we will choose <a id="_idIndexMarker1594"/>Zachary’s Karate Club graph, which represents the members of a Karate Club observed over three years. Over time, there was a disagreement between an administrator (Officer) and the instructor (Mr. Hi), and the club members split and reformed under the Officer and Mr. Hi (shown below as blue and red nodes, respectively). The Zachary Karate Club network is available for download from the NetworkX library:</p>
<figure class="mediaobject"><img alt="A picture containing plant, red  Description automatically generated" height="405" src="../Images/B18331_17_02.png" width="580"/></figure>
<p class="packt_figref">Figure 17.2: Graph representation of the Karate Club Network</p>
<p class="normal">The graph contains 34 nodes labeled with one of “Officer” or “Mr. Hi” depending on which group they ended up in after the split. It contains 78 edges, which are undirected and unweighted. An edge<a id="_idIndexMarker1595"/> between a pair of members indicates that they interact with each other outside the club. To make this dataset more realistic for GNN usage, we will attach a 10-dimensional random feature vector to each node, and an edge weight as an edge feature. Here is the code to convert the Karate Club graph into a DGL dataset that you can then use for downstream node or edge classification tasks:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">KarateClubDataset</span><span class="hljs-class">(</span><span class="hljs-params">DGLDataset</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>().__init__(name=<span class="hljs-string">"karate_club"</span>)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__getitem__</span><span class="hljs-function">(</span><span class="hljs-params">self, i</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> self.graph
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__len__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">process</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
    G = nx.karate_club_graph()
    nodes = [node <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> G.nodes]
    edges = [edge <span class="hljs-keyword">for</span> edge <span class="hljs-keyword">in</span> G.edges]
    node_features = tf.random.uniform(
        (<span class="hljs-built_in">len</span>(nodes), <span class="hljs-number">10</span>), minval=<span class="hljs-number">0</span>, maxval=<span class="hljs-number">1</span>, dtype=tf.dtypes.float32)
    label2int = {<span class="hljs-string">"Mr. Hi"</span>: <span class="hljs-number">0</span>, <span class="hljs-string">"Officer"</span>: <span class="hljs-number">1</span>}
    node_labels = tf.convert_to_tensor(
        [label2int[G.nodes[node][<span class="hljs-string">"club"</span>]] <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> nodes])
    edge_features = tf.random.uniform(
        (<span class="hljs-built_in">len</span>(edges), <span class="hljs-number">1</span>), minval=<span class="hljs-number">3</span>, maxval=<span class="hljs-number">10</span>, dtype=tf.dtypes.int32)
    edges_src = tf.convert_to_tensor([u <span class="hljs-keyword">for</span> u, v <span class="hljs-keyword">in</span> edges])
    edges_dst = tf.convert_to_tensor([v <span class="hljs-keyword">for</span> u, v <span class="hljs-keyword">in</span> edges])
    self.graph = dgl.graph((edges_src, edges_dst), num_nodes=<span class="hljs-built_in">len</span>(nodes))
    self.graph.ndata[<span class="hljs-string">"feat"</span>] = node_features
    self.graph.ndata[<span class="hljs-string">"</span><span class="hljs-string">label"</span>] = node_labels
    self.graph.edata[<span class="hljs-string">"weight"</span>] = edge_features
    <span class="hljs-comment"># assign masks indicating the split (training, validation, test)</span>
    n_nodes = <span class="hljs-built_in">len</span>(nodes)
    n_train = <span class="hljs-built_in">int</span>(n_nodes * <span class="hljs-number">0.6</span>)
    n_val = <span class="hljs-built_in">int</span>(n_nodes * <span class="hljs-number">0.2</span>)
    train_mask = tf.convert_to_tensor(
      np.hstack([np.ones(n_train), np.zeros(n_nodes - n_train)]),
      dtype=tf.<span class="hljs-built_in">bool</span>)
    val_mask = tf.convert_to_tensor(
      np.hstack([np.zeros(n_train), np.ones(n_val), 
                 np.zeros(n_nodes - n_train - n_val)]),
      dtype=tf.<span class="hljs-built_in">bool</span>)
    test_mask = tf.convert_to_tensor(
      np.hstack([np.zeros(n_train + n_val), 
                 np.ones(n_nodes - n_train - n_val)]),
      dtype=tf.<span class="hljs-built_in">bool</span>)
    self.graph.ndata[<span class="hljs-string">"train_mask"</span>] = train_mask
    self.graph.ndata[<span class="hljs-string">"val_mask"</span>] = val_mask
    self.graph.ndata[<span class="hljs-string">"test_mask"</span>] = test_mask
</code></pre>
<p class="normal">Most of the logic is in the <code class="inlineCode">process</code> method. We call the NetworkX method to get the Karate Club as a NetworkX graph, then convert it to a DGL graph object with node features and labels. Even though the Karate Club graph does not have node and edge features defined, we manufacture some random numbers and set them to these properties. Note that this is only for purposes of this example, to show where these features would need to be<a id="_idIndexMarker1596"/> updated if your graph had node and edge features. Note that the dataset contains a single graph.</p>
<p class="normal">In addition, we also want to split the graph into training, validation, and test splits for node classification purposes. For that, we assign masks indicating whether a node belongs to one of these splits. We do this rather simply by splitting the nodes in the graph 60/20/20 and assigning Boolean masks for each split.</p>
<p class="normal">In order to instantiate this dataset from our code, we can say:</p>
<pre class="programlisting code"><code class="hljs-code">dataset = KarateClubDataset()
g = dataset[<span class="hljs-number">0</span>]
print(g)
</code></pre>
<p class="normal">This will give us the following output (reformatted a little for readability). The two main structures are the <code class="inlineCode">ndata_schemas</code> and <code class="inlineCode">edata_schemas</code>, accessible as <code class="inlineCode">g.ndata</code> and <code class="inlineCode">g.edata</code>, respectively. Within <code class="inlineCode">ndata_schemas</code>, we have keys that point to the node features (<code class="inlineCode">feats</code>), node labels (<code class="inlineCode">label</code>), and the masks to indicate the training, validation, and test splits (<code class="inlineCode">train_mask</code>, <code class="inlineCode">val_mask</code>, and <code class="inlineCode">test_mask</code>), respectively. Under <code class="inlineCode">edata_schemas</code>, there is the <code class="inlineCode">weight</code> attribute that indicates the edge weights:</p>
<pre class="programlisting con"><code class="hljs-con">Graph(num_nodes=34, 
      num_edges=78,
      ndata_schemes={
        'feat': Scheme(shape=(10,), dtype=tf.float32),
        'label': Scheme(shape=(), dtype=tf.int32),
        'train_mask': Scheme(shape=(), dtype=tf.bool),
        'val_mask': Scheme(shape=(), dtype=tf.bool),
        'test_mask': Scheme(shape=(), dtype=tf.bool)
      }
      edata_schemes={
         'weight': Scheme(shape=(1,), dtype=tf.int32)
      }
)
</code></pre>
<p class="normal">Please refer to the examples on node classification and link prediction for information on how to use this kind of custom dataset.</p>
<h3 class="heading-3" id="_idParaDest-445">Set of multiple graphs in datasets</h3>
<p class="normal">Datasets that support the graph<a id="_idIndexMarker1597"/> classification task will contain multiple graphs and their associated labels, one per graph. For our example, we will consider a hypothetical dataset of molecules represented as graphs, and the task would be to predict if the molecule is toxic or not (a binary prediction).</p>
<p class="normal">We will use the NetworkX method <code class="inlineCode">random_regular_graph()</code> to generate synthetic graphs with a random number of nodes and node degree. To each node of each graph, we will attach a random 10-dimensional feature vector. Each node will have a label (0 or 1) indicating if the graph is toxic. Note that this is just a simulation of what real data might look like. With real data, the structure of each graph and the values of the node vectors, which are random in our case, will have a real impact on the target variable, i.e., the toxicity of the molecule. </p>
<p class="normal">The figure below shows some examples of what the synthetic “molecules” might look like:</p>
<figure class="mediaobject"><img alt="Chart, radar chart  Description automatically generated" height="470" src="../Images/B18331_17_03.png" width="482"/></figure>
<p class="packt_figref">Figure 17.3: Some examples of random regular graphs generated using NetworkX</p>
<p class="normal">Here is the code to convert a set of random NetworkX graphs into a DGL graph dataset for graph classification. We will <a id="_idIndexMarker1598"/>generate 100 such graphs and store them in a list in the form of a DGL dataset:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> networkx.exception <span class="hljs-keyword">import</span> NetworkXError
<span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">SyntheticDataset</span><span class="hljs-class">(</span><span class="hljs-params">DGLDataset</span><span class="hljs-class">):</span>
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__init__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
    <span class="hljs-built_in">super</span>().__init__(name=<span class="hljs-string">"</span><span class="hljs-string">synthetic"</span>)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__getitem__</span><span class="hljs-function">(</span><span class="hljs-params">self, i</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> self.graphs[i], self.labels[i]
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">__len__</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.graphs)
  <span class="hljs-keyword">def</span><span class="hljs-function"> </span><span class="hljs-title">process</span><span class="hljs-function">(</span><span class="hljs-params">self</span><span class="hljs-function">):</span>
    self.graphs, self.labels = [], []
    num_graphs = <span class="hljs-number">0</span>
    <span class="hljs-keyword">while</span>(<span class="hljs-literal">True</span>):
      d = np.random.randint(<span class="hljs-number">3</span>, <span class="hljs-number">10</span>)
      n = np.random.randint(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)
      <span class="hljs-keyword">if</span> ((n * d) % <span class="hljs-number">2</span>) != <span class="hljs-number">0</span>:
        <span class="hljs-keyword">continue</span>
      <span class="hljs-keyword">if</span> n &lt; d:
        <span class="hljs-keyword">continue</span>
      <span class="hljs-keyword">try</span>:
        g = nx.random_regular_graph(d, n)
      <span class="hljs-keyword">except</span> NetworkXError:
        <span class="hljs-keyword">continue</span>
      g_edges = [edge <span class="hljs-keyword">for</span> edge <span class="hljs-keyword">in</span> g.edges]
      g_src = [u <span class="hljs-keyword">for</span> u, v <span class="hljs-keyword">in</span> g_edges]
      g_dst = [v <span class="hljs-keyword">for</span> u, v <span class="hljs-keyword">in</span> g_edges]
      g_num_nodes = <span class="hljs-built_in">len</span>(g.nodes)
      label = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)
      <span class="hljs-comment"># create graph and add to list of graphs and labels</span>
      dgl_graph = dgl.graph((g_src, g_dst), num_nodes=g_num_nodes)
      dgl_graph.ndata[<span class="hljs-string">"feats"</span>] = tf.random.uniform(
          (g_num_nodes, <span class="hljs-number">10</span>), minval=<span class="hljs-number">0</span>, maxval=<span class="hljs-number">1</span>, dtype=tf.dtypes.float32)
      self.graphs.append(dgl_graph)
      self.labels.append(label)
      num_graphs += <span class="hljs-number">1</span>
      <span class="hljs-keyword">if</span> num_graphs &gt; <span class="hljs-number">100</span>:
        <span class="hljs-keyword">break</span>
    self.labels = tf.convert_to_tensor(self.labels, dtype=tf.dtypes.int64)
</code></pre>
<p class="normal">Once created, we can then call it from our code as follows:</p>
<pre class="programlisting code"><code class="hljs-code">dataset = SyntheticDataset()
graph, label = dataset[<span class="hljs-number">0</span>]   
print(graph)
print(<span class="hljs-string">"label:"</span>, label)
</code></pre>
<p class="normal">This produces the following output for the first graph in the DGL dataset (reformatted slightly for readability). As you can see, the first graph in the dataset has <code class="inlineCode">6</code> nodes and <code class="inlineCode">15</code> edges and contains a feature <a id="_idIndexMarker1599"/>vector (accessible using the <code class="inlineCode">feats</code> key) of size <code class="inlineCode">10</code>. The label is a <code class="inlineCode">0</code>-dimensional tensor (i.e., a scalar) of type long (<code class="inlineCode">int64</code>):</p>
<pre class="programlisting con"><code class="hljs-con">Graph(num_nodes=6, num_edges=15,
      ndata_schemes={
        'feats': Scheme(shape=(10,), dtype=tf.float32)}
      edata_schemes={})
label: tf.Tensor(0, shape=(), dtype=int64)
</code></pre>
<p class="normal">As before, in order to see how you would use this custom dataset for some task such as graph classification, please refer to the example on graph classification earlier in this chapter.</p>
<h1 class="heading-1" id="_idParaDest-446">Future directions</h1>
<p class="normal">Graph neural networks are a rapidly evolving discipline. We have covered working with static homogeneous graphs on various popular graph tasks so far, which covers many real-world use cases. However, it is likely that some graphs are neither homogeneous nor static, and neither can they be easily reduced to this form. In this section, we will look at our options for dealing with heterogenous and temporal graphs.</p>
<h2 class="heading-2" id="_idParaDest-447">Heterogeneous graphs</h2>
<p class="normal">Heterogeneous graphs [7], also called heterographs, differ from the graphs we have seen so far in that they may contain different kinds of nodes and edges. These different types of nodes and edges might also <a id="_idIndexMarker1600"/>contain different types of attributes, including possible representations with different dimensions. Popular examples of heterogeneous graphs are citation graphs that contain authors and papers, recommendation graphs that contain users and products, and knowledge graphs that can contain many different types of entities.</p>
<p class="normal">You can use the MPNN framework on heterogeneous graphs by manually implementing message and update functions individually for each edge type. Each edge type is defined by the triple (source node type, edge type, and destination node type). However, DGL provides support for heterogeneous graphs using the <code class="inlineCode">dgl.heterograph()</code> API, where a graph is specified as a series of graphs, one per edge type.</p>
<p class="normal">Typical learning tasks associated with heterogeneous graphs are similar to their homogeneous counterparts, namely node classification and regression, graph classification, and edge classification/link prediction. A popular graph layer for working with heterogeneous graphs is the <strong class="keyWord">Relational GCN</strong> or <strong class="keyWord">R-GCN</strong>, available as a built-in layer in DGL.</p>
<h2 class="heading-2" id="_idParaDest-448">Temporal Graphs</h2>
<p class="normal">Temporal Graphs [8] is a framework developed at Twitter to handle dynamic graphs that change over time. While GNN <a id="_idIndexMarker1601"/>models have primarily focused on static graphs that do not change over time, adding the time dimension allows us to model many interesting phenomena in social networks, financial transactions, and recommender systems, all of which are inherently dynamic. In such systems, it is the dynamic behavior that conveys the important insights.</p>
<p class="normal">A dynamic graph can be represented as a stream of timed events, such as additions and deletions of nodes and edges. This stream of events is fed into an encoder network that learns a time-dependent encoding for each node in the graph. A decoder is trained on this encoding to support some specific task such as link prediction at a future point in time. There is currently no support in the DGL library for Temporal Graphs, mainly because it is a very rapidly evolving research area.</p>
<p class="normal">At a high level, a <strong class="keyWord">Temporal Graph Network</strong> (<strong class="keyWord">TGN</strong>) encoder works by creating a compressed representation of the nodes based on their interaction and updates over time. The current state of each node is stored in TGN memory and acts as the hidden state <em class="italic">s</em><sub class="italic">t</sub> of an RNN; however, we have a separate state vector <em class="italic">s</em><sub class="italic">t</sub><em class="italic">(t) </em>for each node <em class="italic">i</em> and time point <em class="italic">t</em>. </p>
<p class="normal">A message function similar to what we have seen in the MPNN framework computes two messages <em class="italic">m</em><sub class="italic">i</sub> and <em class="italic">m</em><sub class="italic">j</sub> for a pair of nodes <em class="italic">i</em> and <em class="italic">j</em> using the state vectors and their interaction as input. The message and state vectors are then combined using a memory updater, which is usually implemented as an RNN. TGNs have been found to outperform their static <a id="_idIndexMarker1602"/>counterparts on the tasks of future edge prediction and dynamic node classification both in terms of accuracy and speed.</p>
<h1 class="heading-1" id="_idParaDest-449">Summary</h1>
<p class="normal">In this chapter, we have covered graph neural networks, an exciting set of techniques to learn not only from node features but also from the interaction between nodes. We have covered the intuition behind why graph convolutions work and the parallels between them and convolutions in computer vision. We have described some common graph convolutions, which are provided as layers by DGL. We have demonstrated how to use the DGL for popular graph tasks of node classification, graph classification, and link prediction. In addition, in the unlikely event that our needs are not met by standard DGL graph layers, we have learned how to implement our own graph convolution layer using DGL’s message-passing framework. We have also seen how to build DGL datasets for our own graph data. Finally, we look at some emerging directions of graph neural networks, namely heterogeneous graphs and temporal graphs. This should equip you with skills to use GNNs to solve interesting problems in this area.</p>
<p class="normal">In the next chapter, we will turn our attention to learning about some best ML practices associated with deep learning projects.</p>
<h1 class="heading-1" id="_idParaDest-450">References</h1>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Kipf, T. and Welling, M. (2017). <em class="italic">Semi-supervised Classification with Graph Convolutional Networks</em>. Arxiv Preprint, arXiv: 1609.02907 [cs.LG]. Retrieved from <a href="https://arxiv.org/abs/1609.02907"><span class="url">https://arxiv.org/abs/1609.02907</span></a></li>
<li class="numberedList">Velickovic, P., et al. (2018). <em class="italic">Graph Attention Networks</em>. Arxiv Preprint, arXiv 1710.10903 [stat.ML]. Retrieved from <a href="https://arxiv.org/abs/1710.10903"><span class="url">https://arxiv.org/abs/1710.10903</span></a> </li>
<li class="numberedList">Hamilton, W. L., Ying, R., and Leskovec, J. (2017). <em class="italic">Inductive Representation Learning on Large Graphs</em>. Arxiv Preprint, arXiv: 1706.02216 [cs.SI]. Retrieved from <a href="https://arxiv.org/abs/1706.02216"><span class="url">https://arxiv.org/abs/1706.02216</span></a> </li>
<li class="numberedList">Xu, K., et al. (2018). <em class="italic">How Powerful are Graph Neural Networks?</em>. Arxiv Preprint, arXiv: 1810.00826 [cs.LG]. Retrieved from <a href="https://arxiv.org/abs/1810.00826"><span class="url">https://arxiv.org/abs/1810.00826</span></a> </li>
<li class="numberedList">Gilmer, J., et al. (2017). <em class="italic">Neural Message Passing for Quantum Chemistry</em>. Arxiv Preprint, arXiv: 1704.01212 [cs.LG]. Retrieved from <a href="https://arxiv.org/abs/1704.01212"><span class="url">https://arxiv.org/abs/1704.01212</span></a> </li>
<li class="numberedList">Zachary, W. W. (1977). <em class="italic">An Information Flow Model for Conflict and Fission in Small Groups</em>. Journal of Anthropological Research. Retrieved from <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/jar.33.4.3629752"><span class="url">https://www.journals.uchicago.edu/doi/abs/10.1086/jar.33.4.3629752</span></a> </li>
<li class="numberedList">Pengfei, W. (2020). <em class="italic">Working with Heterogeneous Graphs in DGL</em>. Blog post. Retrieved from <a href="https://www.jianshu.com/p/767950b560c4"><span class="url">https://www.jianshu.com/p/767950b560c4</span></a> </li>
<li class="numberedList">Bronstein, M. (2020). <em class="italic">Temporal Graph Networks</em>. Blog post. Retrieved from <a href="https://towardsdatascience.com/temporal-graph-networks-ab8f327f2efe"><span class="url">https://towardsdatascience.com/temporal-graph-networks-ab8f327f2efe</span></a> </li>
</ol>
<h1 class="heading-1">Join our book’s Discord space</h1>
<p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 2000 members at: <a href="https://packt.link/keras"><span class="url">https://packt.link/keras</span></a></p>
<p class="normal"><img alt="" height="177" src="../Images/QR_Code1831217224278819687.png" width="177"/></p>
</div>
</div>
</body></html>