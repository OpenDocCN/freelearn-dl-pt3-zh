<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Creating Your First Deep Learning Web Application</h1>
                </header>
            
            <article>
                
<p>After developing an understanding of neural networks and their setup for use in real-world projects, the natural next step is to develop a web-based deep learning application. This chapter is dedicated to creating a complete web application—a<span>lbeit a very simplistic one—</span><span>that, in a very simple way, demonstrates how the integration of deep learning in applications is done.</span></p>
<p><span>This chapter will introduce several terms that will be used throughout this book, and so it is a recommended read even</span> <span>for</span> <span>those of you who already have a basic understanding of deep learning web applications so that you are able to understand the terms used in future chapters. We will begin by structuring a deep learning web application and learning how to understand datasets. We will then implement a simple neural network using Python and create a Flask API to work with server-side Python.</span></p>
<p>In this chapter, the following topics will be covered:</p>
<ul>
<li style="font-weight: 400;">Structuring a deep learning web application</li>
<li style="font-weight: 400;">Understanding datasets</li>
<li style="font-weight: 400;">Implementing a simple neural network using Python</li>
<li style="font-weight: 400;">Creating a Flask API that works with server-side Python</li>
<li style="font-weight: 400;">Using cURL and the web client with Flask</li>
<li style="font-weight: 400;">Improving the deep learning backend</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p><span>You can access the code used in this chapter at</span> <a href="https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter3">https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-web/tree/master/Chapter3</a>.</p>
<p>For this chapter, you'll need the following:</p>
<ul>
<li>Python 3.6+</li>
<li>Flask 1.1.0+</li>
<li>TensorFlow 2.0+</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Structuring a deep learning web application</h1>
                </header>
            
            <article>
                
<p>When solving a jigsaw puzzle, it is important that the parts fit, rather than them being forced together. Similarly, when developing a software solution, the parts of the solution must seamlessly work together and their interaction must be simple to understand. Good software requires proper software planning. Hence, providing a solid structure to the software is essential for its long-term use and for easy future maintenance.</p>
<p>Before we begin creating our first deep learning application that works on the web, we must chalk out a blueprint of the solution, keeping in mind the problems we wish to solve and the solutions to them. This is much like how we plan authentication systems or pass form values from one page to another during website development.</p>
<p>A general deep learning web solution would need the following components:</p>
<ul>
<li style="font-weight: 400;">A server that can store data and respond with queries</li>
<li style="font-weight: 400;">A system that can use the stored data and process it to produce deep learning-based responses to queries</li>
<li style="font-weight: 400;">A client that can send data to the server for storage, send queries with new data, and finally, accept and use the responses the server sends after querying the deep learning system</li>
</ul>
<p>Let's try to visualize this structure using a diagram.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A structure diagram of a general deep learning web application</h1>
                </header>
            
            <article>
                
<p>The following diagram depicts the interaction between the web client, web server, and the deep learning model:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1295 image-border" src="assets/f8763b49-1e75-456b-85d4-6b65ae1d8286.png" style="width:24.92em;height:22.75em;"/></p>
<p>We will be creating three software parts—the client, the server, and the deep learning model—which will all work together. To do so, the client will make HTTP requests to the server and the server, in return, will produce output fetched from the separately trained deep learning model. This model may or may not be executed in the files present on the server that respond to the HTTP requests made by the client. In most cases, the deep learning model is separated from the file that handles the HTTP requests.</p>
<p>In the example presented in this chapter, we will present the server, the client, and the deep learning model in separate files. Our client will send simple HTTP requests to the server, such as a page-load request or a <kbd>GET</kbd> request for URLs, which will produce the output from the deep learning model based on the queries passed. However, it is very common practice for the client to communicate with the server via REST APIs.</p>
<p>Let's now move on to understanding the dataset that our application will work on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding datasets</h1>
                </header>
            
            <article>
                
<p>It is of the utmost importance that we properly understand the dataset that we are working on in order to produce the best results—<span>in terms of execution time and space</span> <span>for the data—with the most efficient code. The dataset we will be using here is probably the most popular dataset when it comes to using neural networks with images—the MNIST database of handwritten digits.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The MNIST dataset of handwritten digits</h1>
                </header>
            
            <article>
                
<p>This dataset was created by a team made up of Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. It is a large collection of images of handwritten digits, containing 60,000 training samples and 10,000 testing samples. The dataset is publicly available for download at <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> where it is present in the form of four <kbd>.gz</kbd> compressed files.</p>
<p>The four files are as follows:</p>
<ul>
<li style="font-weight: 400;"><kbd>train-images-idx3-ubyte.gz</kbd>: The training set images. These images will be used to train the neural network classifier.</li>
<li style="font-weight: 400;"><kbd>train-labels-idx1-ubyte.gz</kbd>: The training set labels. Every image in the training set will have a label associated with it, which is the corresponding digit visible in that image.</li>
<li style="font-weight: 400;"><kbd>t10k-images-idx3-ubyte.gz</kbd>: The test set images. We will use these images to test our neural network prediction accuracy.</li>
<li style="font-weight: 400;"><kbd>t10k-labels-idx1-ubyte.gz</kbd>: The labels for the images in the test set. When our neural network makes predictions on the test set, we will compare them against these values to check our results.</li>
</ul>
<p>The images stored in this dataset are not directly available for viewing due to their custom format. The developer working on the dataset is expected to create their own simple viewer for the images. Once you have done this, you will be able to see the images, which look something like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1296 image-border" src="assets/b1fb5c7a-789d-4a36-88df-0aab844dd80a.png" style="width:61.17em;height:20.25em;"/></p>
<p class="mce-root">Let's talk about the images in a bit more depth. They are, as you can see, a little over the 25 pixels mark on both axes. To be exact, the images are all in the form of 28 x 28 pixels. Now, since the images are grayscale, it is possible for them to be stored in a single layer 28 x 28 matrix. Hence, we have a total of 784 values, ranging from 0 to 1, where 0 represents an entirely dark pixel and 1 represents a white pixel. Anything inside that range is a shade of black. In the MNIST dataset, these images are present in the form of a flattened array of 784 floating point numbers. In order to view these images, you need to convert the single dimension array into a two-dimensional array with a 28 x 28 shape and then plot the image using any self-developed or publicly available tools, such as Matplotlib or the Pillow library.</p>
<p>Let's discuss this method in the upcoming section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the dataset</h1>
                </header>
            
            <article>
                
<p>Let's begin by downloading all four files from the MNIST dataset web page, available at <a href="http://yann.lecun.com/exdb/mnist">http://yann.lecun.com/exdb/mnist</a>. Once downloaded, extract all the files and you should have folders that resemble the names in the following list:</p>
<ul>
<li style="font-weight: 400;"><kbd>train-images.idx3-ubyte</kbd></li>
<li style="font-weight: 400;"><kbd>train-labels.idx1-ubyte</kbd></li>
<li style="font-weight: 400;"><kbd>t10k-images.idx3-ubyte</kbd></li>
<li style="font-weight: 400;"><kbd>t10k-labels.idx1-ubyte</kbd></li>
</ul>
<p>Keep these files in your working directory. We will now create a Jupyter notebook to perform <strong>exploratory data analysis</strong> (<strong>EDA</strong>) on the dataset files we have extracted.</p>
<p>Open your Jupyter Notebook environment in your browser and create a new Python notebook. Let's begin by importing the necessary modules:</p>
<pre><strong>import numpy as np</strong><br/><strong>import matplotlib.pyplot as plt</strong></pre>
<p>The preceding lines import the <kbd>numpy</kbd> <span>module</span> <span>and</span> <kbd>matplotlib.pyplot</kbd> <span>to the project. The</span> <kbd>numpy</kbd> <span>module provides high-performance mathematical functions in Python while the</span> <kbd>matplotlib.pyplot</kbd> <span>module provides a simple interface to plot and visualize graphs and images. In order to view all the output from this library in the Jupyter notebook, add the following line of code:</span></p>
<pre><strong>%matplotlib inline</strong></pre>
<div class="packt_infobox">If you are on Windows, to extract a <kbd>.gz</kbd> file you can use the 7-zip <span>software, which is an excellent compression/decompression tool that is available to download for free at</span> <a href="https://www.7-zip.org">https://www.7-zip.org</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating functions to read the image files</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, it is not possible to directly view the images in your downloaded image files. So, we will now create a function in Python that the <kbd>matplotlib</kbd> module will be able to use to display the images in the files:</p>
<pre class="mce-root">def loadImageFile(fileimage):<br/>  f = open(fileimage, "rb")<br/><br/>  f.read(16)<br/>  pixels = 28*28<br/>  images_arr = []<br/>    <br/>  while True:<br/>    try:<br/>      img = []<br/>      for j in range(pixels):<br/>        pix = ord(f.read(1))<br/>        img.append(pix / 255)<br/>      images_arr.append(img)<br/>    except:<br/>      break<br/><br/>  f.close()<br/>  image_sets = np.array(images_arr)<br/>  return image_sets<br/><br/></pre>
<p>The preceding <kbd>loadImageFile</kbd> <span>function</span> <span>takes a single parameter, which is the name of the file that contains the images. We have two such files available for us in our downloaded files folder:</span> <kbd>train-images-idx3-ubyte</kbd> <span>and</span> <kbd>t10k-images-idx3-ubyte</kbd><span>. The output of the preceding function is a <kbd>numpy</kbd> array of images. We can store the result in a Python variable, as shown:</span></p>
<pre>test_images = loadImageFile("t10k-images-idx3-ubyte")</pre>
<p>Now, to view the images that are in the variable holding the <kbd>numpy</kbd> array of images, we can define another function that takes a single image's pixel array of 784 floating point numbers and plots them into a single image. The function can be defined as shown:</p>
<pre>def gen_image(arr):<br/> two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)<br/> plt.imshow(two_d, interpolation='nearest', cmap='gray')<br/> plt.show()<br/> return</pre>
<p>Now, say we want to display the first of the test images; because we have stored the <kbd>numpy</kbd> array of images in the <kbd>test_images</kbd> variable, we can run the following code:</p>
<pre>gen_image(test_images[0])</pre>
<p>We are able to see the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1297 image-border" src="assets/67d8fcf8-1084-4a0e-aa5e-39b2ee798280.png" style="width:21.25em;height:21.00em;"/></p>
<p>Now that we are able to view the images, we can proceed to building a function that will allow us to extract the corresponding digit from the labels.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating functions to read label files</h1>
                </header>
            
            <article>
                
<p>There are two label files available to us in the MNIST dataset: <kbd>train-labels-idx1-ubyte</kbd> and <kbd>t10k-labels-idx1-ubyte</kbd>. To view these files, we can use the following function, which takes input of the filename as an argument and produces an array of one-hot-encoded labels:</p>
<pre>def loadLabelFile(filelabel):<br/>  f = open(filelabel, "rb")<br/><br/>  f.read(8)<br/><br/>  labels_arr = []<br/><br/>  while True:<br/>    row = [0 for x in range(10)]<br/>    try:<br/>      label = ord(f.read(1))<br/>      row[label] = 1<br/>      labels_arr.append(row)<br/>    except:<br/>      break<br/><br/>  f.close()<br/>  label_sets = np.array(labels_arr)<br/>  return label_sets</pre>
<p>This function returns a <kbd>numpy</kbd> array of labels in one-hot encoding, with the dimensions of the number of samples in the dataset times by 10. Let's observe a single entry in order to understand the nature of one-hot encoding. Run the following code, which essentially makes a print of the one-hot-encoded label set from the first sample in the test set:</p>
<pre>test_labels = loadLabelFile("t10k-labels-idx1-ubyte")<br/>print(test_labels[0])</pre>
<p>We get the following output:</p>
<pre><strong>[0 0 0 0 0 0 0 1 0 0]</strong></pre>
<p>We can understand this by noting that since the digit at the seventh index is <kbd>1</kbd>, the label of the first image in the test dataset is <kbd>7</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A summary of the dataset</h1>
                </header>
            
            <article>
                
<p>After a very concise exploration of the available dataset, we are able to come up with the following results.</p>
<p>The training dataset contains 60,000 images with a dimension of 60,000 x 784, where each image is 28 x 28 pixels. The distribution of samples among the digits are as follows:</p>
<div>
<table style="border-collapse: collapse;" border="1">
<tbody>
<tr>
<td>
<p><strong>Digit</strong></p>
</td>
<td>
<p><strong>Number of Samples</strong></p>
</td>
<td>
<p><strong>Digit</strong></p>
</td>
<td>
<p><strong>Number of Samples</strong></p>
</td>
</tr>
<tr>
<td>
<p>0</p>
</td>
<td>
<p>5,923</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>5,421</p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>6,742</p>
</td>
<td>
<p>6</p>
</td>
<td>
<p>5,918</p>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>5,958</p>
</td>
<td>
<p>7</p>
</td>
<td>
<p>6,265</p>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>6,131</p>
</td>
<td>
<p>8</p>
</td>
<td>
<p>5,851</p>
</td>
</tr>
<tr>
<td>
<p>4</p>
</td>
<td>
<p>5,842</p>
</td>
<td>
<p>9</p>
</td>
<td>
<p>5,949</p>
</td>
</tr>
</tbody>
</table>
</div>
<p> </p>
<p>Observe that digit <kbd>5</kbd> has a smaller number of samples than digit <kbd>1</kbd>. So, it is quite possible that a model that isn't finely trained will make mistakes in recognizing digit <kbd>5</kbd>.</p>
<p>The summary of the number of labels present tells us that all 60,000 samples have their corresponding labels and none of their labels are missing.</p>
<p>Similarly, on the test dataset, we have 10,000 images and labels and the distribution of the number of samples is as follows:</p>
<div>
<table style="border-collapse: collapse;" border="1">
<tbody>
<tr>
<td>
<p><strong>Digit</strong></p>
</td>
<td>
<p><strong>Number of Samples</strong></p>
</td>
<td>
<p><strong>Digit</strong></p>
</td>
<td>
<p><strong>Number of Samples</strong></p>
</td>
</tr>
<tr>
<td>
<p>0</p>
</td>
<td>
<p>980</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>892</p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>1,135</p>
</td>
<td>
<p>6</p>
</td>
<td>
<p>958</p>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>1,032</p>
</td>
<td>
<p>7</p>
</td>
<td>
<p>1,028</p>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>1,010</p>
</td>
<td>
<p>8</p>
</td>
<td>
<p>974</p>
</td>
</tr>
<tr>
<td>
<p>4</p>
</td>
<td>
<p>982</p>
</td>
<td>
<p>9</p>
</td>
<td>
<p>1,009</p>
</td>
</tr>
</tbody>
</table>
</div>
<p> </p>
<p>The number of samples in the test dataset is quite evenly spread.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing a simple neural network using Python</h1>
                </header>
            
            <article>
                
<p>After doing a very basic data analysis, we can move on to coding our first neural network in Python. You can revise the concepts of neural networks <span>in <a href="9a68dbce-f50e-4c5a-80e2-2b7f40e082ca.xhtml" target="_blank" rel="noopener noreferrer">Chapter 2</a>, <em>Getting Started With Deep Learning Using Python</em></span>, before moving on. We will now be creating a <strong>convolutional neural network</strong> (<strong>CNN</strong>), which will predict the handwritten digit labels.</p>
<p>We start by creating a new Jupyter notebook. You could name this <kbd>Model.ipynb</kbd> for convention. This notebook will be used to develop a <strong>pickled</strong> version of the deep learning model, which will later be put in a script that will generate predictions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing the necessary modules</h1>
                </header>
            
            <article>
                
<p>The modules that will be needed for <kbd>Model.ipynb</kbd> are imported as follows:</p>
<pre>import numpy as np<br/>import keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Activation<br/>from keras.layers import Conv2D, MaxPooling2D<br/>from keras import backend as K<br/>from keras.layers.normalization import BatchNormalization</pre>
<p>The <span><kbd>keras</kbd></span> module is required to quickly implement high-performance neural networks with the TensorFlow backend. We have talked about Keras in earlier chapters. To install Keras, you can use the following command:</p>
<pre><strong>pip3 install keras<br/></strong></pre>
<p>The preceding command will install Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reusing our functions to load the image and label files</h1>
                </header>
            
            <article>
                
<p>Remember the <kbd>loadImageFile</kbd> and <kbd>loadLabelFile</kbd> functions we created during the exploration of the dataset? We will need them again and so we will copy those same functions into this notebook.</p>
<p>Together, they produce two cells of code for each of the functions:</p>
<ul>
<li>The <kbd>loadImageFile()</kbd> method</li>
<li>The <kbd>loadLabelFile()</kbd> method</li>
</ul>
<p>In a new code cell, we create the <kbd>loadImageFile()</kbd> function:</p>
<pre>def loadImageFile(fileimage):<br/>  f = open(fileimage, "rb")<br/><br/>  f.read(16)<br/>  pixels = 28*28<br/>  images_arr = []<br/>    <br/>  while True:<br/>    try:<br/>      img = []<br/>      for j in range(pixels):<br/>        pix = ord(f.read(1))<br/>        img.append(pix / 255)<br/>      images_arr.append(img)<br/>    except:<br/>      break<br/><br/>  f.close()<br/>  image_sets = np.array(images_arr)<br/>  return image_sets</pre>
<p>In another new code cell, the <kbd>loadLabelFile()</kbd> function is created:</p>
<pre>def loadLabelFile(filelabel):<br/>  f = open(filelabel, "rb")<br/>  f.read(8)<br/><br/>  labels_arr = []<br/><br/>  while True:<br/>    row = [0 for x in range(10)]<br/>    try:<br/>      label = ord(f.read(1))<br/>      row[label] = 1<br/>      labels_arr.append(row)<br/>    except:<br/>      break<br/><br/>  f.close()<br/>  label_sets = np.array(labels_arr)<br/>  return label_sets</pre>
<p class="mce-root">We can then import the images and label files in the form of <kbd>numpy</kbd> arrays by using the following lines of code:</p>
<pre>train_images = loadImageFile("train-images-idx3-ubyte")<br/>train_labels = loadLabelFile("train-labels-idx1-ubyte")<br/><br/>test_images = loadImageFile("t10k-images-dx3-ubyte")<br/>test_labels = loadLabelFile("t10k-labels-idx1-ubyte")</pre>
<p>This creates the <kbd>train_images</kbd>, <kbd>train_labels</kbd>, <kbd>test_images</kbd>, and <kbd>test_labels</kbd> <span>N</span><span>umPy arrays</span><span>. We can observe their shape and we get the following output for</span> <kbd>train_images</kbd><span>:</span></p>
<pre><strong>(60000, 784)</strong></pre>
<p>Next, we will learn how to reshape the arrays for processing with Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reshaping the arrays for processing with Keras</h1>
                </header>
            
            <article>
                
<p>The current shape of the image arrays are not Keras-friendly. We must convert the image arrays into a shape of <kbd>(60000, 28, 28, 1)</kbd> and <kbd>(10000, 28, 28, 1)</kbd>, respectively.</p>
<p>To do so, we use the following lines of code:</p>
<pre>x_train = train_images.reshape(train_images.shape[0], 28, 28, 1)<br/>x_test = test_images.reshape(test_images.shape[0], 28, 28, 1)</pre>
<p>Now, if we observe the shape of <kbd>x_train</kbd>, we get an output as follows:</p>
<pre><strong>(60000, 28, 28, 1)</strong></pre>
<p>We have no changes to make in the labels arrays and so we directly assign them to <kbd>y_train</kbd> and <kbd>y_test</kbd>:</p>
<pre>y_train = train_labels<br/>y_test = test_labels</pre>
<p>Next, we will create a neural network using Keras.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a neural network using Keras</h1>
                </header>
            
            <article>
                
<p>Now, we are ready to proceed with the creation of the neural network:</p>
<ol>
<li>We will first create a <kbd>Sequential</kbd> neural network model in Keras:</li>
</ol>
<pre style="padding-left: 60px;">model = Sequential()</pre>
<ol start="2">
<li>To add a neuron layer to the network, we use the following code:</li>
</ol>
<pre style="padding-left: 60px;">model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))</pre>
<p style="padding-left: 60px;">This adds a two-dimensional convolutional neuron layer to the network with an input shape that is the same as the shape of the images.</p>
<ol start="3">
<li>Now, let's add the activation layer with <kbd>relu</kbd> as the activation function:</li>
</ol>
<pre style="padding-left: 60px;">model.add(Activation('relu'))</pre>
<ol start="4">
<li>After adding the activation layer, we can perform a batch normalization. During training, the data passes through several computational layers and may become too large or too small. This is known as the <strong>covariate shift</strong> and batch normalization helps bring back the data to a central region. This helps the neural network train faster:</li>
</ol>
<pre style="padding-left: 60px;">BatchNormalization(axis=-1)</pre>
<ol start="5">
<li>Let's now add more hidden layers to the model:</li>
</ol>
<pre style="padding-left: 60px;">model.add(Conv2D(32, (3, 3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/><br/>BatchNormalization(axis=-1)<br/>model.add(Conv2D(64,(3, 3)))<br/>model.add(Activation('relu'))<br/>BatchNormalization(axis=-1)<br/>model.add(Conv2D(64, (3, 3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2,2)))<br/><br/>model.add(Flatten())<br/><br/>BatchNormalization()<br/>model.add(Dense(512))<br/>model.add(Activation('relu'))<br/>BatchNormalization()<br/>model.add(Dropout(0.2))</pre>
<ol start="6">
<li>At the last layer of the neural network, we need an output of 10 values, in the form of one-hot encoding, to denote the digit that has been predicted. To do this, we add a final layer of <kbd>10</kbd> neurons. This will hold 10 values in the continuous range of <kbd>0</kbd> to <kbd>1</kbd>:</li>
</ol>
<pre style="padding-left: 60px;">model.add(Dense(10))</pre>
<ol start="7">
<li>Finally, to convert these 10 floating point values to a one-hot encoding, we use a <kbd>softmax</kbd> activation:</li>
</ol>
<pre style="padding-left: 60px;">model.add(Activation('softmax'))</pre>
<p>Let's now compile and train the Keras neural network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Compiling and training a Keras neural network</h1>
                </header>
            
            <article>
                
<p>We are now ready to compile and train the neural network. To compile the neural network, we use the following code:</p>
<pre>model.compile(loss=keras.losses.categorical_crossentropy,<br/>              optimizer=keras.optimizers.Adam(),<br/>              metrics=['accuracy'])</pre>
<p>In our model, which we compiled in the previous block of code, we have set categorical cross-entropy as the <kbd>loss</kbd> function; the optimizer function used is the <kbd>Adam</kbd> optimizer and the metric for evaluation is <kbd>accuracy</kbd>.</p>
<p>We then train the neural network with the <kbd>fit()</kbd> method of the Keras model object:</p>
<pre>model.fit(x_train, y_train,<br/>          batch_size=100,<br/>          epochs=10,<br/>          verbose=2,<br/>          validation_split=0.2)</pre>
<div class="p1 packt_infobox">It is recommended that you perform a split of the training data into further validation and training data, while leaving the test set untouched but for this dataset, it is fine.</div>
<p>The training is done for 10 batches and the batch size is of 100 samples.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating and storing the model</h1>
                </header>
            
            <article>
                
<p>After training the model, we are now ready to evaluate its accuracy. To do so, we will use the following code:</p>
<pre>score = model.evaluate(x_test, y_test, verbose=1)<br/><br/>print('Test loss:', score[0])<br/>print('Test accuracy:', score[1])</pre>
<p>We will get the following output for the preceding code:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1298 image-border" src="assets/523c24c1-f2c0-4d35-88e5-10b86c746140.png" style="width:39.92em;height:5.83em;"/></p>
<p class="mce-root">We get 99% accuracy, which is a very good accuracy score. Now, we can save the model, which will be used in the future to make predictions for user input through the web portal. We will split the model into two parts—the model structure and the model weights. To save the structure, we will use the JSON format, as shown:</p>
<pre>model_json = model.to_json()<br/>with open("model.json", "w") as json_file:<br/>    json_file.write(model_json)</pre>
<p>Now, to save the weights of the Keras model, we use the <kbd>save_weights()</kbd> method for the object:</p>
<pre>model.save_weights('weights.h5')</pre>
<p>Next, we will create a Flask API to work with server-side Python.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a Flask API to work with server-side Python</h1>
                </header>
            
            <article>
                
<p>We have completed our deep learning model and stored its structure in the <kbd>model.json</kbd> file and the weights for the model in the <kbd>weights.h5</kbd> file. We are now ready to wrap the model data in an API so that we can expose the model to web-based calls via the <kbd>GET</kbd> or <kbd>POST</kbd> methods. Here, we will be discussing the <kbd>POST</kbd> method. Let's begin with the required setup on the server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up the environment</h1>
                </header>
            
            <article>
                
<p>In the server, we will require the Flask module—which will be service requests—which in turn will be running code that requires Keras (and so, TensorFlow), NumPy, and many other modules. In order to quickly set up the environment for our project, we follow these steps:</p>
<ol>
<li>Install Anaconda.</li>
<li>Install TensorFlow and Keras.</li>
<li>Install Pillow.</li>
<li>Install Flask.</li>
</ol>
<p>You can refer to the following block of commands to install TensorFlow, Keras, Pillow, and Flask:</p>
<pre><strong>pip3 install tensorflow keras pillow flask</strong></pre>
<p>We are now ready to start developing our API.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Uploading the model structure and weights</h1>
                </header>
            
            <article>
                
<p>The model structure file, <kbd>model.json</kbd>, and the weights file, <kbd>weights.h5</kbd>, need to be present in the working directory. You can copy the files to a new folder—say, <kbd>flask_api</kbd>—or upload them to the correct path if you are using a remote server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating our first Flask server</h1>
                </header>
            
            <article>
                
<p>Create a new file in the working directory and name it <kbd>flask_app.py</kbd>. This file will be the one that handles all requests made to the server. Put the following code in the file:</p>
<pre>from flask import Flask<br/>app = Flask(__name__)<br/>@app.route("/")<br/>def index():<br/>    return "Hello World!"<br/>if __name__ == "__main__":<br/>    app.run(host='0.0.0.0', port=80)</pre>
<p>The preceding code first imports the necessary modules into the script. Then, it sets the app as the Flask server object and defines the <span><kbd>index</kbd> function with a directive of handling all the requests made to the</span> <kbd>"/"</kbd> <span>address, regardless of the type of request. At the end of the script, the</span> <kbd>run()</kbd> <span>method of the Flask object app is used to bind the script to a specified port on the system.</span></p>
<p>We can now deploy this simple <em>Hello World</em> Flask server. We run the following command in a Terminal:</p>
<pre><strong>python flask_app.py</strong></pre>
<p>Now, when we open the <kbd>http://localhost/</kbd> <span>URL</span> <span>in the browser, we are greeted with a page presenting</span> <em>Hello World</em><span>. The <kbd>index</kbd> function handles the requests made at the root of the server, since it's route is set to</span> <kbd>"/"</kbd><span>. Let's now extend this example toward creating an API that can handle requests specifically for prediction.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing the necessary modules</h1>
                </header>
            
            <article>
                
<p>In the preceding example, we will extend the <kbd>flask import</kbd> statement to import an additional method, <kbd>request</kbd>, which will allow us how to handle the <kbd>POST</kbd> requests made to the server. The line then looks as follows:</p>
<pre>from flask import Flask, request</pre>
<p>We then import the modules necessary for the reading and storing of the images. Also, the <kbd>numpy</kbd> module is imported as in the following code snippet:</p>
<pre>from scipy.misc import imread, imresize<br/>import numpy as np</pre>
<p>Finally, we import the <kbd>model_from_json()</kbd> method of the Keras module to load the saved model files. We then import <kbd>tensorflow</kbd>, as Keras is dependent on it to execute:</p>
<pre>from keras.models import model_from_json<br/>import tensorflow as tf</pre>
<p>Next, we load data into the script runtime.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loading data into the script runtime and setting the model</h1>
                </header>
            
            <article>
                
<p>Once we have imported the necessary modules, we load the saved model JSON and weights, as in the following code snippet:</p>
<pre>json_file = open('model.json','r')<br/>model_json = json_file.read()<br/>json_file.close()<br/>model = model_from_json(model_json)<br/><br/>model.load_weights("weights.h5")<br/>model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])<br/>graph = tf.get_default_graph()</pre>
<p>Note that we have also created a default <kbd>graph</kbd> item for the session ahead. This was implicitly created during the model training but is not carried over in the saved <kbd>model</kbd> and <kbd>weights</kbd> files, so we must explicitly create it here.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting the app and index function</h1>
                </header>
            
            <article>
                
<p>Now, we set the <kbd>app</kbd> variable to a Flask object and set the <kbd>"/"</kbd> route to be handled by the <kbd>index</kbd> function, which actually produces no meaningful output. This is because we will be using the <kbd>/predict</kbd> route to serve our prediction API as shown:</p>
<pre>app = Flask(__name__)<br/><br/>@app.route('/')<br/>def index():<br/>    return "Oops, nothing here!"</pre>
<p>We will cover the convert image function in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting the image function</h1>
                </header>
            
            <article>
                
<p>We might sometimes get images in the form of <kbd>base64</kbd> encoded strings if the user makes an image <kbd>POST</kbd> request with a suitable setting. We can create a function to handle that:</p>
<pre>import re<br/>import base64<br/><br/>def stringToImage(img):<br/>    imgstr = re.search(r'base64,(.*)', str(img)).group(1)<br/>    with open('image.png', 'wb') as output:<br/>        output.write(base64.b64decode(imgstr))</pre>
<p>We use the <kbd>re</kbd> module for regex to determine whether the data passed is in the form of a <kbd>base64</kbd> string. The <kbd>base64</kbd> module is needed to decode the string and then the file is saved as <kbd>image.png</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prediction APIs</h1>
                </header>
            
            <article>
                
<p>Now, let's define the <kbd>/predict</kbd> route, which will be our API to respond to the predicted digit with:</p>
<pre>@app.route('/predict/', methods=['POST'])<br/>def predict():<br/>    global model, graph<br/>    <br/>    imgData = request.get_data()<br/>    try:<br/>        stringToImage(imgData)<br/>    except:<br/>        f = request.files['img']<br/>        f.save('image.png')<br/>   <br/>    x = imread('image.png', mode='L')<br/>    x = imresize(x, (28, 28))<br/>    x = x.reshape(1, 28, 28, 1)<br/><br/>    with graph.as_default():<br/>        prediction = model.predict(x)<br/>        response = np.argmax(prediction, axis=1)<br/>        return str(response[0])</pre>
<p>Here, the <kbd>predict()</kbd> function takes in a <kbd>POST</kbd> method input, makes a check on the format that the file is passed in, and then saves it to the disk with the name of <kbd>image.png</kbd>. Then, the image is read into the program and resized to 28 x 28 dimensions. Next, the image array is reshaped, such that it can be put into the Keras model for prediction. Then, we use the <kbd>predict()</kbd> method of the Keras model and get a one-hot-encoded output with the predicted digit's index set to <kbd>1</kbd>, while the rest remains as <kbd>0</kbd>. We determine the digit and send it to the output of the API.</p>
<p>Now, we must, at the end of the file, add the code to bind the server to a port and set the required configuration:</p>
<pre>if __name__ == "__main__":<br/>    app.run(host='0.0.0.0', port=80)<br/>    app.run(debug=True)</pre>
<p>We have set the <kbd>debug=True</kbd> parameter in order to be able to see—in the server's console—whether any error occurs on the server. This is always a good idea during development but in production, this line of code can be skipped.</p>
<p>A final step before we run the application is to update the code for the <kbd>'/'</kbd> route. We will load the <kbd>index.html</kbd> item that we created whenever a person calls this route, as shown:</p>
<pre>@app.route('/')<br/>def index():<br/>    return render_template("index.html")</pre>
<p>We are now all set to start up the server and check whether it is working correctly. We use the same command as used previously to start up the server:</p>
<pre><strong>python flask_app.py</strong></pre>
<p>The preceding command will <span>start up the server.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the API via cURL and creating a web client using Flask</h1>
                </header>
            
            <article>
                
<p><span>With our server running, we can send <kbd>POST</kbd> requests to it with the image content and expect a predicted digit in the output. Two ways to test any API without any third-party tools are as follows:</span></p>
<ul>
<li>Use cURL.</li>
<li>Develop a client to call the API.</li>
</ul>
<p>We will be covering both of these methods.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the API via cURL</h1>
                </header>
            
            <article>
                
<p>Before we develop a client to send <kbd>POST</kbd> requests to the API server, let's test the API via cURL, which is a command-line tool used to simulate <kbd>GET</kbd> and <kbd>POST</kbd> requests to URLs.</p>
<p>Use the following command in Terminal or Command Prompt to make a <kbd>curl</kbd> request to your prediction API:</p>
<pre><strong>curl -X POST -F img=@"path_to_file" http://localhost/predict/</strong></pre>
<p>Here, the <kbd>-F</kbd> flag is used to indicate that the <kbd>POST</kbd> request will contain files. The name of the <kbd>POST</kbd> variable that will hold the file is <kbd>img</kbd>,<kbd>path_to_file</kbd> should be replaced with the full path to the file that you wish to send to the server for the image that the prediction is to be made on.</p>
<p>Let's see how the API works with an example.</p>
<p>Say we have the following image with the <kbd>self2.png</kbd> <span>filename and dimensions</span> <span>of 275 x 275:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1299 image-border" src="assets/c1178ecc-74c4-4240-9fa9-5fa0ff8e6c67.png" style="width:11.58em;height:11.58em;"/></p>
<p>Clearly, the image dimensions on the serverside must be adjusted. To make the request, we use the following command:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1300 image-border" src="assets/a9e4c932-14ec-410e-81ec-255822daa48e.png" style="width:41.50em;height:4.58em;"/></p>
<p>The output of the API is a single integer—<kbd>2</kbd>. So, the API works successfully.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a simple web client for the API</h1>
                </header>
            
            <article>
                
<p>We will now be creating a bare-bones web Client to call the API. To do so, we must modify our current code. In <kbd>flask_app.py</kbd>, first change the <kbd>import</kbd> statement for Flask in order to extend it to another module—<kbd>render_template</kbd>—as shown:</p>
<pre>from flask import Flask, request, render_template</pre>
<p>Now, we create a folder, <kbd>templates</kbd>, in the working directory and add a file, <kbd>index.html</kbd>, to it with the following code:</p>
<pre>&lt;!DOCTYPE html&gt;<br/>&lt;html lang="en"&gt;<br/>  &lt;head&gt;<br/>    &lt;title&gt;MNIST CNN&lt;/title&gt;<br/>  &lt;/head&gt;<br/><br/>  &lt;body&gt;<br/>    &lt;h1&gt;MNIST Handwritten Digits Prediction&lt;/h1&gt;<br/><br/>    &lt;form&gt;<br/>      &lt;input type="file" name="img"&gt;&lt;/input&gt;<br/>      &lt;input type="submit"&gt;&lt;/input&gt;<br/>    &lt;/form&gt;<br/>    &lt;hr&gt;<br/>    &lt;h3&gt;Prediction: &lt;span id="result"&gt;&lt;/span&gt;&lt;/h3&gt;<br/><br/>    &lt;script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'&gt;&lt;/script&gt;<br/><br/>    &lt;script src="{{ url_for('static',filename='index.js') }}"&gt;&lt;/script&gt;<br/><br/>&lt;/body&gt;<br/>&lt;/html&gt;</pre>
<p>Essentially, all we do here is create a form with a single input element of the file type, called <kbd>img</kbd>. We then add jQuery to the page and create a link to a static file, <kbd>index.js</kbd>, which is served in the <kbd>static</kbd> folder of the server.</p>
<p>Let's create the <kbd>index.js</kbd> file. First, create a folder, <kbd>static</kbd>, in the root directory and then create a new file, <kbd>index.js</kbd>, with the following code:</p>
<pre>$("form").submit(function(evt){ <br/>    evt.preventDefault();<br/>    var formData = new FormData($(this)[0]);<br/>    $.ajax({<br/>        url: '/predict/',<br/>        type: 'POST',<br/>        data: formData,<br/>        async: false,<br/>        cache: false,<br/>        contentType: false,<br/>        enctype: 'multipart/form-data',<br/>        processData: false,<br/>        success: function (response) {<br/>            $('#result').empty().append(response);<br/>        }<br/>    });<br/>    return false;<br/>});</pre>
<p>The preceding jQuery code makes a <kbd>POST</kbd> request to the <kbd>/predict/</kbd> route and then updates the <kbd>result</kbd> divide on the page with the value that is returned from the server.</p>
<p>Let's take a sample run on this web client. First, we need to restart the Flask server. Then, we open <kbd>http://localhost/</kbd> in the browser to get a web page that looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1302 image-border" src="assets/216dfe04-0135-4771-979f-4cd732b1d1e5.png" style="width:68.67em;height:23.17em;"/></p>
<p>Say we choose a file named <kbd>mnist7.png</kbd>, which is essentially the first image of the test dataset and looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1303 image-border" src="assets/3ea2f8b5-6d27-47cc-9670-0bb3f2e5e4f9.png" style="width:21.25em;height:21.00em;"/></p>
<p>The expected output is <kbd>7</kbd>. After clicking <span class="packt_screen">Submit</span>, we get the following output on the page:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1304 image-border" src="assets/0ac49e88-f2b8-4b42-b530-eaffc91dcb4a.png" style="width:59.83em;height:20.08em;"/></p>
<p>We can observe that that is the correct output and conclude that the web client works correctly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Improving the deep learning backend</h1>
                </header>
            
            <article>
                
<p>The simple model we have trained here is hardly one that we can claim is close to a perfect model. There are several methods that we can use to extend this model to make it better. For instance, some of the most basic steps that we can take to improve our deep learning model are as follows:</p>
<ul>
<li><strong>Increase training epochs</strong>: We have only trained our model for 10 epochs, which is usually a very small value for any deep learning model. Increasing the number of training epochs can improve the accuracy of the model. However, it can also lead to overfitting and so the number of epochs must be experimented with.</li>
<li><strong>More training samples</strong>: Our web client currently doesn't do much more than show the predicted value. However, we could extend it to get feedback from the user on whether the prediction we made was correct. We can then add the user's input image to the training samples and train with the user-provided label for the image. We must, however, take caution against spammy user input images and labels and only provide this feature to trusted users or beta testers for our web app.</li>
<li><strong>Create a deeper network</strong>: We could increase the number of hidden layers in the network to make the predictions more accurate. Again, this method is susceptible to overfitting and must be carefully experimented with.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This chapter covered, in complete detail, how you can create a deep learning model and then facilitate its usage through an API via a web client or using cURL. The chapter began by discussing how deep learning web applications are structured, the various components of such applications, and how they interact with each other. Then, a short discussion and exploration of the MNIST handwritten digits dataset was presented. This led us on to the next section, where we built a deep learning model and stored it in files for future use. These files were then imported to the server API scripts and executed there whenever the API was called. Finally, the chapter presented a very basic client for the API and also instructed you on how to use the API over cURL through the command-line interface.</p>
<p>In the next chapter, we will discuss how deep learning can be performed within the browser window using TensorFlow.js.</p>


            </article>

            
        </section>
    </body></html>