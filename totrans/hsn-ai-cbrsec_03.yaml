- en: Setting Up Your AI for Cybersecurity Arsenal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduces the main software requirements and their configurations.
    You will learn how to feed a knowledge base with samples of malicious code that
    will be passed as input to AI procedures. IPython notebooks will be introduced
    for the interactive execution of Python tools and commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting to know Python for AI and cybersecurity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enter Anaconda—the data scientist's environment of choice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Playing with Jupyter Notebook
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feeding your AI arsenal—where to find data and malicious samples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting to know Python for AI and cybersecurity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Among all the languages ​​that can be used to program AI tools and algorithms,
    Python is the one that, in recent years, has shown to be constantly growing and
    is appreciated by programmers, new and old. Despite the competition being fierce,
    as languages ​​such as R, as well as Java, can boast tens of thousands of developers
    in their ranks, Python has gained the reputation of being a language of choice
    not only for **data science** but also (and above all) for **machine learning** (**ML**), **deep
    learning** (**DL)**,and more generally, for the development of **artificial intelligence**
    (**AI**) algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The success of Python in these areas should not be surprising. Python was originally
    developed for programming numerical calculations, but was then extended to non-specialist
    areas, assuming the form of a general-purpose programming language, alongside
    better-known languages ​​such as C++ and Java.
  prefs: []
  type: TYPE_NORMAL
- en: 'Python''s success is due to a number of reasons, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Easy to learn**: The language learning curve is indeed much less steep than
    other languages, ​​such as C++ and Java.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speeding up both the code prototyping and code refactoring processes**: Thanks
    to a clean design and clear syntax, programming in Python is much easier than
    other languages. It is also much easier to debug code. It is not uncommon for
    prototypes of programs developed in Python to be released for operation without
    the need for further modifications. These characteristics are essential in areas
    such as data science and AI. Sectors characterized by the need to quickly prototype
    new features and refactor old ones, without having to waste time debugging legacy
    code, are in need of a means to speed up code prototyping and refactoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpreted language and object orientation**: The ability to write code
    in the form of a script that can be started directly on the command line, or better
    still, in interactive mode (as we will see later), without the need to proceed
    with the compilation in executable format, dramatically accelerates the process
    of development, and the testing of applications. Object orientation also facilitates
    the development of APIs and libraries of reusable functionalities, ensuring the
    reliability and robustness of the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The wide availability of open source libraries that expand programming features**:
    The benefits we have talked about so far translate into the availability of numerous
    libraries of high-level functions, freely usable by analysts and developers, and
    made available by the large Python community. These function libraries can be
    easily integrated with each other by virtue of the clean language design, which
    facilitates the development of APIs that can be recalled by the developers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's delve deeper into the most common AI programming libraries available
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Python libraries for AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As anticipated, there are numerous libraries available in Python that can be
    used in the field of data science and ML, including DL and **reinforcement learning**
    (**RL**).
  prefs: []
  type: TYPE_NORMAL
- en: In the same way, there are many functions of graphical representation and reporting.
    In the following sections, we will analyze the characteristics of these libraries.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy as an AI building block
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of all the Python libraries dedicated to data science and AI, there is no doubt
    that NumPy holds a privileged place. Using the functionalities and APIs implemented
    by NumPy, it is possible to build algorithms and tools for ML from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, having specialized libraries available for AI (such as the `scikit-learn`
    library) accelerates the process of the development of AI and ML tools, but to
    fully appreciate the advantages deriving from the use of such higher-level libraries,
    it is useful to understand the building blocks on which they are built. This is
    why knowledge of the basic concepts of NumPy is helpful in this regard.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy multidimensional arrays
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**NumPy** was created to solve important scientific problems, which include
    **linear algebra** and **matrix calculations**. It offers a particularly **optimized
    version, **compared to the corresponding native versions of data structures offered
    by the Python language, such as lists of arrays and making **multidimensional**
    array objects, known as `ndarrays`, available. In fact, an object of the `ndarray`
    type allows the acceleration of operations to reach speeds of up to 25 times faster
    compared to traditional `for` loops, which is necessary to manage access to data
    stored in a traditional Python list.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, NumPy allows the management of operations on matrices, which is particularly
    useful for the implementation of ML algorithms. Unlike `ndarray` objects, matrices
    are objects that can take only two dimensions and represent the main data structures
    used in linear algebra.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of defining NumPy objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Matrix operations with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As anticipated, matrices and the operations executed on them are of particular
    importance in the field of ML, and, more generally, they are used to conveniently
    represent the data to be fed to AI ​​algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Matrices are particularly useful in the management and representation of large
    amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: The notation itself is commonly used to identify the elements of a matrix, making
    use of positional indexes that allow the execution of consistent, rapid fashion
    operations, and calculations that concern either the whole matrix or just specific
    subsets. For example, the ![](img/0c6fe151-0486-488f-9b59-912d58501543.png) element is
    easily identified within the matrix, crossing row ![](img/afbc1ec2-ac8d-4274-ba4a-0bb61100ef01.png) and
    column ![](img/8a391b3a-1f5d-4dfa-8678-f800dea8c887.png).
  prefs: []
  type: TYPE_NORMAL
- en: A special matrix, consisting of only one row (and several columns) is identified
    as a **vector***. *Vectors can be represented in Python as objects of a `list `type.
  prefs: []
  type: TYPE_NORMAL
- en: However, the particular rules established by **linear algebra** should be taken
    into account when performing operations between **matrices and vectors**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic operations that can be performed on matrices are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Addition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subtraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalar multiplication (resulting in a constant value multiplied for each matrix
    element)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If such operations on matrices are relatively simple to accomplish, and are
    required only as a **necessary precondition** that the matrices that add or subtract
    from each other are of the **same size, then **the result of the addition or subtraction
    of two matrices is a **new matrix** whose elements are the result of the sum of
    corresponding elements in row and column order.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with the **product** operation between matrices or between vectors
    and matrices, the rules of linear algebra are partly different, since, for example,
    the **commutative property** is not applicable as it is in the case of the product
    of two scalars.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, while in the case of the product of two numbers among them, the order
    of factors does not change the result of multiplication (that is, *2 x 3 = 3 x
    2*), in the case of the product of two matrices, **the order is important**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, `X`represents a **matrix** and `a` represents a **vector** of coefficients.
    Moreover, it is **not always** possible to **multiply two matrices**, as in the
    case of two matrices with **incompatible dimensions**.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, the `numpy` library provides the `dot()` function to calculate
    the product of two matrices between them (usable whenever this operation is possible):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we calculate the product between matrix `X`and vector
    `a` using the `np.dot()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'This product is the expression of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It represents **one of the most basic models** used in ML to associate a set
    of **weights** (`a`) to an **input data matrix** (`X`) in order to obtain the
    estimated **values** (`y`) as output.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a simple predictor with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To fully understand the use of the `dot()` method of NumPy in matrix multiplication
    operations, we can try to implement a **simple predictor** from scratch, to predict
    future values starting from a set of multiple inputs and on the basis of relative
    weights, using the product between matrices and vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the best and most used ML libraries is definitely the `scikit-learn`
    library. First developed in 2007, the `scikit-learn` library provides a series
    of models and algorithms that are easily reusable in the development of customized
    solutions, which makes use of the main predictive methods and strategies, including
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensionality reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The list does not end here; in fact, `scikit-learn` also provides ready-to-use
    modules that allow the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperparameter optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The particularity of `scikit-learn` is that it uses the `numpy` library in addition
    to the SciPy library for scientific computing. As we have seen, NumPy allows the
    optimization of calculation operations performed on large datasets, using multidimensional
    arrays and matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Among the advantages of `scikit-learn`, we must not forget that it provides
    developers with a very clean **application programming interface** (**API**),
    which makes the development of customized tools from the classes of the library
    relatively simple.
  prefs: []
  type: TYPE_NORMAL
- en: As an example of using the **predictive analytics** templates available in `scikit-learn`,
    we will show how to perform a prediction on training data (stored in the `X` matrix)
    using the **linear regression** model, based on a `y` weight vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal will be to use the `fit()` and `predict()` methods implemented in
    the `LinearRegression` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon execution, the script produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Let's now continue with the Matplotlib and Seaborn libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Matplotlib and Seaborn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the analytical tools used the most by analysts in AI and data science
    consists of the **graphical representation** of data. This allows a preliminary
    activity of data analysis known as **exploratory data analysis** (**EDA**). By
    means of EDA, it is possible to identify, from a simple visual survey of the data,
    the possibility of associating them with regularities or **better predictive models**
    than others.
  prefs: []
  type: TYPE_NORMAL
- en: Among graphical libraries, without a doubt, the best known and most used is
    the `matplotlib` library, through which it is possible to create graphs and images
    of the data being analyzed in a very simple and intuitive way.
  prefs: []
  type: TYPE_NORMAL
- en: '**Matplotlib** is basically a **data plotting tool** inspired by MATLAB, and
    is similar to the `ggplot` tool used in R.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we show a simple example of using the `matplotlib` library,
    using the `plot()` method to plot input data obtained by the `arange()` method
    (array range) of the `numpy` library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In addition to the `matplotlib` library in Python, there is another well-known
    visualization tool among data scientists called **Seaborn**.
  prefs: []
  type: TYPE_NORMAL
- en: Seaborn is an extension of Matplotlib, which makes various visualization tools available for
    data science, simplifying the analyst's task and relieving them of the task of
    having to program the graphical data representation tools from scratch, using
    the basic features offered by `matplotlib` and `scikit-learn`.
  prefs: []
  type: TYPE_NORMAL
- en: Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last (but not least) among Python's most used libraries that we'll look
    at here, is the `pandas` package, which helps to simplify the ordinary activity
    of data cleaning (an activity that absorbs most of the analyst's time) in order
    to proceed with the subsequent data analysis phase.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of `pandas` is very similar to that of the `DataFrame` package
    in R; DataFrame is nothing but a tabular structure used to store data in the form
    of a table, on which the columns represent the variables, while the rows represent
    the data itself.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we will show a typical use of a DataFrame, obtained
    as a result of the instantiation of the `DataFrame` class of `pandas`, which receives,
    as an input parameter, one of the datasets (the `iris` dataset) available in `scikit-learn`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After having instantiated the `iris_df` object of the  `DataFrame` type, the
    `head()` and `describe()` methods of the `pandas` library are invoked, which shows
    us the first five records of the dataset, respectively, and some of the main statistical
    measures calculated in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Python libraries for cybersecurity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python is not only one of the best languages for data science and AI, but also
    the language preferred by penetration testers and malware analysts (along with
    low-level languages, such as C and Assembly).
  prefs: []
  type: TYPE_NORMAL
- en: In Python, there are an infinite number of libraries ready for use, which simplify
    the daily activities of researchers.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will analyze some of the most common and the most used of them.
  prefs: []
  type: TYPE_NORMAL
- en: Pefile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Pefile library is very useful for analyzing Windows executable files, especially
    during the phases of **static malware analysis**, looking for possible indications
    of compromise or the presence of malicious code in executables. In fact, Pefile
    makes it very easy to analyze the **Portable Executable** (**PE**) file format,
    which represents the standard for the object files (contained or retrievable as
    libraries of external executable functions) on the Microsoft platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, not only the classic `.exe` files, but also the `.dll` libraries and `.sys`
    device drivers, follow the PE file format specification. The installation of the
    Pefile library is very simple; it is sufficient to use the `pip` command as used
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the installation is complete, we can test the library with a simple script
    such as the following, which loads the executable `notepad.exe` into runtime memory,
    and then extracts from its executable image some of the most relevant information
    saved in the relative PE file format fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Volatility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another tool widely used by malware analysts is **volatility**, which allows
    the analysis of the runtime memory of an executable process, highlighting the
    presence of possible malware code.
  prefs: []
  type: TYPE_NORMAL
- en: Volatility is a Python-programmable utility, which is often installed by default
    in distributions for malware analysis and pentesting, such as Kali Linux. Volatility
    allows the extraction of important information about processes (such as API hooks,
    network connections and kernel modules) directly from memory dumps, providing
    the analyst with a suite of programmable tools using Python.
  prefs: []
  type: TYPE_NORMAL
- en: These tools allow the extraction from the memory dumps of all the processes
    running on the system and any relevant information about injected **Dynamic-Link
    Libraries** (**DLLs**), along with the presence of rootkits, or more generally,
    the presence of **hidden processes** within the runtime memory, which easily escapes
    the detection of common antivirus softwares.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Python libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen some of the basic Python libraries, which are useful for our analysis
    purposes. How do we install these libraries in our development environment?
  prefs: []
  type: TYPE_NORMAL
- en: Being Python libraries, it is obviously possible to proceed with the installation
    simply by following the traditional utilities provided by the language; in particular,
    using the `pip` command, or launching the `setup.py`provided by each library package.
    However, there is a much easier way to proceed with the configuration of an analysis
    and development environment in the field of AI and data science, using Anaconda,
    as we will see in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Enter Anaconda – the data scientist's environment of choice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given the large number of available Python libraries, their installation is
    often particularly tedious (if not boring), as well as difficult, especially for
    those who are beginning their approach to the world of data science and AI.
  prefs: []
  type: TYPE_NORMAL
- en: To facilitate the setup of an already preconfigured development environment,
    collections of packages and libraries, such as Anaconda ([http://www.anaconda.com/download/](http://www.anaconda.com/download/))
    are made available. This allows quick access to the most used tools and libraries,
    thus speeding up development activities, without the need to waste time solving
    problems with dependencies between packages, or installation issues with the various
    operating systems.
  prefs: []
  type: TYPE_NORMAL
- en: While I'm writing this, the latest available version of Anaconda released is
    5.3.0 (available for download at [https://www.anaconda.com/anaconda-distribution-5-3-0-released/](https://www.anaconda.com/anaconda-distribution-5-3-0-released/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can choose the installation distribution for your platform of choice, whether
    it is Windows, Linux, or macOS, 32-bit or 64-bit or Python 3.7 or 2.7, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6dcb7f19-35fd-4f4d-b1f5-77830903a125.png)'
  prefs: []
  type: TYPE_IMG
- en: Anaconda Python advantages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Anaconda is a collection of over 700 packages developed in Python, among which
    are the data analysis and ML libraries we talked about in the previous paragraphs,
    among many others:'
  prefs: []
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SciPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scikit-learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matplotlib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, Anaconda allows you to configure custom environments, within which
    you can install specific versions not only of Python but also packages and libraries
    used for development.
  prefs: []
  type: TYPE_NORMAL
- en: Conda utility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anaconda provides a very powerful utility, conda. Through conda, it is possible
    to manage and update already installed packages, or install new packages, as well
    as to create custom environments in the easiest possible way.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the conda help menu, run the following command from Command Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Installing packages in Anaconda
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the conda utility, it is possible to install new packages not included
    in the collection of pre-installed packages. To proceed with the installation
    of a new package, simply execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The command being executed will search among the packages contained in the online
    repository of Anaconda Continuum Analytics. Remember that it is always possible
    to proceed with the traditional methods of installation, by resorting to the `pip
    install` commands or by launching the `setup.py` file contained in the package.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, in this case, we will have to worry about solving all the possible
    dependencies and compatibility problems between versions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating custom environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned, one of the strengths of Anaconda is its ability to create custom
    environments, within which we can install specific software versions of both Python
    and of the various packages. Anaconda is in fact usually available with the pre-installed
    versions of Python 2.7 and Python 3.7\. You can decide to combine specific versions
    of Python, without incurring the risk of corrupting the default environments.
    To achieve this, you’ll need to create custom environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume we want to create a custom environment in which we would like
    to install the version of Python 3.5 (or another version). Just invoke the conda
    utility as in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, `conda` proceeds with the creation and configuration of the
    new custom environment named `py35`, in which the version of Python 3.5 is installed.
    To activate the newly created environment, just run the following command from
    Command Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: From now on, all the commands launched will be executed in the `py35` custom
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Some useful Conda commands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the useful Conda commands are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To activate the newly created `py35` custom environment, run the following
    command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Install packages in a specific environment by executing the following commands:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'List the installed packages of a specific environment by running the following
    command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Update Anaconda with the following commands:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Python on steroids with parallel GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To fully exploit the potential of some ML libraries, and especially DL, it is
    necessary to deploy dedicated hardware that includes the use of **graphics processing
    units** (**GPU**s) in addition to traditional CPUs. As current GPUs are, in fact,
    optimized to perform parallel calculations, this feature is very useful for the
    effective execution of many DL algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reference hardware equipment could be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU Intel Core i5 6^(th) Generation or higher (or AMD equivalent)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8 GB RAM as a minimum (16 GB or higher is recommended)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPU  NVIDIA GeForce GTX 960 or higher (visit [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)
    for more info)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux operating system (for example Ubuntu) or Microsoft Windows 10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By leveraging the Numba compiler provided by Anaconda, you can compile the Python
    code and run it on CUDA-capable GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: For further information, please refer to the website of your GPU manufacturer
    and the Numba documentation ([https://numba.pydata.org/numba-doc/latest/user/index.html](https://numba.pydata.org/numba-doc/latest/user/index.html)).
  prefs: []
  type: TYPE_NORMAL
- en: Playing with Jupyter Notebooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Among the most useful tools for the developer, there is undoubtedly the **Jupyter
    Notebook**, which allows, in a single document, the integration of both the Python
    code and the result of its execution, including images and graphics. In this way,
    it is possible to receive immediate feedback on the development activity in progress,
    managing the various phases of programming in an iterative manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the Jupyter Notebook, it is possible to recall the various specific
    libraries installed in a custom environment. Jupyter is a web-based utility, so
    to run the notebook you need to run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to specify the listening port of the service, using the
    `port` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this way, the service will be started on the listening port `9000` (instead
    of the default `8888`).
  prefs: []
  type: TYPE_NORMAL
- en: Jupyter is among the packages that come pre-installed with Anaconda; it is not
    necessary to install the software as it is readily available for use.
  prefs: []
  type: TYPE_NORMAL
- en: In the next paragraphs, we will learn how to use the Jupyter Notebook using
    some examples.
  prefs: []
  type: TYPE_NORMAL
- en: Our first Jupyter Notebook
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once Jupyter is started, you can open an existing notebook inside the root
    directory (which can be viewed at [http://localhost:8888/tree](http://localhost:8888/tree))
    from which the service was started, or proceed to create a new notebook from scratch:'
  prefs: []
  type: TYPE_NORMAL
- en: Notebooks are nothing more than text files with the extension `.ipynb`, inside
    which are saved (in JSON format) Python code and other media resources (such as
    images coded in base64).
  prefs: []
  type: TYPE_NORMAL
- en: To create our first notebook, simply use the menu items available in the dashboard's
    interface, which is very intuitive.
  prefs: []
  type: TYPE_NORMAL
- en: 'All we have to do is to select the folder in which to place the newly created
    notebook, then click on the New button and choose the version of Python that most
    suits our needs, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ffca135-c9c6-4170-97a0-2bb7dc7340f0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'At this point, we can rename the newly created notebook and then proceed with
    the insertion of the cells within the document:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8301e28-2d33-40cc-a4f0-07e52cbe4d74.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can specify the type of content of the cell, choosing between code (default)
    text, markdown, and other options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b36e0ac5-1190-42c3-b565-4bd98e2ed16e.png)'
  prefs: []
  type: TYPE_IMG
- en: Exploring the Jupyter interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we will explore in more detail some of the common tasks in the management
    of notebooks, starting with the renaming of files. The default filename assigned
    to newly created notebooks is, in fact, `Untitled.ipynb`. We must keep that in
    mind to proceed with the renaming of a notebook; this must not be in the running
    state. Therefore, make sure to select the File | Close and Halt menu item before
    assigning a new name to the notebook; simply select the file to be renamed in
    the directory and click on Rename among the dashboard controls:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5148652e-098a-41b3-9099-7072d2c25511.png)'
  prefs: []
  type: TYPE_IMG
- en: What's in a cell?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The cells represent containers in which it is possible to insert different types
    of content; the most commonly occurring content of a cell obviously consists of
    Python code to be executed inside the notebook, but it is also possible to insert
    plain text or markdown inside a cell.
  prefs: []
  type: TYPE_NORMAL
- en: When we insert Python code, the result of the execution is immediately shown
    below the code, within the same cell. To insert a new cell, click on Insert from
    the menu bar, and select Insert Cell Below.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, a keyboard shortcut can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Useful keyboard shortcuts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To speed up the execution of the most common commands, the Jupyter interface
    provides us with a series of keyboard shortcuts, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Ctrl* + *Enter*: Run the selected cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Esc* or *Enter*: Toggle between edit and command mode'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Up and down keys: Scroll cells up/down (command mode)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Press *A* or *B*: Insert a new cell above or below the active cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Press *Y*: Set the active cell as a code cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Press *M*: Transform the active cell to a markdown cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Press *D* twice: Delete the active cell'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Press *Z*: Undo cell deletion'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose your notebook kernel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A particularly interesting feature of notebooks is that behind each notebook
    hides a specific kernel. When we execute a cell containing Python code, that code
    is executed in the **specific kernel** of the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then select and assign a specific kernel to a single notebook, in case
    we have installed several different environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b901812d-f397-4f7c-823e-faba57c15da3.png)'
  prefs: []
  type: TYPE_IMG
- en: It is, in fact, possible to install not only different kernels for different
    versions of Python, but also kernels for other languages such as Java, C, R and
    Julia.
  prefs: []
  type: TYPE_NORMAL
- en: Getting your hands dirty
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To close the Jupyter Notebook argument, we will now try to insert a series
    of cells with example Python code inside, recalling the libraries and packages
    that we need, by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Proceed to insert a new cell, within which we write the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f8da3ad1-77a1-46f3-b6fa-44c785188950.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, add a new cell, within which we will write the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'By running the preceding code, we should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we insert a new cell, within which we will write the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Launching the execution of the code inside the cell, we should get the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7cd389c6-abb0-416c-9e8d-6b2abbe7de8a.png)'
  prefs: []
  type: TYPE_IMG
- en: Congratulations! If everything went as described, you have successfully verified
    your configuration and can proceed further.
  prefs: []
  type: TYPE_NORMAL
- en: Installing DL libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will consider the advantages of installing some of the main
    Python libraries for AI, in particular, to exploit the potential of deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The libraries that we will cover are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prior to discovering the advantages of the individual libraries and proceeding
    with their installation, let's spend a few words on the advantages and characteristics
    of deep learning for cybersecurity.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning pros and cons for cybersecurity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the distinctive features of deep learning, compared to other branches
    of AI, is the ability to exploit general-purpose algorithms, by leveraging neural
    networks. In this way, it is possible to face similar problems that entail several
    different application domains, by reusing common algorithms elaborated in different
    contexts.
  prefs: []
  type: TYPE_NORMAL
- en: The deep learning approach exploits the possibility of **neural networks** (**NNs**) to
    add multiple processing layers, each layer having the task of executing different
    types of processing, sharing the results of the processing with the other layers.
  prefs: []
  type: TYPE_NORMAL
- en: Within a neural network, at least one layer is hidden, thus simulating the behavior
    of human brain neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 'Among the most common uses of deep learning, are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Natural language processing** (**NLP**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These use cases are also of particular importance in the field of cybersecurity.
  prefs: []
  type: TYPE_NORMAL
- en: For example, for **biometric authentication **procedures, which are increasingly carried
    out by resorting to deep learning algorithms, deep learning can also be used successfully
    in the detection of anomalous user behaviors, or in the abnormal use of payment
    instruments, such as credit cards, as part of **fraud detection **procedures.
  prefs: []
  type: TYPE_NORMAL
- en: Another important use of deep learning is in the detection of possible malware
    or networking threats. Given the vast potential for using deep learning, it should
    not be surprising that even bad guys have begun to use it.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, the recent spread of evolved neural networks such as **generative
    adversarial networks** (**GANs**) is posing a serious challenge to traditional
    biometric authentication procedures, which resort to **facial recognition** or
    **voice recognition**. By using a GAN, it is, in fact, possible to generate **artificial
    samples of biometric evidence**, which are practically indistinguishable from
    the original ones.
  prefs: []
  type: TYPE_NORMAL
- en: We will delve deeper into this in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how to proceed with the installation of the main deep learning
    libraries within our development environment.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first deep learning library we will deal with is TensorFlow; in fact, it
    plays a special role, having been specifically developed to program **deep neural
    network** (**DNN**) models.
  prefs: []
  type: TYPE_NORMAL
- en: 'To proceed with the installation of TensorFlow within Anaconda, we must first
    proceed with the creation of a custom environment (if we have not already created
    one) by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we will use the custom environment `py35`, which was previously
    created:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install TensorFlow with conda:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Install a specific version of TensorFlow by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We can test our installation by running a sample TensorFlow program in an interactive
    conda session as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: For further documentation, visit the TensorFlow website at [https://www.tensorflow.org/](https://www.tensorflow.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The other deep learning library we will install is `keras`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A characteristic of Keras is that it can be installed on top of TensorFlow,
    thus constituting a high-level interface (with respect to TensorFlow) for NN development.
    Also, in the case of Keras, as with TensorFlow, we will proceed to the installation
    inside our custom environment `py35`, which we created previously, by executing
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: For further documentation, visit the Keras website at [https://keras.io/](https://keras.io/).
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last example of a deep learning library we will examine here is `pytorch`.
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch is a project developed by Facebook, specially designed to perform large-scale
    image analysis. Even in the case of PyTorch, installation (always within the `py35`
    environment) via conda is rather simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: PyTorch versus TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To compare both of the learning libraries, it should be noted that PyTorch is
    the most optimized solution for performing tensor calculus tasks on GPUs, as it
    has been specifically designed to improve performance in large-scale contexts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the most common use cases for using PyTorch are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: NLP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large-scale image processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social media analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, when compared only on the basis of performance, both PyTorch and TensorFlow
    are excellent choices; there are other characteristics that could make you lean
    toward one solution or the other.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in TensorFlow, the debugging of programs is more complex than in
    PyTorch. This is because, in TensorFlow, development is more cumbersome (having
    to define tensors, initialize a session, keep track of tensors during the session,
    and so on), while the deployment of the TensorFlow model is certainly preferred.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, the indispensable tools for carrying out analysis and development
    activities in AI in the cybersecurity field have been illustrated. We looked at
    the main AI libraries and introduced the advantages and disadvantages of using
    deep learning in the field of cybersecurity.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we will learn how to use the tools at our disposal
    in the best possible way, consciously choosing those that most reflect our security
    analysis strategies.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will start with the development of appropriate classifiers
    for email spam detection.
  prefs: []
  type: TYPE_NORMAL
