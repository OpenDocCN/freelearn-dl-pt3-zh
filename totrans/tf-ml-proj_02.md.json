["```\nInitialize the variables and sets\n    Tree = [root]\n    Fertile = {root}\n    Stats(root) = 0\n    Splits[root] = []\n\nDivide training data into batches.\nFor each batch of training data:\n    Compute leaf assignment  for each feature vector\n    Update the leaf stats in Stats()\n    For each  in Fertile set:\n        if |Splits()| < max_splits\n            then add the split on a randomly selected feature to Splits()\n        else if  is fertile and |Splits()| = max_splits\n            then update the split stats for \n    Calculate the fertile leaves that are finished. \n    For every non-stale finished leaf:\n        turn the leaf into an internal node with its best scoring split \n        remove the leaf from Fertile\n        add the leaf's two children to Tree as leaves\n    If |Fertile| < max_fertile\n        Then add the max_fertile − |Fertile| leaves with \n        the highest weighted leaf scores to Fertile and \n        initialize their Splits and split statistics. \nUntil |Tree| = max_nodes or |Tree| stays the same for max_batches_to_grow batches \n```", "```\narmando@librenix:~/datasets/kaggle-kepler$ kaggle datasets download -d keplersmachines/kepler-labelled-time-series-data\n\nDownloading kepler-labelled-time-series-data.zip to /mnt/disk1tb/datasets/kaggle-kepler\n100%|██████████████████████████████████████| 57.4M/57.4M [00:03<00:00, 18.3MB/s]\n```", "```\nexoTest.csv\nexoTrain.csv\n```", "```\ndsroot = os.path.join(os.path.expanduser('~'),'datasets','kaggle-kepler')\nos.listdir(dsroot)\n```", "```\n['exoTest.csv', 'kepler-labelled-time-series-data.zip', 'exoTrain.csv']\n```", "```\nimport pandas as pd\ntrain = pd.read_csv(os.path.join(dsroot,'exoTrain.csv'))\ntest = pd.read_csv(os.path.join(dsroot,'exoTest.csv'))\nprint('Training data\\n',train.head())\nprint('Test data\\n',test.head())\n```", "```\nTraining data\n    LABEL   FLUX.1   FLUX.2   FLUX.3  \\\n0      2    93.85    83.81    20.10     \n1      2   -38.88   -33.83   -58.54   \n2      2   532.64   535.92   513.73    \n3      2   326.52   347.39   302.35    \n4      2 -1107.21 -1112.59 -1118.95 \n     FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n0    -26.98   -39.56  -124.71 -135.18   \n1    -40.09   -79.31   -72.81  -86.55   \n2    496.92   456.45   466.00  464.50   \n3    298.13   317.74   312.70  322.33   \n4  -1095.10 -1057.55 -1034.48 -998.34   \n\n    FLUX.8  FLUX.9    ...      FLUX.3188  \\\n0   -96.27  -79.89    ...         -78.07      \n1   -85.33  -83.97    ...          -3.28   \n2   486.39  436.56    ...         -71.69  \n3   311.31  312.42    ...           5.71      \n4 -1022.71 -989.57    ...        -594.37    \n\n    FLUX.3189  FLUX.3190  FLUX.3191  \\\n0     -102.15    -102.15      25.13   \n1      -32.21     -32.21     -24.89   \n2       13.31      13.31     -29.89   \n3       -3.73      -3.73      30.05   \n4     -401.66    -401.66    -357.24  \n\n   FLUX.3192  FLUX.3193  FLUX.3194  \n0      48.57      92.54      39.32  \n1      -4.86       0.76     -11.70     \n2     -20.88       5.06     -11.80    \n3      20.03     -12.67      -8.77      \n4    -443.76    -438.54    -399.71   \n\n   FLUX.3195  FLUX.3196  FLUX.3197  \n0      61.42       5.08     -39.54  \n1       6.46      16.00      19.93  \n2     -28.91     -70.02     -96.67  \n3     -17.31     -17.35      13.98  \n4    -384.65    -411.79    -510.54  \n\n[5 rows x 3198 columns]\n\nTest data\n\n    LABEL   FLUX.1   FLUX.2   FLUX.3   \\\n0      2   119.88   100.21    86.46      \n1      2  5736.59  5699.98  5717.16    \n2      2   844.48   817.49   770.07    \n3      2  -826.00  -827.31  -846.12    \n4      2   -39.57   -15.88    -9.16      \n\n       FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n0       48.68    46.12    39.39    18.57   \n1     5692.73  5663.83  5631.16  5626.39   \n2      675.01   605.52   499.45   440.77   \n3     -836.03  -745.50  -784.69  -791.22   \n4       -6.37   -16.13   -24.05    -0.90   \n\n    FLUX.8   FLUX.9    ...      FLUX.3188  \\\n0     6.98     6.63    ...          14.52       \n1  5569.47  5550.44    ...        -581.91    \n2   362.95   207.27    ...          17.82     \n3  -746.50  -709.53    ...         122.34       \n4   -45.20    -5.04    ...         -37.87     \n    FLUX.3189  FLUX.3190  FLUX.3191  \\\n0       19.29      14.44      -1.62   \n1     -984.09   -1230.89   -1600.45   \n2      -51.66     -48.29     -59.99   \n3       93.03      93.03      68.81   \n4      -61.85     -27.15     -21.18     \n\n   FLUX.3192  FLUX.3193  FLUX.3194  \\  \n0      13.33      45.50      31.93    \n1   -1824.53   -2061.17   -2265.98     \n2     -82.10    -174.54     -95.23      \n3       9.81      20.75      20.25    \n4     -33.76     -85.34     -81.46    \n\n   FLUX.3195  FLUX.3196  FLUX.3197  \n0      35.78     269.43      57.72  \n1   -2366.19   -2294.86   -2034.72  \n2    -162.68     -36.79      30.63  \n3    -120.81    -257.56    -215.41  \n4     -61.98     -69.34     -17.84  \n\n[5 rows x 3198 columns]\n```", "```\nx_train = train.drop('LABEL', axis=1)\ny_train = train.LABEL-1 #subtract one because of TGBT\nx_test = test.drop('LABEL', axis=1)\ny_test = test.LABEL-1\n```", "```\nnumeric_column_headers = x_train.columns.values.tolist()\n```", "```\nbc_fn = tf.feature_column.bucketized_column\nnc_fn = tf.feature_column.numeric_column\nbucketized_features = [bc_fn(source_column=nc_fn(key=column),\n                             boundaries=[x_train[column].mean()])\n                       for column in numeric_column_headers]\n```", "```\nall_features = bucketized_features\n```", "```\nbatch_size = 32\npi_fn = tf.estimator.inputs.pandas_input_fn\ntrain_input_fn = pi_fn(x = x_train,\n                       y = y_train,\n                       batch_size = batch_size,\n                       shuffle = True,\n                       num_epochs = None)\n```", "```\neval_input_fn = pi_fn(x = x_test,\n                      y = y_test,\n                      batch_size = batch_size,\n                      shuffle = False,\n                      num_epochs = 1)\n```", "```\nn_trees = 100\nn_steps = 100\n\nm_fn = tf.estimator.BoostedTreesClassifier\nmodel = m_fn(feature_columns=all_features,\n             n_trees = n_trees,\n             n_batches_per_layer = batch_size,\n             model_dir='./tfbtmodel')\n```", "```\nINFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': './tfbtmodel', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd48c93b38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n```", "```\nmodel.train(input_fn=train_input_fn, steps=n_steps)\n```", "```\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./tfbtmodel/model.ckpt-19201\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Saving checkpoints for 19201 into ./tfbtmodel/model.ckpt.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:loss = 1.0475121e-05, step = 19201\nINFO:tensorflow:Saving checkpoints for 19202 into ./tfbtmodel/model.ckpt.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Loss for final step: 1.0475121e-05.\n```", "```\nresults = model.evaluate(input_fn=eval_input_fn)\n```", "```\nINFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\nWARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2018-09-07-04:23:31\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./tfbtmodel/model.ckpt-19203\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2018-09-07-04:23:50\nINFO:tensorflow:Saving dict for global step 19203: accuracy = 0.99122804, accuracy_baseline = 0.99122804, auc = 0.49911517, auc_precision_recall = 0.004386465, average_loss = 0.09851996, global_step = 19203, label/mean = 0.00877193, loss = 0.09749381, precision = 0.0, prediction/mean = 4.402521e-05, recall = 0.0\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 19203: ./tfbtmodel/model.ckpt-19203\n```", "```\nINFO:tensorflow:Restoring parameters from ./tfbtmodel/model.ckpt-19203\n```", "```\nfor key,value in sorted(results.items()):\n    print('{}: {}'.format(key, value))\n```", "```\naccuracy: 0.9912280440330505\naccuracy_baseline: 0.9912280440330505\nauc: 0.4991151690483093\nauc_precision_recall: 0.004386465065181255\naverage_loss: 0.0985199585556984\nglobal_step: 19203\nlabel/mean: 0.008771929889917374\nloss: 0.09749381244182587\nprecision: 0.0\nprediction/mean: 4.4025211536791176e-05\nrecall: 0.0\n```"]