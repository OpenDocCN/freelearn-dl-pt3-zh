["```\n$> pip install git+https://github.com/tensorflow/docs\n```", "```\n$> pip install tensorflow-datasets Pillow opencv-contrib-python\n```", "```\n    import pathlib\n    import cv2\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    import tensorflow_datasets as tfds\n    import tensorflow_docs as tfdocs\n    import tensorflow_docs.plots\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import \\\n        SparseCategoricalCrossentropy\n    from tensorflow.keras.models import Model\n    from tensorflow.keras.optimizers import RMSprop\n    ```", "```\n    AUTOTUNE = tf.data.experimental.AUTOTUNE \n    ```", "```\n    def normalize(input_image, input_mask):\n       input_image = tf.cast(input_image, tf.float32) / 255.0\n        input_mask -= 1\n        return input_image, input_mask\n    ```", "```\n    @tf.function\n    def load_image(dataset_element, train=True):\n      input_image = tf.image.resize(dataset_element['image'],\n                                      (256, 256))\n        input_mask = tf.image.resize(\n            dataset_element['segmentation_mask'], (256, 256))\n        if train and np.random.uniform() > 0.5:\n            input_image = \n                  tf.image.flip_left_right(input_image)\n            input_mask = tf.image.flip_left_right(input_mask)\n        input_image, input_mask = normalize(input_image,\n                                            input_mask)\n        return input_image, input_mask\n    ```", "```\n    def _create_model(self):\n            input = Input(shape=self.input_shape)\n            x = Conv2D(filters=64,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block1_conv1')(input)\n            x = Conv2D(filters=64,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block1_conv2')(x)\n            x = MaxPooling2D(pool_size=(2, 2),\n                             strides=2,\n                             name='block1_pool')(x)\n    ```", "```\n            x = Conv2D(filters=128,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block2_conv1')(x)\n            x = Conv2D(filters=128,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block2_conv2')(x)\n            x = MaxPooling2D(pool_size=(2, 2),\n                             strides=2,\n\n               name='block2_pool')(x)\n    ```", "```\n            x = Conv2D(filters=256,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block3_conv1')(x)\n            x = Conv2D(filters=256,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block3_conv2')(x)\n            x = Conv2D(filters=256,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block3_conv3')(x)\n            x = MaxPooling2D(pool_size=(2, 2),\n                             strides=2,\n                             name='block3_pool')(x)\n            block3_pool = x\n    ```", "```\n            x = Conv2D(filters=512,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block4_conv1')(x)\n            x = Conv2D(filters=512,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block4_conv2')(x)\n            x = Conv2D(filters=512,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block4_conv3')(x)\n            block4_pool = MaxPooling2D(pool_size=(2, 2),\n                                       strides=2,\n                                 name='block4_pool')(x)\n    ```", "```\n            x = Conv2D(filters=512,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block5_conv1')(block4_pool)\n            x = Conv2D(filters=512,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block5_conv2')(x)\n            x = Conv2D(filters=512,\n                       kernel_size=(3, 3),\n                       activation='relu',\n                       padding='same',\n                       name='block5_conv3')(x)\n            block5_pool = MaxPooling2D(pool_size=(2, 2),\n                                       strides=2,\n                                   name='block5_pool')(x)\n    ```", "```\n            model = Model(input, block5_pool)\n            model.load_weights(self.vgg_weights_path,\n                               by_name=True)\n    ```", "```\n            output = Conv2D(filters=self.output_channels,\n                            kernel_size=(7, 7),\n                            activation='relu',\n                            padding='same',\n                            name='conv6')(block5_pool)\n            conv6_4 = Conv2DTranspose(\n                filters=self.output_channels,\n                kernel_size=(4, 4),\n                strides=4,\n                use_bias=False)(output)\n    ```", "```\n            pool4_n = Conv2D(filters=self.output_channels,\n                             kernel_size=(1, 1),\n                             activation='relu',\n                             padding='same',\n                             name='pool4_n')(block4_pool)\n            pool4_n_2 = Conv2DTranspose(\n                filters=self.output_channels,\n                kernel_size=(2, 2),\n                strides=2,\n                use_bias=False)(pool4_n)\n    ```", "```\n            pool3_n = Conv2D(filters=self.output_channels,\n                             kernel_size=(1, 1),\n                             activation='relu',\n                             padding='same',\n                             name='pool3_n')(block3_pool)\n            output = Add(name='add')([pool4_n_2,\n                                      pool3_n,\n                                      conv6_4])\n            output = Conv2DTranspose\n                           (filters=self.output_channels,\n                                     kernel_size=(8, 8),\n                                     strides=8,\n                                 use_bias=False)(output)\n            output = Softmax()(output)\n            return Model(input, output)\n    ```", "```\n        @staticmethod\n        def _plot_model_history(model_history, metric, \n                                            ylim=None):\n            plt.style.use('seaborn-darkgrid')\n            plotter = tfdocs.plots.HistoryPlotter()\n            plotter.plot({'Model': model_history}, \n                                metric=metric)\n            plt.title(f'{metric.upper()}')\n            if ylim is None:\n                plt.ylim([0, 1])\n            else:\n                plt.ylim(ylim)\n            plt.savefig(f'{metric}.png')\n            plt.close()\n    ```", "```\n        def train(self, train_dataset, epochs, \n                         steps_per_epoch,\n                  validation_dataset, validation_steps):\n            hist = \\\n                self.model.fit(train_dataset,\n                               epochs=epochs,\n                       steps_per_epoch=steps_per_epoch,\n                      validation_steps=validation_steps,\n                      validation_data=validation_dataset)\n            self._plot_model_history(hist, 'loss', [0., 2.0])\n            self._plot_model_history(hist, 'accuracy')\n    ```", "```\n        @staticmethod\n        def _process_mask(mask):\n            mask = (mask.numpy() * 127.5).astype('uint8')\n            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n            return mask\n    ```", "```\n        def _save_image_and_masks(self, image,\n                                  ground_truth_mask,\n                                  prediction_mask,\n                                  image_id):\n            image = (image.numpy() * 255.0).astype('uint8')\n            gt_mask = self._process_mask(ground_truth_mask)\n            pred_mask = self._process_mask(prediction_mask)\n            mosaic = np.hstack([image, gt_mask, pred_mask])\n            mosaic = cv2.cvtColor(mosaic, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(f'mosaic_{image_id}.jpg', mosaic)\n    ```", "```\n        @staticmethod\n        def _create_mask(prediction_mask):\n            prediction_mask = tf.argmax(prediction_mask, \n                                         axis=-1)\n            prediction_mask = prediction_mask[..., \n                                              tf.newaxis]\n            return prediction_mask[0]\n    ```", "```\n        def _save_predictions(self, dataset, \n                               sample_size=1):\n            for id, (image, mask) in \\\n                    enumerate(dataset.take(sample_size), \n                                            start=1):\n                pred_mask = self.model.predict(image)\n                pred_mask = self._create_mask(pred_mask)\n                image = image[0]\n                ground_truth_mask = mask[0]\n                self._save_image_and_masks(image,\n                                      ground_truth_mask,\n                                           pred_mask,\n                                           image_id=id)\n    ```", "```\n        def evaluate(self, test_dataset, sample_size=5):\n            result = self.model.evaluate(test_dataset)\n            print(f'Accuracy: {result[1] * 100:.2f}%')\n            self._save_predictions(test_dataset, \n                                    sample_size)\n    ```", "```\n    dataset, info = tfdata.load('oxford_iiit_pet', \n                                 with_info=True)\n    ```", "```\n    TRAIN_SIZE = info.splits['train'].num_examples\n    VALIDATION_SIZE = info.splits['test'].num_examples\n    BATCH_SIZE = 32\n    STEPS_PER_EPOCH = TRAIN_SIZE // BATCH_SIZE\n    VALIDATION_SUBSPLITS = 5\n    VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE\n    VALIDATION_STEPS //= VALIDATION_SUBSPLITS\n    BUFFER_SIZE = 1000\n    ```", "```\n    train_dataset = (dataset['train']\n                     .map(load_image, num_parallel_\n                     calls=AUTOTUNE)\n                     .cache()\n                     .shuffle(BUFFER_SIZE)\n                     .batch(BATCH_SIZE)\n                     .repeat()\n                     .prefetch(buffer_size=AUTOTUNE))\n    test_dataset = (dataset['test']\n                    .map(lambda d: load_image(d,train=False),\n                         num_parallel_calls=AUTOTUNE)\n                    .batch(BATCH_SIZE))\n    ```", "```\n    fcn = FCN(output_channels=3)\n    fcn.train(train_dataset,\n              epochs=120,\n              steps_per_epoch=STEPS_PER_EPOCH,\n              validation_steps=VALIDATION_STEPS,\n              validation_dataset=test_dataset)\n    ```", "```\n    unet.evaluate(test_dataset)\n    ```", "```\n$> pip install git+https://github.com/tensorflow/docs\n```", "```\n$> pip install tensorflow-datasets Pillow opencv-contrib-python\n```", "```\n    import cv2\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    import tensorflow_datasets as tfdata\n    import tensorflow_docs as tfdocs\n    import tensorflow_docs.plots\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import \\\n        SparseCategoricalCrossentropy\n    from tensorflow.keras.models import *\n    from tensorflow.keras.optimizers import RMSprop\n    ```", "```\n    AUTOTUNE = tf.data.experimental.AUTOTUNE \n    ```", "```\n    def normalize(input_image, input_mask):\n        input_image = tf.cast(input_image, tf.float32) / 255.0\n        input_mask -= 1\n        return input_image, input_mask\n    ```", "```\n    @tf.function\n    def load_image(dataset_element, train=True):\n      input_image = tf.image.resize(dataset element['image'],\n                                      (256, 256))\n        input_mask = tf.image.resize(\n            dataset_element['segmentation_mask'],(256, 256))\n        if train and np.random.uniform() > 0.5:\n          input_image = tf.image.flip_left_right(input_image)\n            input_mask = tf.image.flip_left_right(input_mask)\n        input_image, input_mask = normalize(input_image,\n                                            input_mask)\n        return input_image, input_mask\n    ```", "```\n        @staticmethod\n        def _downsample(filters, size, batch_norm=True):\n        initializer = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2D(filters=filters,\n                              kernel_size=size,\n                              strides=2,\n                              padding='same',\n                              kernel_initializer=initializer,\n                              use_bias=False))\n            if batch_norm:\n                layers.add(BatchNormalization())\n            layers.add(LeakyReLU())\n            return layers\n    ```", "```\n        def _upsample(filters, size, dropout=False):\n            init = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2DTranspose(filters=filters,\n                                       kernel_size=size,\n                                       strides=2,\n                                       padding='same',\n                                 kernel_initializer=init,\n                                       use_bias=False))\n            layers.add(BatchNormalization())\n            if dropout:\n                layers.add(Dropout(rate=0.5))\n            layers.add(ReLU())\n            return layers\n    ```", "```\n        def _create_model(self):\n            down_stack = [self._downsample(64, 4,\n                                      batch_norm=False)]\n            for filters in (128, 256, 512, 512, 512, 512, \n                              512):\n                down_block = self._downsample(filters, 4)\n                down_stack.append(down_block)\n            up_stack = []\n            for _ in range(3):\n                up_block = self._upsample(512, 4, \n                                          dropout=True)\n                up_stack.append(up_block)\n            for filters in (512, 256, 128, 64):\n                up_block = self._upsample(filters, 4)\n                up_stack.append(up_block)\n    ```", "```\n            inputs = Input(shape=self.input_size)\n            x = inputs\n            skip_layers = []\n            for down in down_stack:\n                x = down(x)\n                skip_layers.append(x)\n            skip_layers = reversed(skip_layers[:-1])\n            for up, skip_connection in zip(up_stack, \n                                           skip_layers):\n                x = up(x)\n                x = Concatenate()([x, skip_connection])\n    ```", "```\n            init = tf.random_normal_initializer(0.0, 0.02)\n            output = Conv2DTranspose(\n                filters=self.output_channels,\n                kernel_size=3,\n                strides=2,\n                padding='same',\n                kernel_initializer=init)(x)\n            return Model(inputs, outputs=output)\n    ```", "```\n        @staticmethod\n        def _plot_model_history(model_history, metric, \n                                ylim=None):\n            plt.style.use('seaborn-darkgrid')\n            plotter = tfdocs.plots.HistoryPlotter()\n            plotter.plot({'Model': model_history}, \n                               metric=metric)\n            plt.title(f'{metric.upper()}')\n            if ylim is None:\n                plt.ylim([0, 1])\n            else:\n                plt.ylim(ylim)\n            plt.savefig(f'{metric}.png')\n            plt.close()\n    ```", "```\n        def train(self, train_dataset, epochs, \n                         steps_per_epoch,\n                  validation_dataset, validation_steps):\n            hist = \\\n                self.model.fit(train_dataset,\n                               epochs=epochs,\n                        steps_per_epoch=steps_per_epoch,\n                       validation_steps=validation_steps,\n                     validation_data=validation_dataset)\n            self._plot_model_history(hist, 'loss', [0., 2.0])\n            self._plot_model_history(hist, 'accuracy')\n    ```", "```\n        @staticmethod\n        def _process_mask(mask):\n            mask = (mask.numpy() * 127.5).astype('uint8')\n            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n            return mask\n    ```", "```\n        def _save_image_and_masks(self, image,\n                                  ground_truth_mask,\n                                  prediction_mask,\n                                  image_id):\n            image = (image.numpy() * \n                     255.0).astype('uint8')\n            gt_mask = self._process_mask(ground_truth_mask)\n            pred_mask = self._process_mask(prediction_mask)\n            mosaic = np.hstack([image, gt_mask, pred_mask])\n            mosaic = cv2.cvtColor(mosaic, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(f'mosaic_{image_id}.jpg', mosaic)\n    ```", "```\n        @staticmethod\n        def _create_mask(prediction_mask):\n            prediction_mask = tf.argmax(prediction_mask, \n                                           axis=-1)\n            prediction_mask = prediction_mask[...,tf.newaxis]\n            return prediction_mask[0]\n    ```", "```\n        def _save_predictions(self, dataset, \n                                sample_size=1):\n            for id, (image, mask) in \\\n                    enumerate(dataset.take(sample_size), \n                                           start=1):\n                pred_mask = self.model.predict(image)\n                pred_mask = self._create_mask(pred_mask)\n                image = image[0]\n                ground_truth_mask = mask[0]\n                self._save_image_and_masks(image,\n                                      ground_truth_mask,\n                                           pred_mask,\n                                           image_id=id)\n    ```", "```\n        def evaluate(self, test_dataset, sample_size=5):\n            result = self.model.evaluate(test_dataset)\n            print(f'Accuracy: {result[1] * 100:.2f}%')\n            self._save_predictions(test_dataset, \n                                   sample_size)\n    ```", "```\n    dataset, info = tfdata.load('oxford_iiit_pet',\n                                with_info=True)\n    ```", "```\n    TRAIN_SIZE = info.splits['train'].num_examples\n    VALIDATION_SIZE = info.splits['test'].num_examples\n    BATCH_SIZE = 64\n    STEPS_PER_EPOCH = TRAIN_SIZE // BATCH_SIZE\n    VALIDATION_SUBSPLITS = 5\n    VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE\n    VALIDATION_STEPS //= VALIDATION_SUBSPLITS\n    BUFFER_SIZE = 1000\n    ```", "```\n    train_dataset = (dataset['train']\n                     .map(load_image, num_parallel_\n                      calls=AUTOTUNE)\n                     .cache()\n                     .shuffle(BUFFER_SIZE)\n                     .batch(BATCH_SIZE)\n                     .repeat()\n                     .prefetch(buffer_size=AUTOTUNE))\n    test_dataset = (dataset['test']\n                    .map(lambda d: load_image(d, \n                      train=False),\n                         num_parallel_calls=AUTOTUNE)\n                    .batch(BATCH_SIZE))\n    ```", "```\n    unet = UNet()\n    unet.train(train_dataset,\n               epochs=50,\n               steps_per_epoch=STEPS_PER_EPOCH,\n               validation_steps=VALIDATION_STEPS,\n               validation_dataset=test_dataset)\n    ```", "```\n    unet.evaluate(test_dataset)\n    ```", "```\n$> pip install git+https://github.com/tensorflow/docs\n```", "```\n$> pip install tensorflow-datasets Pillow opencv-contrib-python\n```", "```\n    import cv2\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    import tensorflow_datasets as tfdata\n    import tensorflow_docs as tfdocs\n    import tensorflow_docs.plots\n    from tensorflow.keras.applications import MobileNetV2\n    from tensorflow.keras.layers import *\n    from tensorflow.keras.losses import \\\n        SparseCategoricalCrossentropy\n    from tensorflow.keras.models import *\n    from tensorflow.keras.optimizers import RMSprop\n    ```", "```\n    AUTOTUNE = tf.data.experimental.AUTOTUNE \n    ```", "```\n    def normalize(input_image, input_mask):\n        input_image = tf.cast(input_image, tf.float32) / \n                                       255.0\n        input_mask -= 1\n        return input_image, input_mask\n    ```", "```\n    @tf.function\n    def load_image(dataset_element, train=True):\n        input_image = tf.image.resize(dataset\n                               element['image'],(256, 256))\n        input_mask = tf.image.resize(\n            dataset_element['segmentation_mask'], (256,256))\n        if train and np.random.uniform() > 0.5:\n            input_image = tf.image.flip_left_right(input_\n                                                  image)\n            input_mask = \n               tf.image.flip_left_right(input_mask)\n        input_image, input_mask = normalize(input_image,\n                                            input_mask)\n        return input_image, input_mask\n    ```", "```\n        @staticmethod\n        def _upsample(filters, size, dropout=False):\n            init = tf.random_normal_initializer(0.0, 0.02)\n            layers = Sequential()\n            layers.add(Conv2DTranspose(filters=filters,\n                                       kernel_size=size,\n                                       strides=2,\n                                       padding='same',\n                               kernel_initializer=init,\n                                       use_bias=False))\n            layers.add(BatchNormalization())\n            if dropout:\n                layers.add(Dropout(rate=0.5))\n            layers.add(ReLU())\n            return layers\n    ```", "```\n        def _create_model(self):\n          layers = [self.pretrained_model.get_layer(l).output\n                      for l in self.target_layers]\n        down_stack = Model(inputs=self.pretrained_model.\n                                  input, outputs=layers)\n            down_stack.trainable = False\n            up_stack = []\n            for filters in (512, 256, 128, 64):\n                up_block = self._upsample(filters, 4)\n                up_stack.append(up_block)\n    ```", "```\n            inputs = Input(shape=self.input_size)\n            x = inputs\n            skip_layers = down_stack(x)\n            x = skip_layers[-1]\n            skip_layers = reversed(skip_layers[:-1])\n            for up, skip_connection in zip(up_stack, \n                                           skip_layers):\n                x = up(x)\n                x = Concatenate()([x, skip_connection])\n    ```", "```\n            init = tf.random_normal_initializer(0.0, 0.02)\n            output = Conv2DTranspose(\n                filters=self.output_channels,\n                kernel_size=3,\n                strides=2,\n                padding='same',\n                kernel_initializer=init)(x)\n            return Model(inputs, outputs=output)\n    ```", "```\n        @staticmethod\n        def _plot_model_history(model_history, metric, \n                                 ylim=None):\n            plt.style.use('seaborn-darkgrid')\n            plotter = tfdocs.plots.HistoryPlotter()\n            plotter.plot({'Model': model_history}, \n                            metric=metric)\n            plt.title(f'{metric.upper()}')\n            if ylim is None:\n                plt.ylim([0, 1])\n            else:\n                plt.ylim(ylim)\n            plt.savefig(f'{metric}.png')\n            plt.close()\n    ```", "```\n        def train(self, train_dataset, epochs, \n                      steps_per_epoch,\n                  validation_dataset, validation_steps):\n            hist = \\\n                self.model.fit(train_dataset,\n                             epochs=epochs,\n                            steps_per_epoch=steps_per_epoch,\n                           validation_steps=validation_steps,\n                          validation_data=validation_dataset)\n            self._plot_model_history(hist, 'loss', [0., 2.0])\n            self._plot_model_history(hist, 'accuracy')\n    ```", "```\n        @staticmethod\n        def _process_mask(mask):\n            mask = (mask.numpy() * 127.5).astype('uint8')\n            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n            return mask\n    ```", "```\n        def _save_image_and_masks(self, image,\n                                  ground_truth_mask,\n                                  prediction_mask,\n                                  image_id):\n            image = (image.numpy() * 255.0).astype('uint8')\n            gt_mask = self._process_mask(ground_truth_mask)\n            pred_mask = self._process_mask(prediction_mask)\n            mosaic = np.hstack([image, gt_mask, pred_mask])\n            mosaic = cv2.cvtColor(mosaic, cv2.COLOR_RGB2BGR)\n            cv2.imwrite(f'mosaic_{image_id}.jpg', mosaic)\n    ```", "```\n        @staticmethod\n        def _create_mask(prediction_mask):\n            prediction_mask = tf.argmax(prediction_mask, \n                                       axis=-1)\n            prediction_mask = prediction_mask[..., \n                                          tf.newaxis]\n            return prediction_mask[0]\n    ```", "```\n        def _save_predictions(self, dataset, \n                              sample_size=1):\n            for id, (image, mask) in \\\n                    enumerate(dataset.take(sample_size), \n                                start=1):\n                pred_mask = self.model.predict(image)\n                pred_mask = self._create_mask(pred_mask)\n                image = image[0]\n                ground_truth_mask = mask[0]\n                self._save_image_and_masks(image,\n                                      ground_truth_mask,\n                                           pred_mask,\n                                           image_id=id)\n    ```", "```\n        def evaluate(self, test_dataset, sample_size=5):\n            result = self.model.evaluate(test_dataset)\n            print(f'Accuracy: {result[1] * 100:.2f}%')\n            self._save_predictions(test_dataset, sample_size)\n    ```", "```\n    dataset, info = tfdata.load('oxford_iiit_pet',\n                                with_info=True)\n    ```", "```\n    TRAIN_SIZE = info.splits['train'].num_examples\n    VALIDATION_SIZE = info.splits['test'].num_examples\n    BATCH_SIZE = 64\n    STEPS_PER_EPOCH = TRAIN_SIZE // BATCH_SIZE\n    VALIDATION_SUBSPLITS = 5\n    VALIDATION_STEPS = VALIDATION_SIZE // BATCH_SIZE\n    VALIDATION_STEPS //= VALIDATION_SUBSPLITS\n    BUFFER_SIZE = 1000\n    ```", "```\n    train_dataset = (dataset['train']\n                     .map(load_image, num_parallel_\n                      calls=AUTOTUNE)\n                     .cache()\n                     .shuffle(BUFFER_SIZE)\n                     .batch(BATCH_SIZE)\n                     .repeat()\n                     .prefetch(buffer_size=AUTOTUNE))\n    test_dataset = (dataset['test']\n                    .map(lambda d: load_image(d, \n                         train=False),\n                         num_parallel_calls=AUTOTUNE)\n                    .batch(BATCH_SIZE))\n    ```", "```\n    unet = UNet()\n    unet.train(train_dataset,\n               epochs=50,\n               steps_per_epoch=STEPS_PER_EPOCH,\n               validation_steps=VALIDATION_STEPS,\n               validation_dataset=test_dataset)\n    ```", "```\n    unet.evaluate(test_dataset)\n    ```", "```\n$> pip install Pillow tensorflow-hub\n```", "```\n$> git clone –-depth 1 https://github.com/tensorflow/models\n```", "```\n$> sudo apt install -y protobuf-compiler\n$> cd models/research\n$> protoc object_detection/protos/*.proto --python_out=.\n$> cp object_detection/packages/tf2/setup.py .\n$> python -m pip install -q . \n```", "```\n    import glob\n    from io import BytesIO\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    import tensorflow_hub as hub\n    from PIL import Image\n    from object_detection.utils import ops\n    from object_detection.utils import visualization_utils as viz\n    from object_detection.utils.label_map_util import \\\n        create_category_index_from_labelmap\n    ```", "```\n    def load_image(path):\n        image_data = tf.io.gfile.GFile(path, 'rb').read()\n        image = Image.open(BytesIO(image_data))\n        width, height = image.size\n        shape = (1, height, width, 3)\n        image = np.array(image.getdata())\n        image = image.reshape(shape).astype('uint8')\n        return image\n    ```", "```\n    def get_and_save_predictions(model, image_path):\n        image = load_image(image_path)\n        results = model(image)\n    ```", "```\n    model_output = {k: v.numpy() for k, v in \n                    results.items()}\n    ```", "```\n      detection_masks = model_output['detection_masks'][0]\n     detection_masks = tf.convert_to_tensor(detection_masks)\n     detection_boxes = model_output['detection_boxes'][0]\n     detection_boxes = tf.convert_to_tensor(detection_boxes)\n    ```", "```\n        detection_masks_reframed = \\\n         ops.reframe_box_masks_to_image_masks(detection_\n                                    masks,detection_boxes,\n                                     image.shape[1],\n                                   image.shape[2])\n        detection_masks_reframed = \\\n            tf.cast(detection_masks_reframed > 0.5, \n                     tf.uint8)\n        model_output['detection_masks_reframed'] = \\\n            detection_masks_reframed.numpy()\n    ```", "```\n        boxes = model_output['detection_boxes'][0]\n        classes = \\\n           model_output['detection_classes'][0].astype('int')\n        scores = model_output['detection_scores'][0]\n        masks = model_output['detection_masks_reframed']\n        image_with_mask = image.copy()\n        viz.visualize_boxes_and_labels_on_image_array(\n            image=image_with_mask[0],\n            boxes=boxes,\n            classes=classes,\n            scores=scores,\n            category_index=CATEGORY_IDX,\n            use_normalized_coordinates=True,\n            max_boxes_to_draw=200,\n            min_score_thresh=0.30,\n            agnostic_mode=False,\n            instance_masks=masks,\n            line_thickness=5\n        )\n    ```", "```\n        plt.figure(figsize=(24, 32))\n        plt.imshow(image_with_mask[0])\n        plt.savefig(f'output/{image_path.split(\"/\")[-1]}')\n    ```", "```\n    labels_path = 'resources/mscoco_label_map.pbtxt'\n    CATEGORY_IDX =create_category_index_from_labelmap(labels_path)\n    ```", "```\n    MODEL_PATH = ('https://tfhub.dev/tensorflow/mask_rcnn/'\n                  'inception_resnet_v2_1024x1024/1')\n    mask_rcnn = hub.load(MODEL_PATH)\n    ```"]