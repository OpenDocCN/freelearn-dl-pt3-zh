["```\n    import tensorflow as tf \n    ```", "```\n    a = tf.Variable(4.)\n    x_data = tf.keras.Input(shape=(1,))\n    x_val = 5. \n    ```", "```\n    multiply_layer = tf.keras.layers.Lambda(lambda x:tf.multiply(a, x))\n    outputs = multiply_layer(x_data)\n    model = tf.keras.Model(inputs=x_data, outputs=outputs, name=\"gate_1\") \n    ```", "```\n    optimizer=tf.keras.optimizers.SGD(0.01) \n    ```", "```\n    print('Optimizing a Multiplication Gate Output to 50.')\n    for i in range(10):\n\n        # Open a GradientTape.\n        with tf.GradientTape() as tape:\n\n            # Forward pass.\n            mult_output = model(x_val)\n\n            # Loss value as the difference between\n            # the output and a target value, 50.\n            loss_value = tf.square(tf.subtract(mult_output, 50.))\n\n        # Get gradients of loss with reference to the variable \"a\" to adjust.\n        gradients = tape.gradient(loss_value, a)\n\n        # Update the variable \"a\" of the model.\n        optimizer.apply_gradients(zip([gradients], [a]))\n\n        print(\"{} * {} = {}\".format(a.numpy(), x_val, a.numpy() * x_val)) \n    ```", "```\n    Optimizing a Multiplication Gate Output to 50\\. \n    7.0 * 5.0 = 35.0 \n    8.5 * 5.0 = 42.5 \n    9.25 * 5.0 = 46.25 \n    9.625 * 5.0 = 48.125 \n    9.8125 * 5.0 = 49.0625 \n    9.90625 * 5.0 = 49.5312 \n    9.95312 * 5.0 = 49.7656 \n    9.97656 * 5.0 = 49.8828 \n    9.98828 * 5.0 = 49.9414 \n    9.99414 * 5.0 = 49.9707 \n    ```", "```\n    import tensorflow as tf\n    # Initialize variables and input data\n    x_data = tf.keras.Input(dtype=tf.float32, shape=(1,))\n    x_val = 5.\n    a = tf.Variable(1., dtype=tf.float32)\n    b = tf.Variable(1., dtype=tf.float32)\n    # Add a layer which computes f(x) = a * x\n    multiply_layer = tf.keras.layers.Lambda(lambda x:tf.multiply(a, x))\n    # Add a layer which computes f(x) = b + x\n    add_layer = tf.keras.layers.Lambda(lambda x:tf.add(b, x))\n    res = multiply_layer(x_data)\n    outputs = add_layer(res)\n    # Build the model\n    model = tf.keras.Model(inputs=x_data, outputs=outputs, name=\"gate_2\")\n    # Optimizer\n    optimizer=tf.keras.optimizers.SGD(0.01) \n    ```", "```\n    print('Optimizing two Gate Output to 50.')\n    for i in range(10):\n\n        # Open a GradientTape.\n        with tf.GradientTape(persistent=True) as tape:\n\n            # Forward pass.\n            two_gate_output = model(x_val)\n\n            # Loss value as the difference between\n            # the output and a target value, 50.\n            loss_value = tf.square(tf.subtract(two_gate_output, 50.))\n\n        # Get gradients of loss with reference to \n        # the variables \"a\" and \"b\" to adjust.\n        gradients_a = tape.gradient(loss_value, a)\n        gradients_b = tape.gradient(loss_value , b)\n\n        # Update the variables \"a\" and \"b\" of the model.\n        optimizer.apply_gradients(zip([gradients_a, gradients_b], [a, b]))\n\n        print(\"Step: {} ==> {} * {} + {}= {}\".format(i, a.numpy(),\n                                                     x_val, b.numpy(),\n                                                     a.numpy()*x_val+b.numpy())) \n    ```", "```\n    Optimizing Two Gate Output to 50\\. \n    5.4 * 5.0 + 1.88 = 28.88 \n    7.512 * 5.0 + 2.3024 = 39.8624 \n    8.52576 * 5.0 + 2.50515 = 45.134 \n    9.01236 * 5.0 + 2.60247 = 47.6643 \n    9.24593 * 5.0 + 2.64919 = 48.8789 \n    9.35805 * 5.0 + 2.67161 = 49.4619 \n    9.41186 * 5.0 + 2.68237 = 49.7417 \n    9.43769 * 5.0 + 2.68754 = 49.876 \n    9.45009 * 5.0 + 2.69002 = 49.9405 \n    9.45605 * 5.0 + 2.69121 = 49.9714 \n    ```", "```\n    import tensorflow as tf \n    import numpy as np \n    import matplotlib.pyplot as plt \n    tf.random.set_seed(5)\n    np.random.seed(42) \n    ```", "```\n    batch_size = 50 \n    x_data = tf.keras.Input(shape=(1,))\n    x_data = tf.keras.Input(shape=(1,))\n    a1 = tf.Variable(tf.random.normal(shape=[1,1], seed=5))\n    b1 = tf.Variable(tf.random.uniform(shape=[1,1], seed=5))\n    a2 = tf.Variable(tf.random.normal(shape=[1,1], seed=5))\n    b2 = tf.Variable(tf.random.uniform(shape=[1,1], seed=5)) \n    ```", "```\n    class MyCustomGateSigmoid(tf.keras.layers.Layer):\n\n     def __init__(self, units, a1, b1):\n       super(MyCustomGateSigmoid, self).__init__()\n       self.units = units\n       self.a1 = a1\n       self.b1 = b1\n     # Compute f(x) = sigmoid(a1 * x + b1)\n     def call(self, inputs):\n       return tf.math.sigmoid(inputs * self.a1 + self.b1)\n    # Add a layer which computes f(x) = sigmoid(a1 * x + b1)\n    my_custom_gate_sigmoid = MyCustomGateSigmoid(units=1, a1=a1, b1=b1)\n    output_sigmoid = my_custom_gate_sigmoid(x_data)\n    # Build the model\n    model_sigmoid = tf.keras.Model(inputs=x_data, outputs=output_sigmoid, name=\"gate_sigmoid\")\n    class MyCustomGateRelu(tf.keras.layers.Layer):\n\n     def __init__(self, units, a2, b2):\n       super(MyCustomGateRelu, self).__init__()\n       self.units = units\n       self.a2 = a2\n       self.b2 = b2\n     # Compute f(x) = relu(a2 * x + b2)\n     def call(self, inputs):\n       return tf.nn.relu(inputs * self.a2 + self.b2)\n    # Add a layer which computes f(x) = relu(a2 * x + b2)\n    my_custom_gate_relu = MyCustomGateRelu(units=1, a2=a2, b2=b2)\n    outputs_relu = my_custom_gate_relu(x_data)\n    # Build the model\n    model_relu = tf.keras.Model(inputs=x_data, outputs=outputs_relu, name=\"gate_relu\") \n    ```", "```\n    optimizer=tf.keras.optimizers.SGD(0.01) \n    ```", "```\n    # Run loop across gate\n    print('\\n Optimizing Sigmoid AND Relu Output to 0.75')\n    loss_vec_sigmoid = []\n    loss_vec_relu = []\n    activation_sigmoid = []\n    activation_relu = []\n    for i in range(500):\n\n        rand_indices = np.random.choice(len(x), size=batch_size)\n        x_vals = np.transpose([x[rand_indices]])\n        # Open a GradientTape.\n        with tf.GradientTape(persistent=True) as tape:\n\n            # Forward pass.\n            output_sigmoid = model_sigmoid(x_vals)\n            output_relu = model_relu(x_vals)\n\n            # Loss value as the difference as the difference between\n            # the output and a target value, 0.75.\n            loss_sigmoid = tf.reduce_mean(tf.square(tf.subtract(output_sigmoid, 0.75)))\n            loss_vec_sigmoid.append(loss_sigmoid)\n            loss_relu = tf.reduce_mean(tf.square(tf.subtract(output_relu, 0.75)))\n            loss_vec_relu.append(loss_relu)\n\n        # Get gradients of loss_sigmoid with reference to the variable \"a1\" and \"b1\" to adjust.\n        gradients_a1 = tape.gradient(loss_sigmoid, my_custom_gate_sigmoid.a1)\n        gradients_b1 = tape.gradient(loss_sigmoid , my_custom_gate_sigmoid.b1)\n\n        # Get gradients of loss_relu with reference to the variable \"a2\" and \"b2\" to adjust.\n        gradients_a2 = tape.gradient(loss_relu, my_custom_gate_relu.a2)\n        gradients_b2 = tape.gradient(loss_relu , my_custom_gate_relu.b2)\n\n        # Update the variable \"a1\" and \"b1\" of the model.\n        optimizer.apply_gradients(zip([gradients_a1, gradients_b1], [my_custom_gate_sigmoid.a1, my_custom_gate_sigmoid.b1]))\n\n        # Update the variable \"a2\" and \"b2\" of the model.\n        optimizer.apply_gradients(zip([gradients_a2, gradients_b2], [my_custom_gate_relu.a2, my_custom_gate_relu.b2]))\n\n        output_sigmoid = model_sigmoid(x_vals)\n        output_relu = model_relu(x_vals)\n\n        activation_sigmoid.append(np.mean(output_sigmoid))\n        activation_relu.append(np.mean(output_relu))\n\n        if i%50==0:\n            print('sigmoid = ' + str(np.mean(output_sigmoid)) + ' relu = ' + str(np.mean(output_relu))) \n    ```", "```\n    plt.plot(activation_sigmoid, 'k-', label='Sigmoid Activation') \n    plt.plot(activation_relu, 'r--', label='Relu Activation') \n    plt.ylim([0, 1.0]) \n    plt.title('Activation Outputs') \n    plt.xlabel('Generation') \n    plt.ylabel('Outputs') \n    plt.legend(loc='upper right') \n    plt.show() \n    plt.plot(loss_vec_sigmoid, 'k-', label='Sigmoid Loss') \n    plt.plot(loss_vec_relu, 'r--', label='Relu Loss') \n    plt.ylim([0, 1.0]) \n    plt.title('Loss per Generation') \n    plt.xlabel('Generation') \n    plt.ylabel('Loss') \n    plt.legend(loc='upper right') \n    plt.show() \n    ```", "```\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    from sklearn import datasets \n    ```", "```\n    iris = datasets.load_iris() \n    x_vals = np.array([x[0:3] for x in iris.data]) \n    y_vals = np.array([x[3] for x in iris.data]) \n    ```", "```\n    seed = 3 \n    tf.set_random_seed(seed) \n    np.random.seed(seed) \n    ```", "```\n    train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False) \n    test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices))) \n    x_vals_train = x_vals[train_indices] \n    x_vals_test = x_vals[test_indices] \n    y_vals_train = y_vals[train_indices] \n    y_vals_test = y_vals[test_indices]\n    def normalize_cols(m): \n        col_max = m.max(axis=0) \n        col_min = m.min(axis=0) \n        return (m-col_min) / (col_max - col_min) \n    x_vals_train = np.nan_to_num(normalize_cols(x_vals_train)) \n    x_vals_test = np.nan_to_num(normalize_cols(x_vals_test)) \n    ```", "```\n    batch_size = 50 \n    x_data = tf.keras.Input(dtype=tf.float32, shape=(3,)) \n    ```", "```\n    hidden_layer_nodes = 5\n    a1 = tf.Variable(tf.random.normal(shape=[3,hidden_layer_nodes], seed=seed)) \n    b1 = tf.Variable(tf.random.normal(shape=[hidden_layer_nodes], seed=seed))   \n    a2 = tf.Variable(tf.random.normal(shape=[hidden_layer_nodes,1], seed=seed)) \n    b2 = tf.Variable(tf.random.normal(shape=[1], seed=seed)) \n    ```", "```\n    hidden_output = tf.keras.layers.Lambda(lambda x: tf.nn.relu(tf.add(tf.matmul(x, a1), b1)))\n    final_output = tf.keras.layers.Lambda(lambda x: tf.nn.relu(tf.add(tf.matmul(x, a2), b2)))\n    model = tf.keras.Model(inputs=x_data, outputs=output, name=\"1layer_neural_network\") \n    ```", "```\n    optimizer = tf.keras.optimizers.SGD(0.005) \n    ```", "```\n    # First we initialize the loss vectors for storage. \n    loss_vec = []\n    test_loss = []\n    for i in range(500):\n        rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n        rand_x = x_vals_train[rand_index]\n        rand_y = np.transpose([y_vals_train[rand_index]])\n\n        # Open a GradientTape.\n        with tf.GradientTape(persistent=True) as tape:\n\n            # Forward pass.\n            output = model(rand_x)\n\n            # Apply loss function (MSE)\n            loss = tf.reduce_mean(tf.square(rand_y - output))\n            loss_vec.append(np.sqrt(loss))       \n\n        # Get gradients of loss with reference to the variables to adjust.\n        gradients_a1 = tape.gradient(loss, a1)\n        gradients_b1 = tape.gradient(loss, b1)\n        gradients_a2 = tape.gradient(loss, a2)\n        gradients_b2 = tape.gradient(loss, b2)\n\n        # Update the variables of the model.\n        optimizer.apply_gradients(zip([gradients_a1, gradients_b1, gradients_a2, gradients_b2], [a1, b1, a2, b2]))\n\n        # Forward pass.\n        output_test = model(x_vals_test)\n        # Apply loss function (MSE) on test\n        loss_test = tf.reduce_mean(tf.square(np.transpose([y_vals_test]) - output_test))\n        test_loss.append(np.sqrt(loss_test))\n\n        if (i+1)%50==0:\n            print('Generation: ' + str(i+1) + '. Loss = ' + str(np.mean(loss)))\n            print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss)) \n    ```", "```\n    plt.plot(loss_vec, 'k-', label='Train Loss') \n    plt.plot(test_loss, 'r--', label='Test Loss') \n    plt.title('Loss (MSE) per Generation') \n    plt.xlabel('Generation') \n    plt.ylabel('Loss') \n    plt.legend(loc='upper right') \n    plt.show() \n    ```", "```\n    import tensorflow as tf \n    import numpy as np \n    ```", "```\n    data_size = 25\n    conv_size = 5\n    maxpool_size = 5\n    stride_size = 1\n    num_outputs = 5\n    x_input_1d = tf.keras.Input(dtype=tf.float32, shape=(data_size,1), name=\"input_layer\") \n    ```", "```\n    my_conv_output = tf.keras.layers.Conv1D(kernel_size=(conv_size),\n                                            filters=data_size, \n                                            strides=stride_size, \n                                            padding=\"VALID\",\n                                                           name=\"convolution_layer\")(x_input_1d) \n    ```", "```\n    my_activation_output = tf.keras.layers.ReLU(name=\"activation_layer\")(my_conv_output) \n    ```", "```\n    my_maxpool_output = tf.keras.layers.MaxPool1D(strides=stride_size,\n                                                                     pool_size=maxpool_size,\n                                                  padding='VALID',\n                                                  name=\"maxpool_layer\")(my_activation_output) \n    ```", "```\n    my_full_output = tf.keras.layers.Dense(units=num_outputs,\n                                           name=\"fully_connected_layer\")(my_maxpool_output) \n    ```", "```\n    print('>>>> 1D Data <<<<')\n    model_1D = tf.keras.Model(inputs=x_input_1d, outputs=my_full_output, name=\"model_1D\")\n    model_1D.summary()\n    # Input\n    print('\\n== input_layer ==')\n    print('Input = array of length %d' % (x_input_1d.shape.as_list()[1]))\n    # Convolution \n    print('\\n== convolution_layer ==')\n    print('Convolution w/ filter, length = %d, stride size = %d, results in an array of length %d' % \n          (conv_size,stride_size,my_conv_output.shape.as_list()[1]))\n    # Activation \n    print('\\n== activation_layer ==')\n    print('Input = above array of length %d' % (my_conv_output.shape.as_list()[1]))\n    print('ReLU element wise returns an array of length %d' % (my_activation_output.shape.as_list()[1]))\n    # Max Pool \n    print('\\n== maxpool_layer ==')\n    print('Input = above array of length %d' % (my_activation_output.shape.as_list()[1]))\n    print('MaxPool, window length = %d, stride size = %d, results in the array of length %d' %\n         (maxpool_size,stride_size,my_maxpool_output.shape.as_list()[1]))\n    # Fully Connected \n    print('\\n== fully_connected_layer ==')\n    print('Input = above array of length %d' % (my_maxpool_output.shape.as_list()[1]))\n    print('Fully connected layer on all 4 rows with %d outputs' % \n          (my_full_output.shape.as_list()[1])) \n    ```", "```\n    >>>> 1D Data <<<<\n    Model: \"model_1D\"\n    _________________________________________________________________\n    Layer (type)                 Output Shape              Param #   \n    =================================================================\n    input_layer (InputLayer)     [(None, 25, 1)]           0         \n    _________________________________________________________________\n    convolution_layer (Conv1D)   (None, 21, 25)            150       \n    _________________________________________________________________\n    activation_layer (ReLU)      (None, 21, 25)            0         \n    _________________________________________________________________\n    maxpool_layer (MaxPooling1D) (None, 17, 25)            0         \n    _________________________________________________________________\n    fully_connected_layer (Dense (None, 17, 5)             130       \n    =================================================================\n    Total params: 280\n    Trainable params: 280\n    Non-trainable params: 0\n    _________________________________________________________________\n    == input_layer ==\n    Input = array of length 25\n    == convolution_layer ==\n    Convolution w/ filter, length = 5, stride size = 1, results in an array of length 21\n    == activation_layer ==\n    Input = above array of length 21\n    ReLU element wise returns an array of length 21\n    == maxpool_layer ==\n    Input = above array of length 21\n    MaxPool, window length = 5, stride size = 1, results in the array of length 17\n    == fully_connected_layer ==\n    Input = above array of length 17\n    Fully connected layer on all 4 rows with 17 outputs \n    ```", "```\n    row_size = 10\n    col_size = 10\n    conv_size = 2\n    conv_stride_size = 2\n    maxpool_size = 2\n    maxpool_stride_size = 1\n    num_outputs = 5 \n    ```", "```\n    x_input_2d = tf.keras.Input(dtype=tf.float32, shape=(row_size,col_size, 1), name=\"input_layer_2d\") \n    ```", "```\n    my_convolution_output_2d = tf.keras.layers.Conv2D(kernel_size=(conv_size),\n                                                      filters=conv_size,\n                                                      strides=conv_stride_size,\n                                                      padding=\"VALID\",\n                                                      name=\"convolution_layer_2d\")(x_input_2d) \n    ```", "```\n    my_activation_output_2d = tf.keras.layers.ReLU(name=\"activation_layer_2d\")(my_convolution_output_2d) \n    ```", "```\n    my_maxpool_output_2d = tf.keras.layers.MaxPool2D(strides=maxpool_stride_size,\n                                                  pool_size=maxpool_size,\n                                                  padding='VALID',\n                                                  name=\"maxpool_layer_2d\")(my_activation_output_2d) \n    ```", "```\n    my_full_output_2d = tf.keras.layers.Dense(units=num_outputs,\n\n    name=\"fully_connected_layer_2d\")(my_maxpool_output_2d) \n    ```", "```\n    print('>>>> 2D Data <<<<')\n    model_2D = tf.keras.Model(inputs=x_input_2d, outputs=my_full_output_2d, name=\"model_2D\")\n    model_2D.summary()\n    # Input \n    print('\\n== input_layer ==')\n    print('Input = %s array' % (x_input_2d.shape.as_list()[1:3]))\n    # Convolution\n    print('\\n== convolution_layer ==')\n    print('%s Convolution, stride size = [%d, %d] , results in the %s array' % \n          ([conv_size,conv_size],conv_stride_size,conv_stride_size,my_convolution_output_2d.shape.as_list()[1:3]))\n    # Activation\n    print('\\n== activation_layer ==')\n    print('Input = the above %s array' % (my_convolution_output_2d.shape.as_list()[1:3]))\n    print('ReLU element wise returns the %s array' % (my_activation_output_2d.shape.as_list()[1:3]))\n    # Max Pool\n    print('\\n== maxpool_layer ==')\n    print('Input = the above %s array' % (my_activation_output_2d.shape.as_list()[1:3]))\n    print('MaxPool, stride size = [%d, %d], results in %s array' % \n          (maxpool_stride_size,maxpool_stride_size,my_maxpool_output_2d.shape.as_list()[1:3]))\n    # Fully Connected\n    print('\\n== fully_connected_layer ==')\n    print('Input = the above %s array' % (my_maxpool_output_2d.shape.as_list()[1:3]))\n    print('Fully connected layer on all %d rows results in %s outputs' % \n          (my_maxpool_output_2d.shape.as_list()[1],my_full_output_2d.shape.as_list()[3]))\n    feed_dict = {x_input_2d: data_2d} \n    ```", "```\n    >>>> 2D Data <<<<\n    Model: \"model_2D\"\n    _________________________________________________________________\n    Layer (type)                 Output Shape              Param #   \n    =================================================================\n    input_layer_2d (InputLayer)  [(None, 10, 10, 1)]       0         \n    _________________________________________________________________\n    convolution_layer_2d (Conv2D (None, 5, 5, 2)           10        \n    _________________________________________________________________\n    activation_layer_2d (ReLU)   (None, 5, 5, 2)           0         \n    _________________________________________________________________\n    maxpool_layer_2d (MaxPooling (None, 4, 4, 2)           0         \n    _________________________________________________________________\n    fully_connected_layer_2d (De (None, 4, 4, 5)           15        \n    =================================================================\n    Total params: 25\n    Trainable params: 25\n    Non-trainable params: 0\n    _________________________________________________________________\n    == input_layer ==\n    Input = [10, 10] array\n    == convolution_layer ==\n    [2, 2] Convolution, stride size = [2, 2] , results in the [5, 5] array\n    == activation_layer ==\n    Input = the above [5, 5] array\n    ReLU element wise returns the [5, 5] array\n    == maxpool_layer ==\n    Input = the above [5, 5] array\n    MaxPool, stride size = [1, 1], results in [4, 4] array\n    == fully_connected_layer ==\n    Input = the above [4, 4] array\n    Fully connected layer on all 4 rows results in 5 outputs \n    ```", "```\n    import tensorflow as tf\n    import matplotlib.pyplot as plt\n    import csv\n    import random\n    import numpy as np\n    import requests\n    import os \n    ```", "```\n    # name of data file\n    birth_weight_file = 'birth_weight.csv'\n    # download data and create data file if file does not exist in current directory\n    if not os.path.exists(birth_weight_file):\n        birthdata_url = 'https://github.com/PacktPublishing/Machine-Learning-Using-TensorFlow-Cookbook/blob/master/ch6/06_Using_Multiple_Layers/birth_weight.csv'\n        birth_file = requests.get(birthdata_url)\n        birth_data = birth_file.text.split('\\r\\n')\n        birth_header = birth_data[0].split('\\t')\n        birth_data = [[float(x) for x in y.split('\\t') if \n                                            len(x)>=1] \n    for y in birth_data[1:] if len(y)>=1]\n        with open(birth_weight_file, \"w\") as f:\n            writer = csv.writer(f)\n            writer.writerows([birth_header])\n            writer.writerows(birth_data)\n            f.close()\n    # read birth weight data into memory\n    birth_data = []\n    with open(birth_weight_file, newline='') as csvfile:\n        csv_reader = csv.reader(csvfile)\n        birth_header = next(csv_reader)\n        for row in csv_reader:\n            birth_data.append(row)\n    birth_data = [[float(x) for x in row] for row in birth_data]\n    # Extract y-target (birth weight)\n    y_vals = np.array([x[8] for x in birth_data])\n    # Filter for features of interest\n    cols_of_interest = ['AGE', 'LWT', 'RACE', 'SMOKE', 'PTL', 'HT', 'UI']\n    x_vals = np.array([[x[ix] for ix, feature in enumerate(birth_header) if feature in cols_of_interest] for x in birth_data]) \n    ```", "```\n    # make results reproducible\n    seed = 3\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    # set batch size for training\n    batch_size = 150 \n    ```", "```\n    train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n    test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n    x_vals_train = x_vals[train_indices]\n    x_vals_test = x_vals[test_indices]\n    y_vals_train = y_vals[train_indices]\n    y_vals_test = y_vals[test_indices]\n    # Record training column max and min for scaling of non-training data\n    train_max = np.max(x_vals_train, axis=0)\n    train_min = np.min(x_vals_train, axis=0)\n    # Normalize by column (min-max norm to be between 0 and 1)\n    def normalize_cols(mat, max_vals, min_vals):\n        return (mat - min_vals) / (max_vals - min_vals)\n    x_vals_train = np.nan_to_num(normalize_cols(x_vals_train, train_max, train_min))\n    x_vals_test = np.nan_to_num(normalize_cols(x_vals_test, train_max, train_min)) \n    ```", "```\n    # Define Variable Functions (weights and bias)\n    def init_weight(shape, st_dev):\n        weight = tf.Variable(tf.random.normal(shape, stddev=st_dev))\n        return(weight)\n\n    def init_bias(shape, st_dev):\n        bias = tf.Variable(tf.random.normal(shape, stddev=st_dev))\n        return(bias) \n    ```", "```\n    x_data = tf.keras.Input(dtype=tf.float32, shape=(7,)) \n    ```", "```\n    # Create a fully connected layer:\n    def fully_connected(input_layer, weights, biases):\n        return tf.keras.layers.Lambda(lambda x: tf.nn.relu(tf.add(tf.matmul(x, weights), biases)))(input_layer) \n    ```", "```\n    #--------Create the first layer (25 hidden nodes)--------\n    weight_1 = init_weight(shape=[7,25], st_dev=5.0)\n    bias_1 = init_bias(shape=[25], st_dev=10.0)\n    layer_1 = fully_connected(x_data, weight_1, bias_1)\n    #--------Create second layer (10 hidden nodes)--------\n    weight_2 = init_weight(shape=[25, 10], st_dev=5.0)\n    bias_2 = init_bias(shape=[10], st_dev=10.0)\n    layer_2 = fully_connected(layer_1, weight_2, bias_2)\n    #--------Create third layer (3 hidden nodes)--------\n    weight_3 = init_weight(shape=[10, 3], st_dev=5.0)\n    bias_3 = init_bias(shape=[3], st_dev=10.0)\n    layer_3 = fully_connected(layer_2, weight_3, bias_3)\n    #--------Create output layer (1 output value)--------\n    weight_4 = init_weight(shape=[3, 1], st_dev=5.0)\n    bias_4 = init_bias(shape=[1], st_dev=10.0)\n    final_output = fully_connected(layer_3, weight_4, bias_4)\n    model = tf.keras.Model(inputs=x_data, outputs=final_output, name=\"multiple_layers_neural_network\") \n    ```", "```\n    # Declare Adam optimizer\n    optimizer = tf.keras.optimizers.Adam(0.025)\n    # Training loop\n    loss_vec = []\n    test_loss = []\n    for i in range(200):\n        rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n        rand_x = x_vals_train[rand_index]\n        rand_y = np.transpose([y_vals_train[rand_index]])\n\n        # Open a GradientTape.\n        with tf.GradientTape(persistent=True) as tape:\n\n            # Forward pass.\n            output = model(rand_x)\n\n            # Apply loss function (MSE)\n            loss = tf.reduce_mean(tf.abs(rand_y - output))\n            loss_vec.append(loss)       \n\n        # Get gradients of loss with reference to the weights and bias variables to adjust.\n        gradients_w1 = tape.gradient(loss, weight_1)\n        gradients_b1 = tape.gradient(loss, bias_1)\n        gradients_w2 = tape.gradient(loss, weight_2)\n        gradients_b2 = tape.gradient(loss, bias_2)\n        gradients_w3 = tape.gradient(loss, weight_3)\n        gradients_b3 = tape.gradient(loss, bias_3)\n        gradients_w4 = tape.gradient(loss, weight_4)\n        gradients_b4 = tape.gradient(loss, bias_4)\n\n        # Update the weights and bias variables of the model.\n        optimizer.apply_gradients(zip([gradients_w1, gradients_b1, gradients_w2, gradients_b2,\n                                      gradients_w3, gradients_b3, gradients_w4, gradients_b4], \n                                      [weight_1, bias_1, weight_2, bias_2, weight_3, bias_3, weight_4, bias_4]))\n\n        # Forward pass.\n        output_test = model(x_vals_test)\n        # Apply loss function (MSE) on test\n        temp_loss = tf.reduce_mean(tf.abs(np.transpose([y_vals_test]) - output_test))\n        test_loss.append(temp_loss)\n\n        if (i+1) % 25 == 0:\n            print('Generation: ' + str(i+1) + '. Loss = ' + str(loss.numpy())) \n    ```", "```\n    Generation: 25\\. Loss = 1921.8002\n    Generation: 50\\. Loss = 1453.3898\n    Generation: 75\\. Loss = 987.57074\n    Generation: 100\\. Loss = 709.81696\n    Generation: 125\\. Loss = 508.625\n    Generation: 150\\. Loss = 541.36774\n    Generation: 175\\. Loss = 539.6093\n    Generation: 200\\. Loss = 441.64032 \n    ```", "```\n    plt.plot(loss_vec, 'k-', label='Train Loss') \n    plt.plot(test_loss, 'r--', label='Test Loss') \n    plt.title('Loss per Generation') \n    plt.xlabel('Generation') \n    plt.ylabel('Loss') \n    plt.legend(loc='upper right') \n    plt.show() \n    ```", "```\n    # Model Accuracy\n    actuals = np.array([x[0] for x in birth_data])\n    test_actuals = actuals[test_indices]\n    train_actuals = actuals[train_indices]\n    test_preds = model(x_vals_test)\n    train_preds = model(x_vals_train)\n    test_preds = np.array([1.0 if x < 2500.0 else 0.0 for x in test_preds])\n    train_preds = np.array([1.0 if x < 2500.0 else 0.0 for x in train_preds])\n    # Print out accuracies\n    test_acc = np.mean([x == y for x, y in zip(test_preds, test_actuals)])\n    train_acc = np.mean([x == y for x, y in zip(train_preds, train_actuals)])\n    print('On predicting the category of low birthweight from regression output (<2500g):')\n    print('Test Accuracy: {}'.format(test_acc))\n    print('Train Accuracy: {}'.format(train_acc)) \n    ```", "```\n    Test Accuracy: 0.7631578947368421\n    Train Accuracy: 0.7880794701986755 \n    ```", "```\n    import matplotlib.pyplot as plt \n    import numpy as np \n    import tensorflow as tf \n    import requests \n    import os.path\n    import csv \n    ```", "```\n    # Name of data file\n    birth_weight_file = 'birth_weight.csv'\n    birthdata_url = 'https://github.com/PacktPublishing/Machine-Learning-Using-TensorFlow-Cookbook/blob/master/ch6/06_Using_Multiple_Layers/birth_weight.csv'\n    # Download data and create data file if file does not exist in current directory\n    if not os.path.exists(birth_weight_file):\n        birth_file = requests.get(birthdata_url)\n        birth_data = birth_file.text.split('\\r\\n')\n        birth_header = birth_data[0].split('\\t')\n        birth_data = [[float(x) for x in y.split('\\t') if len(x) >= 1]\n                      for y in birth_data[1:] if len(y) >= 1]\n        with open(birth_weight_file, \"w\") as f:\n            writer = csv.writer(f)\n            writer.writerows([birth_header])\n            writer.writerows(birth_data) \n    # read birth weight data into memory\n    birth_data = []\n    with open(birth_weight_file, newline='') as csvfile:\n        csv_reader = csv.reader(csvfile)\n        birth_header = next(csv_reader)\n        for row in csv_reader:\n            birth_data.append(row)\n    birth_data = [[float(x) for x in row] for row in birth_data]\n    # Pull out target variable\n    y_vals = np.array([x[0] for x in birth_data])\n    # Pull out predictor variables (not id, not target, and not birthweight)\n    x_vals = np.array([x[1:8] for x in birth_data])\n\n    train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False) \n    test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices))) \n    x_vals_train = x_vals[train_indices] \n    x_vals_test = x_vals[test_indices] \n    y_vals_train = y_vals[train_indices] \n    y_vals_test = y_vals[test_indices] \n\n    def normalize_cols(m, col_min=np.array([None]), col_max=np.array([None])):\n        if not col_min[0]:\n            col_min = m.min(axis=0)\n        if not col_max[0]:\n            col_max = m.max(axis=0)\n        return (m - col_min) / (col_max - col_min), col_min, col_max\n    x_vals_train, train_min, train_max = np.nan_to_num(normalize_cols(x_vals_train))\n    x_vals_test, _, _ = np.nan_to_num(normalize_cols(x_vals_test, train_min, train_max)) \n    ```", "```\n    batch_size = 90 \n    seed = 98\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    x_data = tf.keras.Input(dtype=tf.float64, shape=(7,)) \n    ```", "```\n    # Create variable definition\n    def init_variable(shape):\n        return(tf.Variable(tf.random.normal(shape=shape, dtype=\"float64\", seed=seed)))\n    # Create a logistic layer definition\n    def logistic(input_layer, multiplication_weight, bias_weight, activation = True):\n\n        # We separate the activation at the end because the loss function will\n        # implement the last sigmoid necessary\n        if activation:\n            return tf.keras.layers.Lambda(lambda x: tf.nn.sigmoid(tf.add(tf.matmul(x, multiplication_weight), bias_weight)))(input_layer)\n        else:\n            return tf.keras.layers.Lambda(lambda x: tf.add(tf.matmul(x, multiplication_weight), bias_weight))(input_layer) \n    ```", "```\n    # First logistic layer (7 inputs to 14 hidden nodes)\n    A1 = init_variable(shape=[7,14])\n    b1 = init_variable(shape=[14])\n    logistic_layer1 = logistic(x_data, A1, b1)\n    # Second logistic layer (14 hidden inputs to 5 hidden nodes)\n    A2 = init_variable(shape=[14,5])\n    b2 = init_variable(shape=[5])\n    logistic_layer2 = logistic(logistic_layer1, A2, b2)\n    # Final output layer (5 hidden nodes to 1 output)\n    A3 = init_variable(shape=[5,1])\n    b3 = init_variable(shape=[1])\n    final_output = logistic(logistic_layer2, A3, b3, activation=False)\n    # Build the model\n    model = tf.keras.Model(inputs=x_data, outputs=final_output, name=\"improving_linear_reg_neural_network\") \n    ```", "```\n    # Loss function (Cross Entropy loss)\n    def cross_entropy(final_output, y_target):\n        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=final_output, labels=y_target)) \n    # Declare optimizer\n    optimizer = tf.keras.optimizers.Adam(0.002) \n    ```", "```\n    # Accuracy\n    def compute_accuracy(final_output, y_target):\n        prediction = tf.round(tf.nn.sigmoid(final_output))\n        predictions_correct = tf.cast(tf.equal(prediction, y_target), tf.float32)\n        return tf.reduce_mean(predictions_correct) \n    ```", "```\n    # Training loop\n    loss_vec = []\n    train_acc = []\n    test_acc = []\n    for i in range(1500):\n        rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n        rand_x = x_vals_train[rand_index]\n        rand_y = np.transpose([y_vals_train[rand_index]])\n\n         # Open a GradientTape.\n        with tf.GradientTape(persistent=True) as tape:\n\n            # Forward pass.\n            output = model(rand_x)\n\n            # Apply loss function (Cross Entropy loss)\n            loss = cross_entropy(output, rand_y)\n            loss_vec.append(loss)\n        # Get gradients of loss with reference to the weights and bias variables to adjust.\n        gradients_A1 = tape.gradient(loss, A1)\n        gradients_b1 = tape.gradient(loss, b1)\n        gradients_A2 = tape.gradient(loss, A2)\n        gradients_b2 = tape.gradient(loss, b2)\n        gradients_A3 = tape.gradient(loss, A3)\n        gradients_b3 = tape.gradient(loss, b3)\n\n        # Update the weights and bias variables of the model.\n        optimizer.apply_gradients(zip([gradients_A1, gradients_b1,gradients_A2, gradients_b2, gradients_A3, gradients_b3], \n                                      [A1, b1, A2, b2, A3, b3]))\n\n        temp_acc_train = compute_accuracy(model(x_vals_train), np.transpose([y_vals_train]))\n        train_acc.append(temp_acc_train)\n\n        temp_acc_test = compute_accuracy(model(x_vals_test), np.transpose([y_vals_test]))\n        test_acc.append(temp_acc_test)\n\n        if (i+1)%150==0:\n            print('Loss = ' + str(loss.numpy())) \n    ```", "```\n    Loss = 0.5885411040188063\n    Loss = 0.581099555117532\n    Loss = 0.6071769535895101\n    Loss = 0.5043174136225906\n    Loss = 0.5023625777095964\n    Loss = 0.485112570717733\n    Loss = 0.5906992621835641\n    Loss = 0.4280814147901789\n    Loss = 0.5425164697605331\n    Loss = 0.35608561907724867 \n    ```", "```\n    # Plot loss over time \n    plt.plot(loss_vec, 'k-') \n    plt.title('Cross Entropy Loss per Generation') \n    plt.xlabel('Generation') \n    plt.ylabel('Cross Entropy Loss') \n    plt.show() \n    # Plot train and test accuracy \n    plt.plot(train_acc, 'k-', label='Train Set Accuracy') \n    plt.plot(test_acc, 'r--', label='Test Set Accuracy') \n    plt.title('Train and Test Accuracy') \n    plt.xlabel('Generation') \n    plt.ylabel('Accuracy') \n    plt.legend(loc='lower right') \n    plt.show() \n    ```", "```\n    import tensorflow as tf\n    import matplotlib.pyplot as plt\n    import csv\n    import numpy as np\n    import random \n    ```", "```\n    batch_size = 50 \n    ```", "```\n     def print_board(board):\n        symbols = ['O', ' ', 'X']\n        board_plus1 = [int(x) + 1 for x in board]\n        board_line1 = ' {} | {} | \n                               {}'.format(symbols[board_plus1[0]],\n                                          symbols[board_plus1[1]],\n                                          symbols[board_plus1[2]])\n        board_line2 = ' {} | {} | \n                               {}'.format(symbols[board_plus1[3]],\n                                          symbols[board_plus1[4]],\n                                          symbols[board_plus1[5]])\n        board_line3 = ' {} | {} | \n                               {}'.format(symbols[board_plus1[6]],\n                                          symbols[board_plus1[7]],\n                                          symbols[board_plus1[8]])\n        print(board_line1)\n        print('___________')\n        print(board_line2)\n        print('___________')\n        print(board_line3) \n    ```", "```\n    def get_symmetry(board, response, transformation): \n        ''' \n        :param board: list of integers 9 long: \n         opposing mark = -1 \n         friendly mark = 1 \n         empty space = 0 \n        :param transformation: one of five transformations on a \n                                                board: \n         rotate180, rotate90, rotate270, flip_v, flip_h \n        :return: tuple: (new_board, new_response) \n        ''' \n\n        if transformation == 'rotate180': \n            new_response = 8 - response \n            return board[::-1], new_response \n\n        elif transformation == 'rotate90': \n            new_response = [6, 3, 0, 7, 4, 1, 8, 5, 2].index(response) \n            tuple_board = list(zip(*[board[6:9], board[3:6], board[0:3]])) \n            return [value for item in tuple_board for value in item], new_response \n\n        elif transformation == 'rotate270': \n            new_response = [2, 5, 8, 1, 4, 7, 0, 3, 6].index(response) \n            tuple_board = list(zip(*[board[0:3], board[3:6], board[6:9]]))[::-1] \n            return [value for item in tuple_board for value in item], new_response \n\n        elif transformation == 'flip_v': \n            new_response = [6, 7, 8, 3, 4, 5, 0, 1, 2].index(response) \n            return board[6:9] +  board[3:6] + board[0:3], new_response \n\n        elif transformation == 'flip_h': \n        # flip_h = rotate180, then flip_v \n            new_response = [2, 1, 0, 5, 4, 3, 8, 7, 6].index(response) \n            new_board = board[::-1] \n            return new_board[6:9] +  new_board[3:6] + new_board[0:3], new_response \n\n        else: \n            raise ValueError('Method not implmented.') \n    ```", "```\n    def get_moves_from_csv(csv_file): \n        ''' \n        :param csv_file: csv file location containing the boards w/ responses \n        :return: moves: list of moves with index of best response \n        ''' \n        moves = [] \n        with open(csv_file, 'rt') as csvfile: \n            reader = csv.reader(csvfile, delimiter=',') \n            for row in reader: \n                moves.append(([int(x) for x in                              row[0:9]],int(row[9]))) \n        return moves \n    ```", "```\n    def get_rand_move(moves, rand_transforms=2): \n        # This function performs random transformations on a board. \n        (board, response) = random.choice(moves) \n        possible_transforms = ['rotate90', 'rotate180', 'rotate270', 'flip_v', 'flip_h'] \n        for i in range(rand_transforms): \n            random_transform = random.choice(possible_transforms) \n            (board, response) = get_symmetry(board, response, random_transform) \n        return board, response \n    ```", "```\n    moves = get_moves_from_csv('base_tic_tac_toe_moves.csv') \n    # Create a train set: \n    train_length = 500 \n    train_set = [] \n    for t in range(train_length): \n        train_set.append(get_rand_move(moves)) \n    ```", "```\n    test_board = [-1, 0, 0, 1, -1, -1, 0, 0, 1] \n    train_set = [x for x in train_set if x[0] != test_board] \n    ```", "```\n    def init_weights(shape): \n        return tf.Variable(tf.random_normal(shape)) \n    A1 = init_weights([9, 81])\n    bias1 = init_weights([81])\n    A2 = init_weights([81, 9])\n    bias2 = init_weights([9]) \n    ```", "```\n    # Initialize input data\n    X = tf.keras.Input(dtype=tf.float32, batch_input_shape=[None, 9])\n    hidden_output = tf.keras.layers.Lambda(lambda x: tf.nn.sigmoid(tf.add(tf.matmul(x, A1), bias1)))(X)\n    final_output = tf.keras.layers.Lambda(lambda x: tf.add(tf.matmul(x, A2), bias2))(hidden_output)\n    model = tf.keras.Model(inputs=X, outputs=final_output, name=\"tic_tac_toe_neural_network\") \n    ```", "```\n    optimizer = tf.keras.optimizers.SGD(0.025) \n    ```", "```\n    # Initialize variables \n    loss_vec = []\n    for i in range(10000):\n        rand_indices = np.random.choice(range(len(train_set)), batch_size, replace=False)\n        batch_data = [train_set[i] for i in rand_indices]\n        x_input = [x[0] for x in batch_data]\n        y_target = np.array([y[1] for y in batch_data])\n        # Open a GradientTape.\n        with tf.GradientTape(persistent=True) as tape:\n            # Forward pass.\n            output = model(np.array(x_input, dtype=float))\n            # Apply loss function (Cross Entropy loss)\n            loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y_target))\n            loss_vec.append(loss)\n        # Get gradients of loss with reference to the weights and bias variables to adjust.\n        gradients_A1 = tape.gradient(loss, A1)\n        gradients_b1 = tape.gradient(loss, bias1)\n        gradients_A2 = tape.gradient(loss, A2)\n        gradients_b2 = tape.gradient(loss, bias2)\n        # Update the weights and bias variables of the model.\n        optimizer.apply_gradients(zip([gradients_A1, gradients_b1, gradients_A2, gradients_b2],\n                                      [A1, bias1, A2, bias2]))\n        if i % 500 == 0:\n            print('Iteration: {}, Loss: {}'.format(i, loss)) \n    ```", "```\n    plt.plot(loss_vec, 'k-', label='Loss') \n    plt.title('Loss (MSE) per Generation') \n    plt.xlabel('Generation') \n    plt.ylabel('Loss') \n    plt.show() \n    ```", "```\n    test_boards = [test_board] \n    logits = model.predict(test_boards)\n    predictions = tf.argmax(logits, 1)\n    print(predictions) \n    ```", "```\n    [6] \n    ```", "```\n    def check(board): \n        wins = [[0,1,2], [3,4,5], [6,7,8], [0,3,6], [1,4,7], [2,5,8], [0,4,8], [2,4,6]] \n        for i in range(len(wins)): \n            if board[wins[i][0]]==board[wins[i][1]]==board[wins[i][2]]==1.: \n                return 1 \n            elif board[wins[i][0]]==board[wins[i][1]]==board[wins[i][2]]==-1.: \n                return 1 \n        return 0 \n    ```", "```\n    game_tracker = [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n    win_logical = False\n    num_moves = 0\n    while not win_logical:\n        player_index = input('Input index of your move (0-8): ')\n        num_moves += 1\n        # Add player move to game\n        game_tracker[int(player_index)] = 1.\n\n        # Get model's move by first getting all the logits for each index\n        [potential_moves] = model(np.array([game_tracker], dtype=float))\n        # Now find allowed moves (where game tracker values = 0.0)\n        allowed_moves = [ix for ix, x in enumerate(game_tracker) if x == 0.0]\n        # Find best move by taking argmax of logits if they are in allowed moves\n        model_move = np.argmax([x if ix in allowed_moves else -999.0 for ix, x in enumerate(potential_moves)])\n\n        # Add model move to game\n        game_tracker[int(model_move)] = -1.\n        print('Model has moved')\n        print_board(game_tracker)\n        # Now check for win or too many moves\n        if check(game_tracker) == -1 or num_moves >= 5:\n            print('Game Over!')\n            win_logical = True\n        elif check(game_tracker) == 1:\n            print('Congratulations, You won!')\n            win_logical = True \n    ```", "```\n    Input index of your move (0-8):  4\n    Model has moved\n       |   |  \n    ___________\n       | X |  \n    ___________\n       |   | O\n    Input index of your move (0-8):  6\n    Model has moved\n     O |   |  \n    ___________\n       | X |  \n    ___________\n     X |   | O\n    Input index of your move (0-8):  2\n    Model has moved\n     O |   | X\n    ___________\n       | X |  \n    ___________\n     X | O | O\n    Congratulations, You won! \n    ```"]