- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Any sufficiently advanced technology is indistinguishable from magic.
  prefs: []
  type: TYPE_NORMAL
- en: – Arthur C. Clarke
  prefs: []
  type: TYPE_NORMAL
- en: This phrase best describes image generation using **artificial** **intelligence**
    (**AI**). The field of deep learning—a subset of artificial intelligence—has been
    developing rapidly in the last decade. Now we can generate artificial but faces
    that are indistinguishable from real people's faces, and to generate realistic
    paintings from simple brush strokes. Most of these abilities are owed to a type
    of deep neural network known as a **generative** **adversarial** **network** (**GAN**).
    With this hands-on book, you'll not only develop image generation skills but also
    gain a solid understanding of the underlying principles.
  prefs: []
  type: TYPE_NORMAL
- en: The book starts with an introduction to the fundamentals of image generation
    using TensorFlow covering variational autoencoders and GANs. As you progress through
    the chapters, you'll learn to build models for different applications for performing
    face swaps using deep fakes, neural style transfer, image-to-image translation,
    turning simple images into photorealistic images, and much more. You'll also understand
    how and why to construct state-of-the-art deep neural networks using advanced
    techniques such as spectral normalization and self-attention layer before working
    with advanced models for face generation and editing. You'll also be introduced
    to photo restoration, text-to-image synthesis, video retargeting, and neural rendering.
    Throughout the book, you'll learn to implement models from scratch in TensorFlow
    2.x, including PixelCNN, VAE, DCGAN, WGAN, pix2pix, CycleGAN, StyleGAN, GauGAN,
    and BigGAN.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this book, you'll be well-versed in TensorFlow and image generative
    technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for deep learning engineers, practitioners, and researchers who
    have basic knowledge of convolutional neural networks and want to use it to learn
    various image generation techniques using TensorFlow 2.x. You'll also find this
    book useful if you are an image processing professional or computer vision engineer
    looking to explore state-of-the-art architectures to improve and enhance images
    and videos. Knowledge of Python and TensorFlow is required to get the best out
    of the book.
  prefs: []
  type: TYPE_NORMAL
- en: How to use this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many online tutorials available teaching the basics of GANs. However,
    the models tend to be rather simple and suitable only for toy datasets. At the
    other end of the spectrum, there are also free codes available for state-of-the-art
    models to generate realistic images. Nevertheless, the code tends to be complex,
    and the lack of explanation makes it difficult for beginners to understand. Many
    of the “Git cloners” who downloaded the codes had no clue how to tweak the models
    to make them work for their applications. This book aims to bridge that gap.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with learning the basic principles and immediately implement the
    code to put them to the test. You'll be able to see the result of your work instantly.
    All the necessary code to build a model is laid bare in a single Jupyter notebook.
    This is to make it easier for you to go through the flow of the code and to modify
    and test the code in an interactive manner. I believe writing from scratch is
    the best way to learn and master deep learning. There are between one to three
    models in each chapter, and we will write all of them from scratch. When you finish
    this book, not only will you be familiar with image generation but you will also
    be an expert in TensorFlow 2.
  prefs: []
  type: TYPE_NORMAL
- en: The chapters are arranged in roughly chronological order of the history of GANs,
    where the chapters may build upon knowledge from previous chapters. Therefore,
    it is best to read the chapters in order, especially the first three chapters,
    which cover the fundamentals. After that, you may jump to chapters that interest
    you more. Should you feel confused by the acronyms during the reading, you can
    refer to the summary of GAN techniques listed in the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B14538_01_Final_JM_ePub.xhtml#_idTextAnchor017), *Getting Started
    with Image Generation Using TensorFlow*, walks through the basics of pixel probability
    and uses it to build our first model to generate handwritten digits.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B14538_02_Final_JM_ePub.xhtml#_idTextAnchor039), *Variational
    Autoencoder*, explains how to build a **variational autoencoder** (**VAE**) and
    use it to generate and edit faces.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B14538_03_Final_JM_ePub.xhtml#_idTextAnchor060), *Generative
    Adversarial Network*, introduces the fundamentals of GANs and builds a DCGAN to
    generate photorealistic images. We''ll then learn about new adversarial loss to
    stabilize the training.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B14538_04_Final_JM_ePub.xhtml#_idTextAnchor084), *Image-to-Image
    Translation*, covers a lot of models and interesting applications. We will first
    implement pix2pix to convert sketches to photorealistic photos. Then we''ll use
    CycleGAN to transform a horse to a zebra. Lastly, we will use BicycleGAN to generate
    a variety of shoes.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B14538_05_Final_JM_ePub.xhtml#_idTextAnchor104), *Style Transfer*,
    explains how to extract the style from a painting and transfer it into a photo.
    We''ll also learn advanced techniques to make neural style transfer run faster
    in runtime, and to use it in state-of-the-art GANs.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B14538_06_Final_JM_ePub.xhtml#_idTextAnchor124), *AI Painter*,
    goes through the underlying principles of image editing and transformation using
    **interactive GAN** (**iGAN**) as an example. Then we will build a GauGAN to create
    photorealistic building facades from a simple segmentation map.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B14538_07_Final_JM_ePub.xhtml#_idTextAnchor136), *High Fidelity
    Face Generation*, shows how to build a StyleGAN using techniques from style transfer.
    However, before that, we will learn to grow the network layer progressively using
    a Progressive GAN.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B14538_08_Final_JM_ePub.xhtml#_idTextAnchor156), *Self-Attention
    for Image Generation*, shows how to build self-attention into a **Self-Attention
    GAN** (**SAGAN**) and a BigGAN for conditional image generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B14538_09_Final_JM_ePub.xhtml#_idTextAnchor175), *Video Synthesis*,
    demonstrates how to use autoencoders to create a deepfake video. Along the way,
    we''ll learn how to use OpenCV and dlib for face processing.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B14538_10_Final_JM_ePub.xhtml#_idTextAnchor195), *Road Ahead*,
    reviews and summarizes the generative techniques we have learned. Then we will
    look at how they are used as the basis of up-and-coming applications, including
    text-to-image-synthesis, video compression, and video retargeting.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Readers should have basic knowledge of deep learning training pipelines, such
    as training convolutional neural networks for image classification. This book
    will mainly use high-level Keras APIs in TensorFlow 2, which is easy to learn.
    Should you need to refresh or learn TensorFlow 2, there are many free tutorials
    available online, such as the one on the official TensorFlow website, [https://www.tensorflow.org/tutorials/keras/classification](https://www.tensorflow.org/tutorials/keras/classification).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Training deep neural networks is computationally intensive. You can train the
    first few simple models using the CPU only. However, as we progress to more complex
    models and datasets in later chapters, the model training could take a few days
    before you start to see satisfactory results. To get the most out of this book,
    you should have access to the GPU to accelerate the model training time. There
    are also free cloud services, such as Google's Colab, that provide GPUs on which
    you can upload and run the code.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code via the GitHub repository (link available
    in the next section). Doing so will help you avoid any potential errors related
    to the copying and pasting of code.**'
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Hands-On-Image-Generation-with-TensorFlow-2.0](https://github.com/PacktPublishing/Hands-On-Image-Generation-with-TensorFlow-2.0).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781838826789_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838826789_ColorImages.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “This is done using `tf.gather(self.beta, labels)`,
    which is conceptually equivalent to `beta = self.beta[labels]`, as follows.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: “From the preceding architecture diagram, we can see that **G1**''s
    encoder output concatenates with **G1**''s features and feeds into the decoder
    part of **G2** to generate high-resolution images.”'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '`customercare@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit www.packtpub.com/support/errata,
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  prefs: []
  type: TYPE_NORMAL
- en: '`copyright@packt.com` with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit authors.packtpub.com.'
  prefs: []
  type: TYPE_NORMAL
- en: Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  prefs: []
  type: TYPE_NORMAL
- en: For more information about Packt, please visit packt.com.
  prefs: []
  type: TYPE_NORMAL
