["```\n    import tensorflow as tf\n    import tensorflow_hub as hub\n    data_dir = tf.keras.utils.get_file(\n        'flower_photos', 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n        untar=True)\n    ```", "```\n    pixels =224\n    BATCH_SIZE = 32 \n    IMAGE_SIZE = (pixels, pixels)\n    NUM_CLASSES = 5\n    datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n    dataflow_kwargs = dict(target_size=IMAGE_SIZE, \n                           batch_size=BATCH_SIZE,\n                       interpolation=\"bilinear\")\n    valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        **datagen_kwargs)\n    valid_generator = valid_datagen.flow_from_directory(\n        data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n    train_datagen = valid_datagen\n    train_generator = train_datagen.flow_from_directory(\n    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)\n    ```", "```\n    labels_idx = (train_generator.class_indices)\n    idx_labels = dict((v,k) for k,v in labels_idx.items())\n    print(idx_labels)\n    ```", "```\n    {0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', 4: 'tulips'}\n    ```", "```\n    mdl = tf.keras.Sequential([\n        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/4\", trainable=False),\n        tf.keras.layers.Dense(NUM_CLASSES, \n                 activation='softmax', name = 'custom_class')\n    ])\n    mdl.build([None, 224, 224, 3])\n    mdl.compile(\n      optimizer=tf.keras.optimizers.SGD(lr=0.005, \n                                               momentum=0.9), \n      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n      metrics=['accuracy'])\n    steps_per_epoch = train_generator.samples \n                                // train_generator.batch_size\n    validation_steps = valid_generator.samples \n                                // valid_generator.batch_size\n    mdl.fit(\n        train_generator,\n        epochs=5, steps_per_epoch=steps_per_epoch,\n        validation_data=valid_generator,\n        validation_steps=validation_steps)\n    ```", "```\ngit clone https://github.com/PacktPublishing/learn-tensorflow-enterprise.git\n```", "```\n learn-tensorflow-enterprise/tree/master/chapter_07/train_base_model/tf_datasets/flower_photos\n```", "```\nimage_classification_builder-train.tfrecord-00000-of-00002\n```", "```\nimage_classification_builder-train.tfrecord-00001-of-00002\n```", "```\nimage_classification_builder-validation.tfrecord-00000-of-00001\n```", "```\nimage_classification_builder-test.tfrecord-00000-of-00001\n```", "```\n    import tensorflow as tf\n    import tensorflow_hub as hub\n    import tensorflow_datasets as tfds\n    root_dir = '<PATH_TO_TFRECORD>'\n    train_file_pattern = \"{}/image_classification_builder-train*.tfrecord*\".format(root_dir)\n    val_file_pattern = \"{}/image_classification_builder-validation*.tfrecord*\".format(root_dir)\n    test_file_pattern = \"{}/image_classification_builder-test*.tfrecord*\".format(root_dir)\n    ```", "```\n    train_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(train_file_pattern))\n    val_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(val_file_pattern))\n    test_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(test_file_pattern))\n    ```", "```\n    train_all_ds = tf.data.TFRecordDataset(train_all_files, num_parallel_reads = AUTOTUNE)\n    val_all_ds = tf.data.TFRecordDataset(val_all_files, num_parallel_reads = AUTOTUNE)\n    test_all_ds = tf.data.TFRecordDataset(test_all_files, num_parallel_reads = AUTOTUNE)\n    ```", "```\n    print(\"Sample size for training: {0}\".format(sum(1 for _ in tf.data.TFRecordDataset(train_all_files)))\n         ,'\\n', \"Sample size for validation: {0}\".format(sum(1 for _ in tf.data.TFRecordDataset(val_all_files)))\n         ,'\\n', \"Sample size for test: {0}\".format(sum(1 for _ in tf.data.TFRecordDataset(test_all_files)))) \n    ```", "```\n    Sample size for training: 3540 \n    Sample size for validation: 80 \n    Sample size for test: 50\n    ```", "```\nfeatures = {\n```", "```\n    'image/channels' :  tf.io.FixedLenFeature([], tf.int64),\n```", "```\n    'image/class/label' :  tf.io.FixedLenFeature([], tf.int64),\n```", "```\n    'image/class/text' : tf.io.FixedLenFeature([], tf.string),\n```", "```\n    'image/colorspace' : tf.io.FixedLenFeature([], tf.string),\n```", "```\n    'image/encoded' : tf.io.FixedLenFeature([], tf.string),\n```", "```\n    'image/filename' : tf.io.FixedLenFeature([], tf.string),\n```", "```\n    'image/format' : tf.io.FixedLenFeature([], tf.string),\n```", "```\n    'image/height' : tf.io.FixedLenFeature([], tf.int64),\n```", "```\n    'image/width' : tf.io.FixedLenFeature([], tf.int64)\n```", "```\n    })\n```", "```\n    def decode_and_resize(serialized_example):\n        # resized image should be [224, 224, 3] and \t \t    # normalized to value range [0, 255]\n        # label is integer index of class.\n\n        parsed_features = tf.io.parse_single_example(\n          serialized_example,\n          features = {\n        'image/channels' :  tf.io.FixedLenFeature([], \t \t                                                tf.int64),\n        'image/class/label' :  tf.io.FixedLenFeature([], \t \t                                                tf.int64),\n        'image/class/text' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/colorspace' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/encoded' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/filename' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/format' : tf.io.FixedLenFeature([], \t \t        \t                                               tf.string),\n        'image/height' : tf.io.FixedLenFeature([], tf.int64),\n        'image/width' : tf.io.FixedLenFeature([], tf.int64)\n        })\n        image = tf.io.decode_jpeg(parsed_features[\n                                'image/encoded'], channels=3)\n        label = tf.cast(parsed_features[\n                              'image/class/label'], tf.int32)\n        label_txt = tf.cast(parsed_features\n                             ['image/class/text'], tf.string)\n        label_one_hot = tf.one_hot(label, depth = 5)\n        resized_image = tf.image.resize(image, [224, 224], \n                                             method='nearest')\n        return resized_image, label_one_hot\n    ```", "```\n    def normalize(image, label):\n        #Convert `image` from [0, 255] -> [0, 1.0] floats \n        image = tf.cast(image, tf.float32) / 255.\n        return image, label\n    ```", "```\n    resized_train_ds = train_all_ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n    resized_val_ds = val_all_ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n    resized_test_ds = test_all_ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n    resized_normalized_train_ds = resized_train_ds.map(normalize, num_parallel_calls=AUTOTUNE)\n    resized_normalized_val_ds = resized_val_ds.map(normalize, num_parallel_calls=AUTOTUNE)\n    resized_normalized_test_ds = resized_test_ds.map(normalize, num_parallel_calls=AUTOTUNE)\n    ```", "```\n    pixels =224\n    IMAGE_SIZE = (pixels, pixels)\n    TRAIN_BATCH_SIZE = 32\n    # Validation and test data are small. Use all in a batch.\n    VAL_BATCH_SIZE = sum(1 for _ in tf.data.TFRecordDataset(val_all_files))\n    TEST_BATCH_SIZE = sum(1 for _ in tf.data.TFRecordDataset(test_all_files))\n    def prepare_for_model(ds, BATCH_SIZE, cache=True, TRAINING_DATA=True, shuffle_buffer_size=1000):\n      if cache:\n        if isinstance(cache, str):\n          ds = ds.cache(cache)\n        else:\n          ds = ds.cache()\n      ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n      if TRAINING_DATA:\n        # Repeat forever\n        ds = ds.repeat()\n      ds = ds.batch(BATCH_SIZE)\n      ds = ds.prefetch(buffer_size=AUTOTUNE)\n      return ds\n    ```", "```\n    NUM_EPOCHS = 5\n    SHUFFLE_BUFFER_SIZE = 1000\n    prepped_test_ds = prepare_for_model(resized_normalized_test_ds, TEST_BATCH_SIZE, False, False)\n    prepped_train_ds = resized_normalized_train_ds.repeat(100).shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n    prepped_train_ds = prepped_train_ds.batch(TRAIN_BATCH_SIZE)\n    prepped_train_ds = prepped_train_ds.prefetch(buffer_size = AUTOTUNE)\n    prepped_val_ds = resized_normalized_val_ds.repeat(NUM_EPOCHS).shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n    prepped_val_ds = prepped_val_ds.batch(80)\n    prepped_val_ds = prepped_val_ds.prefetch(buffer_size = AUTOTUNE)\n    ```", "```\n    FINE_TUNING_CHOICE = False\n    NUM_CLASSES = 5\n    IMAGE_SIZE = (224, 224)\n    mdl = tf.keras.Sequential([\n        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + \n                                   (3,), name='input_layer'),\n        hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/4\", trainable=FINE_TUNING_CHOICE, name = 'resnet_fv'), \n        tf.keras.layers.Dense(NUM_CLASSES, \n                 activation='softmax', name = 'custom_class')\n    ])\n    mdl.build([None, 224, 224, 3])\n    mdl.compile(\n      optimizer=tf.keras.optimizers.SGD(lr=0.005, \n                                               momentum=0.9), \n      loss=tf.keras.losses.CategoricalCrossentropy(\n                      from_logits=True, label_smoothing=0.1),\n      metrics=['accuracy'])\n    mdl.fit(\n        prepped_train_ds,\n        epochs=5, steps_per_epoch=100,\n        validation_data=prepped_val_ds,\n        validation_steps=1)\n    ```", "```\nKERNEL_REGULARIZER = tf.keras.regularizers.l2(l=0.1)\n```", "```\nACTIVITY_REGULARIZER = tf.keras.regularizers.L1L2(l1=0.1,l2=0.1)\n```", "```\nmdl = tf.keras.Sequential([\n```", "```\n    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n```", "```\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",trainable=FINE_TUNING_CHOICE), \n```", "```\n    tf.keras.layers.Dense(NUM_CLASSES \n```", "```\n                         ,activation='softmax'\n```", "```\n                         ,kernel_regularizer=KERNEL_REGULARIZER\n```", "```\n                          ,activity_regularizer = \n```", "```\n                          ACTIVITY_REGULARIZER\n```", "```\n                          ,name = 'custom_class')\n```", "```\n])\n```", "```\nmdl.build([None, 224, 224, 3])\n```", "```\nKERNEL_REGULARIZER = tf.keras.regularizers.l2(l=0.1)\n```", "```\nACTIVITY_REGULARIZER = tf.keras.regularizers.L1L2(l1=0.1,l2=0.1)\n```", "```\ntf.keras.layers.Dense(NUM_CLASSES \n```", "```\n                      ,activation='softmax'\n```", "```\n                      ,kernel_regularizer=KERNEL_REGULARIZER\n```", "```\n                      ,activity_regularizer = \n```", "```\n                                           ACTIVITY_REGULARIZER\n```", "```\n                      ,name = 'custom_class')\n```", "```\n    image_classification_builder-train.tfrecord-00000-of-00002\n    image_classification_builder-train.tfrecord-00001-of-00002\n    image_classification_builder-validation.tfrecord-00000-of-00001\n    image_classification_builder-test.tfrecord-00000-of-00001\n    ```", "```\n    !pip install --quiet neural-structured-learning\n    ```", "```\n    import tensorflow as tf\n    import neural_structured_learning as nsl\n    import tensorflow_hub as hub\n    import tensorflow_datasets as tfds\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    root_dir = './tfrecord-dataset/flowers'\n    train_file_pattern = \"{}/image_classification_builder-train*.tfrecord*\".format(root_dir)\n    val_file_pattern = \"{}/image_classification_builder-validation*.tfrecord*\".format(root_dir)\n    test_file_pattern = \"{}/image_classification_builder-test*.tfrecord*\".format(root_dir)\n    ```", "```\n    train_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(train_file_pattern))\n    val_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(val_file_pattern))\n    test_all_files = tf.data.Dataset.list_files( tf.io.gfile.glob(test_file_pattern))\n    ```", "```\n    train_all_ds = tf.data.TFRecordDataset(train_all_files, num_parallel_reads = AUTOTUNE)\n    val_all_ds = tf.data.TFRecordDataset(val_all_files, num_parallel_reads = AUTOTUNE)\n    test_all_ds = tf.data.TFRecordDataset(test_all_files, num_parallel_reads = AUTOTUNE)\n    ```", "```\n    train_sample_size = sum(1 for _ in tf.data.TFRecordDataset(train_all_files))\n    validation_sample_size = sum(1 for _ in tf.data.TFRecordDataset(val_all_files))\n    test_sample_size = sum(1 for _ in tf.data.TFRecordDataset(test_all_files))\n    print(\"Sample size for training: {0}\".format(train_sample_size)\n         ,'\\n', \"Sample size for validation: {0}\".format(validation_sample_size)\n         ,'\\n', \"Sample size for test: {0}\".format(test_sample_size))\n    ```", "```\n    sum(1 for _ in tf.data.TFRecordDataset(train_all_files))\n    ```", "```\n    Sample size for training: 3540 \n    Sample size for validation: 80 \n    Sample size for test: 50\n    ```", "```\n    def decode_and_resize(serialized_example):\n        # resized image should be [224, 224, 3] and \t \t    # normalized to value range [0, 255]\n        # label is integer index of class.\n\n        parsed_features = tf.io.parse_single_example(\n          serialized_example,\n          features = {\n        'image/channels' :  tf.io.FixedLenFeature([], \t  \t                                                tf.int64),\n        'image/class/label' :  tf.io.FixedLenFeature([], \t \t                                                tf.int64),\n        'image/class/text' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/colorspace' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/encoded' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/filename' : tf.io.FixedLenFeature([], \t \t                                               tf.string),\n        'image/format' : tf.io.FixedLenFeature([], \t \t    \t                                               tf.string),\n        'image/height' : tf.io.FixedLenFeature([], tf.int64),\n        'image/width' : tf.io.FixedLenFeature([], tf.int64)\n        })\n        image = tf.io.decode_jpeg(parsed_features[\n                                'image/encoded'], channels=3)\n        label = tf.cast(parsed_features['image/class/label'], \n                                                     tf.int32)\n        label_txt = tf.cast(parsed_features[\n                              'image/class/text'], tf.string)\n        label_one_hot = tf.one_hot(label, depth = 5)\n        resized_image = tf.image.resize(image, [224, 224], \n                                             method='nearest')\n    return resized_image, label_one_hot\n    ```", "```\n    def normalize(image, label):\n        #Convert `image` from [0, 255] -> [0, 1.0] floats \n        image = tf.cast(image, tf.float32) / 255.\n        return image, label\n    ```", "```\n    resized_train_ds = train_all_ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n    resized_val_ds = val_all_ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n    resized_test_ds = test_all_ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n    resized_normalized_train_ds = resized_train_ds.map(normalize, num_parallel_calls=AUTOTUNE)\n    resized_normalized_val_ds = resized_val_ds.map(normalize, num_parallel_calls=AUTOTUNE)\n    resized_normalized_test_ds = resized_test_ds.map(normalize, num_parallel_calls=AUTOTUNE)\n    ```", "```\n    pixels =224\n    IMAGE_SIZE = (pixels, pixels)\n    TRAIN_BATCH_SIZE = 32\n    VAL_BATCH_SIZE = validation_sample_size\n    TEST_BATCH_SIZE = test_sample_size\n    NUM_EPOCHS = 5\n    SHUFFLE_BUFFER_SIZE = 1000\n    FINE_TUNING_CHOICE = False\n    NUM_CLASSES = 5\n    prepped_test_ds = resized_normalized_test_ds.batch(TEST_BATCH_SIZE).prefetch(buffer_size = AUTOTUNE)\n    prepped_train_ds = resized_normalized_train_ds.repeat(100).shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n    prepped_train_ds = prepped_train_ds.batch(TRAIN_BATCH_SIZE)\n    prepped_train_ds = prepped_train_ds.prefetch(buffer_size = AUTOTUNE)\n    prepped_val_ds = resized_normalized_val_ds.repeat(NUM_EPOCHS).shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n    prepped_val_ds = prepped_val_ds.batch(80)\n    prepped_val_ds = prepped_val_ds.prefetch(buffer_size = AUTOTUNE)\n    ```", "```\n    mdl = tf.keras.Sequential([\n        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n        hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\",trainable=FINE_TUNING_CHOICE), \n        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name = 'custom_class')\n    ])\n    mdl.build([None, 224, 224, 3])\n    ```", "```\n    def examples_to_dict(image, label):\n      return {'image_input': image, 'label_output': label}\n    ```", "```\n    train_set_for_adv_model = prepped_train_ds.map(examples_to_dict)\n    val_set_for_adv_model = prepped_val_ds.map(examples_to_dict)\n    test_set_for_adv_model = prepped_test_ds.map(examples_to_dict)\n    ```", "```\n    adv_config = nsl.configs.make_adv_reg_config()\n    adv_mdl = nsl.keras.AdversarialRegularization(mdl,\n    label_keys=['label_output'],\n    adv_config=adv_config)\n    ```", "```\n    adv_mdl.compile(optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n        loss=tf.keras.losses.CategoricalCrossentropy(\n                      from_logits=True, label_smoothing=0.1),\n        metrics=['accuracy'])\n    adv_mdl.fit(\n        train_set_for_adv_model,\n        epochs=5, steps_per_epoch=100,\n        validation_data=val_set_for_adv_model,\n        validation_steps=1)\n    ```"]