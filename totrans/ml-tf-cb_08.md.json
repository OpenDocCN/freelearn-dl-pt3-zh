["```\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf \n    ```", "```\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n    # Reshape\n    x_train = x_train.reshape(-1, 28, 28, 1)\n    x_test = x_test.reshape(-1, 28, 28, 1)\n    #Padding the images by 2 pixels\n    x_train = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n    x_test = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant') \n    ```", "```\n    image_width = x_train[0].shape[0]\n    image_height = x_train[0].shape[1]\n    num_channels = 1 # grayscale = 1 channel\n    seed = 98\n    np.random.seed(seed)\n    tf.random.set_seed(seed) \n    ```", "```\n    batch_size = 100\n    evaluation_size = 500\n    epochs = 300\n    eval_every = 5 \n    ```", "```\n    x_train = x_train / 255\n    x_test = x_test/ 255 \n    ```", "```\n    input_data = tf.keras.Input(dtype=tf.float32, shape=(image_width,image_height, num_channels), name=\"INPUT\")\n    # First Conv-ReLU-MaxPool Layer\n    conv1 = tf.keras.layers.Conv2D(filters=6,\n                                   kernel_size=5,\n                                   padding='VALID',\n                                   activation=\"relu\",\n                                   name=\"C1\")(input_data)\n    max_pool1 = tf.keras.layers.MaxPool2D(pool_size=2,\n                                          strides=2, \n                                          padding='SAME',\n                                          name=\"S1\")(conv1)\n    # Second Conv-ReLU-MaxPool Layer\n    conv2 = tf.keras.layers.Conv2D(filters=16,\n                                   kernel_size=5,\n                                   padding='VALID',\n                                   strides=1,\n                                   activation=\"relu\",\n                                   name=\"C3\")(max_pool1)\n    max_pool2 = tf.keras.layers.MaxPool2D(pool_size=2,\n                                          strides=2, \n                                          padding='SAME',\n                                          name=\"S4\")(conv2)\n    # Flatten Layer\n    flatten = tf.keras.layers.Flatten(name=\"FLATTEN\")(max_pool2)\n    # First Fully Connected Layer\n    fully_connected1 = tf.keras.layers.Dense(units=120,\n                                             activation=\"relu\",\n                                             name=\"F5\")(flatten)\n    # Second Fully Connected Layer\n    fully_connected2 = tf.keras.layers.Dense(units=84,\n                                             activation=\"relu\",\n                                             name=\"F6\")(fully_connected1)\n    # Final Fully Connected Layer\n    final_model_output = tf.keras.layers.Dense(units=10,\n                                               activation=\"softmax\",\n                                               name=\"OUTPUT\"\n                                               )(fully_connected2)\n\n    model = tf.keras.Model(inputs= input_data, outputs=final_model_output) \n    ```", "```\n    model.compile(\n        optimizer=\"adam\", \n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"] \n    ```", "```\n    model.summary() \n    ```", "```\n    train_loss = []\n    train_acc = []\n    test_acc = []\n    for i in range(epochs):\n        rand_index = np.random.choice(len(x_train), size=batch_size)\n        rand_x = x_train[rand_index]\n        rand_y = y_train[rand_index]\n\n        history_train = model.train_on_batch(rand_x, rand_y)\n\n        if (i+1) % eval_every == 0:\n            eval_index = np.random.choice(len(x_test), size=evaluation_size)\n            eval_x = x_test[eval_index]\n            eval_y = y_test[eval_index]\n\n            history_eval = model.evaluate(eval_x,eval_y)\n\n            # Record and print results\n            train_loss.append(history_train[0])\n            train_acc.append(history_train[1])\n            test_acc.append(history_eval[1])\n            acc_and_loss = [(i+1), history_train\n     [0], history_train[1], history_eval[1]]\n            acc_and_loss = [np.round(x,2) for x in acc_and_loss]\n            print('Epoch # {}. Train Loss: {:.2f}. Train Acc (Test Acc): {:.2f} ({:.2f})'.format(*acc_and_loss)) \n    ```", "```\n    Epoch # 5\\. Train Loss: 2.19\\. Train Acc (Test Acc): 0.23 (0.34)\n    Epoch # 10\\. Train Loss: 2.01\\. Train Acc (Test Acc): 0.59 (0.58)\n    Epoch # 15\\. Train Loss: 1.71\\. Train Acc (Test Acc): 0.74 (0.73)\n    Epoch # 20\\. Train Loss: 1.32\\. Train Acc (Test Acc): 0.73 (0.77)\n     ...\n    Epoch # 290\\. Train Loss: 0.18\\. Train Acc (Test Acc): 0.95 (0.94)\n    Epoch # 295\\. Train Loss: 0.13\\. Train Acc (Test Acc): 0.96 (0.96)\n    Epoch # 300\\. Train Loss: 0.12\\. Train Acc (Test Acc): 0.95 (0.97) \n    ```", "```\n    # Matlotlib code to plot the loss and accuracy\n    eval_indices = range(0, epochs, eval_every)\n    # Plot loss over time\n    plt.plot(eval_indices, train_loss, 'k-')\n    plt.title('Loss per Epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.show()\n    # Plot train and test accuracy\n    plt.plot(eval_indices, train_acc, 'k-', label='Train Set Accuracy')\n    plt.plot(eval_indices, test_acc, 'r--', label='Test Set Accuracy')\n    plt.title('Train and Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.show() \n    ```", "```\n    # Plot some samples and their predictions\n    actuals = y_test[30:36]\n    preds = model.predict(x_test[30:36])\n    predictions = np.argmax(preds,axis=1)\n    images = np.squeeze(x_test[30:36])\n    Nrows = 2\n    Ncols = 3\n    for i in range(6):\n        plt.subplot(Nrows, Ncols, i+1)\n        plt.imshow(np.reshape(images[i], [32,32]), cmap='Greys_r')\n        plt.title('Actual: ' + str(actuals[i]) + ' Pred: ' + str(predictions[i]),\n                                   fontsize=10)\n        frame = plt.gca()\n        frame.axes.get_xaxis().set_visible(False)\n        frame.axes.get_yaxis().set_visible(False)\n    plt.show() \n    ```", "```\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow import keras \n    ```", "```\n    # Set dataset and model parameters\n    batch_size = 128\n    buffer_size= 128\n    epochs=20\n    #Set transformation parameters\n    crop_height = 24\n    crop_width = 24 \n    ```", "```\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() \n    ```", "```\n    dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n    dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \n    ```", "```\n    # Define CIFAR reader\n    def read_cifar_files(image, label):\n        final_image = tf.image.resize_with_crop_or_pad(image, crop_width, crop_height)\n        final_image = image / 255\n        # Randomly flip the image horizontally, change the brightness and contrast\n        final_image = tf.image.random_flip_left_right(final_image)\n        final_image = tf.image.random_brightness(final_image,max_delta=0.1)\n        final_image = tf.image.random_contrast(final_image,lower=0.5, upper=0.8)\n        return final_image, label \n    ```", "```\n    dataset_train_processed = dataset_train.shuffle(buffer_size).batch(batch_size).map(read_cifar_files)\n    dataset_test_processed = dataset_test.batch(batch_size).map(lambda image,label: read_cifar_files(image, label, False)) \n    ```", "```\n    model = keras.Sequential(\n        [# First Conv-ReLU-Conv-ReLU-MaxPool Layer\n         tf.keras.layers.Conv2D(input_shape=[32,32,3],\n                                filters=32,\n                                kernel_size=3,\n                                padding='SAME',\n                                activation=\"relu\",\n                                kernel_initializer='he_uniform',\n                                name=\"C1\"),\n        tf.keras.layers.Conv2D(filters=32,\n                               kernel_size=3,\n                               padding='SAME',\n                               activation=\"relu\",\n                               kernel_initializer='he_uniform',\n                               name=\"C2\"),\n         tf.keras.layers.MaxPool2D((2,2),\n                                   name=\"P1\"),\n         tf.keras.layers.Dropout(0.2),\n        # Second Conv-ReLU-Conv-ReLU-MaxPool Layer\n         tf.keras.layers.Conv2D(filters=64,\n                                kernel_size=3,\n                                padding='SAME',\n                                activation=\"relu\",\n                                kernel_initializer='he_uniform',\n                                name=\"C3\"),\n        tf.keras.layers.Conv2D(filters=64,\n                               kernel_size=3,\n                               padding='SAME',\n                               activation=\"relu\",\n                               kernel_initializer='he_uniform',\n                               name=\"C4\"),\n         tf.keras.layers.MaxPool2D((2,2),\n                                   name=\"P2\"),\n         tf.keras.layers.Dropout(0.2),\n        # Third Conv-ReLU-Conv-ReLU-MaxPool Layer\n         tf.keras.layers.Conv2D(filters=128,\n                                kernel_size=3,\n                                padding='SAME',\n                                activation=\"relu\",\n                                kernel_initializer='he_uniform',\n                                name=\"C5\"),\n        tf.keras.layers.Conv2D(filters=128,\n                               kernel_size=3,\n                               padding='SAME',\n                               activation=\"relu\",\n                               kernel_initializer='he_uniform',\n                               name=\"C6\"),\n         tf.keras.layers.MaxPool2D((2,2),\n                                   name=\"P3\"),\n         tf.keras.layers.Dropout(0.2),\n         # Flatten Layer\n         tf.keras.layers.Flatten(name=\"FLATTEN\"),\n         # Fully Connected Layer\n         tf.keras.layers.Dense(units=128,\n                               activation=\"relu\",\n                               name=\"D1\"),\n        tf.keras.layers.Dropout(0.2),\n        # Final Fully Connected Layer\n        tf.keras.layers.Dense(units=10,\n                              activation=\"softmax\",\n                              name=\"OUTPUT\")\n        ]) \n    ```", "```\n    model.compile(loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    model.summary() \n    ```", "```\n    history = model.fit(dataset_train_processed, \n                        validation_data=dataset_test_processed, \n                        epochs=epochs) \n    ```", "```\n    # Print loss and accuracy\n    # Matlotlib code to plot the loss and accuracy\n    epochs_indices = range(0, 10, 1)\n    # Plot loss over time\n    plt.plot(epochs_indices, history.history[\"loss\"], 'k-')\n    plt.title('Softmax Loss per Epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('Softmax Loss')\n    plt.show()\n    # Plot accuracy over time\n    plt.plot(epochs_indices, history.history[\"val_accuracy\"], 'k-')\n    plt.title('Test Accuracy per Epoch')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.show() \n    ```", "```\n    import tensorflow as tf\n    from tensorflow import keras\n    from tensorflow.keras.applications.inception_v3 import InceptionV3\n    from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions \n    ```", "```\n    batch_size = 32\n    buffer_size= 1000 \n    ```", "```\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n    objects = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck'] \n    ```", "```\n    dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n    dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)) \n    ```", "```\n    def preprocess_cifar10(img, label):\n        img = tf.cast(img, tf.float32)\n        img = tf.image.resize(img, (75, 75))\n    return tf.keras.applications.inception_v3.preprocess_input(img) , label\n    dataset_train_processed = dataset_train.shuffle(buffer_size).batch(batch_size).map(preprocess_cifar10)\n    dataset_test_processed = dataset_test.batch(batch_size).map(preprocess_cifar10) \n    ```", "```\n    inception_model = InceptionV3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=(75,75,3)\n    ) \n    ```", "```\n    x = inception_model.output\n    x= keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dense(1024, activation=\"relu\")(x)\n    x = keras.layers.Dense(128, activation=\"relu\")(x)\n    output = keras.layers.Dense(10, activation=\"softmax\")(x)\n    model=keras.Model(inputs=inception_model.input, outputs = output) \n    ```", "```\n    for inception_layer in inception_model.layers:\n        inception_layer.trainable= False \n    ```", "```\n    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n    ```", "```\n    model.fit(x=dataset_train_processed , \n              validation_data=dataset_test_processed) \n    ```", "```\n    loss: 1.1316 - accuracy: 0.6018 - val_loss: 1.0361 - val_accuracy: 0.6366... \n    ```", "```\n    import imageio\n    import numpy as np\n    from skimage.transform import resize\n    import tensorflow as tf\n    import matplotlib.pyplot as plt\n    import matplotlib as mpl\n    import IPython.display as display\n    import PIL.Image \n    ```", "```\n    content_image_file = 'images/book_cover.jpg' \n    style_image_file = 'images/starry_night.jpg' \n    ```", "```\n    # Read the images\n    content_image = imageio.imread(content_image_file)\n    style_image = imageio.imread(style_image_file)\n    content_image = tf.image.convert_image_dtype(content_image, tf.float32)\n    style_image = tf.image.convert_image_dtype(style_image, tf.float32)\n    # Get shape of target and make the style image the same\n    target_shape = content_image.shape\n    style_image = resize(style_image, target_shape) \n    ```", "```\n    mpl.rcParams['figure.figsize'] = (12,12)\n    mpl.rcParams['axes.grid'] = False\n    plt.subplot(1, 2, 1)\n    plt.imshow(content_image)\n    plt.title(\"Content Image\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(style_image)\n    plt.title(\"Style Image\") \n    ```", "```\n    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n    vgg.trainable = False \n    ```", "```\n    [layer.name for layer in vgg.layers] \n    ```", "```\n    content_layers = ['block4_conv2', 'block5_conv2']\n    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n    num_content_layers = len(content_layers)\n    num_style_layers = len(style_layers) \n    ```", "```\n    def gram_matrix(input_tensor):\n      result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n      input_shape = tf.shape(input_tensor)\n      num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n      return result/(num_locations) \n    ```", "```\n    class StyleContentModel(tf.keras.models.Model):\n      def __init__(self, style_layers, content_layers):\n        super(StyleContentModel, self).__init__()\n        self.vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n        outputs = [vgg.get_layer(name).output for name in style_layers + content_layers]\n        self.vgg = tf.keras.Model([vgg.input], outputs)\n        self.style_layers = style_layers\n        self.content_layers = content_layers\n        self.num_style_layers = len(style_layers)\n        self.vgg.trainable = False\n      def call(self, inputs):\n        \"Expects float input in [0,1]\"\n        inputs = inputs*255.0\n        inputs = inputs[tf.newaxis, :]\n        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n        outputs = self.vgg(preprocessed_input)\n        style_outputs, content_outputs = (outputs[:self.num_style_layers], \n                                                                outputs[self.num_style_layers:])\n        style_outputs = [gram_matrix(style_output)\n                         for style_output in style_outputs]\n        content_dict = {content_name:value \n                        for content_name, value \n                        in zip(self.content_layers, content_outputs)}\n        style_dict = {style_name:value\n                      for style_name, value\n                      in zip(self.style_layers, style_outputs)}\n\n        return {'content':content_dict, 'style':style_dict} \n    ```", "```\n    extractor = StyleContentModel(style_layers, content_layers)\n    style_targets = extractor(style_image)['style']\n    content_targets = extractor(content_image)['content'] \n    ```", "```\n    #Optimizer configuration\n    learning_rate = 0.05\n    beta1 = 0.9\n    beta2 = 0.999\n    opt = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=beta1, beta_2=beta2) \n    ```", "```\n    content_weight = 5.0\n    style_weight = 1.0 \n    ```", "```\n    def style_content_loss(outputs):\n        style_outputs = outputs['style']\n        content_outputs = outputs['content']\n        style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) \n                               for name in style_outputs.keys()])\n        style_loss *= style_weight / num_style_layers\n        content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) \n                              for name in content_outputs.keys()])\n        content_loss *= content_weight / num_content_layers\n        loss = style_loss + content_loss\n        return loss \n    ```", "```\n    def clip_0_1(image):\n      return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0) \n    ```", "```\n    def tensor_to_image(tensor):\n      tensor = tensor*255\n      tensor = np.array(tensor, dtype=np.uint8)\n      if np.ndim(tensor)>3:\n        assert tensor.shape[0] == 1\n        tensor = tensor[0]\n      return PIL.Image.fromarray(tensor) \n    ```", "```\n    epochs = 100\n    image = tf.Variable(content_image)\n    for generation in range(epochs):\n\n        with tf.GradientTape() as tape:\n            outputs = extractor(image)\n            loss = style_content_loss(outputs)\n        grad = tape.gradient(loss, image)\n        opt.apply_gradients([(grad, image)])\n        image.assign(clip_0_1(image))\n        print(\".\", end='')\n    display.display(tensor_to_image(image)) \n    ```", "```\n    import numpy as np\n    import PIL.Image\n    import imageio\n    import matplotlib.pyplot as plt\n    import matplotlib as mpl\n    import tensorflow as tf\n    import IPython.display as display \n    ```", "```\n    # Read the images\t\n    original_img_file = path + 'images/book_cover.jpg' \n    original_img = imageio.imread(original_img_file)\n    # Reshape to 500 max dimension\n    new_shape = tf.cast((500, 500 * original_img.shape[1] / original_img.shape[0]), tf.int32)\n    original_img = tf.image.resize(original_img, new_shape, method='nearest').numpy()\n    # Display the image\n    mpl.rcParams['figure.figsize'] = (20,6)\n    mpl.rcParams['axes.grid'] = False\n    plt.imshow(original_img)\n    plt.title(\"Original Image\") \n    ```", "```\n    inception_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet') \n    ```", "```\n    inception_model.summary() \n    ```", "```\n    names = ['mixed3', 'mixed5']\n    layers = [inception_model.get_layer(name).output for name in names]\n    deep_dream_model = tf.keras.Model(inputs=inception_model.input, outputs=layers) \n    ```", "```\n    def compute_loss(img, model):\n      # Add a dimension to the image to have a batch of size 1.\n      img_batch = tf.expand_dims(img, axis=0)\n      # Apply the model to the images and get the outputs to retrieve the activation.\n      layer_activations = model(img_batch)\n\n      # Compute the loss for each layer\n      losses = []\n      for act in layer_activations:\n        loss = tf.math.reduce_mean(act)\n        losses.append(loss)\n      return  tf.reduce_sum(losses) \n    ```", "```\n    def deprocess(img):\n      img = 255*(img + 1.0)/2.0\n      return tf.cast(img, tf.uint8)\n    def show(img):\n      display.display(PIL.Image.fromarray(np.array(img))) \n    ```", "```\n    def run_deep_dream(image, steps=100, step_size=0.01):\n        # Apply the Inception preprocessing\n        image = tf.keras.applications.inception_v3.preprocess_input(image)\n        image = tf.convert_to_tensor(image)\n        loss = tf.constant(0.0)\n        for n in tf.range(steps):\n            # We use gradient tape to track TensorFlow computations\n            with tf.GradientTape() as tape:\n                # We use watch to force TensorFlow to track the image\n                tape.watch(image)\n                # We compute the loss\n                loss = compute_loss(image, deep_dream_model)\n            # Compute the gradients\n            gradients = tape.gradient(loss, image)\n            # Normalize the gradients.\n            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n\n            # Perform the gradient ascent by directly adding the gradients to the image\n            image = image + gradients*step_size\n            image = tf.clip_by_value(image, -1, 1)\n            # Display the intermediate image\n            if (n % 100 ==0):\n                display.clear_output(wait=True)\n                show(deprocess(image))\n                print (\"Step {}, loss {}\".format(n, loss))\n        # Display the final image\n        result = deprocess(image)\n        display.clear_output(wait=True)\n        show(result)\n        return result \n    ```", "```\n    dream_img = run_deep_dream(image=original_img, \n                               steps=100, step_size=0.01) \n    ```", "```\n    OCTAVE_SCALE = 1.30\n    image = tf.constant(np.array(original_img))\n    base_shape = tf.shape(image)[:-1]\n    float_base_shape = tf.cast(base_shape, tf.float32)\n    for n in range(-2, 3):\n        # Increase the size of the image\n        new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n        image = tf.image.resize(image, new_shape).numpy()\n        # Apply deep dream\n        image = run_deep_dream(image=image, steps=50, step_size=0.01)\n    # Display output\n    display.clear_output(wait=True)\n    image = tf.image.resize(image, base_shape)\n    image = tf.image.convert_image_dtype(image/255.0, dtype=tf.uint8)\n    show(image) \n    ```"]