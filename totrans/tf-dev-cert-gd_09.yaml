- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transfer Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most significant developments of the last decade in the **machine
    learning** (**ML**) space was the concept of **transfer learning**, and rightfully
    so. Transfer learning is the process of applying knowledge gained from solving
    a source task to a target task, which is a different but related task. This approach
    has proven not only effective in saving computational resources required to train
    a deep neural network but also in cases where the target dataset is limited in
    size. Transfer learning reuses learned features from a pre-trained model, enabling
    us to build better-performing models and attain convergence much faster. Because
    of its numerous benefits, transfer learning has become an area of extensive research,
    with several studies exploring the application of transfer learning across different
    domains, such as image classification, object detection, natural language processing,
    and speech recognition.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will introduce the concept of transfer learning, examining
    how it works, and some best practices around the application of transfer learning
    in various use cases. We will apply the concept of transfer learning in a real-world
    application with the aid of well-known pre-trained models. We will see in action
    how to apply these pre-trained models as a feature extractor and also learn how
    to fine-tune them to achieve optimal results. By the end of this chapter, you
    will have a solid understanding of what transfer learning is and how to apply
    it effectively to build real-world image classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a real-world image classifier with transfer learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use Google Colab to run the coding exercise, which requires `python
    >= 3.8.0`, along with the following packages, which can be installed using the
    `pip` `install` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`tensorflow>=2.7.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`os`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib >=3.4.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pathlib`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code bundle for this book is available at the following GitHub link: [https://github.com/PacktPublishing/TensorFlow-Developer-Certificate](https://github.com/PacktPublishing/TensorFlow-Developer-Certificate).
    Also, solutions to all exercises can be found in the GitHub repo itself.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As humans, it is easy for us to transfer knowledge gained from one task or activity
    to another. For instance, if you have a good grasp of Python (the programming
    language, not the snake) and you decide to learn Rust, because of your background
    knowledge in Python, you will find it easier to learn Rust compared to someone
    who has never written a basic program in any programming language. This is because
    certain concepts, such as object-oriented programming, have similarities across
    different programming languages. Transfer learning follows the same principle.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning is a technique in which we leverage a model pre-trained on
    *task A* to solve a different but related *task B*. For example, we use a neural
    network trained on one task and transfer the knowledge gained to multiple related
    tasks. In image classification, we often use deep learning models that have been
    trained on very large datasets, such as ImageNet, which is made up of more than
    1,000,000 images across 1,000 categories. The knowledge gained by these pre-trained
    models can be applied to many different tasks, such as classifying different breeds
    of dogs in a photograph. Just like how we can learn Rust quicker because of our
    knowledge of Python, the same applies here – pre-trained models can leverage information
    gained from a source task and apply it to the target task, reducing both the training
    time and the need for a large amount of annotated data, which may not be available
    or difficult to collect for the target task.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning is not limited to image classification tasks; it can also
    be applied to other deep learning tasks, such as natural language processing,
    speech recognition, and object detection. In [*Chapter 11*](B18118_11.xhtml#_idTextAnchor267),
    *NLP with TensorFlow,* we will apply transfer learning to text classification.
    There, we will see how pretrained models (which we will access from TensorFlow
    Hub), trained on large text corpora, can be fine-tuned for text classification.
  prefs: []
  type: TYPE_NORMAL
- en: In classic ML, as illustrated in *Figure 9**.1(a)*, we train the model from
    scratch for each task, as we have done so far in this book. This approach is resource-
    and data-intensive.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Traditional ML versus transfer learning](img/B18118_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Traditional ML versus transfer learning
  prefs: []
  type: TYPE_NORMAL
- en: However, researchers discovered it was possible to learn visual features so
    that a model learns low-level features from a massive dataset, such as ImageNet,
    and applies this to a new, related task, as illustrated in *Figure 9**.1(b)* –
    for example, in the classification of our weather dataset, which we used in [*Chapter
    8*](B18118_08.xhtml#_idTextAnchor186)*, Handling Overfitting*. By applying transfer
    learning, we can take advantage of the knowledge gained by a model during its
    training on a large dataset and adapt it to solve different but related tasks
    effectively. This approach proved useful, as it not only saves training time and
    resources but has also learned to improve performance, even in scenarios where
    a limited amount of data is available for the target task.
  prefs: []
  type: TYPE_NORMAL
- en: Types of transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two main ways we can apply transfer learning in CNNs. First, we can
    use the pre-trained model as a feature extractor. Here, we freeze the weights
    of the convolutional layers to preserve the knowledge gained from the source task
    and add a new classifier, which is trained for classification of the second task.
    This works because the convolutional layers are reusable, since they only learned
    the low-level features such as edges, corners, and textures, which are generic
    and applicable in different images, as shown in *Figure 9**.2*, while the fully
    connected layers are added to learn high-level details, which are used to classify
    different objects in a photograph.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Transfer learning as a feature extractor](img/B18118_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Transfer learning as a feature extractor
  prefs: []
  type: TYPE_NORMAL
- en: The second method of applying transfer learning is to unfreeze some layers of
    the pre-trained model and add a classifier model to identify the high-level features,
    as shown in *Figure 9**.3*. Here, we train both the unfrozen layers and the new
    classifier together. The pre-trained model is applied as the starting point of
    the new task, and the weight of the unfrozen layers is fine-tuned along with the
    classification layer to adapt the model to the new task.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Transfer learning as a fine-tuned model](img/B18118_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Transfer learning as a fine-tuned model
  prefs: []
  type: TYPE_NORMAL
- en: Pre-trained models are deep networks that have been trained on large datasets.
    By leveraging the knowledge and weights these models have already acquired, we
    can use them as a feature extractor or fine-tune them for our use case, with a
    smaller dataset and less training time. Transfer learning provides ML practitioners
    with access to state-of-the-art models, which can be quickly and easily accessed
    in TensorFlow using an API. This means we don’t always have to train our model
    from scratch, saving time and computational resources, as fine-tuning a model
    is faster than training it from the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: We can apply pre-trained models to relevant use cases, potentially leading to
    higher accuracy and faster convergence. However, if the source and target domains
    are unrelated, transfer learning may not only fail but also harm the performance
    of the target task, due to irrelevant learned features, a situation known as negative
    transfer. Let's apply transfer learning to a real-world image classification task.
    We will explore some of the top-performing pretrained models, such as VGG, Inception,
    MobileNetV2, and EfficientNet. These models have been pretrained for image classification
    tasks. Let’s see how they will fare on the given task.
  prefs: []
  type: TYPE_NORMAL
- en: Building a real-world image classifier with Transfer learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this case study, your company secured a medical project, and you are assigned
    the responsibility to build a pneumonia classifier for GETWELLAI. You have been
    provided with over 5,000 X-ray JPEG images, made up of two categories (pneumonia
    and normal). The dataset was annotated by expert physicians and low-quality images
    have been removed. Let's see how we can tackle this problem using the two types
    of transfer learning techniques we have discussed so far.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, we start by loading the necessary libraries that we will need for
    our project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let''s load the X-ray dataset. To do this, we will use the `wget` command
    to download the file from the specified URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The downloaded file is saved in the current working directory of our Colab instance
    as a ZIP file, which contains a dataset of the X-ray images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we will extract the contents of the `zip` folder by running the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When we run the code, we extract a `dataset` folder that holds `test`, `val`,
    and `train` sub-directories, with each sub-directory holding data for both normal
    and pneumonia X-ray images, as shown in *Figure 9**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – A snapshot of the current working directory that holds the extracted
    ZIP file](img/B18118_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – A snapshot of the current working directory that holds the extracted
    ZIP file
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the following code block to extract the sub-directories and the
    number of images in them. We also saw this code block in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*,*
    *Handling Overfitting*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It gives us a snapshot of the data in each folder and a sense of the data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will use the `view_random_images` function to display some random
    images and their shapes from the `train` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When we run the code, we will get a result similar to *Figure 9**.5*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Random images displayed from the training samples of the X-ray
    dataset](img/B18118_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Random images displayed from the training samples of the X-ray
    dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create an instance of the `ImageDataGenerator` class for our training
    and validation data. We will add the `rescale` parameter to rescale our images
    and ensure that all the pixel values are within the range of 0 to 1\. We do this
    to improve stability and enhance convergence during the training process. The
    resulting `train_datagen` and `valid_datagen` objects are used to generate batches
    of training and validation data, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we set up the `train`, `validation`, and `test` directories.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We used the `flow_from_directory()` method to load images from the training
    directory. The `target_size` argument is used to resize all the images to 224
    x 224 pixels. One key difference between this code and the one we used in [*Chapter
    8*](B18118_08.xhtml#_idTextAnchor186)*, Handling Overfitting* is that the class
    mode argument is set to `binary` because we are dealing with a binary classification
    problem (i.e., normal and pneumonia):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `valid_data` and `test_data` generators are quite similar to the `train_data`
    generator, as they both have their target size set to 224 x 224 as well; the key
    difference is they have set `shuffle` to `false`, which means the images will
    not be shuffled. If we set this to `true`, the images get shuffled.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start by using the same model we applied in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*,
    Handling Overfitting*. To avoid redundancy, let’s focus on the fully connected
    layer, where we have one neuron in the output layer, as this is a binary classification
    task. We will compare the result with using transfer learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we have one neuron in the output layer, and we changed the activation
    function to a sigmoid function, since we are building a binary classifier. In
    the compile step, we also change the loss function to binary cross entropy; everything
    else remains the same. Then, we fit the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The training ends on the 7th epoch, as the validation loss fails to drop further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'On the fifth epoch, the model reached a validation accuracy of 100 percent,
    which looks promising. Let’s evaluate the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: When we evaluate the model on test data, we recorded only an accuracy of 0.7580\.
    This points to signs of overfitting. Of course, we can try a combination of the
    ideas we learned in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*, Handling
    Overfitting* to improve the model’s performance and you are encouraged to do so.
    However, let's learn how to use pre-trained models and see whether we can transfer
    the knowledge gained by these models to our use case and, if possible, get better
    results. Let’s do that next.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling with transfer learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will utilize three widely used pre-trained CNNs for image
    classification – VGG16, InceptionV3, and MobileNet. We will demonstrate the application
    of transfer learning as a feature extractor using these models, followed by adding
    a fully connected layer for label classification. We will also learn how to fine-tune
    a pre-trained model by unfreezing some of its layers. Before we can use these
    models, we need to import them. We can do this using a single line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our models and we are set to go, let’s begin with VGG16.
  prefs: []
  type: TYPE_NORMAL
- en: VGG16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: VGG16 is a CNN architecture developed by the Visual Geometry Group at the University
    of Oxford. It was trained on the ImageNet dataset. The VGG16 architecture secured
    second place in the image classification category in the ImageNet Challenge 2014
    submission. VGG16 is made up of 13 (a 3 x 3 filter) convolutional layers, 5 (2x2)
    max-pooling layers, and 3 fully connected layers, as illustrated in *Figure 9**.6*.
    This gives us 16 layers with learnable parameters; recall that max-pooling layers
    are for dimensionality reduction and they have no weight. This one takes an input
    tensor of the 224 x 224 RGB image.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – The VGG16 model’s architecture (Source: https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765)](img/B18118_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.6 – The VGG16 model’s architecture (Source: https://medium.com/analytics-vidhya/car-brand-classification-using-vgg16-transfer-learning-f219a0f09765)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin by loading VGG16 from Keras. We want to load the model and use
    pre-trained weights from the ImageNet dataset. To do this, we set the `weights`
    parameter to `imagenet`; we also set the `include_top` parameter to `false`. This
    is done because we want to use the model as a feature extractor. This way, we
    can add our own custom-made, fully connected layers for classification. We set
    the input size to (224,224,3) as this is the input image size that VGG16 expects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step enables us to freeze the weights of the model because we want
    to use VGG 16 as a feature extractor. When we freeze all the layers, this makes
    them untrainable, which means their weights will not be updated during training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The next code block creates a new sequential model that uses VGG as its top
    layer, after which we add a fully connected layer made up of a dense layer with
    1,024 neurons, a dropout layer, and an output layer with one neuron, and then
    we set the activation to sigmoid for binary classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We compile and fit our model to the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'In four epochs, our model stops training. It reaches a training accuracy of
    0.9810 but on the validation set, we get an accuracy of 0.875:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: When we evaluate the model, we reach an accuracy of 84.29\. Now, let's use another
    pre-trained model as a feature extractor.
  prefs: []
  type: TYPE_NORMAL
- en: MobileNet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MobileNet is a lightweight CNN model developed by engineers at Google. The model
    is light and efficient, making it a choice model to develop mobile and embedded
    vision apps. Like VGG16, MobileNet was also trained on the ImageNet dataset, and
    it was able to achieve state-of-the-art results. MobileNet has a streamlined architecture
    that makes use of depth-wise separable convolutions. The underlining idea is to
    reduce the number of parameters required during training while maintaining accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply MobileNet as a feature extractor, the steps are similar to what we
    just did with VGG16; hence, let’s look at the code block. We will load the model,
    freeze the layers, and add a fully connected layer as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we compile and fit the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'In just four epochs, the model reaches a validation accuracy of 87.50%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's try fine-tuning a pre-trained model hands-on.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning as a fine-tuned model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: InceptionV3 is another CNN architecture developed by Google. It combines 1x1
    and 3x3 filters to capture different aspects of an image. Let’s unfreeze some
    layers of this pre-trained model so that we can train both the layers we unfroze
    and the fully connected layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will load the InceptionV3 model. We set `include_top=False` to remove
    the classification layer of InceptionV3 and use weights from ImageNet. We unfreeze
    the last 50 layers by setting `trainable` to `true` for these layers. This enables
    us to train these layers on the X-ray dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Note:'
  prefs: []
  type: TYPE_NORMAL
- en: Unfreezing and fine-tuning too many layers on a small dataset is a bad strategy,
    as this can lead to overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create, fit, and compile the model, as we have done so far, and the
    new model reaches a validation accuracy of 100 percent on the fifth epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s evaluate the models using our `evaluate_models` helper function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – An evaluation result from our experiments](img/B18118_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – An evaluation result from our experiments
  prefs: []
  type: TYPE_NORMAL
- en: From the results in *Figure 9**.7*, MobileNet, VGG16, and InceptionV3 came out
    on top. We can see that these models performed much better than our baseline model
    (**model 1**). We also report the results of a few other models from our notebook.
    We can spot signs of overfitting; hence, you can combine some of the ideas we
    discussed in [*Chapter 8*](B18118_08.xhtml#_idTextAnchor186)*, Handling Overfitting*
    to improve your result.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transfer learning has gained traction in the deep learning community, due to
    its improved performance, speed, and accuracy in building deep learning models.
    We discussed the rationale behind transfer learning and explored transfer learning
    as a feature extractor and a fine-tuned model. We built a couple of solutions
    using the top-performing pre-trained models and saw how they outperformed our
    baseline model when applied to the X-ray dataset.
  prefs: []
  type: TYPE_NORMAL
- en: By now, you should have gained a solid understanding of transfer learning and
    its applications. Equipped with this knowledge, you should be able to apply transfer
    learning as either a feature extractor or a fine-tuned model when building real-world
    deep learning solutions for a wide range of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we have come to the end of this chapter and this section of the book.
    In the next chapter, we will discuss **natural language processing** (**NLP**),
    where we will build exciting NLP applications using TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s test what we learned in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the test notebook, load the cat and dog dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocess the image data using the image data generator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a VGG16 model as a feature extractor and build a new CNN model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unfreeze 40 layers of an InceptionV3 model and build a new CNN model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate both the VGG16 and InceptionV3 models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more, you can check out the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kapoor, A., Gulli, A. and Pal, S. (2020) *Deep Learning with TensorFlow and
    Keras Third Edition: Build and deploy supervised, unsupervised, deep, and reinforcement
    learning models*. Packt Publishing Ltd.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Adapting Deep Convolutional Neural Networks for Transfer Learning: A Comparative
    Study* by C. M. B. Al-Rfou, G. Alain, and Y. Bengio, published in arXiv preprint
    arXiv:1511.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Very Deep Convolutional Networks for Large-Scale Image Recognition* by K.
    Simonyan and A. Zisserman, published in arXiv preprint arXiv:1409.1556 in 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks*
    by M. Tan and Q. Le, published in *International Conference on Machine Learning*
    in 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MobileNetV2: Inverted Residuals and Linear Bottlenecks* by M. Sandler, A.
    Howard, M. Zhu, A. Zhmoginov, and L. Chen, published in arXiv preprint arXiv:1801.04381
    in 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition*
    by Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., & Darrell,
    T. (2014).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Harnessing the power of transfer learning for medical image classification*
    by Ryan Burke, *Towards Data* *Science*. [https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7](https://towardsdatascience.com/harnessing-the-power-of-transfer-learning-for-medical-image-classification-fd772054fdc7)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part 3 – Natural Language Processing with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will learn to build **natural language processing** (**NLP**)
    applications with TensorFlow. You will understand how to perform text processing
    and build models for text classification. In this part, you will also learn to
    generate text using LSTMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18118_10.xhtml#_idTextAnchor226), *Introduction to Natural
    Language Processing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B18118_11.xhtml#_idTextAnchor267), *NLP with TensorFlow*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
