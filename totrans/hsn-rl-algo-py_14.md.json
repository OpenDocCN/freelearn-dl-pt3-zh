["```\nsolver = EvolutionaryAlgortihm()\n\nwhile best_fitness < required_fitness:\n\n    candidates = solver.generate_candidates() # for example from crossover and mutation\n\n    fitness_values = []\n    for candidate in candidates:\n        fitness_values.append(evaluate(candidate))\n\n    solver.set_fitness_values(fitness_values)\n\n    best_fitness = solver.evaluate_best_candidate()\n```", "```\n---------------------------------------------------------------------------------\nParallelized Evolution Strategy\n---------------------------------------------------------------------------------\n\nInitialize parameters  on each worker\nInitialize random seed on each worker\n\nfor  do:\n    for ![](img/ebb094da-015f-4821-b5a7-6ee124759d3c.png) do:\n        Sample \n        Evaluate individuals  and \n\n    Spread returns to each other worker\n\n    for  do:\n        Compute normalized rank  from the returns\n        Reconstruct  from the random seeds of the other workers\n         (maybe using Adam)\n```", "```\ndef ES(env_name, hidden_sizes=[8,8], number_iter=1000, num_workers=4, lr=0.01, batch_size=50, std_noise=0.01):\n```", "```\n    initial_seed = np.random.randint(1e7)\nindiv_per_worker = int(batch_size / num_workers)\n    output_queue = mp.Queue(maxsize=num_workers*indiv_per_worker)\n    params_queue = mp.Queue(maxsize=num_workers)\n```", "```\n    processes = []\n\n    for widx in range(num_workers):\n\n        p = mp.Process(target=worker, args=(env_name, initial_seed, hidden_sizes, lr, std_noise, indiv_per_worker, str(widx), params_queue, output_queue))\n        p.start()\n        processes.append(p)\n```", "```\n    for n_iter in range(number_iter):\n        batch_seed = []\n        batch_return = []\n\n        for _ in range(num_workers*indiv_per_worker):\n            p_rews, p_seed = output_queue.get()\n            batch_seed.append(p_seed)\n            batch_return.extend(p_rews)\n\n```", "```\n        batch_return = normalized_rank(batch_return)\n\n        for _ in range(num_workers):\n            params_queue.put([batch_return, batch_seed])\n```", "```\n    for p in processes:\n        p.terminate()\n```", "```\n    sess = tf.Session(config=tf.ConfigProto(device_count={'CPU': 4}, allow_soft_placement=True))\n    sess.run(tf.global_variables_initializer())\n```", "```\nwith tf.device(\"/cpu:0\"):\n    # graph to compute on the CPUs 0\n\n```", "```\n    agent_flatten_shape = sess.run(agent_variables_flatten).shape\n\n    while True:\n```", "```\n        for _ in range(indiv_per_worker):\n            seed = np.random.randint(1e7)\n\n            with temp_seed(seed):\n                sampled_noise = np.random.normal(size=agent_flatten_shape)\n\n            pos_rew= evaluation_on_noise(sampled_noise)\n            neg_rew = evaluation_on_noise(-sampled_noise)\n\n            output_queue.put([[pos_rew, neg_rew], seed])\n```", "```\nwith temp_seed(seed):\n    ..\n```", "```\n        batch_return, batch_seed = params_queue.get()\n        batch_noise = []\n\n        # reconstruction of the perturbations used to generate the individuals\n        for seed in batch_seed:\n            with temp_seed(seed):\n                sampled_noise = np.random.normal(size=agent_flatten_shape)\n\n            batch_noise.append(sampled_noise)\n            batch_noise.append(-sampled_noise)\n\n        # Computation of the gradient estimate following the formula (11.2)\n        vars_grads = np.zeros(agent_flatten_shape)\n        for n, r in zip(batch_noise, batch_return):\n            vars_grads += n * r\n\n        vars_grads /= len(batch_noise) * std_noise\n\n        sess.run(apply_g, feed_dict={new_weights_ph:-vars_grads})\n```"]