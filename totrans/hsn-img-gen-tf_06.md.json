["```\ninput_label = layers.Input(shape=1, dtype=tf.int32, \t \t \t                           name='ClassLabel')        \n        one_hot_label = tf.one_hot(input_label, \t\t\t                                   self.num_classes)\n        one_hot_label = layers.Reshape((self.num_classes,))\t                                       (one_hot_label)\n```", "```\n        input_z = layers.Input(shape=self.z_dim, \t \t      \t                               name='LatentVector')\n        generator_input = layers.Concatenate()([input_z, \n                                                one_hot_label])\n```", "```\ndiscriminator = Model([input_image, input_label], output]\n```", "```\npred_real = discriminator([real_images, class_labels])\n```", "```\nfake_class_labels = tf.random.uniform((batch_size), \t\t\t\t\t\tminval=0, maxval=10, \t\t\t\t\t\tdtype=tf.dtypes.int32)\nfake_images = generator.predict([latent_vector, \t\t\t\t\t\tfake_class_labels])\n```", "```\nencoded_label = tf.one_hot(input_label, self.num_classes)\nembedding = layers.Dense(32 * 32 * 1, activation=None)\\ \t\t\t\t  (encoded_label) \nembedding = layers.Embedding(self.num_classes, \t\t\t\t\t  32*32*1)(input_label)\n```", "```\nx = layers.Multiply()([input_image, embedding])\n```", "```\ndef downsample(self, channels, kernels, strides=2, \t\t    norm=True, activation=True, dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    block = tf.keras.Sequential()\n    block.add(layers.Conv2D(channels, kernels, \t\t   strides=strides, padding='same', \t\t   use_bias=False, \t\t   kernel_initializer=initializer))\n    if norm:\n        block.add(layers.BatchNormalization())              \n    if activation:\n        block.add(layers.LeakyReLU(0.2)) \n    if dropout:\n        block.add(layers.Dropout(0.5))\n    return block\n```", "```\ndef upsample(self, channels, kernels, strides=1,  \t\t  norm=True, activation=True, dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    block = tf.keras.Sequential()\n    block.add(layers.UpSampling2D((2,2)))\n    block.add(layers.Conv2D(channels, kernels, \t\t   strides=strides, padding='same', \t\t   use_bias=False, \t\t   kernel_initializer=initializer))\n    if norm:\n        block.add(InstanceNormalization())              \n    if activation:\n        block.add(layers.LeakyReLU(0.2)) \n    if dropout:\n        block.add(layers.Dropout(0.5))\n    return block\n```", "```\ninput_image = layers.Input(shape=image_shape)\ndown1 = self.downsample(DIM, 4, norm=False)(input_image) # 128\ndown2 = self.downsample(2*DIM, 4)(down1) # 64\ndown3 = self.downsample(4*DIM, 4)(down2) # 32\ndown4 = self.downsample(4*DIM, 4)(down3) # 16\ndown5 = self.downsample(4*DIM, 4)(down4) # 8\ndown6 = self.downsample(4*DIM, 4)(down5) # 4\ndown7 = self.downsample(4*DIM, 4)(down6) # 2\n```", "```\nup6 = self.upsample(4*DIM, 4, dropout=True)(down7) # 4,4*DIM\nconcat6 = layers.Concatenate()([up6, down6])   \nup5 = self.upsample(4*DIM, 4, dropout=True)(concat6) \nconcat5 = layers.Concatenate()([up5, down5])  \nup4 = self.upsample(4*DIM, 4, dropout=True)(concat5) \nconcat4 = layers.Concatenate()([up4, down4])  \nup3 = self.upsample(4*DIM, 4)(concat4) \nconcat3 = layers.Concatenate()([up3, down3]) \nup2 = self.upsample(2*DIM, 4)(concat3) \nconcat2 = layers.Concatenate()([up2, down2])  \nup1 = self.upsample(DIM, 4)(concat2) \nconcat1 = layers.Concatenate()([up1, down1])  \noutput_image = tanh(self.upsample(3, 4, norm=False, \t\t\t\tactivation=None)(concat1))\n```", "```\nLAMBDA = 100\nself.model.compile(loss = ['bce','mae'],\n                   optimizer = Adam(2e-4, 0.5, 0.9999),\n                   loss_weights=[1, LAMBDA])\n```", "```\ndef build_discriminator(self):\n    DIM = 64\n    model = tf.keras.Sequential(name='discriminators') \n    input_image_A = layers.Input(shape=image_shape)\n    input_image_B = layers.Input(shape=image_shape)\n    x = layers.Concatenate()([input_image_A, \t\t\t\t\t   input_image_B])\n    x = self.downsample(DIM, 4, norm=False)(x) \n    x = self.downsample(2*DIM, 4)(x) \n    x = self.downsample(4*DIM, 4)(x) \n    x = self.downsample(8*DIM, 4, strides=1)(x) \n    output = layers.Conv2D(1, 4, activation='sigmoid')(x)\n    return Model([input_image_A, input_image_B], output)     \n```", "```\nreal_labels = tf.ones((batch_size, self.patch_size, \t\t\t\t self.patch_size, 1))\nfake_labels = tf.zeros((batch_size, self.patch_size, \t\t\t\t  self.patch_size, 1))\nfake_images = self.generator.predict(real_images_A)\npred_fake = self.discriminator([real_images_A, \t\t\t\t\t\tfake_images])\npred_real = self.discriminator([real_images_A, \t\t\t\t\t\treal_images_B])\n```", "```\nfrom tensorflow_addons.layers import InstanceNormalization\n```", "```\ndef build_discriminator(self):\n    DIM = 64\n    input_image = layers.Input(shape=image_shape)\n    x = self.downsample(DIM, 4, norm=False)(input_image) # 128\n    x = self.downsample(2*DIM, 4)(x) # 64\n    x = self.downsample(4*DIM, 4)(x) # 32\n    x = self.downsample(8*DIM, 4, strides=1)(x) # 29\n    output = layers.Conv2D(1, 4)(x)\n```", "```\nself.discriminator_B = self.build_discriminator()\nself.discriminator_A = self.build_discriminator()\nself.generator_AB = self.build_generator()\nself.generator_BA = self.build_generator()\n```", "```\nimage_A = layers.Input(shape=input_shape)\nimage_B = layers.Input(shape=input_shape)\n# forward\nfake_B = self.generator_AB(image_A)\ndiscriminator_B_output = self.discriminator_B(fake_B)\nreconstructed_A = self.generator_BA(fake_B)\n# backward\nfake_A = self.generator_BA(image_B)\ndiscriminator_A_output = self.discriminator_A(fake_A)\nreconstructed_B = self.generator_AB(fake_A)\n# identity\nidentity_B = self.generator_AB(image_A)\nidentity_A = self.generator_BA(image_B)\n```", "```\nself.model = Model(inputs=[image_A, image_B],\n                   outputs=[discriminator_B_output,  \n                            discriminator_A_output,\n                            reconstructed_A,\n                            reconstructed_B,\n                            identity_A, identity_B\n                            ])\n```", "```\nself.LAMBDA = 10\nself.LAMBDA_ID = 5\nself.model.compile(loss = ['mse','mse', 'mae','mae',                           'mae','mae'],\n                   optimizer = Adam(2e-4, 0.5),\n                   loss_weights=[1, 1, \n                                 self.LAMBDA, self.LAMBDA,\n                                 self.LAMBDA_ID,  \t\t\t\t\t\tself.LAMBDA_ID])\n```", "```\n# train discriminator\nd_loss_AB = self.train_discriminator(“AB”, real_images_A, \t\t\t\t\t\t\treal_images_B)\nd_loss_BA = self.train_discriminator(“BA”, real_images_B, \t\t\t\t\t\t\treal_images_A)    \n```", "```\n# train generator\ncombined_loss = self.model.train_on_batch(\n                   [real_images_A, real_images_B], \n                   [real_labels, real_labels,\n                    real_images_A, real_images_B,\n                    real_images_A, real_images_B\n \t\t   ])\n```", "```\ninput_image = layers.Input(shape=image_shape, \t\t\t\t\tname='input_image')\ninput_z = layers.Input(shape=(self.z_dim,), name='z') \nz = layers.Reshape((1,1, self.z_dim))(input_z)\nz_tiles = tf.tile(z, [self.batch_size, self.input_shape[0], \t\t\t\tself.input_shape[1], self.z_dim])\nx = layers.Concatenate()([input_image, z_tiles])\n```", "```\nimages_A_1 = layers.Input(shape=input_shape,  \t\t\t\t     name='ImageA_1')\nimages_B_1 = layers.Input(shape=input_shape, \t\t\t\t\tname='ImageB_1') \nz_encode, self.mean_encode, self.logvar_encode = \\ \t\t\t\t\t\tself.encoder(images_B_1)\nfake_B_encode = self.generator([images_A_1, z_encode])\nencode_fake = self.discriminator_1(fake_B_encode)\nencode_real = self.discriminator_1(images_B_1)\nkl_loss =  - 0.5 * tf.reduce_sum(1 + self.logvar_encode - \\\n                            tf.square(self.mean_encode) - \\\n \t\t\t\t\t tf.exp(self.logvar_encode)) \nself.cvae_gan = Model(inputs=[images_A_1, images_B_1],\n                      outputs=[encode_real, encode_fake, fake_B_encode, kl_loss])\n```", "```\nimages_A_2 = layers.Input(shape=input_shape, \t\t\t\t\tname='ImageA_2')\nimages_B_2 = layers.Input(shape=input_shape, \t\t\t\t\tname='ImageB_2')\nz_random = layers.Input(shape=(self.z_dim,), name='z') \nfake_B_random = self.generator([images_A_2, z_random])\n_, mean_random, _ = self.encoder(fake_B_random)\nrandom_fake = self.discriminator_2(fake_B_random)\nrandom_real = self.discriminator_2(images_B_2)      \nself.clr_gan = Model(inputs=[images_A_2, images_B_2, \t\t\t\t\t  z_random], \n                     outputs=[random_real, random_fake, \t\t\t     mean_random])\n```", "```\nimages_A_1, images_B_1 = next(data_generator)\nimages_A_2, images_B_2 = next(data_generator)\nself.train_step(images_A_1, images_B_1, images_A_2, \t\t\timages_B_2)\n```", "```\n    def train_step(self, images_A_1, images_B_1, \t\t\t     images_A_2, images_B_2):\n        z = tf.random.normal((self.batch_size,  \t\t\t\t    self.z_dim))    \n        real_labels = tf.ones((self.batch_size, \t\t\t\t\tself.patch_size, \t\t\t\t\tself.patch_size, 1))\n        fake_labels = tf.zeros((self.batch_size, \t\t\t\t\t self.patch_size, \t\t\t\t\t self.patch_size, 1)) \n        with tf.GradientTape() as tape_e, \t    tf.GradientTape() as tape_g,\\ \t    tf.GradientTape() as tape_d1,\\ \t    tf.GradientTape() as tape_d2:\n            encode_real, encode_fake, fake_B_encode,\\ \t\tkl_loss = self.cvae_gan([images_A_1, \t\t\t\t\t\t   images_B_1])\n            random_real, random_fake, mean_random = \\ \t\t     self.clr_gan([images_A_2, images_B_2, z])\n    ```", "```\n    self.d1_loss = self.mse(real_labels, encode_real) + \\ \t\t    self.mse(fake_labels, encode_fake) \n    gradients_d1 = tape_d1.gradient(self.d1_loss, \t\t self.discriminator_1.trainable_variables)\n    self.optimizer_d1.apply_gradients(zip(gradients_d1, \t\tself.discriminator_1.trainable_variables))\n    self.d2_loss = self.mse(real_labels, random_real) +\\ \t\t\tself.mse(fake_labels, random_fake) \n    gradients_d2 = tape_d2.gradient(self.d2_loss, \t      self.discriminator_2.trainable_variables)\n    self.optimizer_d2.apply_gradients(zip(gradients_d2, \t\tself.discriminator_2.trainable_variables))\n    ```", "```\n    self.LAMBDA_IMAGE = 10\n    self.LAMBDA_LATENT = 0.5\n    self.LAMBDA_KL = 0.01\n    self.gan_1_loss = self.mse(real_labels, encode_fake)\n    self.gan_2_loss = self.mse(real_labels, random_fake)\n    self.image_loss = self.LAMBDA_IMAGE * self.mae( \t\t\t\t    images_B_1, fake_B_encode)\n    self.kl_loss = self.LAMBDA_KL*kl_loss\n    self.latent_loss = self.LAMBDA_LATENT *self.mae(z, \t\t\t\t\t\t\t mean_random)\n    ```", "```\n    encoder_loss = self.gan_1_loss + self.gan_2_loss +\\ \t\t\tself.image_loss + self.kl_loss\n    generator_loss = encoder_loss + self.latent_loss\n    gradients_generator = tape_g.gradient(generator_loss, \t \t \t self.generator.trainable_variables)\n    self.optimizer_generator.apply_gradients(zip( \t\t\tgradients_generator, \t\t\tself.generator.trainable_variables))\n    gradients_encoder = tape_e.gradient(encoder_loss, \t\t\tself.encoder.trainable_variables)\n    self.optimizer_encoder.apply_gradients(zip( \t\t\tgradients_encoder, \t\t\tself.encoder.trainable_variables))\n    ```"]