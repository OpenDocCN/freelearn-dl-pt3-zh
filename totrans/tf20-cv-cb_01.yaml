- en: '*Chapter 1*: Getting Started with TensorFlow 2.x for Computer Vision'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the greatest features of TensorFlow 2.x is that it finally incorporates
    Keras as its high-level API. Why is this so important? While it's true that Keras
    and TensorFlow have had very good compatibility for a while, they have remained
    separate libraries with different development cycles, which causes frequent compatibility
    issues. Now that the relationship between these two immensely popular tools is
    official, they'll grow in the same direction, following a single roadmap and making
    the interoperability between them completely seamless. In the end, Keras is TensorFlow
    and TensorFlow is Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the biggest advantage of this merger is that by using Keras' high-level
    features, we are not sacrificing performance by any means. Simply put, Keras code
    is production-ready!
  prefs: []
  type: TYPE_NORMAL
- en: Unless the requirements of a particular project demand otherwise, in the vast
    majority of the recipes in this book, we'll rely on TensorFlow's Keras API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason behind this decision is twofold:'
  prefs: []
  type: TYPE_NORMAL
- en: Keras is easier to understand and work with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's the encouraged way to develop using TensorFlow 2.x.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with the basic building blocks of the Keras API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading images using the Keras API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading images using the tf.data.Dataset API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saving and loading a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing a model's architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a basic image classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this chapter, you will need a working installation of TensorFlow 2.x. If
    you can access a GPU, either physical or via a cloud provider, your experience
    will be much more enjoyable. In each recipe, in the *Getting ready* section, you
    will find the specific preliminary steps and dependencies to complete it. Finally,
    all the code shown in this chapter is available in this book's GitHub repository
    at [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch1](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following link to see the Code in Action video:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/39wkpGN](https://bit.ly/39wkpGN).'
  prefs: []
  type: TYPE_NORMAL
- en: Working with the basic building blocks of the Keras API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keras is the official high-level API for TensorFlow 2.x and its use is highly
    encouraged for both experimental and production-ready code. Therefore, in this
    first recipe, we'll review the basic building blocks of Keras by creating a very
    simple fully connected neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Are you ready? Let's begin!
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the most basic level, a working installation of TensorFlow 2.x is all you
    need.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following sections, we''ll go over the sequence of steps required to
    complete this recipe. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the required libraries from the Keras API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a model using the Sequential API by passing a list of layers to the
    Sequential constructor. The numbers in each layer correspond to the number of
    neurons or units it contains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a model using the `add()` method to add one layer at a time. The numbers
    in each layer correspond to the number of neurons or units it contains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a model using the Functional API. The numbers in each layer correspond
    to the number of neurons or units it contains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a model using an object-oriented approach by sub-classing `tensorflow.keras.models.Model`.
    The numbers in each layer correspond to the number of neurons or units it contains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare the data so that we can train all the models we defined previously.
    We must reshape the images into vector format because that''s the format that''s
    expected by a fully connected network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'One-hot encode the labels to break any undesired ordering bias:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Take 20% of the data for validation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile, train the models for 50 epochs, and evaluate them on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After 50 epochs, all three models should have obtained around 98% accuracy on
    the test set.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we went over the basic building blocks we'll need to
    build most deep learning-powered computer vision projects using TensorFlow 2.x.
  prefs: []
  type: TYPE_NORMAL
- en: First, we imported the Keras API, the high-level interface for the second version
    of TensorFlow. We learned that all Keras-related functionality is located inside
    the `tensorflow` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we found that TensorFlow 2.x offers great flexibility when it comes to
    defining models. In particular, we have two main APIs we can use to build models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Symbolic**: Also known as the declarative API, it allows us to define a model
    as a **Directed Acyclic Graph (DAG)**, where each layer constitutes a node and
    the interactions or connections between layers are the edges. The pros of this
    API are that you can examine the model by plotting it or printing its architecture;
    compatibility checks are run by the framework, diminishing the probability of
    runtime errors; and if the model compiles, it runs. On the other hand, the main
    con is that it''s not suited for non-DAG architectures (networks with loops),
    such as Tree-LSTMs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Imperative**: Also known as the **model sub-classing API**, this API is a
    more Pythonic, developer-friendly way of specifying a model. It also allows for
    more flexibility in the forward pass than its symbolic counterpart. The pros of
    this API are that developing models becomes no different than any other object-oriented
    task, which speeds up the process of trying out new ideas; specifying a control
    flow is easy using Python''s built-in constructs; and it''s suited for non-DAG
    architectures, such as Tree-RNNs. In terms of its cons, reusability is lost because
    the architecture is hidden within the class; almost no inter-layer compatibility
    checks are run, thus moving most of the debugging responsibility from the framework
    to the developer; and there''s loss of transparency because information about
    the interconnectedness between layers is not available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We defined the same architecture using both the Sequential and Functional APIs,
    which correspond to the symbolic or declarative way of implementing networks,
    and also a third time using an imperative approach.
  prefs: []
  type: TYPE_NORMAL
- en: To make it clear that, in the end, the three networks are the same, no matter
    which approach we took, we trained and evaluated them on the famous `MNIST` dataset,
    obtaining a decent 98% accuracy on the test set.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you''re interested in learning more about Tree-LSTMs, you can read the paper
    where they were first introduced here: https://nlp.stanford.edu/pubs/tai-socher-manning-acl2015.pdf.'
  prefs: []
  type: TYPE_NORMAL
- en: Loading images using the Keras API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to load images using the Keras API, a very
    important task considering that, in computer vision, we'll always work with visual
    data. In particular, we'll learn how to open, explore, and visualize a single
    image, as well as a batch of them. Additionally, we will learn how to programmatically
    download a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Keras relies on the `Pillow` library to manipulate images. You can install
    it easily using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s begin this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the URL and destination of the `CINIC-10` dataset, an alternative to
    the famous `CIFAR-10` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download and decompress the data. By default, it will be stored in `~/.keras/datasets/<FILE_NAME>`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load all image paths and print the number of images found:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load a single image from the dataset and print its metadata:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert an image into a `NumPy` array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display an image using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives us the following image:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Sample image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_01_001.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.1 – Sample image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load a batch of images using `ImageDataGenerator`. As in the previous step,
    each image will be rescaled to the range [0, 1]:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `image_generator`, we''ll pick and display a random batch of 10 images
    directly from the directory they are stored in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The displayed batch is shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.2 – Batch of images'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_01_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.2 – Batch of images
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how it all works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we downloaded a visual dataset with the help of the `get_file()` function,
    which, by default, stores the file with a name of our choosing inside the `~/.keras/datasets`
    directory. If the file already exists in this location, `get_files()` is intelligent
    enough to not download it again.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we decompressed the `CINIC-10` dataset using `untar`. Although these steps
    are not required to load images (we can manually download and decompress a dataset),
    it's often a good idea to automate as many steps as we can.
  prefs: []
  type: TYPE_NORMAL
- en: We then loaded a single image into memory with `load_img()`, a function that
    uses `Pillow` underneath. Because the result of this invocation is in a format
    a neural network won't understand, we transformed it into a `NumPy` array with
    `img_to_array()`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to load batches of images instead of each one individually, we used
    `ImageDataGenerator`, which had been configured to also normalize each image.
    `ImageDataGenerator` is capable of much more, and we'll often use it whenever
    we want to implement data augmentation, but for this recipe, we only used it to
    load groups of 10 images at a time directly from disk, thanks to the `flow_from_directory()`
    method. As a final remark, this last method returns batches of images and labels,
    but we ignored the latter as we're only interested in the former.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To learn more about processing images with Keras, please consult the official
    documentation here: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image.
    For more information on the `CINIC-10` dataset, visit this link: [https://datashare.is.ed.ac.uk/handle/10283/3192](https://datashare.is.ed.ac.uk/handle/10283/3192).'
  prefs: []
  type: TYPE_NORMAL
- en: Loading images using the tf.data.Dataset API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to load images using the `tf.data.Dataset`
    API, one of the most important innovations that TensorFlow 2.x brings. Its functional
    style interface, as well as its high level of optimization, makes it a better
    alternative than the traditional Keras API for large projects, where efficiency
    and performance is a must.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we'll learn how to open, explore, and visualize a single image,
    as well as a batch of them. Additionally, we will learn how to programmatically
    download a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s begin this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to import all the packages we''ll need for this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the URL and destination of the `CINIC-10` dataset, an alternative to
    the famous `CIFAR-10` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download and decompress the data. By default, it will be stored in `~/keras/dataset/<FILE_NAME>`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a dataset of image paths using a glob-like pattern:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Take a single path from the dataset and use it to read the corresponding image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Even though the image is now in memory, we must convert it into a format a
    neural network can work with. For this, we must decode it from its PNG format
    into a `NumPy` array, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the image using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Sample image'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_01_003.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.3 – Sample image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Take the first 10 elements of `image_dataset`, decode and normalize them, and
    then display them using `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Batch of images](img/B14768_01_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 – Batch of images
  prefs: []
  type: TYPE_NORMAL
- en: Let's explain this in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we downloaded the `CINIC-10` dataset using the `get_file()` helper function,
    which saves the fetched file with a name we give it inside the `~/.keras/datasets`
    directory by default. If the file was downloaded before, `get_files()` won't download
    it again.
  prefs: []
  type: TYPE_NORMAL
- en: Because CINIC-10 is compressed, we used `untar` to extract its contents. This
    is certainly not required to execute these steps each time we want to load images,
    given that we can manually download and decompress a dataset, but it's a good
    practice to automate as many steps as possible.
  prefs: []
  type: TYPE_NORMAL
- en: To load the images into memory, we created a dataset of their file paths, which
    enabled us to follow almost the same process to display single or multiple images.
    We did this using the path to load the image into memory. Then, we decoded it
    from its source format (PNG, in this recipe), converted it into a `NumPy` array,
    and then pre-processed it as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we took the first 10 images in the dataset and displayed them with
    `matplotlib`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you want to learn more about the `tf.data.Dataset` API, please refer to
    the official documentation here: [https://www.tensorflow.org/api_docs/python/tf/data/Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).
    For more information regarding the CINIC-10 dataset, go to this link: https://datashare.is.ed.ac.uk/handle/10283/3192.'
  prefs: []
  type: TYPE_NORMAL
- en: Saving and loading a model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training a neural network is hard work and time-consuming. That's why retraining
    a model every time is impractical. The good news is that we can save a network
    to disk and load it whenever we need it, whether to improve its performance with
    more training or to use it to make predictions on fresh data. In this recipe,
    we'll learn about different ways to persist a model.
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll train a `mnist` just to illustrate our point. Let''s
    get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import everything we will need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will download and prepare the data by normalizing the
    train and test sets and one-hot encoding the labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for building a network. The architecture comprises a single
    convolutional layer and two fully connected layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement a function that will evaluate a network using the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare the data, create a validation split, and instantiate the neural network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compile and train the model for 50 epochs, with a batch size of `1024`. Feel
    free to tune these values according to the capacity of your machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Save the model, along with its weights, in HDF5 format using the `save()` method.
    Then, load the persisted model using `load_model()` and evaluate the network''s
    performance on the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we can see that our loaded model obtains 98.36% accuracy on the test set.
    Let's take a look at this in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We just learned how to persist a model to disk and back into memory using TensorFlow's
    2.0 Keras API, which consists of saving both the model and its weights in a single
    `save()` method. Although there are other ways to achieve the same goal, this
    is the preferred and most commonly used method because we can simply restore a
    network to its saved state using the `load_model()` function, and then resume
    training or use it for inference.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also store the model separately from the weights – the former in `to_json()`
    and `save_weights()`, respectively. The advantage of this approach is that we
    can copy a network with the same architecture from scratch using the `model_from_json()`
    function. The downside, though, is that we need more function calls, and this
    effort is rarely worth it.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing a model's architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Due to their complexity, one of the most effective ways to debug a neural network
    is by visualizing its architecture. In this recipe, we''ll learn about two different
    ways we can display a model''s architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a text summary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a visual diagram
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll need both `Pillow` and `pydot` to generate a visual representation of
    a network''s architecture. We can install both libraries using pip, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Visualizing a model''s architecture is pretty easy, as we''ll learn in the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement a model using all the layers we imported in the previous step. Notice
    that we are naming each layer for ease of reference later on. First, let''s define
    the input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the first convolution block:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the second convolution block:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we''ll define the dense layers and the model itself:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Summarize the model by printing a text representation of its architecture,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here''s the summary. The numbers in the **Output Shape** column describe the
    dimensions of the volume produced by that layer, while the number in the **Param
    #** column states the number of parameters in that layer:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Text representation of the network'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_01_005.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.5 – Text representation of the network
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The last few lines summarize the number of trainable and non-trainable parameters.
    The more parameters a model has, the harder and slower it is to train.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot a diagram of the network''s architecture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This produces the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.6 – Visual representation of the network'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B14768_01_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.6 – Visual representation of the network
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's learn how this all works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Visualizing a model is as simple as calling `plot_model()` on the variable that
    holds it. For it to work, however, we must ensure we have the required dependencies
    installed; for instance, `pydot`. Nevertheless, if we want a more detailed summary
    of the number of parameters in our network layer-wise, we must invoke the `summarize()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, naming each layer is a good convention to follow. This makes the architecture
    more readable and easier to reuse in the feature because we can simply retrieve
    a layer by its name. One remarkable application of this feature is **neural style
    transfer**.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a basic image classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll close this chapter by implementing an image classifier on `Fashion-MNIST`,
    a popular alternative to `mnist`. This will help us consolidate the knowledge
    we've acquired from the previous recipes. If, at any point, you need more details
    on a particular step, please refer to the previous recipes.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I encourage you to complete the five previous recipes before tackling this
    one since our goal is to come full circle with the lessons we''ve learned throughout
    this chapter. Also, make sure you have `Pillow` and `pydot` on your system. You
    can install them using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we''ll use the `tensorflow_docs` package to plot the loss and accuracy
    curves of the model. You can install this library with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to complete this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that will load and prepare the dataset. It will normalize
    the data, one-hot encode the labels, take a portion of the training set for validation,
    and wrap the three data subsets into three separate `tf.data.Dataset` instances
    to increase performance using `from_tensor_slices()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Implement a function that will build a network similar to `BatchNormalization`,
    which we''ll use to make the network faster and most stable, and `Dropout` layers,
    which will help us combat overfitting, a situation where the network loses generalization
    power due to high variance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that takes a model''s training history, along with a metric
    of interest, to create a plot corresponding to the training and validation of
    the curves of such a metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Consume the training and validation datasets in batches of 256 images at a
    time. The `prefetch()` method spawns a background thread that populates a buffer
    of size `1024` with image batches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build and train the network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the training and validation loss and accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The first graph corresponds to the loss curve both on the training and validation
    sets:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.7 – Loss plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_01_007.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.7 – Loss plot
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The second plot shows the accuracy curve for the training and validation sets:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.8 – Accuracy plot'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_01_008.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.8 – Accuracy plot
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Visualize the model''s architecture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is a diagram of our model:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.9 – Model architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B14768_01_009.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 1.9 – Model architecture
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Save the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load and evaluate the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That completes the final recipe of this chapter. Let's review how it all works.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we used all the lessons learned in this chapter. We started
    by downloading `Fashion-MNIST` and used the `tf.data.Dataset` API to load its
    images so that we could feed them to our network, which we implemented using the
    declarative Functional high-level Keras API. After fitting our model to the data,
    we examined its performance by reviewing the loss and accuracy curves on the training
    and validation sets with the help of `matplotlib` and `tensorflow_docs`. To gain
    a better understanding of the network, we visualized its architecture with `plot_model()`
    and then saved it to disk, along with its weights, in the convenient HDF5 format.
    Finally, we loaded the model with `load_model()` to evaluate it on new, unseen
    data – that is, the test set – obtaining a respectable 91.3% accuracy rating.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For a deeper explanation of `Fashion-MNIST`, visit this site: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist).
    The GitHub repository for the TensorFlow docs is available here: [https://github.com/tensorflow/docs](https://github.com/tensorflow/docs).'
  prefs: []
  type: TYPE_NORMAL
