["```\ngit clone https://github.com/PacktPublishing/learn-tensorflow-enterprise.git\n```", "```\nmdl.fit(\n```", "```\n    train_dataset,\n```", "```\n    epochs=5, steps_per_epoch=steps_per_epoch,\n```", "```\n    validation_data=valid_dataset,\n```", "```\n    validation_steps=validation_steps)\n```", "```\nsaved_model_path = ''\n```", "```\ntf.saved_model.save(mdl, saved_model_path)\n```", "```\n-rw-r--r--  1 2405393 Oct 12 22:02 saved_model.pb\n```", "```\ndrwxr-xr-x@ 2      64 Oct 12 22:02 assets\n```", "```\ndrwxr-xr-x@ 4     128 Oct 12 22:02 variables\n```", "```\n    path_saved_model =  'flowerclassifier/001'\n    working_model = tf.saved_model.load(path_saved_model)\n    ```", "```\n    print(list(working_model.signatures.keys()))\n    ```", "```\n    ['serving_default']\n    ```", "```\n    infer = working_model.signatures['serving_default']\n    print(infer.structured_outputs)\n    ```", "```\n    {'custom_class': TensorSpec(shape=(None, 5), dtype=tf.float32, name='custom_class')}\n    ```", "```\n    {4: 'tulips', 3: 'dandelion', 1: 'sunflowers', 2: 'daisy', 0: 'roses'}\n    ```", "```\n    !saved_model_cli show --dir {path_saved_model} --all\n    ```", "```\n    signature_def['serving_default']:\n      The given SavedModel SignatureDef contains the following input(s):\n        inputs['input_4'] tensor_info:\n            dtype: DT_FLOAT\n            shape: (-1, 224, 224, 3)\n    ```", "```\n    jpg1 = 'raw_images2440874162_27a7030402_n.jpg'\n    img1_np = nv.imread(jpg1, resize=(224,224),normalize=True)\n    img1_np = nv.expand_dims(img1_np,axis=0)\n    ```", "```\n    prediction = infer(tf.constant(img1_np))\n    ```", "```\n    prediction['custom_class'].numpy()\n    ```", "```\n    array([[2.4262092e-06, 5.6151916e-06, 1.8000206e-05, 1.4342861e-05, 9.9995959e-01]], dtype=float32)\n    ```", "```\n    docker pull tensorflow/serving\n    ```", "```\n    docker run -d --name serv_base_img tensorflow/serving\n    ```", "```\n    flowerclassifier is the directory name two levels up from the saved_model.pb file. In between the two, you will notice that there is a directory, 001. This hierarchy is required by TFS, and so is the naming convention for the middle directory, which has to be an integer. It doesn't have to be 001, as long as it is all integers.The preceding command copies our model into the base image's `/model` directory.\n    ```", "```\n    docker commit --change \"ENV MODEL_NAME flowermodel\" serv_base_img flowermodel\n    ```", "```\n    flowermodel, which is deployed in a TFS container. Once we launch the TFS container, it brings our model up for serving.\n    ```", "```\n    8501, and map it to the Docker container's port, 8501. If your local port 8501 is not available, you may try another local port, say 8502. Then the command would take on -p 8502:8501. The source of our model is in the current directory (as indicated by the inline `$PWD` command) and followed by `flowerclassifier`. This folder also defines an environment variable, `MODEL_NAME`. `-t tensorflow/serving` indicates we want the container to be ready for `STDIN` from `tensorflow/serving`. \n    ```", "```\n    data = json.dumps({ \n        \"instances\": img1_np.tolist()\n    })\n    headers = {\"content-type\": \"application/json\"}\n    ```", "```\n    response = requests.post('http://localhost:8501/v1/models/flowerclassifier:predict', data=data, headers=headers)\n    ```", "```\n    response.json()\n    ```", "```\n    {'predictions': [[2.42621149e-06,\n       5.61519164e-06,\n       1.80002226e-05,\n       1.43428879e-05,\n       0.999959588]]}\n    ```"]