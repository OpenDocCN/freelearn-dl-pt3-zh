- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural Network Foundations with TF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learn the basics of TensorFlow, an open-source library developed
    by Google for machine learning and deep learning. In addition, we introduce the
    basics of neural networks and deep learning, two areas of machine learning that
    have had incredible Cambrian growth during the last few years. The idea behind
    this chapter is to provide all the tools needed to do basic but fully hands-on
    deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: What TensorFlow and Keras are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What the perceptron and multi-layer perceptron are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A real example: recognizing handwritten digits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code files for this chapter can be found at [https://packt.link/dltfchp1](https://packt.link/dltfchp1).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin!
  prefs: []
  type: TYPE_NORMAL
- en: What is TensorFlow (TF)?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is a powerful open-source software library developed by the Google
    Brain Team for deep neural networks, the topic covered in this book. It was first
    made available under the Apache 2.0 License in November 2015 and has since grown
    rapidly; as of May 2022, its GitHub repository ([https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow))
    has more than 129,000 commits, with roughly 3,100 contributors. This in itself
    provides a measure of the popularity of TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us first learn what exactly TensorFlow is and why it is so popular among
    deep neural network researchers and engineers. Google calls it “an open-source
    software library for machine intelligence,” but since there are so many other
    deep learning libraries like PyTorch ([https://pytorch.org/](https://pytorch.org/)),
    Caffe ([https://caffe.berkeleyvision.org/](https://caffe.berkeleyvision.org/)),
    and MXNet ([https://mxnet.apache.org/](https://mxnet.apache.org/)), what makes
    TensorFlow special? Most other deep learning libraries, like TensorFlow, have
    auto-differentiation (a useful mathematical tool used for optimization), many
    are open-source platforms. Most of them support the CPU/GPU option, have pretrained
    models, and support commonly used NN architectures like recurrent neural networks,
    convolutional neural networks, and deep belief networks. So, what else is there
    in TensorFlow? Let me list the top features:'
  prefs: []
  type: TYPE_NORMAL
- en: It works with all popular languages such as Python, C++, Java, R, and Go. TensorFlow
    provides stable Python and C++ APIs, as well as a non-guaranteed backward-compatible
    API for other languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras – a high-level neural network API that has been integrated with TensorFlow
    (in 2.0 Keras became the standard API for interacting with TensorFlow). This API
    specifies how software components should interact.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow allows model deployment and ease of use in production.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most importantly, TensorFlow has very good community support.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The number of stars on GitHub (see *Figure 1.1*) is a measure of popularity
    for all open-source projects. As of May 2022, TensorFlow, Keras, and PyTorch have
    165K, 55K, and 56K stars respectively, which makes TensorFlow the most popular
    framework for machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.1: Number of stars for various deep learning projects on GitHub'
  prefs: []
  type: TYPE_NORMAL
- en: What is Keras?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keras is a beautiful API for composing building blocks to create and train deep
    learning models. Keras can be integrated with multiple deep learning engines including
    Google TensorFlow, Microsoft CNTK, Amazon MXNet, and Theano. Starting with TensorFlow
    2.0, Keras, the API developed by François Chollet, has been adopted as the standard
    high-level API, largely simplifying coding and making programming more intuitive.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Artificial neural networks (briefly, “nets” or ANNs) represent a class of machine
    learning models loosely inspired by studies about the central nervous systems
    of mammals. Each ANN is made up of several interconnected “neurons,” organized
    in “layers.” Neurons in one layer pass messages to neurons in the next layer (they
    “fire,” in jargon terms) and this is how the network computes things. Initial
    studies were started in the early 1950s with the introduction of the “perceptron”
    [1], a two-layer network used for simple operations, and further expanded in the
    late 1960s with the introduction of the “back-propagation” algorithm used for
    efficient multi-layer network training (according to [2] and [3]). Some studies
    argue that these techniques have roots dating further back than normally cited
    [4].
  prefs: []
  type: TYPE_NORMAL
- en: 'Neural networks were a topic of intensive academic studies up until the 1980s,
    at which point other simpler approaches became more relevant. However, there has
    been a resurgence of interest since the mid 2000s, mainly thanks to three factors:
    a breakthrough fast learning algorithm proposed by G. Hinton [3], [5], and [6];
    the introduction of GPUs around 2011 for massive numeric computation; and the
    availability of big collections of data for training.'
  prefs: []
  type: TYPE_NORMAL
- en: These improvements opened the route for modern “deep learning,” a class of neural
    networks characterized by a significant number of layers of neurons that are able
    to learn rather sophisticated models, based on progressive levels of abstraction.
    People began referring to it as “deep” when it started utilizing 3–5 layers a
    few years ago. Now, networks with more than 200 layers are commonplace!
  prefs: []
  type: TYPE_NORMAL
- en: This learning via progressive abstraction resembles vision models that have
    evolved over millions of years within the human brain. Indeed, the human visual
    system is organized into different layers. First, our eyes are connected to an
    area of the brain named the visual cortex (V1), which is located in the lower
    posterior part of our brain. This area is common to many mammals and has the role
    of discriminating basic properties like small changes in visual orientation, spatial
    frequencies, and colors.
  prefs: []
  type: TYPE_NORMAL
- en: 'It has been estimated that V1 consists of about 140 million neurons, with tens
    of billions of connections between them. V1 is then connected to other areas,
    V2, V3, V4, V5, and V6 doing progressively more complex image processing and recognition
    of more sophisticated concepts, such as shapes, faces, animals, and many more.
    It has been estimated that there are ~16 billion human cortical neurons and about
    10–25% of the human cortex is devoted to vision [7]. Deep learning has taken some
    inspiration from this layer-based organization of the human visual system: early
    artificial neuron layers learn basic properties of images while deeper layers
    learn more sophisticated concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: This book covers several major aspects of neural networks by providing working
    nets in TensorFlow. So, let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: Perceptron
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The “perceptron” is a simple algorithm that, given an input vector *x* of *m*
    values (*x*[1], *x*[2],..., and *x*[m]), often called input features or simply
    features, outputs either a *1* (“yes”) or a *0* (“no”). Mathematically, we define
    a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where *w* is a vector of weights, ![](img/B18331_01_002.png) is the dot product
    ![](img/B18331_01_003.png), and *b* is the bias. If you remember elementary geometry,
    *wx* + *b* defines a boundary hyperplane that changes position according to the
    values assigned to *w* and *b*. Note that a hyperplane is a subspace whose dimension
    is one fewer than that of its ambient space. See (*Figure 1.2*) for an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: An example of a hyperplane'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, this is a very simple but effective algorithm! For example,
    given three input features, the amounts of red, green, and blue in a color, the
    perceptron could try to decide whether the color is “white” or not.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the perceptron cannot express a “*maybe*” answer. It can answer “yes”
    (1) or “no” (0) if we understand how to define *w* and *b*. This is the “training”
    process that will be discussed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Our first example of TensorFlow code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are three ways of creating a model in `tf.keras`: sequential API, functional
    API, and model subclassing. In this chapter, we will use the simplest one, `Sequential()`,
    while the other two are discussed in *Chapter 2*, *Regression and Classification*.
    A `Sequential()` model is a linear pipeline (a stack) of neural network layers.
    This code fragment defines a single layer with 10 artificial neurons that expect
    784 input variables (also known as features). Note that the net is “dense,” meaning
    that each neuron in a layer is connected to all neurons located in the previous
    layer, and to all the neurons in the following layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Each neuron can be initialized with specific weights via the `''kernel_initializer''`
    parameter. There are a few choices, the most common of which are listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: '`random_uniform`: Weights are initialized to uniformly random small values
    in the range (-0.05, 0.05).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_normal`: Weights are initialized according to a Gaussian distribution,
    with zero mean and a small standard deviation of 0.05\. For those of you who are
    not familiar with a Gaussian distribution, think about a symmetric “bell curve”
    shape.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`zero`: All weights are initialized to zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A full list is available online ([https://www.tensorflow.org/api_docs/python/tf/keras/initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Multi-layer perceptron: our first example of a network'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we present our first example of a network with multiple dense
    layers. Historically, “perceptron” was the name given to the model having one
    single linear layer, and as a consequence, if it has multiple layers, we call
    it a **Multi-Layer Perceptron** (**MLP**). Note that the input and the output
    layers are visible from the outside, while all the other layers in the middle
    are hidden – hence the name *hidden layers*. In this context, a single layer is
    simply a linear function and the MLP is therefore obtained by stacking multiple
    single layers one after the other:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/Image5021.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3: An example of multiple layer perceptron'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 1.3* each node in the first hidden layer receives an input and “fires”
    (0,1) according to the values of the associated linear function. Then the output
    of the first hidden layer is passed to the second layer where another linear function
    is applied, the results of which are passed to the final output layer consisting
    of one single neuron. It is interesting to note that this layered organization
    vaguely resembles the organization of the human vision system, as we discussed
    earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Problems in training the perceptron and solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s consider a single neuron; what are the best choices for the weight *w*
    and the bias *b*? Ideally, we would like to provide a set of training examples
    and let the computer adjust the weight and the bias in such a way that the errors
    produced in the output are minimized.
  prefs: []
  type: TYPE_NORMAL
- en: In order to make this a bit more concrete, let’s suppose that we have a set
    of images of cats and another separate set of images not containing cats. Suppose
    that each neuron receives input from the value of a single pixel in the images.
    While the computer processes those images, we would like our neuron to adjust
    its weights and its bias so that we have fewer and fewer images wrongly recognized.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach seems very intuitive, but it requires that a small change in
    the weights (or the bias) causes only a small change in the outputs. Think about
    it: if we have a big output jump, we cannot learn *progressively*. After all,
    kids learn little by little. Unfortunately, the perceptron does not show this
    “little-by-little” behavior. A perceptron is either a 0 or 1, and that’s a big
    jump that will not help in learning (see *Figure 1.4*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4: Example of a perceptron – either a 0 or 1'
  prefs: []
  type: TYPE_NORMAL
- en: We need something different, something smoother. We need a function that progressively
    changes from 0 to 1 with no discontinuity. Mathematically, this means that we
    need a continuous function that allows us to compute the derivative. You might
    remember that in mathematics the derivative is the amount by which a function
    is changing at a given point. For functions with input given by real numbers,
    the derivative is the slope of the tangent line at a point on a graph. Later in
    this chapter we will see why derivatives are important for learning, when we will
    talk about gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activation function: sigmoid'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The sigmoid function, defined as ![](img/B18331_01_004.png) and represented
    in the image below, has small output changes in the range (0, 1) when the input
    varies in the range ![](img/B18331_01_005.png). Mathematically the function is
    continuous. A typical sigmoid function is represented in *Figure 1.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.5: A sigmoid function with output in the range (0,1)'
  prefs: []
  type: TYPE_NORMAL
- en: A neuron can use the sigmoid for computing the nonlinear function ![](img/B18331_01_006.png).
    Note that if *z* = *wx* + *b* is very large and positive, then ![](img/B18331_01_007.png)
    so ![](img/B18331_01_008.png), while if *z* = *wx* + *b* is very large and negative,
    then ![](img/B18331_01_009.png) so ![](img/B18331_01_010.png). In other words,
    a neuron with sigmoid activation has a behavior similar to the perceptron, but
    the changes are gradual and output values such as 0.5539 or 0.123191 are perfectly
    legitimate. In this sense a sigmoid neuron can answer “maybe.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Activation function: tanh'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another useful activation function is tanh. It is defined as ![](img/B18331_01_011.png)
    whose shape is shown in *Figure 1.6*. Its outputs range from -1 to 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: Tanh activation function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Activation function: ReLU'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The “sigmoid” is not the only kind of smooth activation function used for neural
    networks. Recently, a very simple function named **ReLU** (**REctified Linear
    Unit**) became very popular because it helps address some problems of optimizations
    observed with sigmoids. We will discuss these problems in more detail when we
    talk about vanishing gradient in *Chapter 5*, *Recurrent Neural Networks*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A ReLU is simply defined as *f*(*x*) = *max*(0, *x*) and the nonlinear function
    is represented in *Figure 1.7*. As we can see, the function is zero for negative
    values and it grows linearly for positive values. The ReLU is also very simple
    to implement (generally three instructions are enough), while the sigmoid is a
    few orders of magnitude more. This helps to squeeze the neural networks onto an
    early GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.7: A ReLU function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Two additional activation functions: ELU and Leaky ReLU'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sigmoid and ReLU are not the only activation functions used for learning.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exponential Linear Unit** (**ELU**) is defined as ![](img/B18331_01_012.png)
    for ![](img/B18331_01_013.png) and its plot is represented in *Figure 1.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.8: An ELU function'
  prefs: []
  type: TYPE_NORMAL
- en: 'LeakyReLU is defined as ![](img/B18331_01_014.png) for ![](img/B18331_01_013.png)
    and its plot is represented in *Figure 1.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.9: A LeakyReLU function'
  prefs: []
  type: TYPE_NORMAL
- en: Both the functions allow small updates if *x* is negative, which might be useful
    in certain conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Activation functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sigmoid, Tanh, ELU, Leaky ReLU, and ReLU are generally called *activation functions*
    in neural network jargon. In the gradient descent section, we will see that those
    gradual changes typical of sigmoid and ReLU functions are the basic building blocks
    to developing a learning algorithm that adapts little by little, by progressively
    reducing the mistakes made by our nets. An example of using the activation function
    ![](img/B18331_01_016.png) with the (*x*[1], *x*[2],..., *x*[m]) input vector,
    the (*w*[1], *w*[2],..., *w*[m]) weight vector, the *b* bias, and the ![](img/B18331_01_017.png)
    summation is given in *Figure 1.10* (note that TensorFlow supports many activation
    functions, a full list of which is available online):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/Image5194.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.10: An example of an activation function applied after a linear function'
  prefs: []
  type: TYPE_NORMAL
- en: 'In short: what are neural networks after all?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In one sentence, machine learning models are a way to compute a function that
    maps some inputs to their corresponding outputs. The function is nothing more
    than a number of addition and multiplication operations. However, when combined
    with a nonlinear activation and stacked in multiple layers, these functions can
    learn almost anything [8]. We also need a meaningful metric capturing what we
    want to optimize (this being the so-called loss function that we will cover later
    in the book), enough data to learn from, and sufficient computational power.
  prefs: []
  type: TYPE_NORMAL
- en: Now, it might be beneficial to stop one moment and ask ourselves what “learning”
    really is? Well, we can say for our purposes that learning is essentially a process
    aimed at generalizing established observations [9] to predict future results.
    So, in short, this is exactly the goal we want to achieve with neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'A real example: recognizing handwritten digits'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section we will build a network that can recognize handwritten numbers.
    To achieve this goal, we use MNIST ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)),
    a database of handwritten digits made up of a training set of 60,000 examples,
    and a test set of 10,000 examples. The training examples are annotated by humans
    with the correct answer. For instance, if the handwritten digit is the number
    “3,” then 3 is simply the label associated with that example.
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, when a dataset with correct answers is available, we say
    that we can perform a form of *supervised learning*. In this case we can use training
    examples for improving our net. Testing examples also have the correct answer
    associated with each digit. In this case, however, the idea is to pretend that
    the label is unknown, let the network do the prediction, and then later on reconsider
    the label to evaluate how well our neural network has learned to recognize digits.
    Unsurprisingly, testing examples are just used to test the performance of our
    net.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each MNIST image is in grayscale and consists of 28 x 28 pixels. A subset of
    these images of numbers is shown in *Figure 1.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![mnist.png](img/B18331_01_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.11: A collection of MNIST images'
  prefs: []
  type: TYPE_NORMAL
- en: One hot-encoding (OHE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use OHE as a simple tool to encode information used inside neural networks.
    In many applications, it is convenient to transform categorical (non-numerical)
    features into numerical variables. For instance, the categorical feature *digit*
    with value *d* in [0–9] can be encoded into a binary vector with 10 positions,
    which has always a 0 value except the *d - th* position where a 1 is present.
    For example, the digit 3 can be encoded as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].
  prefs: []
  type: TYPE_NORMAL
- en: This type of representation is called **One-Hot-Encoding** (**OHE**) or sometimes
    simply one-hot, and is very common in data mining when the learning algorithm
    is specialized in dealing with numerical functions.
  prefs: []
  type: TYPE_NORMAL
- en: Defining a simple neural net in TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section we use TensorFlow to define a network that recognizes MNIST
    handwritten digits. We start with a very simple neural network and then progressively
    improve it.
  prefs: []
  type: TYPE_NORMAL
- en: Following Keras’ style, TensorFlow provides suitable libraries ([https://www.tensorflow.org/api_docs/python/tf/keras/datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets))
    for loading the dataset and splits it into training sets, `X_train`*,* used for
    fine-tuning our net, and test sets, `X_test`*,* used for assessing the performance.
    Later in the chapter, we are going to formally define what a training set, a validation
    set, and a test set are. For now, we just need to know that a training set is
    the dataset used to let our neural network learn from data examples. Data is converted
    into `float32` to use 32-bit precision when training a neural network and normalized
    to the range [0,1]. In addition, we load the true labels into `Y_train` and `Y_test`
    respectively, and perform one-hot encoding on them. Let’s see the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, do not focus too much on understanding why certain parameters have
    specific assigned values, as these choices will be discussed throughout the rest
    of the book. Intuitively, an epoch defines how long the training should last,
    `BATCH_SIZE` is the number of samples you feed in your network at a time, and
    the validation sample is the amount of data reserved for checking or proving the
    validity of the training process. The reason why we picked `EPOCHS = 200`, `BATCH_SIZE
    = 128`, `VALIDATION_SPLIT=0.2`, and `N_HIDDEN = 128` will be clearer later in
    this chapter when we will explore different values and discuss hyperparameters
    optimization. Let’s see our first code fragment of a neural network in TensorFlow.
    Reading is intuitive but you will find a detailed explanation in the upcoming
    pages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can see from the above code that the input layer has a neuron associated
    to each pixel in the image for a total of 28 x 28=784 neurons, one for each pixel
    in the MNIST images.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, the values associated with each pixel are normalized in the range
    [0,1] (which means that the intensity of each pixel is divided by 255, the maximum
    intensity value). The output can be one of ten classes, with one class for each
    digit.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final layer is a single neuron with the activation function `''``softmax''`,
    which is a generalization of the sigmoid function. As discussed earlier, a sigmoid
    function output is in the range (0, 1) when the input varies in the range ![](img/B18331_01_005.png).
    Similarly, a softmax “squashes” a K-dimensional vector of arbitrary real values
    into a K-dimensional vector of real values in the range (0, 1), so that they all
    add up to 1\. In our case, it aggregates ten answers provided by the previous
    layer with ten neurons. What we have just described is implemented with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Once we define the model, we have to compile it so that it can be executed by
    TensorFlow. There are a few choices to be made during compilation. Firstly, we
    need to select an *optimizer*, which is the specific algorithm used to update
    weights while we train our model.
  prefs: []
  type: TYPE_NORMAL
- en: A complete list of optimizers is at [https://www.tensorflow.org/api_docs/python/tf/keras/optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).
    Second, we need to select an *objective function*,which is used by the optimizer
    to navigate the space of weights (frequently objective functions are called either
    *loss functions* or *cost functions* and the process of optimization is defined
    as a process of loss *minimization*). Third, we need to evaluate the trained model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common choices for objective functions (a complete list of loss functions
    is at [https://www.tensorflow.org/api_docs/python/tf/keras/losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses))
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mse`, which defines the mean squared error between the predictions and the
    true values. Mathematically if *d* is a vector of predictions and *y* is the vector
    of *n* observed values, then ![](img/B18331_01_019.png). Note that this objective
    function is the average of all the mistakes made in each prediction. If a prediction
    is far off from the true value, then this distance is made more evident by the
    squaring operation. In addition, the square can add up the error regardless of
    whether a given value is positive or negative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_crossentropy`, which defines the binary logarithmic loss. Suppose that
    our model predicts *p* while the target is *c*, then the binary cross-entropy
    is defined as ![](img/B18331_01_020.png). Note that this objective function is
    suitable for binary labels prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`categorical_crossentropy`, which defines the multiclass logarithmic loss.
    Categorical cross-entropy compares the distribution of the predictions with the
    true distribution, with the probability of the true class set to 1 and 0 for the
    other classes. If the true class is *c* and the prediction is *y*, then the categorical
    cross-entropy is defined as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B18331_01_021.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: One way to think about multi-class logarithm loss is to consider the true class
    represented as a one-hot encoded vector, and the closer the model’s outputs are
    to that vector, the lower the loss. Note that this objective function is suitable
    for multi-class label predictions. It is also the default choice with softmax
    activation. A complete list of loss functions is at [https://www.tensorflow.org/api_docs/python/tf/keras/losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Some common choices for metrics (a complete list of metrics is at [https://www.tensorflow.org/api_docs/python/tf/keras/metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics))
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy, defined as the proportion of correct predictions with respect to the
    total number of predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision, defined as the proportion of correct positive predictions with respect
    to the number of correct and incorrect positive predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recall, defined as the proportion of correct positive predictions with respect
    to the actual number of positive predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A complete list of metrics is at [https://www.tensorflow.org/api_docs/python/tf/keras/metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics).
    Metrics are similar to objective functions, with the only difference being that
    they are not used for training a model, only for evaluating the model. However,
    it is important to understand the difference between metrics and objective functions.
    As discussed, the loss function is used to optimize your network. This is the
    function minimized by the selected optimizer. Instead, a metric is used to judge
    the performance of your network. This is only for you to run an evaluation, and
    it should be separated from the optimization process. On some occasions, it would
    be ideal to directly optimize for a specific metric. However, some metrics are
    not differentiable with respect to their inputs, which precludes them from being
    used directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'When compiling a model in TensorFlow, it is possible to select the optimizer,
    the loss function, and the metric used together with a given model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Stochastic Gradient Descent** (**SGD**) is a particular kind of optimization
    algorithm used to reduce the mistakes made by neural networks after each training
    epoch. We will review SGD and other optimization algorithms in the next chapters.
    Once the model is compiled, it can then be trained with the `fit()` method, which
    specifies a few parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`epochs` is the number of times the model is exposed to the training set. At
    each iteration the optimizer tries to adjust the weights so that the objective
    function is minimized.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size` is the number of training instances observed before the optimizer
    performs a weight update; there are usually many batches per epoch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training a model in TensorFlow is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note that we’ve reserved part of the training set for validation. The key idea
    is that we reserve a part of the training data for measuring the performance on
    the validation while training. This is a good practice to follow for any machine
    learning task, and one that we will adopt in all of our examples. Please note
    that we will return to validation later in this chapter when we will talk about
    overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Once the model is trained, we can evaluate it on the test set that contains
    new examples never seen by the model during the training phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, of course, the training set and the test set are rigorously separated.
    There is no point in evaluating a model on an example that was already used for
    training. In TF we can use the method `evaluate(X_test, Y_test)` to compute the
    `test_loss` and the `test_acc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! You have just defined your first neural network in TensorFlow.
    A few lines of code and your computer should be able to recognize handwritten
    numbers. Let’s run the code and see what the performance is.
  prefs: []
  type: TYPE_NORMAL
- en: Running a simple TensorFlow net and establishing a baseline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, let’s see what happens when we run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'First the net architecture is dumped and we can see the different types of
    layers used, their output shape, how many parameters (i.e., how many weights)
    they need to optimize, and how they are connected. Then, the network is trained
    on 48K samples, and 12K are reserved for validation. Once the neural model is
    built, it is then tested on 10K samples. For now we won’t go into the internals
    of how the training happens, but we can see that the program runs for 200 iterations
    and each time accuracy improves. When the training ends, we test our model on
    the test set and we achieve about 89.96% accuracy on the training dataset, 90.70%
    on validation, and 90.71% on test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This means that nearly 1 in 10 images are incorrectly classified. We can certainly
    do better than that.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the simple net in TensorFlow with hidden layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Okay, we have a baseline of accuracy of 89.96% on the training dataset, 90.70%
    on validation, and 90.71% on test. It is a good starting point, but we can improve
    it. Let’s see how.
  prefs: []
  type: TYPE_NORMAL
- en: 'An initial improvement is to add additional layers to our network because these
    additional neurons might intuitively help to learn more complex patterns in the
    training data. In other words, additional layers add more parameters, potentially
    allowing a model to memorize more complex patterns. So, after the input layer,
    we have a first dense layer with `N_HIDDEN` neurons and an activation function
    `''relu''`. This additional layer is considered *hidden* because it is not directly
    connected either with the input or with the output. After the first hidden layer
    we have a second hidden layer, again with `N_HIDDEN` neurons, followed by an output
    layer with ten neurons, each one of which will fire when the relative digit is
    recognized. The following code defines this new network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `to_categorical(Y_train, NB_CLASSES)` converts the array `Y_train`
    into a matrix with as many columns as there are classes. The number of rows stays
    the same. So, for instance, if we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'then:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s run the code and see what results we get with this multi-layer network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The previous output shows the initial steps of the run while the following output
    shows the conclusion. Not bad. As seen in the following output, by adding two
    hidden layers we reached 90.81% on the training dataset, 91.40% on validation,
    and 91.18% on test. This means that we have increased accuracy on the test dataset
    with respect to the previous network, and we have reduced the number of iterations
    from 200 to 50\. That’s good, but we want more.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want, you can play by yourself and see what happens if you add only
    one hidden layer instead of two or if you add more than two layers. I leave this
    experiment as an exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note that improvement stops (or it become almost imperceptible) after a certain
    number of epochs. In machine learning this is a phenomenon called *convergence*.
  prefs: []
  type: TYPE_NORMAL
- en: Further improving the simple net in TensorFlow with dropout
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now our baseline is 90.81% on training set, 91.40% on validation, and 91.18%
    on test. A second improvement is very simple. We decide to randomly drop – with
    the `DROPOUT` probability – some of the values propagated inside our internal
    dense network of hidden layers during training. In machine learning this is a
    well-known form of regularization. Surprisingly enough, this idea of randomly
    dropping a few values can improve our performance. The idea behind this improvement
    is that random dropouts *force* the network to learn redundant patterns that are
    useful for better generalization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s run the code for 200 iterations as before and we see that this net achieves
    an accuracy of 91.70% on training, 94.42% on validation, and 94.15% on testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note that it has been frequently observed that networks with random dropouts
    in internal hidden layers can “generalize” better on unseen examples contained
    in test sets. Intuitively we can consider this phenomenon as each neuron becoming
    more capable because it knows it cannot depend on its neighbors. Also, it forces
    information to be stored in a redundant way. During testing there is no dropout,
    so we are now using all our highly tuned neurons. In short, it is generally a
    good approach to test how a net performs when some dropout function is adopted.
  prefs: []
  type: TYPE_NORMAL
- en: Besides that, note that training accuracy should still be above test accuracy;
    otherwise, we might be not training for long enough. This is the case in our example
    and therefore we should increase the number of epochs. However, before performing
    this attempt we need to introduce a few other concepts that allow the training
    to converge faster. Let’s talk about optimizers.
  prefs: []
  type: TYPE_NORMAL
- en: Testing different optimizers in TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have defined and used a network, it is useful to start developing
    some intuition about how networks are trained, using an analogy. Let us focus
    on one popular training technique known as **gradient descent** (**GD**). Imagine
    a generic cost function *C*(*w*) in one single variable *w* like in *Figure 1.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.12: An example of GD optimization'
  prefs: []
  type: TYPE_NORMAL
- en: GD can be seen as a hiker who needs to navigate down a steep slope and aims
    to enter a ditch. The slope represents the function *C* while the ditch represents
    the minimum *C*[min]. The hiker has a starting point *w*[0]. The hiker moves little
    by little; imagine that there is almost zero visibility, so the hiker cannot see
    where to go automatically, and they proceed in a zigzag. At each step *r*, the
    gradient is the direction of maximum increase.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematically this direction is the value of the partial derivative ![](img/B18331_01_022.png)
    evaluated at point *w*[r], reached at step *r*. Therefore, by taking the opposite
    direction ![](img/B18331_01_023.png) the hiker can move toward the ditch.
  prefs: []
  type: TYPE_NORMAL
- en: At each step the hiker can decide how big a stride to take before the next stop.
    This is the so-called “learning rate” ![](img/B18331_01_024.png) in GD jargon.
    Note that if ![](img/B18331_01_025.png) is too small, then the hiker will move
    slowly. However, if ![](img/B18331_01_025.png) is too high, then the hiker will
    possibly miss the ditch by stepping over it.
  prefs: []
  type: TYPE_NORMAL
- en: Now you should remember that a sigmoid is a continuous function and it is possible
    to compute the derivative. It can be proven that the sigmoid ![](img/B18331_01_027.png)
    has the derivative ![](img/B18331_01_028.png).
  prefs: []
  type: TYPE_NORMAL
- en: ReLU is not differentiable at 0\. We can however extend the first derivative
    at 0 to a function over the whole domain by defining it to be either a 0 or 1\.
  prefs: []
  type: TYPE_NORMAL
- en: The piecewise derivative of ReLU ![](img/B18331_01_029.png) is ![](img/B18331_01_030.png).
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the derivative, it is possible to optimize the nets with a GD technique.
    TensorFlow computes the derivative on our behalf so we don’t need to worry about
    implementing or computing it.
  prefs: []
  type: TYPE_NORMAL
- en: A neural network is essentially a composition of multiple derivable functions
    with thousands and sometimes millions of parameters. Each network layer computes
    a function, the error of which should be minimized in order to improve the accuracy
    observed during the learning phase. When we discuss backpropagation, we will discover
    that the minimization game is a bit more complex than our toy example. However,
    it is still based on the same intuition of descending a slope to reach a ditch.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow implements a fast variant of GD known as **Stochastic Gradient Descent**
    (**SGD**) and many more advanced optimization techniques such as RMSProp and Adam.
    RMSProp and Adam include the concept of momentum (a velocity component) in addition
    to the acceleration component that SGD has. This allows faster convergence at
    the cost of more computation. Think about a hiker who starts to move in one direction
    and then decides to change direction but remembers previous choices. It can be
    proven that momentum helps accelerate SGD in the relevant direction and dampens
    oscillations [10].
  prefs: []
  type: TYPE_NORMAL
- en: 'SGD was our default choice so far. So now let’s try the other two. It is very
    simple; we just need to change a few lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: That’s it. Let’s test it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, RMSProp is faster than SDG since we are able to achieve in
    only 10 epochs an accuracy of 97.43% on the training dataset, 97.62% on validation,
    and 97.64% on test. That’s a significant improvement on SDG. Now that we have
    a very fast optimizer, let us try to increase significantly the number of epochs
    up to 250, and we get 98.99% accuracy on the training dataset, 97.66% on validation,
    and 97.77% on test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'It is useful to observe how accuracy increases on training and test sets when
    the number of epochs increases (see *Figure 1.13*). As you can see, these two
    curves touch at about 15 epochs and therefore there is no need to train further
    after that point:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.13: An example of accuracy and loss with RMSProp'
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, let’s try the other optimizer, `Adam()`. It’s pretty simple to implement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As we see, `Adam()` is slightly better. With Adam we achieve 98.94% accuracy
    on the training dataset, 97.89% on validation, and 97.82% on test with 50 iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'One more time, let’s plot how accuracy increases on training and test sets
    when the number of epochs increases (see *Figure 1.14*). You’ll notice that by
    choosing Adam as an optimizer we are able to stop after just about 12 epochs or
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.14: An example of accuracy and loss with Adam'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that this is our fifth variant and remember that our initial baseline
    was at 90.71% on the test dataset. So far, we’ve made progressive improvements.
    However, gains are now more and more difficult to obtain. Note that we are optimizing
    with a dropout of 30%. For the sake of completeness, it could be useful to report
    the accuracy of the test dataset for different dropout values (see *Figure 1.15*).
    In this example, we selected Adam as the optimizer. Note that the choice of optimizer
    isn’t a rule of thumb and we can get different performance depending on the problem-optimizer
    combination:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.15: An example of changes in accuracy for different dropout values'
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the number of epochs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s make another attempt and increase the number of epochs used for training
    from 20 to 200\. Unfortunately, this choice increases our computation time tenfold,
    yet gives us no gain. The experiment is unsuccessful, but we have learned that
    if we spend more time learning, we will not necessarily improve the result. Learning
    is more about adopting smart techniques and not necessarily about the time spent
    in computations. Let’s keep track of our five variants in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.16: Accuracy for different models and optimizers'
  prefs: []
  type: TYPE_NORMAL
- en: Controlling the optimizer learning rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is another approach we can take that involves changing the learning parameter
    for our optimizer. As you can see in *Figure 1.17*, the best value reached by
    our three experiments [lr=0.1, lr=0.01, and lr=0.001] is 0.1, which is the default
    learning rate for the optimizer. Good! Adam works well out of the box:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.17: Accuracy for different learning rates'
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the number of internal hidden neurons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Yet another approach involves changing the number of internal hidden neurons.
    We report the results of the experiments with an increasing number of hidden neurons.
    We see that by increasing the complexity of the model, the runtime increases significantly
    because there are more and more parameters to optimize. However, the gains that
    we are getting by increasing the size of the network decrease more and more as
    the network grows (see *Figure 1.18*, *Figure 1.19*, and *Figure 1.20*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.18: Number of parameters for the increasing values of internal hidden
    neurons'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the time needed increases as the size of the internal network
    increases (see *Figure 1.19*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.19: Seconds of computation time for the increasing values of internal
    hidden neurons'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that increasing the number of hidden neurons after a certain value can
    reduce the accuracy because the network might not be able to generalize well (as
    shown in *Figure 1.20*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.20: Test accuracy for the increasing values of internal hidden neurons'
  prefs: []
  type: TYPE_NORMAL
- en: Increasing the size of batch computation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GD tries to minimize the cost function on all the examples provided in the
    training sets and, at the same time, for all the features provided as input. SGD
    is a much less expensive variant that considers only `BATCH_SIZE` examples. So,
    let us see how it behaves when we change this parameter. As you can see, the best
    accuracy value is reached for a `BATCH_SIZE=64` in our four experiments (see *Figure
    1.21*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart](img/B18331_01_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.21: Test accuracy for different batch values'
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing experiments run to recognizing handwritten digits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, let’s summarize: with five different variants, we were able to improve
    our performance from 90.71% to 97.82%. First, we defined a simple layer network
    in TensorFlow. Then, we improved the performance by adding some hidden layers.
    After that, we improved the performance on the test set by adding a few random
    dropouts in our network, and then by experimenting with different types of optimizers:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Accuracy** |'
  prefs: []
  type: TYPE_TB
- en: '| **Model** | **Training** | **Validation** | **Test** |'
  prefs: []
  type: TYPE_TB
- en: '| **Simple** | 89.96% | 90.70% | 90.71% |'
  prefs: []
  type: TYPE_TB
- en: '| **Two hidden layers (128)** | 90.81% | 91.40% | 91.18% |'
  prefs: []
  type: TYPE_TB
- en: '| **Dropout (30%)** | 91.70% | 94.42% | 94.15% (200 epochs) |'
  prefs: []
  type: TYPE_TB
- en: '| **RMSProp** | 97.43% | 97.62% | 97.64% (10 epochs) |'
  prefs: []
  type: TYPE_TB
- en: '| **Adam** | 98.94% | 97.89% | 97.82% (10 epochs) |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1.1: Summary of experiments with various levels of accuracy'
  prefs: []
  type: TYPE_NORMAL
- en: However, the next two experiments (not shown in *Table 1.1*) were not providing
    significant improvements. Increasing the number of internal neurons creates more
    complex models and requires more expensive computations, but it provides only
    marginal gains. We have the same experience if we increase the number of training
    epochs. A final experiment consisted of changing the `BATCH_SIZE` for our optimizer.
    This also provided marginal results.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section we will review a few best practices for improving the training
    phase. In particular, regularization and batch normalization will be discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Adopting regularization to avoid overfitting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Intuitively, a good machine learning model should achieve low error on training
    data. Mathematically this is equivalent to minimizing the loss function on the
    training data given the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_031.png)'
  prefs: []
  type: TYPE_IMG
- en: However, this might not be enough. A model can become excessively complex in
    order to capture all the relations inherently expressed by the training data.
    This increase in complexity might have two negative consequences. First, a complex
    model might require a significant amount of time to be executed. Second, a complex
    model might achieve very good performance on training data but perform quite badly
    on validation data. This is because the model is able to contrive relationships
    between many parameters in the specific training context, but these relationships
    in fact do not exist within a more generalized context. Causing a model to lose
    its ability to generalize in this manner is termed “overfitting. “ Again, learning
    is more about generalization than memorization. Another phenomenon to consider
    is “underfitting.”
  prefs: []
  type: TYPE_NORMAL
- en: 'This happens when a data model cannot capture the relationship between the
    input and output variables accurately, with a high error rate on both the training
    set and new unseen data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.22: Loss function and overfitting'
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, if during the training we see that the loss increases on
    validation, after an initial decrease, then we have a problem of model complexity
    that overfits the training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to solve the overfitting problem, we need a way to capture the complexity
    of a model, i.e. how complex a model can be. What could the solution be? Well,
    a model is nothing more than a vector of weights. Each weight affects the output,
    except for those which are zero, or very close to it. Therefore, the complexity
    of a model can be conveniently represented as the number of non-zero weights.
    In other words, if we have two models M1 and M2 achieving pretty much the same
    performance in terms of a loss function, then we should choose the simplest model,
    the one which has the minimum number of non-zero weights. We can use a hyperparameter
    ![](img/B18331_01_032.png) for controlling the importance of having a simple model,
    as in this formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_033.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are three different types of regularization used in machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: L1 regularization (also known as LASSO). The complexity of the model is expressed
    as the sum of the absolute values of the weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L2 regularization (also known as Ridge). The complexity of the model is expressed
    as the sum of the squares of the weights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ElasticNet regularization. The complexity of the model is captured by a combination
    of the two techniques above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that playing with regularization can be a good way to increase the generalization
    performance of a network, particularly when there is an evident situation of overfitting.
    This set of experiments is left as an exercise to the interested reader.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also note that TensorFlow supports L1, L2, and ElasticNet regularization. A
    complete list of regularizers is at [https://www.tensorflow.org/api_docs/python/tf/keras/regularizers](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers).
    Adding regularization is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Understanding batch normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Batch normalization is another form of regularization and one of the most effective
    improvements proposed during the last few years. Batch normalization enables us
    to accelerate training, in some cases by halving the training epochs, and it offers
    some regularization. During training, the weights in early layers naturally change
    and therefore the inputs of later layers can significantly change. In other words,
    each layer must continuously re-adjust its weights to the different distribution
    for every batch. This may slow down the model’s training greatly. The key idea
    is to make layer inputs more similar in distribution, batch after batch and epoch
    after epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue is that the sigmoid activation function works very well close
    to zero but tends to “get stuck” when values get sufficiently far away from zero.
    If, occasionally, neuron outputs fluctuate far away from the sigmoid zero, then
    said neuron becomes unable to update its own weights.
  prefs: []
  type: TYPE_NORMAL
- en: The other key idea is therefore to transform the layer outputs into a Gaussian
    distribution unit close to zero. This way, layers will have significantly less
    variation from batch to batch. Mathematically, the formula is very simple. The
    activation input x is centered around zero by subtracting the batch mean ![](img/B18331_01_034.png)
    from it. Then the result is divided by ![](img/B18331_01_035.png), the sum of
    batch variance ![](img/B18331_01_016.png), and a small number ![](img/B18331_01_037.png)
    to prevent division by zero. Then, we use a linear transformation ![](img/B18331_01_038.png)
    to make sure that the normalizing effect is applied during training.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, ![](img/B18331_01_039.png) and ![](img/B18331_01_040.png) are parameters
    that get optimized during the training phase in a way similar to any other layer.
    Batch normalization has been proven to be a very effective way to increase both
    the speed of training and accuracy, because it helps to prevent activations becoming
    either too small and vanishing or too big and exploding.
  prefs: []
  type: TYPE_NORMAL
- en: 'Playing with Google Colab: CPUs, GPUs, and TPUs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google offers a truly intuitive tool for training neural networks and for playing
    with TensorFlow at no cost. You can find an actual Colab, which can be freely
    accessed, at [https://colab.research.google.com/](https://colab.research.google.com/)
    and if you are familiar with Jupyter notebooks you will find a very familiar web-based
    environment here. **Colab** stands for **Colaboratory** and is a Google research
    project created to help disseminate machine learning education and research. We
    will see the difference between CPUs, GPUs, and TPUs in *Chapter 15*, *Tensor
    Processing Unit*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, it’s important to know that CPUs are generic processing units, while
    GPUs and TPUs are accelerators, specific processing units suitable for deep learning.
    Let’s see how it works, starting with the screenshot shown in *Figure 1.23*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.23: An example of notebooks in Colab'
  prefs: []
  type: TYPE_NORMAL
- en: By accessing Colab, we can either check a listing of notebooks generated in
    the past or we can create a new notebook. Different versions of Python are supported.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we create a new notebook, we can also select if we want to run it on CPUs,
    GPUs, or in Google’s TPUs as shown in *Figure 1.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.24: Selecting the desired hardware accelerator (None, GPUs, or TPUs)
    – the first step'
  prefs: []
  type: TYPE_NORMAL
- en: By accessing the **Notebook settings** option contained in the **Edit** menu
    (see *Figure 1.24* and *Figure 1.25*), we can select the desired hardware accelerator
    (**None**, **GPUs**, or **TPUs**). Google will allocate the resources at no cost,
    although they can be withdrawn at any time, for example during periods of a particularly
    heavy load. In my experience, this is a very rare event, and you can access Colab
    pretty much any time. However, be polite and do not do something like start mining
    bitcoins at no cost – you will almost certainly get evicted!
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.25: Selecting the desired hardware accelerator (None, GPUs, or TPUs)
    – the second step'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to insert your code (see *Figure 1.26*) in the appropriate
    Colab notebook cells and *voila!* You are good to go. Execute the code and happy
    deep learning without the hassle of buying very expensive hardware to start your
    experiments! *Figure 1.26* contains an example of code in a Google notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.26: An example of code in a notebook'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What is the code we used to test Colab? It is an example of sentiment analysis
    developed on top of the IMDB dataset. The IMDB dataset contains the text of 50,000
    movie reviews from the Internet Movie Database. Each review is either positive
    or negative (for example, thumbs up or thumbs down). The dataset is split into
    25,000 reviews for training and 25,000 reviews for testing. Our goal is to build
    a classifier that can predict the binary judgment given the text. We can easily
    load IMDB via `tf.keras` and the sequences of words in the reviews have been converted
    to sequences of integers, where each integer represents a specific word in a dictionary.
    We also have a convenient way of padding sentences to `max_len`, so that we can
    use all sentences, whether short or long, as inputs to a neural network with an
    input vector of fixed size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s build a model. We are going to use a few layers that will be explained
    in detail in *Chapter 4*, *Word Embeddings*. For now, let’s assume that the `embedding()`
    layer will map the sparse space of words contained in the reviews into a denser
    space. This will make computation easier. In addition, we will use a `GlobalMaxPooling1D()`
    layer, which takes the maximum value of either feature vector from each of the
    `n_words` features. In addition, we have two `Dense()` layers. The last one is
    made up of a single neuron with a sigmoid activation function for making the final
    binary estimation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to train our model and this piece of code is very similar to what
    we have done with MNIST. Let’s see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see the network and then run a few iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the following output, we reach accuracy of 85%, which is not bad
    at all for a simple network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The next section is devoted to tuning hyperparameters and AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning and AutoML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The experiments defined above give some opportunities for fine-tuning a net.
    However, what works for this example will not necessarily work for other examples.
    For a given neural network, there are indeed multiple parameters that can be optimized
    (such as the number of hidden neurons, batch size, number of epochs, and many
    more according to the complexity of the net itself). These parameters are called
    “hyperparameters” to distinguish them from the parameters of the network itself,
    i.e. the values of the weights and biases.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning is the process of finding the optimal combination of those
    hyperparameters that minimize cost functions. The key idea is that if we have
    *n* hyperparameters, then we can imagine that they define a space with *n* dimensions,
    and the goal is to find the point in this space that corresponds to an optimal
    value for the cost function. One way to achieve this goal is to create a grid
    in this space and systematically check the value assumed by the cost function
    for each grid vertex. In other words, the hyperparameters are divided into buckets
    and different combinations of values are checked via a brute-force approach.
  prefs: []
  type: TYPE_NORMAL
- en: If you think that this process of fine-tuning the hyperparameters is manual
    and expensive then you are absolutely right! However, during the last few years,
    we have seen significant results in AutoML, a set of research techniques aimed
    at both automatically tuning hyperparameters and searching automatically for optimal
    network architecture. We will discuss more about this in *Chapter 13*, *An Introduction
    to AutoML*.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting output
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once a net is trained, it can of course be used for making predictions. In
    TensorFlow, this is very simple. We can use this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: For a given input, several types of output can be computed including a method
    `model.evaluate()` used to compute the loss values, a method `model.predict_classes()`
    used to compute category outputs, and a method `model.predict_proba()` used to
    compute class probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: A practical overview of backpropagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multi-layer perceptrons learn from training data through a process called backpropagation.
    In this paragraph we will give an intuition while more details are in *Chapter
    14*, *The Math Behind Deep Learning*. The process can be described as a way of
    progressively correcting mistakes as soon as they are detected. Let’s see how
    this works.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that each neural network layer has an associated set of weights that
    determine the output values for a given set of inputs. Additionally, remember
    that a neural network can have multiple hidden layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the beginning, all the weights have some random assignment. Then the neural
    network is activated for each input in the training set: values are propagated
    *forward* from the input stage through the hidden stages to the output stage where
    a prediction is made.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we keep *Figure 1.27* below simple by only representing a few values
    with green dotted lines but in reality, all the values are propagated forward
    through the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.27: Forward step in backpropagation'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we know the true observed value in the training set, it is possible to
    calculate the error made in the prediction. The key intuition for backtracking
    is to propagate the error back (see *Figure 1.28*), using an appropriate optimizer
    algorithm such as a GD to adjust the neural network weights with the goal of reducing
    the error (again for the sake of simplicity only a few error values are represented
    here):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.28: Backward step in backpropagation'
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of forward propagation from input to output and backward propagation
    of errors is repeated several times until the error gets below a predefined threshold.
    The whole process is represented in *Figure 1.29*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18331_01_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.29: Forward propagation and backward propagation'
  prefs: []
  type: TYPE_NORMAL
- en: The features represent the input, and the labels are used here to drive the
    learning process. The model is updated in such a way that the loss function is
    progressively minimized. In a neural network, what really matters is not the output
    of a single neuron but the collective weights adjusted in each layer. Therefore,
    the network progressively adjusts its internal weights in such a way that the
    prediction increases the number of correctly forecasted labels. Of course, using
    the right set of features and having quality labeled data is fundamental to minimizing
    the bias during the learning process.
  prefs: []
  type: TYPE_NORMAL
- en: What have we learned so far?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned the basics of neural networks. More specifically,
    we have learned what a perceptron is and what a multi-layer perceptron is, how
    to define neural networks in TensorFlow, how to progressively improve metrics
    once a good baseline is established, and how to fine-tune the hyperparameter space.
    In addition to that, we also have a good idea of useful activation functions (sigmoid
    and ReLU) available, and how to train a network with backpropagation algorithms
    based on either GD, SGD, or more sophisticated approaches, such as Adam and RMSProp.
  prefs: []
  type: TYPE_NORMAL
- en: Toward a deep learning approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While playing with handwritten digit recognition, we came to the conclusion
    that the closer we get to an accuracy of 99%, the more difficult it is to improve.
    If we want more improvement, we definitely need a new idea. What are we missing?
    Think about it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fundamental intuition is that in our examples so far, we are not making
    use of the local spatial structure of images, which means we will use the fact
    that an image can be described as a matrix with data locality. In particular,
    this piece of code transforms the bitmap representing each written digit into
    a flat vector where the local spatial structure (the fact that some pixels are
    closer to each other) is gone:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: However, this is not how our brain works. Remember that our vision is based
    on multiple cortex levels, each one recognizing more and more structured information
    while still preserving the locality. First, we see single pixels, then from that,
    we recognize simple geometric forms and then more and more sophisticated elements
    such as objects, faces, human bodies, animals, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Chapter 3*, we will see that a particular type of deep learning network
    known as the **Convolutional Neural Network** (**CNN**) has been developed by
    taking into account both the idea of preserving the local spatial structure in
    images (and more generally in any type of information that has a spatial structure)
    and the idea of learning via progressive levels of abstraction: with one layer
    you can only learn simple patterns; with more than one layer you can learn multiple
    patterns. Before discussing CNN, we need to discuss some aspects of TensorFlow
    architecture and have a practical introduction to a few additional machine learning
    concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we learned what TensorFlow and Keras are and introduced neural
    networks with the perceptron and the multi-layer perceptron. Then, we saw a real
    example of recognizing handwritten digits with several optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is devoted to regression and classification.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rosenblatt, F. (1958). *The perceptron: a probabilistic model for information
    storage and organization in the brain*.Psychol. Rev, vol. 65, pp. 386–408.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Werbos, P. J. (1990). *Backpropagation through time: what it does and how to
    do it*. Proc. IEEE, vol. 78, pp. 1550–1560.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hinton, G. E., Osindero, S., and Teh, Y. W. (2006). *A fast learning algorithm
    for deep belief nets*. Neural Comput, vol. 18, pp. 1527–1554.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Schmidhuber, J. (2015). *Deep learning in neural networks: an overview*.Neural
    Networks : Off. J. Int. Neural Netw. Soc., vol. 61, pp. 85–117.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Leven, S. (1996). *The roots of backpropagation: From ordered derivatives to
    neural networks and political forecasting*.Neural Networks, vol. 9.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). *Learning representations
    by back-propagating errors*.Nature, vol. 323.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Herculano-Houzel, S. (2009). *The human brain in numbers: a linearly scaled-up
    primate brain*. Front. Hum. Neurosci., vol. 3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hornick, K., Stinchcombe, M., and White, H. (1989). *Multilayer feedforward
    networks are universal approximators*. Neural Networks Volume 2, Issue 5\. Pages
    359–366.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vapnik, V. N. (2013). *The nature of statistical learning theory*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sutskever, I., Martens, J., Dahl, G., Hinton, G., (2013). *On the importance
    of initialization and momentum in deep learning*. 30th International Conference
    on Machine Learning, ICML.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 2000 members at: [https://packt.link/keras](https://packt.link/keras)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1831217224278819687.png)'
  prefs: []
  type: TYPE_IMG
