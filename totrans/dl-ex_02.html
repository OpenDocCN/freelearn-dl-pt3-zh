<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Data Modeling in Action - The Titanic Example</h1>
                </header>
            
            <article>
                
<p class="calibre2">Linear models are the basic learning algorithms in the field of data science. Understanding how a linear model works is crucial in your journey of learning data science because it's the basic building block for most of the sophisticated learning algorithms out there, including neural networks.</p>
<p class="calibre2">In this chapter, we are going to dive into a famous problem in the field of data science, which is the Titanic example. The purpose of this example is to introduce linear models for classification and see a full machine learning system pipeline, starting from data handling and exploration up to model evaluation. We are going to cover the following topics in this chapter:</p>
<ul class="calibre7">
<li class="calibre8">Linear models for regression</li>
<li class="calibre8">Linear models for classification</li>
<li class="calibre8">Titanic example—model building and training</li>
<li class="calibre8">Different types of errors</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linear models for regression</h1>
                </header>
            
            <article>
                
<p class="calibre2">Linear regression <span class="calibre10">models are </span>the most basic type of regression models and are widely used in predictive data analysis. The overall idea of regression models is to examine two things:</p>
<ol class="calibre16">
<li class="calibre8">Does a set of explanatory features / input variables do a good job at predicting an output variable? Is the model using features that account for the variability in changes to the dependent variable (output variable)?</li>
<li class="calibre8">Which features in particular are significant ones of the dependent variable? And in what way do they impact the dependent variable (indicated by the magnitude and sign of the parameters)? These regression parameters are used to explain the relationship between one output variable (dependent variable) and one or more input features (independent variables).</li>
</ol>
<p class="calibre2">A regression equation will formulate the impact of the input variables (independent variables) on the output variable (dependent variable). The simplest form of this equation, with one input variable and one output variable, is defined by this formula <em class="calibre19">y = c + b*x.</em> Here, <em class="calibre19">y </em>= estimated dependent score, <em class="calibre19">c </em>= constant, <em class="calibre19">b </em>= regression parameter/coefficients, and <em class="calibre19">x </em>= input (independent) variable.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Motivation</h1>
                </header>
            
            <article>
                
<p class="calibre2">Linear regression models are the building blocks of many learning algorithms, but this is not the only reason behind their popularity. The following are the key factors behind their popularity:</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">Widely used</strong>: Linear regression is the oldest regression technique and it's widely used in many applications, such as forecasting and financial analysis.</li>
<li class="calibre8"><strong class="calibre1">Runs fast</strong>: Linear regression algorithms are very simple and don't include mathematical computations which are too expensive.</li>
<li class="calibre8"><strong class="calibre1">Easy to use</strong> (<strong class="calibre1">not a lot of tuning required</strong>): Linear regression is very easy to use, and mostly it's the first learning method to learn about in the machine learning or data science class as you don't have too many hyperparameters to tune in order to get better performance.</li>
<li class="calibre8"><strong class="calibre1">Highly interpretable</strong>: Because of its simplicity and ease of inspecting the contribution of each predictor-coefficient pair, linear regression is highly interpretable; you can easily understand the model behavior and interpret the model output for non-technical guys. If a coefficient is zero, the associated predictor variable contributes nothing. If a coefficient is not zero, the contribution due to the specific predictor variable can easily be ascertained.</li>
<li class="calibre8"><strong class="calibre1">Basis for many other methods</strong>: Linear regression is considered the underlying foundation for many learning methods, such <span>as </span>neural networks and its growing part, deep learning.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Advertising – a financial example</h1>
                </header>
            
            <article>
                
<p class="calibre2">In order to better understand linear regression models, we will go through an example advertisement. We will try to predict the sales of some companies given some factors related to the amount of money spent by these companies on advertising in TV, radio, and newspapers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dependencies</h1>
                </header>
            
            <article>
                
<p class="calibre2">To model our advertising data samples using linear regression, we will be using the Stats models library to get nice characteristics for linear models, but later on, we will be using scikit-learn, which has very useful functionality for data science in general.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing data with pandas</h1>
                </header>
            
            <article>
                
<p class="calibre2">There are lots of libraries out there in Python that you can use to read, transform, or write data. One of these libraries is pandas (<a href="http://pandas.pydata.org/" class="calibre11">http://pandas.pydata.org/</a>). Pandas is an open source library and has great functionality and tools for data analysis as well as very easy-to-use data structures.</p>
<p class="calibre2">You can easily get pandas in many different ways. The best way to get pandas is to install it via <kbd class="calibre12">conda</kbd> (<a href="http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda" class="calibre11">http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda</a>).</p>
<div class="packtquote">“conda is an open source package management system and environment management system for installing multiple versions of software packages and their dependencies and switching easily between them. It works on Linux, OS X and Windows, and was created for Python programs but can package and distribute any software.” – conda website.</div>
<div class="packtquote">You can easily get conda by installing Anaconda, which is an open data science platform.</div>
<p class="calibre2">So, let's have a look and see how to use pandas in order to read advertising data samples. First off, we need to import <kbd class="calibre12">pandas</kbd>:</p>
<pre class="calibre21">import pandas as pd</pre>
<p class="calibre2">Next up, we can use the <kbd class="calibre12">pandas.read_csv</kbd> method in order to load our data into an easy-to-use pandas data structure called <strong class="calibre13">DataFrame</strong>. For more information about <kbd class="calibre12">pandas.read_csv</kbd> and its parameters, you can refer to the pandas documentation for this method (<a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" class="calibre11">https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html</a>):</p>
<pre class="calibre21"># read advertising data samples into a DataFrame</pre>
<pre class="calibre21">advertising_data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)</pre>
<p class="calibre2">The first argument passed to the <kbd class="calibre12">pandas.read_csv</kbd> method is a string value representing the file path. The string can be a URL that includes <kbd class="calibre12">http</kbd>, <kbd class="calibre12">ftp</kbd>, <kbd class="calibre12">s3</kbd>, and <kbd class="calibre12">file</kbd>. The second argument passed is the index of the column that will be used as a label/name for the data rows.</p>
<p class="calibre2">Now, we have the data DataFrame, which contains the advertising data provided in the URL and each row is labeled by the first column. As mentioned earlier, pandas provides easy-to-use data structures that you can use as containers for your data. These data structures have some methods associated with them and you will be using these methods to transform <span class="calibre10">and/</span>or operate on your data.</p>
<p class="calibre2">Now, let's have a look at the first five rows of the advertising data:</p>
<pre class="calibre21"># DataFrame.head method shows the first n rows of the data where the   <br class="title-page-name"/># default value of n is 5, DataFrame.head(n=5)<br class="title-page-name"/>advertising_data.head()</pre>
<p class="calibre2">Output:</p>
<div class="title-page-name">
<table class="calibre35">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2"/>
<p class="calibre2"> </p>
</td>
<td class="calibre38">
<p class="calibre2"><strong class="calibre13">TV</strong></p>
</td>
<td class="calibre38">
<p class="calibre2"><strong class="calibre13">Radio</strong></p>
</td>
<td class="calibre38">
<p class="calibre2"><strong class="calibre13">Newspaper</strong></p>
</td>
<td class="calibre38">
<p class="calibre2"><strong class="calibre13">Sales</strong></p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">1</p>
</td>
<td class="calibre38">
<p class="calibre2">230.1</p>
</td>
<td class="calibre38">
<p class="calibre2">37.8</p>
</td>
<td class="calibre38">
<p class="calibre2">69.2</p>
</td>
<td class="calibre38">
<p class="calibre2">22.1</p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">2</p>
</td>
<td class="calibre38">
<p class="calibre2">44.5</p>
</td>
<td class="calibre38">
<p class="calibre2">39.3</p>
</td>
<td class="calibre38">
<p class="calibre2">45.1</p>
</td>
<td class="calibre38">
<p class="calibre2">10.4</p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">3</p>
</td>
<td class="calibre38">
<p class="calibre2">17.2</p>
</td>
<td class="calibre38">
<p class="calibre2">45.9</p>
</td>
<td class="calibre38">
<p class="calibre2">69.3</p>
</td>
<td class="calibre38">
<p class="calibre2">9.3</p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">4</p>
</td>
<td class="calibre38">
<p class="calibre2">151.5</p>
</td>
<td class="calibre38">
<p class="calibre2">41.3</p>
</td>
<td class="calibre38">
<p class="calibre2">58.5</p>
</td>
<td class="calibre38">
<p class="calibre2">18.5</p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">5</p>
</td>
<td class="calibre38">
<p class="calibre2">180.8</p>
</td>
<td class="calibre38">
<p class="calibre2">10.8</p>
</td>
<td class="calibre38">
<p class="calibre2">58.4</p>
</td>
<td class="calibre38">
<p class="calibre2">12.9</p>
</td>
</tr>
</tbody>
</table>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the advertising data</h1>
                </header>
            
            <article>
                
<p class="calibre2">This problem falls into the supervised learning type, in which we have explanatory features (input variables) and the response (output variable).</p>
<p class="calibre2">What are the features/input variables?</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">TV</strong>: Advertising dollars spent on TV for a single product in a given market (in thousands of dollars)</li>
<li class="calibre8"><strong class="calibre1">Radio</strong>: Advertising dollars spent on radio</li>
<li class="calibre8"><strong class="calibre1">Newspaper</strong>: Advertising dollars spent on newspapers</li>
</ul>
<p class="calibre2">What is the response/outcome/output variable?</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">Sales</strong>: The sales of a single product in a given market (in thousands of widgets)</li>
</ul>
<p class="calibre2">We can also use the <kbd class="calibre12">DataFrame</kbd> method shape to know the number of samples/observations in our data:</p>
<pre class="calibre21"># print the shape of the DataFrame<br class="title-page-name"/>advertising_data.shape<br class="title-page-name"/>Output:<br class="title-page-name"/>(200, 4)</pre>
<p class="calibre2">So, there are 200 observations in the advertising data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data analysis and visualization</h1>
                </header>
            
            <article>
                
<p class="calibre2">In order to understand the underlying form of the data, the relationship between the features and response, and more insights, we can use different types of visualization. To understand the relationship between the advertising data features and response, we are going to use a scatterplot.</p>
<p class="calibre2">In order to make different types of visualizations of your data, you can use Matplotlib (<a href="https://matplotlib.org/" class="calibre11">https://matplotlib.org/</a>), which is a Python 2D library for making visualizations. To get Matplotlib, you can follow their installation instructions at: <a href="https://matplotlib.org/users/installing.html" class="calibre11">https://matplotlib.org/users/installing.html</a>.</p>
<p class="calibre2">Let's import the visualization library Matplotlib:</p>
<pre class="calibre21">import matplotlib.pyplot as plt<br class="title-page-name"/><br class="title-page-name"/># The next line will allow us to make inline plots that could appear directly in the notebook<br class="title-page-name"/># without poping up in a different window<br class="title-page-name"/>%matplotlib inline</pre>
<p class="calibre2">Now, let's use a scatterplot to visualize the relationship between the advertising data features and response variable:</p>
<pre class="calibre21">fig, axs = plt.subplots(1, 3, sharey=True)<br class="title-page-name"/><br class="title-page-name"/># Adding the scatterplots to the grid <br class="title-page-name"/>advertising_data.plot(kind='scatter', x='TV', y='sales', ax=axs[0], figsize=(16, 8))<br class="title-page-name"/>advertising_data.plot(kind='scatter', x='radio', y='sales', ax=axs[1])<br class="title-page-name"/>advertising_data.plot(kind='scatter', x='newspaper', y='sales', ax=axs[2])</pre>
<p class="calibre2">Output:</p>
<div class="CDPAlignCenter"><img src="assets/45e7442f-7b9e-474c-836e-04228777d540.png" class="calibre31"/></div>
<div class="CDPAlignCenter1">Figure 1: Scatter plot for understanding the relationship between the advertising data features and the response variable</div>
<p class="calibre2">Now, we need to see how the ads will help increase the sales. So, we need to ask ourselves a couple of questions about that. Worthwhile questions to ask will be something like the relationship between the ads and sales, which kind of ads contribute more to the sales, and the approximate effect of each type of ad on the sales. We will try to answer such questions using a simple linear model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Simple regression model</h1>
                </header>
            
            <article>
                
<p class="calibre2">The linear regression model is a learning algorithm that is concerned with predicting a <strong class="calibre13">quantitative </strong>(also known as <strong class="calibre13"><span class="calibre10">numerical</span></strong>) <strong class="calibre13">response</strong> using a combination of <strong class="calibre13">explanatory</strong> <strong class="calibre13">features</strong> (or <strong class="calibre13">inputs</strong> or <strong class="calibre13">predictors</strong>).</p>
<p class="calibre2">A simple linear regression model with only one feature takes the following form:</p>
<p class="CDPAlignCenter3"><em class="calibre19">y = beta<sub class="calibre28">0</sub> + beta<sub class="calibre28">1</sub>x</em></p>
<p class="calibre2">Here:</p>
<ul class="calibre7">
<li class="calibre8"><em class="calibre25">y</em> is the predicted numerical value (response) → <strong class="calibre1">sales</strong></li>
<li class="calibre8"><em class="calibre25">x</em> is the the feature</li>
<li class="calibre8"><em class="calibre25">beta<sub class="calibre28">0</sub></em> is called the <strong class="calibre1">intercept</strong></li>
<li class="calibre8"><em class="calibre25">beta<sub class="calibre28">1</sub></em> is the coefficient of the feature <em class="calibre25">x</em> → <strong class="calibre1">TV ad</strong></li>
</ul>
<p class="calibre2">Both <em class="calibre19">beta<sub class="calibre28">0</sub></em> and <em class="calibre19">beta<sub class="calibre28">1</sub></em> are considered as model <strong class="calibre13">coefficients</strong>. In order to create a model that can predict the value of sales in the advertising example, we need to learn these coefficients because <em class="calibre19">beta<sub class="calibre28">1</sub></em> will be the learned effect of the feature <em class="calibre19">x</em> on the response <em class="calibre19">y</em>. For example, if <em class="calibre19">beta<sub class="calibre28">1</sub> = 0.04</em>, it means that an additional $100 spent on TV ads is <strong class="calibre13">associated with</strong> an increase in sales by four widgets. So, we need to go ahead and see how can we learn these coefficients.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning model coefficients</h1>
                </header>
            
            <article>
                
<p class="calibre2">In order to estimate the coefficients of our model, we need to fit the data with a regression line that gives a similar answer to the actual sales. To get a regression line that best fits the data, we will use a criterion called <strong class="calibre13">least squares</strong>. So, we need to find a line that minimizes the difference between the predicted value and the observed<strong class="calibre13"> </strong>(actual) one. In other words, we need to find a regression line that minimizes the <strong class="calibre13">sum of squared residuals</strong> (<strong class="calibre13">SSresiduals</strong>). <em class="calibre19">Figure 2</em> illustrates this:</p>
<div class="CDPAlignCenter"><img src="assets/7d507cac-b66c-4975-9771-a6e6f64f3732.png" class="calibre39"/></div>
<div class="CDPAlignCenter1">Figure 2: Fitting the data points (sample of TV ads) with a regression line that minimizes the sum of the squared residuals (difference between the predicted and observed value)</div>
<p class="calibre2">The following are the elements that exist in <em class="calibre19">Figure 2</em>:</p>
<ul class="calibre7">
<li class="calibre8"><strong class="calibre1">Black dots</strong> represent the actual or observed values of <em class="calibre25">x</em> (TV ad) and <em class="calibre25">y</em> (sales)</li>
<li class="calibre8"><strong class="calibre1">The blue line</strong> represents the least squares line (regression line)</li>
<li class="calibre8"><strong class="calibre1">The red line</strong> represents the residuals, which are the differences between the predicted and the observed (actual) <span>values</span></li>
</ul>
<p class="calibre2">So, this is how our coefficients relate to the least squares line (regression line):</p>
<ul class="calibre7">
<li class="calibre8"><em class="calibre25">beta<sub class="calibre28">0</sub></em> is the <strong class="calibre1">intercept</strong>, which is the value of <em class="calibre25">y</em> when <em class="calibre25">x =0</em></li>
<li class="calibre8"><em class="calibre25">beta<sub class="calibre28">1</sub></em> is the <strong class="calibre1">slope</strong>, which represents the change in <em class="calibre25">y</em> divided by the change in <em class="calibre25">x</em></li>
</ul>
<p class="calibre2"><em class="calibre19">Figure 3</em> presents a graphical explanation of this:</p>
<div class="CDPAlignCenter"><img src="assets/e2a18228-02ac-44bb-8be4-2a2c3b844def.png" class="calibre40"/></div>
<div class="CDPAlignCenter1">Figure 3: The relation between the least squares line and the model coefficients</div>
<p class="calibre2">Now, let's go ahead and start to learn these coefficients using <strong class="calibre13">Statsmodels</strong>:</p>
<div class="title-page-name">
<pre class="calibre21"><span># To use the formula notation below, we need to import the module like the following<br class="title-page-name"/></span><span>import</span> <span>statsmodels.formula.api</span> <span>as</span> <span>smf<br class="title-page-name"/></span><span># create a fitted model in one line of code(which will represent the least squares line)<br class="title-page-name"/></span><span>lm</span> <span>=</span> <span>smf</span><span>.</span><span>ols</span><span>(</span><span>formula</span><span>=</span><span>'sales ~ TV'</span><span>,</span> <span>data</span><span>=</span><span>advertising_data)</span><span>.</span><span>fit</span><span>()<br class="title-page-name"/></span><span># show the trained model coefficients<br class="title-page-name"/></span><span>lm</span><span>.</span><span>params</span></pre></div>
<p class="calibre2">Output:</p>
<pre class="calibre21">Intercept    7.032594<br class="title-page-name"/>TV           0.047537<br class="title-page-name"/>dtype: float64</pre>
<p class="calibre2">As we mentioned, one of the advantages of linear regression models is that they are easy to interpret, so let's go ahead and interpret the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Interpreting model coefficients</h1>
                </header>
            
            <article>
                
<p class="calibre2">Let's see how to interpret the coefficients of the model, such as the TV ad coefficient (<em class="calibre19">beta<sub class="calibre28">1</sub></em>):</p>
<ul class="calibre7">
<li class="calibre8">A unit increase in the input/feature (TV ad) spending is <strong class="calibre1">associated</strong> with a <kbd class="calibre12">0.047537</kbd> unit increase in Sales (response). In other words, an additional $100 spent on TV ads is <strong class="calibre1">associated with</strong> an increase in sales of 4.7537 widgets.</li>
</ul>
<p class="calibre2">The goal of building a learned model from the TV ad data is to predict the sales for unseen data. So, let's see how we <span class="calibre10">can</span><span class="calibre10"> </span><span class="calibre10">use the learned model in order to predict the value of sales (which we don't know) based on a given value of a TV ad.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the model for prediction</h1>
                </header>
            
            <article>
                
<p class="calibre2">Let's say we have unseen data of TV ad spending and that we want to know their corresponding impact on the sales of the company. So, we need to use the learned model to do that for us. Let's suppose that we want to know how much sales will increase from $50000 of TV advertising.</p>
<p class="calibre2">Let's use our learned model coefficients to make such a calculation:</p>
<p class="CDPAlignCenter3"><em class="calibre19">y = 7.032594 + 0.047537 x 50</em> </p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span># manually calculating the increase in the sales based on $50k<br class="title-page-name"/></span><span>7.032594</span> <span>+</span> <span>0.047537</span><span>*</span><span>50000</span></pre></div>
</div>
<p class="calibre2">Output:</p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21">9,409.444</pre></div>
</div>
<p class="calibre2">We can also use Statsmodels to make the prediction for us. First, we need to provide the TV ad value in a pandas DataFrame since the Statsmodels interface expects it:</p>
<pre class="calibre21"><span># creating a Pandas DataFrame to match Statsmodels interface expectations<br class="title-page-name"/></span><span>new_TVAdSpending</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>({</span><span>'TV'</span><span>:</span> <span>[</span><span>50000</span><span>]})<br class="title-page-name"/></span><span>new_TVAdSpending</span><span>.</span><span>head</span><span>()</span></pre>
<p class="calibre2">Output:</p>
<table class="calibre41">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2"> </p>
</td>
<td class="calibre38">
<p class="calibre2"><strong class="calibre13">TV</strong></p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">0</p>
</td>
<td class="calibre38">
<p class="calibre2">50000</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2">Now, we can go ahead and use the predict function to predict the sales value:</p>
<div class="title-page-name">
<div class="title-page-name">
<pre class="calibre21"><span># use the model to make predictions on a new value<br class="title-page-name"/></span>preds = lm.predict(new_TVAdSpending)</pre></div>
<p class="calibre2">Output:</p>
</div>
<pre class="calibre21">array([ 9.40942557])</pre>
<p class="calibre2">Let's see how the learned least squares line looks. In order to draw the line, we need two points, with each point represented by this pair: (<kbd class="calibre12">x, predict_value_of_x</kbd>).</p>
<p class="calibre2">So, let's take the minimum and maximum values for the TV ad feature:</p>
<pre class="calibre21"><span># create a DataFrame with the minimum and maximum values of TV<br class="title-page-name"/></span><span>X_min_max</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>({</span><span>'TV'</span><span>:</span> <span>[</span><span>advertising_data.</span><span>TV</span><span>.</span><span>min</span><span>(),</span> <span>advertising_data.</span><span>TV</span><span>.</span><span>max</span><span>()]})<br class="title-page-name"/></span><span>X_min_max</span><span>.</span><span>head</span><span>()</span></pre>
<p class="calibre2">Output:</p>
<table class="calibre42">
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2"> </p>
</td>
<td class="calibre38">
<p class="calibre2"><strong class="calibre13">TV</strong></p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">0</p>
</td>
<td class="calibre38">
<p class="calibre2">0.7</p>
</td>
</tr>
<tr class="calibre37">
<td class="calibre38">
<p class="calibre2">1</p>
</td>
<td class="calibre38">
<p class="calibre2">296.4</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2">Let's get the corresponding predictions for these two values:</p>
<pre class="calibre21"><span># predictions for X min and max values<br class="title-page-name"/></span><span>predictions</span> <span>=</span> <span>lm</span><span>.</span><span>predict</span><span>(</span><span>X_min_max</span><span>)<br class="title-page-name"/></span><span>predictions</span></pre>
<p class="calibre2">Output:</p>
<pre class="calibre21">array([  7.0658692,  21.12245377])</pre>
<p class="calibre2">Now, let's plot the actual data and then fit it with the least squares line:</p>
<div class="title-page-name">
<pre class="calibre21"><span># plotting the acutal observed data<br class="title-page-name"/></span><span>advertising_data.</span><span>plot</span><span>(</span><span>kind</span><span>=</span><span>'scatter'</span><span>,</span> <span>x</span><span>=</span><span>'TV'</span><span>,</span> <span>y</span><span>=</span><span>'sales'</span><span>)<br class="title-page-name"/></span><span>#plotting the least squares line<br class="title-page-name"/></span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>new_TVAdSpending</span><span>,</span> <span>preds,</span> <span>c</span><span>=</span><span>'red'</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>)</span></pre></div>
<p class="innercell">Output:</p>
<p class="CDPAlignCenter3"><img src="assets/b2a7c8e3-54d6-4cf8-9b81-ec0167a4cd4a.png" class="calibre43"/></p>
<div class="CDPAlignCenter1">Figure 4: Plot of the actual data and the least squares line</div>
<p class="calibre2">Extensions of this example and further explanations will be explained in the next chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linear models for classification</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this section, we are going to go through logistic regression, which is one of the widely used algorithms for classification.</p>
<p class="calibre2">What's logistic regression? The simple definition of logistic regression is that it's a type of classification algorithm involving a linear discriminant.</p>
<p class="calibre2">We are going to clarify this definition in two points:</p>
<ol class="calibre16">
<li class="calibre8">
<p class="calibre9">Unlike linear regression, logistic regression doesn't try to estimate/predict the value of the numeric variable given a set of features or input variables. Instead, the output of the logistic regression algorithm is the probability that the given sample/observation belongs to a specific class. In simpler words, let's assume that we have a binary classification problem. In this type of problem, we have only two classes in the output variable, for example, diseased or not diseased. So, the probability that a certain sample belongs to the diseased class is <em class="calibre19">P<sub class="calibre28">0</sub></em> and the probability that a certain sample belongs to the not diseased class is <em class="calibre19">P<sub class="calibre28">1</sub> = 1 - P<sub class="calibre28">0</sub></em>. Thus, the output of the logistic regression algorithm is always between 0 and 1.</p>
</li>
<li class="calibre8">
<p class="calibre9">As you probably know, there are a lot of learning algorithms for regression or classification, and each learning algorithm has its own assumption about the data samples. The ability to choose the learning algorithm that fits your data will come gradually with practice and good understanding of the subject. Thus, the central assumption of the logistic regression algorithm is that our input/feature space could be separated into two regions (one for each class) by a linear surface, which could be a line if we only have two features or a plane if we have three, and so on. The position and orientation of this boundary will be determined by your data. If your data satisfies this constraint that is separating them into regions corresponding to each class with a linear surface, then your data is said to be linearly separable. The following figure illustrates this assumption. In <em class="calibre19">Figure 5</em>, we have three dimensions, inputs, or features and two possible classes: diseased (red) and not diseased (blue). The dividing place that separates the two regions from each other is called a <strong class="calibre13">linear discriminant</strong>, and that’s because it's linear and it helps the model to discriminate between samples belonging to different classes:</p>
</li>
</ol>
<p class="CDPAlignCenter3"><img src="assets/16e03c8c-c3e2-4526-851c-0ead591812ed.png" class="calibre44"/></p>
<div class="CDPAlignCenter1">Figure 5: Linear decision surface separating two classes</div>
<p class="calibre2">If your data samples aren't linearly separable, you can make them so by transforming your data into higher dimensional space, by adding more features.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Classification and logistic regression</h1>
                </header>
            
            <article>
                
<p class="calibre2">In the previous section, we learned how to predict continuous quantities (for example, the impact of TV advertising on company sales) as linear functions of input values (for example, TV, Radio, and newspaper advertisements). But for other tasks, the output will not be continuous quantities. For example, predicting whether someone is diseased or not is a classification problem and we need a different learning algorithm to perform this. In this section, we are going to dig deeper into the mathematical analysis of logistic regression, which is a learning algorithm for classification tasks.</p>
<p class="calibre2">In linear regression, we tried to predict the value of the output variable <em class="calibre19">y<sup class="calibre29">(i)</sup></em> for the <em class="calibre19">i<sup class="calibre29">th</sup></em> sample <em class="calibre19">x<sup class="calibre29">(i)</sup></em> in that dataset using a linear model function <em class="calibre19">y = h<sub class="calibre28">θ</sub>(x)=θ<sup class="calibre29">Τ</sup> x</em>. This is not really a great solution for classification tasks such as predicting binary labels <em class="calibre19">(y<sup class="calibre29">(i)</sup> ∈ {0,1})</em>.</p>
<p class="calibre2">Logistic regression is one of the many learning algorithms that we can use for classification tasks, whereby we use a different hypothesis class while trying to predict the probability that a specific sample belongs to the one class and the probability that it belongs to the zero class. So, in logistic regression, we will try to learn the following functions:</p>
<p class="CDPAlignCenter3"><img class="fm-editor-equation1" src="assets/621ad68c-251e-4148-ab09-8075642e6eaa.png"/></p>
<p class="calibre2">The function <img class="fm-editor-equation2" src="assets/aae68862-cda0-4cec-abca-621bc46268f8.png"/> is often called a <strong class="calibre13">sigmoid</strong> or <strong class="calibre13">logistic</strong> function, which squashes the value of <em class="calibre19">θ<sup class="calibre29">Τ</sup>x</em> into a fixed range <em class="calibre19">[0,1]</em>, as shown in the following graph. Because the value will be squashed between [0,1], we can <span class="calibre10">then </span>interpret <em class="calibre19">h<sub class="calibre28">θ</sub>(x)</em> as a probability.</p>
<p class="calibre2">Our goal is to search for a value of the parameters <em class="calibre19">θ</em> so that the probability <em class="calibre19">P(y = 1|x) = h<sub class="calibre28">θ</sub>(x))</em> is large when the input sample <em class="calibre19">x</em> belongs to the one class and small when <em class="calibre19">x</em> belongs to the zero class:</p>
<p class="CDPAlignCenter3"><img src="assets/e319d30b-e5e6-4b80-a840-02107358b9ba.png" class="calibre45"/></p>
<div class="CDPAlignCenter1">Figure 6: Shape of the sigmoid function</div>
<p class="calibre2">So, suppose we have a set of training samples with their corresponding binary labels <em class="calibre19">{(x<sup class="calibre29">(i)</sup>,y<sup class="calibre29">(i)</sup>): i = 1,...,m}.</em> We will need to minimize the following cost function, which measures how good a given <em class="calibre19">h<sub class="calibre28">θ</sub></em> does:</p>
<p class="CDPAlignCenter3"><img class="fm-editor-equation3" src="assets/57740d69-403e-45af-b411-841990cbbb5a.png"/></p>
<p class="calibre2">Note that we have only one of the two terms of the equation's summation as non-zero for each training sample (depending on whether the value of the label <em class="calibre19">y<sup class="calibre29">(i)</sup></em> is <em class="calibre19">0</em> or ). When <em class="calibre19">y<sup class="calibre29">(i)</sup> = 1</em>, minimizing the model cost function means we need to make <em class="calibre19">h<sub class="calibre28">θ</sub>(x<sup class="calibre29">(i)</sup>)</em> large, and when <em class="calibre19">y<sup class="calibre29">(i)</sup> = 0<img class="fm-editor-equation4" src="assets/7851cec8-7d58-4c09-887f-6177ca8b48dc.png"/></em>, we want to make <em class="calibre19">1-h<sub class="calibre28">θ</sub> large</em>.<br class="calibre20"/>
<br class="calibre20"/>
Now, we have a cost function that calculates how well a given hypothesis <em class="calibre19">h<sub class="calibre28">θ</sub></em> fits our training samples. We can learn to classify our training samples by using an optimization technique to minimize <em class="calibre19">J(θ)</em> and find the best choice of parameters <em class="calibre19">θ</em>. Once we have done this, we can use these parameters to classify a new test sample as 1 or 0, checking which of these two class labels is most probable. If <em class="calibre19">P(y = 1|x) &lt; P(y = 0|x)</em> then we output 0, otherwise we output 1, which is the same as defining a threshold of 0.5 between our classes and checking whether <em class="calibre19">h<sub class="calibre28">θ</sub>(x) &gt; 0.5</em>.</p>
<p class="calibre2">To minimize the cost function <em class="calibre19">J(θ),</em> we can use an optimization technique that finds the best value of <em class="calibre19">θ</em> that minimizes the cost function. So, we can use a calculus tool called <strong class="calibre13">gradient</strong>, which tries to find the greatest rate of increase of the cost function. Then, we can take the opposite direction to find the minimum value of this function; for example, the gradient of <em class="calibre19"><span class="calibre10">J(</span><span class="calibre10">θ)</span></em><span class="calibre10"> is denoted by <em class="calibre19">∇<sub class="calibre28">θ</sub>J(θ),</em> </span><span class="calibre10">which means taking the gradient for the cost function with respect to the model parameters. Thus, we need to provide a function that computes <em class="calibre19">J(θ)</em> </span><span class="calibre10">and <em class="calibre19">∇<sub class="calibre28">θ</sub>J(θ)</em> </span><span class="calibre10">for any requested choice of <em class="calibre19">θ</em></span><span class="calibre10">. If we derived the gradient or derivative of the cost function above <em class="calibre19">J(θ)</em> </span><span class="calibre10">with respect to <em class="calibre19">θ<sub class="calibre28">j</sub></em>, </span><span class="calibre10">we will get the following results:</span></p>
<p class="CDPAlignCenter3"><img class="fm-editor-equation5" src="assets/bac9e1fa-8c45-49fa-81e4-0335d4c5c858.png"/></p>
<p class="calibre2">Which can be written in a vector form as:</p>
<p class="CDPAlignCenter3"><img class="fm-editor-equation6" src="assets/d1fd5510-fc07-4c56-985b-b3a942947b8c.png"/></p>
<p class="calibre2">Now, we have a mathematical understanding of the logistic regression, so let's go ahead and use this new learning method for solving a classification task.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Titanic example – model building and training</h1>
                </header>
            
            <article>
                
<p class="calibre2">The sinking of the <span class="calibre10">ship,</span><span class="calibre10"> </span><span class="calibre10">Titanic, is one of the most infamous events in history. This incident led to the deaths of 1,502 passengers and crew out of 2,224. In this problem, we will use data science to predict whether the passenger will survive this tragedy or not and then test the performance of our model based on the actual statistics of the tragedy.</span></p>
<p class="calibre2">To follow up with the Titanic example, you need to do the following:</p>
<ol class="calibre16">
<li class="calibre8">Download this repository in a ZIP file by clicking on <a href="https://github.com/ahmed-menshawy/ML_Titanic/archive/master.zip" target="_blank" class="calibre11">https://github.com/ahmed-menshawy/ML_Titanic/archive/master.zip</a> or execute from the terminal:</li>
<li class="calibre8">Git clone: <a href="https://github.com/ahmed-menshawy/ML_Titanic.git" class="calibre11">https://github.com/ahmed-menshawy/ML_Titanic.git</a></li>
<li class="calibre8">Install <kbd class="calibre12">[virtualenv]</kbd>: (<a href="http://virtualenv.readthedocs.org/en/latest/installation.html" class="calibre11">http://virtualenv.readthedocs.org/en/latest/installation.html</a>)</li>
<li class="calibre8">Navigate to the directory where you unzipped or cloned the repo and create a virtual environment with <kbd class="calibre12">virtualenv ml_titanic</kbd></li>
<li class="calibre8">Activate the environment with <kbd class="calibre12">source ml_titanic/bin/activate</kbd></li>
<li class="calibre8">Install the required dependencies with <kbd class="calibre12">pip install -r requirements.txt</kbd></li>
<li class="calibre8">Execute the <kbd class="calibre12">ipython notebook</kbd> from the command line or terminal</li>
<li class="calibre8">Follow the example code in the chapter</li>
<li class="calibre8">When you're done, deactivate the virtual environment with <kbd class="calibre12">deactivate</kbd></li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data handling and visualization</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this section, we are going to do some data preprocessing and analysis. Data exploration and analysis is considered one of the most important steps while applying machine learning and might also be considered as the most important one, because at this step, you get to know the friend, Data, which is going to stick with you during the training process. Also, knowing your data will enable you to narrow down the set of candidate algorithms that you might use to check which one is the best for your data.</p>
<p class="calibre2">Let's start off by importing the necessary packages for our implementation:</p>
<pre class="calibre21">import matplotlib.pyplot as plt<br class="title-page-name"/> %matplotlib inline<br class="title-page-name"/> <br class="title-page-name"/> from statsmodels.nonparametric.kde import KDEUnivariate<br class="title-page-name"/> from statsmodels.nonparametric import smoothers_lowess<br class="title-page-name"/> from pandas import Series, DataFrame<br class="title-page-name"/> from patsy import dmatrices<br class="title-page-name"/> from sklearn import datasets, svm<br class="title-page-name"/> <br class="title-page-name"/> import numpy as np<br class="title-page-name"/> import pandas as pd<br class="title-page-name"/> import statsmodels.api as sm<br class="title-page-name"/><br class="title-page-name"/>from scipy import stats<br class="title-page-name"/>stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)</pre>
<p class="calibre2">Let’s read the Titanic passengers and crew data using Pandas:</p>
<pre class="calibre21">titanic_data = pd.read_csv("data/titanic_train.csv")</pre>
<p class="calibre2">Next up, let's check the dimensions of our dataset and see how many examples we have and how many explanatory features are describing our dataset:</p>
<pre class="calibre21">titanic_data.shape<br class="title-page-name"/> <br class="title-page-name"/> Output:<br class="title-page-name"/> (891, 12)</pre>
<p class="calibre2">So, we have a total of 891 observations, data samples, or passenger/crew records, and 12 explanatory features for describing this record:</p>
<pre class="calibre21">list(titanic_data)<br class="title-page-name"/> <br class="title-page-name"/> Output:<br class="title-page-name"/> ['PassengerId',<br class="title-page-name"/> 'Survived',<br class="title-page-name"/> 'Pclass',<br class="title-page-name"/> 'Name',<br class="title-page-name"/> 'Sex',<br class="title-page-name"/> 'Age',<br class="title-page-name"/> 'SibSp',<br class="title-page-name"/> 'Parch',<br class="title-page-name"/> 'Ticket',<br class="title-page-name"/> 'Fare',<br class="title-page-name"/> 'Cabin',<br class="title-page-name"/> 'Embarked']</pre>
<p class="calibre2">Let's see the data of some samples/observations:</p>
<pre class="calibre21">titanic_data[500:510]<br class="title-page-name"/> </pre>
<p class="calibre2">Output:</p>
<p class="CDPAlignCenter3"><img src="assets/185f0d5b-b29b-409a-b5a8-1f815ed60bc1.png" class="calibre46"/></p>
<div class="CDPAlignCenter1">Figure 7: Samples from the titanic dataset</div>
<p class="calibre2">Now, we have a Pandas DataFrame that holds the information of 891 passengers that we need to analyze. The columns of the DataFrame represent the explanatory features about each passenger/crew, like name, sex, or age.</p>
<p class="calibre2">Some of these explanatory features are complete without any missing values, such as the survived feature, which has 891 entries. Other explanatory features contain missing values, such as the age feature, which has only 714 entries. Any missing value in the DataFrame is represented as NaN.</p>
<p class="calibre2">If you explore all of the dataset features, you will find that the ticket and cabin features have many missing values (NaNs), and so they won't add much value to our analysis. To handle this, we will drop them from the DataFrame.</p>
<p class="calibre2">Use the following line of code to drop the <kbd class="calibre12">ticket</kbd> and <kbd class="calibre12">cabin</kbd> features entirely from the DataFrame:</p>
<pre class="calibre21">titanic_data = titanic_data.drop(['Ticket','Cabin'], axis=1)</pre>
<p class="calibre2">There are a lot of reasons to have such missing values in our dataset. But in order to preserve the integrity of the dataset, we need to handle such missing values. In this specific problem, we will choose to drop them.</p>
<p class="calibre2">Use the following line of code in order to remove all <kbd class="calibre12">NaN</kbd> values from all the remaining features:</p>
<pre class="calibre21">titanic_data = titanic_data.dropna()</pre>
<p class="calibre2">Now, we have a sort of compete dataset that we can use to do our analysis. If you decided to just delete all the NaNs without deleting the <strong class="calibre13">ticket</strong> and <strong class="calibre13">cabin</strong> features first, you will find that most of the dataset is removed, because the <kbd class="calibre12">.dropna()</kbd> method removes an observation from the DataFrame, even if it has only one NaN in one of the features.</p>
<p class="calibre2">Let’s do some data visualization to see the distribution of some features and understand the relationship between the explanatory features:</p>
<pre class="calibre21"># declaring graph parameters<br class="title-page-name"/>fig = plt.figure(figsize=(18,6))<br class="title-page-name"/>alpha=alpha_scatterplot = 0.3<br class="title-page-name"/>alpha_bar_chart = 0.55<br class="title-page-name"/># Defining a grid of subplots to contain all the figures<br class="title-page-name"/>ax1 = plt.subplot2grid((2,3),(0,0))<br class="title-page-name"/># Add the first bar plot which represents the count of people who survived vs not survived.<br class="title-page-name"/>titanic_data.Survived.value_counts().plot(kind='bar', alpha=alpha_bar_chart)<br class="title-page-name"/># Adding margins to the plot<br class="title-page-name"/>ax1.set_xlim(-1, 2)<br class="title-page-name"/># Adding bar plot title<br class="title-page-name"/>plt.title("Distribution of Survival, (1 = Survived)")<br class="title-page-name"/>plt.subplot2grid((2,3),(0,1))<br class="title-page-name"/>plt.scatter(titanic_data.Survived, titanic_data.Age, alpha=alpha_scatterplot)<br class="title-page-name"/># Setting the value of the y label (age)<br class="title-page-name"/>plt.ylabel("Age")<br class="title-page-name"/># formatting the grid<br class="title-page-name"/>plt.grid(b=True, which='major', axis='y')<br class="title-page-name"/>plt.title("Survival by Age, (1 = Survived)")<br class="title-page-name"/>ax3 = plt.subplot2grid((2,3),(0,2))<br class="title-page-name"/>titanic_data.Pclass.value_counts().plot(kind="barh", alpha=alpha_bar_chart)<br class="title-page-name"/>ax3.set_ylim(-1, len(titanic_data.Pclass.value_counts()))<br class="title-page-name"/>plt.title("Class Distribution")<br class="title-page-name"/>plt.subplot2grid((2,3),(1,0), colspan=2)<br class="title-page-name"/># plotting kernel density estimate of the subse of the 1st class passenger’s age<br class="title-page-name"/>titanic_data.Age[titanic_data.Pclass == 1].plot(kind='kde')<br class="title-page-name"/>titanic_data.Age[titanic_data.Pclass == 2].plot(kind='kde')<br class="title-page-name"/>titanic_data.Age[titanic_data.Pclass == 3].plot(kind='kde')<br class="title-page-name"/># Adding x label (age) to the plot<br class="title-page-name"/>plt.xlabel("Age")<br class="title-page-name"/>plt.title("Age Distribution within classes")<br class="title-page-name"/># Add legend to the plot.<br class="title-page-name"/>plt.legend(('1st Class', '2nd Class','3rd Class'),loc='best')<br class="title-page-name"/>ax5 = plt.subplot2grid((2,3),(1,2))<br class="title-page-name"/>titanic_data.Embarked.value_counts().plot(kind='bar', alpha=alpha_bar_chart)<br class="title-page-name"/>ax5.set_xlim(-1, len(titanic_data.Embarked.value_counts()))<br class="title-page-name"/>plt.title("Passengers per boarding location")</pre>
<div class="CDPAlignCenter"><img src="assets/cdec217d-50f1-41fc-b1ef-bb9b49c18ead.png" class="calibre31"/></div>
<div class="CDPAlignCenter1">Figure 8: Basic visualizations for the Titanic data samples</div>
<p class="calibre2">As we mentioned, the purpose of this analysis is to predict if a specific passenger will survive the tragedy based on the available feature, such as traveling class (called <kbd class="calibre12">pclass</kbd> in the data), <strong class="calibre13">Sex</strong>, <strong class="calibre13">Age</strong>, and <strong class="calibre13">Fare Price</strong>. So, let's see if we can get a better visual understanding of the passengers who survived and died.</p>
<p class="calibre2">First, let's draw a bar plot to see the number of observations in each class (survived/died):</p>
<pre class="calibre21">plt.figure(figsize=(6,4))<br class="title-page-name"/>fig, ax = plt.subplots()<br class="title-page-name"/>titanic_data.Survived.value_counts().plot(kind='barh', color="blue", alpha=.65)<br class="title-page-name"/>ax.set_ylim(-1, len(titanic_data.Survived.value_counts()))<br class="title-page-name"/>plt.title("Breakdown of survivals(0 = Died, 1 = Survived)")</pre>
<p class="CDPAlignCenter3"><img src="assets/2f98e69d-7965-40fa-b36b-c53188be57d4.png" class="calibre47"/></p>
<div class="CDPAlignCenter1">Figure 9: Survival breakdown</div>
<p class="calibre2">Let's get some more understanding of the data by breaking <span class="calibre10">down</span><span class="calibre10"> </span><span class="calibre10">the previous graph by gender:</span></p>
<pre class="calibre21">fig = plt.figure(figsize=(18,6))<br class="title-page-name"/>#Plotting gender based analysis for the survivals.<br class="title-page-name"/>male = titanic_data.Survived[titanic_data.Sex == 'male'].value_counts().sort_index()<br class="title-page-name"/>female = titanic_data.Survived[titanic_data.Sex == 'female'].value_counts().sort_index()<br class="title-page-name"/>ax1 = fig.add_subplot(121)<br class="title-page-name"/>male.plot(kind='barh',label='Male', alpha=0.55)<br class="title-page-name"/>female.plot(kind='barh', color='#FA2379',label='Female', alpha=0.55)<br class="title-page-name"/>plt.title("Gender analysis of survivals (raw value counts) "); plt.legend(loc='best')<br class="title-page-name"/>ax1.set_ylim(-1, 2)<br class="title-page-name"/>ax2 = fig.add_subplot(122)<br class="title-page-name"/>(male/float(male.sum())).plot(kind='barh',label='Male', alpha=0.55)  <br class="title-page-name"/>(female/float(female.sum())).plot(kind='barh', color='#FA2379',label='Female', alpha=0.55)<br class="title-page-name"/>plt.title("Gender analysis of survivals"); plt.legend(loc='best')<br class="title-page-name"/>ax2.set_ylim(-1, 2)</pre>
<p class="CDPAlignCenter3"><img src="assets/c97d7af6-5437-4acf-ac37-66f45ed2462e.png" class="calibre46"/></p>
<div class="CDPAlignCenter1">Figure 10: Further breakdown for the Titanic data by the gender feature</div>
<p class="calibre2">Now, we have more information about the two possible classes (survived and died). The exploration and visualization step is necessary because it gives you more insight into the structure of the data and helps you to choose the suitable learning algorithm for your problem. As you can see, we started with very basic plots and then increased the complexity of the plot to discover more about the data that we were working with.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data analysis – supervised machine learning</h1>
                </header>
            
            <article>
                
<p class="calibre2">The purpose of this analysis is to predict the survivors. So, the outcome will be survived or not, which is a binary classification problem; in it, you have only two possible classes.</p>
<p class="calibre2">There are lots of learning algorithms that we can use for binary classification problems. Logistic regression is one of them. As explained by Wikipedia:</p>
<div class="packtquote"><br class="title-page-name"/>
<em class="calibre25">In statistics, logistic regression or logit regression is a type of regression analysis used for predicting the outcome of a categorical dependent variable (a dependent variable that can take on a limited number of values, whose magnitudes are not meaningful but whose ordering of magnitudes may or may not be meaningful) based on one or more predictor variables. That is, it is used in estimating empirical values of the parameters in a qualitative response model. The probabilities describing the possible outcomes of a single trial are modeled, as a function of the explanatory (predictor) variables, using a logistic function. Frequently (and subsequently in this article) "logistic regression" is used to refer specifically to the problem in which the dependent variable is binary—that is, the number of available categories is two—and problems with more than two categories are referred to as multinomial logistic regression or, if the multiple categories are ordered, as ordered logistic regression. Logistic regression measures the relationship between a categorical dependent variable and one or more independent variables, which are usually (but not necessarily) continuous, by using probability scores as the predicted values of the dependent variable.[1] As such it treats the same set of problems as does probit regression using similar techniques.</em></div>
<p class="calibre2">In order to use logistic regression, we need to create a formula that tells our model the type of features/inputs we're giving it:</p>
<pre class="calibre21"># model formula<br class="title-page-name"/># here the ~ sign is an = sign, and the features of our dataset<br class="title-page-name"/># are written as a formula to predict survived. The C() lets our<br class="title-page-name"/># regression know that those variables are categorical.<br class="title-page-name"/># Ref: http://patsy.readthedocs.org/en/latest/formulas.html<br class="title-page-name"/>formula = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + C(Embarked)'<br class="title-page-name"/># create a results dictionary to hold our regression results for easy analysis later<br class="title-page-name"/>results = {}<br class="title-page-name"/># create a regression friendly dataframe using patsy's dmatrices function<br class="title-page-name"/>y,x = dmatrices(formula, data=titanic_data, return_type='dataframe')<br class="title-page-name"/># instantiate our model<br class="title-page-name"/>model = sm.Logit(y,x)<br class="title-page-name"/># fit our model to the training data<br class="title-page-name"/>res = model.fit()<br class="title-page-name"/># save the result for outputing predictions later<br class="title-page-name"/>results['Logit'] = [res, formula]<br class="title-page-name"/>res.summary()<br class="title-page-name"/>Output:<br class="title-page-name"/>Optimization terminated successfully.<br class="title-page-name"/> Current function value: 0.444388<br class="title-page-name"/> Iterations 6</pre>
<p class="CDPAlignCenter3"><img src="assets/a2254f5c-9ef2-4f13-8658-962474fc88c5.png" class="calibre48"/></p>
<div class="CDPAlignCenter1">Figure 11: Logistic regression results</div>
<p class="calibre2">Now, let's plot the prediction of our model versus actual ones and also the residuals, which is the difference between the actual and predicted values of the target variable:</p>
<pre class="calibre21"># Plot Predictions Vs Actual<br class="title-page-name"/>plt.figure(figsize=(18,4));<br class="title-page-name"/>plt.subplot(121, axisbg="#DBDBDB")<br class="title-page-name"/># generate predictions from our fitted model<br class="title-page-name"/>ypred = res.predict(x)<br class="title-page-name"/>plt.plot(x.index, ypred, 'bo', x.index, y, 'mo', alpha=.25);<br class="title-page-name"/>plt.grid(color='white', linestyle='dashed')<br class="title-page-name"/>plt.title('Logit predictions, Blue: \nFitted/predicted values: Red');<br class="title-page-name"/># Residuals<br class="title-page-name"/>ax2 = plt.subplot(122, axisbg="#DBDBDB")<br class="title-page-name"/>plt.plot(res.resid_dev, 'r-')<br class="title-page-name"/>plt.grid(color='white', linestyle='dashed')<br class="title-page-name"/>ax2.set_xlim(-1, len(res.resid_dev))<br class="title-page-name"/>plt.title('Logit Residuals');</pre>
<div class="CDPAlignCenter1"><img src="assets/c020d1bf-3a74-496d-9d74-4b581068d655.png" class="calibre31"/></div>
<div class="CDPAlignCenter1">Figure 12: Understanding the logit regression model</div>
<p class="calibre2">Now, we have built our logistic regression model, and prior to that, we have done some analysis and exploration of the dataset. The preceding example shows you the general pipelines for building a machine learning solution.</p>
<p class="calibre2">Most of the time, practitioners fall into some technical pitfalls because they lack experience of understanding the concepts of machine learning. For example, someone might get an accuracy of 99% over the test set, and then without doing any investigation of the distribution of classes in the data (such as how many samples are negative and how many samples are positive), they deploy the model.</p>
<p class="calibre2">To highlight some of these concepts and differentiate between different kinds of errors that you need to be aware of and which ones you should really care about, we'll move on to the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Different types of errors</h1>
                </header>
            
            <article>
                
<p class="calibre2">In machine learning, there are two types of errors, and as a newcomer to data science, you need to understand the crucial difference between both of them. If you end up minimizing the wrong type of error, the whole learning system will be useless and you won’t be able to use it in practice over unseen data. To minimize this kind of misunderstanding between practitioners about these two types of errors, we are going to explain them in the following two sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Apparent (training set) error</h1>
                </header>
            
            <article>
                
<p class="calibre2">This the first type of error that you don't have to care about minimizing. Getting a small value for this type of error doesn't mean that your model will work well over the unseen data (generalize). To better understand this type of error, we'll give a trivial example of a class scenario. The purpose of solving problems in the classroom is not to be able to solve the same problem again in the exam, but to be able to solve other problems that won’t necessarily be similar to the ones you practiced in the classroom. The exam problems could be from the same family of the classroom problems, but not necessarily identical.</p>
<p class="calibre2">Apparent error is the ability of the trained model to perform on the training set for which we already know the true outcome/output. If you manage to get 0 error over the training set, then it is a good indicator for you that your model (mostly) <span class="calibre10">won't</span><span class="calibre10"> </span><span class="calibre10">work well on unseen data (won't generalize). On the other hand, data science is about using a training set as a base knowledge for the learning algorithm to work well on future unseen data.</span></p>
<p class="calibre2">In <em class="calibre19">Figure 3</em>, the red curve represents the <strong class="calibre13">apparent</strong> error. Whenever you increase the model's ability to memorize things (such as increasing the model complexity by increasing the number of explanatory features), you will find that this apparent error approaches zero. It can be shown that if you have as many <span class="calibre10">features </span>as observations/samples, then the <strong class="calibre13">apparent</strong> error will be zero:</p>
<p class="CDPAlignCenter3"><img src="assets/04bc2373-a824-45fc-b4d1-7beb0ab33bfb.png" class="calibre49"/></p>
<div class="CDPAlignCenter1">Figure 13: Apparent error (red curve) and generalization/true error (light blue)</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generalization/true error</h1>
                </header>
            
            <article>
                
<p class="calibre2">This is the second and more important type of error in data science. The whole purpose of building learning systems is the ability to get a smaller generalization error on the test set; in other words, to get the model to work well on a set of observation/samples that haven't been used in the training phase. If you still consider the class scenario from the previous section, you can think of generalization error as the ability to solve exam problems that weren’t necessarily similar to the problems you solved in the classroom to learn and get familiar with the subject. So, generalization performance is the model's ability to use the skills (parameters) that it learned in the training phase in order to correctly predict the outcome/output of unseen data.</p>
<p class="calibre2">In <em class="calibre19">Figure 13</em>, the light blue line represents the generalization error. You can see that as you increase the model complexity, the generalization error will be reduced, until some point when the model will start to lose its increasing power and the generalization error will decrease. This part of the curve where you get the generalization error to lose its increasing generalization power, is called <strong class="calibre13">overfitting</strong>.</p>
<p class="calibre2">The takeaway message from this section is to minimize the generalization error as much as you can.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p class="calibre2">A linear model is a very powerful tool that you can use as an initial learning algorithm if your data matches its assumptions. Understanding linear models will help you to understand more sophisticated models that use linear models as building blocks.</p>
<p class="calibre2">Next up, we will continue using the Titanic example by addressing model complexity and assessment in more detail. Model complexity is a very powerful tool and you need to use it carefully in order to enhance the generalization error. Misunderstanding it will lead to overfitting problems.</p>


            </article>

            
        </section>
    </body></html>